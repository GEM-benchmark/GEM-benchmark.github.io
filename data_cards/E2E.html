<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><meta name="description" content="Benchmark natural language generation systems with GEM."/><meta property="og:image" content="https://og-image.now.sh/**GEM**%20Benchmark.png?theme=light&amp;md=1&amp;fontSize=100px&amp;images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fvercel-triangle-black.svg"/><meta name="og:title" content="GEM"/><meta name="twitter:card" content="summary_large_image"/><title>GEM E2E</title><link rel="preload" href="/_next/static/css/2786522978a02f025205.css" as="style"/><link rel="stylesheet" href="/_next/static/css/2786522978a02f025205.css" data-n-g=""/><link rel="preload" href="/_next/static/css/f2fce7b83fe6ca04479b.css" as="style"/><link rel="stylesheet" href="/_next/static/css/f2fce7b83fe6ca04479b.css" data-n-p=""/><noscript data-n-css="true"></noscript><link rel="preload" href="/_next/static/chunks/main-47bc8f80085b54a800da.js" as="script"/><link rel="preload" href="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework.baa41d4dbf5d52db897c.js" as="script"/><link rel="preload" href="/_next/static/chunks/76fa31df43514ea5aaf6b0525de03ac0f65eec9e.4a36a385313236c59b19.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-a9ae7a6d1de4e51a7ab6.js" as="script"/><link rel="preload" href="/_next/static/chunks/cb1608f2.c3a9f0eb95374ca4919a.js" as="script"/><link rel="preload" href="/_next/static/chunks/3a03639cec9cbb3837db9d33dd6cd155d0d21f09.13fa0eac69555f2fe80c.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/data_cards/%5Bid%5D-e1361c13d80af81deda6.js" as="script"/></head><body><div id="__next"><div class="layout_background__1AVEa undefined"><header class="layout_header__2rhWq"><div class="navbar_navwrapper__15zia"><div class="navbar_gradbar__1Xi5u"></div><nav class="navbar_navbar__3gnco"><span class="utils_headingLg__de7p0 navbar_navbarlogo__PLEwr"><a href="/">GEM BENCHMARK</a></span><div class="navbar_menutoggle__358pJ" id="mobile-menu"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="bars" class="svg-inline--fa fa-bars fa-w-14 navbar_bar__QVPSR" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M16 132h416c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163 0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"></path></svg></div><ul><li class="navbar_navitem__3ICSG navbar_pushright__3G2DM"><a href="/resources">Resources</a></li><li class="navbar_navitem__3ICSG"><a href="/data_cards">Data Cards</a></li><li class="navbar_navitem__3ICSG"><a href="/model_cards">Model Cards</a></li><li class="navbar_navitem__3ICSG"><a href="/tutorials">tutorials</a></li><li class="navbar_navitem__3ICSG"><a href="/results">Results</a></li><li class="navbar_navitem__3ICSG"><a href="/papers">Papers</a></li><li class="navbar_navitem__3ICSG"><a href="/team">Team</a></li><li class="navbar_navitem__3ICSG"><a href="/nl_augmenter">NL-Augmenter</a></li><li class="navbar_navitem__3ICSG"><a href="/hackathon">Hackathon</a></li></ul></nav></div></header><div class="layout_container__2t4v2"><main><article><span class="utils_headingXl__1XecN">E2E</span><span class="utils_smallSpace__375iy"></span><span class="utils_lightText__12Ckm">Structure-to-Text</span><div><h2 id="table-of-contents">Table of Contents</h2>
<ul>
<li><a href="#dataset-description">Dataset Description</a>
<ul>
<li><a href="#dataset-and-task-summary">Dataset and Task Summary</a></li>
<li><a href="#why-is-this-dataset-part-of-gem">Why is this dataset part of GEM?</a></li>
<li><a href="#languages">Languages</a></li>
</ul>
</li>
<li><a href="#meta-information">Meta Information</a>
<ul>
<li><a href="#dataset-curators">Dataset Curators</a></li>
<li><a href="#licensing-information">Licensing Information</a></li>
<li><a href="#citation-information">Citation Information</a></li>
<li><a href="#leaderboard">Leaderboard</a></li>
</ul>
</li>
<li><a href="#dataset-structure">Dataset Structure</a>
<ul>
<li><a href="#data-instances">Data Instances</a></li>
<li><a href="#data-fields">Data Fields</a></li>
<li><a href="#data-statistics">Data Statistics</a></li>
</ul>
</li>
<li><a href="#dataset-creation">Dataset Creation</a>
<ul>
<li><a href="#curation-rationale">Curation Rationale</a></li>
<li><a href="#communicative-goal">Communicative Goal</a></li>
<li><a href="#source-data">Source Data</a>
<ul>
<li><a href="#initial-data-collection-and-normalization">Initial Data Collection and Normalization</a></li>
<li><a href="#who-are-the-source-language-producers">Who are the source language producers?</a></li>
</ul>
</li>
<li><a href="#annotations">Annotations</a>
<ul>
<li><a href="#annotation-process">Annotation process</a></li>
<li><a href="#who-are-the-annotators">Who are the annotators?</a></li>
</ul>
</li>
<li><a href="#personal-and-sensitive-information">Personal and Sensitive Information</a></li>
</ul>
</li>
<li><a href="#changes-to-the-original-dataset-for-gem">Changes to the Original Dataset for GEM</a>
<ul>
<li><a href="#special-test-sets">Special test sets</a>
<ul>
<li><a href="#data-shift">Data shift</a></li>
<li><a href="#transformations">Transformations</a></li>
<li><a href="#subpopulations">Subpopulations</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#considerations-for-using-the-data">Considerations for Using the Data</a>
<ul>
<li><a href="#social-impact-of-the-dataset">Social Impact of the Dataset</a></li>
<li><a href="#impact-on-underserved-communities">Impact on Underserved Communities</a></li>
<li><a href="#discussion-of-biases">Discussion of Biases</a></li>
<li><a href="#other-known-limitations">Other Known Limitations</a></li>
</ul>
</li>
<li><a href="#getting-started-with-in-depth-research-on-the-task">Getting started with in-depth research on the task</a></li>
</ul>
<h2 id="dataset-description">Dataset Description</h2>
<ul>
<li><strong>Homepage:</strong> <a href="http://www.macs.hw.ac.uk/InteractionLab/E2E/">http://www.macs.hw.ac.uk/InteractionLab/E2E/</a></li>
<li><strong>Repository:</strong> <a href="https://github.com/tuetschek/e2e-cleaning">https://github.com/tuetschek/e2e-cleaning</a> (cleaned version)</li>
<li><strong>Paper:</strong> <a href="https://www.aclweb.org/anthology/W17-5525/">First data release</a>,
<a href="https://doi.org/10.1016/j.csl.2019.06.009">Detailed E2E Challenge writeup</a>,
<a href="https://www.aclweb.org/anthology/W19-8652/">Cleaned E2E version</a></li>
<li><strong>Point of Contact:</strong> <a href="https://tuetschek.github.io/">Ondrej Dusek</a></li>
</ul>
<h3 id="dataset-and-task-summary">Dataset and Task Summary</h3>
<p>The E2E dataset is designed for a limited-domain data-to-text task -- generation of restaurant descriptions/recommendations based on up to 8 different attributes (name, area, price range etc.).</p>
<h3 id="why-is-this-dataset-part-of-gem">Why is this dataset part of GEM?</h3>
<p>The E2E dataset is one of the largest limited-domain NLG datasets and is frequently used as a data-to-text generation benchmark. The E2E Challenge included 20 systems of very different architectures, with <a href="https://github.com/tuetschek/e2e-eval">system outputs available</a> for download.</p>
<h3 id="languages">Languages</h3>
<p>English</p>
<h2 id="meta-information">Meta Information</h2>
<h3 id="dataset-curators">Dataset Curators</h3>
<p>Jekaterina Novikova, Ondrej Dusek, Verena Rieser (Heriot-Watt University)</p>
<h3 id="licensing-information">Licensing Information</h3>
<p>CC 4.0 BY-SA (<a href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons 4.0 Attribution – Share-Alike</a>)</p>
<h3 id="citation-information">Citation Information</h3>
<p>Cleaned version:</p>
<pre><code>@inproceedings{e2e_cleaned,
	address = {Tokyo, Japan},
	title = {Semantic {Noise} {Matters} for {Neural} {Natural} {Language} {Generation}},
	url = {https://www.aclweb.org/anthology/W19-8652/},
	booktitle = {Proceedings of the 12th {International} {Conference} on {Natural} {Language} {Generation} ({INLG} 2019)},
	author = {Dušek, Ondřej and Howcroft, David M and Rieser, Verena},
	year = {2019},
	pages = {421--426},
}
</code></pre>
<h3 id="leaderboard">Leaderboard</h3>
<h2 id="dataset-structure">Dataset Structure</h2>
<h3 id="data-instances">Data Instances</h3>
<p>All instances are input-output pairs.</p>
<p>Input (meaning representation -- set of attribute-value pairs):</p>
<pre><code>name[Alimentum], area[riverside], familyFriendly[yes], near[Burger King]
</code></pre>
<p>Output (natural language text):</p>
<pre><code>Alimentum is a kids friendly place in the riverside area near Burger King.
</code></pre>
<h3 id="data-fields">Data Fields</h3>
<p>The data is in a CSV format, with the following fields:</p>
<ul>
<li><code>mr</code> -- the meaning representation (MR, input)</li>
<li><code>ref</code> -- reference, i.e. the corresponding natural-language description (output)</li>
</ul>
<p>There are additional fields (<code>fixed</code>, <code>orig_mr</code>) indicating whether the data was modified in the
cleaning process and what was the original MR before cleaning, but these aren't used for NLG.</p>
<p>The MR has a flat structure -- attribute-value pairs are comma separated, with values
enclosed in brackets (see example above). There are 8 attributes:</p>
<ul>
<li><code>name</code> -- restaurant name</li>
<li><code>near</code> -- a landmark close to the restaurant</li>
<li><code>area</code> -- location (riverside, city centre)</li>
<li><code>food</code> -- food type / cuisine (e.g. Japanese, Indian, English etc.)</li>
<li><code>eatType</code> -- restaurant type (restaurant, coffee shop, pub)</li>
<li><code>priceRange</code> -- price range (low, medium, high, &#x3C;£20, £20-30, >£30)</li>
<li><code>rating</code> -- customer rating (low, medium, high, 1/5, 3/5, 5/5)</li>
<li><code>familyFriendly</code> -- is the restaurant family-friendly (yes/no)</li>
</ul>
<p>The same MR is often repeated multiple times with different synonymous references.</p>
<h3 id="data-statistics">Data Statistics</h3>
<table>
<thead>
<tr>
<th></th>
<th>MRs</th>
<th>Distinct MRs</th>
<th>References</th>
</tr>
</thead>
<tbody>
<tr>
<td>Training</td>
<td>12,568</td>
<td>8,362</td>
<td>33,525</td>
</tr>
<tr>
<td>Development</td>
<td>1,484</td>
<td>1,132</td>
<td>4,299</td>
</tr>
<tr>
<td>Test</td>
<td>1,847</td>
<td>1,358</td>
<td>4,693</td>
</tr>
<tr>
<td>Total</td>
<td>15,899</td>
<td>10,852</td>
<td>42,517</td>
</tr>
</tbody>
</table>
<p>The data are divided so that MRs in different data sections do not overlap.</p>
<p>“Distinct MRs” are MRs that remain distinct even if restaurant/place names (attributes <code>name</code>, <code>near</code>)
are delexicalized, i.e., replaced with a placeholder.</p>
<h2 id="dataset-creation">Dataset Creation</h2>
<h3 id="curation-rationale">Curation Rationale</h3>
<p>The dataset was collected to showcase/test neural NLG models. It is larger and contains more lexical richness
and syntactic variation than previous closed-domain NLG datasets.</p>
<h3 id="communicative-goal">Communicative Goal</h3>
<p>Producing a text informing/recommending a restaurant, given all and only the attributes specified on the input.</p>
<h3 id="source-data">Source Data</h3>
<h4 id="initial-data-collection-and-normalization">Initial Data Collection and Normalization</h4>
<p>The source MRs were generated automatically at random from a set of valid attribute values.</p>
<h4 id="who-are-the-source-language-producers">Who are the source language producers?</h4>
<p>N/A (dataset authors).</p>
<h3 id="annotations">Annotations</h3>
<h4 id="annotation-process">Annotation process</h4>
<p>Human references describing the MRs were collected by crowdsourcing on the CrowdFlower (now Appen) platform,
with either textual or pictorial MRs as a baseline. There were basic checks (length, valid characters, repetition).</p>
<p>The pictorial MRs were used in 20% of cases -- these yield higher lexical variation but introduce noise.</p>
<p>Since the original data was noisy (missing/superfluous attributes in the references), GEM uses the later cleaned
version. It contains the same data, but MRs were reannotated by an automatic script based on regular expression
matching.</p>
<h4 id="who-are-the-annotators">Who are the annotators?</h4>
<p>Native English speakers (self-reported &#x26; geographically limited) on the Crowdflower/Appen crowdsourcing platform.</p>
<h3 id="personal-and-sensitive-information">Personal and Sensitive Information</h3>
<p>None present.</p>
<h2 id="changes-to-the-original-dataset-for-gem">Changes to the Original Dataset for GEM</h2>
<p>Using the cleaned version of E2E, otherwise none.</p>
<h3 id="special-test-sets">Special test sets</h3>
<p>4 special test sets for E2E were added to the GEM evaluation suite.</p>
<h4 id="data-shift">Data shift</h4>
<p>We created subsets of the training and development sets of ~500 randomly selected inputs each.</p>
<h4 id="transformations">Transformations</h4>
<p>We applied input scrambling on a subset of 500 randomly selected test instances; the order of the input properties was randomly reassigned.</p>
<h4 id="subpopulations">Subpopulations</h4>
<p>For the input size, we created subpopulations based on the number of restaurant properties in the input.</p>
<table>
<thead>
<tr>
<th>Input length</th>
<th>Frequency English</th>
</tr>
</thead>
<tbody>
<tr>
<td>2</td>
<td>5</td>
</tr>
<tr>
<td>3</td>
<td>120</td>
</tr>
<tr>
<td>4</td>
<td>389</td>
</tr>
<tr>
<td>5</td>
<td>737</td>
</tr>
<tr>
<td>6</td>
<td>1187</td>
</tr>
<tr>
<td>7</td>
<td>1406</td>
</tr>
<tr>
<td>8</td>
<td>774</td>
</tr>
<tr>
<td>9</td>
<td>73</td>
</tr>
<tr>
<td>10</td>
<td>2</td>
</tr>
</tbody>
</table>
<h2 id="considerations-for-using-the-data">Considerations for Using the Data</h2>
<h3 id="social-impact-of-the-dataset">Social Impact of the Dataset</h3>
<p>N/A</p>
<h3 id="impact-on-underserved-communities">Impact on Underserved Communities</h3>
<p>N/A</p>
<h3 id="discussion-of-biases">Discussion of Biases</h3>
<p>The source data is generated randomly, so it should not contain biases. The human references may be biased by the workers'
demographic, but that was not investigated upon data collection.</p>
<h3 id="other-known-limitations">Other Known Limitations</h3>
<p>Even the cleaned version does contain some (low) amounts of noise.</p>
<h2 id="getting-started-with-in-depth-research-on-the-task">Getting started with in-depth research on the task</h2>
<p>[More Information Needed]</p>
</div></article></main><div class="layout_push__1J9g0"></div></div><footer class="layout_footer__127N0 utils_eggshell__Njxsh"><span class="layout_backToHome__1vZsp"><a href="/">← Home</a></span><span>If you have any questions, please join our <a href="https://groups.google.com/g/gem-benchmark" target="_blank" class="utils_accentUnderline__k083p">google group</a> for support.</span></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"taskData":{"id":"E2E","contentHtml":"\u003ch2 id=\"table-of-contents\"\u003eTable of Contents\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#dataset-description\"\u003eDataset Description\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#dataset-and-task-summary\"\u003eDataset and Task Summary\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#why-is-this-dataset-part-of-gem\"\u003eWhy is this dataset part of GEM?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#languages\"\u003eLanguages\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#meta-information\"\u003eMeta Information\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#dataset-curators\"\u003eDataset Curators\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#licensing-information\"\u003eLicensing Information\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#citation-information\"\u003eCitation Information\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#leaderboard\"\u003eLeaderboard\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#dataset-structure\"\u003eDataset Structure\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#data-instances\"\u003eData Instances\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#data-fields\"\u003eData Fields\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#data-statistics\"\u003eData Statistics\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#dataset-creation\"\u003eDataset Creation\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#curation-rationale\"\u003eCuration Rationale\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#communicative-goal\"\u003eCommunicative Goal\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#source-data\"\u003eSource Data\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#initial-data-collection-and-normalization\"\u003eInitial Data Collection and Normalization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#who-are-the-source-language-producers\"\u003eWho are the source language producers?\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#annotations\"\u003eAnnotations\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#annotation-process\"\u003eAnnotation process\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#who-are-the-annotators\"\u003eWho are the annotators?\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#personal-and-sensitive-information\"\u003ePersonal and Sensitive Information\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#changes-to-the-original-dataset-for-gem\"\u003eChanges to the Original Dataset for GEM\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#special-test-sets\"\u003eSpecial test sets\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#data-shift\"\u003eData shift\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#transformations\"\u003eTransformations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#subpopulations\"\u003eSubpopulations\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#considerations-for-using-the-data\"\u003eConsiderations for Using the Data\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#social-impact-of-the-dataset\"\u003eSocial Impact of the Dataset\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#impact-on-underserved-communities\"\u003eImpact on Underserved Communities\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#discussion-of-biases\"\u003eDiscussion of Biases\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#other-known-limitations\"\u003eOther Known Limitations\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#getting-started-with-in-depth-research-on-the-task\"\u003eGetting started with in-depth research on the task\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"dataset-description\"\u003eDataset Description\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eHomepage:\u003c/strong\u003e \u003ca href=\"http://www.macs.hw.ac.uk/InteractionLab/E2E/\"\u003ehttp://www.macs.hw.ac.uk/InteractionLab/E2E/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRepository:\u003c/strong\u003e \u003ca href=\"https://github.com/tuetschek/e2e-cleaning\"\u003ehttps://github.com/tuetschek/e2e-cleaning\u003c/a\u003e (cleaned version)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePaper:\u003c/strong\u003e \u003ca href=\"https://www.aclweb.org/anthology/W17-5525/\"\u003eFirst data release\u003c/a\u003e,\n\u003ca href=\"https://doi.org/10.1016/j.csl.2019.06.009\"\u003eDetailed E2E Challenge writeup\u003c/a\u003e,\n\u003ca href=\"https://www.aclweb.org/anthology/W19-8652/\"\u003eCleaned E2E version\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePoint of Contact:\u003c/strong\u003e \u003ca href=\"https://tuetschek.github.io/\"\u003eOndrej Dusek\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"dataset-and-task-summary\"\u003eDataset and Task Summary\u003c/h3\u003e\n\u003cp\u003eThe E2E dataset is designed for a limited-domain data-to-text task -- generation of restaurant descriptions/recommendations based on up to 8 different attributes (name, area, price range etc.).\u003c/p\u003e\n\u003ch3 id=\"why-is-this-dataset-part-of-gem\"\u003eWhy is this dataset part of GEM?\u003c/h3\u003e\n\u003cp\u003eThe E2E dataset is one of the largest limited-domain NLG datasets and is frequently used as a data-to-text generation benchmark. The E2E Challenge included 20 systems of very different architectures, with \u003ca href=\"https://github.com/tuetschek/e2e-eval\"\u003esystem outputs available\u003c/a\u003e for download.\u003c/p\u003e\n\u003ch3 id=\"languages\"\u003eLanguages\u003c/h3\u003e\n\u003cp\u003eEnglish\u003c/p\u003e\n\u003ch2 id=\"meta-information\"\u003eMeta Information\u003c/h2\u003e\n\u003ch3 id=\"dataset-curators\"\u003eDataset Curators\u003c/h3\u003e\n\u003cp\u003eJekaterina Novikova, Ondrej Dusek, Verena Rieser (Heriot-Watt University)\u003c/p\u003e\n\u003ch3 id=\"licensing-information\"\u003eLicensing Information\u003c/h3\u003e\n\u003cp\u003eCC 4.0 BY-SA (\u003ca href=\"https://creativecommons.org/licenses/by-sa/4.0/\"\u003eCreative Commons 4.0 Attribution – Share-Alike\u003c/a\u003e)\u003c/p\u003e\n\u003ch3 id=\"citation-information\"\u003eCitation Information\u003c/h3\u003e\n\u003cp\u003eCleaned version:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e@inproceedings{e2e_cleaned,\n\taddress = {Tokyo, Japan},\n\ttitle = {Semantic {Noise} {Matters} for {Neural} {Natural} {Language} {Generation}},\n\turl = {https://www.aclweb.org/anthology/W19-8652/},\n\tbooktitle = {Proceedings of the 12th {International} {Conference} on {Natural} {Language} {Generation} ({INLG} 2019)},\n\tauthor = {Dušek, Ondřej and Howcroft, David M and Rieser, Verena},\n\tyear = {2019},\n\tpages = {421--426},\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"leaderboard\"\u003eLeaderboard\u003c/h3\u003e\n\u003ch2 id=\"dataset-structure\"\u003eDataset Structure\u003c/h2\u003e\n\u003ch3 id=\"data-instances\"\u003eData Instances\u003c/h3\u003e\n\u003cp\u003eAll instances are input-output pairs.\u003c/p\u003e\n\u003cp\u003eInput (meaning representation -- set of attribute-value pairs):\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ename[Alimentum], area[riverside], familyFriendly[yes], near[Burger King]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOutput (natural language text):\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eAlimentum is a kids friendly place in the riverside area near Burger King.\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"data-fields\"\u003eData Fields\u003c/h3\u003e\n\u003cp\u003eThe data is in a CSV format, with the following fields:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003emr\u003c/code\u003e -- the meaning representation (MR, input)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eref\u003c/code\u003e -- reference, i.e. the corresponding natural-language description (output)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThere are additional fields (\u003ccode\u003efixed\u003c/code\u003e, \u003ccode\u003eorig_mr\u003c/code\u003e) indicating whether the data was modified in the\ncleaning process and what was the original MR before cleaning, but these aren't used for NLG.\u003c/p\u003e\n\u003cp\u003eThe MR has a flat structure -- attribute-value pairs are comma separated, with values\nenclosed in brackets (see example above). There are 8 attributes:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ename\u003c/code\u003e -- restaurant name\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003enear\u003c/code\u003e -- a landmark close to the restaurant\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003earea\u003c/code\u003e -- location (riverside, city centre)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003efood\u003c/code\u003e -- food type / cuisine (e.g. Japanese, Indian, English etc.)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eeatType\u003c/code\u003e -- restaurant type (restaurant, coffee shop, pub)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003epriceRange\u003c/code\u003e -- price range (low, medium, high, \u0026#x3C;£20, £20-30, \u003e£30)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003erating\u003c/code\u003e -- customer rating (low, medium, high, 1/5, 3/5, 5/5)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003efamilyFriendly\u003c/code\u003e -- is the restaurant family-friendly (yes/no)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe same MR is often repeated multiple times with different synonymous references.\u003c/p\u003e\n\u003ch3 id=\"data-statistics\"\u003eData Statistics\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003eMRs\u003c/th\u003e\n\u003cth\u003eDistinct MRs\u003c/th\u003e\n\u003cth\u003eReferences\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eTraining\u003c/td\u003e\n\u003ctd\u003e12,568\u003c/td\u003e\n\u003ctd\u003e8,362\u003c/td\u003e\n\u003ctd\u003e33,525\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eDevelopment\u003c/td\u003e\n\u003ctd\u003e1,484\u003c/td\u003e\n\u003ctd\u003e1,132\u003c/td\u003e\n\u003ctd\u003e4,299\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eTest\u003c/td\u003e\n\u003ctd\u003e1,847\u003c/td\u003e\n\u003ctd\u003e1,358\u003c/td\u003e\n\u003ctd\u003e4,693\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eTotal\u003c/td\u003e\n\u003ctd\u003e15,899\u003c/td\u003e\n\u003ctd\u003e10,852\u003c/td\u003e\n\u003ctd\u003e42,517\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eThe data are divided so that MRs in different data sections do not overlap.\u003c/p\u003e\n\u003cp\u003e“Distinct MRs” are MRs that remain distinct even if restaurant/place names (attributes \u003ccode\u003ename\u003c/code\u003e, \u003ccode\u003enear\u003c/code\u003e)\nare delexicalized, i.e., replaced with a placeholder.\u003c/p\u003e\n\u003ch2 id=\"dataset-creation\"\u003eDataset Creation\u003c/h2\u003e\n\u003ch3 id=\"curation-rationale\"\u003eCuration Rationale\u003c/h3\u003e\n\u003cp\u003eThe dataset was collected to showcase/test neural NLG models. It is larger and contains more lexical richness\nand syntactic variation than previous closed-domain NLG datasets.\u003c/p\u003e\n\u003ch3 id=\"communicative-goal\"\u003eCommunicative Goal\u003c/h3\u003e\n\u003cp\u003eProducing a text informing/recommending a restaurant, given all and only the attributes specified on the input.\u003c/p\u003e\n\u003ch3 id=\"source-data\"\u003eSource Data\u003c/h3\u003e\n\u003ch4 id=\"initial-data-collection-and-normalization\"\u003eInitial Data Collection and Normalization\u003c/h4\u003e\n\u003cp\u003eThe source MRs were generated automatically at random from a set of valid attribute values.\u003c/p\u003e\n\u003ch4 id=\"who-are-the-source-language-producers\"\u003eWho are the source language producers?\u003c/h4\u003e\n\u003cp\u003eN/A (dataset authors).\u003c/p\u003e\n\u003ch3 id=\"annotations\"\u003eAnnotations\u003c/h3\u003e\n\u003ch4 id=\"annotation-process\"\u003eAnnotation process\u003c/h4\u003e\n\u003cp\u003eHuman references describing the MRs were collected by crowdsourcing on the CrowdFlower (now Appen) platform,\nwith either textual or pictorial MRs as a baseline. There were basic checks (length, valid characters, repetition).\u003c/p\u003e\n\u003cp\u003eThe pictorial MRs were used in 20% of cases -- these yield higher lexical variation but introduce noise.\u003c/p\u003e\n\u003cp\u003eSince the original data was noisy (missing/superfluous attributes in the references), GEM uses the later cleaned\nversion. It contains the same data, but MRs were reannotated by an automatic script based on regular expression\nmatching.\u003c/p\u003e\n\u003ch4 id=\"who-are-the-annotators\"\u003eWho are the annotators?\u003c/h4\u003e\n\u003cp\u003eNative English speakers (self-reported \u0026#x26; geographically limited) on the Crowdflower/Appen crowdsourcing platform.\u003c/p\u003e\n\u003ch3 id=\"personal-and-sensitive-information\"\u003ePersonal and Sensitive Information\u003c/h3\u003e\n\u003cp\u003eNone present.\u003c/p\u003e\n\u003ch2 id=\"changes-to-the-original-dataset-for-gem\"\u003eChanges to the Original Dataset for GEM\u003c/h2\u003e\n\u003cp\u003eUsing the cleaned version of E2E, otherwise none.\u003c/p\u003e\n\u003ch3 id=\"special-test-sets\"\u003eSpecial test sets\u003c/h3\u003e\n\u003cp\u003e4 special test sets for E2E were added to the GEM evaluation suite.\u003c/p\u003e\n\u003ch4 id=\"data-shift\"\u003eData shift\u003c/h4\u003e\n\u003cp\u003eWe created subsets of the training and development sets of ~500 randomly selected inputs each.\u003c/p\u003e\n\u003ch4 id=\"transformations\"\u003eTransformations\u003c/h4\u003e\n\u003cp\u003eWe applied input scrambling on a subset of 500 randomly selected test instances; the order of the input properties was randomly reassigned.\u003c/p\u003e\n\u003ch4 id=\"subpopulations\"\u003eSubpopulations\u003c/h4\u003e\n\u003cp\u003eFor the input size, we created subpopulations based on the number of restaurant properties in the input.\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eInput length\u003c/th\u003e\n\u003cth\u003eFrequency English\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e2\u003c/td\u003e\n\u003ctd\u003e5\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e3\u003c/td\u003e\n\u003ctd\u003e120\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e4\u003c/td\u003e\n\u003ctd\u003e389\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e5\u003c/td\u003e\n\u003ctd\u003e737\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e6\u003c/td\u003e\n\u003ctd\u003e1187\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e7\u003c/td\u003e\n\u003ctd\u003e1406\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e8\u003c/td\u003e\n\u003ctd\u003e774\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e9\u003c/td\u003e\n\u003ctd\u003e73\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e10\u003c/td\u003e\n\u003ctd\u003e2\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"considerations-for-using-the-data\"\u003eConsiderations for Using the Data\u003c/h2\u003e\n\u003ch3 id=\"social-impact-of-the-dataset\"\u003eSocial Impact of the Dataset\u003c/h3\u003e\n\u003cp\u003eN/A\u003c/p\u003e\n\u003ch3 id=\"impact-on-underserved-communities\"\u003eImpact on Underserved Communities\u003c/h3\u003e\n\u003cp\u003eN/A\u003c/p\u003e\n\u003ch3 id=\"discussion-of-biases\"\u003eDiscussion of Biases\u003c/h3\u003e\n\u003cp\u003eThe source data is generated randomly, so it should not contain biases. The human references may be biased by the workers'\ndemographic, but that was not investigated upon data collection.\u003c/p\u003e\n\u003ch3 id=\"other-known-limitations\"\u003eOther Known Limitations\u003c/h3\u003e\n\u003cp\u003eEven the cleaned version does contain some (low) amounts of noise.\u003c/p\u003e\n\u003ch2 id=\"getting-started-with-in-depth-research-on-the-task\"\u003eGetting started with in-depth research on the task\u003c/h2\u003e\n\u003cp\u003e[More Information Needed]\u003c/p\u003e\n","title":"E2E","type":"Structure-to-Text","motivation":"One of the largest limited-domain NLG datasets and is frequently used as a data-to-text generation benchmark."}},"__N_SSG":true},"page":"/data_cards/[id]","query":{"id":"E2E"},"buildId":"WmDhnIlazRejKhqFfVoJ_","nextExport":false,"isFallback":false,"gsp":true,"head":[["meta",{"name":"viewport","content":"width=device-width"}],["meta",{"charSet":"utf-8"}],["link",{"rel":"icon","href":"/favicon.ico"}],["meta",{"name":"description","content":"Benchmark natural language generation systems with GEM."}],["meta",{"property":"og:image","content":"https://og-image.now.sh/**GEM**%20Benchmark.png?theme=light\u0026md=1\u0026fontSize=100px\u0026images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fvercel-triangle-black.svg"}],["meta",{"name":"og:title","content":"GEM"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["title",{"children":"GEM E2E"}]]}</script><script nomodule="" src="/_next/static/chunks/polyfills-e935b474c81cf901504d.js"></script><script src="/_next/static/chunks/main-47bc8f80085b54a800da.js" async=""></script><script src="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" async=""></script><script src="/_next/static/chunks/framework.baa41d4dbf5d52db897c.js" async=""></script><script src="/_next/static/chunks/76fa31df43514ea5aaf6b0525de03ac0f65eec9e.4a36a385313236c59b19.js" async=""></script><script src="/_next/static/chunks/pages/_app-a9ae7a6d1de4e51a7ab6.js" async=""></script><script src="/_next/static/chunks/cb1608f2.c3a9f0eb95374ca4919a.js" async=""></script><script src="/_next/static/chunks/3a03639cec9cbb3837db9d33dd6cd155d0d21f09.13fa0eac69555f2fe80c.js" async=""></script><script src="/_next/static/chunks/pages/data_cards/%5Bid%5D-e1361c13d80af81deda6.js" async=""></script><script src="/_next/static/WmDhnIlazRejKhqFfVoJ_/_buildManifest.js" async=""></script><script src="/_next/static/WmDhnIlazRejKhqFfVoJ_/_ssgManifest.js" async=""></script></body></html>