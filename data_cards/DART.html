<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><meta name="description" content="Benchmark natural language generation systems with GEM."/><meta property="og:image" content="https://og-image.now.sh/**GEM**%20Benchmark.png?theme=light&amp;md=1&amp;fontSize=100px&amp;images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fvercel-triangle-black.svg"/><meta name="og:title" content="GEM"/><meta name="twitter:card" content="summary_large_image"/><title>GEM DART</title><link rel="preload" href="/_next/static/css/2786522978a02f025205.css" as="style"/><link rel="stylesheet" href="/_next/static/css/2786522978a02f025205.css" data-n-g=""/><link rel="preload" href="/_next/static/css/f2fce7b83fe6ca04479b.css" as="style"/><link rel="stylesheet" href="/_next/static/css/f2fce7b83fe6ca04479b.css" data-n-p=""/><noscript data-n-css="true"></noscript><link rel="preload" href="/_next/static/chunks/main-47bc8f80085b54a800da.js" as="script"/><link rel="preload" href="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework.baa41d4dbf5d52db897c.js" as="script"/><link rel="preload" href="/_next/static/chunks/e70fad557dfa42f32a11d0d2c99fe8f6e8d1fa86.4a36a385313236c59b19.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-a9ae7a6d1de4e51a7ab6.js" as="script"/><link rel="preload" href="/_next/static/chunks/cb1608f2.c3a9f0eb95374ca4919a.js" as="script"/><link rel="preload" href="/_next/static/chunks/451c6be158cef50d8cc28b919cf08d1e5b9ff3fc.f0ec181e43727e8a893e.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/data_cards/%5Bid%5D-e1361c13d80af81deda6.js" as="script"/></head><body><div id="__next"><div class="layout_background__1AVEa undefined"><header class="layout_header__2rhWq"><div class="navbar_navwrapper__15zia"><div class="navbar_gradbar__1Xi5u"></div><nav class="navbar_navbar__3gnco"><span class="utils_headingLg__de7p0 navbar_navbarlogo__PLEwr"><a href="/">GEM BENCHMARK</a></span><div class="navbar_menutoggle__358pJ" id="mobile-menu"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="bars" class="svg-inline--fa fa-bars fa-w-14 navbar_bar__QVPSR" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M16 132h416c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163 0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"></path></svg></div><ul><li class="navbar_navitem__3ICSG navbar_pushright__3G2DM"><a href="/resources">Resources</a></li><li class="navbar_navitem__3ICSG"><a href="/data_cards">Data Cards</a></li><li class="navbar_navitem__3ICSG"><a href="/model_cards">Model Cards</a></li><li class="navbar_navitem__3ICSG"><a href="/tutorials">tutorials</a></li><li class="navbar_navitem__3ICSG"><a href="/results">Results</a></li><li class="navbar_navitem__3ICSG"><a href="/papers">Papers</a></li><li class="navbar_navitem__3ICSG"><a href="/team">Team</a></li><li class="navbar_navitem__3ICSG"><a href="/nl_augmenter">NL-Augmenter</a></li><li class="navbar_navitem__3ICSG"><a href="/workshop">Workshop</a></li></ul></nav></div></header><div class="layout_container__2t4v2"><main><article><span class="utils_headingXl__1XecN">DART</span><span class="utils_smallSpace__375iy"></span><span class="utils_lightText__12Ckm">Structure-to-Text</span><div><h2 id="table-of-contents">Table of Contents</h2>
<ul>
<li><a href="#dataset-description">Dataset Description</a>
<ul>
<li><a href="#dataset-and-task-summary">Dataset and Task Summary</a></li>
<li><a href="#why-is-this-dataset-part-of-gem">Why is this dataset part of GEM?</a></li>
<li><a href="#languages">Languages</a></li>
</ul>
</li>
<li><a href="#meta-information">Meta Information</a>
<ul>
<li><a href="#dataset-curators">Dataset Curators</a></li>
<li><a href="#licensing-information">Licensing Information</a></li>
<li><a href="#citation-information">Citation Information</a></li>
<li><a href="#leaderboard">Leaderboard</a></li>
</ul>
</li>
<li><a href="#dataset-structure">Dataset Structure</a>
<ul>
<li><a href="#data-instances">Data Instances</a></li>
<li><a href="#data-fields">Data Fields</a></li>
<li><a href="#data-statistics">Data Statistics</a></li>
</ul>
</li>
<li><a href="#dataset-creation">Dataset Creation</a>
<ul>
<li><a href="#curation-rationale">Curation Rationale</a></li>
<li><a href="#communicative-goal">Communicative Goal</a></li>
<li><a href="#source-data">Source Data</a>
<ul>
<li><a href="#initial-data-collection-and-normalization">Initial Data Collection and Normalization</a></li>
<li><a href="#who-are-the-source-language-producers">Who are the source language producers?</a></li>
</ul>
</li>
<li><a href="#annotations">Annotations</a>
<ul>
<li><a href="#annotation-process">Annotation process</a></li>
<li><a href="#who-are-the-annotators">Who are the annotators?</a></li>
</ul>
</li>
<li><a href="#personal-and-sensitive-information">Personal and Sensitive Information</a></li>
</ul>
</li>
<li><a href="#changes-to-the-original-dataset-for-gem">Changes to the Original Dataset for GEM</a></li>
<li><a href="#considerations-for-using-the-data">Considerations for Using the Data</a>
<ul>
<li><a href="#social-impact-of-the-dataset">Social Impact of the Dataset</a></li>
<li><a href="#impact-on-underserved-communities">Impact on Underserved Communities</a></li>
<li><a href="#discussion-of-biases">Discussion of Biases</a></li>
<li><a href="#other-known-limitations">Other Known Limitations</a></li>
</ul>
</li>
<li><a href="#getting-started-with-in-depth-research-on-the-task">Getting started with in-depth research on the task</a></li>
</ul>
<h2 id="dataset-description">Dataset Description</h2>
<ul>
<li><strong>Homepage:</strong> None (See <strong>Repository</strong>)</li>
<li><strong>Repository:</strong> <a href="https://github.com/Yale-LILY/dart">DART repository</a></li>
<li><strong>Paper:</strong> <a href="https://arxiv.org/abs/2007.02871">DART: Open-Domain Structured Data Record to Text Generation</a></li>
<li><strong>Point of Contact:</strong> {dragomir.radev, r.zhang}@yale.edu, {nazneen.rajani}@salesforce.com</li>
</ul>
<h3 id="dataset-and-task-summary">Dataset and Task Summary</h3>
<p>DART is a large and open-domain structured DAta Record to Text generation corpus with high-quality sentence annotations with each input being a set of entity-relation triples following a tree-structured ontology. It consists of 82191 examples across different domains with each input being a semantic RDF triple set derived from data records in tables and the tree ontology of table schema, annotated with sentence description that covers all facts in the triple set.</p>
<h3 id="why-is-this-dataset-part-of-gem">Why is this dataset part of GEM?</h3>
<p>DART is one of the two datasets representing Table-to-Text NLG in GEM.</p>
<h3 id="languages">Languages</h3>
<p>DART contains English text only (BCP-47: en).</p>
<h2 id="meta-information">Meta Information</h2>
<h3 id="dataset-curators">Dataset Curators</h3>
<p>The dataset was curated by a joint team of researchers from the Yale University, Salesforce Research, the University of Hong Kong, MIT and the University of the Chinese Academy of Sciences.
{dragomir.radev, r.zhang}@yale.edu, {nazneen.rajani}@salesforce.com</p>
<h3 id="licensing-information">Licensing Information</h3>
<p>The dataset was obtained by using multiple complementary methods: (1) human annotation on open-domain Wikipedia tables from WikiTableQuestions (<a href="https://www.aclweb.org/anthology/P15-1142.pdf">Pasupat and Liang, 2015</a>) and WikiSQL (<a href="https://arxiv.org/pdf/1709.00103.pdf">Zhong et al., 2017</a>), (2) automatic conversion of questions in WikiSQL to declarative sentences and (3) incorporation of existing datasets including WebNLG 2017 (Gardent et al., 2017<a href="https://www.aclweb.org/anthology/P17-1017.pdf">a</a>,<a href="https://www.aclweb.org/anthology/W17-3518.pdf">b</a>; <a href="https://www.aclweb.org/anthology/W18-6543.pdf">Shimorina and Gardent, 2018</a>) and Cleaned E2E (<a href="https://arxiv.org/pdf/1706.09254.pdf">Novikova et al., 2017b</a>; Du≈°ek et al., <a href="https://arxiv.org/pdf/1810.01170.pdf">2018</a>, <a href="https://www.aclweb.org/anthology/W19-8652.pdf">2019</a>)</p>
<p>The repository code is under an <a href="https://github.com/Yale-LILY/dart/blob/master/LICENSE">MIT license</a>.</p>
<h3 id="citation-information">Citation Information</h3>
<p>@article{radev2020dart,
title={DART: Open-Domain Structured Data Record to Text Generation},
author={Dragomir Radev and Rui Zhang and Amrit Rau and Abhinand Sivaprasad and Chiachun Hsieh and Nazneen Fatema Rajani and Xiangru Tang and Aadit Vyas and Neha Verma and Pranav Krishna and Yangxiaokang Liu and Nadia Irwanto and Jessica Pan and Faiaz Rahman and Ahmad Zaidi and Murori Mutuma and Yasin Tarabar and Ankit Gupta and Tao Yu and Yi Chern Tan and Xi Victoria Lin and Caiming Xiong and Richard Socher},
journal={arXiv preprint arXiv:2007.02871},
year={2020}
}</p>
<h3 id="leaderboard">Leaderboard</h3>
<p>The dataset supports an active leaderboard, the best results are tracked <a href="https://github.com/Yale-LILY/dart#leaderboard">here</a>. Several state-of-the-art table-to-text models were evaluated on DART, such as BART (<a href="https://arxiv.org/pdf/1910.13461.pdf">Lewis et al., 2020</a>), Seq2Seq-Att (<a href="https://webnlg-challenge.loria.fr/files/melbourne_report.pdf">MELBOURNE</a>) and End-to-End Transformer (<a href="https://arxiv.org/pdf/1908.09022.pdf">Castro Ferreira et al., 2019</a>).
The leaderboard reports BLEU, METEOR, TER, MoverScore, BERTScore and BLEURT scores.</p>
<h2 id="dataset-structure">Dataset Structure</h2>
<h3 id="data-instances">Data Instances</h3>
<p>The DART dataset is available in the data/ directory. The dataset consists of JSON files in data/. Each JSON file contains a list of tripleset-annotation pairs of the form:
{
"tripleset": [
[
"Ben Mauk",
"High school",
"Kenton"
],
[
"Ben Mauk",
"College",
"Wake Forest Cincinnati"
]
],
"subtree_was_extended": false,
"annotations": [
{
"source": "WikiTableQuestions_lily",
"text": "Ben Mauk, who attended Kenton High School, attended Wake Forest Cincinnati for college."
}
]
}</p>
<p>Creators provided delexicalization dictionaries in data/**/delex/ that map string entities to entity categories.</p>
<h3 id="data-fields">Data Fields</h3>
<p>tripleset: a list of tuples, each tuple has 3 items
subtree_was_extended: a boolean variable (true or false)
annotations: a list of dict, each with source and text keys.
source: a string mentioning the name of the source table.
text: a sentence string.</p>
<h3 id="data-statistics">Data Statistics</h3>
<table>
<thead>
<tr>
<th>Input Unit</th>
<th>Examples</th>
<th>Vocab Size</th>
<th>Words per SR</th>
<th>Sents per SR</th>
<th>Tables</th>
</tr>
</thead>
<tbody>
<tr>
<td>Triple Set</td>
<td>82,191</td>
<td>33.2K</td>
<td>21.6</td>
<td>1.5</td>
<td>5,623</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>Train</th>
<th>Dev</th>
<th>Test</th>
</tr>
</thead>
<tbody>
<tr>
<td>62,659</td>
<td>6,980</td>
<td>12,552</td>
</tr>
</tbody>
</table>
<p>Statistics of DART decomposed by different collection methods. DART exhibits a great deal of topical variety in terms of the number of unique predicates, the number of unique triples, and the vocabulary size. These statistics are computed from DART v1.1.1; the number of unique predicates reported is post-unification (see Section 3.4). SR: Surface Realization.
(<a href="https://arxiv.org/pdf/2007.02871.pdf">details in Table 1 and 2</a>).</p>
<h2 id="dataset-creation">Dataset Creation</h2>
<h3 id="curation-rationale">Curation Rationale</h3>
<p>The dataset creators encourage through DART further research in natural language generation from semantic data.
DART provides high-quality sentence annotations with each input being a set of entity-relation triples in a tree structure.</p>
<h3 id="communicative-goal">Communicative Goal</h3>
<p>The speaker is required to produce coherent sentences and construct a trees structured ontology of the column headers.</p>
<h3 id="source-data">Source Data</h3>
<p>The dataset re-uses data from the following pre-existing resources:
(1) human annotation on open-domain Wikipedia tables from WikiTableQuestions (<a href="https://www.aclweb.org/anthology/P15-1142.pdf">Pasupat and Liang,
2015</a>) and WikiSQL (<a href="https://arxiv.org/pdf/1709.00103.pdf">Zhong et al., 2017</a>)
(2) automatic conversion of questions in
WikiSQL to declarative sentences
(3) incorporation of existing datasets including WebNLG 2017 (Gardent et al., 2017<a href="https://www.aclweb.org/anthology/P17-1017.pdf">a</a>,<a href="https://www.aclweb.org/anthology/W17-3518.pdf">b</a>; <a href="https://www.aclweb.org/anthology/W18-6543.pdf">Shimorina and Gardent, 2018</a>) and Cleaned E2E (<a href="https://arxiv.org/pdf/1706.09254.pdf">Novikova et al., 2017b</a>; Du≈°ek et al., <a href="https://arxiv.org/pdf/1810.01170.pdf">2018</a>, <a href="https://www.aclweb.org/anthology/W19-8652.pdf">2019</a>)</p>
<p>Creators also explored automatic alignments between the knowledge base and text including Neural Wikipedian (<a href="https://arxiv.org/pdf/1711.00155.pdf">Vougiouklis et al., 2018</a>) and TRex (<a href="https://www.aclweb.org/anthology/L18-1544.pdf">Elsahar et al., 2018</a>).</p>
<p>We refer the reader to the papers describing these sources for further information.</p>
<h4 id="initial-data-collection-and-normalization">Initial Data Collection and Normalization</h4>
<p>The training data consists of concept sets and captions for the source datasets listed above.
For conversion of a meaning representation (MR) to a triple set, where the NAME slot was represented as the subject.</p>
<h4 id="who-are-the-source-language-producers">Who are the source language producers?</h4>
<p>The language producers are Wikipedia authors and/or editors for Wikipedia tables (WikiTableQuestions, WikiSQL, WebNLG), crowdworkers (E2E) and annotators (DART, E2E).</p>
<p>No demographic information is provided.</p>
<h3 id="annotations">Annotations</h3>
<h4 id="annotation-process">Annotation process</h4>
<p>Creators proposed a two-stage annotation process for constructing triple set sentence pairs based on a tree-structured ontology of each table. First, internal skilled annotators denote the parent column for each column header. Then, a larger number of annotators provide a sentential description of an automatically-chosen subset of table cells in a row. To form a triple set sentence pair, the highlighted cells can be converted to a connected triple set automatically according to the column ontology for the given table.</p>
<h4 id="who-are-the-annotators">Who are the annotators?</h4>
<p>No further information about the MTurk workers has been provided.</p>
<h3 id="personal-and-sensitive-information">Personal and Sensitive Information</h3>
<p>[N/A]</p>
<h2 id="changes-to-the-original-dataset-for-gem">Changes to the Original Dataset for GEM</h2>
<p>No changes were made to the original dataset for GEM at the moment of writing this.
We may, at some future point, introduce additional test set annotation (related to difficulty/challenging-ness) or introduce challenge sets - these are at the moment only tentatively planned.</p>
<h2 id="considerations-for-using-the-data">Considerations for Using the Data</h2>
<h3 id="social-impact-of-the-dataset">Social Impact of the Dataset</h3>
<p>The task is presented as a stepping stone towards building models that achieve more human-like text generation.</p>
<h3 id="impact-on-underserved-communities">Impact on Underserved Communities</h3>
<p>The dataset is in English, a language with an abundance of existing resources.</p>
<h3 id="discussion-of-biases">Discussion of Biases</h3>
<p>The dataset may contain some social biases, as the input sentences are based on Wikipedia (WikiTableQuestions, WikiSQL, WebNLG). Studies have shown that the English Wikipedia contains gender biases(<a href="https://www.aclweb.org/anthology/2020.emnlp-main.23.pdf">Dinan et al., 2020</a>), racial biases([Papakyriakopoulos et al., 2020 (<a href="https://dl.acm.org/doi/pdf/10.1145/3351095.3372843">https://dl.acm.org/doi/pdf/10.1145/3351095.3372843</a>)) and geographical bias(<a href="https://doi.org/10.5204/mcj.315">Livingstone et al., 2010</a>). <a href="https://en.wikipedia.org/wiki/Racial_bias_on_Wikipedia#cite_note-23">More info</a>.</p>
<h3 id="other-known-limitations">Other Known Limitations</h3>
<p>The end-to-end transformer has the lowest performance since the transformer model needs intermediate pipeline planning steps to have higher performance. Similar findings can be found in <a href="https://arxiv.org/pdf/1908.09022.pdf">Castro Ferreira et al., 2019</a>.</p>
<h2 id="getting-started-with-in-depth-research-on-the-task">Getting started with in-depth research on the task</h2>
<p>Experimental results on DART shows that BART model as the highest performance among three models with a BLEU score of 37.06. This is attributed to BART‚Äôs generalization ability due to pretraining (<a href="https://arxiv.org/pdf/2007.02871.pdf">Table 4</a>).</p>
</div></article></main><div class="layout_push__1J9g0"></div></div><footer class="layout_footer__127N0 utils_eggshell__Njxsh"><span class="layout_backToHome__1vZsp"><a href="/">‚Üê Home</a></span><span>If you have any questions, please join our <a href="https://groups.google.com/g/gem-benchmark" target="_blank" class="utils_accentUnderline__k083p">google group</a> for support.</span></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"taskData":{"id":"DART","contentHtml":"\u003ch2 id=\"table-of-contents\"\u003eTable of Contents\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#dataset-description\"\u003eDataset Description\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#dataset-and-task-summary\"\u003eDataset and Task Summary\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#why-is-this-dataset-part-of-gem\"\u003eWhy is this dataset part of GEM?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#languages\"\u003eLanguages\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#meta-information\"\u003eMeta Information\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#dataset-curators\"\u003eDataset Curators\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#licensing-information\"\u003eLicensing Information\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#citation-information\"\u003eCitation Information\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#leaderboard\"\u003eLeaderboard\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#dataset-structure\"\u003eDataset Structure\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#data-instances\"\u003eData Instances\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#data-fields\"\u003eData Fields\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#data-statistics\"\u003eData Statistics\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#dataset-creation\"\u003eDataset Creation\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#curation-rationale\"\u003eCuration Rationale\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#communicative-goal\"\u003eCommunicative Goal\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#source-data\"\u003eSource Data\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#initial-data-collection-and-normalization\"\u003eInitial Data Collection and Normalization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#who-are-the-source-language-producers\"\u003eWho are the source language producers?\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#annotations\"\u003eAnnotations\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#annotation-process\"\u003eAnnotation process\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#who-are-the-annotators\"\u003eWho are the annotators?\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#personal-and-sensitive-information\"\u003ePersonal and Sensitive Information\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#changes-to-the-original-dataset-for-gem\"\u003eChanges to the Original Dataset for GEM\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#considerations-for-using-the-data\"\u003eConsiderations for Using the Data\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#social-impact-of-the-dataset\"\u003eSocial Impact of the Dataset\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#impact-on-underserved-communities\"\u003eImpact on Underserved Communities\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#discussion-of-biases\"\u003eDiscussion of Biases\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#other-known-limitations\"\u003eOther Known Limitations\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#getting-started-with-in-depth-research-on-the-task\"\u003eGetting started with in-depth research on the task\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"dataset-description\"\u003eDataset Description\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eHomepage:\u003c/strong\u003e None (See \u003cstrong\u003eRepository\u003c/strong\u003e)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRepository:\u003c/strong\u003e \u003ca href=\"https://github.com/Yale-LILY/dart\"\u003eDART repository\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePaper:\u003c/strong\u003e \u003ca href=\"https://arxiv.org/abs/2007.02871\"\u003eDART: Open-Domain Structured Data Record to Text Generation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePoint of Contact:\u003c/strong\u003e {dragomir.radev, r.zhang}@yale.edu, {nazneen.rajani}@salesforce.com\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"dataset-and-task-summary\"\u003eDataset and Task Summary\u003c/h3\u003e\n\u003cp\u003eDART is a large and open-domain structured DAta Record to Text generation corpus with high-quality sentence annotations with each input being a set of entity-relation triples following a tree-structured ontology. It consists of 82191 examples across different domains with each input being a semantic RDF triple set derived from data records in tables and the tree ontology of table schema, annotated with sentence description that covers all facts in the triple set.\u003c/p\u003e\n\u003ch3 id=\"why-is-this-dataset-part-of-gem\"\u003eWhy is this dataset part of GEM?\u003c/h3\u003e\n\u003cp\u003eDART is one of the two datasets representing Table-to-Text NLG in GEM.\u003c/p\u003e\n\u003ch3 id=\"languages\"\u003eLanguages\u003c/h3\u003e\n\u003cp\u003eDART contains English text only (BCP-47: en).\u003c/p\u003e\n\u003ch2 id=\"meta-information\"\u003eMeta Information\u003c/h2\u003e\n\u003ch3 id=\"dataset-curators\"\u003eDataset Curators\u003c/h3\u003e\n\u003cp\u003eThe dataset was curated by a joint team of researchers from the Yale University, Salesforce Research, the University of Hong Kong, MIT and the University of the Chinese Academy of Sciences.\n{dragomir.radev, r.zhang}@yale.edu, {nazneen.rajani}@salesforce.com\u003c/p\u003e\n\u003ch3 id=\"licensing-information\"\u003eLicensing Information\u003c/h3\u003e\n\u003cp\u003eThe dataset was obtained by using multiple complementary methods: (1) human annotation on open-domain Wikipedia tables from WikiTableQuestions (\u003ca href=\"https://www.aclweb.org/anthology/P15-1142.pdf\"\u003ePasupat and Liang, 2015\u003c/a\u003e) and WikiSQL (\u003ca href=\"https://arxiv.org/pdf/1709.00103.pdf\"\u003eZhong et al., 2017\u003c/a\u003e), (2) automatic conversion of questions in WikiSQL to declarative sentences and (3) incorporation of existing datasets including WebNLG 2017 (Gardent et al., 2017\u003ca href=\"https://www.aclweb.org/anthology/P17-1017.pdf\"\u003ea\u003c/a\u003e,\u003ca href=\"https://www.aclweb.org/anthology/W17-3518.pdf\"\u003eb\u003c/a\u003e; \u003ca href=\"https://www.aclweb.org/anthology/W18-6543.pdf\"\u003eShimorina and Gardent, 2018\u003c/a\u003e) and Cleaned E2E (\u003ca href=\"https://arxiv.org/pdf/1706.09254.pdf\"\u003eNovikova et al., 2017b\u003c/a\u003e; Du≈°ek et al., \u003ca href=\"https://arxiv.org/pdf/1810.01170.pdf\"\u003e2018\u003c/a\u003e, \u003ca href=\"https://www.aclweb.org/anthology/W19-8652.pdf\"\u003e2019\u003c/a\u003e)\u003c/p\u003e\n\u003cp\u003eThe repository code is under an \u003ca href=\"https://github.com/Yale-LILY/dart/blob/master/LICENSE\"\u003eMIT license\u003c/a\u003e.\u003c/p\u003e\n\u003ch3 id=\"citation-information\"\u003eCitation Information\u003c/h3\u003e\n\u003cp\u003e@article{radev2020dart,\ntitle={DART: Open-Domain Structured Data Record to Text Generation},\nauthor={Dragomir Radev and Rui Zhang and Amrit Rau and Abhinand Sivaprasad and Chiachun Hsieh and Nazneen Fatema Rajani and Xiangru Tang and Aadit Vyas and Neha Verma and Pranav Krishna and Yangxiaokang Liu and Nadia Irwanto and Jessica Pan and Faiaz Rahman and Ahmad Zaidi and Murori Mutuma and Yasin Tarabar and Ankit Gupta and Tao Yu and Yi Chern Tan and Xi Victoria Lin and Caiming Xiong and Richard Socher},\njournal={arXiv preprint arXiv:2007.02871},\nyear={2020}\n}\u003c/p\u003e\n\u003ch3 id=\"leaderboard\"\u003eLeaderboard\u003c/h3\u003e\n\u003cp\u003eThe dataset supports an active leaderboard, the best results are tracked \u003ca href=\"https://github.com/Yale-LILY/dart#leaderboard\"\u003ehere\u003c/a\u003e. Several state-of-the-art table-to-text models were evaluated on DART, such as BART (\u003ca href=\"https://arxiv.org/pdf/1910.13461.pdf\"\u003eLewis et al., 2020\u003c/a\u003e), Seq2Seq-Att (\u003ca href=\"https://webnlg-challenge.loria.fr/files/melbourne_report.pdf\"\u003eMELBOURNE\u003c/a\u003e) and End-to-End Transformer (\u003ca href=\"https://arxiv.org/pdf/1908.09022.pdf\"\u003eCastro Ferreira et al., 2019\u003c/a\u003e).\nThe leaderboard reports BLEU, METEOR, TER, MoverScore, BERTScore and BLEURT scores.\u003c/p\u003e\n\u003ch2 id=\"dataset-structure\"\u003eDataset Structure\u003c/h2\u003e\n\u003ch3 id=\"data-instances\"\u003eData Instances\u003c/h3\u003e\n\u003cp\u003eThe DART dataset is available in the data/ directory. The dataset consists of JSON files in data/. Each JSON file contains a list of tripleset-annotation pairs of the form:\n{\n\"tripleset\": [\n[\n\"Ben Mauk\",\n\"High school\",\n\"Kenton\"\n],\n[\n\"Ben Mauk\",\n\"College\",\n\"Wake Forest Cincinnati\"\n]\n],\n\"subtree_was_extended\": false,\n\"annotations\": [\n{\n\"source\": \"WikiTableQuestions_lily\",\n\"text\": \"Ben Mauk, who attended Kenton High School, attended Wake Forest Cincinnati for college.\"\n}\n]\n}\u003c/p\u003e\n\u003cp\u003eCreators provided delexicalization dictionaries in data/**/delex/ that map string entities to entity categories.\u003c/p\u003e\n\u003ch3 id=\"data-fields\"\u003eData Fields\u003c/h3\u003e\n\u003cp\u003etripleset: a list of tuples, each tuple has 3 items\nsubtree_was_extended: a boolean variable (true or false)\nannotations: a list of dict, each with source and text keys.\nsource: a string mentioning the name of the source table.\ntext: a sentence string.\u003c/p\u003e\n\u003ch3 id=\"data-statistics\"\u003eData Statistics\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eInput Unit\u003c/th\u003e\n\u003cth\u003eExamples\u003c/th\u003e\n\u003cth\u003eVocab Size\u003c/th\u003e\n\u003cth\u003eWords per SR\u003c/th\u003e\n\u003cth\u003eSents per SR\u003c/th\u003e\n\u003cth\u003eTables\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eTriple Set\u003c/td\u003e\n\u003ctd\u003e82,191\u003c/td\u003e\n\u003ctd\u003e33.2K\u003c/td\u003e\n\u003ctd\u003e21.6\u003c/td\u003e\n\u003ctd\u003e1.5\u003c/td\u003e\n\u003ctd\u003e5,623\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eTrain\u003c/th\u003e\n\u003cth\u003eDev\u003c/th\u003e\n\u003cth\u003eTest\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e62,659\u003c/td\u003e\n\u003ctd\u003e6,980\u003c/td\u003e\n\u003ctd\u003e12,552\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eStatistics of DART decomposed by different collection methods. DART exhibits a great deal of topical variety in terms of the number of unique predicates, the number of unique triples, and the vocabulary size. These statistics are computed from DART v1.1.1; the number of unique predicates reported is post-unification (see Section 3.4). SR: Surface Realization.\n(\u003ca href=\"https://arxiv.org/pdf/2007.02871.pdf\"\u003edetails in Table 1 and 2\u003c/a\u003e).\u003c/p\u003e\n\u003ch2 id=\"dataset-creation\"\u003eDataset Creation\u003c/h2\u003e\n\u003ch3 id=\"curation-rationale\"\u003eCuration Rationale\u003c/h3\u003e\n\u003cp\u003eThe dataset creators encourage through DART further research in natural language generation from semantic data.\nDART provides high-quality sentence annotations with each input being a set of entity-relation triples in a tree structure.\u003c/p\u003e\n\u003ch3 id=\"communicative-goal\"\u003eCommunicative Goal\u003c/h3\u003e\n\u003cp\u003eThe speaker is required to produce coherent sentences and construct a trees structured ontology of the column headers.\u003c/p\u003e\n\u003ch3 id=\"source-data\"\u003eSource Data\u003c/h3\u003e\n\u003cp\u003eThe dataset re-uses data from the following pre-existing resources:\n(1) human annotation on open-domain Wikipedia tables from WikiTableQuestions (\u003ca href=\"https://www.aclweb.org/anthology/P15-1142.pdf\"\u003ePasupat and Liang,\n2015\u003c/a\u003e) and WikiSQL (\u003ca href=\"https://arxiv.org/pdf/1709.00103.pdf\"\u003eZhong et al., 2017\u003c/a\u003e)\n(2) automatic conversion of questions in\nWikiSQL to declarative sentences\n(3) incorporation of existing datasets including WebNLG 2017 (Gardent et al., 2017\u003ca href=\"https://www.aclweb.org/anthology/P17-1017.pdf\"\u003ea\u003c/a\u003e,\u003ca href=\"https://www.aclweb.org/anthology/W17-3518.pdf\"\u003eb\u003c/a\u003e; \u003ca href=\"https://www.aclweb.org/anthology/W18-6543.pdf\"\u003eShimorina and Gardent, 2018\u003c/a\u003e) and Cleaned E2E (\u003ca href=\"https://arxiv.org/pdf/1706.09254.pdf\"\u003eNovikova et al., 2017b\u003c/a\u003e; Du≈°ek et al., \u003ca href=\"https://arxiv.org/pdf/1810.01170.pdf\"\u003e2018\u003c/a\u003e, \u003ca href=\"https://www.aclweb.org/anthology/W19-8652.pdf\"\u003e2019\u003c/a\u003e)\u003c/p\u003e\n\u003cp\u003eCreators also explored automatic alignments between the knowledge base and text including Neural Wikipedian (\u003ca href=\"https://arxiv.org/pdf/1711.00155.pdf\"\u003eVougiouklis et al., 2018\u003c/a\u003e) and TRex (\u003ca href=\"https://www.aclweb.org/anthology/L18-1544.pdf\"\u003eElsahar et al., 2018\u003c/a\u003e).\u003c/p\u003e\n\u003cp\u003eWe refer the reader to the papers describing these sources for further information.\u003c/p\u003e\n\u003ch4 id=\"initial-data-collection-and-normalization\"\u003eInitial Data Collection and Normalization\u003c/h4\u003e\n\u003cp\u003eThe training data consists of concept sets and captions for the source datasets listed above.\nFor conversion of a meaning representation (MR) to a triple set, where the NAME slot was represented as the subject.\u003c/p\u003e\n\u003ch4 id=\"who-are-the-source-language-producers\"\u003eWho are the source language producers?\u003c/h4\u003e\n\u003cp\u003eThe language producers are Wikipedia authors and/or editors for Wikipedia tables (WikiTableQuestions, WikiSQL, WebNLG), crowdworkers (E2E) and annotators (DART, E2E).\u003c/p\u003e\n\u003cp\u003eNo demographic information is provided.\u003c/p\u003e\n\u003ch3 id=\"annotations\"\u003eAnnotations\u003c/h3\u003e\n\u003ch4 id=\"annotation-process\"\u003eAnnotation process\u003c/h4\u003e\n\u003cp\u003eCreators proposed a two-stage annotation process for constructing triple set sentence pairs based on a tree-structured ontology of each table. First, internal skilled annotators denote the parent column for each column header. Then, a larger number of annotators provide a sentential description of an automatically-chosen subset of table cells in a row. To form a triple set sentence pair, the highlighted cells can be converted to a connected triple set automatically according to the column ontology for the given table.\u003c/p\u003e\n\u003ch4 id=\"who-are-the-annotators\"\u003eWho are the annotators?\u003c/h4\u003e\n\u003cp\u003eNo further information about the MTurk workers has been provided.\u003c/p\u003e\n\u003ch3 id=\"personal-and-sensitive-information\"\u003ePersonal and Sensitive Information\u003c/h3\u003e\n\u003cp\u003e[N/A]\u003c/p\u003e\n\u003ch2 id=\"changes-to-the-original-dataset-for-gem\"\u003eChanges to the Original Dataset for GEM\u003c/h2\u003e\n\u003cp\u003eNo changes were made to the original dataset for GEM at the moment of writing this.\nWe may, at some future point, introduce additional test set annotation (related to difficulty/challenging-ness) or introduce challenge sets - these are at the moment only tentatively planned.\u003c/p\u003e\n\u003ch2 id=\"considerations-for-using-the-data\"\u003eConsiderations for Using the Data\u003c/h2\u003e\n\u003ch3 id=\"social-impact-of-the-dataset\"\u003eSocial Impact of the Dataset\u003c/h3\u003e\n\u003cp\u003eThe task is presented as a stepping stone towards building models that achieve more human-like text generation.\u003c/p\u003e\n\u003ch3 id=\"impact-on-underserved-communities\"\u003eImpact on Underserved Communities\u003c/h3\u003e\n\u003cp\u003eThe dataset is in English, a language with an abundance of existing resources.\u003c/p\u003e\n\u003ch3 id=\"discussion-of-biases\"\u003eDiscussion of Biases\u003c/h3\u003e\n\u003cp\u003eThe dataset may contain some social biases, as the input sentences are based on Wikipedia (WikiTableQuestions, WikiSQL, WebNLG). Studies have shown that the English Wikipedia contains gender biases(\u003ca href=\"https://www.aclweb.org/anthology/2020.emnlp-main.23.pdf\"\u003eDinan et al., 2020\u003c/a\u003e), racial biases([Papakyriakopoulos et al., 2020 (\u003ca href=\"https://dl.acm.org/doi/pdf/10.1145/3351095.3372843\"\u003ehttps://dl.acm.org/doi/pdf/10.1145/3351095.3372843\u003c/a\u003e)) and geographical bias(\u003ca href=\"https://doi.org/10.5204/mcj.315\"\u003eLivingstone et al., 2010\u003c/a\u003e). \u003ca href=\"https://en.wikipedia.org/wiki/Racial_bias_on_Wikipedia#cite_note-23\"\u003eMore info\u003c/a\u003e.\u003c/p\u003e\n\u003ch3 id=\"other-known-limitations\"\u003eOther Known Limitations\u003c/h3\u003e\n\u003cp\u003eThe end-to-end transformer has the lowest performance since the transformer model needs intermediate pipeline planning steps to have higher performance. Similar findings can be found in \u003ca href=\"https://arxiv.org/pdf/1908.09022.pdf\"\u003eCastro Ferreira et al., 2019\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"getting-started-with-in-depth-research-on-the-task\"\u003eGetting started with in-depth research on the task\u003c/h2\u003e\n\u003cp\u003eExperimental results on DART shows that BART model as the highest performance among three models with a BLEU score of 37.06. This is attributed to BART‚Äôs generalization ability due to pretraining (\u003ca href=\"https://arxiv.org/pdf/2007.02871.pdf\"\u003eTable 4\u003c/a\u003e).\u003c/p\u003e\n","title":"DART","type":"Structure-to-Text","motivation":"Hierarchical, structured format with its open-domain nature"}},"__N_SSG":true},"page":"/data_cards/[id]","query":{"id":"DART"},"buildId":"-4BzhAC0_kuCZeeA-vHE_","nextExport":false,"isFallback":false,"gsp":true,"head":[["meta",{"name":"viewport","content":"width=device-width"}],["meta",{"charSet":"utf-8"}],["link",{"rel":"icon","href":"/favicon.ico"}],["meta",{"name":"description","content":"Benchmark natural language generation systems with GEM."}],["meta",{"property":"og:image","content":"https://og-image.now.sh/**GEM**%20Benchmark.png?theme=light\u0026md=1\u0026fontSize=100px\u0026images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fvercel-triangle-black.svg"}],["meta",{"name":"og:title","content":"GEM"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["title",{"children":"GEM DART"}]]}</script><script nomodule="" src="/_next/static/chunks/polyfills-e69cc13a7e89296a69e4.js"></script><script src="/_next/static/chunks/main-47bc8f80085b54a800da.js" async=""></script><script src="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" async=""></script><script src="/_next/static/chunks/framework.baa41d4dbf5d52db897c.js" async=""></script><script src="/_next/static/chunks/e70fad557dfa42f32a11d0d2c99fe8f6e8d1fa86.4a36a385313236c59b19.js" async=""></script><script src="/_next/static/chunks/pages/_app-a9ae7a6d1de4e51a7ab6.js" async=""></script><script src="/_next/static/chunks/cb1608f2.c3a9f0eb95374ca4919a.js" async=""></script><script src="/_next/static/chunks/451c6be158cef50d8cc28b919cf08d1e5b9ff3fc.f0ec181e43727e8a893e.js" async=""></script><script src="/_next/static/chunks/pages/data_cards/%5Bid%5D-e1361c13d80af81deda6.js" async=""></script><script src="/_next/static/-4BzhAC0_kuCZeeA-vHE_/_buildManifest.js" async=""></script><script src="/_next/static/-4BzhAC0_kuCZeeA-vHE_/_ssgManifest.js" async=""></script></body></html>