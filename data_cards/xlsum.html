<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/favicon.ico"/><meta name="description" content="Benchmark natural language generation systems with GEM."/><meta property="og:image" content="https://og-image.now.sh/**GEM**%20Benchmark.png?theme=light&amp;md=1&amp;fontSize=100px&amp;images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fvercel-triangle-black.svg"/><meta name="og:title" content="GEM"/><meta name="twitter:card" content="summary_large_image"/><title>GEM <!-- -->xlsum</title><meta name="next-head-count" content="8"/><link rel="preload" href="/_next/static/css/42fe94e3e660903d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/42fe94e3e660903d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/93c336621cfc84eb.css" as="style"/><link rel="stylesheet" href="/_next/static/css/93c336621cfc84eb.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js"></script><script src="/_next/static/chunks/webpack-635a834dfd7d0dc2.js" defer=""></script><script src="/_next/static/chunks/framework-7a7e500878b44665.js" defer=""></script><script src="/_next/static/chunks/main-a56c17dda72126ba.js" defer=""></script><script src="/_next/static/chunks/pages/_app-da8862f0ec3a97c1.js" defer=""></script><script src="/_next/static/chunks/c16184b3-ddb1b99b5e568a2a.js" defer=""></script><script src="/_next/static/chunks/50-3dccc3616b494db8.js" defer=""></script><script src="/_next/static/chunks/pages/data_cards/%5Bid%5D-14d2b498c38b49da.js" defer=""></script><script src="/_next/static/456T-gjsiPfCS_Gwi0APa/_buildManifest.js" defer=""></script><script src="/_next/static/456T-gjsiPfCS_Gwi0APa/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="layout_background__oCFQX undefined"><header class="layout_header__SFlEE"><div class="navbar_navwrapper__RkXSe"><div class="navbar_gradbar__Vli6s"></div><nav class="navbar_navbar__vdWdK"><span class="utils_headingLg__RYtYb navbar_navbarlogo__u28NK"><a href="/">GEM BENCHMARK</a></span><div class="navbar_menutoggle__4Urrc" id="mobile-menu"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="bars" class="svg-inline--fa fa-bars navbar_bar__f8cyd" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg></div><ul><li class="navbar_navitem__15TsF navbar_pushright___9_8s"><a href="/resources">Resources</a></li><li class="navbar_navitem__15TsF"><a href="/data_cards">Data Cards</a></li><li class="navbar_navitem__15TsF"><a href="/model_cards">Model Cards</a></li><li class="navbar_navitem__15TsF"><a href="/tutorials">tutorials</a></li><li class="navbar_navitem__15TsF"><a href="/results">Results</a></li><li class="navbar_navitem__15TsF"><a href="/workshop">Workshop</a></li></ul></nav></div></header><div class="layout_container__FUycR layout_wideContainer__IUVFY"><main><article><a href="/data_cards"><a><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="arrow-left" class="svg-inline--fa fa-arrow-left utils_icon__AiQ5I" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path></svg></a></a><span class="utils_spacer__a__NY"></span><span class="utils_headingXl__zlq1q">xlsum</span><span class="utils_smallSpace__dcJPu"></span><span class="utils_lightText__B_gv3">Summarization</span><div class="datacard-wrapper"><div class="datacard">

  <section class="datacard-section">
    <div class="datacard-summary">
      <h2>xlsum</h2>
      <div class="summary-content">
        <p>XLSum is a highly multilingual summarization dataset supporting 44 language. The data stems from BBC news
          articles.</p>
        <p>You can load the dataset via:</p>

        <div class="code-wrapper">
          <div class="toolbar">
            <div class="copy-icon" title="Click to copy code block"></div>
            <div class="expand-modal-icon" title="Click to expand code block"></div>
          </div>
          <pre><code>import datasets
data = datasets.load_dataset('GEM/xlsum')
</code></pre>
        </div>

        <p>The data loader can be found <a href="https://huggingface.co/datasets/GEM/xlsum">here</a>.</p>
      </div>
    </div>

    <div class="datacard-field-wrapper">

      <div class="datacard-field">

        <h5>website

        </h5>

        <p><a href="https://github.com/csebuetnlp/xl-sum">Github</a></p>
      </div>

      <div class="datacard-field">

        <h5>paper

        </h5>

        <p><a href="https://aclanthology.org/2021.findings-acl.413/">ACL Anthology</a></p>
      </div>
    </div>

  </section>

  <section class="datacard-section quick">
    <h3 class="section-title">Quick-Use</h3>

    <div class="datacard-field-wrapper">

      <div class="datacard-field periscope">

        <h5>Contact Name

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>If known, provide the name of at least one person the reader can contact for questions about the
                dataset.</p>
            </div>
          </div>

        </h5>

        <p>Tahmid Hasan</p>
      </div>

      <div class="datacard-field telescope">

        <h5>Multilingual?

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>Is the dataset multilingual?</p>
            </div>
          </div>

        </h5>

        <p>yes</p>
      </div>

      <div class="datacard-field telescope">

        <h5>Covered Languages

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>What languages/dialects are covered in the dataset?</p>
            </div>
          </div>

        </h5>

        <p><code>Amharic</code>, <code>Arabic</code>, <code>Azerbaijani</code>, <code>Bengali, Bangla</code>,
          <code>Burmese</code>, <code>Chinese (family)</code>, <code>English</code>, <code>French</code>,
          <code>Gujarati</code>, <code>Hausa</code>, <code>Hindi</code>, <code>Igbo</code>, <code>Indonesian</code>,
          <code>Japanese</code>, <code>Rundi</code>, <code>Korean</code>, <code>Kirghiz, Kyrgyz</code>,
          <code>Marathi</code>, <code>Nepali (individual language)</code>, <code>Oromo</code>,
          <code>Pushto, Pashto</code>, <code>Persian</code>, <code>Ghanaian Pidgin English</code>,
          <code>Portuguese</code>, <code>Panjabi, Punjabi</code>, <code>Russian</code>,
          <code>Scottish Gaelic, Gaelic</code>, <code>Serbian</code>, <code>Romano-Serbian</code>,
          <code>Sinhala, Sinhalese</code>, <code>Somali</code>, <code>Spanish, Castilian</code>,
          <code>Swahili (individual language), Kiswahili</code>, <code>Tamil</code>, <code>Telugu</code>,
          <code>Thai</code>, <code>Tigrinya</code>, <code>Turkish</code>, <code>Ukrainian</code>, <code>Urdu</code>,
          <code>Uzbek</code>, <code>Vietnamese</code>, <code>Welsh</code>, <code>Yoruba</code></p>
      </div>

      <div class="datacard-field telescope">

        <h5>License

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>What is the license of the dataset?</p>
            </div>
          </div>

        </h5>

        <p>cc-by-nc-sa-4.0: Creative Commons Attribution Non Commercial Share Alike 4.0 International</p>
      </div>

      <div class="datacard-field periscope">

        <h5>Communicative Goal

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>Provide a short description of the communicative goal of a model trained for this task on this dataset.
              </p>
            </div>
          </div>

        </h5>

        <p>Summarize news-like text in one of 45 languages.</p>
      </div>

      <div class="datacard-field telescope">

        <h5>Additional Annotations?

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>Does the dataset have additional annotations for each instance?</p>
            </div>
          </div>

        </h5>

        <p>none</p>
      </div>

      <div class="datacard-field telescope">

        <h5>Contains PII?

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>Does the source language data likely contain Personal Identifying Information about the data creators
                or subjects?</p>
            </div>
          </div>

        </h5>

        <p>likely</p>
      </div>
    </div>

  </section>


  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Dataset Overview

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Where to find the Data and its Documentation</h4>
              </li>
              <li>
                <h4>Languages and Intended Use</h4>
              </li>
              <li>
                <h4>Credit</h4>
              </li>
              <li>
                <h4>Dataset Structure</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Where to find the Data and its Documentation</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Webpage

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the webpage for the dataset (if it exists)?</p>
                </div>
              </div>

            </h5>

            <p><a href="https://github.com/csebuetnlp/xl-sum">Github</a></p>
          </div>

          <div class="datacard-field telescope">

            <h5>Download

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the link to where the original dataset is hosted?</p>
                </div>
              </div>

            </h5>

            <p><a href="https://huggingface.co/datasets/csebuetnlp/xlsum/tree/main/data">Huggingface</a></p>
          </div>

          <div class="datacard-field telescope">

            <h5>Paper

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the link to the paper describing the dataset (open access preferred)?</p>
                </div>
              </div>

            </h5>

            <p><a href="https://aclanthology.org/2021.findings-acl.413/">ACL Anthology</a></p>
          </div>

          <div class="datacard-field microscope">

            <h5>BibTex

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Provide the BibTex-formatted reference for the dataset. Please use the correct published version
                    (ACL anthology, etc.) instead of google scholar created Bibtex.</p>
                </div>
              </div>

            </h5>


            <div class="code-wrapper">
              <div class="toolbar">
                <div class="copy-icon" title="Click to copy code block"></div>
                <div class="expand-modal-icon" title="Click to expand code block"></div>
              </div>
              <pre><code>@inproceedings{hasan-etal-2021-xl,
title = "{XL}-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages",
author = "Hasan, Tahmid  and
Bhattacharjee, Abhik  and
Islam, Md. Saiful  and
Mubasshir, Kazi  and
Li, Yuan-Fang  and
Kang, Yong-Bin  and
Rahman, M. Sohel  and
Shahriyar, Rifat",
booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
month = aug,
year = "2021",
address = "Online",
publisher = "Association for Computational Linguistics",
url = "https://aclanthology.org/2021.findings-acl.413",
pages = "4693--4703",
}
</code></pre>
            </div>

          </div>

          <div class="datacard-field periscope">

            <h5>Contact Name

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>If known, provide the name of at least one person the reader can contact for questions about the
                    dataset.</p>
                </div>
              </div>

            </h5>

            <p>Tahmid Hasan</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Contact Email

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>If known, provide the email of at least one person the reader can contact for questions about the
                    dataset.</p>
                </div>
              </div>

            </h5>

            <p><a href="mailto:tahmidhasan@cse.buet.ac.bd">tahmidhasan@cse.buet.ac.bd</a></p>
          </div>

          <div class="datacard-field telescope">

            <h5>Has a Leaderboard?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the dataset have an active leaderboard?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Leaderboard Link

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Provide a link to the leaderboard.</p>
                </div>
              </div>

            </h5>

            <p><a href="http://explainaboard.nlpedia.ai/leaderboard/task_xlsum/">Explainaboard</a></p>
          </div>

          <div class="datacard-field microscope">

            <h5>Leaderboard Details

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Briefly describe how the leaderboard evaluates models.</p>
                </div>
              </div>

            </h5>

            <p>The leaderboard ranks models based on ROUGE scores (R1/R2/RL) of the generated summaries.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Languages and Intended Use</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Multilingual?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Is the dataset multilingual?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Covered Languages

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What languages/dialects are covered in the dataset?</p>
                </div>
              </div>

            </h5>

            <p><code>Amharic</code>, <code>Arabic</code>, <code>Azerbaijani</code>, <code>Bengali, Bangla</code>,
              <code>Burmese</code>, <code>Chinese (family)</code>, <code>English</code>, <code>French</code>,
              <code>Gujarati</code>, <code>Hausa</code>, <code>Hindi</code>, <code>Igbo</code>, <code>Indonesian</code>,
              <code>Japanese</code>, <code>Rundi</code>, <code>Korean</code>, <code>Kirghiz, Kyrgyz</code>,
              <code>Marathi</code>, <code>Nepali (individual language)</code>, <code>Oromo</code>,
              <code>Pushto, Pashto</code>, <code>Persian</code>, <code>Ghanaian Pidgin English</code>,
              <code>Portuguese</code>, <code>Panjabi, Punjabi</code>, <code>Russian</code>,
              <code>Scottish Gaelic, Gaelic</code>, <code>Serbian</code>, <code>Romano-Serbian</code>,
              <code>Sinhala, Sinhalese</code>, <code>Somali</code>, <code>Spanish, Castilian</code>,
              <code>Swahili (individual language), Kiswahili</code>, <code>Tamil</code>, <code>Telugu</code>,
              <code>Thai</code>, <code>Tigrinya</code>, <code>Turkish</code>, <code>Ukrainian</code>, <code>Urdu</code>,
              <code>Uzbek</code>, <code>Vietnamese</code>, <code>Welsh</code>, <code>Yoruba</code></p>
          </div>

          <div class="datacard-field telescope">

            <h5>License

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the license of the dataset?</p>
                </div>
              </div>

            </h5>

            <p>cc-by-nc-sa-4.0: Creative Commons Attribution Non Commercial Share Alike 4.0 International</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Intended Use

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the intended use of the dataset?</p>
                </div>
              </div>

            </h5>

            <p>Abstractive summarization has centered around the English language, as most large abstractive
              summarization datasets are available in English only. Though there have been some recent efforts for
              curating multilingual abstractive summarization datasets, they are limited in terms of the number of
              languages covered, the number of training samples, or both. To this end, <strong>XL-Sum</strong> presents
              a large-scale abstractive summarization dataset of 1.35 million news articles from 45 languages crawled
              from the British Broadcasting Corporation website. It is intended to be used for both multilingual and
              per-language summarization tasks.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Primary Task

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What primary task does the dataset support?</p>
                </div>
              </div>

            </h5>

            <p>Summarization</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Communicative Goal

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Provide a short description of the communicative goal of a model trained for this task on this
                    dataset.</p>
                </div>
              </div>

            </h5>

            <p>Summarize news-like text in one of 45 languages.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Credit</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Curation Organization Type(s)

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>In what kind of organization did the dataset curation happen?</p>
                </div>
              </div>

            </h5>

            <p><code>academic</code></p>
          </div>

          <div class="datacard-field periscope">

            <h5>Curation Organization(s)

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Name the organization(s).</p>
                </div>
              </div>

            </h5>

            <p>Bangladesh University of Engineering and Technology</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Who added the Dataset to GEM?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Who contributed to the data card and adding the dataset to GEM? List the people+affiliations
                    involved in creating this data card and who helped integrate this dataset into GEM.</p>
                </div>
              </div>

            </h5>

            <p>Tahmid Hasan (Bangladesh University of Engineering and Technology), Abhik Bhattacharjee (Bangladesh
              University of Engineering and Technology)</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Dataset Structure</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Data Fields

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>List and describe the fields present in the dataset.</p>
                </div>
              </div>

            </h5>

            <ul>
              <li><code>gem_id</code>: A string representing the article ID.</li>
              <li><code>url</code>: A string representing the article URL.</li>
              <li><code>title</code>: A string containing the article title.</li>
              <li><code>summary</code>: A string containing the article summary.</li>
              <li><code>text</code> : A string containing the article text.</li>
            </ul>
          </div>

          <div class="datacard-field periscope">

            <h5>Example Instance

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Provide a JSON formatted example of a typical instance in the dataset.</p>
                </div>
              </div>

            </h5>


            <div class="code-wrapper">
              <div class="toolbar">
                <div class="copy-icon" title="Click to copy code block"></div>
                <div class="expand-modal-icon" title="Click to expand code block"></div>
              </div>
              <pre><code>{
"gem_id": "GEM-xlsum_english-train-1589",
"url": "[BBC news](https://www.bbc.com/news)/technology-17657859",
"title": "Yahoo files e-book advert system patent applications",
"summary": "Yahoo has signalled it is investigating e-book adverts as a way to stimulate its earnings.",
"text": "Yahoo's patents suggest users could weigh the type of ads against the sizes of discount before purchase. It says in two US patent applications that ads for digital book readers have been \"less than optimal\" to date. The filings suggest that users could be offered titles at a variety of prices depending on the ads' prominence They add that the products shown could be determined by the type of book being read, or even the contents of a specific chapter, phrase or word. The paperwork was published by the US Patent and Trademark Office late last week and relates to work carried out at the firm's headquarters in Sunnyvale, California. \"Greater levels of advertising, which may be more valuable to an advertiser and potentially more distracting to an e-book reader, may warrant higher discounts,\" it states. Free books It suggests users could be offered ads as hyperlinks based within the book's text, in-laid text or even \"dynamic content\" such as video. Another idea suggests boxes at the bottom of a page could trail later chapters or quotes saying \"brought to you by Company A\". It adds that the more willing the customer is to see the ads, the greater the potential discount. \"Higher frequencies... may even be great enough to allow the e-book to be obtained for free,\" it states. The authors write that the type of ad could influence the value of the discount, with \"lower class advertising... such as teeth whitener advertisements\" offering a cheaper price than \"high\" or \"middle class\" adverts, for things like pizza. The inventors also suggest that ads could be linked to the mood or emotional state the reader is in as a they progress through a title. For example, they say if characters fall in love or show affection during a chapter, then ads for flowers or entertainment could be triggered. The patents also suggest this could applied to children's books - giving the Tom Hanks animated film Polar Express as an example. It says a scene showing a waiter giving the protagonists hot drinks \"may be an excellent opportunity to show an advertisement for hot cocoa, or a branded chocolate bar\". Another example states: \"If the setting includes young characters, a Coke advertisement could be provided, inviting the reader to enjoy a glass of Coke with his book, and providing a graphic of a cool glass.\" It adds that such targeting could be further enhanced by taking account of previous titles the owner has bought. 'Advertising-free zone' At present, several Amazon and Kobo e-book readers offer full-screen adverts when the device is switched off and show smaller ads on their menu screens, but the main text of the titles remains free of marketing. Yahoo does not currently provide ads to these devices, and a move into the area could boost its shrinking revenues. However, Philip Jones, deputy editor of the Bookseller magazine, said that the internet firm might struggle to get some of its ideas adopted. \"This has been mooted before and was fairly well decried,\" he said. \"Perhaps in a limited context it could work if the merchandise was strongly related to the title and was kept away from the text. \"But readers - particularly parents - like the fact that reading is an advertising-free zone. Authors would also want something to say about ads interrupting their narrative flow.\""
}
</code></pre>
            </div>

          </div>

          <div class="datacard-field periscope">

            <h5>Data Splits

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Describe and name the splits in the dataset if there are more than one.</p>
                </div>
              </div>

            </h5>

            <p>The splits in the dataset are specified by the language names, which are as follows:</p>
            <ul>
              <li><code>amharic</code></li>
              <li><code>arabic</code></li>
              <li><code>azerbaijani</code></li>
              <li><code>bengali</code></li>
              <li><code>burmese</code></li>
              <li><code>chinese_simplified</code></li>
              <li><code>chinese_traditional</code></li>
              <li><code>english</code></li>
              <li><code>french</code></li>
              <li><code>gujarati</code></li>
              <li><code>hausa</code></li>
              <li><code>hindi</code></li>
              <li><code>igbo</code></li>
              <li><code>indonesian</code></li>
              <li><code>japanese</code></li>
              <li><code>kirundi</code></li>
              <li><code>korean</code></li>
              <li><code>kyrgyz</code></li>
              <li><code>marathi</code></li>
              <li><code>nepali</code></li>
              <li><code>oromo</code></li>
              <li><code>pashto</code></li>
              <li><code>persian</code></li>
              <li><code>pidgin</code></li>
              <li><code>portuguese</code></li>
              <li><code>punjabi</code></li>
              <li><code>russian</code></li>
              <li><code>scottish_gaelic</code></li>
              <li><code>serbian_cyrillic</code></li>
              <li><code>serbian_latin</code></li>
              <li><code>sinhala</code></li>
              <li><code>somali</code></li>
              <li><code>spanish</code></li>
              <li><code>swahili</code></li>
              <li><code>tamil</code></li>
              <li><code>telugu</code></li>
              <li><code>thai</code></li>
              <li><code>tigrinya</code></li>
              <li><code>turkish</code></li>
              <li><code>ukrainian</code></li>
              <li><code>urdu</code></li>
              <li><code>uzbek</code></li>
              <li><code>vietnamese</code></li>
              <li><code>welsh</code></li>
              <li><code>yoruba</code></li>
            </ul>
          </div>

          <div class="datacard-field microscope">

            <h5>Splitting Criteria

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Describe any criteria for splitting the data, if used. If there are differences between the splits
                    (e.g., if the training annotations are machine-generated and the dev and test ones are created by
                    humans, or if different numbers of annotators contributed to each example), describe them here.</p>
                </div>
              </div>

            </h5>

            <p>We used a 80%-10%-10% split for all languages with a few exceptions. <code>English</code> was split
              93%-3.5%-3.5% for the evaluation set size to resemble that of <code>CNN/DM</code> and <code>XSum</code>;
              <code>Scottish Gaelic</code>, <code>Kyrgyz</code> and <code>Sinhala</code> had relatively fewer samples,
              their evaluation sets were increased to 500 samples for more reliable evaluation. Same articles were used
              for evaluation in the two variants of Chinese and Serbian to prevent data leakage in multilingual
              training. Individual dataset download links with train-dev-test example counts are given below:</p>

            <div class="table-wrapper">
              <div class="toolbar">
                <div class="expand-modal-icon" title="Click to expand table"></div>
              </div>
              <table>
                <thead>
                  <tr>
                    <th>Language</th>
                    <th>ISO 639-1 Code</th>
                    <th>BBC subdomain(s)</th>
                    <th>Train</th>
                    <th>Dev</th>
                    <th>Test</th>
                    <th>Total</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>Amharic</td>
                    <td>am</td>
                    <td><a href="https://www.bbc.com/amharic">BBC amharic</a></td>
                    <td>5761</td>
                    <td>719</td>
                    <td>719</td>
                    <td>7199</td>
                  </tr>
                  <tr>
                    <td>Arabic</td>
                    <td>ar</td>
                    <td><a href="https://www.bbc.com/arabic">BBC arabic</a></td>
                    <td>37519</td>
                    <td>4689</td>
                    <td>4689</td>
                    <td>46897</td>
                  </tr>
                  <tr>
                    <td>Azerbaijani</td>
                    <td>az</td>
                    <td><a href="https://www.bbc.com/azeri">BBC azeri</a></td>
                    <td>6478</td>
                    <td>809</td>
                    <td>809</td>
                    <td>8096</td>
                  </tr>
                  <tr>
                    <td>Bengali</td>
                    <td>bn</td>
                    <td><a href="https://www.bbc.com/bengali">BBC bengali</a></td>
                    <td>8102</td>
                    <td>1012</td>
                    <td>1012</td>
                    <td>10126</td>
                  </tr>
                  <tr>
                    <td>Burmese</td>
                    <td>my</td>
                    <td><a href="https://www.bbc.com/burmese">BBC burmese</a></td>
                    <td>4569</td>
                    <td>570</td>
                    <td>570</td>
                    <td>5709</td>
                  </tr>
                  <tr>
                    <td>Chinese (Simplified)</td>
                    <td>zh-CN</td>
                    <td><a href="https://www.bbc.com/ukchina">BBC ukchina</a>/simp, <a
                        href="https://www.bbc.com/zhongwen">BBC zhongwen</a>/simp</td>
                    <td>37362</td>
                    <td>4670</td>
                    <td>4670</td>
                    <td>46702</td>
                  </tr>
                  <tr>
                    <td>Chinese (Traditional)</td>
                    <td>zh-TW</td>
                    <td><a href="https://www.bbc.com/ukchina">BBC ukchina</a>/trad, <a
                        href="https://www.bbc.com/zhongwen">BBC zhongwen</a>/trad</td>
                    <td>37373</td>
                    <td>4670</td>
                    <td>4670</td>
                    <td>46713</td>
                  </tr>
                  <tr>
                    <td>English</td>
                    <td>en</td>
                    <td><a href="https://www.bbc.com/english">BBC english</a>, <a href="https://www.bbc.com/sinhala">BBC
                        sinhala</a> <code>*</code></td>
                    <td>306522</td>
                    <td>11535</td>
                    <td>11535</td>
                    <td>329592</td>
                  </tr>
                  <tr>
                    <td>French</td>
                    <td>fr</td>
                    <td><a href="https://www.bbc.com/afrique">BBC afrique</a></td>
                    <td>8697</td>
                    <td>1086</td>
                    <td>1086</td>
                    <td>10869</td>
                  </tr>
                  <tr>
                    <td>Gujarati</td>
                    <td>gu</td>
                    <td><a href="https://www.bbc.com/gujarati">BBC gujarati</a></td>
                    <td>9119</td>
                    <td>1139</td>
                    <td>1139</td>
                    <td>11397</td>
                  </tr>
                  <tr>
                    <td>Hausa</td>
                    <td>ha</td>
                    <td><a href="https://www.bbc.com/hausa">BBC hausa</a></td>
                    <td>6418</td>
                    <td>802</td>
                    <td>802</td>
                    <td>8022</td>
                  </tr>
                  <tr>
                    <td>Hindi</td>
                    <td>hi</td>
                    <td><a href="https://www.bbc.com/hindi">BBC hindi</a></td>
                    <td>70778</td>
                    <td>8847</td>
                    <td>8847</td>
                    <td>88472</td>
                  </tr>
                  <tr>
                    <td>Igbo</td>
                    <td>ig</td>
                    <td><a href="https://www.bbc.com/igbo">BBC igbo</a></td>
                    <td>4183</td>
                    <td>522</td>
                    <td>522</td>
                    <td>5227</td>
                  </tr>
                  <tr>
                    <td>Indonesian</td>
                    <td>id</td>
                    <td><a href="https://www.bbc.com/indonesia">BBC indonesia</a></td>
                    <td>38242</td>
                    <td>4780</td>
                    <td>4780</td>
                    <td>47802</td>
                  </tr>
                  <tr>
                    <td>Japanese</td>
                    <td>ja</td>
                    <td><a href="https://www.bbc.com/japanese">BBC japanese</a></td>
                    <td>7113</td>
                    <td>889</td>
                    <td>889</td>
                    <td>8891</td>
                  </tr>
                  <tr>
                    <td>Kirundi</td>
                    <td>rn</td>
                    <td><a href="https://www.bbc.com/gahuza">BBC gahuza</a></td>
                    <td>5746</td>
                    <td>718</td>
                    <td>718</td>
                    <td>7182</td>
                  </tr>
                  <tr>
                    <td>Korean</td>
                    <td>ko</td>
                    <td><a href="https://www.bbc.com/korean">BBC korean</a></td>
                    <td>4407</td>
                    <td>550</td>
                    <td>550</td>
                    <td>5507</td>
                  </tr>
                  <tr>
                    <td>Kyrgyz</td>
                    <td>ky</td>
                    <td><a href="https://www.bbc.com/kyrgyz">BBC kyrgyz</a></td>
                    <td>2266</td>
                    <td>500</td>
                    <td>500</td>
                    <td>3266</td>
                  </tr>
                  <tr>
                    <td>Marathi</td>
                    <td>mr</td>
                    <td><a href="https://www.bbc.com/marathi">BBC marathi</a></td>
                    <td>10903</td>
                    <td>1362</td>
                    <td>1362</td>
                    <td>13627</td>
                  </tr>
                  <tr>
                    <td>Nepali</td>
                    <td>np</td>
                    <td><a href="https://www.bbc.com/nepali">BBC nepali</a></td>
                    <td>5808</td>
                    <td>725</td>
                    <td>725</td>
                    <td>7258</td>
                  </tr>
                  <tr>
                    <td>Oromo</td>
                    <td>om</td>
                    <td><a href="https://www.bbc.com/afaanoromoo">BBC afaanoromoo</a></td>
                    <td>6063</td>
                    <td>757</td>
                    <td>757</td>
                    <td>7577</td>
                  </tr>
                  <tr>
                    <td>Pashto</td>
                    <td>ps</td>
                    <td><a href="https://www.bbc.com/pashto">BBC pashto</a></td>
                    <td>14353</td>
                    <td>1794</td>
                    <td>1794</td>
                    <td>17941</td>
                  </tr>
                  <tr>
                    <td>Persian</td>
                    <td>fa</td>
                    <td><a href="https://www.bbc.com/persian">BBC persian</a></td>
                    <td>47251</td>
                    <td>5906</td>
                    <td>5906</td>
                    <td>59063</td>
                  </tr>
                  <tr>
                    <td>Pidgin<code>**</code></td>
                    <td>pcm</td>
                    <td><a href="https://www.bbc.com/pidgin">BBC pidgin</a></td>
                    <td>9208</td>
                    <td>1151</td>
                    <td>1151</td>
                    <td>11510</td>
                  </tr>
                  <tr>
                    <td>Portuguese</td>
                    <td>pt</td>
                    <td><a href="https://www.bbc.com/portuguese">BBC portuguese</a></td>
                    <td>57402</td>
                    <td>7175</td>
                    <td>7175</td>
                    <td>71752</td>
                  </tr>
                  <tr>
                    <td>Punjabi</td>
                    <td>pa</td>
                    <td><a href="https://www.bbc.com/punjabi">BBC punjabi</a></td>
                    <td>8215</td>
                    <td>1026</td>
                    <td>1026</td>
                    <td>10267</td>
                  </tr>
                  <tr>
                    <td>Russian</td>
                    <td>ru</td>
                    <td><a href="https://www.bbc.com/russian">BBC russian</a>, <a
                        href="https://www.bbc.com/ukrainian">BBC ukrainian</a> <code>*</code></td>
                    <td>62243</td>
                    <td>7780</td>
                    <td>7780</td>
                    <td>77803</td>
                  </tr>
                  <tr>
                    <td>Scottish Gaelic</td>
                    <td>gd</td>
                    <td><a href="https://www.bbc.com/naidheachdan">BBC naidheachdan</a></td>
                    <td>1313</td>
                    <td>500</td>
                    <td>500</td>
                    <td>2313</td>
                  </tr>
                  <tr>
                    <td>Serbian (Cyrillic)</td>
                    <td>sr</td>
                    <td><a href="https://www.bbc.com/serbian">BBC serbian</a>/cyr</td>
                    <td>7275</td>
                    <td>909</td>
                    <td>909</td>
                    <td>9093</td>
                  </tr>
                  <tr>
                    <td>Serbian (Latin)</td>
                    <td>sr</td>
                    <td><a href="https://www.bbc.com/serbian">BBC serbian</a>/lat</td>
                    <td>7276</td>
                    <td>909</td>
                    <td>909</td>
                    <td>9094</td>
                  </tr>
                  <tr>
                    <td>Sinhala</td>
                    <td>si</td>
                    <td><a href="https://www.bbc.com/sinhala">BBC sinhala</a></td>
                    <td>3249</td>
                    <td>500</td>
                    <td>500</td>
                    <td>4249</td>
                  </tr>
                  <tr>
                    <td>Somali</td>
                    <td>so</td>
                    <td><a href="https://www.bbc.com/somali">BBC somali</a></td>
                    <td>5962</td>
                    <td>745</td>
                    <td>745</td>
                    <td>7452</td>
                  </tr>
                  <tr>
                    <td>Spanish</td>
                    <td>es</td>
                    <td><a href="https://www.bbc.com/mundo">BBC mundo</a></td>
                    <td>38110</td>
                    <td>4763</td>
                    <td>4763</td>
                    <td>47636</td>
                  </tr>
                  <tr>
                    <td>Swahili</td>
                    <td>sw</td>
                    <td><a href="https://www.bbc.com/swahili">BBC swahili</a></td>
                    <td>7898</td>
                    <td>987</td>
                    <td>987</td>
                    <td>9872</td>
                  </tr>
                  <tr>
                    <td>Tamil</td>
                    <td>ta</td>
                    <td><a href="https://www.bbc.com/tamil">BBC tamil</a></td>
                    <td>16222</td>
                    <td>2027</td>
                    <td>2027</td>
                    <td>20276</td>
                  </tr>
                  <tr>
                    <td>Telugu</td>
                    <td>te</td>
                    <td><a href="https://www.bbc.com/telugu">BBC telugu</a></td>
                    <td>10421</td>
                    <td>1302</td>
                    <td>1302</td>
                    <td>13025</td>
                  </tr>
                  <tr>
                    <td>Thai</td>
                    <td>th</td>
                    <td><a href="https://www.bbc.com/thai">BBC thai</a></td>
                    <td>6616</td>
                    <td>826</td>
                    <td>826</td>
                    <td>8268</td>
                  </tr>
                  <tr>
                    <td>Tigrinya</td>
                    <td>ti</td>
                    <td><a href="https://www.bbc.com/tigrinya">BBC tigrinya</a></td>
                    <td>5451</td>
                    <td>681</td>
                    <td>681</td>
                    <td>6813</td>
                  </tr>
                  <tr>
                    <td>Turkish</td>
                    <td>tr</td>
                    <td><a href="https://www.bbc.com/turkce">BBC turkce</a></td>
                    <td>27176</td>
                    <td>3397</td>
                    <td>3397</td>
                    <td>33970</td>
                  </tr>
                  <tr>
                    <td>Ukrainian</td>
                    <td>uk</td>
                    <td><a href="https://www.bbc.com/ukrainian">BBC ukrainian</a></td>
                    <td>43201</td>
                    <td>5399</td>
                    <td>5399</td>
                    <td>53999</td>
                  </tr>
                  <tr>
                    <td>Urdu</td>
                    <td>ur</td>
                    <td><a href="https://www.bbc.com/urdu">BBC urdu</a></td>
                    <td>67665</td>
                    <td>8458</td>
                    <td>8458</td>
                    <td>84581</td>
                  </tr>
                  <tr>
                    <td>Uzbek</td>
                    <td>uz</td>
                    <td><a href="https://www.bbc.com/uzbek">BBC uzbek</a></td>
                    <td>4728</td>
                    <td>590</td>
                    <td>590</td>
                    <td>5908</td>
                  </tr>
                  <tr>
                    <td>Vietnamese</td>
                    <td>vi</td>
                    <td><a href="https://www.bbc.com/vietnamese">BBC vietnamese</a></td>
                    <td>32111</td>
                    <td>4013</td>
                    <td>4013</td>
                    <td>40137</td>
                  </tr>
                  <tr>
                    <td>Welsh</td>
                    <td>cy</td>
                    <td><a href="https://www.bbc.com/cymrufyw">BBC cymrufyw</a></td>
                    <td>9732</td>
                    <td>1216</td>
                    <td>1216</td>
                    <td>12164</td>
                  </tr>
                  <tr>
                    <td>Yoruba</td>
                    <td>yo</td>
                    <td><a href="https://www.bbc.com/yoruba">BBC yoruba</a></td>
                    <td>6350</td>
                    <td>793</td>
                    <td>793</td>
                    <td>7936</td>
                  </tr>
                </tbody>
              </table>
            </div>

            <p><code>*</code> A lot of articles in BBC Sinhala and BBC Ukrainian were written in English and Russian
              respectively. They were identified using <a href="https://arxiv.org/abs/1607.01759">Fasttext</a> and moved
              accordingly.
              <code>**</code> West African Pidgin English
            </p>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Dataset in GEM

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Rationale for Inclusion in GEM</h4>
              </li>
              <li>
                <h4>GEM-Specific Curation</h4>
              </li>
              <li>
                <h4>Getting Started with the Task</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Rationale for Inclusion in GEM</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field microscope">

            <h5>Why is the Dataset in GEM?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What does this dataset contribute toward better generation evaluation and why is it part of GEM?
                  </p>
                </div>
              </div>

            </h5>

            <p>Traditional abstractive text summarization has been centered around English and other high-resource
              languages. <strong>XL-Sum</strong> provides a large collection of high-quality article-summary pairs for
              45 languages where the languages range from high-resource to extremely low-resource. This enables the
              research community to explore the summarization capabilities of different models for multiple languages
              and languages in isolation. We believe the addition of <strong>XL-Sum</strong> to GEM makes the domain of
              abstractive text summarization more diversified and inclusive to the research community. We hope our
              efforts in this work will encourage the community to push the boundaries of abstractive text summarization
              beyond the English language, especially for low and mid-resource languages, bringing technological
              advances to communities of these languages that have been traditionally under-served.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Similar Datasets

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Do other datasets for the high level task exist?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Unique Language Coverage

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does this dataset cover other languages than other datasets for the same task?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Difference from other GEM datasets

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What else sets this dataset apart from other similar datasets in GEM?</p>
                </div>
              </div>

            </h5>

            <p>The summaries are highly concise and abstractive.</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Ability that the Dataset measures

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What aspect of model ability can be measured with this dataset?</p>
                </div>
              </div>

            </h5>

            <p>Conciseness, abstractiveness, and overall summarization capability.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>GEM-Specific Curation</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Modificatied for GEM?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Has the GEM version of the dataset been modified in any way (data, processing, splits) from the
                    original curated data?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Additional Splits?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does GEM provide additional splits to the dataset?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Getting Started with the Task</h4>


      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Previous Results

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Previous Results</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Previous Results</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Measured Model Abilities

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What aspect of model ability can be measured with this dataset?</p>
                </div>
              </div>

            </h5>

            <p>Conciseness, abstractiveness, and overall summarization capability.</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Metrics

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What metrics are typically used for this task?</p>
                </div>
              </div>

            </h5>

            <p><code>ROUGE</code></p>
          </div>

          <div class="datacard-field microscope">

            <h5>Proposed Evaluation

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>List and describe the purpose of the metrics and evaluation methodology (including human
                    evaluation) that the dataset creators used when introducing this task.</p>
                </div>
              </div>

            </h5>

            <p>ROUGE is the de facto evaluation metric used for text summarization. However, it was designed
              specifically for evaluating English texts. Due to the nature of the metric, scores are heavily dependent
              on text tokenization / stemming / unnecessary character removal, etc. Some modifications to the original
              ROUGE evaluation were done such as punctuation only removal, language specific tokenization/stemming to
              enable reliable comparison of source and target summaries across different scripts.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Previous results available?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Are previous results available?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Dataset Curation

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Original Curation</h4>
              </li>
              <li>
                <h4>Language Data</h4>
              </li>
              <li>
                <h4>Structured Annotations</h4>
              </li>
              <li>
                <h4>Consent</h4>
              </li>
              <li>
                <h4>Private Identifying Information (PII)</h4>
              </li>
              <li>
                <h4>Maintenance</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Original Curation</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Original Curation Rationale

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Original curation rationale</p>
                </div>
              </div>

            </h5>

            <p>State-of-the-art text summarization models are heavily data-driven, i.e., a large number of
              article-summary pairs are required to train them effectively. As a result, abstractive summarization has
              centered around the English language, as most large abstractive summarization datasets are available in
              English only. Though there have been some recent efforts for curating multilingual abstractive
              summarization datasets, they are limited in terms of the number of languages covered, the number of
              training samples, or both. To this end, we curate <strong>XL-Sum</strong>, a large-scale abstractive
              summarization dataset of 1.35 million news articles from 45 languages crawled from the British
              Broadcasting Corporation website.</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Communicative Goal

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What was the communicative goal?</p>
                </div>
              </div>

            </h5>

            <p>Introduce new languages in the english-centric domain of abstractive text summarization and enable both
              multilingual and per-language summarization.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Sourced from Different Sources

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Is the dataset aggregated from different data sources?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Source Details

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>List the sources (one per line)</p>
                </div>
              </div>

            </h5>

            <p>British Broadcasting Corporation (BBC) news websites.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Language Data</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>How was Language Data Obtained?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>How was the language data obtained?</p>
                </div>
              </div>

            </h5>

            <p><code>Found</code></p>
          </div>

          <div class="datacard-field telescope">

            <h5>Where was it found?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>If found, where from?</p>
                </div>
              </div>

            </h5>

            <p><code>Multiple websites</code></p>
          </div>

          <div class="datacard-field microscope">

            <h5>Language Producers

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What further information do we have on the language producers?</p>
                </div>
              </div>

            </h5>

            <p>The language content was written by professional news editors hired by BBC.</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Topics Covered

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the language in the dataset focus on specific topics? How would you describe them?</p>
                </div>
              </div>

            </h5>

            <p>News</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Data Validation

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Was the text validated by a different worker or a data curator?</p>
                </div>
              </div>

            </h5>

            <p>not validated</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Data Preprocessing

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>How was the text data pre-processed? (Enter N/A if the text was not pre-processed)</p>
                </div>
              </div>

            </h5>

            <p>We used 'NFKC' normalization on all text instances.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Was Data Filtered?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Were text instances selected or filtered?</p>
                </div>
              </div>

            </h5>

            <p>algorithmically</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Filter Criteria

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What were the selection criteria?</p>
                </div>
              </div>

            </h5>

            <p>We designed a crawler to recursively crawl pages starting from the homepage by visiting different article
              links present in each page visited. We were able to take advantage of the fact that all BBC sites have
              somewhat similar structures, and were able to scrape articles from all sites. We discarded pages with no
              textual contents (mostly pages consisting of multimedia contents) before further processing. We designed a
              number of heuristics to make the extraction effective by carefully examining the HTML structures of the
              crawled pages:</p>
            <ol>
              <li>The desired summary must be present within the beginning two paragraphs of an article.</li>
              <li>The summary paragraph must have some portion of texts in bold format.</li>
              <li>The summary paragraph may contain some hyperlinks that may not be bold. The proportion of bold texts
                and hyperlinked texts to the total length of the paragraph in consideration must be at least 95%.</li>
              <li>All texts except the summary and the headline must be included in the input text (including image
                captions).</li>
              <li>The input text must be at least twice as large as the summary.</li>
            </ol>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Structured Annotations</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Additional Annotations?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the dataset have additional annotations for each instance?</p>
                </div>
              </div>

            </h5>

            <p>none</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Annotation Service?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Was an annotation service used?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Consent</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Any Consent Policy?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Was there a consent policy involved when gathering the data?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Consent Policy Details

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What was the consent policy?</p>
                </div>
              </div>

            </h5>

            <p>BBC's policy specifies that the text content within its websites can be used for non-commercial research
              only.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Private Identifying Information (PII)</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Contains PII?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the source language data likely contain Personal Identifying Information about the data
                    creators or subjects?</p>
                </div>
              </div>

            </h5>

            <p>likely</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Categories of PII

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What categories of PII are present or suspected in the data?</p>
                </div>
              </div>

            </h5>

            <p><code>generic PII</code></p>
          </div>

          <div class="datacard-field periscope">

            <h5>Any PII Identification?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Did the curators use any automatic/manual method to identify PII in the dataset?</p>
                </div>
              </div>

            </h5>

            <p>no identification</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Maintenance</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Any Maintenance Plan?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the original dataset have a maintenance plan?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Broader Social Context

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Previous Work on the Social Impact of the Dataset</h4>
              </li>
              <li>
                <h4>Impact on Under-Served Communities</h4>
              </li>
              <li>
                <h4>Discussion of Biases</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Previous Work on the Social Impact of the Dataset</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Usage of Models based on the Data

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Are you aware of cases where models trained on the task featured in this dataset ore related tasks
                    have been used in automated systems?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Impact on Under-Served Communities</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Addresses needs of underserved Communities?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does this dataset address the needs of communities that are traditionally underserved in language
                    technology, and particularly language generation technology? Communities may be underserved for
                    exemple because their language, language variety, or social or geographical context is
                    underepresented in NLP and NLG resources (datasets and models).</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Details on how Dataset Addresses the Needs

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Describe how this dataset addresses the needs of underserved communities.</p>
                </div>
              </div>

            </h5>

            <p>This dataset introduces summarization corpus for many languages where there weren't any datasets like
              this curated before.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Discussion of Biases</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Any Documented Social Biases?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Are there documented social biases in the dataset? Biases in this context are variations in the
                    ways members of different social categories are represented that can have harmful downstream
                    consequences for members of the more disadvantaged group.</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Are the Language Producers Representative of the Language?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the distribution of language producers in the dataset accurately represent the full
                    distribution of speakers of the language world-wide? If not, how does it differ?</p>
                </div>
              </div>

            </h5>

            <p>Yes</p>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Considerations for Using the Data

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>PII Risks and Liability</h4>
              </li>
              <li>
                <h4>Licenses</h4>
              </li>
              <li>
                <h4>Known Technical Limitations</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>PII Risks and Liability</h4>


      </div>

      <div class="datacard-subsection">
        <h4>Licenses</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field periscope">

            <h5>Copyright Restrictions on the Dataset

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Based on your answers in the Intended Use part of the Data Overview Section, which of the following
                    best describe the copyright and licensing status of the dataset?</p>
                </div>
              </div>

            </h5>

            <p><code>research use only</code>, <code>non-commercial use only</code></p>
          </div>

          <div class="datacard-field periscope">

            <h5>Copyright Restrictions on the Language Data

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Based on your answers in the Language part of the Data Curation Section, which of the following
                    best describe the copyright and licensing status of the underlying language data?</p>
                </div>
              </div>

            </h5>

            <p><code>research use only</code>, <code>non-commercial use only</code></p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Known Technical Limitations</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field microscope">

            <h5>Technical Limitations

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Describe any known technical limitations, such as spurrious correlations, train/test overlap,
                    annotation biases, or mis-annotations, and cite the works that first identified these limitations
                    when possible.</p>
                </div>
              </div>

            </h5>

            <p>Human evaluation showed most languages had a high percentage of good summaries in the upper nineties,
              almost none of the summaries contained any conflicting information, while about one-third on average had
              information that was not directly inferrable from the source article. Since generally multiple articles
              are written regarding an important event, there could be an overlap between the training and evaluation
              data in terms on content.</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Unsuited Applications

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>When using a model trained on this dataset in a setting where users or the public may interact with
                    its predictions, what are some pitfalls to look out for? In particular, describe some applications
                    of the general task featured in this dataset that its curation or properties make it less suitable
                    for.</p>
                </div>
              </div>

            </h5>

            <p>The dataset is limited to news domain only. Hence it wouldn't be advisable to use a model trained on this
              dataset for summarizing texts from a different domain i.e. literature, scientific text etc. Another
              pitfall could be hallucinations in the model generated summary.</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Discouraged Use Cases

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What are some discouraged use cases of a model trained to maximize the proposed metrics on this
                    dataset? In particular, think about settings where decisions made by a model that performs
                    reasonably well on the metric my still have strong negative consequences for user or members of the
                    public.</p>
                </div>
              </div>

            </h5>

            <p>ROUGE evaluates the quality of the summary as a whole by considering up to 4-gram overlaps. Therefore, in
              an article about India if the word "India" in the generated summary gets replaced by "Pakistan" due to
              model hallucination, the overall score wouldn't be reduced significantly, but the entire meaning could get
              changed.</p>
          </div>
        </div>

      </div>
    </div>
  </section>
</div></div></article></main><div class="layout_push__lpoMK"></div></div><footer class="layout_footer__WlhMu utils_eggshell__3hbbY"><span class="layout_backToHome__D9QFr"><a href="/">← Home</a></span><span>If you have any questions, please join our <a href="https://groups.google.com/g/gem-benchmark" target="_blank" class="utils_accentUnderline__VG89l">google group</a> for support.</span></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"taskData":{"id":"xlsum","contentHtml":"\u003cdiv class=\"datacard\"\u003e\r\n\r\n  \u003csection class=\"datacard-section\"\u003e\r\n    \u003cdiv class=\"datacard-summary\"\u003e\r\n      \u003ch2\u003exlsum\u003c/h2\u003e\r\n      \u003cdiv class=\"summary-content\"\u003e\r\n        \u003cp\u003eXLSum is a highly multilingual summarization dataset supporting 44 language. The data stems from BBC news\r\n          articles.\u003c/p\u003e\r\n        \u003cp\u003eYou can load the dataset via:\u003c/p\u003e\r\n\r\n        \u003cdiv class=\"code-wrapper\"\u003e\r\n          \u003cdiv class=\"toolbar\"\u003e\r\n            \u003cdiv class=\"copy-icon\" title=\"Click to copy code block\"\u003e\u003c/div\u003e\r\n            \u003cdiv class=\"expand-modal-icon\" title=\"Click to expand code block\"\u003e\u003c/div\u003e\r\n          \u003c/div\u003e\r\n          \u003cpre\u003e\u003ccode\u003eimport datasets\r\ndata = datasets.load_dataset('GEM/xlsum')\r\n\u003c/code\u003e\u003c/pre\u003e\r\n        \u003c/div\u003e\r\n\r\n        \u003cp\u003eThe data loader can be found \u003ca href=\"https://huggingface.co/datasets/GEM/xlsum\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\r\n      \u003c/div\u003e\r\n    \u003c/div\u003e\r\n\r\n    \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n      \u003cdiv class=\"datacard-field\"\u003e\r\n\r\n        \u003ch5\u003ewebsite\r\n\r\n        \u003c/h5\u003e\r\n\r\n        \u003cp\u003e\u003ca href=\"https://github.com/csebuetnlp/xl-sum\"\u003eGithub\u003c/a\u003e\u003c/p\u003e\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-field\"\u003e\r\n\r\n        \u003ch5\u003epaper\r\n\r\n        \u003c/h5\u003e\r\n\r\n        \u003cp\u003e\u003ca href=\"https://aclanthology.org/2021.findings-acl.413/\"\u003eACL Anthology\u003c/a\u003e\u003c/p\u003e\r\n      \u003c/div\u003e\r\n    \u003c/div\u003e\r\n\r\n  \u003c/section\u003e\r\n\r\n  \u003csection class=\"datacard-section quick\"\u003e\r\n    \u003ch3 class=\"section-title\"\u003eQuick-Use\u003c/h3\u003e\r\n\r\n    \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n      \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n        \u003ch5\u003eContact Name\r\n\r\n          \u003cdiv class=\"tooltip\"\u003e\r\n            \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n            \u003cdiv class=\"tooltip-text\"\u003e\r\n              \u003cp\u003eIf known, provide the name of at least one person the reader can contact for questions about the\r\n                dataset.\u003c/p\u003e\r\n            \u003c/div\u003e\r\n          \u003c/div\u003e\r\n\r\n        \u003c/h5\u003e\r\n\r\n        \u003cp\u003eTahmid Hasan\u003c/p\u003e\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n        \u003ch5\u003eMultilingual?\r\n\r\n          \u003cdiv class=\"tooltip\"\u003e\r\n            \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n            \u003cdiv class=\"tooltip-text\"\u003e\r\n              \u003cp\u003eIs the dataset multilingual?\u003c/p\u003e\r\n            \u003c/div\u003e\r\n          \u003c/div\u003e\r\n\r\n        \u003c/h5\u003e\r\n\r\n        \u003cp\u003eyes\u003c/p\u003e\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n        \u003ch5\u003eCovered Languages\r\n\r\n          \u003cdiv class=\"tooltip\"\u003e\r\n            \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n            \u003cdiv class=\"tooltip-text\"\u003e\r\n              \u003cp\u003eWhat languages/dialects are covered in the dataset?\u003c/p\u003e\r\n            \u003c/div\u003e\r\n          \u003c/div\u003e\r\n\r\n        \u003c/h5\u003e\r\n\r\n        \u003cp\u003e\u003ccode\u003eAmharic\u003c/code\u003e, \u003ccode\u003eArabic\u003c/code\u003e, \u003ccode\u003eAzerbaijani\u003c/code\u003e, \u003ccode\u003eBengali, Bangla\u003c/code\u003e,\r\n          \u003ccode\u003eBurmese\u003c/code\u003e, \u003ccode\u003eChinese (family)\u003c/code\u003e, \u003ccode\u003eEnglish\u003c/code\u003e, \u003ccode\u003eFrench\u003c/code\u003e,\r\n          \u003ccode\u003eGujarati\u003c/code\u003e, \u003ccode\u003eHausa\u003c/code\u003e, \u003ccode\u003eHindi\u003c/code\u003e, \u003ccode\u003eIgbo\u003c/code\u003e, \u003ccode\u003eIndonesian\u003c/code\u003e,\r\n          \u003ccode\u003eJapanese\u003c/code\u003e, \u003ccode\u003eRundi\u003c/code\u003e, \u003ccode\u003eKorean\u003c/code\u003e, \u003ccode\u003eKirghiz, Kyrgyz\u003c/code\u003e,\r\n          \u003ccode\u003eMarathi\u003c/code\u003e, \u003ccode\u003eNepali (individual language)\u003c/code\u003e, \u003ccode\u003eOromo\u003c/code\u003e,\r\n          \u003ccode\u003ePushto, Pashto\u003c/code\u003e, \u003ccode\u003ePersian\u003c/code\u003e, \u003ccode\u003eGhanaian Pidgin English\u003c/code\u003e,\r\n          \u003ccode\u003ePortuguese\u003c/code\u003e, \u003ccode\u003ePanjabi, Punjabi\u003c/code\u003e, \u003ccode\u003eRussian\u003c/code\u003e,\r\n          \u003ccode\u003eScottish Gaelic, Gaelic\u003c/code\u003e, \u003ccode\u003eSerbian\u003c/code\u003e, \u003ccode\u003eRomano-Serbian\u003c/code\u003e,\r\n          \u003ccode\u003eSinhala, Sinhalese\u003c/code\u003e, \u003ccode\u003eSomali\u003c/code\u003e, \u003ccode\u003eSpanish, Castilian\u003c/code\u003e,\r\n          \u003ccode\u003eSwahili (individual language), Kiswahili\u003c/code\u003e, \u003ccode\u003eTamil\u003c/code\u003e, \u003ccode\u003eTelugu\u003c/code\u003e,\r\n          \u003ccode\u003eThai\u003c/code\u003e, \u003ccode\u003eTigrinya\u003c/code\u003e, \u003ccode\u003eTurkish\u003c/code\u003e, \u003ccode\u003eUkrainian\u003c/code\u003e, \u003ccode\u003eUrdu\u003c/code\u003e,\r\n          \u003ccode\u003eUzbek\u003c/code\u003e, \u003ccode\u003eVietnamese\u003c/code\u003e, \u003ccode\u003eWelsh\u003c/code\u003e, \u003ccode\u003eYoruba\u003c/code\u003e\u003c/p\u003e\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n        \u003ch5\u003eLicense\r\n\r\n          \u003cdiv class=\"tooltip\"\u003e\r\n            \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n            \u003cdiv class=\"tooltip-text\"\u003e\r\n              \u003cp\u003eWhat is the license of the dataset?\u003c/p\u003e\r\n            \u003c/div\u003e\r\n          \u003c/div\u003e\r\n\r\n        \u003c/h5\u003e\r\n\r\n        \u003cp\u003ecc-by-nc-sa-4.0: Creative Commons Attribution Non Commercial Share Alike 4.0 International\u003c/p\u003e\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n        \u003ch5\u003eCommunicative Goal\r\n\r\n          \u003cdiv class=\"tooltip\"\u003e\r\n            \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n            \u003cdiv class=\"tooltip-text\"\u003e\r\n              \u003cp\u003eProvide a short description of the communicative goal of a model trained for this task on this dataset.\r\n              \u003c/p\u003e\r\n            \u003c/div\u003e\r\n          \u003c/div\u003e\r\n\r\n        \u003c/h5\u003e\r\n\r\n        \u003cp\u003eSummarize news-like text in one of 45 languages.\u003c/p\u003e\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n        \u003ch5\u003eAdditional Annotations?\r\n\r\n          \u003cdiv class=\"tooltip\"\u003e\r\n            \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n            \u003cdiv class=\"tooltip-text\"\u003e\r\n              \u003cp\u003eDoes the dataset have additional annotations for each instance?\u003c/p\u003e\r\n            \u003c/div\u003e\r\n          \u003c/div\u003e\r\n\r\n        \u003c/h5\u003e\r\n\r\n        \u003cp\u003enone\u003c/p\u003e\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n        \u003ch5\u003eContains PII?\r\n\r\n          \u003cdiv class=\"tooltip\"\u003e\r\n            \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n            \u003cdiv class=\"tooltip-text\"\u003e\r\n              \u003cp\u003eDoes the source language data likely contain Personal Identifying Information about the data creators\r\n                or subjects?\u003c/p\u003e\r\n            \u003c/div\u003e\r\n          \u003c/div\u003e\r\n\r\n        \u003c/h5\u003e\r\n\r\n        \u003cp\u003elikely\u003c/p\u003e\r\n      \u003c/div\u003e\r\n    \u003c/div\u003e\r\n\r\n  \u003c/section\u003e\r\n\r\n\r\n  \u003csection class=\"datacard-section open\"\u003e\r\n\r\n    \u003cdiv class=\"datacard-section-preview\"\u003e\r\n      \u003ch3\u003eDataset Overview\r\n\r\n        \u003cdiv class=\"tooltip\"\u003e\r\n          \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n          \u003cdiv class=\"tooltip-text\"\u003e\r\n            \u003cul\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eWhere to find the Data and its Documentation\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eLanguages and Intended Use\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eCredit\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eDataset Structure\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n            \u003c/ul\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/h3\u003e\r\n      \u003cbutton class=\"expand-button\"\u003e\r\n        \u003csvg fill=\"#3c4f50\" height=\"24px\" viewBox=\"0 0 24 24\" width=\"24px\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\r\n          \u003cpath d=\"M0 0h24v24H0z\" fill=\"none\"\u003e\u003c/path\u003e\r\n          \u003cpath d=\"M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z\"\u003e\r\n          \u003c/path\u003e\r\n        \u003c/svg\u003e\r\n      \u003c/button\u003e\r\n    \u003c/div\u003e\r\n\r\n    \u003cdiv class=\"datacard-collapsible\"\u003e\r\n\r\n\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eWhere to find the Data and its Documentation\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eWebpage\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat is the webpage for the dataset (if it exists)?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ca href=\"https://github.com/csebuetnlp/xl-sum\"\u003eGithub\u003c/a\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eDownload\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat is the link to where the original dataset is hosted?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ca href=\"https://huggingface.co/datasets/csebuetnlp/xlsum/tree/main/data\"\u003eHuggingface\u003c/a\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003ePaper\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat is the link to the paper describing the dataset (open access preferred)?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ca href=\"https://aclanthology.org/2021.findings-acl.413/\"\u003eACL Anthology\u003c/a\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eBibTex\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eProvide the BibTex-formatted reference for the dataset. Please use the correct published version\r\n                    (ACL anthology, etc.) instead of google scholar created Bibtex.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n\r\n            \u003cdiv class=\"code-wrapper\"\u003e\r\n              \u003cdiv class=\"toolbar\"\u003e\r\n                \u003cdiv class=\"copy-icon\" title=\"Click to copy code block\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"expand-modal-icon\" title=\"Click to expand code block\"\u003e\u003c/div\u003e\r\n              \u003c/div\u003e\r\n              \u003cpre\u003e\u003ccode\u003e@inproceedings{hasan-etal-2021-xl,\r\ntitle = \"{XL}-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages\",\r\nauthor = \"Hasan, Tahmid  and\r\nBhattacharjee, Abhik  and\r\nIslam, Md. Saiful  and\r\nMubasshir, Kazi  and\r\nLi, Yuan-Fang  and\r\nKang, Yong-Bin  and\r\nRahman, M. Sohel  and\r\nShahriyar, Rifat\",\r\nbooktitle = \"Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021\",\r\nmonth = aug,\r\nyear = \"2021\",\r\naddress = \"Online\",\r\npublisher = \"Association for Computational Linguistics\",\r\nurl = \"https://aclanthology.org/2021.findings-acl.413\",\r\npages = \"4693--4703\",\r\n}\r\n\u003c/code\u003e\u003c/pre\u003e\r\n            \u003c/div\u003e\r\n\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eContact Name\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eIf known, provide the name of at least one person the reader can contact for questions about the\r\n                    dataset.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eTahmid Hasan\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eContact Email\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eIf known, provide the email of at least one person the reader can contact for questions about the\r\n                    dataset.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ca href=\"mailto:tahmidhasan@cse.buet.ac.bd\"\u003etahmidhasan@cse.buet.ac.bd\u003c/a\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eHas a Leaderboard?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDoes the dataset have an active leaderboard?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eyes\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eLeaderboard Link\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eProvide a link to the leaderboard.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ca href=\"http://explainaboard.nlpedia.ai/leaderboard/task_xlsum/\"\u003eExplainaboard\u003c/a\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eLeaderboard Details\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eBriefly describe how the leaderboard evaluates models.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThe leaderboard ranks models based on ROUGE scores (R1/R2/RL) of the generated summaries.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eLanguages and Intended Use\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eMultilingual?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eIs the dataset multilingual?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eyes\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eCovered Languages\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat languages/dialects are covered in the dataset?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ccode\u003eAmharic\u003c/code\u003e, \u003ccode\u003eArabic\u003c/code\u003e, \u003ccode\u003eAzerbaijani\u003c/code\u003e, \u003ccode\u003eBengali, Bangla\u003c/code\u003e,\r\n              \u003ccode\u003eBurmese\u003c/code\u003e, \u003ccode\u003eChinese (family)\u003c/code\u003e, \u003ccode\u003eEnglish\u003c/code\u003e, \u003ccode\u003eFrench\u003c/code\u003e,\r\n              \u003ccode\u003eGujarati\u003c/code\u003e, \u003ccode\u003eHausa\u003c/code\u003e, \u003ccode\u003eHindi\u003c/code\u003e, \u003ccode\u003eIgbo\u003c/code\u003e, \u003ccode\u003eIndonesian\u003c/code\u003e,\r\n              \u003ccode\u003eJapanese\u003c/code\u003e, \u003ccode\u003eRundi\u003c/code\u003e, \u003ccode\u003eKorean\u003c/code\u003e, \u003ccode\u003eKirghiz, Kyrgyz\u003c/code\u003e,\r\n              \u003ccode\u003eMarathi\u003c/code\u003e, \u003ccode\u003eNepali (individual language)\u003c/code\u003e, \u003ccode\u003eOromo\u003c/code\u003e,\r\n              \u003ccode\u003ePushto, Pashto\u003c/code\u003e, \u003ccode\u003ePersian\u003c/code\u003e, \u003ccode\u003eGhanaian Pidgin English\u003c/code\u003e,\r\n              \u003ccode\u003ePortuguese\u003c/code\u003e, \u003ccode\u003ePanjabi, Punjabi\u003c/code\u003e, \u003ccode\u003eRussian\u003c/code\u003e,\r\n              \u003ccode\u003eScottish Gaelic, Gaelic\u003c/code\u003e, \u003ccode\u003eSerbian\u003c/code\u003e, \u003ccode\u003eRomano-Serbian\u003c/code\u003e,\r\n              \u003ccode\u003eSinhala, Sinhalese\u003c/code\u003e, \u003ccode\u003eSomali\u003c/code\u003e, \u003ccode\u003eSpanish, Castilian\u003c/code\u003e,\r\n              \u003ccode\u003eSwahili (individual language), Kiswahili\u003c/code\u003e, \u003ccode\u003eTamil\u003c/code\u003e, \u003ccode\u003eTelugu\u003c/code\u003e,\r\n              \u003ccode\u003eThai\u003c/code\u003e, \u003ccode\u003eTigrinya\u003c/code\u003e, \u003ccode\u003eTurkish\u003c/code\u003e, \u003ccode\u003eUkrainian\u003c/code\u003e, \u003ccode\u003eUrdu\u003c/code\u003e,\r\n              \u003ccode\u003eUzbek\u003c/code\u003e, \u003ccode\u003eVietnamese\u003c/code\u003e, \u003ccode\u003eWelsh\u003c/code\u003e, \u003ccode\u003eYoruba\u003c/code\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eLicense\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat is the license of the dataset?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003ecc-by-nc-sa-4.0: Creative Commons Attribution Non Commercial Share Alike 4.0 International\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eIntended Use\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat is the intended use of the dataset?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eAbstractive summarization has centered around the English language, as most large abstractive\r\n              summarization datasets are available in English only. Though there have been some recent efforts for\r\n              curating multilingual abstractive summarization datasets, they are limited in terms of the number of\r\n              languages covered, the number of training samples, or both. To this end, \u003cstrong\u003eXL-Sum\u003c/strong\u003e presents\r\n              a large-scale abstractive summarization dataset of 1.35 million news articles from 45 languages crawled\r\n              from the British Broadcasting Corporation website. It is intended to be used for both multilingual and\r\n              per-language summarization tasks.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003ePrimary Task\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat primary task does the dataset support?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eSummarization\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eCommunicative Goal\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eProvide a short description of the communicative goal of a model trained for this task on this\r\n                    dataset.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eSummarize news-like text in one of 45 languages.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eCredit\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eCuration Organization Type(s)\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eIn what kind of organization did the dataset curation happen?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ccode\u003eacademic\u003c/code\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eCuration Organization(s)\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eName the organization(s).\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eBangladesh University of Engineering and Technology\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eWho added the Dataset to GEM?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWho contributed to the data card and adding the dataset to GEM? List the people+affiliations\r\n                    involved in creating this data card and who helped integrate this dataset into GEM.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eTahmid Hasan (Bangladesh University of Engineering and Technology), Abhik Bhattacharjee (Bangladesh\r\n              University of Engineering and Technology)\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eDataset Structure\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eData Fields\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eList and describe the fields present in the dataset.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cul\u003e\r\n              \u003cli\u003e\u003ccode\u003egem_id\u003c/code\u003e: A string representing the article ID.\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003eurl\u003c/code\u003e: A string representing the article URL.\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003etitle\u003c/code\u003e: A string containing the article title.\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003esummary\u003c/code\u003e: A string containing the article summary.\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003etext\u003c/code\u003e : A string containing the article text.\u003c/li\u003e\r\n            \u003c/ul\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eExample Instance\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eProvide a JSON formatted example of a typical instance in the dataset.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n\r\n            \u003cdiv class=\"code-wrapper\"\u003e\r\n              \u003cdiv class=\"toolbar\"\u003e\r\n                \u003cdiv class=\"copy-icon\" title=\"Click to copy code block\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"expand-modal-icon\" title=\"Click to expand code block\"\u003e\u003c/div\u003e\r\n              \u003c/div\u003e\r\n              \u003cpre\u003e\u003ccode\u003e{\r\n\"gem_id\": \"GEM-xlsum_english-train-1589\",\r\n\"url\": \"[BBC news](https://www.bbc.com/news)/technology-17657859\",\r\n\"title\": \"Yahoo files e-book advert system patent applications\",\r\n\"summary\": \"Yahoo has signalled it is investigating e-book adverts as a way to stimulate its earnings.\",\r\n\"text\": \"Yahoo's patents suggest users could weigh the type of ads against the sizes of discount before purchase. It says in two US patent applications that ads for digital book readers have been \\\"less than optimal\\\" to date. The filings suggest that users could be offered titles at a variety of prices depending on the ads' prominence They add that the products shown could be determined by the type of book being read, or even the contents of a specific chapter, phrase or word. The paperwork was published by the US Patent and Trademark Office late last week and relates to work carried out at the firm's headquarters in Sunnyvale, California. \\\"Greater levels of advertising, which may be more valuable to an advertiser and potentially more distracting to an e-book reader, may warrant higher discounts,\\\" it states. Free books It suggests users could be offered ads as hyperlinks based within the book's text, in-laid text or even \\\"dynamic content\\\" such as video. Another idea suggests boxes at the bottom of a page could trail later chapters or quotes saying \\\"brought to you by Company A\\\". It adds that the more willing the customer is to see the ads, the greater the potential discount. \\\"Higher frequencies... may even be great enough to allow the e-book to be obtained for free,\\\" it states. The authors write that the type of ad could influence the value of the discount, with \\\"lower class advertising... such as teeth whitener advertisements\\\" offering a cheaper price than \\\"high\\\" or \\\"middle class\\\" adverts, for things like pizza. The inventors also suggest that ads could be linked to the mood or emotional state the reader is in as a they progress through a title. For example, they say if characters fall in love or show affection during a chapter, then ads for flowers or entertainment could be triggered. The patents also suggest this could applied to children's books - giving the Tom Hanks animated film Polar Express as an example. It says a scene showing a waiter giving the protagonists hot drinks \\\"may be an excellent opportunity to show an advertisement for hot cocoa, or a branded chocolate bar\\\". Another example states: \\\"If the setting includes young characters, a Coke advertisement could be provided, inviting the reader to enjoy a glass of Coke with his book, and providing a graphic of a cool glass.\\\" It adds that such targeting could be further enhanced by taking account of previous titles the owner has bought. 'Advertising-free zone' At present, several Amazon and Kobo e-book readers offer full-screen adverts when the device is switched off and show smaller ads on their menu screens, but the main text of the titles remains free of marketing. Yahoo does not currently provide ads to these devices, and a move into the area could boost its shrinking revenues. However, Philip Jones, deputy editor of the Bookseller magazine, said that the internet firm might struggle to get some of its ideas adopted. \\\"This has been mooted before and was fairly well decried,\\\" he said. \\\"Perhaps in a limited context it could work if the merchandise was strongly related to the title and was kept away from the text. \\\"But readers - particularly parents - like the fact that reading is an advertising-free zone. Authors would also want something to say about ads interrupting their narrative flow.\\\"\"\r\n}\r\n\u003c/code\u003e\u003c/pre\u003e\r\n            \u003c/div\u003e\r\n\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eData Splits\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDescribe and name the splits in the dataset if there are more than one.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThe splits in the dataset are specified by the language names, which are as follows:\u003c/p\u003e\r\n            \u003cul\u003e\r\n              \u003cli\u003e\u003ccode\u003eamharic\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003earabic\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003eazerbaijani\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003ebengali\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003eburmese\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003echinese_simplified\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003echinese_traditional\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003eenglish\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003efrench\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003egujarati\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003ehausa\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003ehindi\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003eigbo\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003eindonesian\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003ejapanese\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003ekirundi\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003ekorean\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003ekyrgyz\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003emarathi\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003enepali\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003eoromo\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003epashto\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003epersian\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003epidgin\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003eportuguese\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003epunjabi\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003erussian\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003escottish_gaelic\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003eserbian_cyrillic\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003eserbian_latin\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003esinhala\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003esomali\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003espanish\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003eswahili\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003etamil\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003etelugu\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003ethai\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003etigrinya\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003eturkish\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003eukrainian\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003eurdu\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003euzbek\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003evietnamese\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003ewelsh\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003eyoruba\u003c/code\u003e\u003c/li\u003e\r\n            \u003c/ul\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eSplitting Criteria\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDescribe any criteria for splitting the data, if used. If there are differences between the splits\r\n                    (e.g., if the training annotations are machine-generated and the dev and test ones are created by\r\n                    humans, or if different numbers of annotators contributed to each example), describe them here.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eWe used a 80%-10%-10% split for all languages with a few exceptions. \u003ccode\u003eEnglish\u003c/code\u003e was split\r\n              93%-3.5%-3.5% for the evaluation set size to resemble that of \u003ccode\u003eCNN/DM\u003c/code\u003e and \u003ccode\u003eXSum\u003c/code\u003e;\r\n              \u003ccode\u003eScottish Gaelic\u003c/code\u003e, \u003ccode\u003eKyrgyz\u003c/code\u003e and \u003ccode\u003eSinhala\u003c/code\u003e had relatively fewer samples,\r\n              their evaluation sets were increased to 500 samples for more reliable evaluation. Same articles were used\r\n              for evaluation in the two variants of Chinese and Serbian to prevent data leakage in multilingual\r\n              training. Individual dataset download links with train-dev-test example counts are given below:\u003c/p\u003e\r\n\r\n            \u003cdiv class=\"table-wrapper\"\u003e\r\n              \u003cdiv class=\"toolbar\"\u003e\r\n                \u003cdiv class=\"expand-modal-icon\" title=\"Click to expand table\"\u003e\u003c/div\u003e\r\n              \u003c/div\u003e\r\n              \u003ctable\u003e\r\n                \u003cthead\u003e\r\n                  \u003ctr\u003e\r\n                    \u003cth\u003eLanguage\u003c/th\u003e\r\n                    \u003cth\u003eISO 639-1 Code\u003c/th\u003e\r\n                    \u003cth\u003eBBC subdomain(s)\u003c/th\u003e\r\n                    \u003cth\u003eTrain\u003c/th\u003e\r\n                    \u003cth\u003eDev\u003c/th\u003e\r\n                    \u003cth\u003eTest\u003c/th\u003e\r\n                    \u003cth\u003eTotal\u003c/th\u003e\r\n                  \u003c/tr\u003e\r\n                \u003c/thead\u003e\r\n                \u003ctbody\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eAmharic\u003c/td\u003e\r\n                    \u003ctd\u003eam\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/amharic\"\u003eBBC amharic\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e5761\u003c/td\u003e\r\n                    \u003ctd\u003e719\u003c/td\u003e\r\n                    \u003ctd\u003e719\u003c/td\u003e\r\n                    \u003ctd\u003e7199\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eArabic\u003c/td\u003e\r\n                    \u003ctd\u003ear\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/arabic\"\u003eBBC arabic\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e37519\u003c/td\u003e\r\n                    \u003ctd\u003e4689\u003c/td\u003e\r\n                    \u003ctd\u003e4689\u003c/td\u003e\r\n                    \u003ctd\u003e46897\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eAzerbaijani\u003c/td\u003e\r\n                    \u003ctd\u003eaz\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/azeri\"\u003eBBC azeri\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e6478\u003c/td\u003e\r\n                    \u003ctd\u003e809\u003c/td\u003e\r\n                    \u003ctd\u003e809\u003c/td\u003e\r\n                    \u003ctd\u003e8096\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eBengali\u003c/td\u003e\r\n                    \u003ctd\u003ebn\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/bengali\"\u003eBBC bengali\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e8102\u003c/td\u003e\r\n                    \u003ctd\u003e1012\u003c/td\u003e\r\n                    \u003ctd\u003e1012\u003c/td\u003e\r\n                    \u003ctd\u003e10126\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eBurmese\u003c/td\u003e\r\n                    \u003ctd\u003emy\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/burmese\"\u003eBBC burmese\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e4569\u003c/td\u003e\r\n                    \u003ctd\u003e570\u003c/td\u003e\r\n                    \u003ctd\u003e570\u003c/td\u003e\r\n                    \u003ctd\u003e5709\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eChinese (Simplified)\u003c/td\u003e\r\n                    \u003ctd\u003ezh-CN\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/ukchina\"\u003eBBC ukchina\u003c/a\u003e/simp, \u003ca\r\n                        href=\"https://www.bbc.com/zhongwen\"\u003eBBC zhongwen\u003c/a\u003e/simp\u003c/td\u003e\r\n                    \u003ctd\u003e37362\u003c/td\u003e\r\n                    \u003ctd\u003e4670\u003c/td\u003e\r\n                    \u003ctd\u003e4670\u003c/td\u003e\r\n                    \u003ctd\u003e46702\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eChinese (Traditional)\u003c/td\u003e\r\n                    \u003ctd\u003ezh-TW\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/ukchina\"\u003eBBC ukchina\u003c/a\u003e/trad, \u003ca\r\n                        href=\"https://www.bbc.com/zhongwen\"\u003eBBC zhongwen\u003c/a\u003e/trad\u003c/td\u003e\r\n                    \u003ctd\u003e37373\u003c/td\u003e\r\n                    \u003ctd\u003e4670\u003c/td\u003e\r\n                    \u003ctd\u003e4670\u003c/td\u003e\r\n                    \u003ctd\u003e46713\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eEnglish\u003c/td\u003e\r\n                    \u003ctd\u003een\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/english\"\u003eBBC english\u003c/a\u003e, \u003ca href=\"https://www.bbc.com/sinhala\"\u003eBBC\r\n                        sinhala\u003c/a\u003e \u003ccode\u003e*\u003c/code\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e306522\u003c/td\u003e\r\n                    \u003ctd\u003e11535\u003c/td\u003e\r\n                    \u003ctd\u003e11535\u003c/td\u003e\r\n                    \u003ctd\u003e329592\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eFrench\u003c/td\u003e\r\n                    \u003ctd\u003efr\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/afrique\"\u003eBBC afrique\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e8697\u003c/td\u003e\r\n                    \u003ctd\u003e1086\u003c/td\u003e\r\n                    \u003ctd\u003e1086\u003c/td\u003e\r\n                    \u003ctd\u003e10869\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eGujarati\u003c/td\u003e\r\n                    \u003ctd\u003egu\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/gujarati\"\u003eBBC gujarati\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e9119\u003c/td\u003e\r\n                    \u003ctd\u003e1139\u003c/td\u003e\r\n                    \u003ctd\u003e1139\u003c/td\u003e\r\n                    \u003ctd\u003e11397\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eHausa\u003c/td\u003e\r\n                    \u003ctd\u003eha\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/hausa\"\u003eBBC hausa\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e6418\u003c/td\u003e\r\n                    \u003ctd\u003e802\u003c/td\u003e\r\n                    \u003ctd\u003e802\u003c/td\u003e\r\n                    \u003ctd\u003e8022\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eHindi\u003c/td\u003e\r\n                    \u003ctd\u003ehi\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/hindi\"\u003eBBC hindi\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e70778\u003c/td\u003e\r\n                    \u003ctd\u003e8847\u003c/td\u003e\r\n                    \u003ctd\u003e8847\u003c/td\u003e\r\n                    \u003ctd\u003e88472\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eIgbo\u003c/td\u003e\r\n                    \u003ctd\u003eig\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/igbo\"\u003eBBC igbo\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e4183\u003c/td\u003e\r\n                    \u003ctd\u003e522\u003c/td\u003e\r\n                    \u003ctd\u003e522\u003c/td\u003e\r\n                    \u003ctd\u003e5227\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eIndonesian\u003c/td\u003e\r\n                    \u003ctd\u003eid\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/indonesia\"\u003eBBC indonesia\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e38242\u003c/td\u003e\r\n                    \u003ctd\u003e4780\u003c/td\u003e\r\n                    \u003ctd\u003e4780\u003c/td\u003e\r\n                    \u003ctd\u003e47802\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eJapanese\u003c/td\u003e\r\n                    \u003ctd\u003eja\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/japanese\"\u003eBBC japanese\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e7113\u003c/td\u003e\r\n                    \u003ctd\u003e889\u003c/td\u003e\r\n                    \u003ctd\u003e889\u003c/td\u003e\r\n                    \u003ctd\u003e8891\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eKirundi\u003c/td\u003e\r\n                    \u003ctd\u003ern\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/gahuza\"\u003eBBC gahuza\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e5746\u003c/td\u003e\r\n                    \u003ctd\u003e718\u003c/td\u003e\r\n                    \u003ctd\u003e718\u003c/td\u003e\r\n                    \u003ctd\u003e7182\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eKorean\u003c/td\u003e\r\n                    \u003ctd\u003eko\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/korean\"\u003eBBC korean\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e4407\u003c/td\u003e\r\n                    \u003ctd\u003e550\u003c/td\u003e\r\n                    \u003ctd\u003e550\u003c/td\u003e\r\n                    \u003ctd\u003e5507\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eKyrgyz\u003c/td\u003e\r\n                    \u003ctd\u003eky\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/kyrgyz\"\u003eBBC kyrgyz\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e2266\u003c/td\u003e\r\n                    \u003ctd\u003e500\u003c/td\u003e\r\n                    \u003ctd\u003e500\u003c/td\u003e\r\n                    \u003ctd\u003e3266\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eMarathi\u003c/td\u003e\r\n                    \u003ctd\u003emr\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/marathi\"\u003eBBC marathi\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e10903\u003c/td\u003e\r\n                    \u003ctd\u003e1362\u003c/td\u003e\r\n                    \u003ctd\u003e1362\u003c/td\u003e\r\n                    \u003ctd\u003e13627\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eNepali\u003c/td\u003e\r\n                    \u003ctd\u003enp\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/nepali\"\u003eBBC nepali\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e5808\u003c/td\u003e\r\n                    \u003ctd\u003e725\u003c/td\u003e\r\n                    \u003ctd\u003e725\u003c/td\u003e\r\n                    \u003ctd\u003e7258\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eOromo\u003c/td\u003e\r\n                    \u003ctd\u003eom\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/afaanoromoo\"\u003eBBC afaanoromoo\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e6063\u003c/td\u003e\r\n                    \u003ctd\u003e757\u003c/td\u003e\r\n                    \u003ctd\u003e757\u003c/td\u003e\r\n                    \u003ctd\u003e7577\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003ePashto\u003c/td\u003e\r\n                    \u003ctd\u003eps\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/pashto\"\u003eBBC pashto\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e14353\u003c/td\u003e\r\n                    \u003ctd\u003e1794\u003c/td\u003e\r\n                    \u003ctd\u003e1794\u003c/td\u003e\r\n                    \u003ctd\u003e17941\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003ePersian\u003c/td\u003e\r\n                    \u003ctd\u003efa\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/persian\"\u003eBBC persian\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e47251\u003c/td\u003e\r\n                    \u003ctd\u003e5906\u003c/td\u003e\r\n                    \u003ctd\u003e5906\u003c/td\u003e\r\n                    \u003ctd\u003e59063\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003ePidgin\u003ccode\u003e**\u003c/code\u003e\u003c/td\u003e\r\n                    \u003ctd\u003epcm\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/pidgin\"\u003eBBC pidgin\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e9208\u003c/td\u003e\r\n                    \u003ctd\u003e1151\u003c/td\u003e\r\n                    \u003ctd\u003e1151\u003c/td\u003e\r\n                    \u003ctd\u003e11510\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003ePortuguese\u003c/td\u003e\r\n                    \u003ctd\u003ept\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/portuguese\"\u003eBBC portuguese\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e57402\u003c/td\u003e\r\n                    \u003ctd\u003e7175\u003c/td\u003e\r\n                    \u003ctd\u003e7175\u003c/td\u003e\r\n                    \u003ctd\u003e71752\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003ePunjabi\u003c/td\u003e\r\n                    \u003ctd\u003epa\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/punjabi\"\u003eBBC punjabi\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e8215\u003c/td\u003e\r\n                    \u003ctd\u003e1026\u003c/td\u003e\r\n                    \u003ctd\u003e1026\u003c/td\u003e\r\n                    \u003ctd\u003e10267\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eRussian\u003c/td\u003e\r\n                    \u003ctd\u003eru\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/russian\"\u003eBBC russian\u003c/a\u003e, \u003ca\r\n                        href=\"https://www.bbc.com/ukrainian\"\u003eBBC ukrainian\u003c/a\u003e \u003ccode\u003e*\u003c/code\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e62243\u003c/td\u003e\r\n                    \u003ctd\u003e7780\u003c/td\u003e\r\n                    \u003ctd\u003e7780\u003c/td\u003e\r\n                    \u003ctd\u003e77803\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eScottish Gaelic\u003c/td\u003e\r\n                    \u003ctd\u003egd\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/naidheachdan\"\u003eBBC naidheachdan\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e1313\u003c/td\u003e\r\n                    \u003ctd\u003e500\u003c/td\u003e\r\n                    \u003ctd\u003e500\u003c/td\u003e\r\n                    \u003ctd\u003e2313\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eSerbian (Cyrillic)\u003c/td\u003e\r\n                    \u003ctd\u003esr\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/serbian\"\u003eBBC serbian\u003c/a\u003e/cyr\u003c/td\u003e\r\n                    \u003ctd\u003e7275\u003c/td\u003e\r\n                    \u003ctd\u003e909\u003c/td\u003e\r\n                    \u003ctd\u003e909\u003c/td\u003e\r\n                    \u003ctd\u003e9093\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eSerbian (Latin)\u003c/td\u003e\r\n                    \u003ctd\u003esr\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/serbian\"\u003eBBC serbian\u003c/a\u003e/lat\u003c/td\u003e\r\n                    \u003ctd\u003e7276\u003c/td\u003e\r\n                    \u003ctd\u003e909\u003c/td\u003e\r\n                    \u003ctd\u003e909\u003c/td\u003e\r\n                    \u003ctd\u003e9094\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eSinhala\u003c/td\u003e\r\n                    \u003ctd\u003esi\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/sinhala\"\u003eBBC sinhala\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e3249\u003c/td\u003e\r\n                    \u003ctd\u003e500\u003c/td\u003e\r\n                    \u003ctd\u003e500\u003c/td\u003e\r\n                    \u003ctd\u003e4249\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eSomali\u003c/td\u003e\r\n                    \u003ctd\u003eso\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/somali\"\u003eBBC somali\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e5962\u003c/td\u003e\r\n                    \u003ctd\u003e745\u003c/td\u003e\r\n                    \u003ctd\u003e745\u003c/td\u003e\r\n                    \u003ctd\u003e7452\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eSpanish\u003c/td\u003e\r\n                    \u003ctd\u003ees\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/mundo\"\u003eBBC mundo\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e38110\u003c/td\u003e\r\n                    \u003ctd\u003e4763\u003c/td\u003e\r\n                    \u003ctd\u003e4763\u003c/td\u003e\r\n                    \u003ctd\u003e47636\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eSwahili\u003c/td\u003e\r\n                    \u003ctd\u003esw\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/swahili\"\u003eBBC swahili\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e7898\u003c/td\u003e\r\n                    \u003ctd\u003e987\u003c/td\u003e\r\n                    \u003ctd\u003e987\u003c/td\u003e\r\n                    \u003ctd\u003e9872\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eTamil\u003c/td\u003e\r\n                    \u003ctd\u003eta\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/tamil\"\u003eBBC tamil\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e16222\u003c/td\u003e\r\n                    \u003ctd\u003e2027\u003c/td\u003e\r\n                    \u003ctd\u003e2027\u003c/td\u003e\r\n                    \u003ctd\u003e20276\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eTelugu\u003c/td\u003e\r\n                    \u003ctd\u003ete\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/telugu\"\u003eBBC telugu\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e10421\u003c/td\u003e\r\n                    \u003ctd\u003e1302\u003c/td\u003e\r\n                    \u003ctd\u003e1302\u003c/td\u003e\r\n                    \u003ctd\u003e13025\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eThai\u003c/td\u003e\r\n                    \u003ctd\u003eth\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/thai\"\u003eBBC thai\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e6616\u003c/td\u003e\r\n                    \u003ctd\u003e826\u003c/td\u003e\r\n                    \u003ctd\u003e826\u003c/td\u003e\r\n                    \u003ctd\u003e8268\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eTigrinya\u003c/td\u003e\r\n                    \u003ctd\u003eti\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/tigrinya\"\u003eBBC tigrinya\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e5451\u003c/td\u003e\r\n                    \u003ctd\u003e681\u003c/td\u003e\r\n                    \u003ctd\u003e681\u003c/td\u003e\r\n                    \u003ctd\u003e6813\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eTurkish\u003c/td\u003e\r\n                    \u003ctd\u003etr\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/turkce\"\u003eBBC turkce\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e27176\u003c/td\u003e\r\n                    \u003ctd\u003e3397\u003c/td\u003e\r\n                    \u003ctd\u003e3397\u003c/td\u003e\r\n                    \u003ctd\u003e33970\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eUkrainian\u003c/td\u003e\r\n                    \u003ctd\u003euk\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/ukrainian\"\u003eBBC ukrainian\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e43201\u003c/td\u003e\r\n                    \u003ctd\u003e5399\u003c/td\u003e\r\n                    \u003ctd\u003e5399\u003c/td\u003e\r\n                    \u003ctd\u003e53999\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eUrdu\u003c/td\u003e\r\n                    \u003ctd\u003eur\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/urdu\"\u003eBBC urdu\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e67665\u003c/td\u003e\r\n                    \u003ctd\u003e8458\u003c/td\u003e\r\n                    \u003ctd\u003e8458\u003c/td\u003e\r\n                    \u003ctd\u003e84581\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eUzbek\u003c/td\u003e\r\n                    \u003ctd\u003euz\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/uzbek\"\u003eBBC uzbek\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e4728\u003c/td\u003e\r\n                    \u003ctd\u003e590\u003c/td\u003e\r\n                    \u003ctd\u003e590\u003c/td\u003e\r\n                    \u003ctd\u003e5908\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eVietnamese\u003c/td\u003e\r\n                    \u003ctd\u003evi\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/vietnamese\"\u003eBBC vietnamese\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e32111\u003c/td\u003e\r\n                    \u003ctd\u003e4013\u003c/td\u003e\r\n                    \u003ctd\u003e4013\u003c/td\u003e\r\n                    \u003ctd\u003e40137\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eWelsh\u003c/td\u003e\r\n                    \u003ctd\u003ecy\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/cymrufyw\"\u003eBBC cymrufyw\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e9732\u003c/td\u003e\r\n                    \u003ctd\u003e1216\u003c/td\u003e\r\n                    \u003ctd\u003e1216\u003c/td\u003e\r\n                    \u003ctd\u003e12164\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003eYoruba\u003c/td\u003e\r\n                    \u003ctd\u003eyo\u003c/td\u003e\r\n                    \u003ctd\u003e\u003ca href=\"https://www.bbc.com/yoruba\"\u003eBBC yoruba\u003c/a\u003e\u003c/td\u003e\r\n                    \u003ctd\u003e6350\u003c/td\u003e\r\n                    \u003ctd\u003e793\u003c/td\u003e\r\n                    \u003ctd\u003e793\u003c/td\u003e\r\n                    \u003ctd\u003e7936\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                \u003c/tbody\u003e\r\n              \u003c/table\u003e\r\n            \u003c/div\u003e\r\n\r\n            \u003cp\u003e\u003ccode\u003e*\u003c/code\u003e A lot of articles in BBC Sinhala and BBC Ukrainian were written in English and Russian\r\n              respectively. They were identified using \u003ca href=\"https://arxiv.org/abs/1607.01759\"\u003eFasttext\u003c/a\u003e and moved\r\n              accordingly.\r\n              \u003ccode\u003e**\u003c/code\u003e West African Pidgin English\r\n            \u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n    \u003c/div\u003e\r\n  \u003c/section\u003e\r\n\r\n  \u003csection class=\"datacard-section open\"\u003e\r\n\r\n    \u003cdiv class=\"datacard-section-preview\"\u003e\r\n      \u003ch3\u003eDataset in GEM\r\n\r\n        \u003cdiv class=\"tooltip\"\u003e\r\n          \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n          \u003cdiv class=\"tooltip-text\"\u003e\r\n            \u003cul\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eRationale for Inclusion in GEM\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eGEM-Specific Curation\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eGetting Started with the Task\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n            \u003c/ul\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/h3\u003e\r\n      \u003cbutton class=\"expand-button\"\u003e\r\n        \u003csvg fill=\"#3c4f50\" height=\"24px\" viewBox=\"0 0 24 24\" width=\"24px\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\r\n          \u003cpath d=\"M0 0h24v24H0z\" fill=\"none\"\u003e\u003c/path\u003e\r\n          \u003cpath d=\"M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z\"\u003e\r\n          \u003c/path\u003e\r\n        \u003c/svg\u003e\r\n      \u003c/button\u003e\r\n    \u003c/div\u003e\r\n\r\n    \u003cdiv class=\"datacard-collapsible\"\u003e\r\n\r\n\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eRationale for Inclusion in GEM\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eWhy is the Dataset in GEM?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat does this dataset contribute toward better generation evaluation and why is it part of GEM?\r\n                  \u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eTraditional abstractive text summarization has been centered around English and other high-resource\r\n              languages. \u003cstrong\u003eXL-Sum\u003c/strong\u003e provides a large collection of high-quality article-summary pairs for\r\n              45 languages where the languages range from high-resource to extremely low-resource. This enables the\r\n              research community to explore the summarization capabilities of different models for multiple languages\r\n              and languages in isolation. We believe the addition of \u003cstrong\u003eXL-Sum\u003c/strong\u003e to GEM makes the domain of\r\n              abstractive text summarization more diversified and inclusive to the research community. We hope our\r\n              efforts in this work will encourage the community to push the boundaries of abstractive text summarization\r\n              beyond the English language, especially for low and mid-resource languages, bringing technological\r\n              advances to communities of these languages that have been traditionally under-served.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eSimilar Datasets\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDo other datasets for the high level task exist?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eyes\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eUnique Language Coverage\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDoes this dataset cover other languages than other datasets for the same task?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eyes\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eDifference from other GEM datasets\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat else sets this dataset apart from other similar datasets in GEM?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThe summaries are highly concise and abstractive.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eAbility that the Dataset measures\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat aspect of model ability can be measured with this dataset?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eConciseness, abstractiveness, and overall summarization capability.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eGEM-Specific Curation\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eModificatied for GEM?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eHas the GEM version of the dataset been modified in any way (data, processing, splits) from the\r\n                    original curated data?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eno\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eAdditional Splits?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDoes GEM provide additional splits to the dataset?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eno\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eGetting Started with the Task\u003c/h4\u003e\r\n\r\n\r\n      \u003c/div\u003e\r\n    \u003c/div\u003e\r\n  \u003c/section\u003e\r\n\r\n  \u003csection class=\"datacard-section open\"\u003e\r\n\r\n    \u003cdiv class=\"datacard-section-preview\"\u003e\r\n      \u003ch3\u003ePrevious Results\r\n\r\n        \u003cdiv class=\"tooltip\"\u003e\r\n          \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n          \u003cdiv class=\"tooltip-text\"\u003e\r\n            \u003cul\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003ePrevious Results\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n            \u003c/ul\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/h3\u003e\r\n      \u003cbutton class=\"expand-button\"\u003e\r\n        \u003csvg fill=\"#3c4f50\" height=\"24px\" viewBox=\"0 0 24 24\" width=\"24px\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\r\n          \u003cpath d=\"M0 0h24v24H0z\" fill=\"none\"\u003e\u003c/path\u003e\r\n          \u003cpath d=\"M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z\"\u003e\r\n          \u003c/path\u003e\r\n        \u003c/svg\u003e\r\n      \u003c/button\u003e\r\n    \u003c/div\u003e\r\n\r\n    \u003cdiv class=\"datacard-collapsible\"\u003e\r\n\r\n\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003ePrevious Results\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eMeasured Model Abilities\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat aspect of model ability can be measured with this dataset?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eConciseness, abstractiveness, and overall summarization capability.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eMetrics\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat metrics are typically used for this task?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ccode\u003eROUGE\u003c/code\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eProposed Evaluation\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eList and describe the purpose of the metrics and evaluation methodology (including human\r\n                    evaluation) that the dataset creators used when introducing this task.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eROUGE is the de facto evaluation metric used for text summarization. However, it was designed\r\n              specifically for evaluating English texts. Due to the nature of the metric, scores are heavily dependent\r\n              on text tokenization / stemming / unnecessary character removal, etc. Some modifications to the original\r\n              ROUGE evaluation were done such as punctuation only removal, language specific tokenization/stemming to\r\n              enable reliable comparison of source and target summaries across different scripts.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003ePrevious results available?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eAre previous results available?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eno\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n    \u003c/div\u003e\r\n  \u003c/section\u003e\r\n\r\n  \u003csection class=\"datacard-section open\"\u003e\r\n\r\n    \u003cdiv class=\"datacard-section-preview\"\u003e\r\n      \u003ch3\u003eDataset Curation\r\n\r\n        \u003cdiv class=\"tooltip\"\u003e\r\n          \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n          \u003cdiv class=\"tooltip-text\"\u003e\r\n            \u003cul\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eOriginal Curation\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eLanguage Data\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eStructured Annotations\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eConsent\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003ePrivate Identifying Information (PII)\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eMaintenance\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n            \u003c/ul\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/h3\u003e\r\n      \u003cbutton class=\"expand-button\"\u003e\r\n        \u003csvg fill=\"#3c4f50\" height=\"24px\" viewBox=\"0 0 24 24\" width=\"24px\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\r\n          \u003cpath d=\"M0 0h24v24H0z\" fill=\"none\"\u003e\u003c/path\u003e\r\n          \u003cpath d=\"M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z\"\u003e\r\n          \u003c/path\u003e\r\n        \u003c/svg\u003e\r\n      \u003c/button\u003e\r\n    \u003c/div\u003e\r\n\r\n    \u003cdiv class=\"datacard-collapsible\"\u003e\r\n\r\n\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eOriginal Curation\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eOriginal Curation Rationale\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eOriginal curation rationale\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eState-of-the-art text summarization models are heavily data-driven, i.e., a large number of\r\n              article-summary pairs are required to train them effectively. As a result, abstractive summarization has\r\n              centered around the English language, as most large abstractive summarization datasets are available in\r\n              English only. Though there have been some recent efforts for curating multilingual abstractive\r\n              summarization datasets, they are limited in terms of the number of languages covered, the number of\r\n              training samples, or both. To this end, we curate \u003cstrong\u003eXL-Sum\u003c/strong\u003e, a large-scale abstractive\r\n              summarization dataset of 1.35 million news articles from 45 languages crawled from the British\r\n              Broadcasting Corporation website.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eCommunicative Goal\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat was the communicative goal?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eIntroduce new languages in the english-centric domain of abstractive text summarization and enable both\r\n              multilingual and per-language summarization.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eSourced from Different Sources\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eIs the dataset aggregated from different data sources?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eyes\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eSource Details\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eList the sources (one per line)\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eBritish Broadcasting Corporation (BBC) news websites.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eLanguage Data\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eHow was Language Data Obtained?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eHow was the language data obtained?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ccode\u003eFound\u003c/code\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eWhere was it found?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eIf found, where from?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ccode\u003eMultiple websites\u003c/code\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eLanguage Producers\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat further information do we have on the language producers?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThe language content was written by professional news editors hired by BBC.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eTopics Covered\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDoes the language in the dataset focus on specific topics? How would you describe them?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eNews\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eData Validation\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWas the text validated by a different worker or a data curator?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003enot validated\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eData Preprocessing\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eHow was the text data pre-processed? (Enter N/A if the text was not pre-processed)\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eWe used 'NFKC' normalization on all text instances.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eWas Data Filtered?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWere text instances selected or filtered?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003ealgorithmically\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eFilter Criteria\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat were the selection criteria?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eWe designed a crawler to recursively crawl pages starting from the homepage by visiting different article\r\n              links present in each page visited. We were able to take advantage of the fact that all BBC sites have\r\n              somewhat similar structures, and were able to scrape articles from all sites. We discarded pages with no\r\n              textual contents (mostly pages consisting of multimedia contents) before further processing. We designed a\r\n              number of heuristics to make the extraction effective by carefully examining the HTML structures of the\r\n              crawled pages:\u003c/p\u003e\r\n            \u003col\u003e\r\n              \u003cli\u003eThe desired summary must be present within the beginning two paragraphs of an article.\u003c/li\u003e\r\n              \u003cli\u003eThe summary paragraph must have some portion of texts in bold format.\u003c/li\u003e\r\n              \u003cli\u003eThe summary paragraph may contain some hyperlinks that may not be bold. The proportion of bold texts\r\n                and hyperlinked texts to the total length of the paragraph in consideration must be at least 95%.\u003c/li\u003e\r\n              \u003cli\u003eAll texts except the summary and the headline must be included in the input text (including image\r\n                captions).\u003c/li\u003e\r\n              \u003cli\u003eThe input text must be at least twice as large as the summary.\u003c/li\u003e\r\n            \u003c/ol\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eStructured Annotations\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eAdditional Annotations?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDoes the dataset have additional annotations for each instance?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003enone\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eAnnotation Service?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWas an annotation service used?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eno\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eConsent\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eAny Consent Policy?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWas there a consent policy involved when gathering the data?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eyes\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eConsent Policy Details\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat was the consent policy?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eBBC's policy specifies that the text content within its websites can be used for non-commercial research\r\n              only.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003ePrivate Identifying Information (PII)\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eContains PII?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDoes the source language data likely contain Personal Identifying Information about the data\r\n                    creators or subjects?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003elikely\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eCategories of PII\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat categories of PII are present or suspected in the data?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ccode\u003egeneric PII\u003c/code\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eAny PII Identification?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDid the curators use any automatic/manual method to identify PII in the dataset?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eno identification\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eMaintenance\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eAny Maintenance Plan?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDoes the original dataset have a maintenance plan?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eno\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n    \u003c/div\u003e\r\n  \u003c/section\u003e\r\n\r\n  \u003csection class=\"datacard-section open\"\u003e\r\n\r\n    \u003cdiv class=\"datacard-section-preview\"\u003e\r\n      \u003ch3\u003eBroader Social Context\r\n\r\n        \u003cdiv class=\"tooltip\"\u003e\r\n          \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n          \u003cdiv class=\"tooltip-text\"\u003e\r\n            \u003cul\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003ePrevious Work on the Social Impact of the Dataset\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eImpact on Under-Served Communities\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eDiscussion of Biases\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n            \u003c/ul\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/h3\u003e\r\n      \u003cbutton class=\"expand-button\"\u003e\r\n        \u003csvg fill=\"#3c4f50\" height=\"24px\" viewBox=\"0 0 24 24\" width=\"24px\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\r\n          \u003cpath d=\"M0 0h24v24H0z\" fill=\"none\"\u003e\u003c/path\u003e\r\n          \u003cpath d=\"M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z\"\u003e\r\n          \u003c/path\u003e\r\n        \u003c/svg\u003e\r\n      \u003c/button\u003e\r\n    \u003c/div\u003e\r\n\r\n    \u003cdiv class=\"datacard-collapsible\"\u003e\r\n\r\n\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003ePrevious Work on the Social Impact of the Dataset\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eUsage of Models based on the Data\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eAre you aware of cases where models trained on the task featured in this dataset ore related tasks\r\n                    have been used in automated systems?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eno\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eImpact on Under-Served Communities\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eAddresses needs of underserved Communities?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDoes this dataset address the needs of communities that are traditionally underserved in language\r\n                    technology, and particularly language generation technology? Communities may be underserved for\r\n                    exemple because their language, language variety, or social or geographical context is\r\n                    underepresented in NLP and NLG resources (datasets and models).\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eyes\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eDetails on how Dataset Addresses the Needs\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDescribe how this dataset addresses the needs of underserved communities.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThis dataset introduces summarization corpus for many languages where there weren't any datasets like\r\n              this curated before.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eDiscussion of Biases\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eAny Documented Social Biases?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eAre there documented social biases in the dataset? Biases in this context are variations in the\r\n                    ways members of different social categories are represented that can have harmful downstream\r\n                    consequences for members of the more disadvantaged group.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eno\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eAre the Language Producers Representative of the Language?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDoes the distribution of language producers in the dataset accurately represent the full\r\n                    distribution of speakers of the language world-wide? If not, how does it differ?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eYes\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n    \u003c/div\u003e\r\n  \u003c/section\u003e\r\n\r\n  \u003csection class=\"datacard-section open\"\u003e\r\n\r\n    \u003cdiv class=\"datacard-section-preview\"\u003e\r\n      \u003ch3\u003eConsiderations for Using the Data\r\n\r\n        \u003cdiv class=\"tooltip\"\u003e\r\n          \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n          \u003cdiv class=\"tooltip-text\"\u003e\r\n            \u003cul\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003ePII Risks and Liability\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eLicenses\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eKnown Technical Limitations\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n            \u003c/ul\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/h3\u003e\r\n      \u003cbutton class=\"expand-button\"\u003e\r\n        \u003csvg fill=\"#3c4f50\" height=\"24px\" viewBox=\"0 0 24 24\" width=\"24px\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\r\n          \u003cpath d=\"M0 0h24v24H0z\" fill=\"none\"\u003e\u003c/path\u003e\r\n          \u003cpath d=\"M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z\"\u003e\r\n          \u003c/path\u003e\r\n        \u003c/svg\u003e\r\n      \u003c/button\u003e\r\n    \u003c/div\u003e\r\n\r\n    \u003cdiv class=\"datacard-collapsible\"\u003e\r\n\r\n\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003ePII Risks and Liability\u003c/h4\u003e\r\n\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eLicenses\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eCopyright Restrictions on the Dataset\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eBased on your answers in the Intended Use part of the Data Overview Section, which of the following\r\n                    best describe the copyright and licensing status of the dataset?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ccode\u003eresearch use only\u003c/code\u003e, \u003ccode\u003enon-commercial use only\u003c/code\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eCopyright Restrictions on the Language Data\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eBased on your answers in the Language part of the Data Curation Section, which of the following\r\n                    best describe the copyright and licensing status of the underlying language data?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ccode\u003eresearch use only\u003c/code\u003e, \u003ccode\u003enon-commercial use only\u003c/code\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eKnown Technical Limitations\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eTechnical Limitations\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDescribe any known technical limitations, such as spurrious correlations, train/test overlap,\r\n                    annotation biases, or mis-annotations, and cite the works that first identified these limitations\r\n                    when possible.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eHuman evaluation showed most languages had a high percentage of good summaries in the upper nineties,\r\n              almost none of the summaries contained any conflicting information, while about one-third on average had\r\n              information that was not directly inferrable from the source article. Since generally multiple articles\r\n              are written regarding an important event, there could be an overlap between the training and evaluation\r\n              data in terms on content.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eUnsuited Applications\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhen using a model trained on this dataset in a setting where users or the public may interact with\r\n                    its predictions, what are some pitfalls to look out for? In particular, describe some applications\r\n                    of the general task featured in this dataset that its curation or properties make it less suitable\r\n                    for.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThe dataset is limited to news domain only. Hence it wouldn't be advisable to use a model trained on this\r\n              dataset for summarizing texts from a different domain i.e. literature, scientific text etc. Another\r\n              pitfall could be hallucinations in the model generated summary.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eDiscouraged Use Cases\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat are some discouraged use cases of a model trained to maximize the proposed metrics on this\r\n                    dataset? In particular, think about settings where decisions made by a model that performs\r\n                    reasonably well on the metric my still have strong negative consequences for user or members of the\r\n                    public.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eROUGE evaluates the quality of the summary as a whole by considering up to 4-gram overlaps. Therefore, in\r\n              an article about India if the word \"India\" in the generated summary gets replaced by \"Pakistan\" due to\r\n              model hallucination, the overall score wouldn't be reduced significantly, but the entire meaning could get\r\n              changed.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n    \u003c/div\u003e\r\n  \u003c/section\u003e\r\n\u003c/div\u003e","title":"xlsum","type":"Summarization","languages":"Amharic, Arabic, Azerbaijani, Bengali, Bangla, Burmese, Chinese (family), English, French, Gujarati, Hausa, Hindi, Igbo, Indonesian, Japanese, Rundi, Korean, Kirghiz, Kyrgyz, Marathi, Nepali (individual language), Oromo, Pushto, Pashto, Persian, Ghanaian Pidgin English, Portuguese, Panjabi, Punjabi, Russian, Scottish Gaelic, Gaelic, Serbian, Romano-Serbian, Sinhala, Sinhalese, Somali, Spanish, Castilian, Swahili (individual language), Kiswahili, Tamil, Telugu, Thai, Tigrinya, Turkish, Ukrainian, Urdu, Uzbek, Vietnamese, Welsh, Yoruba","summary":"XLSum is a highly multilingual summarization dataset supporting 44 language. The data stems from BBC news articles."}},"__N_SSG":true},"page":"/data_cards/[id]","query":{"id":"xlsum"},"buildId":"456T-gjsiPfCS_Gwi0APa","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>