<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/favicon.ico"/><meta name="description" content="Benchmark natural language generation systems with GEM."/><meta property="og:image" content="https://og-image.now.sh/**GEM**%20Benchmark.png?theme=light&amp;md=1&amp;fontSize=100px&amp;images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fvercel-triangle-black.svg"/><meta name="og:title" content="GEM"/><meta name="twitter:card" content="summary_large_image"/><title>GEM <!-- -->totto</title><meta name="next-head-count" content="8"/><link rel="preload" href="/_next/static/css/42fe94e3e660903d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/42fe94e3e660903d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/93c336621cfc84eb.css" as="style"/><link rel="stylesheet" href="/_next/static/css/93c336621cfc84eb.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js"></script><script src="/_next/static/chunks/webpack-635a834dfd7d0dc2.js" defer=""></script><script src="/_next/static/chunks/framework-7a7e500878b44665.js" defer=""></script><script src="/_next/static/chunks/main-a56c17dda72126ba.js" defer=""></script><script src="/_next/static/chunks/pages/_app-da8862f0ec3a97c1.js" defer=""></script><script src="/_next/static/chunks/c16184b3-ddb1b99b5e568a2a.js" defer=""></script><script src="/_next/static/chunks/50-3dccc3616b494db8.js" defer=""></script><script src="/_next/static/chunks/pages/data_cards/%5Bid%5D-14d2b498c38b49da.js" defer=""></script><script src="/_next/static/456T-gjsiPfCS_Gwi0APa/_buildManifest.js" defer=""></script><script src="/_next/static/456T-gjsiPfCS_Gwi0APa/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="layout_background__oCFQX undefined"><header class="layout_header__SFlEE"><div class="navbar_navwrapper__RkXSe"><div class="navbar_gradbar__Vli6s"></div><nav class="navbar_navbar__vdWdK"><span class="utils_headingLg__RYtYb navbar_navbarlogo__u28NK"><a href="/">GEM BENCHMARK</a></span><div class="navbar_menutoggle__4Urrc" id="mobile-menu"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="bars" class="svg-inline--fa fa-bars navbar_bar__f8cyd" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg></div><ul><li class="navbar_navitem__15TsF navbar_pushright___9_8s"><a href="/resources">Resources</a></li><li class="navbar_navitem__15TsF"><a href="/data_cards">Data Cards</a></li><li class="navbar_navitem__15TsF"><a href="/model_cards">Model Cards</a></li><li class="navbar_navitem__15TsF"><a href="/tutorials">tutorials</a></li><li class="navbar_navitem__15TsF"><a href="/results">Results</a></li><li class="navbar_navitem__15TsF"><a href="/workshop">Workshop</a></li></ul></nav></div></header><div class="layout_container__FUycR layout_wideContainer__IUVFY"><main><article><a href="/data_cards"><a><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="arrow-left" class="svg-inline--fa fa-arrow-left utils_icon__AiQ5I" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path></svg></a></a><span class="utils_spacer__a__NY"></span><span class="utils_headingXl__zlq1q">totto</span><span class="utils_smallSpace__dcJPu"></span><span class="utils_lightText__B_gv3">Data-to-Text</span><div class="datacard-wrapper"><div class="datacard">
  <section class="datacard-section">
    <div class="datacard-summary">
      <h2>totto</h2>
      <div class="summary-content">
        <p>ToTTo is a high-quality English table-to-text dataset with more than 100,000 examples in which a table from
          Wikipedia with highlighted cells is paired with a sentence that describes the highlighted cells. All examples
          in the dataset were post-edited in multiple steps to ensure that the targets are fully faithful to the input
          information.</p>
        <p>You can load the dataset via:</p>

        <div class="code-wrapper">
          <div class="toolbar">
            <div class="copy-icon" title="Click to copy code block"></div>
            <div class="expand-modal-icon" title="Click to expand code block"></div>
          </div>
          <pre><code>import datasets
data = datasets.load_dataset('GEM/totto')
</code></pre>
        </div>

        <p>The data loader can be found <a href="https://huggingface.co/datasets/GEM/totto">here</a>.</p>
      </div>
    </div>

    <div class="datacard-field-wrapper">

      <div class="datacard-field">

        <h5>website

        </h5>

        <p>n/a</p>
      </div>

      <div class="datacard-field">

        <h5>paper

        </h5>

        <p><a href="https://aclanthology.org/2020.emnlp-main.89">ACL Anthology</a></p>
      </div>

      <div class="datacard-field">

        <h5>authors

        </h5>

        <p>Ankur Parikh, Xuezhi Wang, Sebastian Gehrmann, Manaal Faruqui, Bhuwan Dhingra, Diyi Yang, Dipanjan Das</p>
      </div>
    </div>

  </section>

  <section class="datacard-section quick">
    <h3 class="section-title">Quick-Use</h3>

    <div class="datacard-field-wrapper">

      <div class="datacard-field periscope">

        <h5>Contact Name

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>If known, provide the name of at least one person the reader can contact for questions about the
                dataset.</p>
            </div>
          </div>

        </h5>

        <p>Ankur Parikh</p>
      </div>

      <div class="datacard-field telescope">

        <h5>Multilingual?

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>Is the dataset multilingual?</p>
            </div>
          </div>

        </h5>

        <p>no</p>
      </div>

      <div class="datacard-field telescope">

        <h5>Covered Languages

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>What languages/dialects are covered in the dataset?</p>
            </div>
          </div>

        </h5>

        <p><code>English</code></p>
      </div>

      <div class="datacard-field telescope">

        <h5>License

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>What is the license of the dataset?</p>
            </div>
          </div>

        </h5>

        <p>cc-by-sa-3.0: Creative Commons Attribution Share Alike 3.0 Unported</p>
      </div>

      <div class="datacard-field periscope">

        <h5>Communicative Goal

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>Provide a short description of the communicative goal of a model trained for this task on this dataset.
              </p>
            </div>
          </div>

        </h5>

        <p>The speaker is required to produce a single, coherent English sentence that describes the highlighted cells
          in the given table, also using metadata and any other information from the table as applicable.</p>
      </div>

      <div class="datacard-field telescope">

        <h5>Additional Annotations?

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>Does the dataset have additional annotations for each instance?</p>
            </div>
          </div>

        </h5>

        <p>none</p>
      </div>

      <div class="datacard-field telescope">

        <h5>Contains PII?

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>Does the source language data likely contain Personal Identifying Information about the data creators
                or subjects?</p>
            </div>
          </div>

        </h5>

        <p>no PII</p>
      </div>
    </div>

  </section>


  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Dataset Overview

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Where to find the Data and its Documentation</h4>
              </li>
              <li>
                <h4>Languages and Intended Use</h4>
              </li>
              <li>
                <h4>Credit</h4>
              </li>
              <li>
                <h4>Dataset Structure</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Where to find the Data and its Documentation</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Download

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the link to where the original dataset is hosted?</p>
                </div>
              </div>

            </h5>

            <p><a href="https://github.com/google-research-datasets/totto">ToTTo Main Repo</a> + <a
                href="https://github.com/google-research/language/tree/master/language/totto">ToTTo Supplementary
                Repo</a></p>
          </div>

          <div class="datacard-field telescope">

            <h5>Paper

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the link to the paper describing the dataset (open access preferred)?</p>
                </div>
              </div>

            </h5>

            <p><a href="https://aclanthology.org/2020.emnlp-main.89">ACL Anthology</a></p>
          </div>

          <div class="datacard-field microscope">

            <h5>BibTex

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Provide the BibTex-formatted reference for the dataset. Please use the correct published version
                    (ACL anthology, etc.) instead of google scholar created Bibtex.</p>
                </div>
              </div>

            </h5>


            <div class="code-wrapper">
              <div class="toolbar">
                <div class="copy-icon" title="Click to copy code block"></div>
                <div class="expand-modal-icon" title="Click to expand code block"></div>
              </div>
              <pre><code>@inproceedings{parikh-etal-2020-totto,
title = "{ToTTo}: A Controlled Table-To-Text Generation Dataset",
author = "Parikh, Ankur  and
Wang, Xuezhi  and
Gehrmann, Sebastian  and
Faruqui, Manaal  and
Dhingra, Bhuwan  and
Yang, Diyi  and
Das, Dipanjan",
booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
month = nov,
year = "2020",
address = "Online",
publisher = "Association for Computational Linguistics",
url = "https://aclanthology.org/2020.emnlp-main.89",
doi = "10.18653/v1/2020.emnlp-main.89",
pages = "1173--1186",
abstract = "We present ToTTo, an open-domain English table-to-text dataset with over 120,000 training examples that proposes a controlled generation task: given a Wikipedia table and a set of highlighted table cells, produce a one-sentence description. To obtain generated targets that are natural but also faithful to the source table, we introduce a dataset construction process where annotators directly revise existing candidate sentences from Wikipedia. We present systematic analyses of our dataset and annotation process as well as results achieved by several state-of-the-art baselines. While usually fluent, existing methods often hallucinate phrases that are not supported by the table, suggesting that this dataset can serve as a useful research benchmark for high-precision conditional text generation.",
}
</code></pre>
            </div>

          </div>

          <div class="datacard-field periscope">

            <h5>Contact Name

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>If known, provide the name of at least one person the reader can contact for questions about the
                    dataset.</p>
                </div>
              </div>

            </h5>

            <p>Ankur Parikh</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Contact Email

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>If known, provide the email of at least one person the reader can contact for questions about the
                    dataset.</p>
                </div>
              </div>

            </h5>

            <p><a href="mailto:totto@google.com">totto@google.com</a></p>
          </div>

          <div class="datacard-field telescope">

            <h5>Has a Leaderboard?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the dataset have an active leaderboard?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Leaderboard Link

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Provide a link to the leaderboard.</p>
                </div>
              </div>

            </h5>

            <p><a href="https://github.com/google-research-datasets/totto">Github</a></p>
          </div>

          <div class="datacard-field microscope">

            <h5>Leaderboard Details

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Briefly describe how the leaderboard evaluates models.</p>
                </div>
              </div>

            </h5>

            <p>This dataset has an associated, active <a
                href="https://github.com/google-research-datasets/totto#leaderboard">leaderboard</a> maintained by the
              authors.
              The test set ground truth targets / references are private, i.e they are not publicly shared or
              downloadable - hence, leaderboard submission is necessary for test set evaluation.
              To evaluate your model on the dev or test set AND/OR submit to the leaderboard, you need to submit your
              model files through this <a href="https://forms.gle/AcF9TRqWrPhPzztt7">form</a> (The form provides an
              option to opt-out of going on the leaderboard).</p>
            <p>The leaderboard reports three sets of BLEU, PARENT and BLEURT scores for each submission - on the overall
              test set, the <em>Overlap</em> subset of the test set and the <em>non-Overlap</em> subset of the test set.
            </p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Languages and Intended Use</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Multilingual?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Is the dataset multilingual?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Covered Dialects

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What dialects are covered? Are there multiple dialects per language?</p>
                </div>
              </div>

            </h5>

            <p>No specific dialects. The original language is from Wikipedia and it was post-edited by crowdraters</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Covered Languages

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What languages/dialects are covered in the dataset?</p>
                </div>
              </div>

            </h5>

            <p><code>English</code></p>
          </div>

          <div class="datacard-field periscope">

            <h5>Whose Language?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Whose language is in the dataset?</p>
                </div>
              </div>

            </h5>

            <p>The language is post-edited English only (BCP-47: <code>en</code>) Wikipedia text. No demographic
              information about annotators is provided.
              Some amounts of what may be called non-English text, including characters such as French accents or
              Cyrillic characters, could sometimes occur, especially through fields with entity names as values in the
              input table cells.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>License

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the license of the dataset?</p>
                </div>
              </div>

            </h5>

            <p>cc-by-sa-3.0: Creative Commons Attribution Share Alike 3.0 Unported</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Intended Use

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the intended use of the dataset?</p>
                </div>
              </div>

            </h5>

            <p>ToTTo is a Table-to-Text NLG task, as the paper title says. The task is as follows: Given a Wikipedia
              table with row names, column names and table cells, with a subset of cells highlighted, generate a natural
              language description for the highlighted part of the table . The table need not be exactly rectangular in
              that - cells can sometimes be multi-row or multi-column.</p>
            <p>An earlier example of a Table-to-Text NLG task is <a href="https://arxiv.org/abs/1603.07771">Wikibio</a>
              - here the inputs were Wikipedia infoboxes (from the top right corner of entity-related Wiki pages). In
              contrast, ToTTo mostly has Wikipedia tables from the main article content itself. In general,
              Table-To-Text NLG tasks can be seen as a subclass of Data-To-Text NLG tasks - where the task is to
              generate natural language descriptions of inputs which are in the form of structured or semi-structured
              data. In general, all Data-To-Text NLG tasks need not have an explicit table or other structure - e.g the
              input in <a href="https://www.aclweb.org/anthology/W16-6626.pdf">WebNLG</a> is simply a list of triples.
            </p>
            <p>Importantly, ToTTo differs from earlier examples of Table-To-Text NLG in that:</p>
            <ol>
              <li>
                <p>It does not suffer from the problem of divergent references - where ground truth descriptions
                  themselves have additional information not found in the table. ToTTo overcomes this by having a
                  multi-step annotation process to edit the initial, free-form table descriptions (which are from
                  Wikipedia) to make them faithful, unambiguous and independent of article context.</p>
              </li>
              <li>
                <p>Since it provides <strong>control</strong> in the form of highlighted table cells, it prevents the
                  problem of there being a large number of valid descriptions focussing on different parts of the table.
                </p>
              </li>
            </ol>
          </div>

          <div class="datacard-field telescope">

            <h5>Primary Task

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What primary task does the dataset support?</p>
                </div>
              </div>

            </h5>

            <p>Data-to-Text</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Communicative Goal

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Provide a short description of the communicative goal of a model trained for this task on this
                    dataset.</p>
                </div>
              </div>

            </h5>

            <p>The speaker is required to produce a single, coherent English sentence that describes the highlighted
              cells in the given table, also using metadata and any other information from the table as applicable.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Credit</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Curation Organization Type(s)

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>In what kind of organization did the dataset curation happen?</p>
                </div>
              </div>

            </h5>

            <p><code>industry</code></p>
          </div>

          <div class="datacard-field periscope">

            <h5>Curation Organization(s)

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Name the organization(s).</p>
                </div>
              </div>

            </h5>

            <p>Google Research</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Dataset Creators

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Who created the original dataset? List the people involved in collecting the dataset and their
                    affiliation(s).</p>
                </div>
              </div>

            </h5>

            <p>Ankur Parikh, Xuezhi Wang, Sebastian Gehrmann, Manaal Faruqui, Bhuwan Dhingra, Diyi Yang, Dipanjan Das
            </p>
          </div>

          <div class="datacard-field microscope">

            <h5>Funding

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Who funded the data creation?</p>
                </div>
              </div>

            </h5>

            <p>Google Research</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Who added the Dataset to GEM?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Who contributed to the data card and adding the dataset to GEM? List the people+affiliations
                    involved in creating this data card and who helped integrate this dataset into GEM.</p>
                </div>
              </div>

            </h5>

            <p>Varun Gangal created the initial data card and Yacine Jernite wrote the data loader. The data card was
              updated with new splits by Simon Mille. Sebastian Gehrmann ported the data card and loader from the v1 to
              the v2 version and extended it with the new fields.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Dataset Structure</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Data Fields

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>List and describe the fields present in the dataset.</p>
                </div>
              </div>

            </h5>

            <ul>
              <li>The <code>table</code> field is a <code>List[List[Dict]]</code> in row-major order, with outer lists
                representing rows and the inner lists columns.</li>
              <li>Each <code>Dict</code> has the fields <code>column_span: int</code>, <code>is_header: bool</code>,
                <code>row_span: int</code>, and <code>value: str</code>.</li>
              <li>Table metadata consists of <code>table_page_title</code>, <code>table_section_title</code> and
                <code>table_section_texts</code></li>
              <li>The <code>highlighted_cells</code> are represented as <code>List[[row_index,column_index]]</code>,
                with each <code>[row_index,column_index]</code> indicating that
                <code>table[row_index][column_index]</code> is highlighted.</li>
              <li><code>example_id</code> is the unique id per example.</li>
              <li><code>sentence_annotations[final_sentence]</code> which is the table description/generation target
              </li>
            </ul>
          </div>

          <div class="datacard-field microscope">

            <h5>Reason for Structure

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>How was the dataset structure determined?</p>
                </div>
              </div>

            </h5>

            <p>The structure is aimed to encode highlighted tables in a way that allows rows and columns to span
              multiple fields in width. The other fields are meta-data about the source and the annotations</p>
          </div>

          <div class="datacard-field microscope">

            <h5>How were labels chosen?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>How were the labels chosen?</p>
                </div>
              </div>

            </h5>

            <p>The initial table-description pairs are tables from Wikipedia articles, extracted through heuristics such
              as Number Matching (tables and sentences that overlap with a non-date number of atleast 3 non-zero digits)
              (Refer to Section 4 of the paper for more)</p>
            <ol>
              <li>Table Readability: Tables which are deemed non-readable (due to foreign language, poor formatting etc
                - a very small fraction of 0.5%) are removed from the dataset here.</li>
              <li>Cell Highlighting: The annotator highlights the cells of the table which support the description.</li>
              <li>Deletion: The annotator removes phrases in the description which are not supported by the highlighted
                cells</li>
              <li>Decontextualization: Descriptions may contain pronouns or other forms of anaphora, or other phenomena
                which depend on the overall article topic - these are fixed by replacement (e.g replacing pronouns with
                the entity, provided it occurs in the table). The replacements allowed are limited to one, and
                annotators are also instructed to conserve fluency.</li>
              <li>Secondary Annotation: A second set of annotators is shown the output of Stage 4, and asked to fix it
                if required to ensure it is grammatical.</li>
            </ol>
          </div>

          <div class="datacard-field periscope">

            <h5>Example Instance

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Provide a JSON formatted example of a typical instance in the dataset.</p>
                </div>
              </div>

            </h5>

            <p>The main repository's <code>README.md</code> already provides a thorough walkthrough of data instances
              and fields <a href="https://github.com/google-research-datasets/totto#dataset-description">here</a></p>
            <p>Below is the instance for a table from the wiki-page for the musical artist <em>Weird Al' Yankovic</em> ,
              likely listing his on-television appearances.</p>

            <div class="code-wrapper">
              <div class="toolbar">
                <div class="copy-icon" title="Click to copy code block"></div>
                <div class="expand-modal-icon" title="Click to expand code block"></div>
              </div>
              <pre><code>    {
"table_page_title": "'Weird Al' Yankovic",
"table_webpage_url": "https://en.wikipedia.org/wiki/%22Weird_Al%22_Yankovic",
"table_section_title": "Television",
"table_section_text": "",
"table": "[Described below]",
"highlighted_cells": [[22, 2], [22, 3], [22, 0], [22, 1], [23, 3], [23, 1], [23, 0]],
"example_id": 12345678912345678912,
"sentence_annotations": [{"original_sentence": "In 2016, Al appeared in 2 episodes of BoJack Horseman as Mr. Peanutbutter's brother, Captain Peanutbutter, and was hired to voice the lead role in the 2016 Disney XD series Milo Murphy's Law.",
    "sentence_after_deletion": "In 2016, Al appeared in 2 episodes of BoJack Horseman as Captain Peanutbutter, and was hired to the lead role in the 2016 series Milo Murphy's Law.",
    "sentence_after_ambiguity": "In 2016, Al appeared in 2 episodes of BoJack Horseman as Captain Peanutbutter, and was hired for the lead role in the 2016 series Milo Murphy's 'Law.",
    "final_sentence": "In 2016, Al appeared in 2 episodes of BoJack Horseman as Captain Peanutbutter and was hired for the lead role in the 2016 series Milo Murphy's Law."}],
}
</code></pre>
            </div>

            <p>The <code>table</code> field is expanded as below:</p>

            <div class="code-wrapper">
              <div class="toolbar">
                <div class="copy-icon" title="Click to copy code block"></div>
                <div class="expand-modal-icon" title="Click to expand code block"></div>
              </div>
              <pre><code>    [
[
  {
      "column_span": 1,
       "is_header": true,
       "row_span": 1,
       "value": "Year"},
  {    "column_span": 1,
       "is_header": true,
       "row_span": 1,
       "value": "Title"},
  {    "column_span": 1,
       "is_header": true,
       "row_span": 1,
       "value": "Role"},
  {    "column_span": 1,
       "is_header": true,
       "row_span": 1,
       "value": "Notes"}
],
[
  {    "column_span": 1,
       "is_header": false,
       "row_span": 1,
       "value": "1997"},
  {    "column_span": 1,
       "is_header": false,
       "row_span": 1,
       "value": "Eek! The Cat"},
  {    "column_span": 1,
       "is_header": false,
       "row_span": 1,
       "value": "Himself"},
  {    "column_span": 1,
       "is_header": false,
       "row_span": 1,
       "value": "Episode: 'The FugEektive'"}
], ...
]
</code></pre>
            </div>

            <p>The <a href="https://github.com/google-research/language/tree/master/language/totto">Supplementary
                Repo</a> also provides browsable samples under its <code>sample/</code> folder. It additionally provides
              HTML visualization scripts with their outputs located under the aforementioned folder. The instructions to
              access and visualize these samples can also be found <a
                href="https://github.com/google-research/language/tree/master/language/totto#visualizing-sample-data">here</a>.
            </p>
          </div>

          <div class="datacard-field periscope">

            <h5>Data Splits

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Describe and name the splits in the dataset if there are more than one.</p>
                </div>
              </div>

            </h5>

            <p>The dataset consists of 120,000 train examples and equi-sized dev and test sets with 7700 examples.
              Refer to Table 5 in the paper for a more extensive list of properties about table size, target vocabulary
              etc and their aggregates.</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Splitting Criteria

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Describe any criteria for splitting the data, if used. If there are differences between the splits
                    (e.g., if the training annotations are machine-generated and the dev and test ones are created by
                    humans, or if different numbers of annotators contributed to each example), describe them here.</p>
                </div>
              </div>

            </h5>

            <p>The dev and test splits are further equally distributed between <em>Overlap</em> and <em>non-Overlap</em>
              .
              The examples in the <em>Overlap</em> set are harder on account of the domain shift resulting from them
              having none of their header (row and column) names in common with those seen during training.</p>
            <p>Refer to Table 5 in the paper for a more extensive list of properties about table size, target vocabulary
              etc and their aggregates.</p>
          </div>

          <div class="datacard-field microscope">

            <h5>

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What does an outlier of the dataset in terms of length/perplexity/embedding look like?</p>
                </div>
              </div>

            </h5>

            <p>There are some very large tables in the dataset with thousands of rows. Table 7 shows some of the
              challenges of the dataset, showing that very few examples require access to the table description itself
              which makes those examples an outlier.</p>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Dataset in GEM

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Rationale for Inclusion in GEM</h4>
              </li>
              <li>
                <h4>GEM-Specific Curation</h4>
              </li>
              <li>
                <h4>Getting Started with the Task</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Rationale for Inclusion in GEM</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field microscope">

            <h5>Why is the Dataset in GEM?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What does this dataset contribute toward better generation evaluation and why is it part of GEM?
                  </p>
                </div>
              </div>

            </h5>

            <p>ToTTo is one of the two datasets representing Table-to-Text NLG in GEM, the other one being <a
                href="https://arxiv.org/pdf/2007.02871.pdf">DART</a>. Unlike DART, which combines datasets from multiple
              sources and furnishes them in a unified setting, ToTTo is from a homogeneous source. As explained in the
              Task Summary above, it also has an annotation process explicitly crafted to reduce divergent descriptions,
              which is not true of DART.</p>
            <p>Furthermore, ToTTo is also an instance of a <strong>controlled</strong> generation task - where in
              addition to the input (in this case the table) an additional <strong>control</strong> (in this case the
              highlighted cells) is given as an additional goal for the generation. The DART task formulation does not
              include controls.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Similar Datasets

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Do other datasets for the high level task exist?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Unique Language Coverage

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does this dataset cover other languages than other datasets for the same task?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Difference from other GEM datasets

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What else sets this dataset apart from other similar datasets in GEM?</p>
                </div>
              </div>

            </h5>

            <p>The input is much more complex and the quality much better than that of comparable datasets. The
              highlighted table cells provide a unique challenge to models.</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Ability that the Dataset measures

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What aspect of model ability can be measured with this dataset?</p>
                </div>
              </div>

            </h5>

            <p>Reasoning, surface realization</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>GEM-Specific Curation</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Modificatied for GEM?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Has the GEM version of the dataset been modified in any way (data, processing, splits) from the
                    original curated data?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Additional Splits?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does GEM provide additional splits to the dataset?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Split Information

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Describe how the new splits were created</p>
                </div>
              </div>

            </h5>

            <p>9 challenge sets for ToTTo were added to the GEM evaluation suite, 8 created specifically for the task
              and 1 coming from the original data.</p>
            <ol>
              <li>We created subsets of the training and development sets of 500 randomly selected inputs each.</li>
              <li>We applied input scrambling on a subset of 500 randomly selected test instances; the order of the
                highlighted cells was randomly reassigned.</li>
              <li>For the input size, we created subpopulations based on the number of input highlighted cells in the
                whole table.</li>
            </ol>

            <div class="table-wrapper">
              <div class="toolbar">
                <div class="expand-modal-icon" title="Click to expand table"></div>
              </div>
              <table>
                <thead>
                  <tr>
                    <th>Input length</th>
                    <th>Frequency English</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>1</td>
                    <td>898</td>
                  </tr>
                  <tr>
                    <td>2</td>
                    <td>1850</td>
                  </tr>
                  <tr>
                    <td>3</td>
                    <td>2221</td>
                  </tr>
                  <tr>
                    <td>4</td>
                    <td>1369</td>
                  </tr>
                  <tr>
                    <td>5</td>
                    <td>483</td>
                  </tr>
                  <tr>
                    <td>6</td>
                    <td>379</td>
                  </tr>
                  <tr>
                    <td>7</td>
                    <td>124</td>
                  </tr>
                  <tr>
                    <td>8</td>
                    <td>128</td>
                  </tr>
                  <tr>
                    <td>9</td>
                    <td>61</td>
                  </tr>
                  <tr>
                    <td>10</td>
                    <td>40</td>
                  </tr>
                  <tr>
                    <td>11</td>
                    <td>20</td>
                  </tr>
                  <tr>
                    <td>12</td>
                    <td>26</td>
                  </tr>
                  <tr>
                    <td>13</td>
                    <td>10</td>
                  </tr>
                  <tr>
                    <td>14</td>
                    <td>14</td>
                  </tr>
                  <tr>
                    <td>15</td>
                    <td>14</td>
                  </tr>
                  <tr>
                    <td>16</td>
                    <td>7</td>
                  </tr>
                  <tr>
                    <td>17</td>
                    <td>6</td>
                  </tr>
                  <tr>
                    <td>18</td>
                    <td>5</td>
                  </tr>
                  <tr>
                    <td>19</td>
                    <td>5</td>
                  </tr>
                  <tr>
                    <td>20</td>
                    <td>5</td>
                  </tr>
                  <tr>
                    <td>21</td>
                    <td>4</td>
                  </tr>
                  <tr>
                    <td>22</td>
                    <td>1</td>
                  </tr>
                  <tr>
                    <td>23</td>
                    <td>2</td>
                  </tr>
                  <tr>
                    <td>24</td>
                    <td>4</td>
                  </tr>
                  <tr>
                    <td>25</td>
                    <td>1</td>
                  </tr>
                  <tr>
                    <td>26...496</td>
                    <td>1</td>
                  </tr>
                </tbody>
              </table>
            </div>

            <ol start="4">
              <li>We also divided the test set according to the size of the whole table, based on the idea that larger
                tables represent a bigger space to take into account when generating the highlighted cells; a larger
                table could be more challenging to generate accurate text than a smaller table. There are 693 different
                table sizes, ranging from 2 to 15834 cells.</li>
            </ol>

            <div class="table-wrapper">
              <div class="toolbar">
                <div class="expand-modal-icon" title="Click to expand table"></div>
              </div>
              <table>
                <thead>
                  <tr>
                    <th>Table size</th>
                    <th>Frequency English</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>2</td>
                    <td>71</td>
                  </tr>
                  <tr>
                    <td>3</td>
                    <td>52</td>
                  </tr>
                  <tr>
                    <td>4</td>
                    <td>36</td>
                  </tr>
                  <tr>
                    <td>5</td>
                    <td>41</td>
                  </tr>
                  <tr>
                    <td>6</td>
                    <td>144</td>
                  </tr>
                  <tr>
                    <td>7</td>
                    <td>47</td>
                  </tr>
                  <tr>
                    <td>8</td>
                    <td>59</td>
                  </tr>
                  <tr>
                    <td>9</td>
                    <td>105</td>
                  </tr>
                  <tr>
                    <td>10</td>
                    <td>162</td>
                  </tr>
                  <tr>
                    <td>11</td>
                    <td>36</td>
                  </tr>
                  <tr>
                    <td>12</td>
                    <td>158</td>
                  </tr>
                  <tr>
                    <td>13</td>
                    <td>35</td>
                  </tr>
                  <tr>
                    <td>14</td>
                    <td>79</td>
                  </tr>
                  <tr>
                    <td>15</td>
                    <td>136</td>
                  </tr>
                  <tr>
                    <td>16</td>
                    <td>111</td>
                  </tr>
                  <tr>
                    <td>17</td>
                    <td>48</td>
                  </tr>
                  <tr>
                    <td>18</td>
                    <td>123</td>
                  </tr>
                  <tr>
                    <td>19</td>
                    <td>29</td>
                  </tr>
                  <tr>
                    <td>20</td>
                    <td>112</td>
                  </tr>
                  <tr>
                    <td>21</td>
                    <td>91</td>
                  </tr>
                  <tr>
                    <td>22</td>
                    <td>17</td>
                  </tr>
                  <tr>
                    <td>23</td>
                    <td>7</td>
                  </tr>
                  <tr>
                    <td>24</td>
                    <td>169</td>
                  </tr>
                  <tr>
                    <td>25</td>
                    <td>56</td>
                  </tr>
                  <tr>
                    <td>26</td>
                    <td>12</td>
                  </tr>
                  <tr>
                    <td>27</td>
                    <td>40</td>
                  </tr>
                  <tr>
                    <td>28</td>
                    <td>77</td>
                  </tr>
                  <tr>
                    <td>29</td>
                    <td>7</td>
                  </tr>
                  <tr>
                    <td>30</td>
                    <td>122</td>
                  </tr>
                  <tr>
                    <td>31</td>
                    <td>4</td>
                  </tr>
                  <tr>
                    <td>32</td>
                    <td>49</td>
                  </tr>
                  <tr>
                    <td>33</td>
                    <td>21</td>
                  </tr>
                  <tr>
                    <td>34</td>
                    <td>7</td>
                  </tr>
                  <tr>
                    <td>35</td>
                    <td>103</td>
                  </tr>
                  <tr>
                    <td>36</td>
                    <td>131</td>
                  </tr>
                  <tr>
                    <td>37</td>
                    <td>10</td>
                  </tr>
                  <tr>
                    <td>38</td>
                    <td>6</td>
                  </tr>
                  <tr>
                    <td>39</td>
                    <td>26</td>
                  </tr>
                  <tr>
                    <td>40</td>
                    <td>110</td>
                  </tr>
                  <tr>
                    <td>41</td>
                    <td>1</td>
                  </tr>
                  <tr>
                    <td>42</td>
                    <td>54</td>
                  </tr>
                  <tr>
                    <td>43</td>
                    <td>6</td>
                  </tr>
                  <tr>
                    <td>44</td>
                    <td>47</td>
                  </tr>
                  <tr>
                    <td>45</td>
                    <td>79</td>
                  </tr>
                  <tr>
                    <td>46</td>
                    <td>4</td>
                  </tr>
                  <tr>
                    <td>47</td>
                    <td>2</td>
                  </tr>
                  <tr>
                    <td>48</td>
                    <td>114</td>
                  </tr>
                  <tr>
                    <td>49</td>
                    <td>18</td>
                  </tr>
                  <tr>
                    <td>50</td>
                    <td>55</td>
                  </tr>
                  <tr>
                    <td>51</td>
                    <td>11</td>
                  </tr>
                  <tr>
                    <td>52</td>
                    <td>43</td>
                  </tr>
                  <tr>
                    <td>54</td>
                    <td>80</td>
                  </tr>
                  <tr>
                    <td>55</td>
                    <td>73</td>
                  </tr>
                  <tr>
                    <td>56</td>
                    <td>64</td>
                  </tr>
                  <tr>
                    <td>57</td>
                    <td>12</td>
                  </tr>
                  <tr>
                    <td>58</td>
                    <td>1</td>
                  </tr>
                  <tr>
                    <td>60</td>
                    <td>114</td>
                  </tr>
                  <tr>
                    <td>61</td>
                    <td>4</td>
                  </tr>
                  <tr>
                    <td>63</td>
                    <td>39</td>
                  </tr>
                  <tr>
                    <td>64</td>
                    <td>36</td>
                  </tr>
                  <tr>
                    <td>65</td>
                    <td>62</td>
                  </tr>
                  <tr>
                    <td>66</td>
                    <td>48</td>
                  </tr>
                  <tr>
                    <td>67</td>
                    <td>1</td>
                  </tr>
                  <tr>
                    <td>68</td>
                    <td>36</td>
                  </tr>
                  <tr>
                    <td>69</td>
                    <td>6</td>
                  </tr>
                  <tr>
                    <td>70</td>
                    <td>81</td>
                  </tr>
                  <tr>
                    <td>72</td>
                    <td>76</td>
                  </tr>
                  <tr>
                    <td>73</td>
                    <td>1</td>
                  </tr>
                  <tr>
                    <td>74</td>
                    <td>1</td>
                  </tr>
                  <tr>
                    <td>75</td>
                    <td>44</td>
                  </tr>
                  <tr>
                    <td>76</td>
                    <td>33</td>
                  </tr>
                  <tr>
                    <td>77</td>
                    <td>30</td>
                  </tr>
                  <tr>
                    <td>78</td>
                    <td>66</td>
                  </tr>
                  <tr>
                    <td>79</td>
                    <td>1</td>
                  </tr>
                  <tr>
                    <td>80</td>
                    <td>83</td>
                  </tr>
                  <tr>
                    <td>81</td>
                    <td>12</td>
                  </tr>
                  <tr>
                    <td>82</td>
                    <td>1</td>
                  </tr>
                  <tr>
                    <td>84</td>
                    <td>80</td>
                  </tr>
                  <tr>
                    <td>85</td>
                    <td>25</td>
                  </tr>
                  <tr>
                    <td>86</td>
                    <td>1</td>
                  </tr>
                  <tr>
                    <td>87</td>
                    <td>3</td>
                  </tr>
                  <tr>
                    <td>88</td>
                    <td>35</td>
                  </tr>
                  <tr>
                    <td>90</td>
                    <td>78</td>
                  </tr>
                  <tr>
                    <td>91</td>
                    <td>18</td>
                  </tr>
                  <tr>
                    <td>92</td>
                    <td>22</td>
                  </tr>
                  <tr>
                    <td>93</td>
                    <td>5</td>
                  </tr>
                  <tr>
                    <td>94</td>
                    <td>2</td>
                  </tr>
                  <tr>
                    <td>95</td>
                    <td>31</td>
                  </tr>
                  <tr>
                    <td>96</td>
                    <td>50</td>
                  </tr>
                  <tr>
                    <td>98</td>
                    <td>11</td>
                  </tr>
                  <tr>
                    <td>99</td>
                    <td>14</td>
                  </tr>
                  <tr>
                    <td>100</td>
                    <td>48</td>
                  </tr>
                  <tr>
                    <td>102</td>
                    <td>24</td>
                  </tr>
                  <tr>
                    <td>104</td>
                    <td>29</td>
                  </tr>
                  <tr>
                    <td>105</td>
                    <td>36</td>
                  </tr>
                  <tr>
                    <td>106</td>
                    <td>2</td>
                  </tr>
                  <tr>
                    <td>108</td>
                    <td>51</td>
                  </tr>
                  <tr>
                    <td>110</td>
                    <td>31</td>
                  </tr>
                  <tr>
                    <td>...8000+</td>
                    <td>(up to 10)</td>
                  </tr>
                </tbody>
              </table>
            </div>

            <ol start="5">
              <li>We also created three splits based on the subset of test examples in pages about people.
                We then used the structured information in WikiData to identify the following information:</li>
            </ol>
            <ul>
              <li>gender (male, and female),</li>
              <li>nationality grouped by continent (Africa, Asia, Europe, North America, Oceania, and South America)
              </li>
              <li>ethnicity (African American and all USA)</li>
            </ul>
            <p>The categories within gender, ethnicity, and nationality were chosen based on data availability; The
              ToTTo dataset includes mostly tables that do not focus on people. As a result, only seven people in the
              original test set are marked as having a non-binary gender. Similar sparsity informed the grouping of
              nationalities by continent  only 19 countries are represented by more than 10 people in the test set. In
              case a person has citizenships across multiple continents, we may include the person in any of the
              included continents.</p>
            <p>Finally, ethnicity is very sparsely annotated in WikiData; only 150 test examples in ToTTo have this
              information and 128 of these are African Americans. We thus are unable to compare the performance on,
              e.g., Yoruba or Punjabi people, both of which have fewer than five instances. Another caveat here is that
              only 21 of the 128 people are female. We thus compare the African American population to results on a
              subset that includes all US citizens.</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Split Motivation

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What aspects of the model's generation capacities were the splits created to test?</p>
                </div>
              </div>

            </h5>

            <p>generalization, fairness, robustness</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Getting Started with the Task</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field microscope">

            <h5>Pointers to Resources

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Getting started with in-depth research on the task. Add relevant pointers to resources that
                    researchers can consult when they want to get started digging deeper into the task.</p>
                </div>
              </div>

            </h5>

            <ul>
              <li>
                <p>The highest spot on the leaderboard is currently held by an anonymous method, with BLEU=49.2,
                  PARENT=58.7 and BLEURT=0.249 on the <em>Overall</em> test set.</p>
              </li>
              <li>
                <p>The <strong>highest scoring non-anonymous</strong> method is the T5-based method of <a
                    href="https://arxiv.org/abs/2005.10433">Kale, 2020</a>. This method uses a simple row-major
                  linearization scheme to convert the table (it chooses only the highlighted cells and ignores the other
                  cells - table titles and section titles are prefixed at the start of the respective section table) to
                  a flat string. The linearized input - output description pairs from training examples are then used to
                  finetune T5, with BLEU being used as the dev metric to pick checkpoints, and beam search with beam
                  size 10 being the decoding method.</p>
                <p>Though the best numbers from this method are naturally from the largest T5-pretrained architecture
                  (T5-3B), the paper shows improvements over the next-highest BERT-to-BERT method even when using
                  T5-Base or T5-Small, which have the same and lesser parameters than BERT-to-BERT respectively.</p>
              </li>
              <li>
                <p>The <a href="https://github.com/google-research/language/tree/master/language/totto">Supplementary
                    Repo</a> provides several useful modules to get started with for new approach implementation:</p>
                <ol>
                  <li>
                    <p>Code for the particular preprocessing / linearization scheme used to linearize the tables into
                      flat sequences for the baseline approaches described in the paper has been described and shared <a
                        href="https://github.com/google-research/language/tree/master/language/totto#baseline-preprocessing">herein</a>
                    </p>
                  </li>
                  <li>
                    <p>An <a
                        href="https://github.com/google-research/language/tree/master/language/totto#running-the-evaluation-scripts-locally">evaluation
                        script</a> for locally scoring BLEU and PARENT system outputs on dev (or train) sets. Since
                      BLEURT is a model-based metric, a <a
                        href="https://github.com/google-research/language/tree/master/language/totto#running-the-evaluation-scripts-locall://github.com/google-research/language/tree/master/language/totto#computing-the-bleurt-score">slightly
                        separate</a> set of instructions is provided to evaluate on the same.</p>
                  </li>
                </ol>
              </li>
            </ul>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Previous Results

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Previous Results</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Previous Results</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Measured Model Abilities

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What aspect of model ability can be measured with this dataset?</p>
                </div>
              </div>

            </h5>

            <p>Reasoning, surface realization</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Metrics

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What metrics are typically used for this task?</p>
                </div>
              </div>

            </h5>

            <p><code>BLEU</code>, <code>BLEURT</code>, <code>Other: Other Metrics</code></p>
          </div>

          <div class="datacard-field periscope">

            <h5>Other Metrics

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Definitions of other metrics</p>
                </div>
              </div>

            </h5>

            <p>Parent: a metric that measures the F-1 score of overlap between input content words and those used in
              references and those in generated text while ignoring the general surface form. It can thus measure the
              faithfulness much better than metrics that measure overlap with a reference</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Proposed Evaluation

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>List and describe the purpose of the metrics and evaluation methodology (including human
                    evaluation) that the dataset creators used when introducing this task.</p>
                </div>
              </div>

            </h5>

            <p>The metrics are used as in the leaderboard. The original paper additionally conducted a human evaluation
              focusing on fluency, faithfulness, and coverage.
              Faithfulness was measured as whether facts in the text are not supported by the input, and coverage as the
              number of highlighted cells that were considered. They thus represent precision and recall of the content.
            </p>
          </div>

          <div class="datacard-field telescope">

            <h5>Previous results available?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Are previous results available?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Relevant Previous Results

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What are the most relevant previous results for this task/dataset?</p>
                </div>
              </div>

            </h5>

            <p>See leaderboard.</p>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Dataset Curation

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Original Curation</h4>
              </li>
              <li>
                <h4>Language Data</h4>
              </li>
              <li>
                <h4>Structured Annotations</h4>
              </li>
              <li>
                <h4>Consent</h4>
              </li>
              <li>
                <h4>Private Identifying Information (PII)</h4>
              </li>
              <li>
                <h4>Maintenance</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Original Curation</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Original Curation Rationale

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Original curation rationale</p>
                </div>
              </div>

            </h5>

            <p>Tables occurring in Wikipedia articles were chosen as the data source with the following reasons in mind:
            </p>
            <ol>
              <li>Wide coverage in terms of both vocabulary and concepts.</li>
              <li>Wikipedia tables are not confined to a regular structure, with multi-row or multi-column cells
                occurring with a sufficient frequency.</li>
              <li>Likely to contain reasonable-quality, natural text descriptions in the proximity of the table, which
                are also extractable by heuristics. (see the start of Section 4 for the heuristics used)</li>
            </ol>
            <p>To prevent an overlap with the earlier <a href="https://arxiv.org/abs/1603.07771">Wikibio</a> dataset
              which focussed on Infobox-first sentence pairs from Wikipedia biography articles, the authors avoid using
              Infoboxes as a data source.</p>
            <p>The overall curation process of initially collecting free text and then annotator-revising it, was
              designed to combine the advantages of free-form text descriptions (which are fluent, high-quality and
              unhurriedly written, but also divergent and unfaithful) with annotator descriptions (which can be tailored
              to be faithful and to conform exactly to desired task requirements)</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Communicative Goal

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What was the communicative goal?</p>
                </div>
              </div>

            </h5>

            <p>The speaker is required to produce a single, coherent English sentence that describes the highlighted
              cells in the given table, also using metadata and any other information from the table as applicable.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Sourced from Different Sources

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Is the dataset aggregated from different data sources?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Source Details

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>List the sources (one per line)</p>
                </div>
              </div>

            </h5>

            <p>wikipedia.org</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Language Data</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>How was Language Data Obtained?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>How was the language data obtained?</p>
                </div>
              </div>

            </h5>

            <p><code>Crowdsourced</code></p>
          </div>

          <div class="datacard-field periscope">

            <h5>Where was it crowdsourced?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>If crowdsourced, where from?</p>
                </div>
              </div>

            </h5>

            <p><code>Other crowdworker platform</code></p>
          </div>

          <div class="datacard-field microscope">

            <h5>Language Producers

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What further information do we have on the language producers?</p>
                </div>
              </div>

            </h5>

            <p>The basic source language producers are Wikipedia authors and/or editors, since the annotation starts
              with the natural text description near the Wikipedia table.
              The auxiliary source language producers are the annotators (two per example) who iteratively revise these
              descriptions to make them unambiguous and faithful to a subset of highlighted cells in the table.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Data Validation

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Was the text validated by a different worker or a data curator?</p>
                </div>
              </div>

            </h5>

            <p>validated by crowdworker</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Data Preprocessing

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>How was the text data pre-processed? (Enter N/A if the text was not pre-processed)</p>
                </div>
              </div>

            </h5>

            <p>The initial table-description pairs are tables from Wikipedia articles, extracted through heuristics such
              as Number Matching (tables and sentences that overlap with a non-date number of atleast 3 non-zero digits)
              (Refer to Section 4 of the paper for more)</p>
            <ol>
              <li>Table Readability: Tables which are deemed non-readable (due to foreign language, poor formatting etc
                - a very small fraction of 0.5%) are removed from the dataset here.</li>
              <li>Cell Highlighting: The annotator highlights the cells of the table which support the description.</li>
              <li>Deletion: The annotator removes phrases in the description which are not supported by the highlighted
                cells</li>
              <li>Decontextualization: Descriptions may contain pronouns or other forms of anaphora, or other phenomena
                which depend on the overall article topic - these are fixed by replacement (e.g replacing pronouns with
                the entity, provided it occurs in the table). The replacements allowed are limited to one, and
                annotators are also instructed to conserve fluency.</li>
              <li>Secondary Annotation: A second set of annotators is shown the output of Stage 4, and asked to fix it
                if required to ensure it is grammatical.</li>
            </ol>
            <p>The paper does not specifically describe the annotation platform or location profiles of the annotators.
            </p>
          </div>

          <div class="datacard-field telescope">

            <h5>Was Data Filtered?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Were text instances selected or filtered?</p>
                </div>
              </div>

            </h5>

            <p>algorithmically</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Filter Criteria

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What were the selection criteria?</p>
                </div>
              </div>

            </h5>

            <p>After construction of the splits, the data curators filtered training examples that had rare table header
              combinations (&#x3C;=5 examples) and which had an overlap with the validation or test splits.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Structured Annotations</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Additional Annotations?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the dataset have additional annotations for each instance?</p>
                </div>
              </div>

            </h5>

            <p>none</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Annotation Service?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Was an annotation service used?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Consent</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Any Consent Policy?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Was there a consent policy involved when gathering the data?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Consent Policy Details

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What was the consent policy?</p>
                </div>
              </div>

            </h5>

            <p>Annotators were full time employees that were aware of the goal of the project and consented to having
              the data released as part of the dataset.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Private Identifying Information (PII)</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Contains PII?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the source language data likely contain Personal Identifying Information about the data
                    creators or subjects?</p>
                </div>
              </div>

            </h5>

            <p>no PII</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Justification for no PII

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Provide a justification for selecting <code>no PII</code> above.</p>
                </div>
              </div>

            </h5>

            <p>Since the source data is from wikipedia, only data in the public domain is included in the dataset.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Maintenance</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Any Maintenance Plan?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the original dataset have a maintenance plan?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Maintenance Plan Details

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Describe the original dataset's maintenance plan.</p>
                </div>
              </div>

            </h5>

            <p>For submissions, you can delete your data by emailing <a
                href="mailto:totto@google.com">totto@google.com</a> from the email account used to sign up for the
              submission. Deletion requests will be responded to within 60 days.</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Maintainer Contact Information

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Provide contact information of a person responsible for the dataset maintenance</p>
                </div>
              </div>

            </h5>

            <p>Ankur Parikh (<a href="mailto:aparikh@google.com">aparikh@google.com</a>)</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Any Contestation Mechanism?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the maintenance plan include a contestation mechanism allowing individuals to request removal
                    fo content?</p>
                </div>
              </div>

            </h5>

            <p>form submission</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Contestation Form Link

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Provide the form link or contact information</p>
                </div>
              </div>

            </h5>

            <p><a href="mailto:totto@google.com">totto@google.com</a></p>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Broader Social Context

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Previous Work on the Social Impact of the Dataset</h4>
              </li>
              <li>
                <h4>Impact on Under-Served Communities</h4>
              </li>
              <li>
                <h4>Discussion of Biases</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Previous Work on the Social Impact of the Dataset</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Usage of Models based on the Data

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Are you aware of cases where models trained on the task featured in this dataset ore related tasks
                    have been used in automated systems?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Impact on Under-Served Communities</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Addresses needs of underserved Communities?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does this dataset address the needs of communities that are traditionally underserved in language
                    technology, and particularly language generation technology? Communities may be underserved for
                    exemple because their language, language variety, or social or geographical context is
                    underepresented in NLP and NLG resources (datasets and models).</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Discussion of Biases</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Any Documented Social Biases?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Are there documented social biases in the dataset? Biases in this context are variations in the
                    ways members of different social categories are represented that can have harmful downstream
                    consequences for members of the more disadvantaged group.</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Links and Summaries of Analysis Work

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Provide links to and summaries of works analyzing these biases.</p>
                </div>
              </div>

            </h5>

            <p>The original work as well as our GEM paper analyzes some biases</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Are the Language Producers Representative of the Language?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the distribution of language producers in the dataset accurately represent the full
                    distribution of speakers of the language world-wide? If not, how does it differ?</p>
                </div>
              </div>

            </h5>

            <p>This dataset is created using tables and the table cell contents may hence naturally exhibit biases which
              have been found to exist in Wikipedia such as some forms of gender bias (e.g <a
                href="https://labtomarket.files.wordpress.com/2018/01/wiki_gender_bias.pdf">(Graells-Garido et
                al.,2015)</a> notes that spouse information is more likely discussed for females than males)</p>
            <p>The table descriptions (targets/references) are, as discussed earlier, collected through a two-step
              process.</p>
            <ol>
              <li>The natural text description near the table is taken as a starting point. This is Wikipedia article
                text as created upto that point in time by a chain of collaborative edits from Wikipedia authors.</li>
              <li>The initial description is revised by chain of two or more annotated revisions, to make it unambiguous
                and faithful to a set of highlighted table cells.</li>
            </ol>
            <p>From their origin in 1), the descriptions may exhibit biases seen in Wikipedia text as mentioned above.
              From their revisions in 2), the descriptions may show biases originating from annotator-authored text,
              such as a preference for shorter descriptions since they're faster to write, or linguistic preferences
              influenced by the locations dominant in the annotator distribution. (However, note that these are likely
              to be much reduced since the annotators here are merely revising rather than completely authoring.
              Moreover, each sentence goes through atleast two annotators, which acts as a check against the personal
              biases of a single annotator.)</p>
            <p>Naturally-occurring text is also known to suffer from other biases such as reporting bias <a
                href="https://openreview.net/forum?id=AzxEzvpdE3Wcy&#x26;noteId=vmR8qaby8fqxittps://labtomarket.files.wordpress.com/2018/01/wiki_gender_bias.pdf">(Gordon
                and Van Durme, 2013)</a> - this also applies to this dataset via its origin from Wikipedia.</p>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Considerations for Using the Data

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>PII Risks and Liability</h4>
              </li>
              <li>
                <h4>Licenses</h4>
              </li>
              <li>
                <h4>Known Technical Limitations</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>PII Risks and Liability</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field microscope">

            <h5>Potential PII Risk

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Considering your answers to the PII part of the Data Curation Section, describe any potential
                    privacy to the data subjects and creators risks when using the dataset.</p>
                </div>
              </div>

            </h5>

            <p>Since the source data is from wikipedia, only data in the public domain is included in the dataset.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Licenses</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field periscope">

            <h5>Copyright Restrictions on the Dataset

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Based on your answers in the Intended Use part of the Data Overview Section, which of the following
                    best describe the copyright and licensing status of the dataset?</p>
                </div>
              </div>

            </h5>

            <p><code>open license - commercial use allowed</code></p>
          </div>

          <div class="datacard-field periscope">

            <h5>Copyright Restrictions on the Language Data

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Based on your answers in the Language part of the Data Curation Section, which of the following
                    best describe the copyright and licensing status of the underlying language data?</p>
                </div>
              </div>

            </h5>

            <p><code>open license - commercial use allowed</code></p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Known Technical Limitations</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field microscope">

            <h5>Technical Limitations

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Describe any known technical limitations, such as spurrious correlations, train/test overlap,
                    annotation biases, or mis-annotations, and cite the works that first identified these limitations
                    when possible.</p>
                </div>
              </div>

            </h5>

            <p>The dataset is limited to topics that are present in Wikipedia, more specifically those topics that are
              present in articles which contain atleast one table
              <em>Sports</em> and <em>Countries</em> form 53.4% of the dataset. The remaining fraction is made up of
              broader topics like <em>Europe</em>, <em>North America</em>and <em>Politics</em>
            </p>
          </div>
        </div>

      </div>
    </div>
  </section>
</div></div></article></main><div class="layout_push__lpoMK"></div></div><footer class="layout_footer__WlhMu utils_eggshell__3hbbY"><span class="layout_backToHome__D9QFr"><a href="/"> Home</a></span><span>If you have any questions, please join our <a href="https://groups.google.com/g/gem-benchmark" target="_blank" class="utils_accentUnderline__VG89l">google group</a> for support.</span></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"taskData":{"id":"totto","contentHtml":"\u003cdiv class=\"datacard\"\u003e\r\n  \u003csection class=\"datacard-section\"\u003e\r\n    \u003cdiv class=\"datacard-summary\"\u003e\r\n      \u003ch2\u003etotto\u003c/h2\u003e\r\n      \u003cdiv class=\"summary-content\"\u003e\r\n        \u003cp\u003eToTTo is a high-quality English table-to-text dataset with more than 100,000 examples in which a table from\r\n          Wikipedia with highlighted cells is paired with a sentence that describes the highlighted cells. All examples\r\n          in the dataset were post-edited in multiple steps to ensure that the targets are fully faithful to the input\r\n          information.\u003c/p\u003e\r\n        \u003cp\u003eYou can load the dataset via:\u003c/p\u003e\r\n\r\n        \u003cdiv class=\"code-wrapper\"\u003e\r\n          \u003cdiv class=\"toolbar\"\u003e\r\n            \u003cdiv class=\"copy-icon\" title=\"Click to copy code block\"\u003e\u003c/div\u003e\r\n            \u003cdiv class=\"expand-modal-icon\" title=\"Click to expand code block\"\u003e\u003c/div\u003e\r\n          \u003c/div\u003e\r\n          \u003cpre\u003e\u003ccode\u003eimport datasets\r\ndata = datasets.load_dataset('GEM/totto')\r\n\u003c/code\u003e\u003c/pre\u003e\r\n        \u003c/div\u003e\r\n\r\n        \u003cp\u003eThe data loader can be found \u003ca href=\"https://huggingface.co/datasets/GEM/totto\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\r\n      \u003c/div\u003e\r\n    \u003c/div\u003e\r\n\r\n    \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n      \u003cdiv class=\"datacard-field\"\u003e\r\n\r\n        \u003ch5\u003ewebsite\r\n\r\n        \u003c/h5\u003e\r\n\r\n        \u003cp\u003en/a\u003c/p\u003e\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-field\"\u003e\r\n\r\n        \u003ch5\u003epaper\r\n\r\n        \u003c/h5\u003e\r\n\r\n        \u003cp\u003e\u003ca href=\"https://aclanthology.org/2020.emnlp-main.89\"\u003eACL Anthology\u003c/a\u003e\u003c/p\u003e\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-field\"\u003e\r\n\r\n        \u003ch5\u003eauthors\r\n\r\n        \u003c/h5\u003e\r\n\r\n        \u003cp\u003eAnkur Parikh, Xuezhi Wang, Sebastian Gehrmann, Manaal Faruqui, Bhuwan Dhingra, Diyi Yang, Dipanjan Das\u003c/p\u003e\r\n      \u003c/div\u003e\r\n    \u003c/div\u003e\r\n\r\n  \u003c/section\u003e\r\n\r\n  \u003csection class=\"datacard-section quick\"\u003e\r\n    \u003ch3 class=\"section-title\"\u003eQuick-Use\u003c/h3\u003e\r\n\r\n    \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n      \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n        \u003ch5\u003eContact Name\r\n\r\n          \u003cdiv class=\"tooltip\"\u003e\r\n            \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n            \u003cdiv class=\"tooltip-text\"\u003e\r\n              \u003cp\u003eIf known, provide the name of at least one person the reader can contact for questions about the\r\n                dataset.\u003c/p\u003e\r\n            \u003c/div\u003e\r\n          \u003c/div\u003e\r\n\r\n        \u003c/h5\u003e\r\n\r\n        \u003cp\u003eAnkur Parikh\u003c/p\u003e\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n        \u003ch5\u003eMultilingual?\r\n\r\n          \u003cdiv class=\"tooltip\"\u003e\r\n            \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n            \u003cdiv class=\"tooltip-text\"\u003e\r\n              \u003cp\u003eIs the dataset multilingual?\u003c/p\u003e\r\n            \u003c/div\u003e\r\n          \u003c/div\u003e\r\n\r\n        \u003c/h5\u003e\r\n\r\n        \u003cp\u003eno\u003c/p\u003e\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n        \u003ch5\u003eCovered Languages\r\n\r\n          \u003cdiv class=\"tooltip\"\u003e\r\n            \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n            \u003cdiv class=\"tooltip-text\"\u003e\r\n              \u003cp\u003eWhat languages/dialects are covered in the dataset?\u003c/p\u003e\r\n            \u003c/div\u003e\r\n          \u003c/div\u003e\r\n\r\n        \u003c/h5\u003e\r\n\r\n        \u003cp\u003e\u003ccode\u003eEnglish\u003c/code\u003e\u003c/p\u003e\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n        \u003ch5\u003eLicense\r\n\r\n          \u003cdiv class=\"tooltip\"\u003e\r\n            \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n            \u003cdiv class=\"tooltip-text\"\u003e\r\n              \u003cp\u003eWhat is the license of the dataset?\u003c/p\u003e\r\n            \u003c/div\u003e\r\n          \u003c/div\u003e\r\n\r\n        \u003c/h5\u003e\r\n\r\n        \u003cp\u003ecc-by-sa-3.0: Creative Commons Attribution Share Alike 3.0 Unported\u003c/p\u003e\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n        \u003ch5\u003eCommunicative Goal\r\n\r\n          \u003cdiv class=\"tooltip\"\u003e\r\n            \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n            \u003cdiv class=\"tooltip-text\"\u003e\r\n              \u003cp\u003eProvide a short description of the communicative goal of a model trained for this task on this dataset.\r\n              \u003c/p\u003e\r\n            \u003c/div\u003e\r\n          \u003c/div\u003e\r\n\r\n        \u003c/h5\u003e\r\n\r\n        \u003cp\u003eThe speaker is required to produce a single, coherent English sentence that describes the highlighted cells\r\n          in the given table, also using metadata and any other information from the table as applicable.\u003c/p\u003e\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n        \u003ch5\u003eAdditional Annotations?\r\n\r\n          \u003cdiv class=\"tooltip\"\u003e\r\n            \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n            \u003cdiv class=\"tooltip-text\"\u003e\r\n              \u003cp\u003eDoes the dataset have additional annotations for each instance?\u003c/p\u003e\r\n            \u003c/div\u003e\r\n          \u003c/div\u003e\r\n\r\n        \u003c/h5\u003e\r\n\r\n        \u003cp\u003enone\u003c/p\u003e\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n        \u003ch5\u003eContains PII?\r\n\r\n          \u003cdiv class=\"tooltip\"\u003e\r\n            \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n            \u003cdiv class=\"tooltip-text\"\u003e\r\n              \u003cp\u003eDoes the source language data likely contain Personal Identifying Information about the data creators\r\n                or subjects?\u003c/p\u003e\r\n            \u003c/div\u003e\r\n          \u003c/div\u003e\r\n\r\n        \u003c/h5\u003e\r\n\r\n        \u003cp\u003eno PII\u003c/p\u003e\r\n      \u003c/div\u003e\r\n    \u003c/div\u003e\r\n\r\n  \u003c/section\u003e\r\n\r\n\r\n  \u003csection class=\"datacard-section open\"\u003e\r\n\r\n    \u003cdiv class=\"datacard-section-preview\"\u003e\r\n      \u003ch3\u003eDataset Overview\r\n\r\n        \u003cdiv class=\"tooltip\"\u003e\r\n          \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n          \u003cdiv class=\"tooltip-text\"\u003e\r\n            \u003cul\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eWhere to find the Data and its Documentation\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eLanguages and Intended Use\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eCredit\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eDataset Structure\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n            \u003c/ul\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/h3\u003e\r\n      \u003cbutton class=\"expand-button\"\u003e\r\n        \u003csvg fill=\"#3c4f50\" height=\"24px\" viewBox=\"0 0 24 24\" width=\"24px\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\r\n          \u003cpath d=\"M0 0h24v24H0z\" fill=\"none\"\u003e\u003c/path\u003e\r\n          \u003cpath d=\"M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z\"\u003e\r\n          \u003c/path\u003e\r\n        \u003c/svg\u003e\r\n      \u003c/button\u003e\r\n    \u003c/div\u003e\r\n\r\n    \u003cdiv class=\"datacard-collapsible\"\u003e\r\n\r\n\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eWhere to find the Data and its Documentation\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eDownload\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat is the link to where the original dataset is hosted?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ca href=\"https://github.com/google-research-datasets/totto\"\u003eToTTo Main Repo\u003c/a\u003e + \u003ca\r\n                href=\"https://github.com/google-research/language/tree/master/language/totto\"\u003eToTTo Supplementary\r\n                Repo\u003c/a\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003ePaper\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat is the link to the paper describing the dataset (open access preferred)?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ca href=\"https://aclanthology.org/2020.emnlp-main.89\"\u003eACL Anthology\u003c/a\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eBibTex\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eProvide the BibTex-formatted reference for the dataset. Please use the correct published version\r\n                    (ACL anthology, etc.) instead of google scholar created Bibtex.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n\r\n            \u003cdiv class=\"code-wrapper\"\u003e\r\n              \u003cdiv class=\"toolbar\"\u003e\r\n                \u003cdiv class=\"copy-icon\" title=\"Click to copy code block\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"expand-modal-icon\" title=\"Click to expand code block\"\u003e\u003c/div\u003e\r\n              \u003c/div\u003e\r\n              \u003cpre\u003e\u003ccode\u003e@inproceedings{parikh-etal-2020-totto,\r\ntitle = \"{ToTTo}: A Controlled Table-To-Text Generation Dataset\",\r\nauthor = \"Parikh, Ankur  and\r\nWang, Xuezhi  and\r\nGehrmann, Sebastian  and\r\nFaruqui, Manaal  and\r\nDhingra, Bhuwan  and\r\nYang, Diyi  and\r\nDas, Dipanjan\",\r\nbooktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\r\nmonth = nov,\r\nyear = \"2020\",\r\naddress = \"Online\",\r\npublisher = \"Association for Computational Linguistics\",\r\nurl = \"https://aclanthology.org/2020.emnlp-main.89\",\r\ndoi = \"10.18653/v1/2020.emnlp-main.89\",\r\npages = \"1173--1186\",\r\nabstract = \"We present ToTTo, an open-domain English table-to-text dataset with over 120,000 training examples that proposes a controlled generation task: given a Wikipedia table and a set of highlighted table cells, produce a one-sentence description. To obtain generated targets that are natural but also faithful to the source table, we introduce a dataset construction process where annotators directly revise existing candidate sentences from Wikipedia. We present systematic analyses of our dataset and annotation process as well as results achieved by several state-of-the-art baselines. While usually fluent, existing methods often hallucinate phrases that are not supported by the table, suggesting that this dataset can serve as a useful research benchmark for high-precision conditional text generation.\",\r\n}\r\n\u003c/code\u003e\u003c/pre\u003e\r\n            \u003c/div\u003e\r\n\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eContact Name\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eIf known, provide the name of at least one person the reader can contact for questions about the\r\n                    dataset.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eAnkur Parikh\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eContact Email\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eIf known, provide the email of at least one person the reader can contact for questions about the\r\n                    dataset.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ca href=\"mailto:totto@google.com\"\u003etotto@google.com\u003c/a\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eHas a Leaderboard?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDoes the dataset have an active leaderboard?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eyes\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eLeaderboard Link\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eProvide a link to the leaderboard.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ca href=\"https://github.com/google-research-datasets/totto\"\u003eGithub\u003c/a\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eLeaderboard Details\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eBriefly describe how the leaderboard evaluates models.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThis dataset has an associated, active \u003ca\r\n                href=\"https://github.com/google-research-datasets/totto#leaderboard\"\u003eleaderboard\u003c/a\u003e maintained by the\r\n              authors.\r\n              The test set ground truth targets / references are private, i.e they are not publicly shared or\r\n              downloadable - hence, leaderboard submission is necessary for test set evaluation.\r\n              To evaluate your model on the dev or test set AND/OR submit to the leaderboard, you need to submit your\r\n              model files through this \u003ca href=\"https://forms.gle/AcF9TRqWrPhPzztt7\"\u003eform\u003c/a\u003e (The form provides an\r\n              option to opt-out of going on the leaderboard).\u003c/p\u003e\r\n            \u003cp\u003eThe leaderboard reports three sets of BLEU, PARENT and BLEURT scores for each submission - on the overall\r\n              test set, the \u003cem\u003eOverlap\u003c/em\u003e subset of the test set and the \u003cem\u003enon-Overlap\u003c/em\u003e subset of the test set.\r\n            \u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eLanguages and Intended Use\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eMultilingual?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eIs the dataset multilingual?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eno\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eCovered Dialects\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat dialects are covered? Are there multiple dialects per language?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eNo specific dialects. The original language is from Wikipedia and it was post-edited by crowdraters\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eCovered Languages\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat languages/dialects are covered in the dataset?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ccode\u003eEnglish\u003c/code\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eWhose Language?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhose language is in the dataset?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThe language is post-edited English only (BCP-47: \u003ccode\u003een\u003c/code\u003e) Wikipedia text. No demographic\r\n              information about annotators is provided.\r\n              Some amounts of what may be called non-English text, including characters such as French accents or\r\n              Cyrillic characters, could sometimes occur, especially through fields with entity names as values in the\r\n              input table cells.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eLicense\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat is the license of the dataset?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003ecc-by-sa-3.0: Creative Commons Attribution Share Alike 3.0 Unported\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eIntended Use\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat is the intended use of the dataset?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eToTTo is a Table-to-Text NLG task, as the paper title says. The task is as follows: Given a Wikipedia\r\n              table with row names, column names and table cells, with a subset of cells highlighted, generate a natural\r\n              language description for the highlighted part of the table . The table need not be exactly rectangular in\r\n              that - cells can sometimes be multi-row or multi-column.\u003c/p\u003e\r\n            \u003cp\u003eAn earlier example of a Table-to-Text NLG task is \u003ca href=\"https://arxiv.org/abs/1603.07771\"\u003eWikibio\u003c/a\u003e\r\n              - here the inputs were Wikipedia infoboxes (from the top right corner of entity-related Wiki pages). In\r\n              contrast, ToTTo mostly has Wikipedia tables from the main article content itself. In general,\r\n              Table-To-Text NLG tasks can be seen as a subclass of Data-To-Text NLG tasks - where the task is to\r\n              generate natural language descriptions of inputs which are in the form of structured or semi-structured\r\n              data. In general, all Data-To-Text NLG tasks need not have an explicit table or other structure - e.g the\r\n              input in \u003ca href=\"https://www.aclweb.org/anthology/W16-6626.pdf\"\u003eWebNLG\u003c/a\u003e is simply a list of triples.\r\n            \u003c/p\u003e\r\n            \u003cp\u003eImportantly, ToTTo differs from earlier examples of Table-To-Text NLG in that:\u003c/p\u003e\r\n            \u003col\u003e\r\n              \u003cli\u003e\r\n                \u003cp\u003eIt does not suffer from the problem of divergent references - where ground truth descriptions\r\n                  themselves have additional information not found in the table. ToTTo overcomes this by having a\r\n                  multi-step annotation process to edit the initial, free-form table descriptions (which are from\r\n                  Wikipedia) to make them faithful, unambiguous and independent of article context.\u003c/p\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003cp\u003eSince it provides \u003cstrong\u003econtrol\u003c/strong\u003e in the form of highlighted table cells, it prevents the\r\n                  problem of there being a large number of valid descriptions focussing on different parts of the table.\r\n                \u003c/p\u003e\r\n              \u003c/li\u003e\r\n            \u003c/ol\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003ePrimary Task\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat primary task does the dataset support?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eData-to-Text\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eCommunicative Goal\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eProvide a short description of the communicative goal of a model trained for this task on this\r\n                    dataset.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThe speaker is required to produce a single, coherent English sentence that describes the highlighted\r\n              cells in the given table, also using metadata and any other information from the table as applicable.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eCredit\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eCuration Organization Type(s)\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eIn what kind of organization did the dataset curation happen?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ccode\u003eindustry\u003c/code\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eCuration Organization(s)\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eName the organization(s).\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eGoogle Research\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eDataset Creators\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWho created the original dataset? List the people involved in collecting the dataset and their\r\n                    affiliation(s).\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eAnkur Parikh, Xuezhi Wang, Sebastian Gehrmann, Manaal Faruqui, Bhuwan Dhingra, Diyi Yang, Dipanjan Das\r\n            \u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eFunding\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWho funded the data creation?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eGoogle Research\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eWho added the Dataset to GEM?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWho contributed to the data card and adding the dataset to GEM? List the people+affiliations\r\n                    involved in creating this data card and who helped integrate this dataset into GEM.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eVarun Gangal created the initial data card and Yacine Jernite wrote the data loader. The data card was\r\n              updated with new splits by Simon Mille. Sebastian Gehrmann ported the data card and loader from the v1 to\r\n              the v2 version and extended it with the new fields.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eDataset Structure\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eData Fields\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eList and describe the fields present in the dataset.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cul\u003e\r\n              \u003cli\u003eThe \u003ccode\u003etable\u003c/code\u003e field is a \u003ccode\u003eList[List[Dict]]\u003c/code\u003e in row-major order, with outer lists\r\n                representing rows and the inner lists columns.\u003c/li\u003e\r\n              \u003cli\u003eEach \u003ccode\u003eDict\u003c/code\u003e has the fields \u003ccode\u003ecolumn_span: int\u003c/code\u003e, \u003ccode\u003eis_header: bool\u003c/code\u003e,\r\n                \u003ccode\u003erow_span: int\u003c/code\u003e, and \u003ccode\u003evalue: str\u003c/code\u003e.\u003c/li\u003e\r\n              \u003cli\u003eTable metadata consists of \u003ccode\u003etable_page_title\u003c/code\u003e, \u003ccode\u003etable_section_title\u003c/code\u003e and\r\n                \u003ccode\u003etable_section_texts\u003c/code\u003e\u003c/li\u003e\r\n              \u003cli\u003eThe \u003ccode\u003ehighlighted_cells\u003c/code\u003e are represented as \u003ccode\u003eList[[row_index,column_index]]\u003c/code\u003e,\r\n                with each \u003ccode\u003e[row_index,column_index]\u003c/code\u003e indicating that\r\n                \u003ccode\u003etable[row_index][column_index]\u003c/code\u003e is highlighted.\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003eexample_id\u003c/code\u003e is the unique id per example.\u003c/li\u003e\r\n              \u003cli\u003e\u003ccode\u003esentence_annotations[final_sentence]\u003c/code\u003e which is the table description/generation target\r\n              \u003c/li\u003e\r\n            \u003c/ul\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eReason for Structure\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eHow was the dataset structure determined?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThe structure is aimed to encode highlighted tables in a way that allows rows and columns to span\r\n              multiple fields in width. The other fields are meta-data about the source and the annotations\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eHow were labels chosen?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eHow were the labels chosen?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThe initial table-description pairs are tables from Wikipedia articles, extracted through heuristics such\r\n              as Number Matching (tables and sentences that overlap with a non-date number of atleast 3 non-zero digits)\r\n              (Refer to Section 4 of the paper for more)\u003c/p\u003e\r\n            \u003col\u003e\r\n              \u003cli\u003eTable Readability: Tables which are deemed non-readable (due to foreign language, poor formatting etc\r\n                - a very small fraction of 0.5%) are removed from the dataset here.\u003c/li\u003e\r\n              \u003cli\u003eCell Highlighting: The annotator highlights the cells of the table which support the description.\u003c/li\u003e\r\n              \u003cli\u003eDeletion: The annotator removes phrases in the description which are not supported by the highlighted\r\n                cells\u003c/li\u003e\r\n              \u003cli\u003eDecontextualization: Descriptions may contain pronouns or other forms of anaphora, or other phenomena\r\n                which depend on the overall article topic - these are fixed by replacement (e.g replacing pronouns with\r\n                the entity, provided it occurs in the table). The replacements allowed are limited to one, and\r\n                annotators are also instructed to conserve fluency.\u003c/li\u003e\r\n              \u003cli\u003eSecondary Annotation: A second set of annotators is shown the output of Stage 4, and asked to fix it\r\n                if required to ensure it is grammatical.\u003c/li\u003e\r\n            \u003c/ol\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eExample Instance\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eProvide a JSON formatted example of a typical instance in the dataset.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThe main repository's \u003ccode\u003eREADME.md\u003c/code\u003e already provides a thorough walkthrough of data instances\r\n              and fields \u003ca href=\"https://github.com/google-research-datasets/totto#dataset-description\"\u003ehere\u003c/a\u003e\u003c/p\u003e\r\n            \u003cp\u003eBelow is the instance for a table from the wiki-page for the musical artist \u003cem\u003eWeird Al' Yankovic\u003c/em\u003e ,\r\n              likely listing his on-television appearances.\u003c/p\u003e\r\n\r\n            \u003cdiv class=\"code-wrapper\"\u003e\r\n              \u003cdiv class=\"toolbar\"\u003e\r\n                \u003cdiv class=\"copy-icon\" title=\"Click to copy code block\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"expand-modal-icon\" title=\"Click to expand code block\"\u003e\u003c/div\u003e\r\n              \u003c/div\u003e\r\n              \u003cpre\u003e\u003ccode\u003e    {\r\n\"table_page_title\": \"'Weird Al' Yankovic\",\r\n\"table_webpage_url\": \"https://en.wikipedia.org/wiki/%22Weird_Al%22_Yankovic\",\r\n\"table_section_title\": \"Television\",\r\n\"table_section_text\": \"\",\r\n\"table\": \"[Described below]\",\r\n\"highlighted_cells\": [[22, 2], [22, 3], [22, 0], [22, 1], [23, 3], [23, 1], [23, 0]],\r\n\"example_id\": 12345678912345678912,\r\n\"sentence_annotations\": [{\"original_sentence\": \"In 2016, Al appeared in 2 episodes of BoJack Horseman as Mr. Peanutbutter's brother, Captain Peanutbutter, and was hired to voice the lead role in the 2016 Disney XD series Milo Murphy's Law.\",\r\n    \"sentence_after_deletion\": \"In 2016, Al appeared in 2 episodes of BoJack Horseman as Captain Peanutbutter, and was hired to the lead role in the 2016 series Milo Murphy's Law.\",\r\n    \"sentence_after_ambiguity\": \"In 2016, Al appeared in 2 episodes of BoJack Horseman as Captain Peanutbutter, and was hired for the lead role in the 2016 series Milo Murphy's 'Law.\",\r\n    \"final_sentence\": \"In 2016, Al appeared in 2 episodes of BoJack Horseman as Captain Peanutbutter and was hired for the lead role in the 2016 series Milo Murphy's Law.\"}],\r\n}\r\n\u003c/code\u003e\u003c/pre\u003e\r\n            \u003c/div\u003e\r\n\r\n            \u003cp\u003eThe \u003ccode\u003etable\u003c/code\u003e field is expanded as below:\u003c/p\u003e\r\n\r\n            \u003cdiv class=\"code-wrapper\"\u003e\r\n              \u003cdiv class=\"toolbar\"\u003e\r\n                \u003cdiv class=\"copy-icon\" title=\"Click to copy code block\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"expand-modal-icon\" title=\"Click to expand code block\"\u003e\u003c/div\u003e\r\n              \u003c/div\u003e\r\n              \u003cpre\u003e\u003ccode\u003e    [\r\n[\r\n  {\r\n      \"column_span\": 1,\r\n       \"is_header\": true,\r\n       \"row_span\": 1,\r\n       \"value\": \"Year\"},\r\n  {    \"column_span\": 1,\r\n       \"is_header\": true,\r\n       \"row_span\": 1,\r\n       \"value\": \"Title\"},\r\n  {    \"column_span\": 1,\r\n       \"is_header\": true,\r\n       \"row_span\": 1,\r\n       \"value\": \"Role\"},\r\n  {    \"column_span\": 1,\r\n       \"is_header\": true,\r\n       \"row_span\": 1,\r\n       \"value\": \"Notes\"}\r\n],\r\n[\r\n  {    \"column_span\": 1,\r\n       \"is_header\": false,\r\n       \"row_span\": 1,\r\n       \"value\": \"1997\"},\r\n  {    \"column_span\": 1,\r\n       \"is_header\": false,\r\n       \"row_span\": 1,\r\n       \"value\": \"Eek! The Cat\"},\r\n  {    \"column_span\": 1,\r\n       \"is_header\": false,\r\n       \"row_span\": 1,\r\n       \"value\": \"Himself\"},\r\n  {    \"column_span\": 1,\r\n       \"is_header\": false,\r\n       \"row_span\": 1,\r\n       \"value\": \"Episode: 'The FugEektive'\"}\r\n], ...\r\n]\r\n\u003c/code\u003e\u003c/pre\u003e\r\n            \u003c/div\u003e\r\n\r\n            \u003cp\u003eThe \u003ca href=\"https://github.com/google-research/language/tree/master/language/totto\"\u003eSupplementary\r\n                Repo\u003c/a\u003e also provides browsable samples under its \u003ccode\u003esample/\u003c/code\u003e folder. It additionally provides\r\n              HTML visualization scripts with their outputs located under the aforementioned folder. The instructions to\r\n              access and visualize these samples can also be found \u003ca\r\n                href=\"https://github.com/google-research/language/tree/master/language/totto#visualizing-sample-data\"\u003ehere\u003c/a\u003e.\r\n            \u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eData Splits\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDescribe and name the splits in the dataset if there are more than one.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThe dataset consists of 120,000 train examples and equi-sized dev and test sets with 7700 examples.\r\n              Refer to Table 5 in the paper for a more extensive list of properties about table size, target vocabulary\r\n              etc and their aggregates.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eSplitting Criteria\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDescribe any criteria for splitting the data, if used. If there are differences between the splits\r\n                    (e.g., if the training annotations are machine-generated and the dev and test ones are created by\r\n                    humans, or if different numbers of annotators contributed to each example), describe them here.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThe dev and test splits are further equally distributed between \u003cem\u003eOverlap\u003c/em\u003e and \u003cem\u003enon-Overlap\u003c/em\u003e\r\n              .\r\n              The examples in the \u003cem\u003eOverlap\u003c/em\u003e set are harder on account of the domain shift resulting from them\r\n              having none of their header (row and column) names in common with those seen during training.\u003c/p\u003e\r\n            \u003cp\u003eRefer to Table 5 in the paper for a more extensive list of properties about table size, target vocabulary\r\n              etc and their aggregates.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003e\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat does an outlier of the dataset in terms of length/perplexity/embedding look like?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThere are some very large tables in the dataset with thousands of rows. Table 7 shows some of the\r\n              challenges of the dataset, showing that very few examples require access to the table description itself\r\n              which makes those examples an outlier.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n    \u003c/div\u003e\r\n  \u003c/section\u003e\r\n\r\n  \u003csection class=\"datacard-section open\"\u003e\r\n\r\n    \u003cdiv class=\"datacard-section-preview\"\u003e\r\n      \u003ch3\u003eDataset in GEM\r\n\r\n        \u003cdiv class=\"tooltip\"\u003e\r\n          \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n          \u003cdiv class=\"tooltip-text\"\u003e\r\n            \u003cul\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eRationale for Inclusion in GEM\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eGEM-Specific Curation\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eGetting Started with the Task\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n            \u003c/ul\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/h3\u003e\r\n      \u003cbutton class=\"expand-button\"\u003e\r\n        \u003csvg fill=\"#3c4f50\" height=\"24px\" viewBox=\"0 0 24 24\" width=\"24px\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\r\n          \u003cpath d=\"M0 0h24v24H0z\" fill=\"none\"\u003e\u003c/path\u003e\r\n          \u003cpath d=\"M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z\"\u003e\r\n          \u003c/path\u003e\r\n        \u003c/svg\u003e\r\n      \u003c/button\u003e\r\n    \u003c/div\u003e\r\n\r\n    \u003cdiv class=\"datacard-collapsible\"\u003e\r\n\r\n\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eRationale for Inclusion in GEM\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eWhy is the Dataset in GEM?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat does this dataset contribute toward better generation evaluation and why is it part of GEM?\r\n                  \u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eToTTo is one of the two datasets representing Table-to-Text NLG in GEM, the other one being \u003ca\r\n                href=\"https://arxiv.org/pdf/2007.02871.pdf\"\u003eDART\u003c/a\u003e. Unlike DART, which combines datasets from multiple\r\n              sources and furnishes them in a unified setting, ToTTo is from a homogeneous source. As explained in the\r\n              Task Summary above, it also has an annotation process explicitly crafted to reduce divergent descriptions,\r\n              which is not true of DART.\u003c/p\u003e\r\n            \u003cp\u003eFurthermore, ToTTo is also an instance of a \u003cstrong\u003econtrolled\u003c/strong\u003e generation task - where in\r\n              addition to the input (in this case the table) an additional \u003cstrong\u003econtrol\u003c/strong\u003e (in this case the\r\n              highlighted cells) is given as an additional goal for the generation. The DART task formulation does not\r\n              include controls.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eSimilar Datasets\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDo other datasets for the high level task exist?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eyes\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eUnique Language Coverage\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDoes this dataset cover other languages than other datasets for the same task?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eno\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eDifference from other GEM datasets\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat else sets this dataset apart from other similar datasets in GEM?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThe input is much more complex and the quality much better than that of comparable datasets. The\r\n              highlighted table cells provide a unique challenge to models.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eAbility that the Dataset measures\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat aspect of model ability can be measured with this dataset?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eReasoning, surface realization\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eGEM-Specific Curation\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eModificatied for GEM?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eHas the GEM version of the dataset been modified in any way (data, processing, splits) from the\r\n                    original curated data?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eyes\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eAdditional Splits?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDoes GEM provide additional splits to the dataset?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eyes\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eSplit Information\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDescribe how the new splits were created\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e9 challenge sets for ToTTo were added to the GEM evaluation suite, 8 created specifically for the task\r\n              and 1 coming from the original data.\u003c/p\u003e\r\n            \u003col\u003e\r\n              \u003cli\u003eWe created subsets of the training and development sets of 500 randomly selected inputs each.\u003c/li\u003e\r\n              \u003cli\u003eWe applied input scrambling on a subset of 500 randomly selected test instances; the order of the\r\n                highlighted cells was randomly reassigned.\u003c/li\u003e\r\n              \u003cli\u003eFor the input size, we created subpopulations based on the number of input highlighted cells in the\r\n                whole table.\u003c/li\u003e\r\n            \u003c/ol\u003e\r\n\r\n            \u003cdiv class=\"table-wrapper\"\u003e\r\n              \u003cdiv class=\"toolbar\"\u003e\r\n                \u003cdiv class=\"expand-modal-icon\" title=\"Click to expand table\"\u003e\u003c/div\u003e\r\n              \u003c/div\u003e\r\n              \u003ctable\u003e\r\n                \u003cthead\u003e\r\n                  \u003ctr\u003e\r\n                    \u003cth\u003eInput length\u003c/th\u003e\r\n                    \u003cth\u003eFrequency English\u003c/th\u003e\r\n                  \u003c/tr\u003e\r\n                \u003c/thead\u003e\r\n                \u003ctbody\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e1\u003c/td\u003e\r\n                    \u003ctd\u003e898\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e2\u003c/td\u003e\r\n                    \u003ctd\u003e1850\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e3\u003c/td\u003e\r\n                    \u003ctd\u003e2221\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e4\u003c/td\u003e\r\n                    \u003ctd\u003e1369\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e5\u003c/td\u003e\r\n                    \u003ctd\u003e483\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e6\u003c/td\u003e\r\n                    \u003ctd\u003e379\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e7\u003c/td\u003e\r\n                    \u003ctd\u003e124\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e8\u003c/td\u003e\r\n                    \u003ctd\u003e128\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e9\u003c/td\u003e\r\n                    \u003ctd\u003e61\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e10\u003c/td\u003e\r\n                    \u003ctd\u003e40\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e11\u003c/td\u003e\r\n                    \u003ctd\u003e20\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e12\u003c/td\u003e\r\n                    \u003ctd\u003e26\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e13\u003c/td\u003e\r\n                    \u003ctd\u003e10\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e14\u003c/td\u003e\r\n                    \u003ctd\u003e14\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e15\u003c/td\u003e\r\n                    \u003ctd\u003e14\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e16\u003c/td\u003e\r\n                    \u003ctd\u003e7\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e17\u003c/td\u003e\r\n                    \u003ctd\u003e6\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e18\u003c/td\u003e\r\n                    \u003ctd\u003e5\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e19\u003c/td\u003e\r\n                    \u003ctd\u003e5\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e20\u003c/td\u003e\r\n                    \u003ctd\u003e5\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e21\u003c/td\u003e\r\n                    \u003ctd\u003e4\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e22\u003c/td\u003e\r\n                    \u003ctd\u003e1\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e23\u003c/td\u003e\r\n                    \u003ctd\u003e2\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e24\u003c/td\u003e\r\n                    \u003ctd\u003e4\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e25\u003c/td\u003e\r\n                    \u003ctd\u003e1\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e26...496\u003c/td\u003e\r\n                    \u003ctd\u003e1\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                \u003c/tbody\u003e\r\n              \u003c/table\u003e\r\n            \u003c/div\u003e\r\n\r\n            \u003col start=\"4\"\u003e\r\n              \u003cli\u003eWe also divided the test set according to the size of the whole table, based on the idea that larger\r\n                tables represent a bigger space to take into account when generating the highlighted cells; a larger\r\n                table could be more challenging to generate accurate text than a smaller table. There are 693 different\r\n                table sizes, ranging from 2 to 15834 cells.\u003c/li\u003e\r\n            \u003c/ol\u003e\r\n\r\n            \u003cdiv class=\"table-wrapper\"\u003e\r\n              \u003cdiv class=\"toolbar\"\u003e\r\n                \u003cdiv class=\"expand-modal-icon\" title=\"Click to expand table\"\u003e\u003c/div\u003e\r\n              \u003c/div\u003e\r\n              \u003ctable\u003e\r\n                \u003cthead\u003e\r\n                  \u003ctr\u003e\r\n                    \u003cth\u003eTable size\u003c/th\u003e\r\n                    \u003cth\u003eFrequency English\u003c/th\u003e\r\n                  \u003c/tr\u003e\r\n                \u003c/thead\u003e\r\n                \u003ctbody\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e2\u003c/td\u003e\r\n                    \u003ctd\u003e71\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e3\u003c/td\u003e\r\n                    \u003ctd\u003e52\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e4\u003c/td\u003e\r\n                    \u003ctd\u003e36\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e5\u003c/td\u003e\r\n                    \u003ctd\u003e41\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e6\u003c/td\u003e\r\n                    \u003ctd\u003e144\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e7\u003c/td\u003e\r\n                    \u003ctd\u003e47\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e8\u003c/td\u003e\r\n                    \u003ctd\u003e59\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e9\u003c/td\u003e\r\n                    \u003ctd\u003e105\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e10\u003c/td\u003e\r\n                    \u003ctd\u003e162\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e11\u003c/td\u003e\r\n                    \u003ctd\u003e36\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e12\u003c/td\u003e\r\n                    \u003ctd\u003e158\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e13\u003c/td\u003e\r\n                    \u003ctd\u003e35\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e14\u003c/td\u003e\r\n                    \u003ctd\u003e79\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e15\u003c/td\u003e\r\n                    \u003ctd\u003e136\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e16\u003c/td\u003e\r\n                    \u003ctd\u003e111\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e17\u003c/td\u003e\r\n                    \u003ctd\u003e48\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e18\u003c/td\u003e\r\n                    \u003ctd\u003e123\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e19\u003c/td\u003e\r\n                    \u003ctd\u003e29\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e20\u003c/td\u003e\r\n                    \u003ctd\u003e112\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e21\u003c/td\u003e\r\n                    \u003ctd\u003e91\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e22\u003c/td\u003e\r\n                    \u003ctd\u003e17\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e23\u003c/td\u003e\r\n                    \u003ctd\u003e7\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e24\u003c/td\u003e\r\n                    \u003ctd\u003e169\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e25\u003c/td\u003e\r\n                    \u003ctd\u003e56\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e26\u003c/td\u003e\r\n                    \u003ctd\u003e12\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e27\u003c/td\u003e\r\n                    \u003ctd\u003e40\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e28\u003c/td\u003e\r\n                    \u003ctd\u003e77\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e29\u003c/td\u003e\r\n                    \u003ctd\u003e7\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e30\u003c/td\u003e\r\n                    \u003ctd\u003e122\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e31\u003c/td\u003e\r\n                    \u003ctd\u003e4\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e32\u003c/td\u003e\r\n                    \u003ctd\u003e49\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e33\u003c/td\u003e\r\n                    \u003ctd\u003e21\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e34\u003c/td\u003e\r\n                    \u003ctd\u003e7\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e35\u003c/td\u003e\r\n                    \u003ctd\u003e103\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e36\u003c/td\u003e\r\n                    \u003ctd\u003e131\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e37\u003c/td\u003e\r\n                    \u003ctd\u003e10\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e38\u003c/td\u003e\r\n                    \u003ctd\u003e6\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e39\u003c/td\u003e\r\n                    \u003ctd\u003e26\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e40\u003c/td\u003e\r\n                    \u003ctd\u003e110\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e41\u003c/td\u003e\r\n                    \u003ctd\u003e1\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e42\u003c/td\u003e\r\n                    \u003ctd\u003e54\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e43\u003c/td\u003e\r\n                    \u003ctd\u003e6\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e44\u003c/td\u003e\r\n                    \u003ctd\u003e47\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e45\u003c/td\u003e\r\n                    \u003ctd\u003e79\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e46\u003c/td\u003e\r\n                    \u003ctd\u003e4\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e47\u003c/td\u003e\r\n                    \u003ctd\u003e2\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e48\u003c/td\u003e\r\n                    \u003ctd\u003e114\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e49\u003c/td\u003e\r\n                    \u003ctd\u003e18\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e50\u003c/td\u003e\r\n                    \u003ctd\u003e55\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e51\u003c/td\u003e\r\n                    \u003ctd\u003e11\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e52\u003c/td\u003e\r\n                    \u003ctd\u003e43\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e54\u003c/td\u003e\r\n                    \u003ctd\u003e80\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e55\u003c/td\u003e\r\n                    \u003ctd\u003e73\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e56\u003c/td\u003e\r\n                    \u003ctd\u003e64\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e57\u003c/td\u003e\r\n                    \u003ctd\u003e12\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e58\u003c/td\u003e\r\n                    \u003ctd\u003e1\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e60\u003c/td\u003e\r\n                    \u003ctd\u003e114\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e61\u003c/td\u003e\r\n                    \u003ctd\u003e4\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e63\u003c/td\u003e\r\n                    \u003ctd\u003e39\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e64\u003c/td\u003e\r\n                    \u003ctd\u003e36\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e65\u003c/td\u003e\r\n                    \u003ctd\u003e62\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e66\u003c/td\u003e\r\n                    \u003ctd\u003e48\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e67\u003c/td\u003e\r\n                    \u003ctd\u003e1\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e68\u003c/td\u003e\r\n                    \u003ctd\u003e36\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e69\u003c/td\u003e\r\n                    \u003ctd\u003e6\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e70\u003c/td\u003e\r\n                    \u003ctd\u003e81\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e72\u003c/td\u003e\r\n                    \u003ctd\u003e76\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e73\u003c/td\u003e\r\n                    \u003ctd\u003e1\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e74\u003c/td\u003e\r\n                    \u003ctd\u003e1\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e75\u003c/td\u003e\r\n                    \u003ctd\u003e44\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e76\u003c/td\u003e\r\n                    \u003ctd\u003e33\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e77\u003c/td\u003e\r\n                    \u003ctd\u003e30\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e78\u003c/td\u003e\r\n                    \u003ctd\u003e66\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e79\u003c/td\u003e\r\n                    \u003ctd\u003e1\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e80\u003c/td\u003e\r\n                    \u003ctd\u003e83\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e81\u003c/td\u003e\r\n                    \u003ctd\u003e12\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e82\u003c/td\u003e\r\n                    \u003ctd\u003e1\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e84\u003c/td\u003e\r\n                    \u003ctd\u003e80\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e85\u003c/td\u003e\r\n                    \u003ctd\u003e25\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e86\u003c/td\u003e\r\n                    \u003ctd\u003e1\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e87\u003c/td\u003e\r\n                    \u003ctd\u003e3\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e88\u003c/td\u003e\r\n                    \u003ctd\u003e35\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e90\u003c/td\u003e\r\n                    \u003ctd\u003e78\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e91\u003c/td\u003e\r\n                    \u003ctd\u003e18\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e92\u003c/td\u003e\r\n                    \u003ctd\u003e22\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e93\u003c/td\u003e\r\n                    \u003ctd\u003e5\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e94\u003c/td\u003e\r\n                    \u003ctd\u003e2\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e95\u003c/td\u003e\r\n                    \u003ctd\u003e31\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e96\u003c/td\u003e\r\n                    \u003ctd\u003e50\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e98\u003c/td\u003e\r\n                    \u003ctd\u003e11\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e99\u003c/td\u003e\r\n                    \u003ctd\u003e14\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e100\u003c/td\u003e\r\n                    \u003ctd\u003e48\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e102\u003c/td\u003e\r\n                    \u003ctd\u003e24\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e104\u003c/td\u003e\r\n                    \u003ctd\u003e29\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e105\u003c/td\u003e\r\n                    \u003ctd\u003e36\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e106\u003c/td\u003e\r\n                    \u003ctd\u003e2\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e108\u003c/td\u003e\r\n                    \u003ctd\u003e51\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e110\u003c/td\u003e\r\n                    \u003ctd\u003e31\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                  \u003ctr\u003e\r\n                    \u003ctd\u003e...8000+\u003c/td\u003e\r\n                    \u003ctd\u003e(up to 10)\u003c/td\u003e\r\n                  \u003c/tr\u003e\r\n                \u003c/tbody\u003e\r\n              \u003c/table\u003e\r\n            \u003c/div\u003e\r\n\r\n            \u003col start=\"5\"\u003e\r\n              \u003cli\u003eWe also created three splits based on the subset of test examples in pages about people.\r\n                We then used the structured information in WikiData to identify the following information:\u003c/li\u003e\r\n            \u003c/ol\u003e\r\n            \u003cul\u003e\r\n              \u003cli\u003egender (male, and female),\u003c/li\u003e\r\n              \u003cli\u003enationality grouped by continent (Africa, Asia, Europe, North America, Oceania, and South America)\r\n              \u003c/li\u003e\r\n              \u003cli\u003eethnicity (African American and all USA)\u003c/li\u003e\r\n            \u003c/ul\u003e\r\n            \u003cp\u003eThe categories within gender, ethnicity, and nationality were chosen based on data availability; The\r\n              ToTTo dataset includes mostly tables that do not focus on people. As a result, only seven people in the\r\n              original test set are marked as having a non-binary gender. Similar sparsity informed the grouping of\r\n              nationalities by continent  only 19 countries are represented by more than 10 people in the test set. In\r\n              case a person has citizenships across multiple continents, we may include the person in any of the\r\n              included continents.\u003c/p\u003e\r\n            \u003cp\u003eFinally, ethnicity is very sparsely annotated in WikiData; only 150 test examples in ToTTo have this\r\n              information and 128 of these are African Americans. We thus are unable to compare the performance on,\r\n              e.g., Yoruba or Punjabi people, both of which have fewer than five instances. Another caveat here is that\r\n              only 21 of the 128 people are female. We thus compare the African American population to results on a\r\n              subset that includes all US citizens.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eSplit Motivation\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat aspects of the model's generation capacities were the splits created to test?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003egeneralization, fairness, robustness\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eGetting Started with the Task\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003ePointers to Resources\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eGetting started with in-depth research on the task. Add relevant pointers to resources that\r\n                    researchers can consult when they want to get started digging deeper into the task.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cul\u003e\r\n              \u003cli\u003e\r\n                \u003cp\u003eThe highest spot on the leaderboard is currently held by an anonymous method, with BLEU=49.2,\r\n                  PARENT=58.7 and BLEURT=0.249 on the \u003cem\u003eOverall\u003c/em\u003e test set.\u003c/p\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003cp\u003eThe \u003cstrong\u003ehighest scoring non-anonymous\u003c/strong\u003e method is the T5-based method of \u003ca\r\n                    href=\"https://arxiv.org/abs/2005.10433\"\u003eKale, 2020\u003c/a\u003e. This method uses a simple row-major\r\n                  linearization scheme to convert the table (it chooses only the highlighted cells and ignores the other\r\n                  cells - table titles and section titles are prefixed at the start of the respective section table) to\r\n                  a flat string. The linearized input - output description pairs from training examples are then used to\r\n                  finetune T5, with BLEU being used as the dev metric to pick checkpoints, and beam search with beam\r\n                  size 10 being the decoding method.\u003c/p\u003e\r\n                \u003cp\u003eThough the best numbers from this method are naturally from the largest T5-pretrained architecture\r\n                  (T5-3B), the paper shows improvements over the next-highest BERT-to-BERT method even when using\r\n                  T5-Base or T5-Small, which have the same and lesser parameters than BERT-to-BERT respectively.\u003c/p\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003cp\u003eThe \u003ca href=\"https://github.com/google-research/language/tree/master/language/totto\"\u003eSupplementary\r\n                    Repo\u003c/a\u003e provides several useful modules to get started with for new approach implementation:\u003c/p\u003e\r\n                \u003col\u003e\r\n                  \u003cli\u003e\r\n                    \u003cp\u003eCode for the particular preprocessing / linearization scheme used to linearize the tables into\r\n                      flat sequences for the baseline approaches described in the paper has been described and shared \u003ca\r\n                        href=\"https://github.com/google-research/language/tree/master/language/totto#baseline-preprocessing\"\u003eherein\u003c/a\u003e\r\n                    \u003c/p\u003e\r\n                  \u003c/li\u003e\r\n                  \u003cli\u003e\r\n                    \u003cp\u003eAn \u003ca\r\n                        href=\"https://github.com/google-research/language/tree/master/language/totto#running-the-evaluation-scripts-locally\"\u003eevaluation\r\n                        script\u003c/a\u003e for locally scoring BLEU and PARENT system outputs on dev (or train) sets. Since\r\n                      BLEURT is a model-based metric, a \u003ca\r\n                        href=\"https://github.com/google-research/language/tree/master/language/totto#running-the-evaluation-scripts-locall://github.com/google-research/language/tree/master/language/totto#computing-the-bleurt-score\"\u003eslightly\r\n                        separate\u003c/a\u003e set of instructions is provided to evaluate on the same.\u003c/p\u003e\r\n                  \u003c/li\u003e\r\n                \u003c/ol\u003e\r\n              \u003c/li\u003e\r\n            \u003c/ul\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n    \u003c/div\u003e\r\n  \u003c/section\u003e\r\n\r\n  \u003csection class=\"datacard-section open\"\u003e\r\n\r\n    \u003cdiv class=\"datacard-section-preview\"\u003e\r\n      \u003ch3\u003ePrevious Results\r\n\r\n        \u003cdiv class=\"tooltip\"\u003e\r\n          \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n          \u003cdiv class=\"tooltip-text\"\u003e\r\n            \u003cul\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003ePrevious Results\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n            \u003c/ul\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/h3\u003e\r\n      \u003cbutton class=\"expand-button\"\u003e\r\n        \u003csvg fill=\"#3c4f50\" height=\"24px\" viewBox=\"0 0 24 24\" width=\"24px\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\r\n          \u003cpath d=\"M0 0h24v24H0z\" fill=\"none\"\u003e\u003c/path\u003e\r\n          \u003cpath d=\"M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z\"\u003e\r\n          \u003c/path\u003e\r\n        \u003c/svg\u003e\r\n      \u003c/button\u003e\r\n    \u003c/div\u003e\r\n\r\n    \u003cdiv class=\"datacard-collapsible\"\u003e\r\n\r\n\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003ePrevious Results\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eMeasured Model Abilities\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat aspect of model ability can be measured with this dataset?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eReasoning, surface realization\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eMetrics\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat metrics are typically used for this task?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ccode\u003eBLEU\u003c/code\u003e, \u003ccode\u003eBLEURT\u003c/code\u003e, \u003ccode\u003eOther: Other Metrics\u003c/code\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eOther Metrics\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDefinitions of other metrics\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eParent: a metric that measures the F-1 score of overlap between input content words and those used in\r\n              references and those in generated text while ignoring the general surface form. It can thus measure the\r\n              faithfulness much better than metrics that measure overlap with a reference\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eProposed Evaluation\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eList and describe the purpose of the metrics and evaluation methodology (including human\r\n                    evaluation) that the dataset creators used when introducing this task.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThe metrics are used as in the leaderboard. The original paper additionally conducted a human evaluation\r\n              focusing on fluency, faithfulness, and coverage.\r\n              Faithfulness was measured as whether facts in the text are not supported by the input, and coverage as the\r\n              number of highlighted cells that were considered. They thus represent precision and recall of the content.\r\n            \u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003ePrevious results available?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eAre previous results available?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eyes\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eRelevant Previous Results\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat are the most relevant previous results for this task/dataset?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eSee leaderboard.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n    \u003c/div\u003e\r\n  \u003c/section\u003e\r\n\r\n  \u003csection class=\"datacard-section open\"\u003e\r\n\r\n    \u003cdiv class=\"datacard-section-preview\"\u003e\r\n      \u003ch3\u003eDataset Curation\r\n\r\n        \u003cdiv class=\"tooltip\"\u003e\r\n          \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n          \u003cdiv class=\"tooltip-text\"\u003e\r\n            \u003cul\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eOriginal Curation\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eLanguage Data\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eStructured Annotations\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eConsent\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003ePrivate Identifying Information (PII)\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eMaintenance\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n            \u003c/ul\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/h3\u003e\r\n      \u003cbutton class=\"expand-button\"\u003e\r\n        \u003csvg fill=\"#3c4f50\" height=\"24px\" viewBox=\"0 0 24 24\" width=\"24px\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\r\n          \u003cpath d=\"M0 0h24v24H0z\" fill=\"none\"\u003e\u003c/path\u003e\r\n          \u003cpath d=\"M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z\"\u003e\r\n          \u003c/path\u003e\r\n        \u003c/svg\u003e\r\n      \u003c/button\u003e\r\n    \u003c/div\u003e\r\n\r\n    \u003cdiv class=\"datacard-collapsible\"\u003e\r\n\r\n\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eOriginal Curation\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eOriginal Curation Rationale\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eOriginal curation rationale\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eTables occurring in Wikipedia articles were chosen as the data source with the following reasons in mind:\r\n            \u003c/p\u003e\r\n            \u003col\u003e\r\n              \u003cli\u003eWide coverage in terms of both vocabulary and concepts.\u003c/li\u003e\r\n              \u003cli\u003eWikipedia tables are not confined to a regular structure, with multi-row or multi-column cells\r\n                occurring with a sufficient frequency.\u003c/li\u003e\r\n              \u003cli\u003eLikely to contain reasonable-quality, natural text descriptions in the proximity of the table, which\r\n                are also extractable by heuristics. (see the start of Section 4 for the heuristics used)\u003c/li\u003e\r\n            \u003c/ol\u003e\r\n            \u003cp\u003eTo prevent an overlap with the earlier \u003ca href=\"https://arxiv.org/abs/1603.07771\"\u003eWikibio\u003c/a\u003e dataset\r\n              which focussed on Infobox-first sentence pairs from Wikipedia biography articles, the authors avoid using\r\n              Infoboxes as a data source.\u003c/p\u003e\r\n            \u003cp\u003eThe overall curation process of initially collecting free text and then annotator-revising it, was\r\n              designed to combine the advantages of free-form text descriptions (which are fluent, high-quality and\r\n              unhurriedly written, but also divergent and unfaithful) with annotator descriptions (which can be tailored\r\n              to be faithful and to conform exactly to desired task requirements)\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eCommunicative Goal\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat was the communicative goal?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThe speaker is required to produce a single, coherent English sentence that describes the highlighted\r\n              cells in the given table, also using metadata and any other information from the table as applicable.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eSourced from Different Sources\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eIs the dataset aggregated from different data sources?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eyes\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eSource Details\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eList the sources (one per line)\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003ewikipedia.org\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eLanguage Data\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eHow was Language Data Obtained?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eHow was the language data obtained?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ccode\u003eCrowdsourced\u003c/code\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eWhere was it crowdsourced?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eIf crowdsourced, where from?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ccode\u003eOther crowdworker platform\u003c/code\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eLanguage Producers\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat further information do we have on the language producers?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThe basic source language producers are Wikipedia authors and/or editors, since the annotation starts\r\n              with the natural text description near the Wikipedia table.\r\n              The auxiliary source language producers are the annotators (two per example) who iteratively revise these\r\n              descriptions to make them unambiguous and faithful to a subset of highlighted cells in the table.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eData Validation\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWas the text validated by a different worker or a data curator?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003evalidated by crowdworker\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eData Preprocessing\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eHow was the text data pre-processed? (Enter N/A if the text was not pre-processed)\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThe initial table-description pairs are tables from Wikipedia articles, extracted through heuristics such\r\n              as Number Matching (tables and sentences that overlap with a non-date number of atleast 3 non-zero digits)\r\n              (Refer to Section 4 of the paper for more)\u003c/p\u003e\r\n            \u003col\u003e\r\n              \u003cli\u003eTable Readability: Tables which are deemed non-readable (due to foreign language, poor formatting etc\r\n                - a very small fraction of 0.5%) are removed from the dataset here.\u003c/li\u003e\r\n              \u003cli\u003eCell Highlighting: The annotator highlights the cells of the table which support the description.\u003c/li\u003e\r\n              \u003cli\u003eDeletion: The annotator removes phrases in the description which are not supported by the highlighted\r\n                cells\u003c/li\u003e\r\n              \u003cli\u003eDecontextualization: Descriptions may contain pronouns or other forms of anaphora, or other phenomena\r\n                which depend on the overall article topic - these are fixed by replacement (e.g replacing pronouns with\r\n                the entity, provided it occurs in the table). The replacements allowed are limited to one, and\r\n                annotators are also instructed to conserve fluency.\u003c/li\u003e\r\n              \u003cli\u003eSecondary Annotation: A second set of annotators is shown the output of Stage 4, and asked to fix it\r\n                if required to ensure it is grammatical.\u003c/li\u003e\r\n            \u003c/ol\u003e\r\n            \u003cp\u003eThe paper does not specifically describe the annotation platform or location profiles of the annotators.\r\n            \u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eWas Data Filtered?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWere text instances selected or filtered?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003ealgorithmically\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eFilter Criteria\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat were the selection criteria?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eAfter construction of the splits, the data curators filtered training examples that had rare table header\r\n              combinations (\u0026#x3C;=5 examples) and which had an overlap with the validation or test splits.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eStructured Annotations\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eAdditional Annotations?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDoes the dataset have additional annotations for each instance?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003enone\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eAnnotation Service?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWas an annotation service used?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eno\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eConsent\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eAny Consent Policy?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWas there a consent policy involved when gathering the data?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eyes\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eConsent Policy Details\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eWhat was the consent policy?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eAnnotators were full time employees that were aware of the goal of the project and consented to having\r\n              the data released as part of the dataset.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003ePrivate Identifying Information (PII)\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eContains PII?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDoes the source language data likely contain Personal Identifying Information about the data\r\n                    creators or subjects?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eno PII\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eJustification for no PII\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eProvide a justification for selecting \u003ccode\u003eno PII\u003c/code\u003e above.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eSince the source data is from wikipedia, only data in the public domain is included in the dataset.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eMaintenance\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eAny Maintenance Plan?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDoes the original dataset have a maintenance plan?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eyes\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eMaintenance Plan Details\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDescribe the original dataset's maintenance plan.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eFor submissions, you can delete your data by emailing \u003ca\r\n                href=\"mailto:totto@google.com\"\u003etotto@google.com\u003c/a\u003e from the email account used to sign up for the\r\n              submission. Deletion requests will be responded to within 60 days.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eMaintainer Contact Information\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eProvide contact information of a person responsible for the dataset maintenance\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eAnkur Parikh (\u003ca href=\"mailto:aparikh@google.com\"\u003eaparikh@google.com\u003c/a\u003e)\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eAny Contestation Mechanism?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDoes the maintenance plan include a contestation mechanism allowing individuals to request removal\r\n                    fo content?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eform submission\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eContestation Form Link\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eProvide the form link or contact information\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ca href=\"mailto:totto@google.com\"\u003etotto@google.com\u003c/a\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n    \u003c/div\u003e\r\n  \u003c/section\u003e\r\n\r\n  \u003csection class=\"datacard-section open\"\u003e\r\n\r\n    \u003cdiv class=\"datacard-section-preview\"\u003e\r\n      \u003ch3\u003eBroader Social Context\r\n\r\n        \u003cdiv class=\"tooltip\"\u003e\r\n          \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n          \u003cdiv class=\"tooltip-text\"\u003e\r\n            \u003cul\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003ePrevious Work on the Social Impact of the Dataset\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eImpact on Under-Served Communities\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eDiscussion of Biases\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n            \u003c/ul\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/h3\u003e\r\n      \u003cbutton class=\"expand-button\"\u003e\r\n        \u003csvg fill=\"#3c4f50\" height=\"24px\" viewBox=\"0 0 24 24\" width=\"24px\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\r\n          \u003cpath d=\"M0 0h24v24H0z\" fill=\"none\"\u003e\u003c/path\u003e\r\n          \u003cpath d=\"M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z\"\u003e\r\n          \u003c/path\u003e\r\n        \u003c/svg\u003e\r\n      \u003c/button\u003e\r\n    \u003c/div\u003e\r\n\r\n    \u003cdiv class=\"datacard-collapsible\"\u003e\r\n\r\n\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003ePrevious Work on the Social Impact of the Dataset\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eUsage of Models based on the Data\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eAre you aware of cases where models trained on the task featured in this dataset ore related tasks\r\n                    have been used in automated systems?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eno\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eImpact on Under-Served Communities\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eAddresses needs of underserved Communities?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDoes this dataset address the needs of communities that are traditionally underserved in language\r\n                    technology, and particularly language generation technology? Communities may be underserved for\r\n                    exemple because their language, language variety, or social or geographical context is\r\n                    underepresented in NLP and NLG resources (datasets and models).\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eno\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eDiscussion of Biases\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field telescope\"\u003e\r\n\r\n            \u003ch5\u003eAny Documented Social Biases?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eAre there documented social biases in the dataset? Biases in this context are variations in the\r\n                    ways members of different social categories are represented that can have harmful downstream\r\n                    consequences for members of the more disadvantaged group.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eyes\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eLinks and Summaries of Analysis Work\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eProvide links to and summaries of works analyzing these biases.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThe original work as well as our GEM paper analyzes some biases\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eAre the Language Producers Representative of the Language?\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDoes the distribution of language producers in the dataset accurately represent the full\r\n                    distribution of speakers of the language world-wide? If not, how does it differ?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThis dataset is created using tables and the table cell contents may hence naturally exhibit biases which\r\n              have been found to exist in Wikipedia such as some forms of gender bias (e.g \u003ca\r\n                href=\"https://labtomarket.files.wordpress.com/2018/01/wiki_gender_bias.pdf\"\u003e(Graells-Garido et\r\n                al.,2015)\u003c/a\u003e notes that spouse information is more likely discussed for females than males)\u003c/p\u003e\r\n            \u003cp\u003eThe table descriptions (targets/references) are, as discussed earlier, collected through a two-step\r\n              process.\u003c/p\u003e\r\n            \u003col\u003e\r\n              \u003cli\u003eThe natural text description near the table is taken as a starting point. This is Wikipedia article\r\n                text as created upto that point in time by a chain of collaborative edits from Wikipedia authors.\u003c/li\u003e\r\n              \u003cli\u003eThe initial description is revised by chain of two or more annotated revisions, to make it unambiguous\r\n                and faithful to a set of highlighted table cells.\u003c/li\u003e\r\n            \u003c/ol\u003e\r\n            \u003cp\u003eFrom their origin in 1), the descriptions may exhibit biases seen in Wikipedia text as mentioned above.\r\n              From their revisions in 2), the descriptions may show biases originating from annotator-authored text,\r\n              such as a preference for shorter descriptions since they're faster to write, or linguistic preferences\r\n              influenced by the locations dominant in the annotator distribution. (However, note that these are likely\r\n              to be much reduced since the annotators here are merely revising rather than completely authoring.\r\n              Moreover, each sentence goes through atleast two annotators, which acts as a check against the personal\r\n              biases of a single annotator.)\u003c/p\u003e\r\n            \u003cp\u003eNaturally-occurring text is also known to suffer from other biases such as reporting bias \u003ca\r\n                href=\"https://openreview.net/forum?id=AzxEzvpdE3Wcy\u0026#x26;noteId=vmR8qaby8fqxittps://labtomarket.files.wordpress.com/2018/01/wiki_gender_bias.pdf\"\u003e(Gordon\r\n                and Van Durme, 2013)\u003c/a\u003e - this also applies to this dataset via its origin from Wikipedia.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n    \u003c/div\u003e\r\n  \u003c/section\u003e\r\n\r\n  \u003csection class=\"datacard-section open\"\u003e\r\n\r\n    \u003cdiv class=\"datacard-section-preview\"\u003e\r\n      \u003ch3\u003eConsiderations for Using the Data\r\n\r\n        \u003cdiv class=\"tooltip\"\u003e\r\n          \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n          \u003cdiv class=\"tooltip-text\"\u003e\r\n            \u003cul\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003ePII Risks and Liability\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eLicenses\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n              \u003cli\u003e\r\n                \u003ch4\u003eKnown Technical Limitations\u003c/h4\u003e\r\n              \u003c/li\u003e\r\n            \u003c/ul\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/h3\u003e\r\n      \u003cbutton class=\"expand-button\"\u003e\r\n        \u003csvg fill=\"#3c4f50\" height=\"24px\" viewBox=\"0 0 24 24\" width=\"24px\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\r\n          \u003cpath d=\"M0 0h24v24H0z\" fill=\"none\"\u003e\u003c/path\u003e\r\n          \u003cpath d=\"M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z\"\u003e\r\n          \u003c/path\u003e\r\n        \u003c/svg\u003e\r\n      \u003c/button\u003e\r\n    \u003c/div\u003e\r\n\r\n    \u003cdiv class=\"datacard-collapsible\"\u003e\r\n\r\n\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003ePII Risks and Liability\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003ePotential PII Risk\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eConsidering your answers to the PII part of the Data Curation Section, describe any potential\r\n                    privacy to the data subjects and creators risks when using the dataset.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eSince the source data is from wikipedia, only data in the public domain is included in the dataset.\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eLicenses\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eCopyright Restrictions on the Dataset\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eBased on your answers in the Intended Use part of the Data Overview Section, which of the following\r\n                    best describe the copyright and licensing status of the dataset?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ccode\u003eopen license - commercial use allowed\u003c/code\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n\r\n          \u003cdiv class=\"datacard-field periscope\"\u003e\r\n\r\n            \u003ch5\u003eCopyright Restrictions on the Language Data\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eBased on your answers in the Language part of the Data Curation Section, which of the following\r\n                    best describe the copyright and licensing status of the underlying language data?\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003e\u003ccode\u003eopen license - commercial use allowed\u003c/code\u003e\u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n\r\n      \u003cdiv class=\"datacard-subsection\"\u003e\r\n        \u003ch4\u003eKnown Technical Limitations\u003c/h4\u003e\r\n\r\n\r\n        \u003cdiv class=\"datacard-field-wrapper\"\u003e\r\n\r\n          \u003cdiv class=\"datacard-field microscope\"\u003e\r\n\r\n            \u003ch5\u003eTechnical Limitations\r\n\r\n              \u003cdiv class=\"tooltip\"\u003e\r\n                \u003cdiv class=\"tooltip-icon\"\u003e\u003c/div\u003e\r\n                \u003cdiv class=\"tooltip-text\"\u003e\r\n                  \u003cp\u003eDescribe any known technical limitations, such as spurrious correlations, train/test overlap,\r\n                    annotation biases, or mis-annotations, and cite the works that first identified these limitations\r\n                    when possible.\u003c/p\u003e\r\n                \u003c/div\u003e\r\n              \u003c/div\u003e\r\n\r\n            \u003c/h5\u003e\r\n\r\n            \u003cp\u003eThe dataset is limited to topics that are present in Wikipedia, more specifically those topics that are\r\n              present in articles which contain atleast one table\r\n              \u003cem\u003eSports\u003c/em\u003e and \u003cem\u003eCountries\u003c/em\u003e form 53.4% of the dataset. The remaining fraction is made up of\r\n              broader topics like \u003cem\u003eEurope\u003c/em\u003e, \u003cem\u003eNorth America\u003c/em\u003eand \u003cem\u003ePolitics\u003c/em\u003e\r\n            \u003c/p\u003e\r\n          \u003c/div\u003e\r\n        \u003c/div\u003e\r\n\r\n      \u003c/div\u003e\r\n    \u003c/div\u003e\r\n  \u003c/section\u003e\r\n\u003c/div\u003e","title":"totto","type":"Data-to-Text","languages":"English","summary":"ToTTo is a high-quality English table-to-text dataset with more than 100,000 examples in which a table from Wikipedia with highlighted cells is paired with a sentence that describes the highlighted cells. All examples in the dataset were post-edited in multiple steps to ensure that the targets are fully faithful to the input information."}},"__N_SSG":true},"page":"/data_cards/[id]","query":{"id":"totto"},"buildId":"456T-gjsiPfCS_Gwi0APa","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>