<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><meta name="description" content="Benchmark natural language generation systems with GEM."/><meta property="og:image" content="https://og-image.now.sh/**GEM**%20Benchmark.png?theme=light&amp;md=1&amp;fontSize=100px&amp;images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fvercel-triangle-black.svg"/><meta name="og:title" content="GEM"/><meta name="twitter:card" content="summary_large_image"/><title>GEM Tasks</title><meta name="next-head-count" content="8"/><link rel="preload" href="/_next/static/css/a3e0e142709ba87c.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a3e0e142709ba87c.css" data-n-g=""/><link rel="preload" href="/_next/static/css/dfbff94633a4668c.css" as="style"/><link rel="stylesheet" href="/_next/static/css/dfbff94633a4668c.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-802c8e53e523ea8b.js" defer=""></script><script src="/_next/static/chunks/framework-a87821de553db91d.js" defer=""></script><script src="/_next/static/chunks/main-6dfdacc79861396c.js" defer=""></script><script src="/_next/static/chunks/pages/_app-f4e7aa7b46503ccf.js" defer=""></script><script src="/_next/static/chunks/cb1608f2-4ba41bd4c311e4ed.js" defer=""></script><script src="/_next/static/chunks/50-1fbacdd54a295188.js" defer=""></script><script src="/_next/static/chunks/pages/data_cards-3732495895dbf537.js" defer=""></script><script src="/_next/static/wY7mInOr_TjcaNnly8edR/_buildManifest.js" defer=""></script><script src="/_next/static/wY7mInOr_TjcaNnly8edR/_ssgManifest.js" defer=""></script><script src="/_next/static/wY7mInOr_TjcaNnly8edR/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="layout_background__qqb_S undefined"><header class="layout_header__kY0Lt"><div class="navbar_navwrapper__PQ35R"><div class="navbar_gradbar__2_FPI"></div><nav class="navbar_navbar__9q1fQ"><span class="utils_headingLg__5535D navbar_navbarlogo__R_s98"><a href="/">GEM BENCHMARK</a></span><div class="navbar_menutoggle__XS8Qx" id="mobile-menu"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="bars" class="svg-inline--fa fa-bars fa-w-14 navbar_bar___PSVO" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M16 132h416c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163 0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"></path></svg></div><ul><li class="navbar_navitem__wFPZL navbar_pushright__cG1uq"><a href="/resources">Resources</a></li><li class="navbar_navitem__wFPZL"><a href="/data_cards">Data Cards</a></li><li class="navbar_navitem__wFPZL"><a href="/model_cards">Model Cards</a></li><li class="navbar_navitem__wFPZL"><a href="/tutorials">tutorials</a></li><li class="navbar_navitem__wFPZL"><a href="/results">Results</a></li><li class="navbar_navitem__wFPZL"><a href="/papers">Papers</a></li><li class="navbar_navitem__wFPZL"><a href="/team">Team</a></li><li class="navbar_navitem__wFPZL"><a href="/workshop">Workshop</a></li></ul></nav></div></header><div class="layout_container__fbLkO undefined"><main><section><h2 class="utils_headingXl__u25Y2">List of Tasks</h2><p class="data_cards_description__CJI96">The list below links to data statements [<!-- --><a target="_blank" href="https://www.aclweb.org/anthology/Q18-1041/">1</a>, <!-- --><a target="_blank" href="https://arxiv.org/abs/1803.09010">2</a>] for each of the datasets that are part of GEM tasks. The template used to produce the initial statements and a guide on how to write them can be found here: [<!-- --><a download="" target="_blank" href="/statement_template.md">download template</a>] [<!-- --><a href="/tutorials/writing_a_data_card">view guide</a>]. We have released an extended version of this template and anÂ <!-- --><a target="_blank" href="https://huggingface.co/spaces/GEM/DatasetCardForm">interactive collection tool</a>.<!-- --></p><ul class="utils_list__4Mu4l"><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/conversational_weather">conversational_weather</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Data-to-Text</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">English</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">The purpose of this dataset is to assess how well a model can learn a template-like structure in a very low data setting. The task here is to produce a response to a weather-related query. The reply is further specified through the data attributes and discourse structure in the input. The output contains both the lexicalized text and discourse markers for attributes (e.g., `_ARG_TEMP_ 34`).</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/dart">dart</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Data-to-Text</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">English</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">DART is an English dataset aggregating multiple other data-to-text dataset in a common triple-based format. The new format is completely flat, thus not requiring a model to learn hierarchical structures, while still retaining the full information.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/e2e_nlg">e2e_nlg</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Data-to-Text</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">English</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">The E2E NLG dataset is an English benchmark dataset for data-to-text models that verbalize a set of 2-9 key-value attribute pairs in the restaurant domain. The version used for GEM is the cleaned E2E NLG dataset, which filters examples with hallucinations and outputs that don&#x27;t fully cover all input attributes.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/mlb_data_to_text">mlb_data_to_text</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Data-to-Text</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">English</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">The MLB dataset is an English sport-related data-to-text dataset in the baseball domain. The input is a large table with results of a game and the output is a description of the game.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/RotoWire_English-German">RotoWire_English-German</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Data-to-Text</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">English, German</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">This dataset is a data-to-text dataset in the basketball domain. The input are tables in a fixed format with statistics about a game (in English) and the target is a German translation of the originally English description. The translations were done by professional translators with basketball experience. The dataset can be used to evaluate the cross-lingual data-to-text capabilities of a model with complex inputs.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/sportsett_basketball">sportsett_basketball</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Data-to-Text</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">English</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">The sportsett dataset is an English data-to-text dataset in the basketball domain. The inputs are statistics summarizing an NBA game and the outputs are high-quality descriptions of the game in natural language.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/surface_realisation_st_2020">surface_realisation_st_2020</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Data-to-Text</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Arabic, Chinese, English, French, Hindi, Indonesian, Japanese, Korean, Portuguese, Russian, Spanish, Castilian</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">This dataset was used as part of the multilingual surface realization shared task in which a model gets full or partial universal dependency structures and has to reconstruct the natural language. This dataset support 11 languages.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/totto">totto</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Data-to-Text</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">English</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">ToTTo is a high-quality English table-to-text dataset with more than 100,000 examples in which a table from Wikipedia with highlighted cells is paired with a sentence that describes the highlighted cells. All examples in the dataset were post-edited in multiple steps to ensure that the targets are fully faithful to the input information.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/turku_hockey_data2text">turku_hockey_data2text</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Data-to-Text</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Finnish</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">This is a Finnish data-to-text dataset in which the input is structured information about a hockey game and the output a description of the game.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/viggo">viggo</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Data-to-Text</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">English</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">ViGGO is an English data-to-text generation dataset in the video game domain, with target responses being more conversational than information-seeking, yet constrained to the information presented in a meaning representation. The dataset is relatively small with about 5,000 datasets but very clean, and can thus serve for evaluating transfer learning, low-resource, or few-shot capabilities of neural models.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/web_nlg">web_nlg</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Data-to-Text</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Russian, English</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">WebNLG is a bi-lingual dataset (English, Russian) of parallel DBpedia triple sets and short texts that cover about 450 different DBpedia properties. The WebNLG data was originally created to promote the development of RDF verbalisers able to generate short text and to handle micro-planning (i.e., sentence segmentation and ordering, referring expression generation, aggregation); the goal of the task is to generate texts starting from 1 to 7 input triples which have entities in common (so the input is actually a connected Knowledge Graph). The dataset contains about 17,000 triple sets and 45,000 crowdsourced texts in English, and 7,000 triples sets and 19,000 crowdsourced texts in Russian. A challenging test set section with entities and/or properties that have not been seen at training time is available.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/CrossWOZ">CrossWOZ</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Dialog Response Generation</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Chinese</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">CrossWOZ is a Chinese multi-domain task-oriented dialogue dataset . It contains 6K dialogue sessions and 102K utterances for 5 domains, including hotel, restaurant, attraction, metro, and taxi. About 60{\%} of the dialogues have cross-domain user goals that favor inter-domain dependency and encourage natural transition across domains in conversation.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/cs_restaurants">cs_restaurants</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Dialog Response Generation</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Czech</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">The Czech Restaurants dataset is a task oriented dialog dataset in which a model needs to verbalize a response that a service agent could provide which is specified through a series of dialog acts. The dataset originated as a translation of an English dataset to test the generation capabilities of an NLG system on a highly morphologically rich language like Czech.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/RiSAWOZ">RiSAWOZ</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Dialog Response Generation</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Mandarin Chinese</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">RiSAWOZ is a Chinese dialog dataset. It can be used to study various dialogue tasks, such as Dialogue State Tracking, Dialogue Context-to-Text Generation, Coreference Resolution and Unified Generative Ellipsis and Coreference Resolution.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/schema_guided_dialog">schema_guided_dialog</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Dialog Response Generation</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">English</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">The GEM version of this dataset functions as a response generation dataset. The input specifies dialog acts that a model needs to verbalize. The Schema-Guided Dialog dataset is challenging since it comprises multiple domains from hotel and travel to restaurants, and a wide range of dialog acts. The context of each conversation is provided as well.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/Taskmaster">Taskmaster</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Dialog Response Generation</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">English</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">This is a large task-oriented dialog dataset in which a model has to produce the response. The input contains the context and a structured representation of what the model is supposed to generate. The input is already pre-formatted as string, turning this into a pure text-to-text problem.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/opusparcus">opusparcus</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Paraphrasing</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">German, English, Finnish, French, Russian, Swedish</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">Opusparcus is a paraphrase corpus for six European languages - German, English, Finnish, French, Russian, and Swedish. The paraphrases consist of subtitles from movies and TV shows.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/turku_paraphrase_corpus">turku_paraphrase_corpus</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Paraphrasing</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Finnish</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">This is a Finnish paraphrase corpus which consists of pairs of text passages, where a typical passage is about a sentence long. It can be used to either identify or generate paraphrases.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/squad_v2">squad_v2</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Question Generation</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">English</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">SQuAD2.0 is a dataset that tests the ability of a system to not only answer reading comprehension questions, but also abstain when presented with a question that cannot be answered based on the provided paragraph.  F1 score is used to evaluate models on the leaderboard. In GEM, we are using this dataset for the question-generation task in which a model should generate squad-like questions from an input text.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/ART">ART</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Reasoning</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">English</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">Abductive reasoning is inference to the most plausible explanation. For example, if Jenny finds her house in a mess when she returns from work, and remembers that she left a window open, she can hypothesize that a thief broke into her house and caused the mess, as the most plausible explanation. This data loader focuses on abductive NLG - a conditional English generation task for explaining given observations in natural language.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/common_gen">common_gen</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Reasoning</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">English</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">CommonGen is an English text generation task to explicitly test machines for the ability of generative commonsense reasoning. Given a set of common concepts, the task is to generate a coherent sentence describing an everyday scenario using these concepts. CommonGen is challenging because it inherently requires 1) relational reasoning using background commonsense knowledge, and 2) compositional generalization ability to work on unseen concept combinations. The dataset, constructed through a combination of crowd-sourcing from AMT and existing caption corpora, consists of 30k concept-sets and 50k sentences in total. Note that the CommonGen test set is private and requires submission to the external leaderboard.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/BiSECT">BiSECT</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Simplification</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">English, German, French, Spanish, Castilian</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">This dataset is composed of 1 million complex sentences with the task to split and simplify them while retaining the full meaning. Compared to other simplification corpora, BiSECT requires more significant edits. BiSECT offers splits in English, German, French, and Spanish.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/cochrane-simplification">cochrane-simplification</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Simplification</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">English</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">Cochrane is an English dataset for paragraph-level simplification of medical texts. Cochrane is a database of systematic reviews of clinical questions, many of which have summaries in plain English targeting readers without a university education. The dataset comprises about 4,500 of such pairs.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/SIMPITIKI">SIMPITIKI</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Simplification</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Italian</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">SIMPITIKI is an Italian Simplification dataset. Its examples were selected from Italian Wikipedia such that their editing tracking descriptions contain any of the words &quot;Simplified&quot;/&quot;Simplify&quot;/&quot;Simplification&quot;.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/wiki_auto_asset_turk">wiki_auto_asset_turk</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Simplification</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">English</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">WikiAuto is an English simplification dataset that we paired with ASSET and TURK, two very high-quality evaluation datasets, as test sets. The input is an English sentence taken from Wikipedia and the target a simplified sentence. ASSET and TURK contain the same test examples but have references that are simplified in different ways (splitting sentences vs. rewriting and splitting).</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/indonlg">indonlg</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Summarization</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Indonesian, Javanese, Sundanese</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">IndoNLG is a collection of various Indonesian, Javanese, and Sundanese NLG tasks including summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/mlsum">mlsum</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Summarization</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">German, Spanish, Castilian</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">MLSum is a multilingual summarization dataset crawled from different news websites. The GEM version supports the German and Spanish subset alongside specifically collected challenge sets for COVID-related articles to test out-of-domain generalization.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/OrangeSum">OrangeSum</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Summarization</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">French</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">OrangeSum is a French summarization dataset inspired by XSum. It features two subtasks - abstract generation and title generation. The data was sourced from &quot;Orange Actu&quot; articles between 2011 and 2020.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/wiki_cat_sum">wiki_cat_sum</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Summarization</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">English</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">WikiCatSum is an English summarization dataset in three domains - animals, companies, and film. It provides multiple paragraphs of text paired with a summary of the paragraphs.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/xlsum">xlsum</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Summarization</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Amharic, Arabic, Azerbaijani, Bengali, Bangla, Burmese, Chinese (family), English, French, Gujarati, Hausa, Hindi, Igbo, Indonesian, Japanese, Rundi, Korean, Kirghiz, Kyrgyz, Marathi, Nepali (individual language), Oromo, Pushto, Pashto, Persian, Ghanaian Pidgin English, Portuguese, Panjabi, Punjabi, Russian, Scottish Gaelic, Gaelic, Serbian, Romano-Serbian, Sinhala, Sinhalese, Somali, Spanish, Castilian, Swahili (individual language), Kiswahili, Tamil, Telugu, Thai, Tigrinya, Turkish, Ukrainian, Urdu, Uzbek, Vietnamese, Welsh, Yoruba</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">XLSum is a highly multilingual summarization dataset supporting 44 language. The data stems from BBC news articles.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/xsum">xsum</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Summarization</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">English</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">XSum is an English news summarization dataset where the task is to predict the first sentence of an article from the rest of it.</div></li><li class="utils_listItem__s2m6i"><a class="data_cards_larger__cB35Y" href="/data_cards/SciDuet">SciDuet</a><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">Text-to-Slide</small><span class="utils_smallSpace__n1Oyc"></span>|<!-- --><span class="utils_smallSpace__n1Oyc"></span><small class="utils_lightText__eUzGY">English</small><span class="utils_smallSpace__n1Oyc"></span><div class="data_cards_dataset__6BwH5">This dataset supports the document-to-slide generation task where a model has to generate presentation slide content from the text of a document.</div></li></ul></section></main><div class="layout_push__2FFZa"></div></div><footer class="layout_footer__dka_2 utils_eggshell__LF2UE"><span class="layout_backToHome__9sjx_"><a href="/">â Home</a></span><span>If you have any questions, please join our <!-- --><a href="https://groups.google.com/g/gem-benchmark" target="_blank" class="utils_accentUnderline__FmNQy">google group</a> for support.<!-- --></span></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"allTasksData":[{"id":"conversational_weather","title":"conversational_weather","type":"Data-to-Text","languages":"English","summary":"The purpose of this dataset is to assess how well a model can learn a template-like structure in a very low data setting. The task here is to produce a response to a weather-related query. The reply is further specified through the data attributes and discourse structure in the input. The output contains both the lexicalized text and discourse markers for attributes (e.g., `_ARG_TEMP_ 34`)."},{"id":"dart","title":"dart","type":"Data-to-Text","languages":"English","summary":"DART is an English dataset aggregating multiple other data-to-text dataset in a common triple-based format. The new format is completely flat, thus not requiring a model to learn hierarchical structures, while still retaining the full information."},{"id":"e2e_nlg","title":"e2e_nlg","type":"Data-to-Text","languages":"English","summary":"The E2E NLG dataset is an English benchmark dataset for data-to-text models that verbalize a set of 2-9 key-value attribute pairs in the restaurant domain. The version used for GEM is the cleaned E2E NLG dataset, which filters examples with hallucinations and outputs that don't fully cover all input attributes."},{"id":"mlb_data_to_text","title":"mlb_data_to_text","type":"Data-to-Text","languages":"English","summary":"The MLB dataset is an English sport-related data-to-text dataset in the baseball domain. The input is a large table with results of a game and the output is a description of the game."},{"id":"RotoWire_English-German","title":"RotoWire_English-German","type":"Data-to-Text","languages":"English, German","summary":"This dataset is a data-to-text dataset in the basketball domain. The input are tables in a fixed format with statistics about a game (in English) and the target is a German translation of the originally English description. The translations were done by professional translators with basketball experience. The dataset can be used to evaluate the cross-lingual data-to-text capabilities of a model with complex inputs."},{"id":"sportsett_basketball","title":"sportsett_basketball","type":"Data-to-Text","languages":"English","summary":"The sportsett dataset is an English data-to-text dataset in the basketball domain. The inputs are statistics summarizing an NBA game and the outputs are high-quality descriptions of the game in natural language."},{"id":"surface_realisation_st_2020","title":"surface_realisation_st_2020","type":"Data-to-Text","languages":"Arabic, Chinese, English, French, Hindi, Indonesian, Japanese, Korean, Portuguese, Russian, Spanish, Castilian","summary":"This dataset was used as part of the multilingual surface realization shared task in which a model gets full or partial universal dependency structures and has to reconstruct the natural language. This dataset support 11 languages."},{"id":"totto","title":"totto","type":"Data-to-Text","languages":"English","summary":"ToTTo is a high-quality English table-to-text dataset with more than 100,000 examples in which a table from Wikipedia with highlighted cells is paired with a sentence that describes the highlighted cells. All examples in the dataset were post-edited in multiple steps to ensure that the targets are fully faithful to the input information."},{"id":"turku_hockey_data2text","title":"turku_hockey_data2text","type":"Data-to-Text","languages":"Finnish","summary":"This is a Finnish data-to-text dataset in which the input is structured information about a hockey game and the output a description of the game."},{"id":"viggo","title":"viggo","type":"Data-to-Text","languages":"English","summary":"ViGGO is an English data-to-text generation dataset in the video game domain, with target responses being more conversational than information-seeking, yet constrained to the information presented in a meaning representation. The dataset is relatively small with about 5,000 datasets but very clean, and can thus serve for evaluating transfer learning, low-resource, or few-shot capabilities of neural models."},{"id":"web_nlg","title":"web_nlg","type":"Data-to-Text","languages":"Russian, English","summary":"WebNLG is a bi-lingual dataset (English, Russian) of parallel DBpedia triple sets and short texts that cover about 450 different DBpedia properties. The WebNLG data was originally created to promote the development of RDF verbalisers able to generate short text and to handle micro-planning (i.e., sentence segmentation and ordering, referring expression generation, aggregation); the goal of the task is to generate texts starting from 1 to 7 input triples which have entities in common (so the input is actually a connected Knowledge Graph). The dataset contains about 17,000 triple sets and 45,000 crowdsourced texts in English, and 7,000 triples sets and 19,000 crowdsourced texts in Russian. A challenging test set section with entities and/or properties that have not been seen at training time is available."},{"id":"CrossWOZ","title":"CrossWOZ","type":"Dialog Response Generation","languages":"Chinese","summary":"CrossWOZ is a Chinese multi-domain task-oriented dialogue dataset . It contains 6K dialogue sessions and 102K utterances for 5 domains, including hotel, restaurant, attraction, metro, and taxi. About 60{\\%} of the dialogues have cross-domain user goals that favor inter-domain dependency and encourage natural transition across domains in conversation."},{"id":"cs_restaurants","title":"cs_restaurants","type":"Dialog Response Generation","languages":"Czech","summary":"The Czech Restaurants dataset is a task oriented dialog dataset in which a model needs to verbalize a response that a service agent could provide which is specified through a series of dialog acts. The dataset originated as a translation of an English dataset to test the generation capabilities of an NLG system on a highly morphologically rich language like Czech."},{"id":"RiSAWOZ","title":"RiSAWOZ","type":"Dialog Response Generation","languages":"Mandarin Chinese","summary":"RiSAWOZ is a Chinese dialog dataset. It can be used to study various dialogue tasks, such as Dialogue State Tracking, Dialogue Context-to-Text Generation, Coreference Resolution and Unified Generative Ellipsis and Coreference Resolution."},{"id":"schema_guided_dialog","title":"schema_guided_dialog","type":"Dialog Response Generation","languages":"English","summary":"The GEM version of this dataset functions as a response generation dataset. The input specifies dialog acts that a model needs to verbalize. The Schema-Guided Dialog dataset is challenging since it comprises multiple domains from hotel and travel to restaurants, and a wide range of dialog acts. The context of each conversation is provided as well."},{"id":"Taskmaster","title":"Taskmaster","type":"Dialog Response Generation","languages":"English","summary":"This is a large task-oriented dialog dataset in which a model has to produce the response. The input contains the context and a structured representation of what the model is supposed to generate. The input is already pre-formatted as string, turning this into a pure text-to-text problem."},{"id":"opusparcus","title":"opusparcus","type":"Paraphrasing","languages":"German, English, Finnish, French, Russian, Swedish","summary":"Opusparcus is a paraphrase corpus for six European languages - German, English, Finnish, French, Russian, and Swedish. The paraphrases consist of subtitles from movies and TV shows."},{"id":"turku_paraphrase_corpus","title":"turku_paraphrase_corpus","type":"Paraphrasing","languages":"Finnish","summary":"This is a Finnish paraphrase corpus which consists of pairs of text passages, where a typical passage is about a sentence long. It can be used to either identify or generate paraphrases."},{"id":"squad_v2","title":"squad_v2","type":"Question Generation","languages":"English","summary":"SQuAD2.0 is a dataset that tests the ability of a system to not only answer reading comprehension questions, but also abstain when presented with a question that cannot be answered based on the provided paragraph.  F1 score is used to evaluate models on the leaderboard. In GEM, we are using this dataset for the question-generation task in which a model should generate squad-like questions from an input text."},{"id":"ART","title":"ART","type":"Reasoning","languages":"English","summary":"Abductive reasoning is inference to the most plausible explanation. For example, if Jenny finds her house in a mess when she returns from work, and remembers that she left a window open, she can hypothesize that a thief broke into her house and caused the mess, as the most plausible explanation. This data loader focuses on abductive NLG - a conditional English generation task for explaining given observations in natural language."},{"id":"common_gen","title":"common_gen","type":"Reasoning","languages":"English","summary":"CommonGen is an English text generation task to explicitly test machines for the ability of generative commonsense reasoning. Given a set of common concepts, the task is to generate a coherent sentence describing an everyday scenario using these concepts. CommonGen is challenging because it inherently requires 1) relational reasoning using background commonsense knowledge, and 2) compositional generalization ability to work on unseen concept combinations. The dataset, constructed through a combination of crowd-sourcing from AMT and existing caption corpora, consists of 30k concept-sets and 50k sentences in total. Note that the CommonGen test set is private and requires submission to the external leaderboard."},{"id":"BiSECT","title":"BiSECT","type":"Simplification","languages":"English, German, French, Spanish, Castilian","summary":"This dataset is composed of 1 million complex sentences with the task to split and simplify them while retaining the full meaning. Compared to other simplification corpora, BiSECT requires more significant edits. BiSECT offers splits in English, German, French, and Spanish."},{"id":"cochrane-simplification","title":"cochrane-simplification","type":"Simplification","languages":"English","summary":"Cochrane is an English dataset for paragraph-level simplification of medical texts. Cochrane is a database of systematic reviews of clinical questions, many of which have summaries in plain English targeting readers without a university education. The dataset comprises about 4,500 of such pairs."},{"id":"SIMPITIKI","title":"SIMPITIKI","type":"Simplification","languages":"Italian","summary":"SIMPITIKI is an Italian Simplification dataset. Its examples were selected from Italian Wikipedia such that their editing tracking descriptions contain any of the words \"Simplified\"/\"Simplify\"/\"Simplification\"."},{"id":"wiki_auto_asset_turk","title":"wiki_auto_asset_turk","type":"Simplification","languages":"English","summary":"WikiAuto is an English simplification dataset that we paired with ASSET and TURK, two very high-quality evaluation datasets, as test sets. The input is an English sentence taken from Wikipedia and the target a simplified sentence. ASSET and TURK contain the same test examples but have references that are simplified in different ways (splitting sentences vs. rewriting and splitting)."},{"id":"indonlg","title":"indonlg","type":"Summarization","languages":"Indonesian, Javanese, Sundanese","summary":"IndoNLG is a collection of various Indonesian, Javanese, and Sundanese NLG tasks including summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks."},{"id":"mlsum","title":"mlsum","type":"Summarization","languages":"German, Spanish, Castilian","summary":"MLSum is a multilingual summarization dataset crawled from different news websites. The GEM version supports the German and Spanish subset alongside specifically collected challenge sets for COVID-related articles to test out-of-domain generalization."},{"id":"OrangeSum","title":"OrangeSum","type":"Summarization","languages":"French","summary":"OrangeSum is a French summarization dataset inspired by XSum. It features two subtasks - abstract generation and title generation. The data was sourced from \"Orange Actu\" articles between 2011 and 2020."},{"id":"wiki_cat_sum","title":"wiki_cat_sum","type":"Summarization","languages":"English","summary":"WikiCatSum is an English summarization dataset in three domains - animals, companies, and film. It provides multiple paragraphs of text paired with a summary of the paragraphs."},{"id":"xlsum","title":"xlsum","type":"Summarization","languages":"Amharic, Arabic, Azerbaijani, Bengali, Bangla, Burmese, Chinese (family), English, French, Gujarati, Hausa, Hindi, Igbo, Indonesian, Japanese, Rundi, Korean, Kirghiz, Kyrgyz, Marathi, Nepali (individual language), Oromo, Pushto, Pashto, Persian, Ghanaian Pidgin English, Portuguese, Panjabi, Punjabi, Russian, Scottish Gaelic, Gaelic, Serbian, Romano-Serbian, Sinhala, Sinhalese, Somali, Spanish, Castilian, Swahili (individual language), Kiswahili, Tamil, Telugu, Thai, Tigrinya, Turkish, Ukrainian, Urdu, Uzbek, Vietnamese, Welsh, Yoruba","summary":"XLSum is a highly multilingual summarization dataset supporting 44 language. The data stems from BBC news articles."},{"id":"xsum","title":"xsum","type":"Summarization","languages":"English","summary":"XSum is an English news summarization dataset where the task is to predict the first sentence of an article from the rest of it."},{"id":"SciDuet","title":"SciDuet","type":"Text-to-Slide","languages":"English","summary":"This dataset supports the document-to-slide generation task where a model has to generate presentation slide content from the text of a document."}]},"__N_SSG":true},"page":"/data_cards","query":{},"buildId":"wY7mInOr_TjcaNnly8edR","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>