<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/favicon.ico"/><meta name="description" content="Benchmark natural language generation systems with GEM."/><meta property="og:image" content="https://og-image.now.sh/**GEM**%20Benchmark.png?theme=light&amp;md=1&amp;fontSize=100px&amp;images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fvercel-triangle-black.svg"/><meta name="og:title" content="GEM"/><meta name="twitter:card" content="summary_large_image"/><title>GEM 2024</title><meta name="next-head-count" content="8"/><link rel="preload" href="/_next/static/css/42fe94e3e660903d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/42fe94e3e660903d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/93c336621cfc84eb.css" as="style"/><link rel="stylesheet" href="/_next/static/css/93c336621cfc84eb.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js"></script><script src="/_next/static/chunks/webpack-635a834dfd7d0dc2.js" defer=""></script><script src="/_next/static/chunks/framework-7a7e500878b44665.js" defer=""></script><script src="/_next/static/chunks/main-a56c17dda72126ba.js" defer=""></script><script src="/_next/static/chunks/pages/_app-da8862f0ec3a97c1.js" defer=""></script><script src="/_next/static/chunks/c16184b3-ddb1b99b5e568a2a.js" defer=""></script><script src="/_next/static/chunks/50-3dccc3616b494db8.js" defer=""></script><script src="/_next/static/chunks/pages/shared_task-dd67867075ef15d0.js" defer=""></script><script src="/_next/static/64ekgEf2Sn1vpQfHbMHiq/_buildManifest.js" defer=""></script><script src="/_next/static/64ekgEf2Sn1vpQfHbMHiq/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="layout_background__oCFQX undefined"><header class="layout_header__SFlEE"><div class="navbar_navwrapper__RkXSe"><div class="navbar_gradbar__Vli6s"></div><nav class="navbar_navbar__vdWdK"><span class="utils_headingLg__RYtYb navbar_navbarlogo__u28NK"><a href="/">GEM BENCHMARK</a></span><div class="navbar_menutoggle__4Urrc" id="mobile-menu"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="bars" class="svg-inline--fa fa-bars navbar_bar__f8cyd" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg></div><ul><li class="navbar_navitem__15TsF navbar_pushright___9_8s"><a href="/resources">Resources</a></li><li class="navbar_navitem__15TsF"><a href="/data_cards">Data Cards</a></li><li class="navbar_navitem__15TsF"><a href="/model_cards">Model Cards</a></li><li class="navbar_navitem__15TsF"><a href="/tutorials">tutorials</a></li><li class="navbar_navitem__15TsF"><a href="/results">Results</a></li><li class="navbar_navitem__15TsF"><a href="/workshop">Workshop</a></li></ul></nav></div></header><div class="layout_container__FUycR undefined"><main><article><span class="utils_headingXl__zlq1q">GEM Shared Task at the Generation Challenges (INLG&#x27;24)</span><span class="utils_smallSpace__dcJPu"></span><div><h1 id="user-content-shared-task---gem-2024">Shared Task - GEM 2024</h1>
<h2 id="user-content-event">Event</h2>
<p>The GEM shared task is endorsed by <a href="https://aclweb.org/aclwiki/SIGGEN">SIGGEN</a>, and will be part of the Generation Challenges at INLG in Tokyo late September 2024. Participants will have the possibility to (i) publish a system description in the GenChal proceedings (available on the ACL anthology, see <a href="https://aclanthology.org/volumes/2023.inlg-genchal/">GenChal’23 Proceedings</a>), and (ii) present their results during the GenChal session at the INLG conference in Tokyo in September 2024, along with the shared task overview by the organizers.</p>
<h2 id="user-content-general-information">General information</h2>
<p>Our <strong><a href="https://nyustern.az1.qualtrics.com/jfe/form/SV_8qRqfdN3qBy3Bqe">pre-registration form</a></strong> is now available. Although this step is needed in order to receive the test data, submission will NOT be mandatory, so don't hesitate to fill in the form and play with the data! And if you do, please make sure you record the details of your experiments since you will be asked to write one model card per submission. The form will remain open until the submission deadline, but in case of high number of participants, priority for the human evaluation will be established according to the pre-registration date (earlier pre-registrations will be considered first).</p>
<p>This year, the GEM shared task features two main tasks: <strong>Data-to-text generation</strong> and <strong>Summarization</strong>, with a special emphasis on multilinguality; furthermore, no training data is provided, and the test data includes previously unpublished test sets; data illustrations are provided in <a href="https://docs.google.com/document/d/1xaGRNl-f6aOH7GWZCOwb745rGvBu-Mz7FtTyvOSmqBM/edit?usp=sharing">this online document</a>.</p>
<h2 id="user-content-data-to-text-task">Data-to-text Task</h2>
<p>The data-to-text task consists in generating texts from input triple sets in the WebNLG fashion, where each triple is made of Subject | Property | Object. There are two subtasks:</p>
<ul>
<li><strong>Subtask 1: WebNLG-based (D2T-1)</strong>: we use the official WebNLG test set (1,779 inputs) for the “seen” subtask; even though the WebNLG test set contains properties and entities not seen in the training/dev data, we consider the whole WebNLG dataset as seen since all splits (training/dev/test) have been available online for 3 years. The dataset contains 220 different properties; the original dataset specifications can be found on the <a href="https://synalp.gitlabpages.inria.fr/webnlg-challenge/challenge_2020/">WebNLG website</a>.</li>
<li><strong>Subtask 2: Wikidata-based (D2T-2)</strong>: we use new triple sets compiled from Wikidata (i.e. new properties and entities, 1,800 inputs) for the “unseen” subtask. The dataset contains 74 different properties, none of which were in WebNLG; more information about the Wikidata-based inputs can be found in <a href="https://aclanthology.org/2023.mmnlg-1.5.pdf">this paper</a></li>
</ul>
<p>For each subtask, there are 3 parallel datasets (see examples <a href="https://docs.google.com/document/d/1xaGRNl-f6aOH7GWZCOwb745rGvBu-Mz7FtTyvOSmqBM/edit?usp=sharing">here</a>):</p>
<ul>
<li><strong>Dataset 1: Factual (FA)</strong>: we use the triples as found in the WebNLG data and on Wikidata.</li>
<li><strong>Dataset 2: Counterfactual (CFA)</strong>: entities in the factual dataset are switched based on their class (e.g. a person entity is replaced by another person entity, a date by another date, etc.).</li>
<li><strong>Dataset 3: Fictional (FI)</strong>: entities in the factual datasets are replaced by made up entities (obtained via LLM prompting).</li>
</ul>
<p><strong>Data and languages:</strong> No training or development data is provided, only test data (2 sets of 3 test files); to get access to the test data, please pre-register using the link at the top of the page. We accept submissions of outputs in the following languages: English (en), Chinese (zh), German (de), Russian (ru), Spanish (es), Korean (ko), Hindi (hi), Swahili (sw), Arabic (ar). For both subtasks, a subset of the data/languages will be selected for human evaluation based on the number of submissions we receive for each language.</p>
<p><strong>DISCLAIMER:</strong> This dataset contains counterfactual and fictional data, so it is possible that in some (rare) cases, the resulting data could be judged offensive. In the counterfactual dataset for instance, real person names, roles, dates, locations etc. are switched, which can result in some unfortunate combinations; e.g. a work or a person can end up being associated with Adolf Hitler as author, employee, spouse… In the fictional dataset, entity names are made up by a language model and in theory cannot have the same form as existing known entities, but we cannot ensure that no entity will have a label that one could consider offensive.</p>
<p><strong>Submissions:</strong> Please submit your model outputs <a href="https://my.chateval.org/gemv3submit/">here</a>; you can perform a basic check of your output files <a href="https://github.com/mille-s/GEM24_CheckSystemOutputs">here</a>. Each team is expected to submit outputs for the 3 datasets of the subtask(s) they participate in, in three different files. As for the WebNLG shared tasks, each submission file must be a .txt file (UTF-8 encoding) where each text is true-cased and detokenized; see an <a href="https://synalp.gitlabpages.inria.fr/webnlg-challenge/files/submission-example-2020-nlg.txt">example</a> for English on the WebNLG page. In the submission files, each line should correspond to the verbalisation of one triple set: Line 1 should represent the verbalisation of the triple set with the ID=1, line 2 — the triple set with the ID=2, etc. If no output is produced, an empty line is expected, so all output files are expected to contain as many lines as there are inputs. Each submission file should be named with the (i) system name, (ii) subtask and dataset, and (iii) ISO 639-1 standard language id (see Data and languages above), separated by underscores: SystemX_[subtask]-[dataset]_[lang id].txt; for instance for a submission for the WebNLG subtask, Factual dataset in English: <strong>SystemX_D2T-1-FA_en.txt</strong>.</p>
<p><strong>Evaluation:</strong> Only human evaluation will be carried out, via 4 quality criteria: Grammaticality, Fluency, No-omissions, No-Additions; see definitions <a href="https://docs.google.com/document/d/1xaGRNl-f6aOH7GWZCOwb745rGvBu-Mz7FtTyvOSmqBM/edit?usp=sharing">here.</a></p>
<h2 id="user-content-summarization-task">Summarization Task</h2>
<p>The summarization task generates a concise summary based on the input text document. To make this task challenging, we focus on several different aspects of the task: underrepresented language (Swahili), cross-lingual, and long-context input.</p>
<p>There are three subtasks corresponding to the above aspects (see examples <a href="https://docs.google.com/document/d/1xaGRNl-f6aOH7GWZCOwb745rGvBu-Mz7FtTyvOSmqBM/edit?usp=sharing">here</a>):</p>
<ul>
<li><strong>Subtask 1: Underrepresented Language Summarization (Swahili).</strong> Both the input text document and the generated summary in this subtask are Swahili, which is usually not covered sufficiently in large language models (LLMs) as an underrepresented language. The dataset we use is the <a href="https://zenodo.org/records/4300294">Swahili news dataset</a>, which contains Swahili news articles collected from different websites. It was originally created for a classification task but we’ll use the input text (news article) as our input article for summarization [23,268 articles in train.csv].</li>
<li><strong>Subtask 2: Cross-lingual Summarization.</strong> This subtask checks the cross-lingual summarization setting between English and another language for both directions. The data is scraped from news websites similar to <a href="https://huggingface.co/datasets/csebuetnlp/xlsum">XLSum</a> <a href="https://aclanthology.org/2021.findings-acl.413/">(Hasan et al., 2021)</a>. For example, the input document is English and the generated summary is Chinese (en document → zh summary); the input document is Chinese and the generated summary is English (zh document → en summary). The languages covered can be found in the “Data and Languages” section below.</li>
<li><strong>Subtask 3: English Book Chapter Summarization.</strong> We test the English summarization with long-context input (e.g. book chapters) in this subtask. A recent work ( <a href="https://arxiv.org/abs/2105.08209">Kryściński et al., 2021</a>) has introduced an available dataset for long-context input along with human-written summaries. We’ll also leverage the undergraduate student reading group at NYU to acquire human references.</li>
</ul>
<p><strong>Data and languages:</strong> No training or development data is provided, only test data (1 testset per subtask); to get access to the test data, please pre-register using the link at the top of the page. For subtask 2, we require submissions of outputs in the following languages for the cross-lingual task: English (en), Chinese (zh), German (de), Russian (ru), Spanish (es), Korean (ko), Hindi (hi), Swahili (sw), Arabic (ar). For all tasks, a subset of the data/languages will be selected for human evaluation based on the number of submissions we receive for each language and on the available annotators.</p>
<p><strong>Submissions:</strong> Please submit your model outputs <a href="https://my.chateval.org/gemv3submit/">here</a>; you can perform a basic check of your output files <a href="https://github.com/mille-s/GEM24_CheckSystemOutputs">here</a>. Each team is expected to submit outputs for the subtask(s) they participate in. Each submission file should be named with the (i) system name, (ii) subtask, and (iii) ISO 639-1 standard language id.</p>
<ul>
<li>For subtask 1, we expect one output file in Swahili. The expected filename is <strong>SystemX_Summ-1_sw.jsonl</strong>.</li>
<li>For subtask 2, we expect at least one cross-lingual file and up to 8 files of the different languages from the input language. The file name for each language output should be in the format of SystemX_Summ-2_[lang id].jsonl (e.g., for Chinese: <strong>SystemX_Summ-2_zh.jsonl</strong>).</li>
<li>For subtask 3, we expect one output file in English that only includes the information in the book chapters. The expected filename is <strong>SystemX_Summ-3_en.jsonl</strong>.</li>
</ul>
<p>Each submission file must be a jsonl file (UTF-8 encoding) where each text is true-cased and detokenized; see an <a href="https://drive.google.com/file/d/1oeYfxX05BP_099AboVy499HVvgWBmcmY/view?usp=sharing">example</a> for English.</p>
<p><strong>Evaluation:</strong> Only human evaluation will be carried out, via 5 quality criteria: Understandability, Compactness, Grammaticality, Coherence, Faithfulness, Saliency; see definitions <a href="https://docs.google.com/document/d/1xaGRNl-f6aOH7GWZCOwb745rGvBu-Mz7FtTyvOSmqBM/edit?usp=sharing">here.</a></p>
<h2 id="user-content-important-dates">Important Dates</h2>
<p><code>February 20</code> GEM shared task launched, pre-registration open.</p>
<p><code>March 8</code> Deadline for pre-registering systems (pre-registration will remain open until the submission date; late pre-registrations do not guarantee participation to the human evaluation).</p>
<p><del>April 5</del> <code>April 11</code> Deadline for output submission (all tasks).</p>
<p><del>April6</del> <code>April 12</code> Human evaluation starts.</p>
<p><code>Before summer</code> Human evaluation results.</p>
<p><strong>System Descriptions and Analyses</strong></p>
<p><code>TBD</code> System Descriptions and Analyses due</p>
<p><code>TBD</code> Notification of Acceptance</p>
<p><code>TBD</code> Camera-ready due</p>
<p><code>Late September</code> GEM at the Generation Challenges session of INLG'24 in Tokyo.</p>
<p>To stay up-to-date on announcements, please join our <a href="https://groups.google.com/g/gem-benchmark">Google Group</a>. The same group may be used for questions and discussions.</p>
</div></article></main><div class="layout_push__lpoMK"></div></div><footer class="layout_footer__WlhMu utils_eggshell__3hbbY"><span class="layout_backToHome__D9QFr"><a href="/">← Home</a></span><span>If you have any questions, please join our <a href="https://groups.google.com/g/gem-benchmark" target="_blank" class="utils_accentUnderline__VG89l">google group</a> for support.</span></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"sharedTaskData":{"contentHtml":"\u003ch1 id=\"user-content-shared-task---gem-2024\"\u003eShared Task - GEM 2024\u003c/h1\u003e\n\u003ch2 id=\"user-content-event\"\u003eEvent\u003c/h2\u003e\n\u003cp\u003eThe GEM shared task is endorsed by \u003ca href=\"https://aclweb.org/aclwiki/SIGGEN\"\u003eSIGGEN\u003c/a\u003e, and will be part of the Generation Challenges at INLG in Tokyo late September 2024. Participants will have the possibility to (i) publish a system description in the GenChal proceedings (available on the ACL anthology, see \u003ca href=\"https://aclanthology.org/volumes/2023.inlg-genchal/\"\u003eGenChal’23 Proceedings\u003c/a\u003e), and (ii) present their results during the GenChal session at the INLG conference in Tokyo in September 2024, along with the shared task overview by the organizers.\u003c/p\u003e\n\u003ch2 id=\"user-content-general-information\"\u003eGeneral information\u003c/h2\u003e\n\u003cp\u003eOur \u003cstrong\u003e\u003ca href=\"https://nyustern.az1.qualtrics.com/jfe/form/SV_8qRqfdN3qBy3Bqe\"\u003epre-registration form\u003c/a\u003e\u003c/strong\u003e is now available. Although this step is needed in order to receive the test data, submission will NOT be mandatory, so don't hesitate to fill in the form and play with the data! And if you do, please make sure you record the details of your experiments since you will be asked to write one model card per submission. The form will remain open until the submission deadline, but in case of high number of participants, priority for the human evaluation will be established according to the pre-registration date (earlier pre-registrations will be considered first).\u003c/p\u003e\n\u003cp\u003eThis year, the GEM shared task features two main tasks: \u003cstrong\u003eData-to-text generation\u003c/strong\u003e and \u003cstrong\u003eSummarization\u003c/strong\u003e, with a special emphasis on multilinguality; furthermore, no training data is provided, and the test data includes previously unpublished test sets; data illustrations are provided in \u003ca href=\"https://docs.google.com/document/d/1xaGRNl-f6aOH7GWZCOwb745rGvBu-Mz7FtTyvOSmqBM/edit?usp=sharing\"\u003ethis online document\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"user-content-data-to-text-task\"\u003eData-to-text Task\u003c/h2\u003e\n\u003cp\u003eThe data-to-text task consists in generating texts from input triple sets in the WebNLG fashion, where each triple is made of Subject | Property | Object. There are two subtasks:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eSubtask 1: WebNLG-based (D2T-1)\u003c/strong\u003e: we use the official WebNLG test set (1,779 inputs) for the “seen” subtask; even though the WebNLG test set contains properties and entities not seen in the training/dev data, we consider the whole WebNLG dataset as seen since all splits (training/dev/test) have been available online for 3 years. The dataset contains 220 different properties; the original dataset specifications can be found on the \u003ca href=\"https://synalp.gitlabpages.inria.fr/webnlg-challenge/challenge_2020/\"\u003eWebNLG website\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSubtask 2: Wikidata-based (D2T-2)\u003c/strong\u003e: we use new triple sets compiled from Wikidata (i.e. new properties and entities, 1,800 inputs) for the “unseen” subtask. The dataset contains 74 different properties, none of which were in WebNLG; more information about the Wikidata-based inputs can be found in \u003ca href=\"https://aclanthology.org/2023.mmnlg-1.5.pdf\"\u003ethis paper\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFor each subtask, there are 3 parallel datasets (see examples \u003ca href=\"https://docs.google.com/document/d/1xaGRNl-f6aOH7GWZCOwb745rGvBu-Mz7FtTyvOSmqBM/edit?usp=sharing\"\u003ehere\u003c/a\u003e):\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eDataset 1: Factual (FA)\u003c/strong\u003e: we use the triples as found in the WebNLG data and on Wikidata.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDataset 2: Counterfactual (CFA)\u003c/strong\u003e: entities in the factual dataset are switched based on their class (e.g. a person entity is replaced by another person entity, a date by another date, etc.).\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDataset 3: Fictional (FI)\u003c/strong\u003e: entities in the factual datasets are replaced by made up entities (obtained via LLM prompting).\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eData and languages:\u003c/strong\u003e No training or development data is provided, only test data (2 sets of 3 test files); to get access to the test data, please pre-register using the link at the top of the page. We accept submissions of outputs in the following languages: English (en), Chinese (zh), German (de), Russian (ru), Spanish (es), Korean (ko), Hindi (hi), Swahili (sw), Arabic (ar). For both subtasks, a subset of the data/languages will be selected for human evaluation based on the number of submissions we receive for each language.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eDISCLAIMER:\u003c/strong\u003e This dataset contains counterfactual and fictional data, so it is possible that in some (rare) cases, the resulting data could be judged offensive. In the counterfactual dataset for instance, real person names, roles, dates, locations etc. are switched, which can result in some unfortunate combinations; e.g. a work or a person can end up being associated with Adolf Hitler as author, employee, spouse… In the fictional dataset, entity names are made up by a language model and in theory cannot have the same form as existing known entities, but we cannot ensure that no entity will have a label that one could consider offensive.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSubmissions:\u003c/strong\u003e Please submit your model outputs \u003ca href=\"https://my.chateval.org/gemv3submit/\"\u003ehere\u003c/a\u003e; you can perform a basic check of your output files \u003ca href=\"https://github.com/mille-s/GEM24_CheckSystemOutputs\"\u003ehere\u003c/a\u003e. Each team is expected to submit outputs for the 3 datasets of the subtask(s) they participate in, in three different files. As for the WebNLG shared tasks, each submission file must be a .txt file (UTF-8 encoding) where each text is true-cased and detokenized; see an \u003ca href=\"https://synalp.gitlabpages.inria.fr/webnlg-challenge/files/submission-example-2020-nlg.txt\"\u003eexample\u003c/a\u003e for English on the WebNLG page. In the submission files, each line should correspond to the verbalisation of one triple set: Line 1 should represent the verbalisation of the triple set with the ID=1, line 2 — the triple set with the ID=2, etc. If no output is produced, an empty line is expected, so all output files are expected to contain as many lines as there are inputs. Each submission file should be named with the (i) system name, (ii) subtask and dataset, and (iii) ISO 639-1 standard language id (see Data and languages above), separated by underscores: SystemX_[subtask]-[dataset]_[lang id].txt; for instance for a submission for the WebNLG subtask, Factual dataset in English: \u003cstrong\u003eSystemX_D2T-1-FA_en.txt\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eEvaluation:\u003c/strong\u003e Only human evaluation will be carried out, via 4 quality criteria: Grammaticality, Fluency, No-omissions, No-Additions; see definitions \u003ca href=\"https://docs.google.com/document/d/1xaGRNl-f6aOH7GWZCOwb745rGvBu-Mz7FtTyvOSmqBM/edit?usp=sharing\"\u003ehere.\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"user-content-summarization-task\"\u003eSummarization Task\u003c/h2\u003e\n\u003cp\u003eThe summarization task generates a concise summary based on the input text document. To make this task challenging, we focus on several different aspects of the task: underrepresented language (Swahili), cross-lingual, and long-context input.\u003c/p\u003e\n\u003cp\u003eThere are three subtasks corresponding to the above aspects (see examples \u003ca href=\"https://docs.google.com/document/d/1xaGRNl-f6aOH7GWZCOwb745rGvBu-Mz7FtTyvOSmqBM/edit?usp=sharing\"\u003ehere\u003c/a\u003e):\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eSubtask 1: Underrepresented Language Summarization (Swahili).\u003c/strong\u003e Both the input text document and the generated summary in this subtask are Swahili, which is usually not covered sufficiently in large language models (LLMs) as an underrepresented language. The dataset we use is the \u003ca href=\"https://zenodo.org/records/4300294\"\u003eSwahili news dataset\u003c/a\u003e, which contains Swahili news articles collected from different websites. It was originally created for a classification task but we’ll use the input text (news article) as our input article for summarization [23,268 articles in train.csv].\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSubtask 2: Cross-lingual Summarization.\u003c/strong\u003e This subtask checks the cross-lingual summarization setting between English and another language for both directions. The data is scraped from news websites similar to \u003ca href=\"https://huggingface.co/datasets/csebuetnlp/xlsum\"\u003eXLSum\u003c/a\u003e \u003ca href=\"https://aclanthology.org/2021.findings-acl.413/\"\u003e(Hasan et al., 2021)\u003c/a\u003e. For example, the input document is English and the generated summary is Chinese (en document → zh summary); the input document is Chinese and the generated summary is English (zh document → en summary). The languages covered can be found in the “Data and Languages” section below.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSubtask 3: English Book Chapter Summarization.\u003c/strong\u003e We test the English summarization with long-context input (e.g. book chapters) in this subtask. A recent work ( \u003ca href=\"https://arxiv.org/abs/2105.08209\"\u003eKryściński et al., 2021\u003c/a\u003e) has introduced an available dataset for long-context input along with human-written summaries. We’ll also leverage the undergraduate student reading group at NYU to acquire human references.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eData and languages:\u003c/strong\u003e No training or development data is provided, only test data (1 testset per subtask); to get access to the test data, please pre-register using the link at the top of the page. For subtask 2, we require submissions of outputs in the following languages for the cross-lingual task: English (en), Chinese (zh), German (de), Russian (ru), Spanish (es), Korean (ko), Hindi (hi), Swahili (sw), Arabic (ar). For all tasks, a subset of the data/languages will be selected for human evaluation based on the number of submissions we receive for each language and on the available annotators.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSubmissions:\u003c/strong\u003e Please submit your model outputs \u003ca href=\"https://my.chateval.org/gemv3submit/\"\u003ehere\u003c/a\u003e; you can perform a basic check of your output files \u003ca href=\"https://github.com/mille-s/GEM24_CheckSystemOutputs\"\u003ehere\u003c/a\u003e. Each team is expected to submit outputs for the subtask(s) they participate in. Each submission file should be named with the (i) system name, (ii) subtask, and (iii) ISO 639-1 standard language id.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFor subtask 1, we expect one output file in Swahili. The expected filename is \u003cstrong\u003eSystemX_Summ-1_sw.jsonl\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003eFor subtask 2, we expect at least one cross-lingual file and up to 8 files of the different languages from the input language. The file name for each language output should be in the format of SystemX_Summ-2_[lang id].jsonl (e.g., for Chinese: \u003cstrong\u003eSystemX_Summ-2_zh.jsonl\u003c/strong\u003e).\u003c/li\u003e\n\u003cli\u003eFor subtask 3, we expect one output file in English that only includes the information in the book chapters. The expected filename is \u003cstrong\u003eSystemX_Summ-3_en.jsonl\u003c/strong\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEach submission file must be a jsonl file (UTF-8 encoding) where each text is true-cased and detokenized; see an \u003ca href=\"https://drive.google.com/file/d/1oeYfxX05BP_099AboVy499HVvgWBmcmY/view?usp=sharing\"\u003eexample\u003c/a\u003e for English.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eEvaluation:\u003c/strong\u003e Only human evaluation will be carried out, via 5 quality criteria: Understandability, Compactness, Grammaticality, Coherence, Faithfulness, Saliency; see definitions \u003ca href=\"https://docs.google.com/document/d/1xaGRNl-f6aOH7GWZCOwb745rGvBu-Mz7FtTyvOSmqBM/edit?usp=sharing\"\u003ehere.\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"user-content-important-dates\"\u003eImportant Dates\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eFebruary 20\u003c/code\u003e GEM shared task launched, pre-registration open.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eMarch 8\u003c/code\u003e Deadline for pre-registering systems (pre-registration will remain open until the submission date; late pre-registrations do not guarantee participation to the human evaluation).\u003c/p\u003e\n\u003cp\u003e\u003cdel\u003eApril 5\u003c/del\u003e \u003ccode\u003eApril 11\u003c/code\u003e Deadline for output submission (all tasks).\u003c/p\u003e\n\u003cp\u003e\u003cdel\u003eApril6\u003c/del\u003e \u003ccode\u003eApril 12\u003c/code\u003e Human evaluation starts.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eBefore summer\u003c/code\u003e Human evaluation results.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSystem Descriptions and Analyses\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eTBD\u003c/code\u003e System Descriptions and Analyses due\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eTBD\u003c/code\u003e Notification of Acceptance\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eTBD\u003c/code\u003e Camera-ready due\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eLate September\u003c/code\u003e GEM at the Generation Challenges session of INLG'24 in Tokyo.\u003c/p\u003e\n\u003cp\u003eTo stay up-to-date on announcements, please join our \u003ca href=\"https://groups.google.com/g/gem-benchmark\"\u003eGoogle Group\u003c/a\u003e. The same group may be used for questions and discussions.\u003c/p\u003e\n"}},"__N_SSG":true},"page":"/shared_task","query":{},"buildId":"64ekgEf2Sn1vpQfHbMHiq","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>