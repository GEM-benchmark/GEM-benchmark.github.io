---
title: surface_realisation_st_2020
type: Data-to-Text
languages: Arabic, Chinese, English, French, Hindi, Indonesian, Japanese, Korean, Portuguese, Russian, Spanish, Castilian
summary: This dataset was used as part of the multilingual surface realization shared task in which a model gets full or partial universal dependency structures and has to reconstruct the natural language. This dataset support 11 languages.
---
<div class="datacard">

  <section class="datacard-section">
    <div class="datacard-summary">
      <h2>surface_realisation_st_2020</h2>
      <div class="summary-content">
        <p>This dataset was used as part of the multilingual surface realization shared task in which a model gets full
          or partial universal dependency structures and has to reconstruct the natural language. This dataset support
          11 languages.</p>
        <p>You can load the dataset via:</p>

        <div class="code-wrapper">
          <div class="toolbar">
            <div class="copy-icon" title="Click to copy code block"></div>
            <div class="expand-modal-icon" title="Click to expand code block"></div>
          </div>
          <pre><code>import datasets
data = datasets.load_dataset('GEM/surface_realisation_st_2020')
</code></pre>
        </div>

        <p>The data loader can be found <a
            href="https://huggingface.co/datasets/GEM/surface_realisation_st_2020">here</a>.</p>
      </div>
    </div>

    <div class="datacard-field-wrapper">

      <div class="datacard-field">

        <h5>website

        </h5>

        <p><a href="http://taln.upf.edu/pages/msr2020-ws/SRST.html#data">Website</a></p>
      </div>

      <div class="datacard-field">

        <h5>paper

        </h5>

        <p><a href="https://aclanthology.org/2020.msr-1.1/">ACL Anthology</a></p>
      </div>

      <div class="datacard-field">

        <h5>authors

        </h5>

        <p>Simon Mille (Pompeu Fabra University); Leo Wanner (Pompeu Fabra University); Anya Belz (Brighton University);
          Bernd Bohnet (Google Inc.); Thiago Castro Ferreira (Federal University of Minas Gerais); Yvette Graham
          (ADAPT/Trinity College Dublin)</p>
      </div>
    </div>

  </section>

  <section class="datacard-section quick">
    <h3 class="section-title">Quick-Use</h3>

    <div class="datacard-field-wrapper">

      <div class="datacard-field periscope">

        <h5>Contact Name

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>If known, provide the name of at least one person the reader can contact for questions about the
                dataset.</p>
            </div>
          </div>

        </h5>

        <p>Simon Mille</p>
      </div>

      <div class="datacard-field telescope">

        <h5>Multilingual?

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>Is the dataset multilingual?</p>
            </div>
          </div>

        </h5>

        <p>yes</p>
      </div>

      <div class="datacard-field telescope">

        <h5>Covered Languages

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>What languages/dialects are covered in the dataset?</p>
            </div>
          </div>

        </h5>

        <p><code>Arabic</code>, <code>Chinese</code>, <code>English</code>, <code>French</code>, <code>Hindi</code>,
          <code>Indonesian</code>, <code>Japanese</code>, <code>Korean</code>, <code>Portuguese</code>,
          <code>Russian</code>, <code>Spanish, Castilian</code></p>
      </div>

      <div class="datacard-field telescope">

        <h5>License

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>What is the license of the dataset?</p>
            </div>
          </div>

        </h5>

        <p>cc-by-2.5: Creative Commons Attribution 2.5 Generic</p>
      </div>

      <div class="datacard-field periscope">

        <h5>Communicative Goal

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>Provide a short description of the communicative goal of a model trained for this task on this dataset.
              </p>
            </div>
          </div>

        </h5>

        <p>The models are able to introduce surface features (syntax, morphology, topology) from more or less abstract
          inputs in different, the most abstract being predicate-argument structures. The datasets cover a large variety
          of domains (news, blogs, forums, wikipedia pages, etc.).</p>
      </div>

      <div class="datacard-field telescope">

        <h5>Additional Annotations?

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>Does the dataset have additional annotations for each instance?</p>
            </div>
          </div>

        </h5>

        <p>none</p>
      </div>

      <div class="datacard-field telescope">

        <h5>Contains PII?

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>Does the source language data likely contain Personal Identifying Information about the data creators
                or subjects?</p>
            </div>
          </div>

        </h5>

        <p>unlikely</p>
      </div>
    </div>

  </section>


  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Dataset Overview

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Where to find the Data and its Documentation</h4>
              </li>
              <li>
                <h4>Languages and Intended Use</h4>
              </li>
              <li>
                <h4>Credit</h4>
              </li>
              <li>
                <h4>Dataset Structure</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Where to find the Data and its Documentation</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Webpage

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the webpage for the dataset (if it exists)?</p>
                </div>
              </div>

            </h5>

            <p><a href="http://taln.upf.edu/pages/msr2020-ws/SRST.html#data">Website</a></p>
          </div>

          <div class="datacard-field telescope">

            <h5>Download

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the link to where the original dataset is hosted?</p>
                </div>
              </div>

            </h5>

            <p><a
                href="https://sites.google.com/site/genchalrepository/surface-realisation/sr-20-multilingual">Website</a>
            </p>
          </div>

          <div class="datacard-field telescope">

            <h5>Paper

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the link to the paper describing the dataset (open access preferred)?</p>
                </div>
              </div>

            </h5>

            <p><a href="https://aclanthology.org/2020.msr-1.1/">ACL Anthology</a></p>
          </div>

          <div class="datacard-field microscope">

            <h5>BibTex

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Provide the BibTex-formatted reference for the dataset. Please use the correct published version
                    (ACL anthology, etc.) instead of google scholar created Bibtex.</p>
                </div>
              </div>

            </h5>


            <div class="code-wrapper">
              <div class="toolbar">
                <div class="copy-icon" title="Click to copy code block"></div>
                <div class="expand-modal-icon" title="Click to expand code block"></div>
              </div>
              <pre><code>@inproceedings{mille-etal-2020-third,
title = "The Third Multilingual Surface Realisation Shared Task ({SR}{'}20): Overview and Evaluation Results",
author = "Mille, Simon  and
Belz, Anya  and
Bohnet, Bernd  and
Castro Ferreira, Thiago  and
Graham, Yvette  and
Wanner, Leo",
booktitle = "Proceedings of the Third Workshop on Multilingual Surface Realisation",
month = dec,
year = "2020",
address = "Barcelona, Spain (Online)",
publisher = "Association for Computational Linguistics",
url = "https://aclanthology.org/2020.msr-1.1",
pages = "1--20",
abstract = "This paper presents results from the Third Shared Task on Multilingual Surface Realisation (SR{'}20) which was organised as part of the COLING{'}20 Workshop on Multilingual Surface Realisation. As in SR{'}18 and SR{'}19, the shared task comprised two tracks: (1) a Shallow Track where the inputs were full UD structures with word order information removed and tokens lemmatised; and (2) a Deep Track where additionally, functional words and morphological information were removed. Moreover, each track had two subtracks: (a) restricted-resource, where only the data provided or approved as part of a track could be used for training models, and (b) open-resource, where any data could be used. The Shallow Track was offered in 11 languages, whereas the Deep Track in 3 ones. Systems were evaluated using both automatic metrics and direct assessment by human evaluators in terms of Readability and Meaning Similarity to reference outputs. We present the evaluation results, along with descriptions of the SR{'}19 tracks, data and evaluation methods, as well as brief summaries of the participating systems. For full descriptions of the participating systems, please see the separate system reports elsewhere in this volume.",
}
</code></pre>
            </div>

          </div>

          <div class="datacard-field periscope">

            <h5>Contact Name

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>If known, provide the name of at least one person the reader can contact for questions about the
                    dataset.</p>
                </div>
              </div>

            </h5>

            <p>Simon Mille</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Contact Email

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>If known, provide the email of at least one person the reader can contact for questions about the
                    dataset.</p>
                </div>
              </div>

            </h5>

            <p><a href="mailto:sfmille@gmail.com">sfmille@gmail.com</a></p>
          </div>

          <div class="datacard-field telescope">

            <h5>Has a Leaderboard?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the dataset have an active leaderboard?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Languages and Intended Use</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Multilingual?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Is the dataset multilingual?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Covered Dialects

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What dialects are covered? Are there multiple dialects per language?</p>
                </div>
              </div>

            </h5>

            <p>No multiple dialects.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Covered Languages

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What languages/dialects are covered in the dataset?</p>
                </div>
              </div>

            </h5>

            <p><code>Arabic</code>, <code>Chinese</code>, <code>English</code>, <code>French</code>, <code>Hindi</code>,
              <code>Indonesian</code>, <code>Japanese</code>, <code>Korean</code>, <code>Portuguese</code>,
              <code>Russian</code>, <code>Spanish, Castilian</code></p>
          </div>

          <div class="datacard-field periscope">

            <h5>Whose Language?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Whose language is in the dataset?</p>
                </div>
              </div>

            </h5>

            <p>Unknown</p>
          </div>

          <div class="datacard-field telescope">

            <h5>License

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the license of the dataset?</p>
                </div>
              </div>

            </h5>

            <p>cc-by-2.5: Creative Commons Attribution 2.5 Generic</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Intended Use

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the intended use of the dataset?</p>
                </div>
              </div>

            </h5>

            <p>The dataset is intended to be used for training models to solve several NLG subtasks, such as function
              word introduction, morphological agreement resolution, word order determination and inflection generation.
            </p>
            <p>Comment about the license: the dataset has multiple licences, since each original dataset has their own
              type of licence. All datasets but one are CC-BY and subclasses of it, the other one is GPL (French
              Sequoia).</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Primary Task

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What primary task does the dataset support?</p>
                </div>
              </div>

            </h5>

            <p>Data-to-Text</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Communicative Goal

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Provide a short description of the communicative goal of a model trained for this task on this
                    dataset.</p>
                </div>
              </div>

            </h5>

            <p>The models are able to introduce surface features (syntax, morphology, topology) from more or less
              abstract inputs in different, the most abstract being predicate-argument structures. The datasets cover a
              large variety of domains (news, blogs, forums, wikipedia pages, etc.).</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Credit</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Curation Organization Type(s)

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>In what kind of organization did the dataset curation happen?</p>
                </div>
              </div>

            </h5>

            <p><code>industry</code>, <code>academic</code></p>
          </div>

          <div class="datacard-field periscope">

            <h5>Curation Organization(s)

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Name the organization(s).</p>
                </div>
              </div>

            </h5>

            <p>Pompeu Fabra University, Google Inc., University of Brighton, Federal University of Minas Gerais,
              ADAPT/Trinity College Dublin</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Dataset Creators

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Who created the original dataset? List the people involved in collecting the dataset and their
                    affiliation(s).</p>
                </div>
              </div>

            </h5>

            <p>Simon Mille (Pompeu Fabra University); Leo Wanner (Pompeu Fabra University); Anya Belz (Brighton
              University); Bernd Bohnet (Google Inc.); Thiago Castro Ferreira (Federal University of Minas Gerais);
              Yvette Graham (ADAPT/Trinity College Dublin)</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Funding

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Who funded the data creation?</p>
                </div>
              </div>

            </h5>

            <p>Mostly EU funds via H2020 projects</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Who added the Dataset to GEM?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Who contributed to the data card and adding the dataset to GEM? List the people+affiliations
                    involved in creating this data card and who helped integrate this dataset into GEM.</p>
                </div>
              </div>

            </h5>

            <p>Simon Mille (Pompeu Fabra University)</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Dataset Structure</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Data Fields

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>List and describe the fields present in the dataset.</p>
                </div>
              </div>

            </h5>

            <p><code>input</code> (string): this field contains an input tree in CoNLL-U format; the CoNLL-U format is a
              one-word-per-line format with the following tab-separated 10 columns (see <a
                href="http://universaldependencies.org/format.html">here</a>): [1] Position, [2] Lemma, [3] Wordform,
              [4] Part of Speech, [5] Fine-grained Part of Speech (if available), [6] Features (FEATS), [7] governor,
              [8] dependency relation, [9] additional dependency information, and [10] metadata. For the surface task,
              the input is a Universal Dependency tree of a given language in which the word order was scrambled and the
              surface forms removed (only lemmas are available); for the deep task, the input is a tree derived from the
              surface input, with predicate-argument relations between content words only (function words were removed)
              and without any morphological agreement information.</p>
            <p><code>target_tokenized</code> (string): this field contains the target sentence to generate, in which
              every non-initial and non-final token is surrounded by two spaces. This output is usually used for
              automatic evaluations.</p>
            <p><code>target</code> (string): this field contains the detokenised target sentence to generate. This
              output is usually used for human evaluations.</p>
            <p><code>gem_id</code> (string): a unique ID.</p>
            <p><code>sentence_id</code> (string): the original ID of a sentence in the UD dataset.</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Reason for Structure

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>How was the dataset structure determined?</p>
                </div>
              </div>

            </h5>

            <p>The structure of the input (CoNLL-U) was chosen according to the standards in parsing, and because the
              original UD datasets were provided in this format.</p>
          </div>

          <div class="datacard-field microscope">

            <h5>How were labels chosen?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>How were the labels chosen?</p>
                </div>
              </div>

            </h5>

            <p>The input labels for the surface track are the original labels in the UD treebanks; see <a
                href="https://universaldependencies.org/u/dep/index.html">here</a> for the dependencies, <a
                href="https://universaldependencies.org/u/feat/index.html">here</a> for the features, and <a
                href="https://universaldependencies.org/u/pos/index.html">here</a> for the PoS tags.</p>
            <p>The input labels for the deep track are a subset of the PoS tags and features of the surface track, and
              for the relations, universal predicate-argument relations augmented with a few specific relations to
              capture coordinations and named entity relations for instance.</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Example Instance

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Provide a JSON formatted example of a typical instance in the dataset.</p>
                </div>
              </div>

            </h5>


            <div class="code-wrapper">
              <div class="toolbar">
                <div class="copy-icon" title="Click to copy code block"></div>
                <div class="expand-modal-icon" title="Click to expand code block"></div>
              </div>
              <pre><code>{"input": "1\tGoogle\t_\tPROPN\tNNP\tNumber=Sing\t5\tnsubj\t_\t_\n2\t\t_\tPUNCT\t.\tlin=+1\t5\tpunct\t_\t_\n3\tinto\t_\tADP\tIN\t_\t6\tcase\t_\t_\n4\tif\t_\tSCONJ\tIN\t_\t5\tmark\t_\t_\n5\tmorph\t_\tVERB\tVBD\tMood=Ind|Tense=Past|VerbForm=Fin\t7\tadvcl\t_\t_\n6\tGoogleOS\t_\tPROPN\tNNP\tNumber=Sing\t5\tobl\t_\t_\n7\twhat\t_\tPRON\tWP\tPronType=Int\t0\troot\t_\t_", "target_tokenized": "What if Google Morphed Into GoogleOS ?", "target": "What if Google Morphed Into GoogleOS?", "gem_id": "GEM-surface_realisation_st_2020-T1-test-en_ewt-ud-test-0", "sentence_id": ""}
</code></pre>
            </div>

          </div>

          <div class="datacard-field periscope">

            <h5>Data Splits

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Describe and name the splits in the dataset if there are more than one.</p>
                </div>
              </div>

            </h5>

            <p>There are 119 splits in the dataset:</p>
            <ul>
              <li>29 training sets, which correspond to 20 UD datasets (11 languages), 9 of which have both surface and
                deep inputs (3 languages);</li>
              <li>29 development set which correspond to the 29 training sets above;</li>
              <li>29 test sets for the data described above;</li>
              <li>4 out-of-domain test sets, 3 surface inputs and 1 deep one (3 languages for which PUD out-of-domain
                datasets were available);</li>
              <li>9 automatically parsed in-domain test sets, 6 surface inputs and 3 deep inputs (6 languages for which
                good UD parsers were available);</li>
              <li>9 automatically parsed out-of-domain test sets, 6 surface inputs and 3 deep inputs (6 languages for
                which we were able to create clean Wikipedia text and that had a good UD parser).</li>
            </ul>
          </div>

          <div class="datacard-field microscope">

            <h5>Splitting Criteria

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Describe any criteria for splitting the data, if used. If there are differences between the splits
                    (e.g., if the training annotations are machine-generated and the dev and test ones are created by
                    humans, or if different numbers of annotators contributed to each example), describe them here.</p>
                </div>
              </div>

            </h5>

            <p>Described above for more clarity.</p>
          </div>

          <div class="datacard-field microscope">

            <h5>

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What does an outlier of the dataset in terms of length/perplexity/embedding look like?</p>
                </div>
              </div>

            </h5>

            <p>An outlier would usually be an input that corresponds to a very long sentence (e.g. 159 words in English,
              when the average number of words per sentence is around 25).</p>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Dataset in GEM

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Rationale for Inclusion in GEM</h4>
              </li>
              <li>
                <h4>GEM-Specific Curation</h4>
              </li>
              <li>
                <h4>Getting Started with the Task</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Rationale for Inclusion in GEM</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field microscope">

            <h5>Why is the Dataset in GEM?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What does this dataset contribute toward better generation evaluation and why is it part of GEM?
                  </p>
                </div>
              </div>

            </h5>

            <p>The datset includes languages from different families and some languages not often used in NLG (e.g.
              Arabic, Indonesian, Korean, Hindi). It proposes two tasks, which can be tackled both separately and in one
              shot, with different levels of difficulty: the most superficial task (T1) consits in ordering and
              inflecting some trees, and the deeper task (T2) includes extra tasks such as defining the syntactic
              structure and introducing function words and morphological agreement information. Both tasks can allow for
              developing modules for pipeline NLG architectures. T1 is rather straightforward to evaluate: BLEU works
              quite well for some languages since all the words are present in the input and few word orders only can be
              possible for a syntactic tree. But T2 is more challenging to evaluate, since more outputs are correct
              given one particular input.</p>
            <p>There is a large variety of sizes in the datasets, both clean and noisy data, parallel data in different
              languages, and many already available system outputs to use as baselines.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Similar Datasets

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Do other datasets for the high level task exist?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Unique Language Coverage

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does this dataset cover other languages than other datasets for the same task?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Difference from other GEM datasets

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What else sets this dataset apart from other similar datasets in GEM?</p>
                </div>
              </div>

            </h5>

            <p>This is possibly the only dataset that starts the generation process from predicate-argument structures
              and from syntactic structures. It also has parallel datasets in a few languages (coming from the PUD
              parallel annotations).</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Ability that the Dataset measures

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What aspect of model ability can be measured with this dataset?</p>
                </div>
              </div>

            </h5>

            <p>Syntacticisation, functional word introduction, word order resolution, agreement resolution,
              morphological inflection</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>GEM-Specific Curation</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Modificatied for GEM?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Has the GEM version of the dataset been modified in any way (data, processing, splits) from the
                    original curated data?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Additional Splits?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does GEM provide additional splits to the dataset?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Getting Started with the Task</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field microscope">

            <h5>Pointers to Resources

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Getting started with in-depth research on the task. Add relevant pointers to resources that
                    researchers can consult when they want to get started digging deeper into the task.</p>
                </div>
              </div>

            </h5>

            <p><a href="http://taln.upf.edu/pages/msr2020-ws/SRST.html">Website</a></p>
          </div>

          <div class="datacard-field microscope">

            <h5>Technical Terms

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Technical terms used in this card and the dataset and their definitions</p>
                </div>
              </div>

            </h5>

            <p>Syntacticisation: prediction of the syntactic</p>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Previous Results

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Previous Results</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Previous Results</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Measured Model Abilities

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What aspect of model ability can be measured with this dataset?</p>
                </div>
              </div>

            </h5>

            <p>Syntacticisation, functional word introduction, word order resolution, morphological agreement
              resolution, morphological inflection</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Metrics

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What metrics are typically used for this task?</p>
                </div>
              </div>

            </h5>

            <p><code>BLEU</code>, <code>BERT-Score</code>, <code>Other: Other Metrics</code></p>
          </div>

          <div class="datacard-field periscope">

            <h5>Other Metrics

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Definitions of other metrics</p>
                </div>
              </div>

            </h5>

            <p>NIST: n-gram similarity metric weighted in favour of less frequent n-grams which are taken to be more
              informative.</p>
            <p>Normalised edit distance (DIST): inverse, normalised, character-based string-edit distance that starts by
              computing the minimum number of character inserts, deletes and substitutions (all at cost 1) required to
              turn the system output into the (single) reference text.</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Proposed Evaluation

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>List and describe the purpose of the metrics and evaluation methodology (including human
                    evaluation) that the dataset creators used when introducing this task.</p>
                </div>
              </div>

            </h5>

            <p>BLEU, NIST, BERTScore and DIST simply aim at calculating in different ways the similarity between a
              predicted and a reference sentence.</p>
            <p>Two additional criteria have been used for human evaluation, Readability and Meaning SImilarity. The
              statement to be assessed in the Readability evaluation was: "The text reads well and is free from
              grammatical errors and awkward constructions.". The corresponding statement in the Meaning Similarity
              evaluation, in which system outputs (‘the black text’) were compared to reference sentences (‘the gray
              text’), was: "The meaning of the gray text is adequately expressed by the black text."</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Previous results available?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Are previous results available?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Other Evaluation Approaches

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What evaluation approaches have others used?</p>
                </div>
              </div>

            </h5>

            <p>Same as above.</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Relevant Previous Results

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What are the most relevant previous results for this task/dataset?</p>
                </div>
              </div>

            </h5>

            <ul>
              <li><a href="https://aclanthology.org/2020.acl-main.134/">Fast and Accurate Non-Projective Dependency Tree
                  Linearization</a></li>
              <li><a href="https://aclanthology.org/2020.acl-main.665/">Shape of Synth to Come: Why We Should Use
                  Synthetic Data for English Surface Realization</a></li>
            </ul>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Dataset Curation

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Original Curation</h4>
              </li>
              <li>
                <h4>Language Data</h4>
              </li>
              <li>
                <h4>Structured Annotations</h4>
              </li>
              <li>
                <h4>Consent</h4>
              </li>
              <li>
                <h4>Private Identifying Information (PII)</h4>
              </li>
              <li>
                <h4>Maintenance</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Original Curation</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Original Curation Rationale

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Original curation rationale</p>
                </div>
              </div>

            </h5>

            <p>The datasets were created in the context of the Surface Realisation Shared Task series.</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Communicative Goal

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What was the communicative goal?</p>
                </div>
              </div>

            </h5>

            <p>The dataset's objective was to allow for training systems to perform tasks related to surface realisation
              (introduction of function words, syntacticisation, resolution of morphological agreements, word order
              resolution, inflection generation.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Sourced from Different Sources

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Is the dataset aggregated from different data sources?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Source Details

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>List the sources (one per line)</p>
                </div>
              </div>

            </h5>

            <p>Each of the 20 used UD datasets comes from various sources, all listed on the individual page of each UD
              treeebank (<a href="https://universaldependencies.org/">https://universaldependencies.org/</a>).</p>
            <p>Additional test sets were created for the task, and were obtained from Wikipedia pages for 6 languages.
            </p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Language Data</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>How was Language Data Obtained?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>How was the language data obtained?</p>
                </div>
              </div>

            </h5>

            <p><code>Found</code></p>
          </div>

          <div class="datacard-field telescope">

            <h5>Where was it found?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>If found, where from?</p>
                </div>
              </div>

            </h5>

            <p><code>Multiple websites</code></p>
          </div>

          <div class="datacard-field microscope">

            <h5>Language Producers

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What further information do we have on the language producers?</p>
                </div>
              </div>

            </h5>

            <p>There are numerous sources of language in the multiple datasets.</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Topics Covered

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the language in the dataset focus on specific topics? How would you describe them?</p>
                </div>
              </div>

            </h5>

            <p>There is a large variety of topics in the multiple datasets.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Data Validation

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Was the text validated by a different worker or a data curator?</p>
                </div>
              </div>

            </h5>

            <p>not validated</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Data Preprocessing

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>How was the text data pre-processed? (Enter N/A if the text was not pre-processed)</p>
                </div>
              </div>

            </h5>

            <p>The text data was detokenised so as to create references for automatic evaluations (several languages
              don't use spaces to separate words, and running metrics like BLEU would not make sense without separating
              all the tokens in a sentence).</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Was Data Filtered?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Were text instances selected or filtered?</p>
                </div>
              </div>

            </h5>

            <p>hybrid</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Filter Criteria

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What were the selection criteria?</p>
                </div>
              </div>

            </h5>

            <p>For the Wikipedia test created for the shared task, extensive filtering was applied to achieve reasonably
              good text quality. Sentences that include special characters, contain unusual tokens (e.g. ISBN), or have
              unbalanced quotation marks or brackets were skipped. Furthermore, only sentences with more than 5 tokens
              and shorter than 50 tokens were selected. After the initial filtering, quite a few malformed sentences
              remained. In order to remove those, the sentences were scored with BERT and
              only the top half scored sentences were kept. Finally, via manual inspection, patterns and expressions
              were identified to
              further reduce the number of malformed sentences.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Structured Annotations</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Additional Annotations?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the dataset have additional annotations for each instance?</p>
                </div>
              </div>

            </h5>

            <p>none</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Annotation Service?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Was an annotation service used?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Consent</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Any Consent Policy?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Was there a consent policy involved when gathering the data?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Justification for Using the Data

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>If not, what is the justification for reusing the data?</p>
                </div>
              </div>

            </h5>

            <p>The Universal Dependency data had been previously used for shared tasks on parsing, so it made sense to
              reuse it for generation.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Private Identifying Information (PII)</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Contains PII?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the source language data likely contain Personal Identifying Information about the data
                    creators or subjects?</p>
                </div>
              </div>

            </h5>

            <p>unlikely</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Any PII Identification?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Did the curators use any automatic/manual method to identify PII in the dataset?</p>
                </div>
              </div>

            </h5>

            <p>no identification</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Maintenance</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Any Maintenance Plan?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the original dataset have a maintenance plan?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Broader Social Context

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Previous Work on the Social Impact of the Dataset</h4>
              </li>
              <li>
                <h4>Impact on Under-Served Communities</h4>
              </li>
              <li>
                <h4>Discussion of Biases</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Previous Work on the Social Impact of the Dataset</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Usage of Models based on the Data

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Are you aware of cases where models trained on the task featured in this dataset ore related tasks
                    have been used in automated systems?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Impact on Under-Served Communities</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Addresses needs of underserved Communities?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does this dataset address the needs of communities that are traditionally underserved in language
                    technology, and particularly language generation technology? Communities may be underserved for
                    exemple because their language, language variety, or social or geographical context is
                    underepresented in NLP and NLG resources (datasets and models).</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Details on how Dataset Addresses the Needs

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Describe how this dataset addresses the needs of underserved communities.</p>
                </div>
              </div>

            </h5>

            <p>Thanks to the original work of the UD dataset creators, the surface realisation dataset addresses a few
              languages which are possibly under-served in NLG: e.g. Arabic, Hindi, Indonesian, Korean.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Discussion of Biases</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Any Documented Social Biases?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Are there documented social biases in the dataset? Biases in this context are variations in the
                    ways members of different social categories are represented that can have harmful downstream
                    consequences for members of the more disadvantaged group.</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Are the Language Producers Representative of the Language?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the distribution of language producers in the dataset accurately represent the full
                    distribution of speakers of the language world-wide? If not, how does it differ?</p>
                </div>
              </div>

            </h5>

            <p>It is very likely that the distribution of language producers is not fully represented in the datasets of
              each language.</p>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Considerations for Using the Data

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>PII Risks and Liability</h4>
              </li>
              <li>
                <h4>Licenses</h4>
              </li>
              <li>
                <h4>Known Technical Limitations</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>PII Risks and Liability</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field microscope">

            <h5>Potential PII Risk

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Considering your answers to the PII part of the Data Curation Section, describe any potential
                    privacy to the data subjects and creators risks when using the dataset.</p>
                </div>
              </div>

            </h5>

            <p>No risks foreseen.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Licenses</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field periscope">

            <h5>Copyright Restrictions on the Dataset

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Based on your answers in the Intended Use part of the Data Overview Section, which of the following
                    best describe the copyright and licensing status of the dataset?</p>
                </div>
              </div>

            </h5>

            <p><code>multiple licenses</code>, <code>open license - commercial use allowed</code></p>
          </div>

          <div class="datacard-field periscope">

            <h5>Copyright Restrictions on the Language Data

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Based on your answers in the Language part of the Data Curation Section, which of the following
                    best describe the copyright and licensing status of the underlying language data?</p>
                </div>
              </div>

            </h5>

            <p><code>multiple licenses</code>, <code>open license - commercial use allowed</code></p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Known Technical Limitations</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field microscope">

            <h5>Technical Limitations

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Describe any known technical limitations, such as spurrious correlations, train/test overlap,
                    annotation biases, or mis-annotations, and cite the works that first identified these limitations
                    when possible.</p>
                </div>
              </div>

            </h5>

            <p>The deep track inputs (predicate-argument structures) are not of perfect quality, they were derived
              automatically from gold or predicted syntactic parses using handcrafted grammars.</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Unsuited Applications

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>When using a model trained on this dataset in a setting where users or the public may interact with
                    its predictions, what are some pitfalls to look out for? In particular, describe some applications
                    of the general task featured in this dataset that its curation or properties make it less suitable
                    for.</p>
                </div>
              </div>

            </h5>

            <p>The datasets are probably not fitted to train tools to produce "unusual" languages (e.g. poetry, kid
              writing etc.).</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Discouraged Use Cases

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What are some discouraged use cases of a model trained to maximize the proposed metrics on this
                    dataset? In particular, think about settings where decisions made by a model that performs
                    reasonably well on the metric my still have strong negative consequences for user or members of the
                    public.</p>
                </div>
              </div>

            </h5>

            <p>To be thought of :)</p>
          </div>
        </div>

      </div>
    </div>
  </section>
</div>