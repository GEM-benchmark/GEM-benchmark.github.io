---
title: BiSECT
type: Simplification
languages: English, German, French, Spanish, Castilian
summary: This dataset is composed of 1 million complex sentences with the task to split and simplify them while retaining the full meaning. Compared to other simplification corpora, BiSECT requires more significant edits. BiSECT offers splits in English, German, French, and Spanish.
---
<div class="datacard">
  <section class="datacard-section">
    <div class="datacard-summary">
      <h2>BiSECT</h2>
      <div class="summary-content">
        <p>This dataset is composed of 1 million complex sentences with the task to split and simplify them while
          retaining the full meaning. Compared to other simplification corpora, BiSECT requires more significant edits.
          BiSECT offers splits in English, German, French, and Spanish.</p>
        <p>You can load the dataset via:</p>

        <div class="code-wrapper">
          <div class="toolbar">
            <div class="copy-icon" title="Click to copy code block"></div>
            <div class="expand-modal-icon" title="Click to expand code block"></div>
          </div>
          <pre><code>import datasets
data = datasets.load_dataset('GEM/BiSECT')
</code></pre>
        </div>

        <p>The data loader can be found <a href="https://huggingface.co/datasets/GEM/BiSECT">here</a>.</p>
      </div>
    </div>

    <div class="datacard-field-wrapper">

      <div class="datacard-field">

        <h5>website

        </h5>

        <p><a href="https://github.com/mounicam/BiSECT">Link</a></p>
      </div>

      <div class="datacard-field">

        <h5>paper

        </h5>

        <p><a href="https://aclanthology.org/2021.emnlp-main.500/">Link</a></p>
      </div>
    </div>

  </section>

  <section class="datacard-section quick">
    <h3 class="section-title">Quick-Use</h3>

    <div class="datacard-field-wrapper">

      <div class="datacard-field periscope">

        <h5>Contact Name

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>If known, provide the name of at least one person the reader can contact for questions about the
                dataset.
              </p>
            </div>
          </div>

        </h5>

        <p>Joongwon Kim, Mounica Maddela, Reno Kriz</p>
      </div>

      <div class="datacard-field telescope">

        <h5>Multilingual?

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>Is the dataset multilingual?</p>
            </div>
          </div>

        </h5>

        <p>yes</p>
      </div>

      <div class="datacard-field telescope">

        <h5>Covered Languages

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>What languages/dialects are covered in the dataset?</p>
            </div>
          </div>

        </h5>

        <p><code>English</code>, <code>German</code>, <code>French</code>, <code>Spanish, Castilian</code></p>
      </div>

      <div class="datacard-field telescope">

        <h5>License

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>What is the license of the dataset?</p>
            </div>
          </div>

        </h5>

        <p>other: Other license</p>
      </div>

      <div class="datacard-field periscope">

        <h5>Communicative Goal

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>Provide a short description of the communicative goal of a model trained for this task on this dataset.
              </p>
            </div>
          </div>

        </h5>

        <p>To rewrite a long, complex sentence into shorter, readable, meaning-equivalent sentences.</p>
      </div>

      <div class="datacard-field telescope">

        <h5>Additional Annotations?

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>Does the dataset have additional annotations for each instance?</p>
            </div>
          </div>

        </h5>

        <p>none</p>
      </div>

      <div class="datacard-field telescope">

        <h5>Contains PII?

          <div class="tooltip">
            <div class="tooltip-icon"></div>
            <div class="tooltip-text">
              <p>Does the source language data likely contain Personal Identifying Information about the data creators
                or
                subjects?</p>
            </div>
          </div>

        </h5>

        <p>unlikely</p>
      </div>
    </div>

  </section>


  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Dataset Overview

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Where to find the Data and its Documentation</h4>
              </li>
              <li>
                <h4>Languages and Intended Use</h4>
              </li>
              <li>
                <h4>Credit</h4>
              </li>
              <li>
                <h4>Dataset Structure</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Where to find the Data and its Documentation</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Webpage

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the webpage for the dataset (if it exists)?</p>
                </div>
              </div>

            </h5>

            <p><a href="https://github.com/mounicam/BiSECT">Link</a></p>
          </div>

          <div class="datacard-field telescope">

            <h5>Download

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the link to where the original dataset is hosted?</p>
                </div>
              </div>

            </h5>

            <p><a href="https://github.com/mounicam/BiSECT/tree/main/bisect">Link</a></p>
          </div>

          <div class="datacard-field telescope">

            <h5>Paper

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the link to the paper describing the dataset (open access preferred)?</p>
                </div>
              </div>

            </h5>

            <p><a href="https://aclanthology.org/2021.emnlp-main.500/">Link</a></p>
          </div>

          <div class="datacard-field microscope">

            <h5>BibTex

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Provide the BibTex-formatted reference for the dataset. Please use the correct published version
                    (ACL
                    anthology, etc.) instead of google scholar created Bibtex.</p>
                </div>
              </div>

            </h5>


            <div class="code-wrapper">
              <div class="toolbar">
                <div class="copy-icon" title="Click to copy code block"></div>
                <div class="expand-modal-icon" title="Click to expand code block"></div>
              </div>
              <pre><code>@inproceedings{kim-etal-2021-bisect,
    title = "{B}i{SECT}: Learning to Split and Rephrase Sentences with Bitexts",
    author = "Kim, Joongwon  and
      Maddela, Mounica  and
      Kriz, Reno  and
      Xu, Wei  and
      Callison-Burch, Chris",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.500",
    pages = "6193--6209"
}
</code></pre>
            </div>

          </div>

          <div class="datacard-field periscope">

            <h5>Contact Name

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>If known, provide the name of at least one person the reader can contact for questions about the
                    dataset.</p>
                </div>
              </div>

            </h5>

            <p>Joongwon Kim, Mounica Maddela, Reno Kriz</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Contact Email

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>If known, provide the email of at least one person the reader can contact for questions about the
                    dataset.</p>
                </div>
              </div>

            </h5>

            <p><a href="mailto:jkim0118@seas.upenn.edu">jkim0118@seas.upenn.edu</a>, <a
                href="mailto:mmaddela3@gatech.edu">mmaddela3@gatech.edu</a>, <a
                href="mailto:rkriz1@jh.edu">rkriz1@jh.edu</a></p>
          </div>

          <div class="datacard-field telescope">

            <h5>Has a Leaderboard?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the dataset have an active leaderboard?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Languages and Intended Use</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Multilingual?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Is the dataset multilingual?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Covered Languages

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What languages/dialects are covered in the dataset?</p>
                </div>
              </div>

            </h5>

            <p><code>English</code>, <code>German</code>, <code>French</code>, <code>Spanish, Castilian</code></p>
          </div>

          <div class="datacard-field telescope">

            <h5>License

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the license of the dataset?</p>
                </div>
              </div>

            </h5>

            <p>other: Other license</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Intended Use

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the intended use of the dataset?</p>
                </div>
              </div>

            </h5>

            <p>Split and Rephrase.</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Add. License Info

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What is the 'other' license of the dataset?</p>
                </div>
              </div>

            </h5>

            <p>The dataset is not licensed by itself, and the source OPUS data consists solely of publicly available
              parallel corpora.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Primary Task

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What primary task does the dataset support?</p>
                </div>
              </div>

            </h5>

            <p>Simplification</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Communicative Goal

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Provide a short description of the communicative goal of a model trained for this task on this
                    dataset.</p>
                </div>
              </div>

            </h5>

            <p>To rewrite a long, complex sentence into shorter, readable, meaning-equivalent sentences.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Credit</h4>


      </div>

      <div class="datacard-subsection">
        <h4>Dataset Structure</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Data Fields

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>List and describe the fields present in the dataset.</p>
                </div>
              </div>

            </h5>

            <ul>
              <li><code>gem_id</code> (string): a unique identifier for the instance</li>
              <li><code>source_sentence</code> (string): sentence to be simplified</li>
              <li><code>target_sentence</code> (string)" simplified text that was split and rephrased</li>
            </ul>
          </div>

          <div class="datacard-field periscope">

            <h5>Example Instance

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Provide a JSON formatted example of a typical instance in the dataset.</p>
                </div>
              </div>

            </h5>


            <div class="code-wrapper">
              <div class="toolbar">
                <div class="copy-icon" title="Click to copy code block"></div>
                <div class="expand-modal-icon" title="Click to expand code block"></div>
              </div>
              <pre><code>{
   "gem_id": "bisect-train-0",
   "source_sentence": "The report on the visit to Bhutan states that the small community has made the task of coordination less complex and success is manifested in the synchronized programming cycles which now apply to all but one of the agencies ( the World Health Organization ) .",
   "target_sentence": "The report on the visit to Bhutan says that the small community has made the coordination work less complex . Success manifests itself in synchronized programming cycles that now apply to all but one organism ( the World Health Organization ) ."
}
</code></pre>
            </div>

          </div>

          <div class="datacard-field periscope">

            <h5>Data Splits

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Describe and name the splits in the dataset if there are more than one.</p>
                </div>
              </div>

            </h5>

            <p>For the main English BiSECT dataset, the splits are as follows: 1. Train (n=928440) 2. Validation
              (n=9079)
              3. Test (n=583) Additional challenge sets were derived from the data presented in the paper. Please refer
              to
              the challenge set sections. The train/validation/test splits for other languages are as follows: German
              (n=184638/n=864/n=735) Spanish (n=282944/n=3638/n=3081) French (n=491035/n=2400/n=1036)</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Splitting Criteria

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Describe any criteria for splitting the data, if used. If there are differences between the splits
                    (e.g., if the training annotations are machine-generated and the dev and test ones are created by
                    humans, or if different numbers of annotators contributed to each example), describe them here.</p>
                </div>
              </div>

            </h5>

            <p>While all training data were derived from subsets of the OPUS corpora, different source subsets were used
              for training v.s., validation and testing. The training set comprised more web crawl data, whereas
              development and test sets comprised EMEA and EU texts. Details can be found in the BiSECT paper.</p>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Dataset in GEM

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Rationale for Inclusion in GEM</h4>
              </li>
              <li>
                <h4>GEM-Specific Curation</h4>
              </li>
              <li>
                <h4>Getting Started with the Task</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Rationale for Inclusion in GEM</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field microscope">

            <h5>Why is the Dataset in GEM?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What does this dataset contribute toward better generation evaluation and why is it part of GEM?
                  </p>
                </div>
              </div>

            </h5>

            <p>Understanding long and complex sentences is challenging for both humans and NLP models. The BiSECT
              dataset
              helps facilitate more research on Split and Rephrase as a task within itself, as well as how it can
              benefit
              downstream NLP applications.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Similar Datasets

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Do other datasets for the high level task exist?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Unique Language Coverage

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does this dataset cover other languages than other datasets for the same task?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Difference from other GEM datasets

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What else sets this dataset apart from other similar datasets in GEM?</p>
                </div>
              </div>

            </h5>

            <p>BiSECT is the largest available corpora for the Split and Rephrase task. In addition, it has been shown
              that BiSECT is of higher quality than previous Split and Rephrase corpora and contains a wider variety of
              splitting operations.</p>
            <p>Most previous Split and Rephrase corpora (HSplit-Wiki, Cont-Benchmark, and Wiki-Benchmark) were manually
              written at a small scale and focused on evaluation, while the one corpus of comparable size, WikiSplit,
              contains around 25% of pairs contain significant errors. This is because Wikipedia editors are not only
              trying to split a sentence, but also often simultaneously modifying the sentence for other purposes, which
              results in changes of the initial meaning.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>GEM-Specific Curation</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Modificatied for GEM?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Has the GEM version of the dataset been modified in any way (data, processing, splits) from the
                    original curated data?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field periscope">

            <h5>GEM Modifications

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What changes have been made to he original dataset?</p>
                </div>
              </div>

            </h5>

            <p><code>data points added</code></p>
          </div>

          <div class="datacard-field microscope">

            <h5>Modification Details

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>For each of these changes, described them in more details and provided the intended purpose of the
                    modification</p>
                </div>
              </div>

            </h5>

            <p>The original BiSECT training, validation, and test splits are maintained to ensure a fair comparison.
              Note
              that the original BiSECT test set was created by manually selecting 583 high-quality Split and Rephrase
              instances from 1000 random source-target pairs sampled from the EMEA and JRC-Acquis corpora from OPUS.</p>
            <p>As the first challenge set, we include the HSPLIT-Wiki test set, containing 359 pairs. For each complex
              sentence, there are four reference splits; To ensure replicability, as reference splits, we again follow
              the
              BiSECT paper and present only the references from HSplit2-full.</p>
            <p>In addition to the two evaluation sets used in the original BiSECT paper, we also introduce a second
              challenge set. For this, we initially consider all 7,293 pairs from the EMEA and JRC-Acquis corpora. From
              there, we classify each pair using the classification algorithm from Section 4.2 of the original BiSECT
              paper. The three classes are as follows:</p>
            <ol>
              <li>Direct Insertion: when a long sentence l contains two independent clauses and requires only minor
                changes in order to make a fluent and meaning-preserving split s.</li>
              <li>Changes near Split, when l contains one independent and one dependent clause, but modifications are
                restricted to the region where l is split.</li>
              <li>Changes across Sentences, where major changes are required throughout l in order to create a fluent
                split s.
                We keep only pairs labeled as Type 3, and after filtering out pairs with significant length differences
                (signaling potential content addition/deletion), we present a second challenge set of 1,798 pairs.</li>
            </ol>
          </div>

          <div class="datacard-field telescope">

            <h5>Additional Splits?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does GEM provide additional splits to the dataset?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Getting Started with the Task</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field microscope">

            <h5>Pointers to Resources

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Getting started with in-depth research on the task. Add relevant pointers to resources that
                    researchers can consult when they want to get started digging deeper into the task.</p>
                </div>
              </div>

            </h5>

            <p>The dataset can be downloaded from the original repository by the authors.</p>
            <p>The original BiSECT paper proposes several transformer-based models that can be used as baselines, which
              also compares against Copy512, an LSTM-based model and the previous state-of-the-art.</p>
            <p>The common metric used for automatic evaluation of Split and Rephrase, and sentence simplification more
              generally is SARI. The BiSECT paper also evaluates using BERTScore. Note that automatic evaluations tend
              to
              not correlate well with human judgments, so a human evaluation for quality is generally expected for
              publication. The original BiSECT paper provides templates for collecting quality annotations from Amazon
              Mechanical Turk.</p>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Previous Results

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Previous Results</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Previous Results</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Measured Model Abilities

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What aspect of model ability can be measured with this dataset?</p>
                </div>
              </div>

            </h5>

            <p>Text comprehension (needed to generate meaning-equivalent output) and notions of complexity (what is more
              'readable' in terms of syntactic structure, lexical choice, punctuation).</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Metrics

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What metrics are typically used for this task?</p>
                </div>
              </div>

            </h5>

            <p><code>Other: Other Metrics</code>, <code>BERT-Score</code></p>
          </div>

          <div class="datacard-field periscope">

            <h5>Other Metrics

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Definitions of other metrics</p>
                </div>
              </div>

            </h5>

            <p>SARI is a metric used for evaluating automatic text simplification systems. The metric compares the
              predicted simplified sentences against the reference and the source sentences. It explicitly measures the
              goodness of words that are added, deleted and kept by the system.</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Proposed Evaluation

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>List and describe the purpose of the metrics and evaluation methodology (including human
                    evaluation)
                    that the dataset creators used when introducing this task.</p>
                </div>
              </div>

            </h5>

            <p>Existing automatic metrics, such as BLEU (Papineni et al., 2002) and SAMSA (Sulem et al., 2018),
              are not optimal for the Split and Rephrase task as
              they rely on lexical overlap between the output and
              the target (or source) and underestimate the splitting capability of the models that rephrase often.</p>
            <p>As such, the dataset creators focused on BERTScore (Zhang et al., 2020) and SARI (Xu et al., 2016).
              BERTScore captures meaning preservation and fluency
              well (Scialom et al., 2021). SARI can provide three
              separate F1/precision scores that explicitly measure the correctness of inserted, kept and deleted
              n-grams when compared to both the source and
              the target. The authors used an extended version of SARI
              that considers lexical paraphrases of the reference.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Previous results available?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Are previous results available?</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Dataset Curation

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Original Curation</h4>
              </li>
              <li>
                <h4>Language Data</h4>
              </li>
              <li>
                <h4>Structured Annotations</h4>
              </li>
              <li>
                <h4>Consent</h4>
              </li>
              <li>
                <h4>Private Identifying Information (PII)</h4>
              </li>
              <li>
                <h4>Maintenance</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Original Curation</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Original Curation Rationale

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Original curation rationale</p>
                </div>
              </div>

            </h5>

            <p>BiSECT was constructed to satisfy the need of a Split and Rephrase corpus that is both large-scale and
              high-quality. Most previous Split and Rephrase corpora (HSplit-Wiki, Cont-Benchmark, and Wiki-Benchmark)
              were manually written at a small scale and focused on evaluation, while the one corpus of comparable size,
              WikiSplit, contains around 25% of pairs contain significant errors. This is because Wikipedia editors are
              not only trying to split a sentence, but also often simultaneously modifying the sentence for other
              purposes, which results in changes of the initial meaning.</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Communicative Goal

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What was the communicative goal?</p>
                </div>
              </div>

            </h5>

            <p>The goal of Split and Rephrase is to break down longer sentences into multiple shorter sentences, which
              has
              downstream applications for many NLP tasks, including machine translation and dependency parsing.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Sourced from Different Sources

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Is the dataset aggregated from different data sources?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Language Data</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>How was Language Data Obtained?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>How was the language data obtained?</p>
                </div>
              </div>

            </h5>

            <p><code>Found</code></p>
          </div>

          <div class="datacard-field telescope">

            <h5>Where was it found?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>If found, where from?</p>
                </div>
              </div>

            </h5>

            <p><code>Other</code></p>
          </div>

          <div class="datacard-field microscope">

            <h5>Language Producers

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What further information do we have on the language producers?</p>
                </div>
              </div>

            </h5>

            <p>N/A.</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Topics Covered

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the language in the dataset focus on specific topics? How would you describe them?</p>
                </div>
              </div>

            </h5>

            <p>There is a range of topics spanning domains such as web crawl and government documents (European
              Parliament, United Nations, EMEA).</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Data Validation

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Was the text validated by a different worker or a data curator?</p>
                </div>
              </div>

            </h5>

            <p>validated by data curator</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Data Preprocessing

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>How was the text data pre-processed? (Enter N/A if the text was not pre-processed)</p>
                </div>
              </div>

            </h5>

            <p>The construction of the BiSECT corpus relies on leveraging the sentence-level alignments from OPUS), a
              collection of bilingual parallel corpora over many language pairs. Given a target language A, this work
              extracts all 1-2 and 2-1 sentence alignments from parallel corpora between A and a set of foreign
              languages
              B.</p>
            <p>Next, the foreign sentences are translated into English using Google Translateâ€™s Web API service to
              obtain
              sentence alignments between a single long sentence and two corresponding split sentences, both in the
              desired language.</p>
            <p>The authors further filtered the data in a hybrid fashion.</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Was Data Filtered?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Were text instances selected or filtered?</p>
                </div>
              </div>

            </h5>

            <p>hybrid</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Filter Criteria

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What were the selection criteria?</p>
                </div>
              </div>

            </h5>

            <p>To remove noise, the authors remove pairs where the single long sentence (l) contains a token with a
              punctuation after the first two and before the last two alphabetic characters. The authors also removed
              instances where l contains more than one unconnected component in its dependency tree, generated via
              SpaCy.
            </p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Structured Annotations</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Additional Annotations?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the dataset have additional annotations for each instance?</p>
                </div>
              </div>

            </h5>

            <p>none</p>
          </div>

          <div class="datacard-field telescope">

            <h5>Annotation Service?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Was an annotation service used?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Consent</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Any Consent Policy?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Was there a consent policy involved when gathering the data?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Justification for Using the Data

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>If not, what is the justification for reusing the data?</p>
                </div>
              </div>

            </h5>

            <p>Since this data is collected from OPUS, all instances are already in the public domain.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Private Identifying Information (PII)</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Contains PII?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the source language data likely contain Personal Identifying Information about the data
                    creators
                    or subjects?</p>
                </div>
              </div>

            </h5>

            <p>unlikely</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Categories of PII

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>What categories of PII are present or suspected in the data?</p>
                </div>
              </div>

            </h5>

            <p><code>generic PII</code></p>
          </div>

          <div class="datacard-field periscope">

            <h5>Any PII Identification?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Did the curators use any automatic/manual method to identify PII in the dataset?</p>
                </div>
              </div>

            </h5>

            <p>no identification</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Maintenance</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Any Maintenance Plan?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the original dataset have a maintenance plan?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Broader Social Context

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>Previous Work on the Social Impact of the Dataset</h4>
              </li>
              <li>
                <h4>Impact on Under-Served Communities</h4>
              </li>
              <li>
                <h4>Discussion of Biases</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>Previous Work on the Social Impact of the Dataset</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Usage of Models based on the Data

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Are you aware of cases where models trained on the task featured in this dataset ore related tasks
                    have been used in automated systems?</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Impact on Under-Served Communities</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Addresses needs of underserved Communities?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does this dataset address the needs of communities that are traditionally underserved in language
                    technology, and particularly language generation technology? Communities may be underserved for
                    exemple because their language, language variety, or social or geographical context is
                    underepresented
                    in NLP and NLG resources (datasets and models).</p>
                </div>
              </div>

            </h5>

            <p>yes</p>
          </div>

          <div class="datacard-field microscope">

            <h5>Details on how Dataset Addresses the Needs

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Describe how this dataset addresses the needs of underserved communities.</p>
                </div>
              </div>

            </h5>

            <p>The data as provided in GEMv2 is in English, which is a language with abundant existing resources.
              However,
              the original paper also provides Split and Rephrase pairs for French, Spanish, and German, while providing
              a
              framework for leveraging bilingual corpora from any language pair found within OPUS.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Discussion of Biases</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field telescope">

            <h5>Any Documented Social Biases?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Are there documented social biases in the dataset? Biases in this context are variations in the
                    ways
                    members of different social categories are represented that can have harmful downstream consequences
                    for members of the more disadvantaged group.</p>
                </div>
              </div>

            </h5>

            <p>no</p>
          </div>

          <div class="datacard-field periscope">

            <h5>Are the Language Producers Representative of the Language?

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Does the distribution of language producers in the dataset accurately represent the full
                    distribution
                    of speakers of the language world-wide? If not, how does it differ?</p>
                </div>
              </div>

            </h5>

            <p>The language produced in the dataset is limited to what is captured in the used subset of the OPUS
              corpora,
              which might not represent the full distribution of speakers from all locations. For example, the corpora
              used are from a limited set of relatively formal domains, so it is possible that high performance on the
              BiSECT test set may not transfer to more informal text.</p>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="datacard-section open">

    <div class="datacard-section-preview">
      <h3>Considerations for Using the Data

        <div class="tooltip">
          <div class="tooltip-icon"></div>
          <div class="tooltip-text">
            <ul>
              <li>
                <h4>PII Risks and Liability</h4>
              </li>
              <li>
                <h4>Licenses</h4>
              </li>
              <li>
                <h4>Known Technical Limitations</h4>
              </li>
            </ul>
          </div>
        </div>

      </h3>
      <button class="expand-button">
        <svg fill="#3c4f50" height="24px" viewBox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
          <path d="M0 0h24v24H0z" fill="none"></path>
          <path d="M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z">
          </path>
        </svg>
      </button>
    </div>

    <div class="datacard-collapsible">



      <div class="datacard-subsection">
        <h4>PII Risks and Liability</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field microscope">

            <h5>Potential PII Risk

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Considering your answers to the PII part of the Data Curation Section, describe any potential
                    privacy
                    to the data subjects and creators risks when using the dataset.</p>
                </div>
              </div>

            </h5>

            <p>Since this data is collected from OPUS, all pairs are already in the public domain.</p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Licenses</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field periscope">

            <h5>Copyright Restrictions on the Dataset

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Based on your answers in the Intended Use part of the Data Overview Section, which of the following
                    best describe the copyright and licensing status of the dataset?</p>
                </div>
              </div>

            </h5>

            <p><code>public domain</code></p>
          </div>

          <div class="datacard-field periscope">

            <h5>Copyright Restrictions on the Language Data

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Based on your answers in the Language part of the Data Curation Section, which of the following
                    best
                    describe the copyright and licensing status of the underlying language data?</p>
                </div>
              </div>

            </h5>

            <p><code>public domain</code></p>
          </div>
        </div>

      </div>

      <div class="datacard-subsection">
        <h4>Known Technical Limitations</h4>


        <div class="datacard-field-wrapper">

          <div class="datacard-field microscope">

            <h5>Technical Limitations

              <div class="tooltip">
                <div class="tooltip-icon"></div>
                <div class="tooltip-text">
                  <p>Describe any known technical limitations, such as spurrious correlations, train/test overlap,
                    annotation biases, or mis-annotations, and cite the works that first identified these limitations
                    when
                    possible.</p>
                </div>
              </div>

            </h5>

            <p>The creation of English BiSECT relies on translating non-English text back to English. While machine
              translation systems tend to perform well on high-resource languages, there is still a non-negligible
              chance
              that there these systems make errors; through a manual evaluation of a subset of BiSECT, it was found that
              15% of pairs contained significant errors, while an additional 22% contained minor adequacy/fluency
              errors.
              This problem is exacerbated slightly when creating German BiSECT (22% significant errors, 24% minor
              errors),
              and these numbers would likely get larger if lower-resource languages were used.</p>
          </div>
        </div>

      </div>
    </div>
  </section>
</div>