{
    "submission_name": "T5-large (Baseline)",
    "param_count": 0,
    "schema_guided_dialog_challenge_train_sample": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_challenge_train_sample",
        "N": 500
    },
    "schema_guided_dialog_challenge_validation_sample": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_challenge_validation_sample",
        "N": 500
    },
    "wiki_auto_asset_turk_challenge_validation_sample": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_challenge_validation_sample",
        "N": 500
    },
    "totto_test_contrast_challenge_input_size-input_length_34": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 65,
        "mean_pred_length": 65.0,
        "std_pred_length": 0.0,
        "median_pred_length": 65.0,
        "min_pred_length": 65,
        "max_pred_length": 65,
        "distinct-1": 0.6307692307692307,
        "vocab_size-1": 41,
        "unique-1": 33,
        "entropy-1": 4.886549577400339,
        "distinct-2": 0.90625,
        "vocab_size-2": 58,
        "unique-2": 54,
        "entropy-2": 5.78125,
        "cond_entropy-2": 0.9124475825313524,
        "distinct-3": 0.9682539682539683,
        "vocab_size-3": 61,
        "unique-3": 59,
        "entropy-3": 5.913787860007857,
        "cond_entropy-3": 0.13601008223007524,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 47.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 47.0,
        "min_pred_length-nopunct": 47,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.7872340425531915,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 4.995766245156567,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.5235619560570095,
        "cond_entropy-2-nopunct": 0.5399440284335147,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 45,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.491853096329673,
        "cond_entropy-3-nopunct": -0.03170885972733836,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.31915,
            "recall": 0.63833,
            "fmeasure": 0.42355
        },
        "rouge2": {
            "precision": 0.07971,
            "recall": 0.16222,
            "fmeasure": 0.10637
        },
        "rougeL": {
            "precision": 0.20567,
            "recall": 0.4143,
            "fmeasure": 0.27356
        },
        "rougeLsum": {
            "precision": 0.20567,
            "recall": 0.4143,
            "fmeasure": 0.27356
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "nist": 1.4914859191818135,
        "bleu": 10.60078,
        "bleurt": -0.92781,
        "nubia": {
            "semantic_relation": 2.85274,
            "contradiction": 0.26843,
            "irrelevancy": 57.56391,
            "logical_agreement": 42.16765,
            "grammar_ref": 4.75948,
            "grammar_hyp": 4.26553,
            "nubia_score": 0.05717
        },
        "meteor": 0.23848910555075706,
        "bertscore": {
            "precision": 0.79384,
            "recall": 0.87028,
            "f1": 0.83028
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_35": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 8.0,
        "median_pred_length": 19.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.9210526315789473,
        "vocab_size-1": 35,
        "unique-1": 32,
        "entropy-1": 5.090032776601483,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.03310859910983792,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 7.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.9428571428571428,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.01499730265925,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.03632322362560796,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.09019780897157811,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5793,
            "recall": 0.45497,
            "fmeasure": 0.50731
        },
        "rouge2": {
            "precision": 0.26923,
            "recall": 0.22222,
            "fmeasure": 0.24242
        },
        "rougeL": {
            "precision": 0.48386,
            "recall": 0.38567,
            "fmeasure": 0.42727
        },
        "rougeLsum": {
            "precision": 0.48386,
            "recall": 0.38567,
            "fmeasure": 0.42727
        },
        "local_recall": {
            "1": 0.1,
            "2": 1.0,
            "3": 0.38636363636363635
        },
        "nist": 1.2928672155108556,
        "bleu": 10.00554,
        "bleurt": -0.16032,
        "nubia": {
            "semantic_relation": 3.50681,
            "contradiction": 15.58743,
            "irrelevancy": 45.17773,
            "logical_agreement": 39.23484,
            "grammar_ref": 3.96887,
            "grammar_hyp": 4.9422,
            "nubia_score": 0.38165
        },
        "meteor": 0.2453291248081193,
        "bertscore": {
            "precision": 0.85025,
            "recall": 0.8261,
            "f1": 0.83584
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_38": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.30769,
            "recall": 0.26667,
            "fmeasure": 0.28571
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.07143,
            "fmeasure": 0.07692
        },
        "rougeL": {
            "precision": 0.23077,
            "recall": 0.2,
            "fmeasure": 0.21429
        },
        "rougeLsum": {
            "precision": 0.23077,
            "recall": 0.2,
            "fmeasure": 0.21429
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333
        },
        "nist": 1.3251132139617805,
        "bleu": 6.19108,
        "bleurt": -0.36261,
        "nubia": {
            "semantic_relation": 2.1379,
            "contradiction": 2.33324,
            "irrelevancy": 97.29278,
            "logical_agreement": 0.37398,
            "grammar_ref": 5.48676,
            "grammar_hyp": 4.98434,
            "nubia_score": 0.16718
        },
        "meteor": 0.14931313041983682,
        "bertscore": {
            "precision": 0.80397,
            "recall": 0.79024,
            "f1": 0.79647
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_40": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.33333,
            "fmeasure": 0.41667
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.26667,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.26667,
            "fmeasure": 0.33333
        },
        "local_recall": {
            "1": 0,
            "2": 0.38461538461538464
        },
        "nist": 0.6328835016528253,
        "bleu": 3.42817,
        "bleurt": -0.9826,
        "nubia": {
            "semantic_relation": 2.7756,
            "contradiction": 10.44329,
            "irrelevancy": 88.63083,
            "logical_agreement": 0.92588,
            "grammar_ref": 5.57252,
            "grammar_hyp": 6.03071,
            "nubia_score": 0.167
        },
        "meteor": 0.13973799126637554,
        "bertscore": {
            "precision": 0.80432,
            "recall": 0.79564,
            "f1": 0.79996
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 58,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.761,
        "total_length": 1185,
        "mean_pred_length": 20.43103448275862,
        "std_pred_length": 9.609822684799845,
        "median_pred_length": 20.0,
        "min_pred_length": 6,
        "max_pred_length": 46,
        "distinct-1": 0.49873417721518987,
        "vocab_size-1": 591,
        "unique-1": 480,
        "entropy-1": 7.96369854357441,
        "distinct-2": 0.90150842945874,
        "vocab_size-2": 1016,
        "unique-2": 971,
        "entropy-2": 9.852012955131839,
        "cond_entropy-2": 1.691767161659998,
        "distinct-3": 0.9747427502338635,
        "vocab_size-3": 1042,
        "unique-3": 1031,
        "entropy-3": 9.986219524038514,
        "cond_entropy-3": 0.14973791877809176,
        "total_length-nopunct": 1054,
        "mean_pred_length-nopunct": 18.17241379310345,
        "std_pred_length-nopunct": 8.618620441319706,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.5531309297912713,
        "vocab_size-1-nopunct": 583,
        "unique-1-nopunct": 477,
        "entropy-1-nopunct": 8.164990408970095,
        "distinct-2-nopunct": 0.9206827309236948,
        "vocab_size-2-nopunct": 917,
        "unique-2-nopunct": 879,
        "entropy-2-nopunct": 9.74441343115315,
        "cond_entropy-2-nopunct": 1.6773395472629877,
        "distinct-3-nopunct": 0.988272921108742,
        "vocab_size-3-nopunct": 927,
        "unique-3-nopunct": 918,
        "entropy-3-nopunct": 9.847857758570806,
        "cond_entropy-3-nopunct": 0.11570886158948028,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.88054,
            "recall": 0.82364,
            "fmeasure": 0.83612
        },
        "rouge2": {
            "precision": 0.78486,
            "recall": 0.72601,
            "fmeasure": 0.73699
        },
        "rougeL": {
            "precision": 0.86585,
            "recall": 0.8093,
            "fmeasure": 0.82177
        },
        "rougeLsum": {
            "precision": 0.86585,
            "recall": 0.8093,
            "fmeasure": 0.82177
        },
        "local_recall": {
            "1": 0.035106382978723406,
            "2": 0.16666666666666666,
            "3": 0.2913907284768212,
            "4": 0.5,
            "5": 0.6370370370370371,
            "6": 0.7019230769230769,
            "7": 0.7982456140350878,
            "8": 0.7687074829931972,
            "9": 0.9084967320261438,
            "10": 0.9389671361502347
        },
        "nist": 10.928646243582229,
        "bleu": 81.779,
        "bleurt": 0.15891,
        "nubia": {
            "semantic_relation": 4.05709,
            "contradiction": 3.98219,
            "irrelevancy": 32.2112,
            "logical_agreement": 63.8066,
            "grammar_ref": 4.50862,
            "grammar_hyp": 4.76392,
            "nubia_score": 0.61241
        },
        "meteor": 0.502816257193618,
        "bertscore": {
            "precision": 0.95969,
            "recall": 0.95425,
            "f1": 0.95411
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_41": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.64444,
            "recall": 0.79744,
            "fmeasure": 0.71048
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.55556,
            "fmeasure": 0.43305
        },
        "rougeL": {
            "precision": 0.62222,
            "recall": 0.7641,
            "fmeasure": 0.68381
        },
        "rougeLsum": {
            "precision": 0.62222,
            "recall": 0.7641,
            "fmeasure": 0.68381
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.75,
            "3": 0.6666666666666666
        },
        "nist": 2.9927068734107967,
        "bleu": 49.58272,
        "bleurt": 0.38047,
        "nubia": {
            "semantic_relation": 3.19038,
            "contradiction": 82.56494,
            "irrelevancy": 8.18235,
            "logical_agreement": 9.25271,
            "grammar_ref": 6.66832,
            "grammar_hyp": 5.24662,
            "nubia_score": 0.4829
        },
        "meteor": 0.4583736498074521,
        "bertscore": {
            "precision": 0.94511,
            "recall": 0.96932,
            "f1": 0.95428
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 61,
        "msttr-100": 0.67133,
        "msttr-100_nopunct": 0.72769,
        "total_length": 1587,
        "mean_pred_length": 26.016393442622952,
        "std_pred_length": 8.95433186362285,
        "median_pred_length": 25.0,
        "min_pred_length": 8,
        "max_pred_length": 45,
        "distinct-1": 0.4732199117832388,
        "vocab_size-1": 751,
        "unique-1": 605,
        "entropy-1": 8.126497179662385,
        "distinct-2": 0.8558322411533421,
        "vocab_size-2": 1306,
        "unique-2": 1198,
        "entropy-2": 10.162598923215855,
        "cond_entropy-2": 1.8946423083911552,
        "distinct-3": 0.967235494880546,
        "vocab_size-3": 1417,
        "unique-3": 1374,
        "entropy-3": 10.448579531213301,
        "cond_entropy-3": 0.27515167416550346,
        "total_length-nopunct": 1363,
        "mean_pred_length-nopunct": 22.34426229508197,
        "std_pred_length-nopunct": 8.56199234876916,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.5451210564930301,
        "vocab_size-1-nopunct": 743,
        "unique-1-nopunct": 602,
        "entropy-1-nopunct": 8.444870650069364,
        "distinct-2-nopunct": 0.8870967741935484,
        "vocab_size-2-nopunct": 1155,
        "unique-2-nopunct": 1072,
        "entropy-2-nopunct": 10.044755115916864,
        "cond_entropy-2-nopunct": 1.6584922624013574,
        "distinct-3-nopunct": 0.9734085414987913,
        "vocab_size-3-nopunct": 1208,
        "unique-3-nopunct": 1177,
        "entropy-3-nopunct": 10.222887903752966,
        "cond_entropy-3-nopunct": 0.18732479077926179,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.68704,
            "recall": 0.66248,
            "fmeasure": 0.66112
        },
        "rouge2": {
            "precision": 0.41075,
            "recall": 0.39758,
            "fmeasure": 0.39684
        },
        "rougeL": {
            "precision": 0.54635,
            "recall": 0.52733,
            "fmeasure": 0.52544
        },
        "rougeLsum": {
            "precision": 0.54635,
            "recall": 0.52733,
            "fmeasure": 0.52544
        },
        "local_recall": {
            "1": 0.17204301075268819,
            "2": 0.40271493212669685,
            "3": 0.7160751565762005
        },
        "nist": 6.799092474997973,
        "bleu": 37.95942,
        "bleurt": 0.12525,
        "nubia": {
            "semantic_relation": 3.9178,
            "contradiction": 12.43922,
            "irrelevancy": 26.51848,
            "logical_agreement": 61.0423,
            "grammar_ref": 4.28842,
            "grammar_hyp": 4.20061,
            "nubia_score": 0.64359
        },
        "meteor": 0.35431938347041997,
        "bertscore": {
            "precision": 0.91048,
            "recall": 0.90424,
            "f1": 0.90601
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_42": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 32.0,
        "std_pred_length": 0.0,
        "median_pred_length": 32.0,
        "min_pred_length": 32,
        "max_pred_length": 32,
        "distinct-1": 0.625,
        "vocab_size-1": 20,
        "unique-1": 16,
        "entropy-1": 3.952819531114783,
        "distinct-2": 0.7419354838709677,
        "vocab_size-2": 23,
        "unique-2": 20,
        "entropy-2": 4.284683810317086,
        "cond_entropy-2": 0.3656442943276322,
        "distinct-3": 0.7666666666666667,
        "vocab_size-3": 23,
        "unique-3": 20,
        "entropy-3": 4.32323142879762,
        "cond_entropy-3": 0.0608647018161942,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.72,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.9238561897747233,
        "distinct-2-nopunct": 0.7916666666666666,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.053508854797679,
        "cond_entropy-2-nopunct": 0.1596526650229539,
        "distinct-3-nopunct": 0.8260869565217391,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.110093477608016,
        "cond_entropy-3-nopunct": 0.07969130306787978,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.53333,
            "recall": 0.56667,
            "fmeasure": 0.54815
        },
        "rouge2": {
            "precision": 0.31944,
            "recall": 0.33772,
            "fmeasure": 0.32752
        },
        "rougeL": {
            "precision": 0.41333,
            "recall": 0.43667,
            "fmeasure": 0.4237
        },
        "rougeLsum": {
            "precision": 0.41333,
            "recall": 0.43667,
            "fmeasure": 0.4237
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.75,
            "3": 0.5
        },
        "nist": 2.872805586187066,
        "bleu": 27.5018,
        "bleurt": -0.48409,
        "nubia": {
            "semantic_relation": 2.88244,
            "contradiction": 0.91059,
            "irrelevancy": 95.98107,
            "logical_agreement": 3.10834,
            "grammar_ref": 4.19943,
            "grammar_hyp": 3.24564,
            "nubia_score": 0.49888
        },
        "meteor": 0.33908222362117146,
        "bertscore": {
            "precision": 0.91535,
            "recall": 0.87203,
            "f1": 0.89317
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_52": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 40.0,
        "std_pred_length": 0.0,
        "median_pred_length": 40.0,
        "min_pred_length": 40,
        "max_pred_length": 40,
        "distinct-1": 0.725,
        "vocab_size-1": 29,
        "unique-1": 27,
        "entropy-1": 4.3205843997621045,
        "distinct-2": 1.0,
        "vocab_size-2": 39,
        "unique-2": 39,
        "entropy-2": 5.285402218862247,
        "cond_entropy-2": 0.990493298462329,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.03747470541866295,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 28.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 28.0,
        "min_pred_length-nopunct": 28,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.9642857142857143,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.735926350629034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": 0.021606654179938616,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.05444778402237652,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7931,
            "recall": 0.60238,
            "fmeasure": 0.68332
        },
        "rouge2": {
            "precision": 0.55357,
            "recall": 0.41571,
            "fmeasure": 0.47382
        },
        "rougeL": {
            "precision": 0.55172,
            "recall": 0.41905,
            "fmeasure": 0.47535
        },
        "rougeLsum": {
            "precision": 0.55172,
            "recall": 0.41905,
            "fmeasure": 0.47535
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.75
        },
        "nist": 3.5509608676832585,
        "bleu": 52.51568,
        "bleurt": 0.15424,
        "nubia": {
            "semantic_relation": 3.44121,
            "contradiction": 1.60785,
            "irrelevancy": 1.109,
            "logical_agreement": 97.28315,
            "grammar_ref": 3.72412,
            "grammar_hyp": 2.71936,
            "nubia_score": 0.64964
        },
        "meteor": 0.39546964224579695,
        "bertscore": {
            "precision": 0.91985,
            "recall": 0.89318,
            "f1": 0.90187
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_60": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 43,
        "mean_pred_length": 21.5,
        "std_pred_length": 3.5,
        "median_pred_length": 21.5,
        "min_pred_length": 18,
        "max_pred_length": 25,
        "distinct-1": 0.6511627906976745,
        "vocab_size-1": 28,
        "unique-1": 16,
        "entropy-1": 4.6645231848843425,
        "distinct-2": 0.926829268292683,
        "vocab_size-2": 38,
        "unique-2": 35,
        "entropy-2": 5.211210541203447,
        "cond_entropy-2": 0.5350649938711924,
        "distinct-3": 0.9743589743589743,
        "vocab_size-3": 38,
        "unique-3": 37,
        "entropy-3": 5.234120167580196,
        "cond_entropy-3": 0.03041431680826746,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 18.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7027027027027027,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.5944564061110205,
        "distinct-2-nopunct": 0.9142857142857143,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.957854445516392,
        "cond_entropy-2-nopunct": 0.3985407228064015,
        "distinct-3-nopunct": 0.9696969696969697,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.9837880587523955,
        "cond_entropy-3-nopunct": 0.036323223625607956,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.87946,
            "recall": 0.85734,
            "fmeasure": 0.86571
        },
        "rouge2": {
            "precision": 0.64444,
            "recall": 0.63626,
            "fmeasure": 0.63858
        },
        "rougeL": {
            "precision": 0.6498,
            "recall": 0.61687,
            "fmeasure": 0.63057
        },
        "rougeLsum": {
            "precision": 0.6498,
            "recall": 0.61687,
            "fmeasure": 0.63057
        },
        "local_recall": {
            "1": 0.4,
            "2": 1.0,
            "3": 0.8666666666666667
        },
        "nist": 4.696886410851329,
        "bleu": 53.26278,
        "bleurt": 0.19995,
        "nubia": {
            "semantic_relation": 3.96907,
            "contradiction": 48.09338,
            "irrelevancy": 30.01323,
            "logical_agreement": 21.89339,
            "grammar_ref": 4.80653,
            "grammar_hyp": 4.98062,
            "nubia_score": 0.59799
        },
        "meteor": 0.4329204631624454,
        "bertscore": {
            "precision": 0.95347,
            "recall": 0.94202,
            "f1": 0.94453
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_75": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.277613436819116,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.1219280948873624,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.04089198233393865,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75,
            "recall": 0.44444,
            "fmeasure": 0.55769
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.28431,
            "fmeasure": 0.36218
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.44444,
            "fmeasure": 0.55769
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.44444,
            "fmeasure": 0.55769
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5
        },
        "nist": 1.048364453949866,
        "bleu": 21.91844,
        "bleurt": -0.03781,
        "nubia": {
            "semantic_relation": 2.45768,
            "contradiction": 10.87388,
            "irrelevancy": 3.32773,
            "logical_agreement": 85.7984,
            "grammar_ref": 4.60656,
            "grammar_hyp": 4.20752,
            "nubia_score": 0.28115
        },
        "meteor": 0.29399242375920503,
        "bertscore": {
            "precision": 0.92245,
            "recall": 0.84554,
            "f1": 0.88232
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 32,
        "msttr-100": 0.70667,
        "msttr-100_nopunct": 0.74333,
        "total_length": 699,
        "mean_pred_length": 21.84375,
        "std_pred_length": 9.627789774268027,
        "median_pred_length": 20.5,
        "min_pred_length": 6,
        "max_pred_length": 44,
        "distinct-1": 0.5321888412017167,
        "vocab_size-1": 372,
        "unique-1": 300,
        "entropy-1": 7.5532903007124155,
        "distinct-2": 0.8950524737631185,
        "vocab_size-2": 597,
        "unique-2": 563,
        "entropy-2": 9.100371084936976,
        "cond_entropy-2": 1.3844639866618735,
        "distinct-3": 0.9637795275590552,
        "vocab_size-3": 612,
        "unique-3": 602,
        "entropy-3": 9.209734267626441,
        "cond_entropy-3": 0.1203828672878423,
        "total_length-nopunct": 614,
        "mean_pred_length-nopunct": 19.1875,
        "std_pred_length-nopunct": 8.060077155337906,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.5944625407166124,
        "vocab_size-1-nopunct": 365,
        "unique-1-nopunct": 298,
        "entropy-1-nopunct": 7.727011192160455,
        "distinct-2-nopunct": 0.915807560137457,
        "vocab_size-2-nopunct": 533,
        "unique-2-nopunct": 509,
        "entropy-2-nopunct": 8.96239462404885,
        "cond_entropy-2-nopunct": 1.3015994360155432,
        "distinct-3-nopunct": 0.9818181818181818,
        "vocab_size-3-nopunct": 540,
        "unique-3-nopunct": 533,
        "entropy-3-nopunct": 9.061915285680733,
        "cond_entropy-3-nopunct": 0.110646812547426,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.88234,
            "recall": 0.87748,
            "fmeasure": 0.87251
        },
        "rouge2": {
            "precision": 0.77355,
            "recall": 0.76884,
            "fmeasure": 0.76188
        },
        "rougeL": {
            "precision": 0.87028,
            "recall": 0.85365,
            "fmeasure": 0.85391
        },
        "rougeLsum": {
            "precision": 0.87028,
            "recall": 0.85365,
            "fmeasure": 0.85391
        },
        "local_recall": {
            "1": 0.049281314168377825,
            "2": 0.16822429906542055,
            "3": 0.323943661971831,
            "4": 0.625,
            "5": 0.7272727272727273,
            "6": 0.7647058823529411,
            "7": 0.8939393939393939,
            "8": 0.873015873015873,
            "9": 0.8809523809523809,
            "10": 0.967741935483871
        },
        "nist": 10.154315981395674,
        "bleu": 84.70591,
        "bleurt": 0.22603,
        "nubia": {
            "semantic_relation": 4.34867,
            "contradiction": 2.52352,
            "irrelevancy": 32.54227,
            "logical_agreement": 64.93421,
            "grammar_ref": 4.51508,
            "grammar_hyp": 4.59012,
            "nubia_score": 0.67745
        },
        "meteor": 0.5230223228653087,
        "bertscore": {
            "precision": 0.96275,
            "recall": 0.96797,
            "f1": 0.96226
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_100": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 36.0,
        "std_pred_length": 0.0,
        "median_pred_length": 36.0,
        "min_pred_length": 36,
        "max_pred_length": 36,
        "distinct-1": 0.4166666666666667,
        "vocab_size-1": 15,
        "unique-1": 12,
        "entropy-1": 3.0655583128246056,
        "distinct-2": 0.4857142857142857,
        "vocab_size-2": 17,
        "unique-2": 13,
        "entropy-2": 3.5491981909790677,
        "cond_entropy-2": 0.5437646406863959,
        "distinct-3": 0.5294117647058824,
        "vocab_size-3": 18,
        "unique-3": 13,
        "entropy-3": 3.7447721220031855,
        "cond_entropy-3": 0.24204701414076202,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.5909090909090909,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.202545961618968,
        "distinct-2-nopunct": 0.6666666666666666,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.535174565635903,
        "cond_entropy-2-nopunct": 0.39248030197018835,
        "distinct-3-nopunct": 0.75,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.684183719779189,
        "cond_entropy-3-nopunct": 0.1918662970004286,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.18056,
            "recall": 0.45,
            "fmeasure": 0.25155
        },
        "rouge2": {
            "precision": 0.07143,
            "recall": 0.2193,
            "fmeasure": 0.10522
        },
        "rougeL": {
            "precision": 0.13889,
            "recall": 0.375,
            "fmeasure": 0.19798
        },
        "rougeLsum": {
            "precision": 0.13889,
            "recall": 0.375,
            "fmeasure": 0.19798
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.7142857142857143
        },
        "nist": 0.8112079077539776,
        "bleu": 4.56116,
        "bleurt": -0.4598,
        "nubia": {
            "semantic_relation": 3.31066,
            "contradiction": 20.66425,
            "irrelevancy": 76.18474,
            "logical_agreement": 3.151,
            "grammar_ref": 5.69136,
            "grammar_hyp": 2.25105,
            "nubia_score": 0.66617
        },
        "meteor": 0.23166946807669342,
        "bertscore": {
            "precision": 0.72074,
            "recall": 0.81128,
            "f1": 0.74428
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_123": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 34.0,
        "std_pred_length": 0.0,
        "median_pred_length": 34.0,
        "min_pred_length": 34,
        "max_pred_length": 34,
        "distinct-1": 0.7647058823529411,
        "vocab_size-1": 26,
        "unique-1": 19,
        "entropy-1": 4.594672032363178,
        "distinct-2": 0.9090909090909091,
        "vocab_size-2": 30,
        "unique-2": 27,
        "entropy-2": 4.8625759375402735,
        "cond_entropy-2": 0.28283695999185554,
        "distinct-3": 0.9375,
        "vocab_size-3": 30,
        "unique-3": 28,
        "entropy-3": 4.875,
        "cond_entropy-3": 0.01810588064154658,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 30.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 30.0,
        "min_pred_length-nopunct": 30,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.7333333333333333,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.348394345536403,
        "distinct-2-nopunct": 0.896551724137931,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.651084443403434,
        "cond_entropy-2-nopunct": 0.2874658306281387,
        "distinct-3-nopunct": 0.9285714285714286,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.664497779200463,
        "cond_entropy-3-nopunct": 0.0208024983586036,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5625,
            "recall": 0.44091,
            "fmeasure": 0.48331
        },
        "rouge2": {
            "precision": 0.19355,
            "recall": 0.11909,
            "fmeasure": 0.14608
        },
        "rougeL": {
            "precision": 0.40625,
            "recall": 0.30455,
            "fmeasure": 0.34056
        },
        "rougeLsum": {
            "precision": 0.40625,
            "recall": 0.30455,
            "fmeasure": 0.34056
        },
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.45454545454545453
        },
        "nist": 2.968114330168674,
        "bleu": 32.66519,
        "bleurt": -0.07651,
        "nubia": {
            "semantic_relation": 2.45331,
            "contradiction": 93.60962,
            "irrelevancy": 4.01312,
            "logical_agreement": 2.37727,
            "grammar_ref": 4.34131,
            "grammar_hyp": 4.45545,
            "nubia_score": 0.2235
        },
        "meteor": 0.1805432377371035,
        "bertscore": {
            "precision": 0.91139,
            "recall": 0.83508,
            "f1": 0.86648
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_125": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.614369445886757,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.5057731339256742,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7647058823529411,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.4992275471326932,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.5375371587496608,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.23529,
            "recall": 0.28356,
            "fmeasure": 0.25621
        },
        "rouge2": {
            "precision": 0.0625,
            "recall": 0.07639,
            "fmeasure": 0.06845
        },
        "rougeL": {
            "precision": 0.21569,
            "recall": 0.23379,
            "fmeasure": 0.22353
        },
        "rougeLsum": {
            "precision": 0.21569,
            "recall": 0.23379,
            "fmeasure": 0.22353
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "nist": 1.1076685432222044,
        "bleu": 5.10928,
        "bleurt": -0.51387,
        "nubia": {
            "semantic_relation": 1.19713,
            "contradiction": 31.22915,
            "irrelevancy": 67.58457,
            "logical_agreement": 1.18628,
            "grammar_ref": 4.12033,
            "grammar_hyp": 3.57394,
            "nubia_score": 0.11702
        },
        "meteor": 0.12010865911715858,
        "bertscore": {
            "precision": 0.67961,
            "recall": 0.68091,
            "f1": 0.68018
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_127": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.7391304347826086,
        "vocab_size-1": 17,
        "unique-1": 12,
        "entropy-1": 3.9690016298759936,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.5156372763149877,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.7841837197791883,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.4920461291964057,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.2,
            "recall": 0.30037,
            "fmeasure": 0.24005
        },
        "rouge2": {
            "precision": 0.05263,
            "recall": 0.0812,
            "fmeasure": 0.06384
        },
        "rougeL": {
            "precision": 0.15,
            "recall": 0.22527,
            "fmeasure": 0.18004
        },
        "rougeLsum": {
            "precision": 0.15,
            "recall": 0.22527,
            "fmeasure": 0.18004
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.2
        },
        "nist": 0.640129044199351,
        "bleu": 2.44266,
        "bleurt": -0.92752,
        "nubia": {
            "semantic_relation": 0.6499,
            "contradiction": 16.47845,
            "irrelevancy": 81.45873,
            "logical_agreement": 2.06282,
            "grammar_ref": 4.48671,
            "grammar_hyp": 3.76482,
            "nubia_score": 0.08872
        },
        "meteor": 0.12807000003785643,
        "bertscore": {
            "precision": 0.69594,
            "recall": 0.72462,
            "f1": 0.70999
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_133": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.4,
            "recall": 0.35294,
            "fmeasure": 0.375
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.25,
            "fmeasure": 0.26667
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.29412,
            "fmeasure": 0.3125
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.29412,
            "fmeasure": 0.3125
        },
        "local_recall": {
            "1": 0,
            "2": 0.4
        },
        "nist": 1.66578250153649,
        "bleu": 20.70317,
        "bleurt": -0.39103,
        "nubia": {
            "semantic_relation": 2.11493,
            "contradiction": 96.53339,
            "irrelevancy": 2.28837,
            "logical_agreement": 1.17823,
            "grammar_ref": 4.28272,
            "grammar_hyp": 4.79082,
            "nubia_score": 0.15088
        },
        "meteor": 0.21512735963051483,
        "bertscore": {
            "precision": 0.76222,
            "recall": 0.78934,
            "f1": 0.77554
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 116,
        "msttr-100": 0.42242,
        "msttr-100_nopunct": 0.41965,
        "total_length": 6225,
        "mean_pred_length": 53.66379310344828,
        "std_pred_length": 14.387460995193987,
        "median_pred_length": 53.0,
        "min_pred_length": 20,
        "max_pred_length": 81,
        "distinct-1": 0.11068273092369478,
        "vocab_size-1": 689,
        "unique-1": 306,
        "entropy-1": 5.443642823252724,
        "distinct-2": 0.27549517105909316,
        "vocab_size-2": 1683,
        "unique-2": 868,
        "entropy-2": 9.387593166409973,
        "cond_entropy-2": 3.9446182142756725,
        "distinct-3": 0.4618721842149174,
        "vocab_size-3": 2768,
        "unique-3": 1693,
        "entropy-3": 10.75823642388943,
        "cond_entropy-3": 1.3874605553306294,
        "total_length-nopunct": 5788,
        "mean_pred_length-nopunct": 49.89655172413793,
        "std_pred_length-nopunct": 13.963239490709556,
        "median_pred_length-nopunct": 49.5,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 76,
        "distinct-1-nopunct": 0.11800276434001382,
        "vocab_size-1-nopunct": 683,
        "unique-1-nopunct": 305,
        "entropy-1-nopunct": 5.32841655226766,
        "distinct-2-nopunct": 0.2757404795486601,
        "vocab_size-2-nopunct": 1564,
        "unique-2-nopunct": 806,
        "entropy-2-nopunct": 9.266033233966613,
        "cond_entropy-2-nopunct": 3.9852732538176143,
        "distinct-3-nopunct": 0.4557235421166307,
        "vocab_size-3-nopunct": 2532,
        "unique-3-nopunct": 1549,
        "entropy-3-nopunct": 10.613949966290186,
        "cond_entropy-3-nopunct": 1.3680845780979976,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.13649,
            "recall": 0.12608,
            "fmeasure": 0.12874
        },
        "rouge2": {
            "precision": 0.04598,
            "recall": 0.03982,
            "fmeasure": 0.04119
        },
        "rougeL": {
            "precision": 0.13506,
            "recall": 0.12464,
            "fmeasure": 0.12731
        },
        "rougeLsum": {
            "precision": 0.13506,
            "recall": 0.12464,
            "fmeasure": 0.12731
        },
        "local_recall": {
            "1": 0.07488738738738739,
            "2": 0.1580188679245283,
            "3": 0.18035426731078905
        },
        "nist": 0.7553748448908337,
        "bleu": 0.37394,
        "bleurt": -0.5192,
        "nubia": {
            "semantic_relation": 3.33322,
            "contradiction": 32.95661,
            "irrelevancy": 16.57266,
            "logical_agreement": 50.47073,
            "grammar_ref": 2.53819,
            "grammar_hyp": 2.36975,
            "nubia_score": 0.13881
        },
        "meteor": 0.09023603198500217,
        "bertscore": {
            "precision": 0.85161,
            "recall": 0.86592,
            "f1": 0.85826
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 40,
        "msttr-100": 0.679,
        "msttr-100_nopunct": 0.72556,
        "total_length": 1070,
        "mean_pred_length": 26.75,
        "std_pred_length": 7.3169324173454005,
        "median_pred_length": 26.0,
        "min_pred_length": 10,
        "max_pred_length": 44,
        "distinct-1": 0.46448598130841123,
        "vocab_size-1": 497,
        "unique-1": 376,
        "entropy-1": 7.732183135774198,
        "distinct-2": 0.8514563106796117,
        "vocab_size-2": 877,
        "unique-2": 797,
        "entropy-2": 9.611914176619601,
        "cond_entropy-2": 1.763586724364981,
        "distinct-3": 0.9575757575757575,
        "vocab_size-3": 948,
        "unique-3": 919,
        "entropy-3": 9.852522656875108,
        "cond_entropy-3": 0.2437455411807144,
        "total_length-nopunct": 905,
        "mean_pred_length-nopunct": 22.625,
        "std_pred_length-nopunct": 5.7475538274991385,
        "median_pred_length-nopunct": 21.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.5370165745856353,
        "vocab_size-1-nopunct": 486,
        "unique-1-nopunct": 372,
        "entropy-1-nopunct": 7.991307726816877,
        "distinct-2-nopunct": 0.8786127167630058,
        "vocab_size-2-nopunct": 760,
        "unique-2-nopunct": 705,
        "entropy-2-nopunct": 9.429549381723147,
        "cond_entropy-2-nopunct": 1.48298991745083,
        "distinct-3-nopunct": 0.9648484848484848,
        "vocab_size-3-nopunct": 796,
        "unique-3-nopunct": 776,
        "entropy-3-nopunct": 9.606099475786623,
        "cond_entropy-3-nopunct": 0.1812899154340214,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74809,
            "recall": 0.70501,
            "fmeasure": 0.71556
        },
        "rouge2": {
            "precision": 0.50105,
            "recall": 0.47222,
            "fmeasure": 0.48025
        },
        "rougeL": {
            "precision": 0.59631,
            "recall": 0.56343,
            "fmeasure": 0.57149
        },
        "rougeLsum": {
            "precision": 0.59631,
            "recall": 0.56343,
            "fmeasure": 0.57149
        },
        "local_recall": {
            "1": 0.1643835616438356,
            "2": 0.4378698224852071,
            "3": 0.7763975155279503
        },
        "nist": 6.908540888960539,
        "bleu": 42.74956,
        "bleurt": 0.12848,
        "nubia": {
            "semantic_relation": 3.94503,
            "contradiction": 19.20278,
            "irrelevancy": 29.24648,
            "logical_agreement": 51.55074,
            "grammar_ref": 4.29053,
            "grammar_hyp": 4.12836,
            "nubia_score": 0.66514
        },
        "meteor": 0.3788804987793388,
        "bertscore": {
            "precision": 0.91934,
            "recall": 0.91468,
            "f1": 0.91514
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_496": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8095238095238095,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 3.9161269465882835,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.42961067210860193,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185188,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.25,
            "recall": 0.12903,
            "fmeasure": 0.17021
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.1875,
            "recall": 0.09677,
            "fmeasure": 0.12766
        },
        "rougeLsum": {
            "precision": 0.1875,
            "recall": 0.09677,
            "fmeasure": 0.12766
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.21428571428571427,
            "3": 0.1111111111111111
        },
        "nist": 1.3559472423157046,
        "bleu": 5.13666,
        "bleurt": -0.73286,
        "nubia": {
            "semantic_relation": 1.56415,
            "contradiction": 54.49542,
            "irrelevancy": 44.2061,
            "logical_agreement": 1.29847,
            "grammar_ref": 4.34568,
            "grammar_hyp": 3.44184,
            "nubia_score": 0.11438
        },
        "meteor": 0.08442784526435636,
        "bertscore": {
            "precision": 0.8153,
            "recall": 0.78345,
            "f1": 0.78295
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 88,
        "mean_pred_length": 17.6,
        "std_pred_length": 8.380930735902785,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.7613636363636364,
        "vocab_size-1": 67,
        "unique-1": 56,
        "entropy-1": 5.847223630217677,
        "distinct-2": 0.9879518072289156,
        "vocab_size-2": 82,
        "unique-2": 81,
        "entropy-2": 6.3509430458047635,
        "cond_entropy-2": 0.4007242284504751,
        "distinct-3": 1.0,
        "vocab_size-3": 78,
        "unique-3": 78,
        "entropy-3": 6.285402218862257,
        "cond_entropy-3": -0.06399618684365072,
        "total_length-nopunct": 81,
        "mean_pred_length-nopunct": 16.2,
        "std_pred_length-nopunct": 7.652450587883596,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.8024691358024691,
        "vocab_size-1-nopunct": 65,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.842755404039055,
        "distinct-2-nopunct": 0.9868421052631579,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.221611723969907,
        "cond_entropy-2-nopunct": 0.3984020172233085,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 71,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 6.149747119504677,
        "cond_entropy-3-nopunct": -0.07001137985439648,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.88731,
            "recall": 0.85669,
            "fmeasure": 0.8692
        },
        "rouge2": {
            "precision": 0.79753,
            "recall": 0.77185,
            "fmeasure": 0.78187
        },
        "rougeL": {
            "precision": 0.88731,
            "recall": 0.85669,
            "fmeasure": 0.8692
        },
        "rougeLsum": {
            "precision": 0.88731,
            "recall": 0.85669,
            "fmeasure": 0.8692
        },
        "local_recall": {
            "1": 0.027777777777777776,
            "2": 0.2857142857142857,
            "3": 0.5,
            "4": 0.5,
            "5": 0.14285714285714285,
            "6": 1.0,
            "7": 1.0,
            "8": 1.0,
            "9": 0.875,
            "10": 0.8571428571428571
        },
        "nist": 7.599972795071383,
        "bleu": 84.22183,
        "bleurt": 0.29096,
        "nubia": {
            "semantic_relation": 4.10667,
            "contradiction": 0.24636,
            "irrelevancy": 29.07565,
            "logical_agreement": 70.67799,
            "grammar_ref": 5.04038,
            "grammar_hyp": 5.02834,
            "nubia_score": 0.62198
        },
        "meteor": 0.5921169057865439,
        "bertscore": {
            "precision": 0.97572,
            "recall": 0.961,
            "f1": 0.96512
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_11": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.662,
        "msttr-100_nopunct": 0.755,
        "total_length": 593,
        "mean_pred_length": 29.65,
        "std_pred_length": 10.46553868656554,
        "median_pred_length": 29.5,
        "min_pred_length": 14,
        "max_pred_length": 55,
        "distinct-1": 0.5042158516020236,
        "vocab_size-1": 299,
        "unique-1": 239,
        "entropy-1": 7.135202022860348,
        "distinct-2": 0.8691099476439791,
        "vocab_size-2": 498,
        "unique-2": 459,
        "entropy-2": 8.81213616862351,
        "cond_entropy-2": 1.5985661938188638,
        "distinct-3": 0.9638336347197106,
        "vocab_size-3": 533,
        "unique-3": 516,
        "entropy-3": 9.034707709101749,
        "cond_entropy-3": 0.22077245042889884,
        "total_length-nopunct": 472,
        "mean_pred_length-nopunct": 23.6,
        "std_pred_length-nopunct": 7.742092740338364,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.6228813559322034,
        "vocab_size-1-nopunct": 294,
        "unique-1-nopunct": 239,
        "entropy-1-nopunct": 7.552894133690745,
        "distinct-2-nopunct": 0.9203539823008849,
        "vocab_size-2-nopunct": 416,
        "unique-2-nopunct": 393,
        "entropy-2-nopunct": 8.63024871588425,
        "cond_entropy-2-nopunct": 1.1136931957156162,
        "distinct-3-nopunct": 0.9745370370370371,
        "vocab_size-3-nopunct": 421,
        "unique-3-nopunct": 411,
        "entropy-3-nopunct": 8.702214151463963,
        "cond_entropy-3-nopunct": 0.07844368773393125,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.69993,
            "recall": 0.67242,
            "fmeasure": 0.66662
        },
        "rouge2": {
            "precision": 0.45051,
            "recall": 0.43777,
            "fmeasure": 0.43141
        },
        "rougeL": {
            "precision": 0.54093,
            "recall": 0.53233,
            "fmeasure": 0.52162
        },
        "rougeLsum": {
            "precision": 0.54093,
            "recall": 0.53233,
            "fmeasure": 0.52162
        },
        "local_recall": {
            "1": 0.10344827586206896,
            "2": 0.38461538461538464,
            "3": 0.7349397590361446
        },
        "nist": 6.1195179544519185,
        "bleu": 41.54356,
        "bleurt": 0.08126,
        "nubia": {
            "semantic_relation": 3.66393,
            "contradiction": 15.22411,
            "irrelevancy": 37.7768,
            "logical_agreement": 46.99909,
            "grammar_ref": 4.38156,
            "grammar_hyp": 4.19099,
            "nubia_score": 0.58157
        },
        "meteor": 0.35567775962746945,
        "bertscore": {
            "precision": 0.90773,
            "recall": 0.91472,
            "f1": 0.90661
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_12": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 26,
        "msttr-100": 0.64125,
        "msttr-100_nopunct": 0.70167,
        "total_length": 828,
        "mean_pred_length": 31.846153846153847,
        "std_pred_length": 10.357800136546324,
        "median_pred_length": 32.0,
        "min_pred_length": 14,
        "max_pred_length": 51,
        "distinct-1": 0.47342995169082125,
        "vocab_size-1": 392,
        "unique-1": 297,
        "entropy-1": 7.454927010768438,
        "distinct-2": 0.8316708229426434,
        "vocab_size-2": 667,
        "unique-2": 590,
        "entropy-2": 9.211221843038091,
        "cond_entropy-2": 1.6764832686079572,
        "distinct-3": 0.9458762886597938,
        "vocab_size-3": 734,
        "unique-3": 702,
        "entropy-3": 9.479410554810356,
        "cond_entropy-3": 0.262689369883686,
        "total_length-nopunct": 696,
        "mean_pred_length-nopunct": 26.76923076923077,
        "std_pred_length-nopunct": 8.450342242990436,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.5545977011494253,
        "vocab_size-1-nopunct": 386,
        "unique-1-nopunct": 295,
        "entropy-1-nopunct": 7.742556347105285,
        "distinct-2-nopunct": 0.8865671641791045,
        "vocab_size-2-nopunct": 594,
        "unique-2-nopunct": 546,
        "entropy-2-nopunct": 9.113765634655833,
        "cond_entropy-2-nopunct": 1.414299161975108,
        "distinct-3-nopunct": 0.9627329192546584,
        "vocab_size-3-nopunct": 620,
        "unique-3-nopunct": 604,
        "entropy-3-nopunct": 9.24396035637547,
        "cond_entropy-3-nopunct": 0.13350301817608698,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73412,
            "recall": 0.69454,
            "fmeasure": 0.70273
        },
        "rouge2": {
            "precision": 0.47076,
            "recall": 0.4497,
            "fmeasure": 0.4532
        },
        "rougeL": {
            "precision": 0.56185,
            "recall": 0.53275,
            "fmeasure": 0.53636
        },
        "rougeLsum": {
            "precision": 0.56185,
            "recall": 0.53275,
            "fmeasure": 0.53636
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3277310924369748,
            "3": 0.8083700440528634
        },
        "nist": 6.47915069436809,
        "bleu": 37.41804,
        "bleurt": 0.09101,
        "nubia": {
            "semantic_relation": 3.7029,
            "contradiction": 14.32176,
            "irrelevancy": 41.23641,
            "logical_agreement": 44.44183,
            "grammar_ref": 4.04917,
            "grammar_hyp": 3.96399,
            "nubia_score": 0.60756
        },
        "meteor": 0.3596400822645017,
        "bertscore": {
            "precision": 0.90948,
            "recall": 0.90923,
            "f1": 0.90682
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 28,
        "msttr-100": 0.73333,
        "msttr-100_nopunct": 0.778,
        "total_length": 630,
        "mean_pred_length": 22.5,
        "std_pred_length": 8.736213628994461,
        "median_pred_length": 21.0,
        "min_pred_length": 10,
        "max_pred_length": 51,
        "distinct-1": 0.5587301587301587,
        "vocab_size-1": 352,
        "unique-1": 285,
        "entropy-1": 7.665081472620463,
        "distinct-2": 0.9169435215946844,
        "vocab_size-2": 552,
        "unique-2": 520,
        "entropy-2": 9.040258168464195,
        "cond_entropy-2": 1.2207548463264422,
        "distinct-3": 0.9738675958188153,
        "vocab_size-3": 559,
        "unique-3": 549,
        "entropy-3": 9.106066443207268,
        "cond_entropy-3": 0.07175622288304269,
        "total_length-nopunct": 554,
        "mean_pred_length-nopunct": 19.785714285714285,
        "std_pred_length-nopunct": 6.778943990965928,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.6245487364620939,
        "vocab_size-1-nopunct": 346,
        "unique-1-nopunct": 285,
        "entropy-1-nopunct": 7.807717480755644,
        "distinct-2-nopunct": 0.94106463878327,
        "vocab_size-2-nopunct": 495,
        "unique-2-nopunct": 473,
        "entropy-2-nopunct": 8.904642961757904,
        "cond_entropy-2-nopunct": 1.1573082495691716,
        "distinct-3-nopunct": 0.9959839357429718,
        "vocab_size-3-nopunct": 496,
        "unique-3-nopunct": 494,
        "entropy-3-nopunct": 8.951969803553919,
        "cond_entropy-3-nopunct": 0.050860433705680094,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.87905,
            "recall": 0.85798,
            "fmeasure": 0.86379
        },
        "rouge2": {
            "precision": 0.78993,
            "recall": 0.7545,
            "fmeasure": 0.76236
        },
        "rougeL": {
            "precision": 0.85925,
            "recall": 0.85151,
            "fmeasure": 0.85089
        },
        "rougeLsum": {
            "precision": 0.85925,
            "recall": 0.85151,
            "fmeasure": 0.85089
        },
        "local_recall": {
            "1": 0.02119460500963391,
            "2": 0.07894736842105263,
            "3": 0.23684210526315788,
            "4": 0.5,
            "5": 0.6129032258064516,
            "6": 0.5873015873015873,
            "7": 0.8641975308641975,
            "8": 0.8870967741935484,
            "9": 0.9454545454545454,
            "10": 0.9883720930232558
        },
        "nist": 9.628827990806979,
        "bleu": 80.24908,
        "bleurt": 0.13656,
        "nubia": {
            "semantic_relation": 4.2038,
            "contradiction": 7.82885,
            "irrelevancy": 29.34533,
            "logical_agreement": 62.82582,
            "grammar_ref": 4.66117,
            "grammar_hyp": 4.78786,
            "nubia_score": 0.66323
        },
        "meteor": 0.5234297863510653,
        "bertscore": {
            "precision": 0.96757,
            "recall": 0.9662,
            "f1": 0.96273
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 7,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.78,
        "total_length": 178,
        "mean_pred_length": 25.428571428571427,
        "std_pred_length": 6.020373573058707,
        "median_pred_length": 27.0,
        "min_pred_length": 16,
        "max_pred_length": 37,
        "distinct-1": 0.7078651685393258,
        "vocab_size-1": 126,
        "unique-1": 112,
        "entropy-1": 6.5482423138280215,
        "distinct-2": 0.9590643274853801,
        "vocab_size-2": 164,
        "unique-2": 161,
        "entropy-2": 7.310457614437936,
        "cond_entropy-2": 0.6852618115196395,
        "distinct-3": 1.0,
        "vocab_size-3": 164,
        "unique-3": 164,
        "entropy-3": 7.357552004618105,
        "cond_entropy-3": 0.039483196906577804,
        "total_length-nopunct": 157,
        "mean_pred_length-nopunct": 22.428571428571427,
        "std_pred_length-nopunct": 4.467570220317683,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.7643312101910829,
        "vocab_size-1-nopunct": 120,
        "unique-1-nopunct": 110,
        "entropy-1-nopunct": 6.527599192282896,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 144,
        "unique-2-nopunct": 142,
        "entropy-2-nopunct": 7.119721837318527,
        "cond_entropy-2-nopunct": 0.6279169843440561,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 143,
        "unique-3-nopunct": 143,
        "entropy-3-nopunct": 7.159871336778397,
        "cond_entropy-3-nopunct": 0.04548990486013316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.90638,
            "recall": 0.93669,
            "fmeasure": 0.91913
        },
        "rouge2": {
            "precision": 0.83864,
            "recall": 0.87889,
            "fmeasure": 0.85544
        },
        "rougeL": {
            "precision": 0.89038,
            "recall": 0.93239,
            "fmeasure": 0.90951
        },
        "rougeLsum": {
            "precision": 0.89038,
            "recall": 0.93239,
            "fmeasure": 0.90951
        },
        "local_recall": {
            "1": 0.041176470588235294,
            "2": 0.13636363636363635,
            "3": 0.6,
            "4": 0.9166666666666666,
            "5": 0.9375,
            "6": 1.0,
            "7": 0.9333333333333333,
            "8": 0.96,
            "9": 1.0,
            "10": 1.0
        },
        "nist": 8.689584678562245,
        "bleu": 91.84737,
        "bleurt": 0.34107,
        "nubia": {
            "semantic_relation": 4.4066,
            "contradiction": 1.83885,
            "irrelevancy": 47.35794,
            "logical_agreement": 50.8032,
            "grammar_ref": 4.66733,
            "grammar_hyp": 4.58181,
            "nubia_score": 0.66824
        },
        "meteor": 0.5930127144877596,
        "bertscore": {
            "precision": 0.98282,
            "recall": 0.98666,
            "f1": 0.98386
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_13": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.63,
        "msttr-100_nopunct": 0.72,
        "total_length": 303,
        "mean_pred_length": 30.3,
        "std_pred_length": 10.109896141899778,
        "median_pred_length": 30.5,
        "min_pred_length": 10,
        "max_pred_length": 47,
        "distinct-1": 0.5643564356435643,
        "vocab_size-1": 171,
        "unique-1": 142,
        "entropy-1": 6.642902280999878,
        "distinct-2": 0.8771331058020477,
        "vocab_size-2": 257,
        "unique-2": 237,
        "entropy-2": 7.894282110335912,
        "cond_entropy-2": 1.1926202254993212,
        "distinct-3": 0.9646643109540636,
        "vocab_size-3": 273,
        "unique-3": 264,
        "entropy-3": 8.071319417735875,
        "cond_entropy-3": 0.17085306690073238,
        "total_length-nopunct": 245,
        "mean_pred_length-nopunct": 24.5,
        "std_pred_length-nopunct": 9.091204540653566,
        "median_pred_length-nopunct": 25.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.6816326530612244,
        "vocab_size-1-nopunct": 167,
        "unique-1-nopunct": 142,
        "entropy-1-nopunct": 6.9025803201504345,
        "distinct-2-nopunct": 0.9404255319148936,
        "vocab_size-2-nopunct": 221,
        "unique-2-nopunct": 211,
        "entropy-2-nopunct": 7.742432797610403,
        "cond_entropy-2-nopunct": 0.8710889718792357,
        "distinct-3-nopunct": 0.9866666666666667,
        "vocab_size-3-nopunct": 222,
        "unique-3-nopunct": 219,
        "entropy-3-nopunct": 7.7871145245503275,
        "cond_entropy-3-nopunct": 0.05064102244904577,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.69434,
            "recall": 0.61912,
            "fmeasure": 0.64295
        },
        "rouge2": {
            "precision": 0.43152,
            "recall": 0.38606,
            "fmeasure": 0.40091
        },
        "rougeL": {
            "precision": 0.52282,
            "recall": 0.47456,
            "fmeasure": 0.48911
        },
        "rougeLsum": {
            "precision": 0.52282,
            "recall": 0.47456,
            "fmeasure": 0.48911
        },
        "local_recall": {
            "1": 0.1780821917808219,
            "2": 0.4067796610169492,
            "3": 0.6712328767123288
        },
        "nist": 5.116138275237456,
        "bleu": 34.22372,
        "bleurt": 0.00036,
        "nubia": {
            "semantic_relation": 3.6665,
            "contradiction": 7.00555,
            "irrelevancy": 40.19863,
            "logical_agreement": 52.79581,
            "grammar_ref": 4.57725,
            "grammar_hyp": 4.61191,
            "nubia_score": 0.54725
        },
        "meteor": 0.33041096053740426,
        "bertscore": {
            "precision": 0.90317,
            "recall": 0.90002,
            "f1": 0.89807
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_14": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.655,
        "msttr-100_nopunct": 0.7,
        "total_length": 468,
        "mean_pred_length": 33.42857142857143,
        "std_pred_length": 13.324061402023705,
        "median_pred_length": 33.0,
        "min_pred_length": 13,
        "max_pred_length": 55,
        "distinct-1": 0.5534188034188035,
        "vocab_size-1": 259,
        "unique-1": 210,
        "entropy-1": 7.16398855072248,
        "distinct-2": 0.8744493392070485,
        "vocab_size-2": 397,
        "unique-2": 367,
        "entropy-2": 8.515811345315194,
        "cond_entropy-2": 1.2870349035249897,
        "distinct-3": 0.9568181818181818,
        "vocab_size-3": 421,
        "unique-3": 407,
        "entropy-3": 8.68641781009102,
        "cond_entropy-3": 0.16968699315189117,
        "total_length-nopunct": 401,
        "mean_pred_length-nopunct": 28.642857142857142,
        "std_pred_length-nopunct": 10.694505550963628,
        "median_pred_length-nopunct": 31.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.6309226932668329,
        "vocab_size-1-nopunct": 253,
        "unique-1-nopunct": 210,
        "entropy-1-nopunct": 7.300308146319599,
        "distinct-2-nopunct": 0.8863049095607235,
        "vocab_size-2-nopunct": 343,
        "unique-2-nopunct": 319,
        "entropy-2-nopunct": 8.315026965574676,
        "cond_entropy-2-nopunct": 1.0516054895940066,
        "distinct-3-nopunct": 0.9571045576407506,
        "vocab_size-3-nopunct": 357,
        "unique-3-nopunct": 345,
        "entropy-3-nopunct": 8.449145627202581,
        "cond_entropy-3-nopunct": 0.14199072347227767,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.64509,
            "recall": 0.72179,
            "fmeasure": 0.67386
        },
        "rouge2": {
            "precision": 0.38272,
            "recall": 0.44656,
            "fmeasure": 0.40435
        },
        "rougeL": {
            "precision": 0.55952,
            "recall": 0.63128,
            "fmeasure": 0.58657
        },
        "rougeLsum": {
            "precision": 0.55952,
            "recall": 0.63128,
            "fmeasure": 0.58657
        },
        "local_recall": {
            "1": 0.22857142857142856,
            "2": 0.5507246376811594,
            "3": 0.7415254237288136
        },
        "nist": 5.334063856507208,
        "bleu": 36.77742,
        "bleurt": 0.13351,
        "nubia": {
            "semantic_relation": 3.64648,
            "contradiction": 27.1957,
            "irrelevancy": 33.6235,
            "logical_agreement": 39.1808,
            "grammar_ref": 4.37064,
            "grammar_hyp": 3.9389,
            "nubia_score": 0.59263
        },
        "meteor": 0.356665509175662,
        "bertscore": {
            "precision": 0.9091,
            "recall": 0.91725,
            "f1": 0.91267
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 63,
        "msttr-100": 0.73765,
        "msttr-100_nopunct": 0.784,
        "total_length": 1710,
        "mean_pred_length": 27.142857142857142,
        "std_pred_length": 9.82038233965726,
        "median_pred_length": 27.0,
        "min_pred_length": 9,
        "max_pred_length": 46,
        "distinct-1": 0.4783625730994152,
        "vocab_size-1": 818,
        "unique-1": 654,
        "entropy-1": 8.341600559509793,
        "distinct-2": 0.9101396478445659,
        "vocab_size-2": 1499,
        "unique-2": 1427,
        "entropy-2": 10.428793357067692,
        "cond_entropy-2": 1.9411490269564216,
        "distinct-3": 0.9797979797979798,
        "vocab_size-3": 1552,
        "unique-3": 1543,
        "entropy-3": 10.55803949875798,
        "cond_entropy-3": 0.13756709081099688,
        "total_length-nopunct": 1529,
        "mean_pred_length-nopunct": 24.26984126984127,
        "std_pred_length-nopunct": 8.628499012742598,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.5297580117724002,
        "vocab_size-1-nopunct": 810,
        "unique-1-nopunct": 652,
        "entropy-1-nopunct": 8.564363156025648,
        "distinct-2-nopunct": 0.9338335607094134,
        "vocab_size-2-nopunct": 1369,
        "unique-2-nopunct": 1314,
        "entropy-2-nopunct": 10.342505664213306,
        "cond_entropy-2-nopunct": 1.8458008119767142,
        "distinct-3-nopunct": 0.9964362081254454,
        "vocab_size-3-nopunct": 1398,
        "unique-3-nopunct": 1393,
        "entropy-3-nopunct": 10.447171709871014,
        "cond_entropy-3-nopunct": 0.11253155856323083,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.87869,
            "recall": 0.8688,
            "fmeasure": 0.86587
        },
        "rouge2": {
            "precision": 0.77577,
            "recall": 0.76018,
            "fmeasure": 0.75885
        },
        "rougeL": {
            "precision": 0.86439,
            "recall": 0.86046,
            "fmeasure": 0.85394
        },
        "rougeLsum": {
            "precision": 0.86439,
            "recall": 0.86046,
            "fmeasure": 0.85394
        },
        "local_recall": {
            "1": 0.030204081632653063,
            "2": 0.20491803278688525,
            "3": 0.4298245614035088,
            "4": 0.6441717791411042,
            "5": 0.718562874251497,
            "6": 0.8064516129032258,
            "7": 0.8493975903614458,
            "8": 0.9116279069767442,
            "9": 0.9367816091954023,
            "10": 0.9537037037037037
        },
        "nist": 11.400989943025703,
        "bleu": 85.77423,
        "bleurt": 0.16113,
        "nubia": {
            "semantic_relation": 4.20349,
            "contradiction": 1.69431,
            "irrelevancy": 41.17531,
            "logical_agreement": 57.13037,
            "grammar_ref": 4.4268,
            "grammar_hyp": 4.5764,
            "nubia_score": 0.60617
        },
        "meteor": 0.5437358821491814,
        "bertscore": {
            "precision": 0.96618,
            "recall": 0.96881,
            "f1": 0.96516
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 71,
        "msttr-100": 0.64625,
        "msttr-100_nopunct": 0.69714,
        "total_length": 830,
        "mean_pred_length": 11.690140845070422,
        "std_pred_length": 4.728074822743232,
        "median_pred_length": 10.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.4457831325301205,
        "vocab_size-1": 370,
        "unique-1": 300,
        "entropy-1": 7.137902580443087,
        "distinct-2": 0.7931488801054019,
        "vocab_size-2": 602,
        "unique-2": 534,
        "entropy-2": 8.957212453440501,
        "cond_entropy-2": 1.4815350851828433,
        "distinct-3": 0.9011627906976745,
        "vocab_size-3": 620,
        "unique-3": 581,
        "entropy-3": 9.177015076829697,
        "cond_entropy-3": 0.21810708871967655,
        "total_length-nopunct": 737,
        "mean_pred_length-nopunct": 10.380281690140846,
        "std_pred_length-nopunct": 4.273621010380889,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.49525101763907736,
        "vocab_size-1-nopunct": 365,
        "unique-1-nopunct": 299,
        "entropy-1-nopunct": 7.3209485500797085,
        "distinct-2-nopunct": 0.7987987987987988,
        "vocab_size-2-nopunct": 532,
        "unique-2-nopunct": 476,
        "entropy-2-nopunct": 8.776502527639256,
        "cond_entropy-2-nopunct": 1.6075369699419697,
        "distinct-3-nopunct": 0.8957983193277311,
        "vocab_size-3-nopunct": 533,
        "unique-3-nopunct": 498,
        "entropy-3-nopunct": 8.951243331519903,
        "cond_entropy-3-nopunct": 0.23364718555726818,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79975,
            "recall": 0.78225,
            "fmeasure": 0.77301
        },
        "rouge2": {
            "precision": 0.62916,
            "recall": 0.63232,
            "fmeasure": 0.61602
        },
        "rougeL": {
            "precision": 0.76037,
            "recall": 0.75022,
            "fmeasure": 0.7381
        },
        "rougeLsum": {
            "precision": 0.76037,
            "recall": 0.75022,
            "fmeasure": 0.7381
        },
        "local_recall": {
            "1": 0.2905027932960894,
            "2": 0.6157894736842106,
            "3": 0.7931726907630522
        },
        "nist": 7.50064265179942,
        "bleu": 57.70195,
        "bleurt": 0.35095,
        "nubia": {
            "semantic_relation": 4.15519,
            "contradiction": 7.90874,
            "irrelevancy": 36.97382,
            "logical_agreement": 55.11744,
            "grammar_ref": 5.37595,
            "grammar_hyp": 5.43434,
            "nubia_score": 0.69278
        },
        "meteor": 0.4323468153806958,
        "bertscore": {
            "precision": 0.94669,
            "recall": 0.94532,
            "f1": 0.94432
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_15": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.68333,
        "msttr-100_nopunct": 0.75,
        "total_length": 366,
        "mean_pred_length": 26.142857142857142,
        "std_pred_length": 9.70903219288354,
        "median_pred_length": 23.5,
        "min_pred_length": 14,
        "max_pred_length": 45,
        "distinct-1": 0.5737704918032787,
        "vocab_size-1": 210,
        "unique-1": 171,
        "entropy-1": 6.972955251035185,
        "distinct-2": 0.9204545454545454,
        "vocab_size-2": 324,
        "unique-2": 310,
        "entropy-2": 8.256635942542797,
        "cond_entropy-2": 1.1936109622822608,
        "distinct-3": 0.9940828402366864,
        "vocab_size-3": 336,
        "unique-3": 335,
        "entropy-3": 8.386811721778706,
        "cond_entropy-3": 0.13857560013923778,
        "total_length-nopunct": 307,
        "mean_pred_length-nopunct": 21.928571428571427,
        "std_pred_length-nopunct": 7.4013925882159475,
        "median_pred_length-nopunct": 21.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.6644951140065146,
        "vocab_size-1-nopunct": 204,
        "unique-1-nopunct": 171,
        "entropy-1-nopunct": 7.108235895447942,
        "distinct-2-nopunct": 0.9419795221843004,
        "vocab_size-2-nopunct": 276,
        "unique-2-nopunct": 267,
        "entropy-2-nopunct": 8.047932451662382,
        "cond_entropy-2-nopunct": 0.9860073507474404,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 279,
        "unique-3-nopunct": 279,
        "entropy-3-nopunct": 8.124121311829194,
        "cond_entropy-3-nopunct": 0.07997216353114696,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.61963,
            "recall": 0.54153,
            "fmeasure": 0.56486
        },
        "rouge2": {
            "precision": 0.30834,
            "recall": 0.26837,
            "fmeasure": 0.27694
        },
        "rougeL": {
            "precision": 0.48713,
            "recall": 0.43499,
            "fmeasure": 0.4469
        },
        "rougeLsum": {
            "precision": 0.48713,
            "recall": 0.43499,
            "fmeasure": 0.4469
        },
        "local_recall": {
            "1": 0.2619047619047619,
            "2": 0.20588235294117646,
            "3": 0.5247148288973384
        },
        "nist": 4.134135826240573,
        "bleu": 21.12853,
        "bleurt": -0.06252,
        "nubia": {
            "semantic_relation": 3.50247,
            "contradiction": 26.84961,
            "irrelevancy": 25.77613,
            "logical_agreement": 47.37426,
            "grammar_ref": 3.91022,
            "grammar_hyp": 4.09461,
            "nubia_score": 0.54176
        },
        "meteor": 0.2717290831496788,
        "bertscore": {
            "precision": 0.88888,
            "recall": 0.87029,
            "f1": 0.87795
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_16": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.73,
        "total_length": 196,
        "mean_pred_length": 28.0,
        "std_pred_length": 4.6291004988627575,
        "median_pred_length": 27.0,
        "min_pred_length": 21,
        "max_pred_length": 37,
        "distinct-1": 0.5510204081632653,
        "vocab_size-1": 108,
        "unique-1": 79,
        "entropy-1": 6.1466412383155875,
        "distinct-2": 0.8518518518518519,
        "vocab_size-2": 161,
        "unique-2": 141,
        "entropy-2": 7.226211868642628,
        "cond_entropy-2": 1.0299674334285875,
        "distinct-3": 0.9230769230769231,
        "vocab_size-3": 168,
        "unique-3": 157,
        "entropy-3": 7.338811741835175,
        "cond_entropy-3": 0.12552412533016993,
        "total_length-nopunct": 160,
        "mean_pred_length-nopunct": 22.857142857142858,
        "std_pred_length-nopunct": 3.602720060833855,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6375,
        "vocab_size-1-nopunct": 102,
        "unique-1-nopunct": 77,
        "entropy-1-nopunct": 6.321627861806048,
        "distinct-2-nopunct": 0.8758169934640523,
        "vocab_size-2-nopunct": 134,
        "unique-2-nopunct": 120,
        "entropy-2-nopunct": 6.977944133528168,
        "cond_entropy-2-nopunct": 0.6890097464382761,
        "distinct-3-nopunct": 0.9452054794520548,
        "vocab_size-3-nopunct": 138,
        "unique-3-nopunct": 132,
        "entropy-3-nopunct": 7.066536887647144,
        "cond_entropy-3-nopunct": 0.10199074017478624,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.67393,
            "recall": 0.59412,
            "fmeasure": 0.62396
        },
        "rouge2": {
            "precision": 0.37035,
            "recall": 0.35346,
            "fmeasure": 0.35848
        },
        "rougeL": {
            "precision": 0.5363,
            "recall": 0.49738,
            "fmeasure": 0.5089
        },
        "rougeLsum": {
            "precision": 0.5363,
            "recall": 0.49738,
            "fmeasure": 0.5089
        },
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.48333333333333334,
            "3": 0.6956521739130435
        },
        "nist": 4.858300122761022,
        "bleu": 33.73587,
        "bleurt": 0.05231,
        "nubia": {
            "semantic_relation": 3.0059,
            "contradiction": 4.38573,
            "irrelevancy": 64.26177,
            "logical_agreement": 31.3525,
            "grammar_ref": 3.5611,
            "grammar_hyp": 3.56883,
            "nubia_score": 0.42676
        },
        "meteor": 0.30819793505805226,
        "bertscore": {
            "precision": 0.89935,
            "recall": 0.88468,
            "f1": 0.88981
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_17": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.79,
        "total_length": 247,
        "mean_pred_length": 41.166666666666664,
        "std_pred_length": 10.462897410479671,
        "median_pred_length": 36.5,
        "min_pred_length": 30,
        "max_pred_length": 60,
        "distinct-1": 0.6032388663967612,
        "vocab_size-1": 149,
        "unique-1": 125,
        "entropy-1": 6.614944080662865,
        "distinct-2": 0.9128630705394191,
        "vocab_size-2": 220,
        "unique-2": 209,
        "entropy-2": 7.683590062666338,
        "cond_entropy-2": 1.0374873259918602,
        "distinct-3": 0.9957446808510638,
        "vocab_size-3": 234,
        "unique-3": 233,
        "entropy-3": 7.868006308267109,
        "cond_entropy-3": 0.19027069513861292,
        "total_length-nopunct": 199,
        "mean_pred_length-nopunct": 33.166666666666664,
        "std_pred_length-nopunct": 5.580223014261069,
        "median_pred_length-nopunct": 31.0,
        "min_pred_length-nopunct": 29,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.7236180904522613,
        "vocab_size-1-nopunct": 144,
        "unique-1-nopunct": 124,
        "entropy-1-nopunct": 6.841047861976813,
        "distinct-2-nopunct": 0.9689119170984456,
        "vocab_size-2-nopunct": 187,
        "unique-2-nopunct": 183,
        "entropy-2-nopunct": 7.519918177164432,
        "cond_entropy-2-nopunct": 0.6932405771120064,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 187,
        "unique-3-nopunct": 187,
        "entropy-3-nopunct": 7.546894459887616,
        "cond_entropy-3-nopunct": 0.02395613919709636,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72392,
            "recall": 0.79343,
            "fmeasure": 0.75291
        },
        "rouge2": {
            "precision": 0.59729,
            "recall": 0.6578,
            "fmeasure": 0.6219
        },
        "rougeL": {
            "precision": 0.65882,
            "recall": 0.73265,
            "fmeasure": 0.68891
        },
        "rougeLsum": {
            "precision": 0.65882,
            "recall": 0.73265,
            "fmeasure": 0.68891
        },
        "local_recall": {
            "1": 0.5151515151515151,
            "2": 0.4444444444444444,
            "3": 0.8141592920353983
        },
        "nist": 5.635142045332182,
        "bleu": 55.83869,
        "bleurt": 0.22093,
        "nubia": {
            "semantic_relation": 3.68351,
            "contradiction": 33.28078,
            "irrelevancy": 31.53963,
            "logical_agreement": 35.17959,
            "grammar_ref": 3.81267,
            "grammar_hyp": 3.29749,
            "nubia_score": 0.64549
        },
        "meteor": 0.4461464892487165,
        "bertscore": {
            "precision": 0.91692,
            "recall": 0.93266,
            "f1": 0.92106
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02_parent": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72264,
        "msttr-100_nopunct": 0.76841,
        "total_length": 7213,
        "mean_pred_length": 20.091922005571032,
        "std_pred_length": 9.49445910452566,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.3666990156661583,
        "vocab_size-1": 2645,
        "unique-1": 1952,
        "entropy-1": 9.126331215578004,
        "distinct-2": 0.8262328567259994,
        "vocab_size-2": 5663,
        "unique-2": 5225,
        "entropy-2": 12.115099856400926,
        "cond_entropy-2": 2.7291720972784907,
        "distinct-3": 0.9575057736720555,
        "vocab_size-3": 6219,
        "unique-3": 6091,
        "entropy-3": 12.51846472638313,
        "cond_entropy-3": 0.42154667407596275,
        "total_length-nopunct": 6370,
        "mean_pred_length-nopunct": 17.74373259052925,
        "std_pred_length-nopunct": 8.28470137515936,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.41334379905808477,
        "vocab_size-1-nopunct": 2633,
        "unique-1-nopunct": 1949,
        "entropy-1-nopunct": 9.490784012020617,
        "distinct-2-nopunct": 0.8481117950424222,
        "vocab_size-2-nopunct": 5098,
        "unique-2-nopunct": 4740,
        "entropy-2-nopunct": 12.022647785553223,
        "cond_entropy-2-nopunct": 2.672958492128687,
        "distinct-3-nopunct": 0.97310686482661,
        "vocab_size-3-nopunct": 5500,
        "unique-3-nopunct": 5399,
        "entropy-3-nopunct": 12.396973766549186,
        "cond_entropy-3-nopunct": 0.40135611026316653,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.88638,
            "recall": 0.86124,
            "fmeasure": 0.86462
        },
        "rouge2": {
            "precision": 0.78287,
            "recall": 0.76144,
            "fmeasure": 0.76029
        },
        "rougeL": {
            "precision": 0.86875,
            "recall": 0.8461,
            "fmeasure": 0.84782
        },
        "rougeLsum": {
            "precision": 0.86875,
            "recall": 0.8461,
            "fmeasure": 0.84782
        },
        "local_recall": {
            "1": 0.03031973539140022,
            "2": 0.15566037735849056,
            "3": 0.336144578313253,
            "4": 0.555045871559633,
            "5": 0.6722306525037937,
            "6": 0.7492957746478873,
            "7": 0.8292349726775956,
            "8": 0.8576598311218335,
            "9": 0.9026455026455027,
            "10": 0.9441860465116279
        },
        "nist": 13.071812397108598,
        "bleu": 84.31801,
        "bleurt": 0.21901,
        "nubia": {
            "semantic_relation": 4.20837,
            "contradiction": 3.35002,
            "irrelevancy": 31.71486,
            "logical_agreement": 64.93513,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.775,
            "nubia_score": 0.6471
        },
        "meteor": 0.5239953121659693,
        "bertscore": {
            "precision": 0.96702,
            "recall": 0.96512,
            "f1": 0.9629
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 52,
        "msttr-100": 0.64429,
        "msttr-100_nopunct": 0.69167,
        "total_length": 755,
        "mean_pred_length": 14.51923076923077,
        "std_pred_length": 4.452701792669016,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.4291390728476821,
        "vocab_size-1": 324,
        "unique-1": 246,
        "entropy-1": 7.101947911918181,
        "distinct-2": 0.7766714082503556,
        "vocab_size-2": 546,
        "unique-2": 489,
        "entropy-2": 8.76398042693824,
        "cond_entropy-2": 1.4181944863525449,
        "distinct-3": 0.8863287250384024,
        "vocab_size-3": 577,
        "unique-3": 546,
        "entropy-3": 9.025882180691946,
        "cond_entropy-3": 0.2642481416156479,
        "total_length-nopunct": 649,
        "mean_pred_length-nopunct": 12.48076923076923,
        "std_pred_length-nopunct": 4.00715890441184,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.4915254237288136,
        "vocab_size-1-nopunct": 319,
        "unique-1-nopunct": 245,
        "entropy-1-nopunct": 7.2826046645642295,
        "distinct-2-nopunct": 0.8006700167504187,
        "vocab_size-2-nopunct": 478,
        "unique-2-nopunct": 433,
        "entropy-2-nopunct": 8.610278622905202,
        "cond_entropy-2-nopunct": 1.4096742966357771,
        "distinct-3-nopunct": 0.8990825688073395,
        "vocab_size-3-nopunct": 490,
        "unique-3-nopunct": 464,
        "entropy-3-nopunct": 8.821465208015194,
        "cond_entropy-3-nopunct": 0.24950062422757116,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73034,
            "recall": 0.74364,
            "fmeasure": 0.71946
        },
        "rouge2": {
            "precision": 0.52694,
            "recall": 0.50446,
            "fmeasure": 0.50485
        },
        "rougeL": {
            "precision": 0.67373,
            "recall": 0.68757,
            "fmeasure": 0.66382
        },
        "rougeLsum": {
            "precision": 0.67373,
            "recall": 0.68757,
            "fmeasure": 0.66382
        },
        "local_recall": {
            "1": 0.2894736842105263,
            "2": 0.5945945945945946,
            "3": 0.7660668380462725
        },
        "nist": 6.6443015984767,
        "bleu": 49.10023,
        "bleurt": 0.36102,
        "nubia": {
            "semantic_relation": 4.10143,
            "contradiction": 15.04738,
            "irrelevancy": 27.35529,
            "logical_agreement": 57.59734,
            "grammar_ref": 5.15177,
            "grammar_hyp": 4.99165,
            "nubia_score": 0.67469
        },
        "meteor": 0.4096619515003532,
        "bertscore": {
            "precision": 0.92951,
            "recall": 0.9298,
            "f1": 0.92692
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 254,
        "msttr-100": 0.45717,
        "msttr-100_nopunct": 0.46042,
        "total_length": 5309,
        "mean_pred_length": 20.901574803149607,
        "std_pred_length": 7.434368839362228,
        "median_pred_length": 19.0,
        "min_pred_length": 6,
        "max_pred_length": 45,
        "distinct-1": 0.1676398568468638,
        "vocab_size-1": 890,
        "unique-1": 541,
        "entropy-1": 5.664696592154575,
        "distinct-2": 0.390108803165183,
        "vocab_size-2": 1972,
        "unique-2": 1325,
        "entropy-2": 9.688403139071777,
        "cond_entropy-2": 3.9585812124623843,
        "distinct-3": 0.5850864403249323,
        "vocab_size-3": 2809,
        "unique-3": 2132,
        "entropy-3": 10.802266481655513,
        "cond_entropy-3": 1.1751145591922003,
        "total_length-nopunct": 4842,
        "mean_pred_length-nopunct": 19.062992125984252,
        "std_pred_length-nopunct": 7.2151939764671775,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.1825691862866584,
        "vocab_size-1-nopunct": 884,
        "unique-1-nopunct": 540,
        "entropy-1-nopunct": 5.562561852511567,
        "distinct-2-nopunct": 0.3818657367044464,
        "vocab_size-2-nopunct": 1752,
        "unique-2-nopunct": 1170,
        "entropy-2-nopunct": 9.470765932600782,
        "cond_entropy-2-nopunct": 4.1165898560147385,
        "distinct-3-nopunct": 0.5729118597138901,
        "vocab_size-3-nopunct": 2483,
        "unique-3-nopunct": 1885,
        "entropy-3-nopunct": 10.582979269386497,
        "cond_entropy-3-nopunct": 1.1820873230413869,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.332,
            "recall": 0.33593,
            "fmeasure": 0.33245
        },
        "rouge2": {
            "precision": 0.18947,
            "recall": 0.18799,
            "fmeasure": 0.18837
        },
        "rougeL": {
            "precision": 0.33003,
            "recall": 0.33445,
            "fmeasure": 0.33077
        },
        "rougeLsum": {
            "precision": 0.33003,
            "recall": 0.33445,
            "fmeasure": 0.33077
        },
        "local_recall": {
            "1": 0.10054347826086957,
            "2": 0.18169209431345354,
            "3": 0.24914675767918087,
            "4": 0.22857142857142856,
            "5": 0.2727272727272727,
            "6": 0.2,
            "7": 0.3333333333333333
        },
        "nist": 1.0471626027712235,
        "bleu": 3.30849,
        "bleurt": -0.3837,
        "nubia": {
            "semantic_relation": 3.34201,
            "contradiction": 36.82337,
            "irrelevancy": 15.44331,
            "logical_agreement": 47.73332,
            "grammar_ref": 2.90382,
            "grammar_hyp": 3.0008,
            "nubia_score": 0.20322
        },
        "meteor": 0.15166679796578675,
        "bertscore": {
            "precision": 0.86777,
            "recall": 0.87948,
            "f1": 0.87317
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 251,
        "msttr-100": 0.5194,
        "msttr-100_nopunct": 0.53041,
        "total_length": 8431,
        "mean_pred_length": 33.58964143426295,
        "std_pred_length": 10.257779686391114,
        "median_pred_length": 31.0,
        "min_pred_length": 14,
        "max_pred_length": 64,
        "distinct-1": 0.12916617245878306,
        "vocab_size-1": 1089,
        "unique-1": 380,
        "entropy-1": 7.876865403051653,
        "distinct-2": 0.3622249388753056,
        "vocab_size-2": 2963,
        "unique-2": 1634,
        "entropy-2": 10.704248752716728,
        "cond_entropy-2": 2.7094377138101065,
        "distinct-3": 0.5399167612561483,
        "vocab_size-3": 4281,
        "unique-3": 2921,
        "entropy-3": 11.561107273660888,
        "cond_entropy-3": 0.8860166212752005,
        "total_length-nopunct": 7434,
        "mean_pred_length-nopunct": 29.617529880478088,
        "std_pred_length-nopunct": 9.148461841089578,
        "median_pred_length-nopunct": 28.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.1451439332795265,
        "vocab_size-1-nopunct": 1079,
        "unique-1-nopunct": 378,
        "entropy-1-nopunct": 8.14483599585228,
        "distinct-2-nopunct": 0.38340526242517053,
        "vocab_size-2-nopunct": 2754,
        "unique-2-nopunct": 1593,
        "entropy-2-nopunct": 10.638565666261425,
        "cond_entropy-2-nopunct": 2.5757928545997117,
        "distinct-3-nopunct": 0.5572706289671091,
        "vocab_size-3-nopunct": 3863,
        "unique-3-nopunct": 2723,
        "entropy-3-nopunct": 11.424606890266956,
        "cond_entropy-3-nopunct": 0.8090629266038263,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.6848,
            "recall": 0.67163,
            "fmeasure": 0.67151
        },
        "rouge2": {
            "precision": 0.39092,
            "recall": 0.381,
            "fmeasure": 0.38194
        },
        "rougeL": {
            "precision": 0.49147,
            "recall": 0.48192,
            "fmeasure": 0.48144
        },
        "rougeLsum": {
            "precision": 0.49147,
            "recall": 0.48192,
            "fmeasure": 0.48144
        },
        "local_recall": {
            "1": 0.23029516704508596,
            "2": 0.5507109004739337,
            "3": 0.806497175141243
        },
        "nist": 7.51303829399894,
        "bleu": 39.92103,
        "bleurt": -0.0446,
        "nubia": {
            "semantic_relation": 3.94609,
            "contradiction": 26.88078,
            "irrelevancy": 10.65263,
            "logical_agreement": 62.46659,
            "grammar_ref": 4.22372,
            "grammar_hyp": 4.33437,
            "nubia_score": 0.64411
        },
        "meteor": 0.340942671056098,
        "bertscore": {
            "precision": 0.89196,
            "recall": 0.89159,
            "f1": 0.89041
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_18": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.81,
        "msttr-100_nopunct": 0.82,
        "total_length": 123,
        "mean_pred_length": 24.6,
        "std_pred_length": 7.605261336732617,
        "median_pred_length": 22.0,
        "min_pred_length": 18,
        "max_pred_length": 39,
        "distinct-1": 0.7235772357723578,
        "vocab_size-1": 89,
        "unique-1": 76,
        "entropy-1": 6.1445065547829625,
        "distinct-2": 0.9661016949152542,
        "vocab_size-2": 114,
        "unique-2": 110,
        "entropy-2": 6.8148464391923405,
        "cond_entropy-2": 0.6057669969377226,
        "distinct-3": 0.9911504424778761,
        "vocab_size-3": 112,
        "unique-3": 111,
        "entropy-3": 6.802479847370958,
        "cond_entropy-3": -0.009366741813910342,
        "total_length-nopunct": 107,
        "mean_pred_length-nopunct": 21.4,
        "std_pred_length-nopunct": 5.885575587824865,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.794392523364486,
        "vocab_size-1-nopunct": 85,
        "unique-1-nopunct": 76,
        "entropy-1-nopunct": 6.153673967806923,
        "distinct-2-nopunct": 0.9705882352941176,
        "vocab_size-2-nopunct": 99,
        "unique-2-nopunct": 96,
        "entropy-2-nopunct": 6.613601812559735,
        "cond_entropy-2-nopunct": 0.46339845840230875,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 97,
        "unique-3-nopunct": 97,
        "entropy-3-nopunct": 6.599912842187142,
        "cond_entropy-3-nopunct": -0.010656829681275173,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.6781,
            "recall": 0.59425,
            "fmeasure": 0.61659
        },
        "rouge2": {
            "precision": 0.42237,
            "recall": 0.39279,
            "fmeasure": 0.39395
        },
        "rougeL": {
            "precision": 0.54709,
            "recall": 0.49961,
            "fmeasure": 0.50733
        },
        "rougeLsum": {
            "precision": 0.54709,
            "recall": 0.49961,
            "fmeasure": 0.50733
        },
        "local_recall": {
            "1": 0.07142857142857142,
            "2": 0.5238095238095238,
            "3": 0.6266666666666667
        },
        "nist": 3.8196180013662016,
        "bleu": 27.64234,
        "bleurt": -0.17494,
        "nubia": {
            "semantic_relation": 3.1839,
            "contradiction": 25.25654,
            "irrelevancy": 22.66169,
            "logical_agreement": 52.08177,
            "grammar_ref": 3.87874,
            "grammar_hyp": 4.42466,
            "nubia_score": 0.44779
        },
        "meteor": 0.2768227392108811,
        "bertscore": {
            "precision": 0.87813,
            "recall": 0.88507,
            "f1": 0.87965
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_19": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.78,
        "msttr-100_nopunct": 0.85,
        "total_length": 120,
        "mean_pred_length": 24.0,
        "std_pred_length": 7.536577472566709,
        "median_pred_length": 23.0,
        "min_pred_length": 12,
        "max_pred_length": 33,
        "distinct-1": 0.7583333333333333,
        "vocab_size-1": 91,
        "unique-1": 79,
        "entropy-1": 6.224820000342161,
        "distinct-2": 1.0,
        "vocab_size-2": 115,
        "unique-2": 115,
        "entropy-2": 6.84549005094439,
        "cond_entropy-2": 0.5493718984447915,
        "distinct-3": 1.0,
        "vocab_size-3": 110,
        "unique-3": 110,
        "entropy-3": 6.781359713524669,
        "cond_entropy-3": -0.06413033741971554,
        "total_length-nopunct": 103,
        "mean_pred_length-nopunct": 20.6,
        "std_pred_length-nopunct": 6.343500610861482,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.8446601941747572,
        "vocab_size-1-nopunct": 87,
        "unique-1-nopunct": 77,
        "entropy-1-nopunct": 6.327087420303099,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 98,
        "unique-2-nopunct": 98,
        "entropy-2-nopunct": 6.614709844115218,
        "cond_entropy-2-nopunct": 0.30595982722437637,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 93,
        "unique-3-nopunct": 93,
        "entropy-3-nopunct": 6.539158811108037,
        "cond_entropy-3-nopunct": -0.07555103300717696,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.52112,
            "recall": 0.58587,
            "fmeasure": 0.54439
        },
        "rouge2": {
            "precision": 0.24432,
            "recall": 0.28862,
            "fmeasure": 0.25957
        },
        "rougeL": {
            "precision": 0.43573,
            "recall": 0.49462,
            "fmeasure": 0.45679
        },
        "rougeLsum": {
            "precision": 0.43573,
            "recall": 0.49462,
            "fmeasure": 0.45679
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.48484848484848486,
            "3": 0.6571428571428571
        },
        "nist": 3.423506801132947,
        "bleu": 17.18393,
        "bleurt": -0.07833,
        "nubia": {
            "semantic_relation": 3.09906,
            "contradiction": 47.65016,
            "irrelevancy": 48.30747,
            "logical_agreement": 4.04238,
            "grammar_ref": 5.00025,
            "grammar_hyp": 4.69031,
            "nubia_score": 0.41525
        },
        "meteor": 0.2989448154295501,
        "bertscore": {
            "precision": 0.8618,
            "recall": 0.89268,
            "f1": 0.87633
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-large (Baseline)/cs_restaurants_test",
        "N": 297,
        "msttr-100": 0.53232,
        "msttr-100_nopunct": 0.53808,
        "total_length": 5664,
        "mean_pred_length": 19.07070707070707,
        "std_pred_length": 7.176353601600365,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 39,
        "distinct-1": 0.0748587570621469,
        "vocab_size-1": 424,
        "unique-1": 166,
        "entropy-1": 6.133573904630082,
        "distinct-2": 0.21743991056456122,
        "vocab_size-2": 1167,
        "unique-2": 624,
        "entropy-2": 8.760983549731607,
        "cond_entropy-2": 2.52606271429385,
        "distinct-3": 0.34477317554240633,
        "vocab_size-3": 1748,
        "unique-3": 1116,
        "entropy-3": 9.48478841419146,
        "cond_entropy-3": 0.7421736107936044,
        "total_length-nopunct": 5209,
        "mean_pred_length-nopunct": 17.53872053872054,
        "std_pred_length-nopunct": 6.790219921215148,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.08062967940103667,
        "vocab_size-1-nopunct": 420,
        "unique-1-nopunct": 165,
        "entropy-1-nopunct": 6.136488626854011,
        "distinct-2-nopunct": 0.21661237785016288,
        "vocab_size-2-nopunct": 1064,
        "unique-2-nopunct": 562,
        "entropy-2-nopunct": 8.647187701138002,
        "cond_entropy-2-nopunct": 2.6180310767257056,
        "distinct-3-nopunct": 0.34821235102925246,
        "vocab_size-3-nopunct": 1607,
        "unique-3-nopunct": 1038,
        "entropy-3-nopunct": 9.364098944601968,
        "cond_entropy-3-nopunct": 0.7513093633122194,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.46519,
            "recall": 0.48317,
            "fmeasure": 0.45428
        },
        "rouge2": {
            "precision": 0.25554,
            "recall": 0.26061,
            "fmeasure": 0.24778
        },
        "rougeL": {
            "precision": 0.41944,
            "recall": 0.43501,
            "fmeasure": 0.40981
        },
        "rougeLsum": {
            "precision": 0.41944,
            "recall": 0.43501,
            "fmeasure": 0.40981
        },
        "local_recall": {
            "1": 0.30504171200580343
        },
        "nist": 1.4009319685867365,
        "bleu": 3.2164,
        "bleurt": -0.70729,
        "nubia": {
            "semantic_relation": 2.99604,
            "contradiction": 29.97675,
            "irrelevancy": 26.46612,
            "logical_agreement": 43.55712,
            "grammar_ref": 6.65825,
            "grammar_hyp": 5.93859,
            "nubia_score": 0.31473
        },
        "meteor": 0.13983396722676875,
        "bertscore": {
            "precision": 0.82101,
            "recall": 0.85001,
            "f1": 0.83494
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.702,
        "msttr-100_nopunct": 0.7475,
        "total_length": 557,
        "mean_pred_length": 15.472222222222221,
        "std_pred_length": 5.418518202070824,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.526032315978456,
        "vocab_size-1": 293,
        "unique-1": 243,
        "entropy-1": 7.235146587512408,
        "distinct-2": 0.8272552783109405,
        "vocab_size-2": 431,
        "unique-2": 395,
        "entropy-2": 8.537867681325624,
        "cond_entropy-2": 1.0731042191705282,
        "distinct-3": 0.9175257731958762,
        "vocab_size-3": 445,
        "unique-3": 424,
        "entropy-3": 8.718141993735443,
        "cond_entropy-3": 0.16695841078972576,
        "total_length-nopunct": 485,
        "mean_pred_length-nopunct": 13.472222222222221,
        "std_pred_length-nopunct": 4.193156535164775,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5876288659793815,
        "vocab_size-1-nopunct": 285,
        "unique-1-nopunct": 240,
        "entropy-1-nopunct": 7.360795284398869,
        "distinct-2-nopunct": 0.8285077951002228,
        "vocab_size-2-nopunct": 372,
        "unique-2-nopunct": 342,
        "entropy-2-nopunct": 8.327022052393133,
        "cond_entropy-2-nopunct": 1.0312549272288627,
        "distinct-3-nopunct": 0.9176755447941889,
        "vocab_size-3-nopunct": 379,
        "unique-3-nopunct": 361,
        "entropy-3-nopunct": 8.486513467745583,
        "cond_entropy-3-nopunct": 0.16349358838483902,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75529,
            "recall": 0.7303,
            "fmeasure": 0.72199
        },
        "rouge2": {
            "precision": 0.53553,
            "recall": 0.52336,
            "fmeasure": 0.51293
        },
        "rougeL": {
            "precision": 0.67265,
            "recall": 0.65075,
            "fmeasure": 0.64334
        },
        "rougeLsum": {
            "precision": 0.67265,
            "recall": 0.65075,
            "fmeasure": 0.64334
        },
        "local_recall": {
            "1": 0.19801980198019803,
            "2": 0.5238095238095238,
            "3": 0.7331378299120235
        },
        "nist": 6.3369139540155555,
        "bleu": 41.0471,
        "bleurt": 0.23531,
        "nubia": {
            "semantic_relation": 3.92457,
            "contradiction": 14.97344,
            "irrelevancy": 32.20733,
            "logical_agreement": 52.81923,
            "grammar_ref": 4.68979,
            "grammar_hyp": 4.53079,
            "nubia_score": 0.67424
        },
        "meteor": 0.37328234546139377,
        "bertscore": {
            "precision": 0.93108,
            "recall": 0.92311,
            "f1": 0.92539
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_20": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.8,
        "total_length": 124,
        "mean_pred_length": 24.8,
        "std_pred_length": 6.144916598294887,
        "median_pred_length": 27.0,
        "min_pred_length": 17,
        "max_pred_length": 34,
        "distinct-1": 0.7016129032258065,
        "vocab_size-1": 87,
        "unique-1": 76,
        "entropy-1": 6.026056711639546,
        "distinct-2": 0.9411764705882353,
        "vocab_size-2": 112,
        "unique-2": 107,
        "entropy-2": 6.764483519574103,
        "cond_entropy-2": 0.6798642660799247,
        "distinct-3": 0.9912280701754386,
        "vocab_size-3": 113,
        "unique-3": 112,
        "entropy-3": 6.815346154515631,
        "cond_entropy-3": 0.05657904914036805,
        "total_length-nopunct": 108,
        "mean_pred_length-nopunct": 21.6,
        "std_pred_length-nopunct": 4.223742416388575,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7870370370370371,
        "vocab_size-1-nopunct": 85,
        "unique-1-nopunct": 76,
        "entropy-1-nopunct": 6.149091928411418,
        "distinct-2-nopunct": 0.941747572815534,
        "vocab_size-2-nopunct": 97,
        "unique-2-nopunct": 92,
        "entropy-2-nopunct": 6.562666667938929,
        "cond_entropy-2-nopunct": 0.44298229165137337,
        "distinct-3-nopunct": 0.9795918367346939,
        "vocab_size-3-nopunct": 96,
        "unique-3-nopunct": 94,
        "entropy-3-nopunct": 6.573893517584606,
        "cond_entropy-3-nopunct": 0.017544903688759928,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.59042,
            "recall": 0.47573,
            "fmeasure": 0.51783
        },
        "rouge2": {
            "precision": 0.31355,
            "recall": 0.27619,
            "fmeasure": 0.28785
        },
        "rougeL": {
            "precision": 0.43949,
            "recall": 0.35448,
            "fmeasure": 0.38547
        },
        "rougeLsum": {
            "precision": 0.43949,
            "recall": 0.35448,
            "fmeasure": 0.38547
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.34375,
            "3": 0.5802469135802469
        },
        "nist": 2.558394525649051,
        "bleu": 19.72969,
        "bleurt": -0.16672,
        "nubia": {
            "semantic_relation": 3.14458,
            "contradiction": 2.09182,
            "irrelevancy": 49.30054,
            "logical_agreement": 48.60763,
            "grammar_ref": 4.13756,
            "grammar_hyp": 4.22344,
            "nubia_score": 0.44164
        },
        "meteor": 0.24326053052035243,
        "bertscore": {
            "precision": 0.88359,
            "recall": 0.81802,
            "f1": 0.84852
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_21": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": 0.53,
        "msttr-100_nopunct": 0.59,
        "total_length": 117,
        "mean_pred_length": 29.25,
        "std_pred_length": 12.193748398257199,
        "median_pred_length": 27.5,
        "min_pred_length": 14,
        "max_pred_length": 48,
        "distinct-1": 0.5470085470085471,
        "vocab_size-1": 64,
        "unique-1": 45,
        "entropy-1": 5.510590497961168,
        "distinct-2": 0.8672566371681416,
        "vocab_size-2": 98,
        "unique-2": 84,
        "entropy-2": 6.5480118163783585,
        "cond_entropy-2": 1.014758459005567,
        "distinct-3": 0.926605504587156,
        "vocab_size-3": 101,
        "unique-3": 93,
        "entropy-3": 6.621395333951228,
        "cond_entropy-3": 0.08337130274855942,
        "total_length-nopunct": 103,
        "mean_pred_length-nopunct": 25.75,
        "std_pred_length-nopunct": 10.497023387608508,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.6019417475728155,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.542089818630535,
        "distinct-2-nopunct": 0.8686868686868687,
        "vocab_size-2-nopunct": 86,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.3591052311688765,
        "cond_entropy-2-nopunct": 0.853153218944511,
        "distinct-3-nopunct": 0.9263157894736842,
        "vocab_size-3-nopunct": 88,
        "unique-3-nopunct": 81,
        "entropy-3-nopunct": 6.422487187278316,
        "cond_entropy-3-nopunct": 0.06423464616884866,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.56454,
            "recall": 0.5588,
            "fmeasure": 0.55111
        },
        "rouge2": {
            "precision": 0.25381,
            "recall": 0.29516,
            "fmeasure": 0.2667
        },
        "rougeL": {
            "precision": 0.4369,
            "recall": 0.44974,
            "fmeasure": 0.43252
        },
        "rougeLsum": {
            "precision": 0.4369,
            "recall": 0.44974,
            "fmeasure": 0.43252
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.3333333333333333,
            "3": 0.5595238095238095
        },
        "nist": 3.3971862455712016,
        "bleu": 13.61504,
        "bleurt": 0.07599,
        "nubia": {
            "semantic_relation": 3.43196,
            "contradiction": 31.35982,
            "irrelevancy": 5.05036,
            "logical_agreement": 63.58981,
            "grammar_ref": 3.12827,
            "grammar_hyp": 3.4013,
            "nubia_score": 0.52029
        },
        "meteor": 0.25557184968209623,
        "bertscore": {
            "precision": 0.88785,
            "recall": 0.85778,
            "f1": 0.87161
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_22": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.40952,
            "fmeasure": 0.48718
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.21727,
            "fmeasure": 0.26111
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.29524,
            "fmeasure": 0.35256
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.29524,
            "fmeasure": 0.35256
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.09090909090909091,
            "3": 0.6666666666666666
        },
        "nist": 0.5875750602742751,
        "bleu": 14.98256,
        "bleurt": 0.22809,
        "nubia": {
            "semantic_relation": 3.74321,
            "contradiction": 1.26871,
            "irrelevancy": 97.41854,
            "logical_agreement": 1.31274,
            "grammar_ref": 4.03834,
            "grammar_hyp": 4.23123,
            "nubia_score": 0.53242
        },
        "meteor": 0.24396432821326908,
        "bertscore": {
            "precision": 0.90854,
            "recall": 0.89141,
            "f1": 0.89159
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_23": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 73,
        "mean_pred_length": 36.5,
        "std_pred_length": 3.5,
        "median_pred_length": 36.5,
        "min_pred_length": 33,
        "max_pred_length": 40,
        "distinct-1": 0.7123287671232876,
        "vocab_size-1": 52,
        "unique-1": 43,
        "entropy-1": 5.391142880471829,
        "distinct-2": 0.9577464788732394,
        "vocab_size-2": 68,
        "unique-2": 65,
        "entropy-2": 6.065240077251157,
        "cond_entropy-2": 0.6684262581429478,
        "distinct-3": 1.0,
        "vocab_size-3": 69,
        "unique-3": 69,
        "entropy-3": 6.108524456778164,
        "cond_entropy-3": 0.04573385901261752,
        "total_length-nopunct": 62,
        "mean_pred_length-nopunct": 31.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 31.0,
        "min_pred_length-nopunct": 26,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.8064516129032258,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.506221511825304,
        "distinct-2-nopunct": 0.9833333333333333,
        "vocab_size-2-nopunct": 59,
        "unique-2-nopunct": 58,
        "entropy-2-nopunct": 5.873557262275184,
        "cond_entropy-2-nopunct": 0.3822682437352654,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.85798099512757,
        "cond_entropy-3-nopunct": -0.014426841860256882,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.37222,
            "recall": 0.49167,
            "fmeasure": 0.42302
        },
        "rouge2": {
            "precision": 0.17081,
            "recall": 0.20178,
            "fmeasure": 0.18398
        },
        "rougeL": {
            "precision": 0.29683,
            "recall": 0.40922,
            "fmeasure": 0.34365
        },
        "rougeLsum": {
            "precision": 0.29683,
            "recall": 0.40922,
            "fmeasure": 0.34365
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.38095238095238093,
            "3": 0.5789473684210527
        },
        "nist": 2.54214689966467,
        "bleu": 8.27222,
        "bleurt": 0.02792,
        "nubia": {
            "semantic_relation": 2.97655,
            "contradiction": 87.18272,
            "irrelevancy": 10.32199,
            "logical_agreement": 2.49529,
            "grammar_ref": 4.17,
            "grammar_hyp": 3.92153,
            "nubia_score": 0.47928
        },
        "meteor": 0.2335183247513793,
        "bertscore": {
            "precision": 0.85604,
            "recall": 0.87414,
            "f1": 0.86053
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 41,
        "msttr-100": 0.608,
        "msttr-100_nopunct": 0.66,
        "total_length": 555,
        "mean_pred_length": 13.536585365853659,
        "std_pred_length": 4.849428233712938,
        "median_pred_length": 13.0,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.45225225225225224,
        "vocab_size-1": 251,
        "unique-1": 202,
        "entropy-1": 6.833994510197046,
        "distinct-2": 0.7879377431906615,
        "vocab_size-2": 405,
        "unique-2": 366,
        "entropy-2": 8.387655653606446,
        "cond_entropy-2": 1.3055897682317998,
        "distinct-3": 0.8837209302325582,
        "vocab_size-3": 418,
        "unique-3": 395,
        "entropy-3": 8.565052075405518,
        "cond_entropy-3": 0.1879084656520823,
        "total_length-nopunct": 478,
        "mean_pred_length-nopunct": 11.658536585365853,
        "std_pred_length-nopunct": 4.15322241097235,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5125523012552301,
        "vocab_size-1-nopunct": 245,
        "unique-1-nopunct": 201,
        "entropy-1-nopunct": 6.953773407869175,
        "distinct-2-nopunct": 0.8100686498855835,
        "vocab_size-2-nopunct": 354,
        "unique-2-nopunct": 323,
        "entropy-2-nopunct": 8.218067129935019,
        "cond_entropy-2-nopunct": 1.3723407275236155,
        "distinct-3-nopunct": 0.898989898989899,
        "vocab_size-3-nopunct": 356,
        "unique-3-nopunct": 338,
        "entropy-3-nopunct": 8.354372142833267,
        "cond_entropy-3-nopunct": 0.15067449755009862,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77889,
            "recall": 0.7511,
            "fmeasure": 0.75798
        },
        "rouge2": {
            "precision": 0.57481,
            "recall": 0.54701,
            "fmeasure": 0.55353
        },
        "rougeL": {
            "precision": 0.67776,
            "recall": 0.65035,
            "fmeasure": 0.65627
        },
        "rougeLsum": {
            "precision": 0.67776,
            "recall": 0.65035,
            "fmeasure": 0.65627
        },
        "local_recall": {
            "1": 0.28888888888888886,
            "2": 0.5371900826446281,
            "3": 0.7818181818181819
        },
        "nist": 6.602093133118456,
        "bleu": 47.8621,
        "bleurt": 0.35397,
        "nubia": {
            "semantic_relation": 4.06589,
            "contradiction": 8.81546,
            "irrelevancy": 28.01441,
            "logical_agreement": 63.17013,
            "grammar_ref": 4.45723,
            "grammar_hyp": 4.52537,
            "nubia_score": 0.72341
        },
        "meteor": 0.4151305791076374,
        "bertscore": {
            "precision": 0.93928,
            "recall": 0.93542,
            "f1": 0.93544
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-large (Baseline)/cs_restaurants_test",
        "N": 86,
        "msttr-100": 0.53316,
        "msttr-100_nopunct": 0.54294,
        "total_length": 1919,
        "mean_pred_length": 22.313953488372093,
        "std_pred_length": 5.387888286136154,
        "median_pred_length": 22.0,
        "min_pred_length": 13,
        "max_pred_length": 35,
        "distinct-1": 0.1464304325169359,
        "vocab_size-1": 281,
        "unique-1": 121,
        "entropy-1": 6.098612109153657,
        "distinct-2": 0.36770321876704853,
        "vocab_size-2": 674,
        "unique-2": 399,
        "entropy-2": 8.57867297762157,
        "cond_entropy-2": 2.4127046146189,
        "distinct-3": 0.5134516313680595,
        "vocab_size-3": 897,
        "unique-3": 633,
        "entropy-3": 9.17209339231789,
        "cond_entropy-3": 0.5941108830957814,
        "total_length-nopunct": 1776,
        "mean_pred_length-nopunct": 20.651162790697676,
        "std_pred_length-nopunct": 5.034225747865896,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.15653153153153154,
        "vocab_size-1-nopunct": 278,
        "unique-1-nopunct": 121,
        "entropy-1-nopunct": 6.0930535146583065,
        "distinct-2-nopunct": 0.37100591715976333,
        "vocab_size-2-nopunct": 627,
        "unique-2-nopunct": 369,
        "entropy-2-nopunct": 8.478287813287674,
        "cond_entropy-2-nopunct": 2.474665458731843,
        "distinct-3-nopunct": 0.5199501246882793,
        "vocab_size-3-nopunct": 834,
        "unique-3-nopunct": 592,
        "entropy-3-nopunct": 9.080785297304118,
        "cond_entropy-3-nopunct": 0.5872129321353546,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.57222,
            "recall": 0.46838,
            "fmeasure": 0.50842
        },
        "rouge2": {
            "precision": 0.31018,
            "recall": 0.25311,
            "fmeasure": 0.27487
        },
        "rougeL": {
            "precision": 0.48912,
            "recall": 0.39724,
            "fmeasure": 0.4329
        },
        "rougeLsum": {
            "precision": 0.48912,
            "recall": 0.39724,
            "fmeasure": 0.4329
        },
        "local_recall": {
            "1": 0.2935361216730038
        },
        "nist": 1.8120543921968333,
        "bleu": 4.66585,
        "bleurt": -0.5866,
        "nubia": {
            "semantic_relation": 2.75015,
            "contradiction": 25.46752,
            "irrelevancy": 22.34893,
            "logical_agreement": 52.18355,
            "grammar_ref": 6.22337,
            "grammar_hyp": 5.81666,
            "nubia_score": 0.46639
        },
        "meteor": 0.12906711843714638,
        "bertscore": {
            "precision": 0.83093,
            "recall": 0.85117,
            "f1": 0.84082
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_24": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": 0.64,
        "msttr-100_nopunct": NaN,
        "total_length": 112,
        "mean_pred_length": 28.0,
        "std_pred_length": 11.335784048754634,
        "median_pred_length": 24.0,
        "min_pred_length": 17,
        "max_pred_length": 47,
        "distinct-1": 0.6071428571428571,
        "vocab_size-1": 68,
        "unique-1": 53,
        "entropy-1": 5.636272248318938,
        "distinct-2": 0.8703703703703703,
        "vocab_size-2": 94,
        "unique-2": 84,
        "entropy-2": 6.444611807678951,
        "cond_entropy-2": 0.7776389176466355,
        "distinct-3": 0.9423076923076923,
        "vocab_size-3": 98,
        "unique-3": 92,
        "entropy-3": 6.585055102756484,
        "cond_entropy-3": 0.15237697563461314,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 20.75,
        "std_pred_length-nopunct": 3.112474899497183,
        "median_pred_length-nopunct": 21.5,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7590361445783133,
        "vocab_size-1-nopunct": 63,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 5.758638714976686,
        "distinct-2-nopunct": 0.9367088607594937,
        "vocab_size-2-nopunct": 74,
        "unique-2-nopunct": 69,
        "entropy-2-nopunct": 6.1771984696960915,
        "cond_entropy-2-nopunct": 0.43711168972549697,
        "distinct-3-nopunct": 0.96,
        "vocab_size-3-nopunct": 72,
        "unique-3-nopunct": 69,
        "entropy-3-nopunct": 6.148818690495889,
        "cond_entropy-3-nopunct": -0.034962057681222174,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78815,
            "recall": 0.61007,
            "fmeasure": 0.68296
        },
        "rouge2": {
            "precision": 0.63409,
            "recall": 0.48182,
            "fmeasure": 0.54342
        },
        "rougeL": {
            "precision": 0.77728,
            "recall": 0.60257,
            "fmeasure": 0.67414
        },
        "rougeLsum": {
            "precision": 0.77728,
            "recall": 0.60257,
            "fmeasure": 0.67414
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.4772727272727273,
            "3": 0.631578947368421
        },
        "nist": 4.634436887314611,
        "bleu": 54.88388,
        "bleurt": 0.06564,
        "nubia": {
            "semantic_relation": 3.79562,
            "contradiction": 12.22302,
            "irrelevancy": 26.4569,
            "logical_agreement": 61.32008,
            "grammar_ref": 4.25341,
            "grammar_hyp": 4.16238,
            "nubia_score": 0.61874
        },
        "meteor": 0.3849167813136198,
        "bertscore": {
            "precision": 0.93962,
            "recall": 0.90362,
            "f1": 0.91725
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-large (Baseline)/cs_restaurants_test",
        "N": 9,
        "msttr-100": 0.585,
        "msttr-100_nopunct": 0.64,
        "total_length": 218,
        "mean_pred_length": 24.22222222222222,
        "std_pred_length": 5.328701692569688,
        "median_pred_length": 25.0,
        "min_pred_length": 17,
        "max_pred_length": 33,
        "distinct-1": 0.42201834862385323,
        "vocab_size-1": 92,
        "unique-1": 56,
        "entropy-1": 5.619724289748145,
        "distinct-2": 0.7464114832535885,
        "vocab_size-2": 156,
        "unique-2": 122,
        "entropy-2": 7.1139942111797225,
        "cond_entropy-2": 1.4502833917773892,
        "distinct-3": 0.87,
        "vocab_size-3": 174,
        "unique-3": 157,
        "entropy-3": 7.340710237359285,
        "cond_entropy-3": 0.22964301010929478,
        "total_length-nopunct": 198,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 5.41602560309064,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.45454545454545453,
        "vocab_size-1-nopunct": 90,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.600158565441818,
        "distinct-2-nopunct": 0.7566137566137566,
        "vocab_size-2-nopunct": 143,
        "unique-2-nopunct": 113,
        "entropy-2-nopunct": 6.9921439799784615,
        "cond_entropy-2-nopunct": 1.446466886531758,
        "distinct-3-nopunct": 0.8777777777777778,
        "vocab_size-3-nopunct": 158,
        "unique-3-nopunct": 143,
        "entropy-3-nopunct": 7.207856343669863,
        "cond_entropy-3-nopunct": 0.20551848432209383,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.56692,
            "recall": 0.47387,
            "fmeasure": 0.50133
        },
        "rouge2": {
            "precision": 0.30748,
            "recall": 0.25267,
            "fmeasure": 0.26927
        },
        "rougeL": {
            "precision": 0.46156,
            "recall": 0.36433,
            "fmeasure": 0.39603
        },
        "rougeLsum": {
            "precision": 0.46156,
            "recall": 0.36433,
            "fmeasure": 0.39603
        },
        "local_recall": {
            "1": 0.34814814814814815
        },
        "nist": 1.6742796118976087,
        "bleu": 7.05837,
        "bleurt": -0.53727,
        "nubia": {
            "semantic_relation": 2.82506,
            "contradiction": 26.28653,
            "irrelevancy": 23.97117,
            "logical_agreement": 49.7423,
            "grammar_ref": 6.01604,
            "grammar_hyp": 5.85013,
            "nubia_score": 0.35099
        },
        "meteor": 0.17097260746394408,
        "bertscore": {
            "precision": 0.84657,
            "recall": 0.86825,
            "f1": 0.85704
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_25": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.029610672108601983,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.03310859910983796,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.68421,
            "recall": 0.8125,
            "fmeasure": 0.74286
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.46667,
            "fmeasure": 0.42424
        },
        "rougeL": {
            "precision": 0.57895,
            "recall": 0.6875,
            "fmeasure": 0.62857
        },
        "rougeLsum": {
            "precision": 0.57895,
            "recall": 0.6875,
            "fmeasure": 0.62857
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.5714285714285714,
            "3": 1.0
        },
        "nist": 3.4658188131790992,
        "bleu": 17.27761,
        "bleurt": 0.27075,
        "nubia": {
            "semantic_relation": 4.17251,
            "contradiction": 0.11516,
            "irrelevancy": 69.60048,
            "logical_agreement": 30.28436,
            "grammar_ref": 3.92881,
            "grammar_hyp": 3.4485,
            "nubia_score": 0.84735
        },
        "meteor": 0.3846037752343375,
        "bertscore": {
            "precision": 0.92032,
            "recall": 0.93023,
            "f1": 0.92525
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_27": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 0.5,
        "median_pred_length": 13.5,
        "min_pred_length": 13,
        "max_pred_length": 14,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 24,
        "unique-1": 21,
        "entropy-1": 4.532665279941249,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.048968687611256015,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.92,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.4838561897747224,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.05361880976054911,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.4881,
            "recall": 0.46418,
            "fmeasure": 0.47461
        },
        "rouge2": {
            "precision": 0.26923,
            "recall": 0.25694,
            "fmeasure": 0.2623
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.43773,
            "fmeasure": 0.43298
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.43773,
            "fmeasure": 0.43298
        },
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.0,
            "3": 0.3888888888888889
        },
        "nist": 1.7225953677085906,
        "bleu": 5.6119,
        "bleurt": -0.15486,
        "nubia": {
            "semantic_relation": 4.05706,
            "contradiction": 0.34107,
            "irrelevancy": 58.45804,
            "logical_agreement": 41.20089,
            "grammar_ref": 5.41182,
            "grammar_hyp": 5.8276,
            "nubia_score": 0.57019
        },
        "meteor": 0.20285416320746094,
        "bertscore": {
            "precision": 0.84691,
            "recall": 0.84444,
            "f1": 0.84371
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_28": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 71,
        "mean_pred_length": 35.5,
        "std_pred_length": 16.5,
        "median_pred_length": 35.5,
        "min_pred_length": 19,
        "max_pred_length": 52,
        "distinct-1": 0.6619718309859155,
        "vocab_size-1": 47,
        "unique-1": 34,
        "entropy-1": 5.305040521602751,
        "distinct-2": 0.8695652173913043,
        "vocab_size-2": 60,
        "unique-2": 54,
        "entropy-2": 5.807728985732317,
        "cond_entropy-2": 0.4981872060977424,
        "distinct-3": 0.9402985074626866,
        "vocab_size-3": 63,
        "unique-3": 59,
        "entropy-3": 5.946686205383141,
        "cond_entropy-3": 0.1479361889357747,
        "total_length-nopunct": 65,
        "mean_pred_length-nopunct": 32.5,
        "std_pred_length-nopunct": 14.5,
        "median_pred_length-nopunct": 32.5,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.676923076923077,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.191995990704809,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.647837264735419,
        "cond_entropy-2-nopunct": 0.4663292683900908,
        "distinct-3-nopunct": 0.9344262295081968,
        "vocab_size-3-nopunct": 57,
        "unique-3-nopunct": 53,
        "entropy-3-nopunct": 5.799589796579275,
        "cond_entropy-3-nopunct": 0.16255393049187905,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.29202,
            "recall": 0.49683,
            "fmeasure": 0.3634
        },
        "rouge2": {
            "precision": 0.11423,
            "recall": 0.22662,
            "fmeasure": 0.15065
        },
        "rougeL": {
            "precision": 0.23138,
            "recall": 0.43651,
            "fmeasure": 0.30006
        },
        "rougeLsum": {
            "precision": 0.23138,
            "recall": 0.43651,
            "fmeasure": 0.30006
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.2,
            "3": 0.5454545454545454
        },
        "nist": 1.67218020713629,
        "bleu": 7.07579,
        "bleurt": -0.07174,
        "nubia": {
            "semantic_relation": 2.80254,
            "contradiction": 0.52919,
            "irrelevancy": 99.35184,
            "logical_agreement": 0.11898,
            "grammar_ref": 5.71002,
            "grammar_hyp": 4.27167,
            "nubia_score": 0.4248
        },
        "meteor": 0.22046292093338096,
        "bertscore": {
            "precision": 0.79936,
            "recall": 0.87759,
            "f1": 0.82494
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 159,
        "msttr-100": 0.45417,
        "msttr-100_nopunct": 0.4499,
        "total_length": 10345,
        "mean_pred_length": 65.062893081761,
        "std_pred_length": 8.953187503500931,
        "median_pred_length": 67.0,
        "min_pred_length": 42,
        "max_pred_length": 85,
        "distinct-1": 0.11406476558724021,
        "vocab_size-1": 1180,
        "unique-1": 570,
        "entropy-1": 5.7719647580765185,
        "distinct-2": 0.2873551934027096,
        "vocab_size-2": 2927,
        "unique-2": 1699,
        "entropy-2": 9.870794879517675,
        "cond_entropy-2": 4.114430055524729,
        "distinct-3": 0.4913732921112995,
        "vocab_size-3": 4927,
        "unique-3": 3342,
        "entropy-3": 11.43638958568775,
        "cond_entropy-3": 1.5784619090166936,
        "total_length-nopunct": 9604,
        "mean_pred_length-nopunct": 60.40251572327044,
        "std_pred_length-nopunct": 9.108099579378017,
        "median_pred_length-nopunct": 62.0,
        "min_pred_length-nopunct": 37,
        "max_pred_length-nopunct": 79,
        "distinct-1-nopunct": 0.12213660974593919,
        "vocab_size-1-nopunct": 1173,
        "unique-1-nopunct": 569,
        "entropy-1-nopunct": 5.672864212777691,
        "distinct-2-nopunct": 0.2930651138168343,
        "vocab_size-2-nopunct": 2768,
        "unique-2-nopunct": 1610,
        "entropy-2-nopunct": 9.789012623312674,
        "cond_entropy-2-nopunct": 4.157098927429286,
        "distinct-3-nopunct": 0.492677148395434,
        "vocab_size-3-nopunct": 4575,
        "unique-3-nopunct": 3125,
        "entropy-3-nopunct": 11.307082691727176,
        "cond_entropy-3-nopunct": 1.5279489257636887,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.44021,
            "recall": 0.37848,
            "fmeasure": 0.39445
        },
        "rouge2": {
            "precision": 0.19925,
            "recall": 0.17789,
            "fmeasure": 0.183
        },
        "rougeL": {
            "precision": 0.41188,
            "recall": 0.3567,
            "fmeasure": 0.37033
        },
        "rougeLsum": {
            "precision": 0.41188,
            "recall": 0.3567,
            "fmeasure": 0.37033
        },
        "local_recall": {
            "1": 0.0705003248862898,
            "2": 0.1607717041800643,
            "3": 0.2530541012216405
        },
        "nist": 0.9769544618898331,
        "bleu": 1.32885,
        "bleurt": -0.5325,
        "nubia": {
            "semantic_relation": 3.33111,
            "contradiction": 33.677,
            "irrelevancy": 18.00736,
            "logical_agreement": 48.31564,
            "grammar_ref": 2.45758,
            "grammar_hyp": 2.3572,
            "nubia_score": 0.12198
        },
        "meteor": 0.10898367502683932,
        "bertscore": {
            "precision": 0.85431,
            "recall": 0.86508,
            "f1": 0.85924
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05_parent": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72264,
        "msttr-100_nopunct": 0.76841,
        "total_length": 7213,
        "mean_pred_length": 20.091922005571032,
        "std_pred_length": 9.49445910452566,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.3666990156661583,
        "vocab_size-1": 2645,
        "unique-1": 1952,
        "entropy-1": 9.126331215578004,
        "distinct-2": 0.8262328567259994,
        "vocab_size-2": 5663,
        "unique-2": 5225,
        "entropy-2": 12.115099856400926,
        "cond_entropy-2": 2.7291720972784907,
        "distinct-3": 0.9575057736720555,
        "vocab_size-3": 6219,
        "unique-3": 6091,
        "entropy-3": 12.51846472638313,
        "cond_entropy-3": 0.42154667407596275,
        "total_length-nopunct": 6370,
        "mean_pred_length-nopunct": 17.74373259052925,
        "std_pred_length-nopunct": 8.28470137515936,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.41334379905808477,
        "vocab_size-1-nopunct": 2633,
        "unique-1-nopunct": 1949,
        "entropy-1-nopunct": 9.490784012020617,
        "distinct-2-nopunct": 0.8481117950424222,
        "vocab_size-2-nopunct": 5098,
        "unique-2-nopunct": 4740,
        "entropy-2-nopunct": 12.022647785553223,
        "cond_entropy-2-nopunct": 2.672958492128687,
        "distinct-3-nopunct": 0.97310686482661,
        "vocab_size-3-nopunct": 5500,
        "unique-3-nopunct": 5399,
        "entropy-3-nopunct": 12.396973766549186,
        "cond_entropy-3-nopunct": 0.40135611026316653,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.88638,
            "recall": 0.86124,
            "fmeasure": 0.86462
        },
        "rouge2": {
            "precision": 0.78287,
            "recall": 0.76144,
            "fmeasure": 0.76029
        },
        "rougeL": {
            "precision": 0.86875,
            "recall": 0.8461,
            "fmeasure": 0.84782
        },
        "rougeLsum": {
            "precision": 0.86875,
            "recall": 0.8461,
            "fmeasure": 0.84782
        },
        "local_recall": {
            "1": 0.03031973539140022,
            "2": 0.15566037735849056,
            "3": 0.336144578313253,
            "4": 0.555045871559633,
            "5": 0.6722306525037937,
            "6": 0.7492957746478873,
            "7": 0.8292349726775956,
            "8": 0.8576598311218335,
            "9": 0.9026455026455027,
            "10": 0.9441860465116279
        },
        "nist": 13.071812397108598,
        "bleu": 84.31801,
        "bleurt": 0.21901,
        "nubia": {
            "semantic_relation": 4.20837,
            "contradiction": 3.35002,
            "irrelevancy": 31.71486,
            "logical_agreement": 64.93513,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.775,
            "nubia_score": 0.6471
        },
        "meteor": 0.5239953121659693,
        "bertscore": {
            "precision": 0.96702,
            "recall": 0.96512,
            "f1": 0.9629
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_32": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 30.0,
        "std_pred_length": 0.0,
        "median_pred_length": 30.0,
        "min_pred_length": 30,
        "max_pred_length": 30,
        "distinct-1": 0.7333333333333333,
        "vocab_size-1": 22,
        "unique-1": 18,
        "entropy-1": 4.1898980954642875,
        "distinct-2": 0.896551724137931,
        "vocab_size-2": 26,
        "unique-2": 23,
        "entropy-2": 4.651084443403434,
        "cond_entropy-2": 0.48591022725446514,
        "distinct-3": 0.9285714285714286,
        "vocab_size-3": 26,
        "unique-3": 24,
        "entropy-3": 4.664497779200463,
        "cond_entropy-3": 0.020802498358603594,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8695652173913043,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.262692390839622,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.368522527728205,
        "cond_entropy-2-nopunct": 0.11768784439846627,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": 0.02812389937955851,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75,
            "recall": 0.4362,
            "fmeasure": 0.55102
        },
        "rouge2": {
            "precision": 0.52174,
            "recall": 0.30065,
            "fmeasure": 0.38075
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.33815,
            "fmeasure": 0.4277
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.33815,
            "fmeasure": 0.4277
        },
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.4642857142857143
        },
        "nist": 2.008539351797713,
        "bleu": 29.35005,
        "bleurt": -0.54789,
        "nubia": {
            "semantic_relation": 2.634,
            "contradiction": 42.64678,
            "irrelevancy": 47.72792,
            "logical_agreement": 9.62531,
            "grammar_ref": 4.14314,
            "grammar_hyp": 4.16278,
            "nubia_score": 0.19845
        },
        "meteor": 0.25723170258327843,
        "bertscore": {
            "precision": 0.94866,
            "recall": 0.86277,
            "f1": 0.90368
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 29,
        "msttr-100": 0.45579,
        "msttr-100_nopunct": 0.45167,
        "total_length": 1968,
        "mean_pred_length": 67.86206896551724,
        "std_pred_length": 4.174835432899779,
        "median_pred_length": 68.0,
        "min_pred_length": 59,
        "max_pred_length": 75,
        "distinct-1": 0.18648373983739838,
        "vocab_size-1": 367,
        "unique-1": 203,
        "entropy-1": 5.308765293732354,
        "distinct-2": 0.4156781846312532,
        "vocab_size-2": 806,
        "unique-2": 507,
        "entropy-2": 8.782354708605503,
        "cond_entropy-2": 3.4925702938804712,
        "distinct-3": 0.6073298429319371,
        "vocab_size-3": 1160,
        "unique-3": 843,
        "entropy-3": 9.753245246731671,
        "cond_entropy-3": 0.9827136427196336,
        "total_length-nopunct": 1821,
        "mean_pred_length-nopunct": 62.793103448275865,
        "std_pred_length-nopunct": 4.020458974869511,
        "median_pred_length-nopunct": 63.0,
        "min_pred_length-nopunct": 55,
        "max_pred_length-nopunct": 71,
        "distinct-1-nopunct": 0.19934102141680396,
        "vocab_size-1-nopunct": 363,
        "unique-1-nopunct": 202,
        "entropy-1-nopunct": 5.2002139768443305,
        "distinct-2-nopunct": 0.43470982142857145,
        "vocab_size-2-nopunct": 779,
        "unique-2-nopunct": 499,
        "entropy-2-nopunct": 8.768063837642305,
        "cond_entropy-2-nopunct": 3.5861137558026024,
        "distinct-3-nopunct": 0.6222348269994328,
        "vocab_size-3-nopunct": 1097,
        "unique-3-nopunct": 815,
        "entropy-3-nopunct": 9.686899770015883,
        "cond_entropy-3-nopunct": 0.9280131200592203,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.71574,
            "recall": 0.6361,
            "fmeasure": 0.64745
        },
        "rouge2": {
            "precision": 0.4431,
            "recall": 0.41051,
            "fmeasure": 0.41506
        },
        "rougeL": {
            "precision": 0.70016,
            "recall": 0.6202,
            "fmeasure": 0.63172
        },
        "rougeLsum": {
            "precision": 0.70016,
            "recall": 0.6202,
            "fmeasure": 0.63172
        },
        "local_recall": {
            "1": 0.07167832167832168,
            "2": 0.1411764705882353,
            "3": 0.2434017595307918
        },
        "nist": 1.1667903402371678,
        "bleu": 1.52787,
        "bleurt": -0.52542,
        "nubia": {
            "semantic_relation": 3.18632,
            "contradiction": 34.40898,
            "irrelevancy": 21.5539,
            "logical_agreement": 44.03712,
            "grammar_ref": 2.50557,
            "grammar_hyp": 2.44257,
            "nubia_score": 0.17635
        },
        "meteor": 0.10917015801393236,
        "bertscore": {
            "precision": 0.86037,
            "recall": 0.85753,
            "f1": 0.85866
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc_parent": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72264,
        "msttr-100_nopunct": 0.76841,
        "total_length": 7213,
        "mean_pred_length": 20.091922005571032,
        "std_pred_length": 9.49445910452566,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.3666990156661583,
        "vocab_size-1": 2645,
        "unique-1": 1952,
        "entropy-1": 9.126331215578004,
        "distinct-2": 0.8262328567259994,
        "vocab_size-2": 5663,
        "unique-2": 5225,
        "entropy-2": 12.115099856400926,
        "cond_entropy-2": 2.7291720972784907,
        "distinct-3": 0.9575057736720555,
        "vocab_size-3": 6219,
        "unique-3": 6091,
        "entropy-3": 12.51846472638313,
        "cond_entropy-3": 0.42154667407596275,
        "total_length-nopunct": 6370,
        "mean_pred_length-nopunct": 17.74373259052925,
        "std_pred_length-nopunct": 8.28470137515936,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.41334379905808477,
        "vocab_size-1-nopunct": 2633,
        "unique-1-nopunct": 1949,
        "entropy-1-nopunct": 9.490784012020617,
        "distinct-2-nopunct": 0.8481117950424222,
        "vocab_size-2-nopunct": 5098,
        "unique-2-nopunct": 4740,
        "entropy-2-nopunct": 12.022647785553223,
        "cond_entropy-2-nopunct": 2.672958492128687,
        "distinct-3-nopunct": 0.97310686482661,
        "vocab_size-3-nopunct": 5500,
        "unique-3-nopunct": 5399,
        "entropy-3-nopunct": 12.396973766549186,
        "cond_entropy-3-nopunct": 0.40135611026316653,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.88638,
            "recall": 0.86124,
            "fmeasure": 0.86462
        },
        "rouge2": {
            "precision": 0.78287,
            "recall": 0.76144,
            "fmeasure": 0.76029
        },
        "rougeL": {
            "precision": 0.86875,
            "recall": 0.8461,
            "fmeasure": 0.84782
        },
        "rougeLsum": {
            "precision": 0.86875,
            "recall": 0.8461,
            "fmeasure": 0.84782
        },
        "local_recall": {
            "1": 0.03031973539140022,
            "2": 0.15566037735849056,
            "3": 0.336144578313253,
            "4": 0.555045871559633,
            "5": 0.6722306525037937,
            "6": 0.7492957746478873,
            "7": 0.8292349726775956,
            "8": 0.8576598311218335,
            "9": 0.9026455026455027,
            "10": 0.9441860465116279
        },
        "nist": 13.071812397108598,
        "bleu": 84.31801,
        "bleurt": 0.21901,
        "nubia": {
            "semantic_relation": 4.20837,
            "contradiction": 3.35002,
            "irrelevancy": 31.71486,
            "logical_agreement": 64.93513,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.775,
            "nubia_score": 0.6471
        },
        "meteor": 0.5239953121659693,
        "bertscore": {
            "precision": 0.96702,
            "recall": 0.96512,
            "f1": 0.9629
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_33": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.6,
            "recall": 0.32432,
            "fmeasure": 0.42105
        },
        "rouge2": {
            "precision": 0.52632,
            "recall": 0.27778,
            "fmeasure": 0.36364
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.27027,
            "fmeasure": 0.35088
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.27027,
            "fmeasure": 0.35088
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.29411764705882354
        },
        "nist": 1.0550511953046133,
        "bleu": 16.74259,
        "bleurt": -0.41634,
        "nubia": {
            "semantic_relation": 2.92473,
            "contradiction": 0.19465,
            "irrelevancy": 35.68686,
            "logical_agreement": 64.1185,
            "grammar_ref": 4.39709,
            "grammar_hyp": 3.82459,
            "nubia_score": 0.38317
        },
        "meteor": 0.21449841356811292,
        "bertscore": {
            "precision": 0.88096,
            "recall": 0.80188,
            "f1": 0.83956
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 174,
        "msttr-100": 0.70852,
        "msttr-100_nopunct": 0.75208,
        "total_length": 2769,
        "mean_pred_length": 15.913793103448276,
        "std_pred_length": 7.098529431870016,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 39,
        "distinct-1": 0.4312026002166847,
        "vocab_size-1": 1194,
        "unique-1": 928,
        "entropy-1": 8.443524698618077,
        "distinct-2": 0.8585741811175337,
        "vocab_size-2": 2228,
        "unique-2": 2083,
        "entropy-2": 10.886853107786523,
        "cond_entropy-2": 2.1378883518637672,
        "distinct-3": 0.9624122263527468,
        "vocab_size-3": 2330,
        "unique-3": 2283,
        "entropy-3": 11.135662440978583,
        "cond_entropy-3": 0.2677998847013008,
        "total_length-nopunct": 2434,
        "mean_pred_length-nopunct": 13.988505747126437,
        "std_pred_length-nopunct": 6.0372298071400134,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.4868529170090386,
        "vocab_size-1-nopunct": 1185,
        "unique-1-nopunct": 926,
        "entropy-1-nopunct": 8.764854125337825,
        "distinct-2-nopunct": 0.8716814159292036,
        "vocab_size-2-nopunct": 1970,
        "unique-2-nopunct": 1856,
        "entropy-2-nopunct": 10.723656720115514,
        "cond_entropy-2-nopunct": 2.1112534014481357,
        "distinct-3-nopunct": 0.9741131351869607,
        "vocab_size-3-nopunct": 2032,
        "unique-3-nopunct": 1995,
        "entropy-3-nopunct": 10.964860359833423,
        "cond_entropy-3-nopunct": 0.266934535875832,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.859,
            "recall": 0.76474,
            "fmeasure": 0.79208
        },
        "rouge2": {
            "precision": 0.70387,
            "recall": 0.62635,
            "fmeasure": 0.64601
        },
        "rougeL": {
            "precision": 0.82658,
            "recall": 0.73298,
            "fmeasure": 0.75927
        },
        "rougeLsum": {
            "precision": 0.82658,
            "recall": 0.73298,
            "fmeasure": 0.75927
        },
        "local_recall": {
            "1": 0.04249737670514166,
            "2": 0.12871287128712872,
            "3": 0.3439153439153439,
            "4": 0.5080645161290323,
            "5": 0.5696594427244582,
            "6": 0.7164179104477612,
            "7": 0.8430379746835444
        },
        "nist": 9.560786398837095,
        "bleu": 64.64752,
        "bleurt": 0.19126,
        "nubia": {
            "semantic_relation": 4.19258,
            "contradiction": 5.03849,
            "irrelevancy": 15.94847,
            "logical_agreement": 79.01303,
            "grammar_ref": 4.58509,
            "grammar_hyp": 4.98136,
            "nubia_score": 0.66717
        },
        "meteor": 0.4407881308736309,
        "bertscore": {
            "precision": 0.95481,
            "recall": 0.93516,
            "f1": 0.94197
        }
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 253,
        "msttr-100": 0.45538,
        "msttr-100_nopunct": 0.45958,
        "total_length": 5294,
        "mean_pred_length": 20.92490118577075,
        "std_pred_length": 7.439764202808971,
        "median_pred_length": 19.0,
        "min_pred_length": 6,
        "max_pred_length": 45,
        "distinct-1": 0.16773706082357387,
        "vocab_size-1": 888,
        "unique-1": 539,
        "entropy-1": 5.664430847588878,
        "distinct-2": 0.39039873041063283,
        "vocab_size-2": 1968,
        "unique-2": 1322,
        "entropy-2": 9.6859892621447,
        "cond_entropy-2": 3.9566000814617315,
        "distinct-3": 0.5850041771094403,
        "vocab_size-3": 2801,
        "unique-3": 2126,
        "entropy-3": 10.79770783766226,
        "cond_entropy-3": 1.172923759665834,
        "total_length-nopunct": 4829,
        "mean_pred_length-nopunct": 19.08695652173913,
        "std_pred_length-nopunct": 7.219343514251539,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.1826465106647339,
        "vocab_size-1-nopunct": 882,
        "unique-1-nopunct": 538,
        "entropy-1-nopunct": 5.562121128787129,
        "distinct-2-nopunct": 0.381993006993007,
        "vocab_size-2-nopunct": 1748,
        "unique-2-nopunct": 1166,
        "entropy-2-nopunct": 9.467747015723257,
        "cond_entropy-2-nopunct": 4.1135001680899865,
        "distinct-3-nopunct": 0.5727504048114735,
        "vocab_size-3-nopunct": 2476,
        "unique-3-nopunct": 1879,
        "entropy-3-nopunct": 10.578611673617939,
        "cond_entropy-3-nopunct": 1.1808415482653307,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.33331,
            "recall": 0.33725,
            "fmeasure": 0.33377
        },
        "rouge2": {
            "precision": 0.19022,
            "recall": 0.18874,
            "fmeasure": 0.18911
        },
        "rougeL": {
            "precision": 0.33134,
            "recall": 0.33577,
            "fmeasure": 0.33207
        },
        "rougeLsum": {
            "precision": 0.33134,
            "recall": 0.33577,
            "fmeasure": 0.33207
        },
        "local_recall": {
            "1": 0.10102389078498293,
            "2": 0.18270571827057183,
            "3": 0.24914675767918087,
            "4": 0.22857142857142856,
            "5": 0.2727272727272727,
            "6": 0.2,
            "7": 0.3333333333333333
        },
        "nist": 1.048181930729908,
        "bleu": 3.31548,
        "bleurt": -0.3834,
        "nubia": {
            "semantic_relation": 3.34389,
            "contradiction": 36.79518,
            "irrelevancy": 15.44015,
            "logical_agreement": 47.76467,
            "grammar_ref": 2.90527,
            "grammar_hyp": 2.99989,
            "nubia_score": 0.20372
        },
        "meteor": 0.15197485531286692,
        "bertscore": {
            "precision": 0.86792,
            "recall": 0.87967,
            "f1": 0.87334
        }
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.6,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 2.5967916319816364,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 1.3041417874778878,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.5384615384615384,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.1887870678023824,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 1.5221464871136665,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0
        },
        "nist": 0.4893233335256416,
        "bleu": 3.12519,
        "bleurt": -0.45951,
        "nubia": {
            "semantic_relation": 2.86711,
            "contradiction": 43.95423,
            "irrelevancy": 16.24323,
            "logical_agreement": 39.80254,
            "grammar_ref": 2.53664,
            "grammar_hyp": 3.22986,
            "nubia_score": 0.07588
        },
        "meteor": 0.05714285714285715,
        "bertscore": {
            "precision": 0.82974,
            "recall": 0.83181,
            "f1": 0.83077
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 144,
        "msttr-100": 0.71429,
        "msttr-100_nopunct": 0.76333,
        "total_length": 2107,
        "mean_pred_length": 14.631944444444445,
        "std_pred_length": 6.75333922319768,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 43,
        "distinct-1": 0.3754152823920266,
        "vocab_size-1": 791,
        "unique-1": 561,
        "entropy-1": 8.093560766403607,
        "distinct-2": 0.7473255221599593,
        "vocab_size-2": 1467,
        "unique-2": 1261,
        "entropy-2": 10.193113994706032,
        "cond_entropy-2": 1.7861896648387594,
        "distinct-3": 0.8779549202858714,
        "vocab_size-3": 1597,
        "unique-3": 1485,
        "entropy-3": 10.508398331041935,
        "cond_entropy-3": 0.30278637142845444,
        "total_length-nopunct": 1829,
        "mean_pred_length-nopunct": 12.70138888888889,
        "std_pred_length-nopunct": 5.771192661630204,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.42810278840896665,
        "vocab_size-1-nopunct": 783,
        "unique-1-nopunct": 560,
        "entropy-1-nopunct": 8.377149400913861,
        "distinct-2-nopunct": 0.7721068249258161,
        "vocab_size-2-nopunct": 1301,
        "unique-2-nopunct": 1143,
        "entropy-2-nopunct": 10.0352371130093,
        "cond_entropy-2-nopunct": 1.7360076190391764,
        "distinct-3-nopunct": 0.8935756002595717,
        "vocab_size-3-nopunct": 1377,
        "unique-3-nopunct": 1295,
        "entropy-3-nopunct": 10.309304635252191,
        "cond_entropy-3-nopunct": 0.27854041290910053,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76954,
            "recall": 0.71756,
            "fmeasure": 0.72398
        },
        "rouge2": {
            "precision": 0.54652,
            "recall": 0.50605,
            "fmeasure": 0.51065
        },
        "rougeL": {
            "precision": 0.68039,
            "recall": 0.63569,
            "fmeasure": 0.63996
        },
        "rougeLsum": {
            "precision": 0.68039,
            "recall": 0.63569,
            "fmeasure": 0.63996
        },
        "local_recall": {
            "1": 0.22957198443579765,
            "2": 0.4922737306843267,
            "3": 0.7501945525291829
        },
        "nist": 7.670365724119574,
        "bleu": 47.65062,
        "bleurt": 0.24327,
        "nubia": {
            "semantic_relation": 4.06646,
            "contradiction": 6.70235,
            "irrelevancy": 29.99988,
            "logical_agreement": 63.29777,
            "grammar_ref": 4.70586,
            "grammar_hyp": 4.7722,
            "nubia_score": 0.70128
        },
        "meteor": 0.3998393033852821,
        "bertscore": {
            "precision": 0.9278,
            "recall": 0.91842,
            "f1": 0.92068
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 58,
        "msttr-100": 0.73545,
        "msttr-100_nopunct": 0.76889,
        "total_length": 1109,
        "mean_pred_length": 19.120689655172413,
        "std_pred_length": 9.658081458313045,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.5166816952209198,
        "vocab_size-1": 573,
        "unique-1": 466,
        "entropy-1": 7.983831472774149,
        "distinct-2": 0.9267364414843007,
        "vocab_size-2": 974,
        "unique-2": 933,
        "entropy-2": 9.850683196706292,
        "cond_entropy-2": 1.6546044077812887,
        "distinct-3": 0.9848942598187311,
        "vocab_size-3": 978,
        "unique-3": 969,
        "entropy-3": 9.918168255011857,
        "cond_entropy-3": 0.07839955772236339,
        "total_length-nopunct": 995,
        "mean_pred_length-nopunct": 17.155172413793103,
        "std_pred_length-nopunct": 8.735187904612825,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.5688442211055277,
        "vocab_size-1-nopunct": 566,
        "unique-1-nopunct": 464,
        "entropy-1-nopunct": 8.183271299800154,
        "distinct-2-nopunct": 0.9391675560298826,
        "vocab_size-2-nopunct": 880,
        "unique-2-nopunct": 845,
        "entropy-2-nopunct": 9.723283699808395,
        "cond_entropy-2-nopunct": 1.6324632773867713,
        "distinct-3-nopunct": 0.9920364050056882,
        "vocab_size-3-nopunct": 872,
        "unique-3-nopunct": 865,
        "entropy-3-nopunct": 9.763792165154774,
        "cond_entropy-3-nopunct": 0.050315119721057004,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.83654,
            "recall": 0.73239,
            "fmeasure": 0.76578
        },
        "rouge2": {
            "precision": 0.69317,
            "recall": 0.60786,
            "fmeasure": 0.63351
        },
        "rougeL": {
            "precision": 0.817,
            "recall": 0.72068,
            "fmeasure": 0.75033
        },
        "rougeLsum": {
            "precision": 0.817,
            "recall": 0.72068,
            "fmeasure": 0.75033
        },
        "local_recall": {
            "1": 0.044548651817116064,
            "2": 0.1619718309859155,
            "3": 0.3246753246753247,
            "4": 0.49038461538461536,
            "5": 0.5363128491620112,
            "6": 0.7383512544802867,
            "7": 0.8192488262910798
        },
        "nist": 8.668083996534097,
        "bleu": 64.63185,
        "bleurt": 0.14539,
        "nubia": {
            "semantic_relation": 4.14544,
            "contradiction": 4.0095,
            "irrelevancy": 15.30201,
            "logical_agreement": 80.68849,
            "grammar_ref": 4.54049,
            "grammar_hyp": 4.8976,
            "nubia_score": 0.66855
        },
        "meteor": 0.430384106240719,
        "bertscore": {
            "precision": 0.95235,
            "recall": 0.92996,
            "f1": 0.93857
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 158,
        "msttr-100": 0.54117,
        "msttr-100_nopunct": 0.55906,
        "total_length": 6009,
        "mean_pred_length": 38.03164556962025,
        "std_pred_length": 11.232536874360697,
        "median_pred_length": 37.0,
        "min_pred_length": 14,
        "max_pred_length": 70,
        "distinct-1": 0.16159094691296388,
        "vocab_size-1": 971,
        "unique-1": 389,
        "entropy-1": 7.792607305778149,
        "distinct-2": 0.4230046145957956,
        "vocab_size-2": 2475,
        "unique-2": 1504,
        "entropy-2": 10.545587637663308,
        "cond_entropy-2": 2.6530892884013557,
        "distinct-3": 0.6038995257333567,
        "vocab_size-3": 3438,
        "unique-3": 2525,
        "entropy-3": 11.331160626876242,
        "cond_entropy-3": 0.8125690646111766,
        "total_length-nopunct": 5322,
        "mean_pred_length-nopunct": 33.68354430379747,
        "std_pred_length-nopunct": 10.134593350234605,
        "median_pred_length-nopunct": 33.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 61,
        "distinct-1-nopunct": 0.18057121382938746,
        "vocab_size-1-nopunct": 961,
        "unique-1-nopunct": 388,
        "entropy-1-nopunct": 8.03370505829471,
        "distinct-2-nopunct": 0.4419054996127033,
        "vocab_size-2-nopunct": 2282,
        "unique-2-nopunct": 1423,
        "entropy-2-nopunct": 10.484428414134502,
        "cond_entropy-2-nopunct": 2.5283377784804624,
        "distinct-3-nopunct": 0.6198561725928885,
        "vocab_size-3-nopunct": 3103,
        "unique-3-nopunct": 2330,
        "entropy-3-nopunct": 11.197621175701137,
        "cond_entropy-3-nopunct": 0.7347713849994298,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.67438,
            "recall": 0.64134,
            "fmeasure": 0.65013
        },
        "rouge2": {
            "precision": 0.37656,
            "recall": 0.35527,
            "fmeasure": 0.36094
        },
        "rougeL": {
            "precision": 0.46322,
            "recall": 0.43876,
            "fmeasure": 0.44478
        },
        "rougeLsum": {
            "precision": 0.46322,
            "recall": 0.43876,
            "fmeasure": 0.44478
        },
        "local_recall": {
            "1": 0.21608265947888589,
            "2": 0.4716981132075472,
            "3": 0.7815275310834814
        },
        "nist": 7.323595266905664,
        "bleu": 39.4825,
        "bleurt": -0.14416,
        "nubia": {
            "semantic_relation": 3.81381,
            "contradiction": 22.52057,
            "irrelevancy": 13.35584,
            "logical_agreement": 64.12359,
            "grammar_ref": 4.0976,
            "grammar_hyp": 4.25699,
            "nubia_score": 0.62011
        },
        "meteor": 0.3200688653715221,
        "bertscore": {
            "precision": 0.88264,
            "recall": 0.88029,
            "f1": 0.88005
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 22,
        "msttr-100": 0.716,
        "msttr-100_nopunct": 0.765,
        "total_length": 502,
        "mean_pred_length": 22.818181818181817,
        "std_pred_length": 10.030119928750802,
        "median_pred_length": 21.0,
        "min_pred_length": 10,
        "max_pred_length": 42,
        "distinct-1": 0.5677290836653387,
        "vocab_size-1": 285,
        "unique-1": 233,
        "entropy-1": 7.308244592819481,
        "distinct-2": 0.9208333333333333,
        "vocab_size-2": 442,
        "unique-2": 420,
        "entropy-2": 8.710975803905825,
        "cond_entropy-2": 1.266122338106891,
        "distinct-3": 0.982532751091703,
        "vocab_size-3": 450,
        "unique-3": 444,
        "entropy-3": 8.800972838305858,
        "cond_entropy-3": 0.09940778858663592,
        "total_length-nopunct": 446,
        "mean_pred_length-nopunct": 20.272727272727273,
        "std_pred_length-nopunct": 8.74997048401161,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.6278026905829597,
        "vocab_size-1-nopunct": 280,
        "unique-1-nopunct": 233,
        "entropy-1-nopunct": 7.441017577886565,
        "distinct-2-nopunct": 0.9268867924528302,
        "vocab_size-2-nopunct": 393,
        "unique-2-nopunct": 375,
        "entropy-2-nopunct": 8.544490177415103,
        "cond_entropy-2-nopunct": 1.1608604499625248,
        "distinct-3-nopunct": 0.9900497512437811,
        "vocab_size-3-nopunct": 398,
        "unique-3-nopunct": 394,
        "entropy-3-nopunct": 8.631151193666442,
        "cond_entropy-3-nopunct": 0.09421192694114447,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.84922,
            "recall": 0.81619,
            "fmeasure": 0.82209
        },
        "rouge2": {
            "precision": 0.71845,
            "recall": 0.69367,
            "fmeasure": 0.69616
        },
        "rougeL": {
            "precision": 0.82602,
            "recall": 0.79598,
            "fmeasure": 0.8006
        },
        "rougeLsum": {
            "precision": 0.82602,
            "recall": 0.79598,
            "fmeasure": 0.8006
        },
        "local_recall": {
            "1": 0.04,
            "2": 0.15254237288135594,
            "3": 0.46875,
            "4": 0.46938775510204084,
            "5": 0.7162162162162162,
            "6": 0.7777777777777778,
            "7": 0.9166666666666666
        },
        "nist": 8.665743990724934,
        "bleu": 72.15789,
        "bleurt": 0.31358,
        "nubia": {
            "semantic_relation": 4.39792,
            "contradiction": 2.91557,
            "irrelevancy": 13.59035,
            "logical_agreement": 83.49408,
            "grammar_ref": 4.50363,
            "grammar_hyp": 4.72684,
            "nubia_score": 0.73731
        },
        "meteor": 0.475066156111124,
        "bertscore": {
            "precision": 0.96203,
            "recall": 0.95492,
            "f1": 0.95701
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 59,
        "msttr-100": 0.72111,
        "msttr-100_nopunct": 0.7425,
        "total_length": 968,
        "mean_pred_length": 16.406779661016948,
        "std_pred_length": 5.980529549898858,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 42,
        "distinct-1": 0.48037190082644626,
        "vocab_size-1": 465,
        "unique-1": 375,
        "entropy-1": 7.688915656879294,
        "distinct-2": 0.8393839383938394,
        "vocab_size-2": 763,
        "unique-2": 692,
        "entropy-2": 9.388409544135971,
        "cond_entropy-2": 1.459288611488898,
        "distinct-3": 0.9223529411764706,
        "vocab_size-3": 784,
        "unique-3": 739,
        "entropy-3": 9.5536333622287,
        "cond_entropy-3": 0.16868721746138693,
        "total_length-nopunct": 858,
        "mean_pred_length-nopunct": 14.542372881355933,
        "std_pred_length-nopunct": 5.512150012405739,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.5314685314685315,
        "vocab_size-1-nopunct": 456,
        "unique-1-nopunct": 373,
        "entropy-1-nopunct": 7.846432427186329,
        "distinct-2-nopunct": 0.8397997496871089,
        "vocab_size-2-nopunct": 671,
        "unique-2-nopunct": 613,
        "entropy-2-nopunct": 9.192793994541587,
        "cond_entropy-2-nopunct": 1.4264190436983766,
        "distinct-3-nopunct": 0.922972972972973,
        "vocab_size-3-nopunct": 683,
        "unique-3-nopunct": 643,
        "entropy-3-nopunct": 9.35635032068852,
        "cond_entropy-3-nopunct": 0.17833677954056495,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77853,
            "recall": 0.75809,
            "fmeasure": 0.75886
        },
        "rouge2": {
            "precision": 0.55409,
            "recall": 0.53967,
            "fmeasure": 0.54004
        },
        "rougeL": {
            "precision": 0.67419,
            "recall": 0.66378,
            "fmeasure": 0.66113
        },
        "rougeLsum": {
            "precision": 0.67419,
            "recall": 0.66378,
            "fmeasure": 0.66113
        },
        "local_recall": {
            "1": 0.25157232704402516,
            "2": 0.5488721804511278,
            "3": 0.7996870109546166
        },
        "nist": 7.268487900362162,
        "bleu": 48.58589,
        "bleurt": 0.34739,
        "nubia": {
            "semantic_relation": 4.29321,
            "contradiction": 1.83638,
            "irrelevancy": 28.62995,
            "logical_agreement": 69.53367,
            "grammar_ref": 4.6237,
            "grammar_hyp": 4.4204,
            "nubia_score": 0.77708
        },
        "meteor": 0.40855126511206824,
        "bertscore": {
            "precision": 0.93788,
            "recall": 0.93231,
            "f1": 0.93388
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 64,
        "mean_pred_length": 21.333333333333332,
        "std_pred_length": 11.08552609887726,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 37,
        "distinct-1": 0.875,
        "vocab_size-1": 56,
        "unique-1": 50,
        "entropy-1": 5.71875,
        "distinct-2": 1.0,
        "vocab_size-2": 61,
        "unique-2": 61,
        "entropy-2": 5.930737337562883,
        "cond_entropy-2": 0.12745864903829598,
        "distinct-3": 1.0,
        "vocab_size-3": 58,
        "unique-3": 58,
        "entropy-3": 5.85798099512757,
        "cond_entropy-3": -0.07275634243531406,
        "total_length-nopunct": 57,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 9.899494936611665,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.9298245614035088,
        "vocab_size-1-nopunct": 53,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.692539136971755,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 54,
        "entropy-2-nopunct": 5.7548875021634665,
        "cond_entropy-2-nopunct": 0.03310859910983799,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 51,
        "unique-3-nopunct": 51,
        "entropy-3-nopunct": 5.6724253419715005,
        "cond_entropy-3-nopunct": -0.08246216019197294,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.79643,
            "recall": 0.7316,
            "fmeasure": 0.75958
        },
        "rouge2": {
            "precision": 0.5675,
            "recall": 0.51923,
            "fmeasure": 0.53957
        },
        "rougeL": {
            "precision": 0.69643,
            "recall": 0.64177,
            "fmeasure": 0.66496
        },
        "rougeLsum": {
            "precision": 0.69643,
            "recall": 0.64177,
            "fmeasure": 0.66496
        },
        "local_recall": {
            "1": 0.1282051282051282,
            "2": 0.13333333333333333,
            "3": 0.5,
            "4": 0.2857142857142857,
            "5": 0.5,
            "6": 0.8571428571428571,
            "7": 0.8571428571428571
        },
        "nist": 5.1937007499032415,
        "bleu": 49.16494,
        "bleurt": 0.24033,
        "nubia": {
            "semantic_relation": 4.69836,
            "contradiction": 0.36505,
            "irrelevancy": 21.22393,
            "logical_agreement": 78.41101,
            "grammar_ref": 4.54431,
            "grammar_hyp": 4.82368,
            "nubia_score": 0.81708
        },
        "meteor": 0.43298054265789293,
        "bertscore": {
            "precision": 0.934,
            "recall": 0.94112,
            "f1": 0.93501
        }
    },
    "schema_guided_dialog_challenge_test_backtranslation": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_challenge_test_backtranslation",
        "N": 500,
        "msttr-100": 0.6773,
        "msttr-100_nopunct": 0.70909,
        "total_length": 6314,
        "mean_pred_length": 12.628,
        "std_pred_length": 6.94792170364635,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 39,
        "distinct-1": 0.15631929046563192,
        "vocab_size-1": 987,
        "unique-1": 576,
        "entropy-1": 7.755135474972048,
        "distinct-2": 0.47248022015823876,
        "vocab_size-2": 2747,
        "unique-2": 1898,
        "entropy-2": 10.596436513794751,
        "cond_entropy-2": 2.581453011042053,
        "distinct-3": 0.688558524651863,
        "vocab_size-3": 3659,
        "unique-3": 3003,
        "entropy-3": 11.410152157802374,
        "cond_entropy-3": 0.839517235528984,
        "total_length-nopunct": 5525,
        "mean_pred_length-nopunct": 11.05,
        "std_pred_length-nopunct": 6.383690155388183,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.17647058823529413,
        "vocab_size-1-nopunct": 975,
        "unique-1-nopunct": 573,
        "entropy-1-nopunct": 7.944614783740842,
        "distinct-2-nopunct": 0.4855721393034826,
        "vocab_size-2-nopunct": 2440,
        "unique-2-nopunct": 1734,
        "entropy-2-nopunct": 10.403349337048752,
        "cond_entropy-2-nopunct": 2.59228608637675,
        "distinct-3-nopunct": 0.7007734806629834,
        "vocab_size-3-nopunct": 3171,
        "unique-3-nopunct": 2648,
        "entropy-3-nopunct": 11.196908696597115,
        "cond_entropy-3-nopunct": 0.8390811235516465,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_backtranslation.json",
        "rouge1": {
            "precision": 0.55897,
            "recall": 0.54603,
            "fmeasure": 0.5399
        },
        "rouge2": {
            "precision": 0.33986,
            "recall": 0.33213,
            "fmeasure": 0.32775
        },
        "rougeL": {
            "precision": 0.49415,
            "recall": 0.48395,
            "fmeasure": 0.47803
        },
        "rougeLsum": {
            "precision": 0.49415,
            "recall": 0.48395,
            "fmeasure": 0.47803
        },
        "local_recall": {
            "1": 0.5595326409495549
        },
        "nist": 5.875655450691675,
        "bleu": 30.93323,
        "bleurt": -0.07753,
        "nubia": {
            "semantic_relation": 3.59397,
            "contradiction": 7.4808,
            "irrelevancy": 22.74462,
            "logical_agreement": 69.77458,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.52606,
            "nubia_score": 0.64146
        },
        "meteor": 0.31216781112155173,
        "bertscore": {
            "precision": 0.86856,
            "recall": 0.86311,
            "f1": 0.86533
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_challenge_test_asset_backtranslation",
        "N": 359,
        "msttr-100": 0.7125,
        "msttr-100_nopunct": 0.7617,
        "total_length": 6060,
        "mean_pred_length": 16.880222841225628,
        "std_pred_length": 8.284604909220102,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 64,
        "distinct-1": 0.367986798679868,
        "vocab_size-1": 2230,
        "unique-1": 1650,
        "entropy-1": 8.917730416232075,
        "distinct-2": 0.8233643220487634,
        "vocab_size-2": 4694,
        "unique-2": 4306,
        "entropy-2": 11.85216532693724,
        "cond_entropy-2": 2.618674223982778,
        "distinct-3": 0.9524522650692624,
        "vocab_size-3": 5088,
        "unique-3": 4983,
        "entropy-3": 12.204672991970279,
        "cond_entropy-3": 0.37772035707050644,
        "total_length-nopunct": 5349,
        "mean_pred_length-nopunct": 14.899721448467966,
        "std_pred_length-nopunct": 7.233932338720305,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.41521779771919987,
        "vocab_size-1-nopunct": 2221,
        "unique-1-nopunct": 1648,
        "entropy-1-nopunct": 9.287393728137562,
        "distinct-2-nopunct": 0.8472945891783568,
        "vocab_size-2-nopunct": 4228,
        "unique-2-nopunct": 3916,
        "entropy-2-nopunct": 11.770365636598466,
        "cond_entropy-2-nopunct": 2.6451008548604134,
        "distinct-3-nopunct": 0.9727920535521486,
        "vocab_size-3-nopunct": 4505,
        "unique-3-nopunct": 4421,
        "entropy-3-nopunct": 12.109816147985503,
        "cond_entropy-3-nopunct": 0.37015247930654305,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_backtranslation.json",
        "rouge1": {
            "precision": 0.68164,
            "recall": 0.61872,
            "fmeasure": 0.63457
        },
        "rouge2": {
            "precision": 0.45241,
            "recall": 0.41134,
            "fmeasure": 0.41771
        },
        "rougeL": {
            "precision": 0.6254,
            "recall": 0.57245,
            "fmeasure": 0.58426
        },
        "rougeLsum": {
            "precision": 0.6254,
            "recall": 0.57245,
            "fmeasure": 0.58426
        },
        "local_recall": {
            "1": 0.049855072463768114,
            "2": 0.12087912087912088,
            "3": 0.205158264947245,
            "4": 0.29603399433427763,
            "5": 0.3652058432934927,
            "6": 0.42610837438423643,
            "7": 0.478310502283105,
            "8": 0.6121031746031746,
            "9": 0.7532374100719424
        },
        "nist": 8.40904384366068,
        "bleu": 41.53243,
        "sari": 43.74287,
        "bleurt": -0.21616,
        "nubia": {
            "semantic_relation": 3.38073,
            "contradiction": 13.52166,
            "irrelevancy": 33.11941,
            "logical_agreement": 53.35893,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.24237,
            "nubia_score": 0.44072
        },
        "meteor": 0.3260291002864926,
        "bertscore": {
            "precision": 0.90357,
            "recall": 0.89652,
            "f1": 0.89552
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_7": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 47,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.73167,
        "total_length": 757,
        "mean_pred_length": 16.106382978723403,
        "std_pred_length": 6.461783044071231,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 35,
        "distinct-1": 0.44121532364597094,
        "vocab_size-1": 334,
        "unique-1": 245,
        "entropy-1": 7.271175304150111,
        "distinct-2": 0.7943661971830986,
        "vocab_size-2": 564,
        "unique-2": 485,
        "entropy-2": 8.93081727757942,
        "cond_entropy-2": 1.4437322701975783,
        "distinct-3": 0.8868778280542986,
        "vocab_size-3": 588,
        "unique-3": 547,
        "entropy-3": 9.081686214153956,
        "cond_entropy-3": 0.16393897507817826,
        "total_length-nopunct": 643,
        "mean_pred_length-nopunct": 13.680851063829786,
        "std_pred_length-nopunct": 5.331984513308197,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.5085536547433903,
        "vocab_size-1-nopunct": 327,
        "unique-1-nopunct": 244,
        "entropy-1-nopunct": 7.4629713226999375,
        "distinct-2-nopunct": 0.8104026845637584,
        "vocab_size-2-nopunct": 483,
        "unique-2-nopunct": 425,
        "entropy-2-nopunct": 8.708122860777996,
        "cond_entropy-2-nopunct": 1.333707831234551,
        "distinct-3-nopunct": 0.8888888888888888,
        "vocab_size-3-nopunct": 488,
        "unique-3-nopunct": 455,
        "entropy-3-nopunct": 8.815334100546057,
        "cond_entropy-3-nopunct": 0.13243750753425568,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75003,
            "recall": 0.7613,
            "fmeasure": 0.74089
        },
        "rouge2": {
            "precision": 0.48809,
            "recall": 0.49848,
            "fmeasure": 0.48543
        },
        "rougeL": {
            "precision": 0.65252,
            "recall": 0.65379,
            "fmeasure": 0.64053
        },
        "rougeLsum": {
            "precision": 0.65252,
            "recall": 0.65379,
            "fmeasure": 0.64053
        },
        "local_recall": {
            "1": 0.22758620689655173,
            "2": 0.43884892086330934,
            "3": 0.7419354838709677
        },
        "nist": 6.437827291780568,
        "bleu": 44.58455,
        "bleurt": 0.30992,
        "nubia": {
            "semantic_relation": 4.09107,
            "contradiction": 8.36904,
            "irrelevancy": 29.54878,
            "logical_agreement": 62.08218,
            "grammar_ref": 4.53522,
            "grammar_hyp": 4.35385,
            "nubia_score": 0.71154
        },
        "meteor": 0.3846666721059977,
        "bertscore": {
            "precision": 0.92152,
            "recall": 0.92602,
            "f1": 0.92136
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 80,
        "msttr-100": 0.55969,
        "msttr-100_nopunct": 0.56724,
        "total_length": 3264,
        "mean_pred_length": 40.8,
        "std_pred_length": 9.512360380052893,
        "median_pred_length": 39.0,
        "min_pred_length": 20,
        "max_pred_length": 80,
        "distinct-1": 0.21997549019607843,
        "vocab_size-1": 718,
        "unique-1": 341,
        "entropy-1": 7.596501836941123,
        "distinct-2": 0.5216708542713567,
        "vocab_size-2": 1661,
        "unique-2": 1107,
        "entropy-2": 10.140620840043262,
        "cond_entropy-2": 2.4555765574449757,
        "distinct-3": 0.7000644329896907,
        "vocab_size-3": 2173,
        "unique-3": 1699,
        "entropy-3": 10.802989823913187,
        "cond_entropy-3": 0.6791190541877936,
        "total_length-nopunct": 2919,
        "mean_pred_length-nopunct": 36.4875,
        "std_pred_length-nopunct": 8.955436547148329,
        "median_pred_length-nopunct": 35.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 71,
        "distinct-1-nopunct": 0.24323398424117848,
        "vocab_size-1-nopunct": 710,
        "unique-1-nopunct": 340,
        "entropy-1-nopunct": 7.7830575756249445,
        "distinct-2-nopunct": 0.5406833392039451,
        "vocab_size-2-nopunct": 1535,
        "unique-2-nopunct": 1051,
        "entropy-2-nopunct": 10.081356952133508,
        "cond_entropy-2-nopunct": 2.36099580137001,
        "distinct-3-nopunct": 0.7122145704965567,
        "vocab_size-3-nopunct": 1965,
        "unique-3-nopunct": 1560,
        "entropy-3-nopunct": 10.669921849574001,
        "cond_entropy-3-nopunct": 0.6002891200557364,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.66473,
            "recall": 0.61037,
            "fmeasure": 0.63067
        },
        "rouge2": {
            "precision": 0.35148,
            "recall": 0.32054,
            "fmeasure": 0.33211
        },
        "rougeL": {
            "precision": 0.44393,
            "recall": 0.41354,
            "fmeasure": 0.42414
        },
        "rougeLsum": {
            "precision": 0.44393,
            "recall": 0.41354,
            "fmeasure": 0.42414
        },
        "local_recall": {
            "1": 0.20485584218512898,
            "2": 0.5053619302949062,
            "3": 0.7139001349527665
        },
        "nist": 6.791746226648872,
        "bleu": 33.83927,
        "bleurt": -0.20243,
        "nubia": {
            "semantic_relation": 3.54158,
            "contradiction": 28.94486,
            "irrelevancy": 14.68986,
            "logical_agreement": 56.36527,
            "grammar_ref": 4.0565,
            "grammar_hyp": 4.26735,
            "nubia_score": 0.55811
        },
        "meteor": 0.287065170021758,
        "bertscore": {
            "precision": 0.87602,
            "recall": 0.86499,
            "f1": 0.86919
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_29": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.67,
        "msttr-100_nopunct": NaN,
        "total_length": 115,
        "mean_pred_length": 16.428571428571427,
        "std_pred_length": 7.247800510837612,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 26,
        "distinct-1": 0.6521739130434783,
        "vocab_size-1": 75,
        "unique-1": 61,
        "entropy-1": 5.806031866071564,
        "distinct-2": 0.9629629629629629,
        "vocab_size-2": 104,
        "unique-2": 101,
        "entropy-2": 6.673823728995278,
        "cond_entropy-2": 0.7407197082395623,
        "distinct-3": 1.0,
        "vocab_size-3": 101,
        "unique-3": 101,
        "entropy-3": 6.658211482751779,
        "cond_entropy-3": -0.02979594513282773,
        "total_length-nopunct": 99,
        "mean_pred_length-nopunct": 14.142857142857142,
        "std_pred_length-nopunct": 6.534055214873869,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7272727272727273,
        "vocab_size-1-nopunct": 72,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 5.829627698021293,
        "distinct-2-nopunct": 0.967391304347826,
        "vocab_size-2-nopunct": 89,
        "unique-2-nopunct": 87,
        "entropy-2-nopunct": 6.450139265816119,
        "cond_entropy-2-nopunct": 0.6813605075166483,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 85,
        "unique-3-nopunct": 85,
        "entropy-3-nopunct": 6.409390936137707,
        "cond_entropy-3-nopunct": -0.034701755187976156,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7152,
            "recall": 0.70394,
            "fmeasure": 0.68794
        },
        "rouge2": {
            "precision": 0.56648,
            "recall": 0.56232,
            "fmeasure": 0.54687
        },
        "rougeL": {
            "precision": 0.6728,
            "recall": 0.67284,
            "fmeasure": 0.65313
        },
        "rougeLsum": {
            "precision": 0.6728,
            "recall": 0.67284,
            "fmeasure": 0.65313
        },
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.41379310344827586,
            "3": 0.6949152542372882
        },
        "nist": 4.306319393454199,
        "bleu": 39.24397,
        "bleurt": 0.00317,
        "nubia": {
            "semantic_relation": 4.08967,
            "contradiction": 2.76221,
            "irrelevancy": 36.75783,
            "logical_agreement": 60.47996,
            "grammar_ref": 4.56703,
            "grammar_hyp": 4.52798,
            "nubia_score": 0.68811
        },
        "meteor": 0.3107571907615697,
        "bertscore": {
            "precision": 0.8935,
            "recall": 0.89334,
            "f1": 0.89212
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 30,
        "msttr-100": 0.72429,
        "msttr-100_nopunct": 0.76,
        "total_length": 701,
        "mean_pred_length": 23.366666666666667,
        "std_pred_length": 12.394846599382431,
        "median_pred_length": 21.5,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.5221112696148359,
        "vocab_size-1": 366,
        "unique-1": 291,
        "entropy-1": 7.649610877159002,
        "distinct-2": 0.9001490312965723,
        "vocab_size-2": 604,
        "unique-2": 563,
        "entropy-2": 9.152093537479168,
        "cond_entropy-2": 1.3556658309133212,
        "distinct-3": 0.9641185647425897,
        "vocab_size-3": 618,
        "unique-3": 604,
        "entropy-3": 9.24028906844281,
        "cond_entropy-3": 0.09621778144981609,
        "total_length-nopunct": 617,
        "mean_pred_length-nopunct": 20.566666666666666,
        "std_pred_length-nopunct": 10.288126921629397,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.5818476499189628,
        "vocab_size-1-nopunct": 359,
        "unique-1-nopunct": 291,
        "entropy-1-nopunct": 7.790130794702131,
        "distinct-2-nopunct": 0.9233390119250426,
        "vocab_size-2-nopunct": 542,
        "unique-2-nopunct": 512,
        "entropy-2-nopunct": 9.017516619080554,
        "cond_entropy-2-nopunct": 1.287769238398441,
        "distinct-3-nopunct": 0.9838420107719928,
        "vocab_size-3-nopunct": 548,
        "unique-3-nopunct": 541,
        "entropy-3-nopunct": 9.086506991299897,
        "cond_entropy-3-nopunct": 0.07866901175428297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.79619,
            "recall": 0.73139,
            "fmeasure": 0.74651
        },
        "rouge2": {
            "precision": 0.61958,
            "recall": 0.55982,
            "fmeasure": 0.57473
        },
        "rougeL": {
            "precision": 0.76379,
            "recall": 0.6938,
            "fmeasure": 0.71016
        },
        "rougeLsum": {
            "precision": 0.76379,
            "recall": 0.6938,
            "fmeasure": 0.71016
        },
        "local_recall": {
            "1": 0.05203619909502263,
            "2": 0.16049382716049382,
            "3": 0.4067796610169492,
            "4": 0.4057971014492754,
            "5": 0.5869565217391305,
            "6": 0.6818181818181818,
            "7": 0.8812785388127854
        },
        "nist": 8.047352981980849,
        "bleu": 58.06972,
        "bleurt": 0.06423,
        "nubia": {
            "semantic_relation": 4.02546,
            "contradiction": 3.91114,
            "irrelevancy": 23.61986,
            "logical_agreement": 72.46899,
            "grammar_ref": 4.65355,
            "grammar_hyp": 5.0677,
            "nubia_score": 0.60872
        },
        "meteor": 0.4194401504885029,
        "bertscore": {
            "precision": 0.94416,
            "recall": 0.93122,
            "f1": 0.93462
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 9,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.78,
        "total_length": 185,
        "mean_pred_length": 20.555555555555557,
        "std_pred_length": 8.680899993166493,
        "median_pred_length": 22.0,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.6972972972972973,
        "vocab_size-1": 129,
        "unique-1": 107,
        "entropy-1": 6.601243022128531,
        "distinct-2": 0.9431818181818182,
        "vocab_size-2": 166,
        "unique-2": 160,
        "entropy-2": 7.314489715203632,
        "cond_entropy-2": 0.5839078372668702,
        "distinct-3": 0.9880239520958084,
        "vocab_size-3": 165,
        "unique-3": 163,
        "entropy-3": 7.359752196665645,
        "cond_entropy-3": 0.053073721766856055,
        "total_length-nopunct": 164,
        "mean_pred_length-nopunct": 18.22222222222222,
        "std_pred_length-nopunct": 7.6561925230898735,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.7560975609756098,
        "vocab_size-1-nopunct": 124,
        "unique-1-nopunct": 107,
        "entropy-1-nopunct": 6.625711374760003,
        "distinct-2-nopunct": 0.9483870967741935,
        "vocab_size-2-nopunct": 147,
        "unique-2-nopunct": 143,
        "entropy-2-nopunct": 7.137351663310858,
        "cond_entropy-2-nopunct": 0.547682647703902,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 146,
        "unique-3-nopunct": 146,
        "entropy-3-nopunct": 7.18982455888002,
        "cond_entropy-3-nopunct": 0.06102737966281357,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.84262,
            "recall": 0.72501,
            "fmeasure": 0.76014
        },
        "rouge2": {
            "precision": 0.68023,
            "recall": 0.57575,
            "fmeasure": 0.60257
        },
        "rougeL": {
            "precision": 0.78641,
            "recall": 0.68161,
            "fmeasure": 0.7131
        },
        "rougeLsum": {
            "precision": 0.78641,
            "recall": 0.68161,
            "fmeasure": 0.7131
        },
        "local_recall": {
            "1": 0.06666666666666667,
            "2": 0.18181818181818182,
            "3": 0.0,
            "4": 0.8,
            "5": 0.5294117647058824,
            "6": 0.66,
            "7": 0.7777777777777778
        },
        "nist": 6.7290140539207615,
        "bleu": 58.55045,
        "bleurt": 0.00896,
        "nubia": {
            "semantic_relation": 4.09359,
            "contradiction": 5.01593,
            "irrelevancy": 28.38677,
            "logical_agreement": 66.59729,
            "grammar_ref": 4.59683,
            "grammar_hyp": 5.35087,
            "nubia_score": 0.5844
        },
        "meteor": 0.4001140330376913,
        "bertscore": {
            "precision": 0.93908,
            "recall": 0.9061,
            "f1": 0.92077
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 41,
        "msttr-100": 0.55471,
        "msttr-100_nopunct": 0.57333,
        "total_length": 1761,
        "mean_pred_length": 42.951219512195124,
        "std_pred_length": 8.610688818406118,
        "median_pred_length": 44.0,
        "min_pred_length": 20,
        "max_pred_length": 59,
        "distinct-1": 0.2788188529244747,
        "vocab_size-1": 491,
        "unique-1": 263,
        "entropy-1": 7.288420964509225,
        "distinct-2": 0.5784883720930233,
        "vocab_size-2": 995,
        "unique-2": 696,
        "entropy-2": 9.505070035819244,
        "cond_entropy-2": 2.1379706043807145,
        "distinct-3": 0.7331745086360929,
        "vocab_size-3": 1231,
        "unique-3": 980,
        "entropy-3": 10.047468813968862,
        "cond_entropy-3": 0.5578567774532079,
        "total_length-nopunct": 1565,
        "mean_pred_length-nopunct": 38.170731707317074,
        "std_pred_length-nopunct": 7.953837665614372,
        "median_pred_length-nopunct": 40.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.3111821086261981,
        "vocab_size-1-nopunct": 487,
        "unique-1-nopunct": 261,
        "entropy-1-nopunct": 7.500637160433695,
        "distinct-2-nopunct": 0.6082677165354331,
        "vocab_size-2-nopunct": 927,
        "unique-2-nopunct": 662,
        "entropy-2-nopunct": 9.462058135165414,
        "cond_entropy-2-nopunct": 2.0126893349044703,
        "distinct-3-nopunct": 0.7532029669588671,
        "vocab_size-3-nopunct": 1117,
        "unique-3-nopunct": 903,
        "entropy-3-nopunct": 9.92916643704411,
        "cond_entropy-3-nopunct": 0.47176057329740195,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.64683,
            "recall": 0.58775,
            "fmeasure": 0.61017
        },
        "rouge2": {
            "precision": 0.33933,
            "recall": 0.313,
            "fmeasure": 0.32228
        },
        "rougeL": {
            "precision": 0.4448,
            "recall": 0.3983,
            "fmeasure": 0.41534
        },
        "rougeLsum": {
            "precision": 0.4448,
            "recall": 0.3983,
            "fmeasure": 0.41534
        },
        "local_recall": {
            "1": 0.21148036253776434,
            "2": 0.3877551020408163,
            "3": 0.6868008948545862
        },
        "nist": 6.392798597743967,
        "bleu": 34.93727,
        "bleurt": -0.219,
        "nubia": {
            "semantic_relation": 3.41502,
            "contradiction": 31.7222,
            "irrelevancy": 15.59631,
            "logical_agreement": 52.68148,
            "grammar_ref": 3.92594,
            "grammar_hyp": 4.01647,
            "nubia_score": 0.54382
        },
        "meteor": 0.2798542788115092,
        "bertscore": {
            "precision": 0.8715,
            "recall": 0.86013,
            "f1": 0.86444
        }
    },
    "web_nlg_ru_test_contrast_challenge_combinations-seen": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 494,
        "msttr-100": 0.45971,
        "msttr-100_nopunct": 0.4557,
        "total_length": 24323,
        "mean_pred_length": 49.23684210526316,
        "std_pred_length": 16.30685565781168,
        "median_pred_length": 48.0,
        "min_pred_length": 14,
        "max_pred_length": 84,
        "distinct-1": 0.072071701681536,
        "vocab_size-1": 1753,
        "unique-1": 705,
        "entropy-1": 5.8726260916596305,
        "distinct-2": 0.1997565991019346,
        "vocab_size-2": 4760,
        "unique-2": 2441,
        "entropy-2": 10.13677139112792,
        "cond_entropy-2": 4.264896830883357,
        "distinct-3": 0.3688022284122563,
        "vocab_size-3": 8606,
        "unique-3": 5292,
        "entropy-3": 11.876282753981341,
        "cond_entropy-3": 1.776675737843972,
        "total_length-nopunct": 22395,
        "mean_pred_length-nopunct": 45.33400809716599,
        "std_pred_length-nopunct": 15.576238564614911,
        "median_pred_length-nopunct": 44.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 80,
        "distinct-1-nopunct": 0.0778745255637419,
        "vocab_size-1-nopunct": 1744,
        "unique-1-nopunct": 703,
        "entropy-1-nopunct": 5.771541276095675,
        "distinct-2-nopunct": 0.20181726861787133,
        "vocab_size-2-nopunct": 4420,
        "unique-2-nopunct": 2291,
        "entropy-2-nopunct": 9.993925389185,
        "cond_entropy-2-nopunct": 4.30040459932197,
        "distinct-3-nopunct": 0.3683841734012239,
        "vocab_size-3-nopunct": 7886,
        "unique-3-nopunct": 4934,
        "entropy-3-nopunct": 11.692700490001586,
        "cond_entropy-3-nopunct": 1.7342446272342407,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.38166,
            "recall": 0.35431,
            "fmeasure": 0.35926
        },
        "rouge2": {
            "precision": 0.17246,
            "recall": 0.16154,
            "fmeasure": 0.1635
        },
        "rougeL": {
            "precision": 0.3477,
            "recall": 0.3241,
            "fmeasure": 0.32747
        },
        "rougeLsum": {
            "precision": 0.3477,
            "recall": 0.3241,
            "fmeasure": 0.32747
        },
        "local_recall": {
            "1": 0.08550443458980045,
            "2": 0.1832552693208431,
            "3": 0.27004063538973033,
            "4": 0.0,
            "5": 0.5,
            "6": 0.0,
            "7": 0.0
        },
        "nist": 1.0989868565231895,
        "bleu": 1.99961,
        "bleurt": -0.52113,
        "nubia": {
            "semantic_relation": 3.29214,
            "contradiction": 32.80197,
            "irrelevancy": 17.32023,
            "logical_agreement": 49.87779,
            "grammar_ref": 2.60025,
            "grammar_hyp": 2.5521,
            "nubia_score": 0.14381
        },
        "meteor": 0.12316421878453475,
        "bertscore": {
            "precision": 0.85689,
            "recall": 0.86944,
            "f1": 0.86253
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation_parent": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.72435,
        "msttr-100_nopunct": 0.76541,
        "total_length": 6957,
        "mean_pred_length": 19.37883008356546,
        "std_pred_length": 9.592894176785535,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.35518183124910163,
        "vocab_size-1": 2471,
        "unique-1": 1802,
        "entropy-1": 9.05504691719738,
        "distinct-2": 0.8243407093058502,
        "vocab_size-2": 5439,
        "unique-2": 5002,
        "entropy-2": 12.060159685285985,
        "cond_entropy-2": 2.735285609845925,
        "distinct-3": 0.9541593204039109,
        "vocab_size-3": 5953,
        "unique-3": 5824,
        "entropy-3": 12.443872967783085,
        "cond_entropy-3": 0.4019231058393918,
        "total_length-nopunct": 6171,
        "mean_pred_length-nopunct": 17.18941504178273,
        "std_pred_length-nopunct": 8.415584392103106,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.3986387943607195,
        "vocab_size-1-nopunct": 2460,
        "unique-1-nopunct": 1800,
        "entropy-1-nopunct": 9.4005582577569,
        "distinct-2-nopunct": 0.8470406056434963,
        "vocab_size-2-nopunct": 4923,
        "unique-2-nopunct": 4562,
        "entropy-2-nopunct": 11.977220121622265,
        "cond_entropy-2-nopunct": 2.7196221359150345,
        "distinct-3-nopunct": 0.9719420502475702,
        "vocab_size-3-nopunct": 5300,
        "unique-3-nopunct": 5199,
        "entropy-3-nopunct": 12.342783592540554,
        "cond_entropy-3-nopunct": 0.39303752247397783,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.84006,
            "recall": 0.75493,
            "fmeasure": 0.77952
        },
        "rouge2": {
            "precision": 0.6877,
            "recall": 0.61926,
            "fmeasure": 0.63642
        },
        "rougeL": {
            "precision": 0.81097,
            "recall": 0.72754,
            "fmeasure": 0.75098
        },
        "rougeLsum": {
            "precision": 0.81097,
            "recall": 0.72754,
            "fmeasure": 0.75098
        },
        "local_recall": {
            "1": 0.04690152801358234,
            "2": 0.15197956577266922,
            "3": 0.3610503282275711,
            "4": 0.5071315372424723,
            "5": 0.592938733125649,
            "6": 0.7185990338164251,
            "7": 0.8468881252386407
        },
        "nist": 10.679929126928785,
        "bleu": 64.19993,
        "bleurt": 0.15481,
        "nubia": {
            "semantic_relation": 4.17358,
            "contradiction": 4.55557,
            "irrelevancy": 17.94298,
            "logical_agreement": 77.50146,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.94561,
            "nubia_score": 0.65904
        },
        "meteor": 0.43673495570659426,
        "bertscore": {
            "precision": 0.9506,
            "recall": 0.93397,
            "f1": 0.93935
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02_parent": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.72435,
        "msttr-100_nopunct": 0.76541,
        "total_length": 6957,
        "mean_pred_length": 19.37883008356546,
        "std_pred_length": 9.592894176785535,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.35518183124910163,
        "vocab_size-1": 2471,
        "unique-1": 1802,
        "entropy-1": 9.05504691719738,
        "distinct-2": 0.8243407093058502,
        "vocab_size-2": 5439,
        "unique-2": 5002,
        "entropy-2": 12.060159685285985,
        "cond_entropy-2": 2.735285609845925,
        "distinct-3": 0.9541593204039109,
        "vocab_size-3": 5953,
        "unique-3": 5824,
        "entropy-3": 12.443872967783085,
        "cond_entropy-3": 0.4019231058393918,
        "total_length-nopunct": 6171,
        "mean_pred_length-nopunct": 17.18941504178273,
        "std_pred_length-nopunct": 8.415584392103106,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.3986387943607195,
        "vocab_size-1-nopunct": 2460,
        "unique-1-nopunct": 1800,
        "entropy-1-nopunct": 9.4005582577569,
        "distinct-2-nopunct": 0.8470406056434963,
        "vocab_size-2-nopunct": 4923,
        "unique-2-nopunct": 4562,
        "entropy-2-nopunct": 11.977220121622265,
        "cond_entropy-2-nopunct": 2.7196221359150345,
        "distinct-3-nopunct": 0.9719420502475702,
        "vocab_size-3-nopunct": 5300,
        "unique-3-nopunct": 5199,
        "entropy-3-nopunct": 12.342783592540554,
        "cond_entropy-3-nopunct": 0.39303752247397783,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.84006,
            "recall": 0.75493,
            "fmeasure": 0.77952
        },
        "rouge2": {
            "precision": 0.6877,
            "recall": 0.61926,
            "fmeasure": 0.63642
        },
        "rougeL": {
            "precision": 0.81097,
            "recall": 0.72754,
            "fmeasure": 0.75098
        },
        "rougeLsum": {
            "precision": 0.81097,
            "recall": 0.72754,
            "fmeasure": 0.75098
        },
        "local_recall": {
            "1": 0.04690152801358234,
            "2": 0.15197956577266922,
            "3": 0.3610503282275711,
            "4": 0.5071315372424723,
            "5": 0.592938733125649,
            "6": 0.7185990338164251,
            "7": 0.8468881252386407
        },
        "nist": 10.679929126928785,
        "bleu": 64.19993,
        "bleurt": 0.15481,
        "nubia": {
            "semantic_relation": 4.17358,
            "contradiction": 4.55557,
            "irrelevancy": 17.94298,
            "logical_agreement": 77.50146,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.94561,
            "nubia_score": 0.65904
        },
        "meteor": 0.43673495570659426,
        "bertscore": {
            "precision": 0.9506,
            "recall": 0.93397,
            "f1": 0.93935
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 63,
        "msttr-100": 0.7225,
        "msttr-100_nopunct": 0.76071,
        "total_length": 1627,
        "mean_pred_length": 25.825396825396826,
        "std_pred_length": 9.358028015270797,
        "median_pred_length": 25.0,
        "min_pred_length": 6,
        "max_pred_length": 46,
        "distinct-1": 0.4535955746773202,
        "vocab_size-1": 738,
        "unique-1": 567,
        "entropy-1": 8.209521219707147,
        "distinct-2": 0.8836317135549873,
        "vocab_size-2": 1382,
        "unique-2": 1299,
        "entropy-2": 10.243151278828192,
        "cond_entropy-2": 1.8761457099801029,
        "distinct-3": 0.9586942038640907,
        "vocab_size-3": 1439,
        "unique-3": 1419,
        "entropy-3": 10.397153227136185,
        "cond_entropy-3": 0.16427586180711382,
        "total_length-nopunct": 1458,
        "mean_pred_length-nopunct": 23.142857142857142,
        "std_pred_length-nopunct": 8.347335175680163,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.5,
        "vocab_size-1-nopunct": 729,
        "unique-1-nopunct": 564,
        "entropy-1-nopunct": 8.414793637878025,
        "distinct-2-nopunct": 0.9118279569892473,
        "vocab_size-2-nopunct": 1272,
        "unique-2-nopunct": 1202,
        "entropy-2-nopunct": 10.198384336351635,
        "cond_entropy-2-nopunct": 1.853300111658881,
        "distinct-3-nopunct": 0.9857357357357357,
        "vocab_size-3-nopunct": 1313,
        "unique-3-nopunct": 1298,
        "entropy-3-nopunct": 10.348214872323467,
        "cond_entropy-3-nopunct": 0.1596037618970197,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.81039,
            "recall": 0.7438,
            "fmeasure": 0.76205
        },
        "rouge2": {
            "precision": 0.6665,
            "recall": 0.62349,
            "fmeasure": 0.6306
        },
        "rougeL": {
            "precision": 0.78848,
            "recall": 0.72163,
            "fmeasure": 0.74028
        },
        "rougeLsum": {
            "precision": 0.78848,
            "recall": 0.72163,
            "fmeasure": 0.74028
        },
        "local_recall": {
            "1": 0.05110896817743491,
            "2": 0.18012422360248448,
            "3": 0.3617021276595745,
            "4": 0.5522388059701493,
            "5": 0.6392156862745098,
            "6": 0.7128463476070529,
            "7": 0.8490566037735849
        },
        "nist": 9.235704550467695,
        "bleu": 64.38112,
        "bleurt": 0.06728,
        "nubia": {
            "semantic_relation": 4.12563,
            "contradiction": 4.73783,
            "irrelevancy": 23.05146,
            "logical_agreement": 72.21071,
            "grammar_ref": 4.43738,
            "grammar_hyp": 4.85725,
            "nubia_score": 0.62757
        },
        "meteor": 0.4357257173382707,
        "bertscore": {
            "precision": 0.93889,
            "recall": 0.932,
            "f1": 0.93179
        }
    },
    "totto_test_contrast_challenge_gender-male": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 300,
        "msttr-100": 0.72771,
        "msttr-100_nopunct": 0.78357,
        "total_length": 4828,
        "mean_pred_length": 16.093333333333334,
        "std_pred_length": 5.997051127197618,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 38,
        "distinct-1": 0.3792460646230323,
        "vocab_size-1": 1831,
        "unique-1": 1413,
        "entropy-1": 8.813955754462999,
        "distinct-2": 0.780256183745583,
        "vocab_size-2": 3533,
        "unique-2": 3129,
        "entropy-2": 11.452102864128085,
        "cond_entropy-2": 2.319122118518254,
        "distinct-3": 0.935666982024598,
        "vocab_size-3": 3956,
        "unique-3": 3786,
        "entropy-3": 11.889548817997538,
        "cond_entropy-3": 0.42999989231954433,
        "total_length-nopunct": 4231,
        "mean_pred_length-nopunct": 14.103333333333333,
        "std_pred_length-nopunct": 5.4288724018488,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.43063105648782796,
        "vocab_size-1-nopunct": 1822,
        "unique-1-nopunct": 1410,
        "entropy-1-nopunct": 9.20270850968443,
        "distinct-2-nopunct": 0.8069193589417452,
        "vocab_size-2-nopunct": 3172,
        "unique-2-nopunct": 2870,
        "entropy-2-nopunct": 11.310009345212826,
        "cond_entropy-2-nopunct": 2.209706374193835,
        "distinct-3-nopunct": 0.9482236298540347,
        "vocab_size-3-nopunct": 3443,
        "unique-3-nopunct": 3316,
        "entropy-3-nopunct": 11.703960281880942,
        "cond_entropy-3-nopunct": 0.41934049309716165,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80369,
            "recall": 0.77021,
            "fmeasure": 0.77648
        },
        "rouge2": {
            "precision": 0.57558,
            "recall": 0.55048,
            "fmeasure": 0.55496
        },
        "rougeL": {
            "precision": 0.6844,
            "recall": 0.65968,
            "fmeasure": 0.66278
        },
        "rougeLsum": {
            "precision": 0.6844,
            "recall": 0.65968,
            "fmeasure": 0.66278
        },
        "local_recall": {
            "1": 0.19953325554259044,
            "2": 0.43405889884763127,
            "3": 0.8027439024390244
        },
        "nist": 8.68476301439324,
        "bleu": 46.69003,
        "bleurt": 0.36651,
        "nubia": {
            "semantic_relation": 4.40847,
            "contradiction": 4.62889,
            "irrelevancy": 23.60605,
            "logical_agreement": 71.76505,
            "grammar_ref": 4.83962,
            "grammar_hyp": 4.87257,
            "nubia_score": 0.78593
        },
        "meteor": 0.4124877293822172,
        "bertscore": {
            "precision": 0.94149,
            "recall": 0.93852,
            "f1": 0.93888
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_9": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 105,
        "msttr-100": 0.69067,
        "msttr-100_nopunct": 0.74,
        "total_length": 1552,
        "mean_pred_length": 14.780952380952382,
        "std_pred_length": 7.610745476759694,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 48,
        "distinct-1": 0.4072164948453608,
        "vocab_size-1": 632,
        "unique-1": 486,
        "entropy-1": 7.823968113533274,
        "distinct-2": 0.7767795438838977,
        "vocab_size-2": 1124,
        "unique-2": 986,
        "entropy-2": 9.853626944300355,
        "cond_entropy-2": 1.7428879591566353,
        "distinct-3": 0.8926974664679582,
        "vocab_size-3": 1198,
        "unique-3": 1113,
        "entropy-3": 10.125438151138475,
        "cond_entropy-3": 0.27916890769759173,
        "total_length-nopunct": 1332,
        "mean_pred_length-nopunct": 12.685714285714285,
        "std_pred_length-nopunct": 6.450270257482071,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.46846846846846846,
        "vocab_size-1-nopunct": 624,
        "unique-1-nopunct": 485,
        "entropy-1-nopunct": 8.07517568832323,
        "distinct-2-nopunct": 0.8019559902200489,
        "vocab_size-2-nopunct": 984,
        "unique-2-nopunct": 879,
        "entropy-2-nopunct": 9.686123873964494,
        "cond_entropy-2-nopunct": 1.7313791550106494,
        "distinct-3-nopunct": 0.9055258467023173,
        "vocab_size-3-nopunct": 1016,
        "unique-3-nopunct": 954,
        "entropy-3-nopunct": 9.898899362586878,
        "cond_entropy-3-nopunct": 0.233091417242701,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65298,
            "recall": 0.61167,
            "fmeasure": 0.61705
        },
        "rouge2": {
            "precision": 0.41994,
            "recall": 0.39978,
            "fmeasure": 0.40304
        },
        "rougeL": {
            "precision": 0.55072,
            "recall": 0.52318,
            "fmeasure": 0.52423
        },
        "rougeLsum": {
            "precision": 0.55072,
            "recall": 0.52318,
            "fmeasure": 0.52423
        },
        "local_recall": {
            "1": 0.24277456647398843,
            "2": 0.4117647058823529,
            "3": 0.7193548387096774
        },
        "nist": 6.921481748718531,
        "bleu": 41.31923,
        "bleurt": 0.09941,
        "nubia": {
            "semantic_relation": 3.53734,
            "contradiction": 17.29944,
            "irrelevancy": 31.47795,
            "logical_agreement": 51.22261,
            "grammar_ref": 4.94529,
            "grammar_hyp": 4.93052,
            "nubia_score": 0.60661
        },
        "meteor": 0.3506934789432849,
        "bertscore": {
            "precision": 0.89969,
            "recall": 0.89127,
            "f1": 0.89391
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05_parent": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.72435,
        "msttr-100_nopunct": 0.76541,
        "total_length": 6957,
        "mean_pred_length": 19.37883008356546,
        "std_pred_length": 9.592894176785535,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.35518183124910163,
        "vocab_size-1": 2471,
        "unique-1": 1802,
        "entropy-1": 9.05504691719738,
        "distinct-2": 0.8243407093058502,
        "vocab_size-2": 5439,
        "unique-2": 5002,
        "entropy-2": 12.060159685285985,
        "cond_entropy-2": 2.735285609845925,
        "distinct-3": 0.9541593204039109,
        "vocab_size-3": 5953,
        "unique-3": 5824,
        "entropy-3": 12.443872967783085,
        "cond_entropy-3": 0.4019231058393918,
        "total_length-nopunct": 6171,
        "mean_pred_length-nopunct": 17.18941504178273,
        "std_pred_length-nopunct": 8.415584392103106,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.3986387943607195,
        "vocab_size-1-nopunct": 2460,
        "unique-1-nopunct": 1800,
        "entropy-1-nopunct": 9.4005582577569,
        "distinct-2-nopunct": 0.8470406056434963,
        "vocab_size-2-nopunct": 4923,
        "unique-2-nopunct": 4562,
        "entropy-2-nopunct": 11.977220121622265,
        "cond_entropy-2-nopunct": 2.7196221359150345,
        "distinct-3-nopunct": 0.9719420502475702,
        "vocab_size-3-nopunct": 5300,
        "unique-3-nopunct": 5199,
        "entropy-3-nopunct": 12.342783592540554,
        "cond_entropy-3-nopunct": 0.39303752247397783,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.84006,
            "recall": 0.75493,
            "fmeasure": 0.77952
        },
        "rouge2": {
            "precision": 0.6877,
            "recall": 0.61926,
            "fmeasure": 0.63642
        },
        "rougeL": {
            "precision": 0.81097,
            "recall": 0.72754,
            "fmeasure": 0.75098
        },
        "rougeLsum": {
            "precision": 0.81097,
            "recall": 0.72754,
            "fmeasure": 0.75098
        },
        "local_recall": {
            "1": 0.04690152801358234,
            "2": 0.15197956577266922,
            "3": 0.3610503282275711,
            "4": 0.5071315372424723,
            "5": 0.592938733125649,
            "6": 0.7185990338164251,
            "7": 0.8468881252386407
        },
        "nist": 10.679929126928785,
        "bleu": 64.19993,
        "bleurt": 0.15481,
        "nubia": {
            "semantic_relation": 4.17358,
            "contradiction": 4.55557,
            "irrelevancy": 17.94298,
            "logical_agreement": 77.50146,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.94561,
            "nubia_score": 0.65904
        },
        "meteor": 0.43673495570659426,
        "bertscore": {
            "precision": 0.9506,
            "recall": 0.93397,
            "f1": 0.93935
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc_parent": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.72435,
        "msttr-100_nopunct": 0.76541,
        "total_length": 6957,
        "mean_pred_length": 19.37883008356546,
        "std_pred_length": 9.592894176785535,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.35518183124910163,
        "vocab_size-1": 2471,
        "unique-1": 1802,
        "entropy-1": 9.05504691719738,
        "distinct-2": 0.8243407093058502,
        "vocab_size-2": 5439,
        "unique-2": 5002,
        "entropy-2": 12.060159685285985,
        "cond_entropy-2": 2.735285609845925,
        "distinct-3": 0.9541593204039109,
        "vocab_size-3": 5953,
        "unique-3": 5824,
        "entropy-3": 12.443872967783085,
        "cond_entropy-3": 0.4019231058393918,
        "total_length-nopunct": 6171,
        "mean_pred_length-nopunct": 17.18941504178273,
        "std_pred_length-nopunct": 8.415584392103106,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.3986387943607195,
        "vocab_size-1-nopunct": 2460,
        "unique-1-nopunct": 1800,
        "entropy-1-nopunct": 9.4005582577569,
        "distinct-2-nopunct": 0.8470406056434963,
        "vocab_size-2-nopunct": 4923,
        "unique-2-nopunct": 4562,
        "entropy-2-nopunct": 11.977220121622265,
        "cond_entropy-2-nopunct": 2.7196221359150345,
        "distinct-3-nopunct": 0.9719420502475702,
        "vocab_size-3-nopunct": 5300,
        "unique-3-nopunct": 5199,
        "entropy-3-nopunct": 12.342783592540554,
        "cond_entropy-3-nopunct": 0.39303752247397783,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.84006,
            "recall": 0.75493,
            "fmeasure": 0.77952
        },
        "rouge2": {
            "precision": 0.6877,
            "recall": 0.61926,
            "fmeasure": 0.63642
        },
        "rougeL": {
            "precision": 0.81097,
            "recall": 0.72754,
            "fmeasure": 0.75098
        },
        "rougeLsum": {
            "precision": 0.81097,
            "recall": 0.72754,
            "fmeasure": 0.75098
        },
        "local_recall": {
            "1": 0.04690152801358234,
            "2": 0.15197956577266922,
            "3": 0.3610503282275711,
            "4": 0.5071315372424723,
            "5": 0.592938733125649,
            "6": 0.7185990338164251,
            "7": 0.8468881252386407
        },
        "nist": 10.679929126928785,
        "bleu": 64.19993,
        "bleurt": 0.15481,
        "nubia": {
            "semantic_relation": 4.17358,
            "contradiction": 4.55557,
            "irrelevancy": 17.94298,
            "logical_agreement": 77.50146,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.94561,
            "nubia_score": 0.65904
        },
        "meteor": 0.43673495570659426,
        "bertscore": {
            "precision": 0.9506,
            "recall": 0.93397,
            "f1": 0.93935
        }
    },
    "web_nlg_ru_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 354,
        "msttr-100": 0.45805,
        "msttr-100_nopunct": 0.45602,
        "total_length": 20080,
        "mean_pred_length": 56.72316384180791,
        "std_pred_length": 14.529229263262911,
        "median_pred_length": 59.5,
        "min_pred_length": 11,
        "max_pred_length": 85,
        "distinct-1": 0.07639442231075697,
        "vocab_size-1": 1534,
        "unique-1": 621,
        "entropy-1": 5.845776269614674,
        "distinct-2": 0.2048058400081111,
        "vocab_size-2": 4040,
        "unique-2": 2057,
        "entropy-2": 10.038074852703824,
        "cond_entropy-2": 4.198163779002068,
        "distinct-3": 0.366611604377452,
        "vocab_size-3": 7102,
        "unique-3": 4284,
        "entropy-3": 11.666446787227066,
        "cond_entropy-3": 1.6467677918653947,
        "total_length-nopunct": 18618,
        "mean_pred_length-nopunct": 52.59322033898305,
        "std_pred_length-nopunct": 14.028766222295257,
        "median_pred_length-nopunct": 55.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 79,
        "distinct-1-nopunct": 0.08190997958964442,
        "vocab_size-1-nopunct": 1525,
        "unique-1-nopunct": 620,
        "entropy-1-nopunct": 5.753704805075618,
        "distinct-2-nopunct": 0.20784056066579062,
        "vocab_size-2-nopunct": 3796,
        "unique-2-nopunct": 1937,
        "entropy-2-nopunct": 9.962625553196874,
        "cond_entropy-2-nopunct": 4.257622146832333,
        "distinct-3-nopunct": 0.3683417085427136,
        "vocab_size-3-nopunct": 6597,
        "unique-3-nopunct": 4023,
        "entropy-3-nopunct": 11.548661662636936,
        "cond_entropy-3-nopunct": 1.6085461318101082,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.53809,
            "recall": 0.52652,
            "fmeasure": 0.52463
        },
        "rouge2": {
            "precision": 0.27253,
            "recall": 0.26947,
            "fmeasure": 0.26592
        },
        "rougeL": {
            "precision": 0.51425,
            "recall": 0.50367,
            "fmeasure": 0.50133
        },
        "rougeLsum": {
            "precision": 0.51425,
            "recall": 0.50367,
            "fmeasure": 0.50133
        },
        "local_recall": {
            "1": 0.09224121735863235,
            "2": 0.1830670926517572,
            "3": 0.24841034336583298,
            "4": 0.1891891891891892,
            "5": 0.22727272727272727,
            "6": 0.0,
            "7": 0.2
        },
        "nist": 1.0895855762331332,
        "bleu": 1.55353,
        "bleurt": -0.50412,
        "nubia": {
            "semantic_relation": 3.31077,
            "contradiction": 32.98626,
            "irrelevancy": 18.07439,
            "logical_agreement": 48.93935,
            "grammar_ref": 2.54394,
            "grammar_hyp": 2.46998,
            "nubia_score": 0.13888
        },
        "meteor": 0.11924095487232426,
        "bertscore": {
            "precision": 0.85969,
            "recall": 0.87048,
            "f1": 0.8646
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_30": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 122,
        "msttr-100": 0.7325,
        "msttr-100_nopunct": 0.77941,
        "total_length": 2039,
        "mean_pred_length": 16.71311475409836,
        "std_pred_length": 6.620236621243815,
        "median_pred_length": 14.5,
        "min_pred_length": 6,
        "max_pred_length": 42,
        "distinct-1": 0.45316331535066207,
        "vocab_size-1": 924,
        "unique-1": 734,
        "entropy-1": 8.320299312627487,
        "distinct-2": 0.8643714136671883,
        "vocab_size-2": 1657,
        "unique-2": 1521,
        "entropy-2": 10.538065534355097,
        "cond_entropy-2": 1.946821176343581,
        "distinct-3": 0.9610027855153204,
        "vocab_size-3": 1725,
        "unique-3": 1667,
        "entropy-3": 10.725228515360877,
        "cond_entropy-3": 0.16958122820097066,
        "total_length-nopunct": 1792,
        "mean_pred_length-nopunct": 14.688524590163935,
        "std_pred_length-nopunct": 6.111105138997948,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.5100446428571429,
        "vocab_size-1-nopunct": 914,
        "unique-1-nopunct": 730,
        "entropy-1-nopunct": 8.612480424156317,
        "distinct-2-nopunct": 0.881437125748503,
        "vocab_size-2-nopunct": 1472,
        "unique-2-nopunct": 1364,
        "entropy-2-nopunct": 10.387905393274169,
        "cond_entropy-2-nopunct": 1.8580461293733697,
        "distinct-3-nopunct": 0.9664082687338501,
        "vocab_size-3-nopunct": 1496,
        "unique-3-nopunct": 1453,
        "entropy-3-nopunct": 10.522879715152783,
        "cond_entropy-3-nopunct": 0.1484354851699079,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75102,
            "recall": 0.72617,
            "fmeasure": 0.72605
        },
        "rouge2": {
            "precision": 0.50812,
            "recall": 0.48851,
            "fmeasure": 0.48991
        },
        "rougeL": {
            "precision": 0.64398,
            "recall": 0.61702,
            "fmeasure": 0.62014
        },
        "rougeLsum": {
            "precision": 0.64398,
            "recall": 0.61702,
            "fmeasure": 0.62014
        },
        "local_recall": {
            "1": 0.1842696629213483,
            "2": 0.4035608308605341,
            "3": 0.7631384159881569
        },
        "nist": 7.462299819089226,
        "bleu": 43.44516,
        "bleurt": 0.27091,
        "nubia": {
            "semantic_relation": 4.24598,
            "contradiction": 4.38979,
            "irrelevancy": 30.58249,
            "logical_agreement": 65.02772,
            "grammar_ref": 4.69288,
            "grammar_hyp": 4.70221,
            "nubia_score": 0.7325
        },
        "meteor": 0.3828774974489264,
        "bertscore": {
            "precision": 0.92239,
            "recall": 0.92016,
            "f1": 0.91928
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_31": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 79,
        "mean_pred_length": 19.75,
        "std_pred_length": 11.211043662389331,
        "median_pred_length": 14.5,
        "min_pred_length": 11,
        "max_pred_length": 39,
        "distinct-1": 0.759493670886076,
        "vocab_size-1": 60,
        "unique-1": 52,
        "entropy-1": 5.645350211075794,
        "distinct-2": 0.9866666666666667,
        "vocab_size-2": 74,
        "unique-2": 73,
        "entropy-2": 6.202152023829224,
        "cond_entropy-2": 0.48525144139882465,
        "distinct-3": 1.0,
        "vocab_size-3": 71,
        "unique-3": 71,
        "entropy-3": 6.149747119504677,
        "cond_entropy-3": -0.050902556906691585,
        "total_length-nopunct": 68,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 8.74642784226795,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.8529411764705882,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 5.729160959241514,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 64,
        "unique-2-nopunct": 64,
        "entropy-2-nopunct": 6.0,
        "cond_entropy-2-nopunct": 0.2776079083840402,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 60,
        "unique-3-nopunct": 60,
        "entropy-3-nopunct": 5.906890595608517,
        "cond_entropy-3-nopunct": -0.09310940439148153,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.84875,
            "recall": 0.96859,
            "fmeasure": 0.89573
        },
        "rouge2": {
            "precision": 0.74384,
            "recall": 0.83988,
            "fmeasure": 0.781
        },
        "rougeL": {
            "precision": 0.76542,
            "recall": 0.88191,
            "fmeasure": 0.81089
        },
        "rougeLsum": {
            "precision": 0.76542,
            "recall": 0.88191,
            "fmeasure": 0.81089
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.8181818181818182,
            "3": 0.9555555555555556
        },
        "nist": 5.714486940835772,
        "bleu": 75.87795,
        "bleurt": 0.59887,
        "nubia": {
            "semantic_relation": 4.50849,
            "contradiction": 0.17068,
            "irrelevancy": 41.9166,
            "logical_agreement": 57.91273,
            "grammar_ref": 4.43427,
            "grammar_hyp": 3.92844,
            "nubia_score": 0.88826
        },
        "meteor": 0.5604230071009011,
        "bertscore": {
            "precision": 0.96138,
            "recall": 0.98056,
            "f1": 0.96957
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_32": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 49,
        "msttr-100": 0.6975,
        "msttr-100_nopunct": 0.75571,
        "total_length": 886,
        "mean_pred_length": 18.081632653061224,
        "std_pred_length": 6.730487245284235,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 38,
        "distinct-1": 0.5248306997742663,
        "vocab_size-1": 465,
        "unique-1": 381,
        "entropy-1": 7.7392180775721275,
        "distinct-2": 0.9020310633213859,
        "vocab_size-2": 755,
        "unique-2": 709,
        "entropy-2": 9.445469256042289,
        "cond_entropy-2": 1.494299510586548,
        "distinct-3": 0.9746192893401016,
        "vocab_size-3": 768,
        "unique-3": 751,
        "entropy-3": 9.568416460945702,
        "cond_entropy-3": 0.12061500409978394,
        "total_length-nopunct": 759,
        "mean_pred_length-nopunct": 15.489795918367347,
        "std_pred_length-nopunct": 5.7645023821187475,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.5994729907773386,
        "vocab_size-1-nopunct": 455,
        "unique-1-nopunct": 377,
        "entropy-1-nopunct": 7.956861055565915,
        "distinct-2-nopunct": 0.9140845070422535,
        "vocab_size-2-nopunct": 649,
        "unique-2-nopunct": 616,
        "entropy-2-nopunct": 9.230639145669459,
        "cond_entropy-2-nopunct": 1.3569032217502148,
        "distinct-3-nopunct": 0.9818456883509834,
        "vocab_size-3-nopunct": 649,
        "unique-3-nopunct": 639,
        "entropy-3-nopunct": 9.329913761047157,
        "cond_entropy-3-nopunct": 0.1069234502722402,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77051,
            "recall": 0.70905,
            "fmeasure": 0.72757
        },
        "rouge2": {
            "precision": 0.52782,
            "recall": 0.48802,
            "fmeasure": 0.49952
        },
        "rougeL": {
            "precision": 0.67898,
            "recall": 0.63332,
            "fmeasure": 0.64564
        },
        "rougeLsum": {
            "precision": 0.67898,
            "recall": 0.63332,
            "fmeasure": 0.64564
        },
        "local_recall": {
            "1": 0.23711340206185566,
            "2": 0.44508670520231214,
            "3": 0.7571157495256167
        },
        "nist": 6.937020080293748,
        "bleu": 43.89607,
        "bleurt": 0.24946,
        "nubia": {
            "semantic_relation": 4.24645,
            "contradiction": 7.28393,
            "irrelevancy": 23.67219,
            "logical_agreement": 69.04388,
            "grammar_ref": 4.75318,
            "grammar_hyp": 4.8385,
            "nubia_score": 0.72783
        },
        "meteor": 0.370754951117178,
        "bertscore": {
            "precision": 0.93216,
            "recall": 0.92395,
            "f1": 0.92635
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_33": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 21,
        "msttr-100": 0.69333,
        "msttr-100_nopunct": 0.73,
        "total_length": 306,
        "mean_pred_length": 14.571428571428571,
        "std_pred_length": 5.720234998264858,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.5718954248366013,
        "vocab_size-1": 175,
        "unique-1": 147,
        "entropy-1": 6.7497551904479804,
        "distinct-2": 0.9122807017543859,
        "vocab_size-2": 260,
        "unique-2": 248,
        "entropy-2": 7.9250498864017205,
        "cond_entropy-2": 0.9627389760196526,
        "distinct-3": 0.9848484848484849,
        "vocab_size-3": 260,
        "unique-3": 258,
        "entropy-3": 8.006515331479676,
        "cond_entropy-3": 0.05576655190077092,
        "total_length-nopunct": 259,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 4.59122696883579,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6563706563706564,
        "vocab_size-1-nopunct": 170,
        "unique-1-nopunct": 147,
        "entropy-1-nopunct": 6.866466935514909,
        "distinct-2-nopunct": 0.9369747899159664,
        "vocab_size-2-nopunct": 223,
        "unique-2-nopunct": 217,
        "entropy-2-nopunct": 7.722047110035871,
        "cond_entropy-2-nopunct": 0.8998975187274829,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 217,
        "unique-3-nopunct": 217,
        "entropy-3-nopunct": 7.761551232444494,
        "cond_entropy-3-nopunct": 0.019357503600884597,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75975,
            "recall": 0.74529,
            "fmeasure": 0.74198
        },
        "rouge2": {
            "precision": 0.53983,
            "recall": 0.51395,
            "fmeasure": 0.51917
        },
        "rougeL": {
            "precision": 0.66318,
            "recall": 0.65638,
            "fmeasure": 0.6504
        },
        "rougeLsum": {
            "precision": 0.66318,
            "recall": 0.65638,
            "fmeasure": 0.6504
        },
        "local_recall": {
            "1": 0.2028985507246377,
            "2": 0.37735849056603776,
            "3": 0.7925531914893617
        },
        "nist": 5.850451575221767,
        "bleu": 44.28333,
        "bleurt": 0.24746,
        "nubia": {
            "semantic_relation": 4.07179,
            "contradiction": 8.66524,
            "irrelevancy": 34.2189,
            "logical_agreement": 57.11586,
            "grammar_ref": 4.80447,
            "grammar_hyp": 4.81996,
            "nubia_score": 0.71128
        },
        "meteor": 0.3894984813941837,
        "bertscore": {
            "precision": 0.92913,
            "recall": 0.92679,
            "f1": 0.92597
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_34": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75,
        "total_length": 127,
        "mean_pred_length": 18.142857142857142,
        "std_pred_length": 7.219587867710444,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.6692913385826772,
        "vocab_size-1": 85,
        "unique-1": 68,
        "entropy-1": 6.090612935210653,
        "distinct-2": 0.925,
        "vocab_size-2": 111,
        "unique-2": 103,
        "entropy-2": 6.750599866423834,
        "cond_entropy-2": 0.5486120796008902,
        "distinct-3": 0.9734513274336283,
        "vocab_size-3": 110,
        "unique-3": 107,
        "entropy-3": 6.767081617282463,
        "cond_entropy-3": 0.02616347744528387,
        "total_length-nopunct": 109,
        "mean_pred_length-nopunct": 15.571428571428571,
        "std_pred_length-nopunct": 6.7793202958312415,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.7339449541284404,
        "vocab_size-1-nopunct": 80,
        "unique-1-nopunct": 66,
        "entropy-1-nopunct": 6.08801032947951,
        "distinct-2-nopunct": 0.9411764705882353,
        "vocab_size-2-nopunct": 96,
        "unique-2-nopunct": 91,
        "entropy-2-nopunct": 6.5473774252836225,
        "cond_entropy-2-nopunct": 0.5060457033245116,
        "distinct-3-nopunct": 0.9894736842105263,
        "vocab_size-3-nopunct": 94,
        "unique-3-nopunct": 93,
        "entropy-3-nopunct": 6.548802976752,
        "cond_entropy-3-nopunct": 0.010639608487488727,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.51443,
            "recall": 0.56945,
            "fmeasure": 0.51629
        },
        "rouge2": {
            "precision": 0.18522,
            "recall": 0.23497,
            "fmeasure": 0.19597
        },
        "rougeL": {
            "precision": 0.38863,
            "recall": 0.45243,
            "fmeasure": 0.39712
        },
        "rougeLsum": {
            "precision": 0.38863,
            "recall": 0.45243,
            "fmeasure": 0.39712
        },
        "local_recall": {
            "1": 0.2413793103448276,
            "2": 0.43478260869565216,
            "3": 0.5964912280701754
        },
        "nist": 3.1628761413257416,
        "bleu": 9.24884,
        "bleurt": -0.0474,
        "nubia": {
            "semantic_relation": 3.76689,
            "contradiction": 1.37505,
            "irrelevancy": 53.72707,
            "logical_agreement": 44.89789,
            "grammar_ref": 4.83605,
            "grammar_hyp": 4.29798,
            "nubia_score": 0.60013
        },
        "meteor": 0.237418648965703,
        "bertscore": {
            "precision": 0.87041,
            "recall": 0.87286,
            "f1": 0.86706
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 642,
        "msttr-100": 0.44295,
        "msttr-100_nopunct": 0.43996,
        "total_length": 24482,
        "mean_pred_length": 38.13395638629284,
        "std_pred_length": 19.405593813715036,
        "median_pred_length": 34.0,
        "min_pred_length": 6,
        "max_pred_length": 85,
        "distinct-1": 0.07544318274650764,
        "vocab_size-1": 1847,
        "unique-1": 733,
        "entropy-1": 6.011658261514642,
        "distinct-2": 0.2083473154362416,
        "vocab_size-2": 4967,
        "unique-2": 2580,
        "entropy-2": 10.283849966406606,
        "cond_entropy-2": 4.257880887881664,
        "distinct-3": 0.36675575480644884,
        "vocab_size-3": 8508,
        "unique-3": 5193,
        "entropy-3": 11.901337314562804,
        "cond_entropy-3": 1.65978381481088,
        "total_length-nopunct": 22482,
        "mean_pred_length-nopunct": 35.018691588785046,
        "std_pred_length-nopunct": 18.223336503056633,
        "median_pred_length-nopunct": 31.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 79,
        "distinct-1-nopunct": 0.08175429232274709,
        "vocab_size-1-nopunct": 1838,
        "unique-1-nopunct": 732,
        "entropy-1-nopunct": 5.925186729608593,
        "distinct-2-nopunct": 0.2086996336996337,
        "vocab_size-2-nopunct": 4558,
        "unique-2-nopunct": 2356,
        "entropy-2-nopunct": 10.141825165320439,
        "cond_entropy-2-nopunct": 4.321998764389112,
        "distinct-3-nopunct": 0.36663836210963296,
        "vocab_size-3-nopunct": 7772,
        "unique-3-nopunct": 4794,
        "entropy-3-nopunct": 11.734327220355002,
        "cond_entropy-3-nopunct": 1.632999854571681,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.49018,
            "recall": 0.47146,
            "fmeasure": 0.47229
        },
        "rouge2": {
            "precision": 0.27398,
            "recall": 0.26531,
            "fmeasure": 0.26513
        },
        "rougeL": {
            "precision": 0.45642,
            "recall": 0.44034,
            "fmeasure": 0.44021
        },
        "rougeLsum": {
            "precision": 0.45642,
            "recall": 0.44034,
            "fmeasure": 0.44021
        },
        "local_recall": {
            "1": 0.09749303621169916,
            "2": 0.20681198910081744,
            "3": 0.3019594121763471,
            "4": 0.19736842105263158,
            "5": 0.24242424242424243,
            "6": 0.18181818181818182,
            "7": 0.25
        },
        "nist": 1.3380894056935384,
        "bleu": 2.87988,
        "bleurt": -0.45569,
        "nubia": {
            "semantic_relation": 3.29935,
            "contradiction": 34.36472,
            "irrelevancy": 17.12356,
            "logical_agreement": 48.51172,
            "grammar_ref": 2.74601,
            "grammar_hyp": 2.78344,
            "nubia_score": 0.16859
        },
        "meteor": 0.14376982338849895,
        "bertscore": {
            "precision": 0.86589,
            "recall": 0.8761,
            "f1": 0.87048
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?request": {
        "predictions_file": "T5-large (Baseline)/cs_restaurants_test",
        "N": 149,
        "msttr-100": 0.15,
        "msttr-100_nopunct": 0.13,
        "total_length": 2831,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.005298481102084069,
        "vocab_size-1": 15,
        "unique-1": 0,
        "entropy-1": 3.7216117239698994,
        "distinct-2": 0.006711409395973154,
        "vocab_size-2": 18,
        "unique-2": 0,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.47755304355428224,
        "distinct-3": 0.006711409395973154,
        "vocab_size-3": 17,
        "unique-3": 0,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 2384,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.005453020134228188,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 3.5,
        "distinct-2-nopunct": 0.006711409395973154,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.44022392894185186,
        "distinct-3-nopunct": 0.006711409395973154,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.07958,
            "recall": 0.14152,
            "fmeasure": 0.09998
        },
        "rouge2": {
            "precision": 0.03201,
            "recall": 0.05856,
            "fmeasure": 0.04088
        },
        "rougeL": {
            "precision": 0.06951,
            "recall": 0.12792,
            "fmeasure": 0.08858
        },
        "rougeLsum": {
            "precision": 0.06951,
            "recall": 0.12792,
            "fmeasure": 0.08858
        },
        "local_recall": {
            "1": 0.0871313672922252
        },
        "nist": 0.28808156627970205,
        "bleu": 0.32271,
        "bleurt": -1.10539,
        "nubia": {
            "semantic_relation": 1.05925,
            "contradiction": 50.96298,
            "irrelevancy": 38.41476,
            "logical_agreement": 10.62226,
            "grammar_ref": 6.81129,
            "grammar_hyp": 5.60226,
            "nubia_score": 0.0148
        },
        "meteor": 0.0500369749526553,
        "bertscore": {
            "precision": 0.77103,
            "recall": 0.83398,
            "f1": 0.80118
        }
    },
    "totto_test_contrast_challenge_gender-female": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 300,
        "msttr-100": 0.68741,
        "msttr-100_nopunct": 0.73872,
        "total_length": 5481,
        "mean_pred_length": 18.27,
        "std_pred_length": 7.583563366474453,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 65,
        "distinct-1": 0.35340266374749135,
        "vocab_size-1": 1937,
        "unique-1": 1543,
        "entropy-1": 8.528629496384143,
        "distinct-2": 0.7243775332947308,
        "vocab_size-2": 3753,
        "unique-2": 3326,
        "entropy-2": 11.33432504746929,
        "cond_entropy-2": 2.5539983411055975,
        "distinct-3": 0.8936693300553166,
        "vocab_size-3": 4362,
        "unique-3": 4120,
        "entropy-3": 11.95879996867924,
        "cond_entropy-3": 0.6256437660852251,
        "total_length-nopunct": 4776,
        "mean_pred_length-nopunct": 15.92,
        "std_pred_length-nopunct": 6.494633682253887,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.40326633165829145,
        "vocab_size-1-nopunct": 1926,
        "unique-1-nopunct": 1540,
        "entropy-1-nopunct": 8.870585905276066,
        "distinct-2-nopunct": 0.7464253798033958,
        "vocab_size-2-nopunct": 3341,
        "unique-2-nopunct": 3017,
        "entropy-2-nopunct": 11.173937522790718,
        "cond_entropy-2-nopunct": 2.439921774906624,
        "distinct-3-nopunct": 0.9092432950191571,
        "vocab_size-3-nopunct": 3797,
        "unique-3-nopunct": 3622,
        "entropy-3-nopunct": 11.777107328523357,
        "cond_entropy-3-nopunct": 0.6532120505259065,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79633,
            "recall": 0.76962,
            "fmeasure": 0.77448
        },
        "rouge2": {
            "precision": 0.547,
            "recall": 0.53066,
            "fmeasure": 0.53284
        },
        "rougeL": {
            "precision": 0.67362,
            "recall": 0.65418,
            "fmeasure": 0.65655
        },
        "rougeLsum": {
            "precision": 0.67362,
            "recall": 0.65418,
            "fmeasure": 0.65655
        },
        "local_recall": {
            "1": 0.21679909194097616,
            "2": 0.365819209039548,
            "3": 0.8025460455037919
        },
        "nist": 8.723432872215174,
        "bleu": 46.0382,
        "bleurt": 0.33968,
        "nubia": {
            "semantic_relation": 4.44227,
            "contradiction": 5.20463,
            "irrelevancy": 24.8034,
            "logical_agreement": 69.99196,
            "grammar_ref": 4.91577,
            "grammar_hyp": 4.89668,
            "nubia_score": 0.7863
        },
        "meteor": 0.40594899596345646,
        "bertscore": {
            "precision": 0.93783,
            "recall": 0.93534,
            "f1": 0.93522
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_35": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 103,
        "msttr-100": 0.71471,
        "msttr-100_nopunct": 0.756,
        "total_length": 1754,
        "mean_pred_length": 17.02912621359223,
        "std_pred_length": 6.031400537220256,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 34,
        "distinct-1": 0.44811858608893956,
        "vocab_size-1": 786,
        "unique-1": 614,
        "entropy-1": 8.151592552725614,
        "distinct-2": 0.8176862507571169,
        "vocab_size-2": 1350,
        "unique-2": 1237,
        "entropy-2": 10.11918170398552,
        "cond_entropy-2": 1.7141966710124559,
        "distinct-3": 0.9063307493540051,
        "vocab_size-3": 1403,
        "unique-3": 1346,
        "entropy-3": 10.318627171867275,
        "cond_entropy-3": 0.19146449124689754,
        "total_length-nopunct": 1541,
        "mean_pred_length-nopunct": 14.96116504854369,
        "std_pred_length-nopunct": 5.822491259581641,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.5048669695003245,
        "vocab_size-1-nopunct": 778,
        "unique-1-nopunct": 611,
        "entropy-1-nopunct": 8.396536772615928,
        "distinct-2-nopunct": 0.8261474269819193,
        "vocab_size-2-nopunct": 1188,
        "unique-2-nopunct": 1106,
        "entropy-2-nopunct": 9.92436683269012,
        "cond_entropy-2-nopunct": 1.63302249261486,
        "distinct-3-nopunct": 0.90187265917603,
        "vocab_size-3-nopunct": 1204,
        "unique-3-nopunct": 1159,
        "entropy-3-nopunct": 10.082880876419889,
        "cond_entropy-3-nopunct": 0.1933377655696028,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77749,
            "recall": 0.76098,
            "fmeasure": 0.75733
        },
        "rouge2": {
            "precision": 0.5606,
            "recall": 0.54969,
            "fmeasure": 0.54642
        },
        "rougeL": {
            "precision": 0.68288,
            "recall": 0.671,
            "fmeasure": 0.6659
        },
        "rougeLsum": {
            "precision": 0.68288,
            "recall": 0.671,
            "fmeasure": 0.6659
        },
        "local_recall": {
            "1": 0.21646341463414634,
            "2": 0.494949494949495,
            "3": 0.802491103202847
        },
        "nist": 7.995624422870114,
        "bleu": 52.24776,
        "bleurt": 0.3195,
        "nubia": {
            "semantic_relation": 4.29454,
            "contradiction": 6.39196,
            "irrelevancy": 27.71448,
            "logical_agreement": 65.89356,
            "grammar_ref": 4.60982,
            "grammar_hyp": 4.63473,
            "nubia_score": 0.75325
        },
        "meteor": 0.4198828861389127,
        "bertscore": {
            "precision": 0.93869,
            "recall": 0.93441,
            "f1": 0.93523
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 460,
        "msttr-100": 0.43012,
        "msttr-100_nopunct": 0.42155,
        "total_length": 25230,
        "mean_pred_length": 54.84782608695652,
        "std_pred_length": 15.359131813247478,
        "median_pred_length": 58.0,
        "min_pred_length": 11,
        "max_pred_length": 84,
        "distinct-1": 0.0641696393182719,
        "vocab_size-1": 1619,
        "unique-1": 575,
        "entropy-1": 5.751742508514609,
        "distinct-2": 0.17924909164311667,
        "vocab_size-2": 4440,
        "unique-2": 2053,
        "entropy-2": 10.031129867678988,
        "cond_entropy-2": 4.285263928269105,
        "distinct-3": 0.34076511723570546,
        "vocab_size-3": 8284,
        "unique-3": 4685,
        "entropy-3": 11.807626531998322,
        "cond_entropy-3": 1.80282693539626,
        "total_length-nopunct": 23373,
        "mean_pred_length-nopunct": 50.81086956521739,
        "std_pred_length-nopunct": 14.846354087069288,
        "median_pred_length-nopunct": 53.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 80,
        "distinct-1-nopunct": 0.06888289907157831,
        "vocab_size-1-nopunct": 1610,
        "unique-1-nopunct": 574,
        "entropy-1-nopunct": 5.645378669005436,
        "distinct-2-nopunct": 0.18120717496617642,
        "vocab_size-2-nopunct": 4152,
        "unique-2-nopunct": 1933,
        "entropy-2-nopunct": 9.923354258814381,
        "cond_entropy-2-nopunct": 4.334455667985935,
        "distinct-3-nopunct": 0.34039994655502603,
        "vocab_size-3-nopunct": 7643,
        "unique-3-nopunct": 4402,
        "entropy-3-nopunct": 11.653055767279223,
        "cond_entropy-3-nopunct": 1.7577620201477788,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.32317,
            "recall": 0.31318,
            "fmeasure": 0.31397
        },
        "rouge2": {
            "precision": 0.11717,
            "recall": 0.11437,
            "fmeasure": 0.11422
        },
        "rougeL": {
            "precision": 0.31438,
            "recall": 0.30578,
            "fmeasure": 0.30574
        },
        "rougeLsum": {
            "precision": 0.31438,
            "recall": 0.30578,
            "fmeasure": 0.30574
        },
        "local_recall": {
            "1": 0.08219749652294854,
            "2": 0.15874339727550738,
            "3": 0.2107157137145142,
            "4": 0.0,
            "5": 0.5,
            "6": 0.0,
            "7": 0.0
        },
        "nist": 0.8707889591907871,
        "bleu": 1.00262,
        "bleurt": -0.52349,
        "nubia": {
            "semantic_relation": 3.32396,
            "contradiction": 32.98326,
            "irrelevancy": 17.13871,
            "logical_agreement": 49.87803,
            "grammar_ref": 2.52111,
            "grammar_hyp": 2.41379,
            "nubia_score": 0.13823
        },
        "meteor": 0.10490634060846445,
        "bertscore": {
            "precision": 0.85249,
            "recall": 0.86648,
            "f1": 0.8589
        }
    },
    "schema_guided_dialog_challenge_test_bfp02": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_challenge_test_bfp02",
        "N": 500,
        "msttr-100": 0.68968,
        "msttr-100_nopunct": 0.71564,
        "total_length": 6338,
        "mean_pred_length": 12.676,
        "std_pred_length": 7.296233548893565,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 42,
        "distinct-1": 0.15588513726727674,
        "vocab_size-1": 988,
        "unique-1": 550,
        "entropy-1": 7.840069732710471,
        "distinct-2": 0.4775608084960603,
        "vocab_size-2": 2788,
        "unique-2": 1925,
        "entropy-2": 10.663465105379338,
        "cond_entropy-2": 2.5877142469001857,
        "distinct-3": 0.6910828025477707,
        "vocab_size-3": 3689,
        "unique-3": 2995,
        "entropy-3": 11.46145828513111,
        "cond_entropy-3": 0.8148428556536184,
        "total_length-nopunct": 5575,
        "mean_pred_length-nopunct": 11.15,
        "std_pred_length-nopunct": 6.703394662407995,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.1747085201793722,
        "vocab_size-1-nopunct": 974,
        "unique-1-nopunct": 545,
        "entropy-1-nopunct": 8.015662890710411,
        "distinct-2-nopunct": 0.4920197044334975,
        "vocab_size-2-nopunct": 2497,
        "unique-2-nopunct": 1756,
        "entropy-2-nopunct": 10.491390799226672,
        "cond_entropy-2-nopunct": 2.596461519028374,
        "distinct-3-nopunct": 0.7049825174825175,
        "vocab_size-3-nopunct": 3226,
        "unique-3-nopunct": 2658,
        "entropy-3-nopunct": 11.269842055980185,
        "cond_entropy-3-nopunct": 0.8120319742019485,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp02.json",
        "rouge1": {
            "precision": 0.58405,
            "recall": 0.54607,
            "fmeasure": 0.5533
        },
        "rouge2": {
            "precision": 0.3681,
            "recall": 0.34467,
            "fmeasure": 0.3483
        },
        "rougeL": {
            "precision": 0.52302,
            "recall": 0.48942,
            "fmeasure": 0.49583
        },
        "rougeLsum": {
            "precision": 0.52302,
            "recall": 0.48942,
            "fmeasure": 0.49583
        },
        "local_recall": {
            "1": 0.5579571204462263
        },
        "nist": 6.168732851019268,
        "bleu": 32.0406,
        "bleurt": -0.08836,
        "nubia": {
            "semantic_relation": 3.62065,
            "contradiction": 6.14698,
            "irrelevancy": 22.49337,
            "logical_agreement": 71.35966,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.69593,
            "nubia_score": 0.63855
        },
        "meteor": 0.3121533190505653,
        "bertscore": {
            "precision": 0.87296,
            "recall": 0.86078,
            "f1": 0.86632
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_10": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 162,
        "msttr-100": 0.71458,
        "msttr-100_nopunct": 0.769,
        "total_length": 2404,
        "mean_pred_length": 14.839506172839506,
        "std_pred_length": 6.390496010663615,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 39,
        "distinct-1": 0.34900166389351084,
        "vocab_size-1": 839,
        "unique-1": 616,
        "entropy-1": 8.052236465811692,
        "distinct-2": 0.7502230151650312,
        "vocab_size-2": 1682,
        "unique-2": 1475,
        "entropy-2": 10.375931017166057,
        "cond_entropy-2": 2.0192521344597534,
        "distinct-3": 0.9004807692307693,
        "vocab_size-3": 1873,
        "unique-3": 1773,
        "entropy-3": 10.755578427505075,
        "cond_entropy-3": 0.3747576132270902,
        "total_length-nopunct": 2097,
        "mean_pred_length-nopunct": 12.944444444444445,
        "std_pred_length-nopunct": 5.635261559103196,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.39675727229375296,
        "vocab_size-1-nopunct": 832,
        "unique-1-nopunct": 615,
        "entropy-1-nopunct": 8.366902905595444,
        "distinct-2-nopunct": 0.772093023255814,
        "vocab_size-2-nopunct": 1494,
        "unique-2-nopunct": 1334,
        "entropy-2-nopunct": 10.217256087080711,
        "cond_entropy-2-nopunct": 1.9513227362559944,
        "distinct-3-nopunct": 0.9091934574168077,
        "vocab_size-3-nopunct": 1612,
        "unique-3-nopunct": 1539,
        "entropy-3-nopunct": 10.54435606146493,
        "cond_entropy-3-nopunct": 0.35104821536965486,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75315,
            "recall": 0.72735,
            "fmeasure": 0.7276
        },
        "rouge2": {
            "precision": 0.49744,
            "recall": 0.47853,
            "fmeasure": 0.47824
        },
        "rougeL": {
            "precision": 0.63686,
            "recall": 0.61384,
            "fmeasure": 0.61403
        },
        "rougeLsum": {
            "precision": 0.63686,
            "recall": 0.61384,
            "fmeasure": 0.61403
        },
        "local_recall": {
            "1": 0.20642201834862386,
            "2": 0.3914027149321267,
            "3": 0.7666878575969485
        },
        "nist": 7.685526706591661,
        "bleu": 43.06341,
        "bleurt": 0.29054,
        "nubia": {
            "semantic_relation": 4.22207,
            "contradiction": 7.71369,
            "irrelevancy": 27.37892,
            "logical_agreement": 64.90738,
            "grammar_ref": 4.55751,
            "grammar_hyp": 4.56918,
            "nubia_score": 0.75002
        },
        "meteor": 0.39156966803418547,
        "bertscore": {
            "precision": 0.92874,
            "recall": 0.92343,
            "f1": 0.92366
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_11": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.615,
        "msttr-100_nopunct": 0.664,
        "total_length": 667,
        "mean_pred_length": 18.52777777777778,
        "std_pred_length": 8.48032399509172,
        "median_pred_length": 16.5,
        "min_pred_length": 9,
        "max_pred_length": 49,
        "distinct-1": 0.4017991004497751,
        "vocab_size-1": 268,
        "unique-1": 211,
        "entropy-1": 6.826413507824512,
        "distinct-2": 0.7464342313787639,
        "vocab_size-2": 471,
        "unique-2": 400,
        "entropy-2": 8.570634893864204,
        "cond_entropy-2": 1.5950412908084197,
        "distinct-3": 0.8840336134453781,
        "vocab_size-3": 526,
        "unique-3": 479,
        "entropy-3": 8.941538117082944,
        "cond_entropy-3": 0.4004093061398646,
        "total_length-nopunct": 551,
        "mean_pred_length-nopunct": 15.305555555555555,
        "std_pred_length-nopunct": 6.781590457687818,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.47731397459165154,
        "vocab_size-1-nopunct": 263,
        "unique-1-nopunct": 211,
        "entropy-1-nopunct": 6.997304111124427,
        "distinct-2-nopunct": 0.7883495145631068,
        "vocab_size-2-nopunct": 406,
        "unique-2-nopunct": 348,
        "entropy-2-nopunct": 8.46508933888385,
        "cond_entropy-2-nopunct": 1.5563732708011186,
        "distinct-3-nopunct": 0.9081419624217119,
        "vocab_size-3-nopunct": 435,
        "unique-3-nopunct": 401,
        "entropy-3-nopunct": 8.69955135934593,
        "cond_entropy-3-nopunct": 0.2443844824091984,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75661,
            "recall": 0.76562,
            "fmeasure": 0.75238
        },
        "rouge2": {
            "precision": 0.56094,
            "recall": 0.5758,
            "fmeasure": 0.56097
        },
        "rougeL": {
            "precision": 0.67269,
            "recall": 0.6872,
            "fmeasure": 0.67154
        },
        "rougeLsum": {
            "precision": 0.67269,
            "recall": 0.6872,
            "fmeasure": 0.67154
        },
        "local_recall": {
            "1": 0.3157894736842105,
            "2": 0.5377358490566038,
            "3": 0.7448680351906158
        },
        "nist": 6.255812268469644,
        "bleu": 45.65971,
        "bleurt": 0.31192,
        "nubia": {
            "semantic_relation": 3.99656,
            "contradiction": 14.94599,
            "irrelevancy": 25.36801,
            "logical_agreement": 59.686,
            "grammar_ref": 3.9304,
            "grammar_hyp": 3.93091,
            "nubia_score": 0.71785
        },
        "meteor": 0.4194097889465601,
        "bertscore": {
            "precision": 0.92937,
            "recall": 0.93038,
            "f1": 0.92808
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-both_seen": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 1075,
        "msttr-100": 0.46108,
        "msttr-100_nopunct": 0.45714,
        "total_length": 48903,
        "mean_pred_length": 45.49116279069767,
        "std_pred_length": 19.5569214785376,
        "median_pred_length": 45.0,
        "min_pred_length": 6,
        "max_pred_length": 85,
        "distinct-1": 0.0511216080813038,
        "vocab_size-1": 2500,
        "unique-1": 876,
        "entropy-1": 5.982704119578414,
        "distinct-2": 0.15225390984360626,
        "vocab_size-2": 7282,
        "unique-2": 3446,
        "entropy-2": 10.407864660053441,
        "cond_entropy-2": 4.421481326514748,
        "distinct-3": 0.2940559964066477,
        "vocab_size-3": 13748,
        "unique-3": 7776,
        "entropy-3": 12.279469120347093,
        "cond_entropy-3": 1.911465132846389,
        "total_length-nopunct": 45119,
        "mean_pred_length-nopunct": 41.971162790697676,
        "std_pred_length-nopunct": 18.529024523992312,
        "median_pred_length-nopunct": 41.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 80,
        "distinct-1-nopunct": 0.055187393337618296,
        "vocab_size-1-nopunct": 2490,
        "unique-1-nopunct": 875,
        "entropy-1-nopunct": 5.8944147846159485,
        "distinct-2-nopunct": 0.15298338025610753,
        "vocab_size-2-nopunct": 6738,
        "unique-2-nopunct": 3201,
        "entropy-2-nopunct": 10.284489010799275,
        "cond_entropy-2-nopunct": 4.475398973014096,
        "distinct-3-nopunct": 0.29537573599571787,
        "vocab_size-3-nopunct": 12692,
        "unique-3-nopunct": 7321,
        "entropy-3-nopunct": 12.116952195672702,
        "cond_entropy-3-nopunct": 1.870678028290563,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.42261,
            "recall": 0.40755,
            "fmeasure": 0.40825
        },
        "rouge2": {
            "precision": 0.20902,
            "recall": 0.20267,
            "fmeasure": 0.20252
        },
        "rougeL": {
            "precision": 0.39916,
            "recall": 0.38615,
            "fmeasure": 0.38599
        },
        "rougeLsum": {
            "precision": 0.39916,
            "recall": 0.38615,
            "fmeasure": 0.38599
        },
        "local_recall": {
            "1": 0.08964417711428364,
            "2": 0.18334499650104968,
            "3": 0.25859434682964094,
            "4": 0.19480519480519481,
            "5": 0.2702702702702703,
            "6": 0.15384615384615385,
            "7": 0.2222222222222222
        },
        "nist": 1.1240969681809088,
        "bleu": 1.97646,
        "bleurt": -0.48359,
        "nubia": {
            "semantic_relation": 3.31533,
            "contradiction": 33.64713,
            "irrelevancy": 17.15519,
            "logical_agreement": 49.19768,
            "grammar_ref": 2.64396,
            "grammar_hyp": 2.62254,
            "nubia_score": 0.15561
        },
        "meteor": 0.1238937206903203,
        "bertscore": {
            "precision": 0.86051,
            "recall": 0.87239,
            "f1": 0.86591
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform": {
        "predictions_file": "T5-large (Baseline)/cs_restaurants_test",
        "N": 609,
        "msttr-100": 0.51982,
        "msttr-100_nopunct": 0.53363,
        "total_length": 11196,
        "mean_pred_length": 18.38423645320197,
        "std_pred_length": 6.597766536303857,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 55,
        "distinct-1": 0.06073597713469096,
        "vocab_size-1": 680,
        "unique-1": 248,
        "entropy-1": 6.265376166865326,
        "distinct-2": 0.18314914517804856,
        "vocab_size-2": 1939,
        "unique-2": 968,
        "entropy-2": 9.165806452256996,
        "cond_entropy-2": 2.794536222164549,
        "distinct-3": 0.30857887352174784,
        "vocab_size-3": 3079,
        "unique-3": 1948,
        "entropy-3": 10.069251860724492,
        "cond_entropy-3": 0.9898594737129297,
        "total_length-nopunct": 10273,
        "mean_pred_length-nopunct": 16.86863711001642,
        "std_pred_length-nopunct": 6.302121384019703,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 53,
        "distinct-1-nopunct": 0.06580356273727246,
        "vocab_size-1-nopunct": 676,
        "unique-1-nopunct": 247,
        "entropy-1-nopunct": 6.297998808663708,
        "distinct-2-nopunct": 0.1824296357615894,
        "vocab_size-2-nopunct": 1763,
        "unique-2-nopunct": 922,
        "entropy-2-nopunct": 8.993735079167388,
        "cond_entropy-2-nopunct": 2.8972246913276463,
        "distinct-3-nopunct": 0.3093318608503589,
        "vocab_size-3-nopunct": 2801,
        "unique-3-nopunct": 1802,
        "entropy-3-nopunct": 9.910927194715779,
        "cond_entropy-3-nopunct": 1.0289581324318557,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.46632,
            "recall": 0.52823,
            "fmeasure": 0.47383
        },
        "rouge2": {
            "precision": 0.24942,
            "recall": 0.28381,
            "fmeasure": 0.25252
        },
        "rougeL": {
            "precision": 0.41796,
            "recall": 0.47117,
            "fmeasure": 0.42388
        },
        "rougeLsum": {
            "precision": 0.41796,
            "recall": 0.47117,
            "fmeasure": 0.42388
        },
        "local_recall": {
            "1": 0.3252263447541275
        },
        "nist": 1.6410046367202982,
        "bleu": 4.18778,
        "bleurt": -0.6749,
        "nubia": {
            "semantic_relation": 3.11935,
            "contradiction": 29.26895,
            "irrelevancy": 26.19057,
            "logical_agreement": 44.54047,
            "grammar_ref": 6.96179,
            "grammar_hyp": 5.96884,
            "nubia_score": 0.35579
        },
        "meteor": 0.1487583106461311,
        "bertscore": {
            "precision": 0.82324,
            "recall": 0.85658,
            "f1": 0.83924
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?confirm": {
        "predictions_file": "T5-large (Baseline)/cs_restaurants_test",
        "N": 22,
        "msttr-100": 0.27,
        "msttr-100_nopunct": 0.28333,
        "total_length": 349,
        "mean_pred_length": 15.863636363636363,
        "std_pred_length": 4.0485177371191785,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 26,
        "distinct-1": 0.09455587392550144,
        "vocab_size-1": 33,
        "unique-1": 0,
        "entropy-1": 4.313189203646648,
        "distinct-2": 0.14984709480122324,
        "vocab_size-2": 49,
        "unique-2": 0,
        "entropy-2": 5.198271832101382,
        "cond_entropy-2": 0.8631810164864364,
        "distinct-3": 0.16065573770491803,
        "vocab_size-3": 49,
        "unique-3": 0,
        "entropy-3": 5.2244522428652935,
        "cond_entropy-3": 0.05937069712319387,
        "total_length-nopunct": 304,
        "mean_pred_length-nopunct": 13.818181818181818,
        "std_pred_length-nopunct": 3.4855071841237844,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.10197368421052631,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 4.1670735881963585,
        "distinct-2-nopunct": 0.14893617021276595,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 4.991858843284792,
        "cond_entropy-2-nopunct": 0.8247106586247708,
        "distinct-3-nopunct": 0.16153846153846155,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 5.02386709167138,
        "cond_entropy-3-nopunct": 0.060166581061925184,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.45833,
            "recall": 0.49517,
            "fmeasure": 0.4717
        },
        "rouge2": {
            "precision": 0.30895,
            "recall": 0.32753,
            "fmeasure": 0.31499
        },
        "rougeL": {
            "precision": 0.42955,
            "recall": 0.46599,
            "fmeasure": 0.44298
        },
        "rougeLsum": {
            "precision": 0.42955,
            "recall": 0.46599,
            "fmeasure": 0.44298
        },
        "local_recall": {
            "1": 0.26285714285714284
        },
        "nist": 1.0535990205943764,
        "bleu": 5.11295,
        "bleurt": -0.5535,
        "nubia": {
            "semantic_relation": 2.59486,
            "contradiction": 32.8941,
            "irrelevancy": 26.23153,
            "logical_agreement": 40.87437,
            "grammar_ref": 6.09546,
            "grammar_hyp": 5.67022,
            "nubia_score": 0.34968
        },
        "meteor": 0.13859503489720829,
        "bertscore": {
            "precision": 0.85295,
            "recall": 0.88075,
            "f1": 0.86654
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_36": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 131,
        "msttr-100": 0.73048,
        "msttr-100_nopunct": 0.77667,
        "total_length": 2183,
        "mean_pred_length": 16.66412213740458,
        "std_pred_length": 7.634404536458874,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 49,
        "distinct-1": 0.4521300961978928,
        "vocab_size-1": 987,
        "unique-1": 781,
        "entropy-1": 8.385598152254637,
        "distinct-2": 0.8572124756335283,
        "vocab_size-2": 1759,
        "unique-2": 1621,
        "entropy-2": 10.594737259300198,
        "cond_entropy-2": 1.930822142361432,
        "distinct-3": 0.9604372722540343,
        "vocab_size-3": 1845,
        "unique-3": 1795,
        "entropy-3": 10.815005027518145,
        "cond_entropy-3": 0.21124340515580523,
        "total_length-nopunct": 1899,
        "mean_pred_length-nopunct": 14.49618320610687,
        "std_pred_length-nopunct": 6.83320814286287,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.5134281200631912,
        "vocab_size-1-nopunct": 975,
        "unique-1-nopunct": 777,
        "entropy-1-nopunct": 8.685667200182444,
        "distinct-2-nopunct": 0.877262443438914,
        "vocab_size-2-nopunct": 1551,
        "unique-2-nopunct": 1448,
        "entropy-2-nopunct": 10.429350323488421,
        "cond_entropy-2-nopunct": 1.8367972413779914,
        "distinct-3-nopunct": 0.9688454489920586,
        "vocab_size-3-nopunct": 1586,
        "unique-3-nopunct": 1549,
        "entropy-3-nopunct": 10.607175136701619,
        "cond_entropy-3-nopunct": 0.20213783575610467,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7575,
            "recall": 0.70379,
            "fmeasure": 0.71554
        },
        "rouge2": {
            "precision": 0.51843,
            "recall": 0.47809,
            "fmeasure": 0.48692
        },
        "rougeL": {
            "precision": 0.64964,
            "recall": 0.60401,
            "fmeasure": 0.61417
        },
        "rougeLsum": {
            "precision": 0.64964,
            "recall": 0.60401,
            "fmeasure": 0.61417
        },
        "local_recall": {
            "1": 0.20424403183023873,
            "2": 0.4423076923076923,
            "3": 0.7314165497896213
        },
        "nist": 7.375761830071001,
        "bleu": 40.94426,
        "bleurt": 0.23362,
        "nubia": {
            "semantic_relation": 4.17307,
            "contradiction": 9.02056,
            "irrelevancy": 28.27565,
            "logical_agreement": 62.70379,
            "grammar_ref": 4.61481,
            "grammar_hyp": 4.68862,
            "nubia_score": 0.70602
        },
        "meteor": 0.3649322365441522,
        "bertscore": {
            "precision": 0.92415,
            "recall": 0.91662,
            "f1": 0.91899
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 213,
        "msttr-100": 0.64013,
        "msttr-100_nopunct": 0.67574,
        "total_length": 7709,
        "mean_pred_length": 36.1924882629108,
        "std_pred_length": 9.514779208474176,
        "median_pred_length": 36.0,
        "min_pred_length": 14,
        "max_pred_length": 71,
        "distinct-1": 0.15060319107536646,
        "vocab_size-1": 1161,
        "unique-1": 461,
        "entropy-1": 7.931666447213962,
        "distinct-2": 0.41915688367129134,
        "vocab_size-2": 3142,
        "unique-2": 1895,
        "entropy-2": 10.861067800733384,
        "cond_entropy-2": 2.8200296847452115,
        "distinct-3": 0.6177399423314568,
        "vocab_size-3": 4499,
        "unique-3": 3325,
        "entropy-3": 11.74408247471598,
        "cond_entropy-3": 0.9097525356111611,
        "total_length-nopunct": 6844,
        "mean_pred_length-nopunct": 32.13145539906103,
        "std_pred_length-nopunct": 8.721652740181257,
        "median_pred_length-nopunct": 32.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 65,
        "distinct-1-nopunct": 0.16832261835184104,
        "vocab_size-1-nopunct": 1152,
        "unique-1-nopunct": 461,
        "entropy-1-nopunct": 8.18542208930492,
        "distinct-2-nopunct": 0.43779218820690696,
        "vocab_size-2-nopunct": 2903,
        "unique-2-nopunct": 1805,
        "entropy-2-nopunct": 10.79952142101503,
        "cond_entropy-2-nopunct": 2.696685248420937,
        "distinct-3-nopunct": 0.6339981302586476,
        "vocab_size-3-nopunct": 4069,
        "unique-3-nopunct": 3079,
        "entropy-3-nopunct": 11.61175065368915,
        "cond_entropy-3-nopunct": 0.8346980588529137,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.66719,
            "recall": 0.64985,
            "fmeasure": 0.65171
        },
        "rouge2": {
            "precision": 0.36652,
            "recall": 0.35588,
            "fmeasure": 0.35698
        },
        "rougeL": {
            "precision": 0.46439,
            "recall": 0.44879,
            "fmeasure": 0.45096
        },
        "rougeLsum": {
            "precision": 0.46439,
            "recall": 0.44879,
            "fmeasure": 0.45096
        },
        "local_recall": {
            "1": 0.21282495667244367,
            "2": 0.4788732394366197,
            "3": 0.79158258864226
        },
        "nist": 7.482384215042702,
        "bleu": 38.25771,
        "bleurt": -0.11236,
        "nubia": {
            "semantic_relation": 3.88016,
            "contradiction": 22.66513,
            "irrelevancy": 13.65364,
            "logical_agreement": 63.68124,
            "grammar_ref": 4.14495,
            "grammar_hyp": 4.26936,
            "nubia_score": 0.62959
        },
        "meteor": 0.3257590435353137,
        "bertscore": {
            "precision": 0.88435,
            "recall": 0.88529,
            "f1": 0.88364
        }
    },
    "cs_restaurants_challenge_test_scramble_parent": {
        "predictions_file": "T5-large (Baseline)/cs_restaurants_test",
        "N": 500,
        "msttr-100": 0.53946,
        "msttr-100_nopunct": 0.54602,
        "total_length": 9244,
        "mean_pred_length": 18.488,
        "std_pred_length": 6.025434092245969,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 39,
        "distinct-1": 0.06328429251406317,
        "vocab_size-1": 585,
        "unique-1": 218,
        "entropy-1": 6.267923986423061,
        "distinct-2": 0.18424062214089662,
        "vocab_size-2": 1611,
        "unique-2": 848,
        "entropy-2": 8.879995863055038,
        "cond_entropy-2": 2.540929794004086,
        "distinct-3": 0.29342552159146046,
        "vocab_size-3": 2419,
        "unique-3": 1551,
        "entropy-3": 9.568921867188223,
        "cond_entropy-3": 0.7422083507978757,
        "total_length-nopunct": 8341,
        "mean_pred_length-nopunct": 16.682,
        "std_pred_length-nopunct": 5.725458584253317,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.06965591655676777,
        "vocab_size-1-nopunct": 581,
        "unique-1-nopunct": 218,
        "entropy-1-nopunct": 6.2699586443571595,
        "distinct-2-nopunct": 0.1867108787144497,
        "vocab_size-2-nopunct": 1464,
        "unique-2-nopunct": 792,
        "entropy-2-nopunct": 8.73399543072716,
        "cond_entropy-2-nopunct": 2.6106673495007535,
        "distinct-3-nopunct": 0.30064023974935294,
        "vocab_size-3-nopunct": 2207,
        "unique-3-nopunct": 1444,
        "entropy-3-nopunct": 9.445832921392217,
        "cond_entropy-3-nopunct": 0.770422353490472,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.39868,
            "recall": 0.45304,
            "fmeasure": 0.4066
        },
        "rouge2": {
            "precision": 0.21794,
            "recall": 0.24881,
            "fmeasure": 0.22199
        },
        "rougeL": {
            "precision": 0.35521,
            "recall": 0.40489,
            "fmeasure": 0.36283
        },
        "rougeLsum": {
            "precision": 0.35521,
            "recall": 0.40489,
            "fmeasure": 0.36283
        },
        "local_recall": {
            "1": 0.29117167481947354
        },
        "nist": 1.4382726638316312,
        "bleu": 3.45864,
        "bleurt": -0.7531,
        "nubia": {
            "semantic_relation": 2.70654,
            "contradiction": 33.73713,
            "irrelevancy": 28.15432,
            "logical_agreement": 38.10855,
            "grammar_ref": 6.87434,
            "grammar_hyp": 5.88316,
            "nubia_score": 0.29184
        },
        "meteor": 0.13450157023713796,
        "bertscore": {
            "precision": 0.8154,
            "recall": 0.85196,
            "f1": 0.83297
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 64,
        "mean_pred_length": 16.0,
        "std_pred_length": 2.1213203435596424,
        "median_pred_length": 15.5,
        "min_pred_length": 14,
        "max_pred_length": 19,
        "distinct-1": 0.484375,
        "vocab_size-1": 31,
        "unique-1": 28,
        "entropy-1": 3.5436450333085068,
        "distinct-2": 0.95,
        "vocab_size-2": 57,
        "unique-2": 55,
        "entropy-2": 5.794309137239126,
        "cond_entropy-2": 2.2810877683767212,
        "distinct-3": 1.0,
        "vocab_size-3": 56,
        "unique-3": 56,
        "entropy-3": 5.807354922057609,
        "cond_entropy-3": 0.021087317559147598,
        "total_length-nopunct": 59,
        "mean_pred_length-nopunct": 14.75,
        "std_pred_length-nopunct": 2.384848003542364,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.4915254237288136,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 3.353715627865983,
        "distinct-2-nopunct": 0.9272727272727272,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.599541531706474,
        "cond_entropy-2-nopunct": 2.429747898131101,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 51,
        "unique-3-nopunct": 51,
        "entropy-3-nopunct": 5.6724253419715005,
        "cond_entropy-3-nopunct": 0.08714405981938499,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.125,
            "recall": 0.08333,
            "fmeasure": 0.1
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.125,
            "recall": 0.08333,
            "fmeasure": 0.1
        },
        "rougeLsum": {
            "precision": 0.125,
            "recall": 0.08333,
            "fmeasure": 0.1
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.0
        },
        "nist": 0.19558018855906042,
        "bleu": 0.86465,
        "bleurt": -0.43688,
        "nubia": {
            "semantic_relation": 3.05037,
            "contradiction": 55.74249,
            "irrelevancy": 13.33216,
            "logical_agreement": 30.92535,
            "grammar_ref": 3.0388,
            "grammar_hyp": 2.87098,
            "nubia_score": 0.21216
        },
        "meteor": 0.03947368421052632,
        "bertscore": {
            "precision": 0.85098,
            "recall": 0.85842,
            "f1": 0.85434
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 19,
        "msttr-100": 0.46,
        "msttr-100_nopunct": 0.456,
        "total_length": 608,
        "mean_pred_length": 32.0,
        "std_pred_length": 17.435595774162696,
        "median_pred_length": 30.0,
        "min_pred_length": 11,
        "max_pred_length": 73,
        "distinct-1": 0.2631578947368421,
        "vocab_size-1": 160,
        "unique-1": 97,
        "entropy-1": 5.035607454698842,
        "distinct-2": 0.5755517826825127,
        "vocab_size-2": 339,
        "unique-2": 236,
        "entropy-2": 7.985610586098514,
        "cond_entropy-2": 2.943966916968763,
        "distinct-3": 0.7719298245614035,
        "vocab_size-3": 440,
        "unique-3": 356,
        "entropy-3": 8.618353553021755,
        "cond_entropy-3": 0.6333725529139848,
        "total_length-nopunct": 552,
        "mean_pred_length-nopunct": 29.05263157894737,
        "std_pred_length-nopunct": 16.278735513451206,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 67,
        "distinct-1-nopunct": 0.2807971014492754,
        "vocab_size-1-nopunct": 155,
        "unique-1-nopunct": 97,
        "entropy-1-nopunct": 4.851639055378654,
        "distinct-2-nopunct": 0.5797373358348968,
        "vocab_size-2-nopunct": 309,
        "unique-2-nopunct": 215,
        "entropy-2-nopunct": 7.850990243558758,
        "cond_entropy-2-nopunct": 3.0630063031056203,
        "distinct-3-nopunct": 0.7801556420233463,
        "vocab_size-3-nopunct": 401,
        "unique-3-nopunct": 328,
        "entropy-3-nopunct": 8.485672269185443,
        "cond_entropy-3-nopunct": 0.6684331260237013,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.32895,
            "recall": 0.30785,
            "fmeasure": 0.31571
        },
        "rouge2": {
            "precision": 0.22661,
            "recall": 0.21959,
            "fmeasure": 0.22094
        },
        "rougeL": {
            "precision": 0.30639,
            "recall": 0.29282,
            "fmeasure": 0.29689
        },
        "rougeLsum": {
            "precision": 0.30639,
            "recall": 0.29282,
            "fmeasure": 0.29689
        },
        "local_recall": {
            "1": 0.07975460122699386,
            "2": 0.1875,
            "3": 0.30434782608695654
        },
        "nist": 1.1445683548637557,
        "bleu": 3.04181,
        "bleurt": -0.51419,
        "nubia": {
            "semantic_relation": 3.0421,
            "contradiction": 36.48982,
            "irrelevancy": 16.28379,
            "logical_agreement": 47.22639,
            "grammar_ref": 2.97301,
            "grammar_hyp": 2.8939,
            "nubia_score": 0.15717
        },
        "meteor": 0.17236274149411912,
        "bertscore": {
            "precision": 0.84973,
            "recall": 0.85859,
            "f1": 0.85351
        }
    },
    "totto_test_contrast_challenge_ethnicity-african_american": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 128,
        "msttr-100": 0.708,
        "msttr-100_nopunct": 0.75235,
        "total_length": 2043,
        "mean_pred_length": 15.9609375,
        "std_pred_length": 6.185166660737102,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 42,
        "distinct-1": 0.38717572197748407,
        "vocab_size-1": 791,
        "unique-1": 611,
        "entropy-1": 7.966409254194675,
        "distinct-2": 0.7733681462140992,
        "vocab_size-2": 1481,
        "unique-2": 1317,
        "entropy-2": 10.188078664749758,
        "cond_entropy-2": 1.9555655637284064,
        "distinct-3": 0.9294907666480134,
        "vocab_size-3": 1661,
        "unique-3": 1588,
        "entropy-3": 10.620887935051678,
        "cond_entropy-3": 0.37478928627978475,
        "total_length-nopunct": 1792,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.7513585351636705,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.43638392857142855,
        "vocab_size-1-nopunct": 782,
        "unique-1-nopunct": 608,
        "entropy-1-nopunct": 8.243304708667765,
        "distinct-2-nopunct": 0.7992788461538461,
        "vocab_size-2-nopunct": 1330,
        "unique-2-nopunct": 1201,
        "entropy-2-nopunct": 10.072442192877519,
        "cond_entropy-2-nopunct": 1.8521705311040437,
        "distinct-3-nopunct": 0.9427083333333334,
        "vocab_size-3-nopunct": 1448,
        "unique-3-nopunct": 1395,
        "entropy-3-nopunct": 10.443556016687362,
        "cond_entropy-3-nopunct": 0.3611167526613031,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7921,
            "recall": 0.75464,
            "fmeasure": 0.76428
        },
        "rouge2": {
            "precision": 0.53934,
            "recall": 0.52566,
            "fmeasure": 0.52537
        },
        "rougeL": {
            "precision": 0.67981,
            "recall": 0.65786,
            "fmeasure": 0.6599
        },
        "rougeLsum": {
            "precision": 0.67981,
            "recall": 0.65786,
            "fmeasure": 0.6599
        },
        "local_recall": {
            "1": 0.1606060606060606,
            "2": 0.3289036544850498,
            "3": 0.7786052809749492
        },
        "nist": 7.485767248770156,
        "bleu": 44.89769,
        "bleurt": 0.34097,
        "nubia": {
            "semantic_relation": 4.3983,
            "contradiction": 5.38022,
            "irrelevancy": 27.65968,
            "logical_agreement": 66.9601,
            "grammar_ref": 4.21731,
            "grammar_hyp": 4.23611,
            "nubia_score": 0.81322
        },
        "meteor": 0.39565866137551053,
        "bertscore": {
            "precision": 0.9341,
            "recall": 0.93051,
            "f1": 0.93054
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 4,
        "msttr-100": 0.44,
        "msttr-100_nopunct": 0.43,
        "total_length": 137,
        "mean_pred_length": 34.25,
        "std_pred_length": 15.039531242695032,
        "median_pred_length": 27.5,
        "min_pred_length": 22,
        "max_pred_length": 60,
        "distinct-1": 0.3722627737226277,
        "vocab_size-1": 51,
        "unique-1": 33,
        "entropy-1": 4.295675273298937,
        "distinct-2": 0.7218045112781954,
        "vocab_size-2": 96,
        "unique-2": 74,
        "entropy-2": 6.383972566966272,
        "cond_entropy-2": 2.102746277570311,
        "distinct-3": 0.8372093023255814,
        "vocab_size-3": 108,
        "unique-3": 91,
        "entropy-3": 6.66223849566624,
        "cond_entropy-3": 0.27450867655034383,
        "total_length-nopunct": 125,
        "mean_pred_length-nopunct": 31.25,
        "std_pred_length-nopunct": 14.515078366994786,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 56,
        "distinct-1-nopunct": 0.384,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 4.089317445085795,
        "distinct-2-nopunct": 0.7024793388429752,
        "vocab_size-2-nopunct": 85,
        "unique-2-nopunct": 65,
        "entropy-2-nopunct": 6.17980603095046,
        "cond_entropy-2-nopunct": 2.1042366603678997,
        "distinct-3-nopunct": 0.8376068376068376,
        "vocab_size-3-nopunct": 98,
        "unique-3-nopunct": 83,
        "entropy-3-nopunct": 6.519770275064987,
        "cond_entropy-3-nopunct": 0.33959013151023487,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.57576,
            "recall": 0.60909,
            "fmeasure": 0.59091
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.225,
            "fmeasure": 0.21111
        },
        "rougeL": {
            "precision": 0.55303,
            "recall": 0.58636,
            "fmeasure": 0.56818
        },
        "rougeLsum": {
            "precision": 0.55303,
            "recall": 0.58636,
            "fmeasure": 0.56818
        },
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.15384615384615385,
            "3": 0.3076923076923077
        },
        "nist": 1.1184637029281386,
        "bleu": 2.22878,
        "bleurt": -0.49579,
        "nubia": {
            "semantic_relation": 3.30431,
            "contradiction": 36.87532,
            "irrelevancy": 18.14604,
            "logical_agreement": 44.97864,
            "grammar_ref": 2.93748,
            "grammar_hyp": 2.90374,
            "nubia_score": 0.17675
        },
        "meteor": 0.1297757261697824,
        "bertscore": {
            "precision": 0.86272,
            "recall": 0.86823,
            "f1": 0.86443
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_37": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.74,
        "total_length": 131,
        "mean_pred_length": 13.1,
        "std_pred_length": 4.3,
        "median_pred_length": 13.0,
        "min_pred_length": 5,
        "max_pred_length": 23,
        "distinct-1": 0.6412213740458015,
        "vocab_size-1": 84,
        "unique-1": 65,
        "entropy-1": 6.039873551778513,
        "distinct-2": 0.8512396694214877,
        "vocab_size-2": 103,
        "unique-2": 93,
        "entropy-2": 6.571432658619163,
        "cond_entropy-2": 0.3391311196399521,
        "distinct-3": 0.8918918918918919,
        "vocab_size-3": 99,
        "unique-3": 93,
        "entropy-3": 6.537394920287229,
        "cond_entropy-3": -0.020755704218840498,
        "total_length-nopunct": 119,
        "mean_pred_length-nopunct": 11.9,
        "std_pred_length-nopunct": 3.8587562763149474,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6890756302521008,
        "vocab_size-1-nopunct": 82,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 6.097038797177292,
        "distinct-2-nopunct": 0.8440366972477065,
        "vocab_size-2-nopunct": 92,
        "unique-2-nopunct": 83,
        "entropy-2-nopunct": 6.4008531319575805,
        "cond_entropy-2-nopunct": 0.3586564417647609,
        "distinct-3-nopunct": 0.8787878787878788,
        "vocab_size-3-nopunct": 87,
        "unique-3-nopunct": 81,
        "entropy-3-nopunct": 6.341181619948499,
        "cond_entropy-3-nopunct": -0.022567351118256786,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.90446,
            "recall": 0.91275,
            "fmeasure": 0.90325
        },
        "rouge2": {
            "precision": 0.81987,
            "recall": 0.84372,
            "fmeasure": 0.82611
        },
        "rougeL": {
            "precision": 0.86784,
            "recall": 0.87135,
            "fmeasure": 0.86452
        },
        "rougeLsum": {
            "precision": 0.86784,
            "recall": 0.87135,
            "fmeasure": 0.86452
        },
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.18181818181818182,
            "3": 0.9150943396226415
        },
        "nist": 6.322082796857341,
        "bleu": 73.98803,
        "bleurt": 0.77353,
        "nubia": {
            "semantic_relation": 4.82003,
            "contradiction": 0.24755,
            "irrelevancy": 13.06861,
            "logical_agreement": 86.68385,
            "grammar_ref": 5.03704,
            "grammar_hyp": 4.97538,
            "nubia_score": 0.9274
        },
        "meteor": 0.5472364127901538,
        "bertscore": {
            "precision": 0.97982,
            "recall": 0.97639,
            "f1": 0.97763
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 339,
        "msttr-100": 0.4359,
        "msttr-100_nopunct": 0.43513,
        "total_length": 8306,
        "mean_pred_length": 24.50147492625369,
        "std_pred_length": 10.358578344407013,
        "median_pred_length": 23.0,
        "min_pred_length": 6,
        "max_pred_length": 66,
        "distinct-1": 0.13424030821093186,
        "vocab_size-1": 1115,
        "unique-1": 620,
        "entropy-1": 5.682386443852756,
        "distinct-2": 0.32847997991715827,
        "vocab_size-2": 2617,
        "unique-2": 1679,
        "entropy-2": 9.819201587065242,
        "cond_entropy-2": 4.0915474820445565,
        "distinct-3": 0.5194022024121657,
        "vocab_size-3": 3962,
        "unique-3": 2886,
        "entropy-3": 11.107912366194222,
        "cond_entropy-3": 1.353805012201219,
        "total_length-nopunct": 7606,
        "mean_pred_length-nopunct": 22.436578171091444,
        "std_pred_length-nopunct": 9.96089498986168,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 61,
        "distinct-1-nopunct": 0.14580594267683408,
        "vocab_size-1-nopunct": 1109,
        "unique-1-nopunct": 620,
        "entropy-1-nopunct": 5.569848308055855,
        "distinct-2-nopunct": 0.31952662721893493,
        "vocab_size-2-nopunct": 2322,
        "unique-2-nopunct": 1472,
        "entropy-2-nopunct": 9.599344989963637,
        "cond_entropy-2-nopunct": 4.212968076176645,
        "distinct-3-nopunct": 0.50635103926097,
        "vocab_size-3-nopunct": 3508,
        "unique-3-nopunct": 2552,
        "entropy-3-nopunct": 10.88154302611775,
        "cond_entropy-3-nopunct": 1.3604855868957244,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.2812,
            "recall": 0.28414,
            "fmeasure": 0.28154
        },
        "rouge2": {
            "precision": 0.14196,
            "recall": 0.14086,
            "fmeasure": 0.14114
        },
        "rougeL": {
            "precision": 0.27973,
            "recall": 0.28304,
            "fmeasure": 0.28028
        },
        "rougeLsum": {
            "precision": 0.27973,
            "recall": 0.28304,
            "fmeasure": 0.28028
        },
        "local_recall": {
            "1": 0.09550561797752809,
            "2": 0.15956482320942883,
            "3": 0.20473773265651438,
            "4": 0.2222222222222222,
            "5": 0.3333333333333333,
            "6": 0.16666666666666666,
            "7": 0.25
        },
        "nist": 0.9530455046316599,
        "bleu": 2.43011,
        "bleurt": -0.40998,
        "nubia": {
            "semantic_relation": 3.31877,
            "contradiction": 36.26016,
            "irrelevancy": 15.6626,
            "logical_agreement": 48.07723,
            "grammar_ref": 2.83259,
            "grammar_hyp": 2.89959,
            "nubia_score": 0.19527
        },
        "meteor": 0.13601958968695715,
        "bertscore": {
            "precision": 0.86461,
            "recall": 0.87712,
            "f1": 0.87033
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_only_match": {
        "predictions_file": "T5-large (Baseline)/cs_restaurants_test",
        "N": 16,
        "msttr-100": 0.4825,
        "msttr-100_nopunct": 0.50667,
        "total_length": 425,
        "mean_pred_length": 26.5625,
        "std_pred_length": 5.600990425808636,
        "median_pred_length": 27.0,
        "min_pred_length": 13,
        "max_pred_length": 34,
        "distinct-1": 0.2564705882352941,
        "vocab_size-1": 109,
        "unique-1": 60,
        "entropy-1": 5.531787921987415,
        "distinct-2": 0.4963325183374083,
        "vocab_size-2": 203,
        "unique-2": 135,
        "entropy-2": 7.171929617812702,
        "cond_entropy-2": 1.6088275093817592,
        "distinct-3": 0.6234096692111959,
        "vocab_size-3": 245,
        "unique-3": 187,
        "entropy-3": 7.572839988144004,
        "cond_entropy-3": 0.40232172818813433,
        "total_length-nopunct": 383,
        "mean_pred_length-nopunct": 23.9375,
        "std_pred_length-nopunct": 5.344024115776425,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.27676240208877284,
        "vocab_size-1-nopunct": 106,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 5.5010326534741925,
        "distinct-2-nopunct": 0.5149863760217984,
        "vocab_size-2-nopunct": 189,
        "unique-2-nopunct": 129,
        "entropy-2-nopunct": 7.082799665726105,
        "cond_entropy-2-nopunct": 1.6311134973745303,
        "distinct-3-nopunct": 0.6495726495726496,
        "vocab_size-3-nopunct": 228,
        "unique-3-nopunct": 176,
        "entropy-3-nopunct": 7.512388940358383,
        "cond_entropy-3-nopunct": 0.41992242423129655,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.48303,
            "recall": 0.47283,
            "fmeasure": 0.46925
        },
        "rouge2": {
            "precision": 0.27095,
            "recall": 0.27791,
            "fmeasure": 0.26808
        },
        "rougeL": {
            "precision": 0.40118,
            "recall": 0.40126,
            "fmeasure": 0.39356
        },
        "rougeLsum": {
            "precision": 0.40118,
            "recall": 0.40126,
            "fmeasure": 0.39356
        },
        "local_recall": {
            "1": 0.29959514170040485
        },
        "nist": 1.4248151815085845,
        "bleu": 6.87262,
        "bleurt": -0.62525,
        "nubia": {
            "semantic_relation": 2.66086,
            "contradiction": 34.6433,
            "irrelevancy": 26.86027,
            "logical_agreement": 38.49643,
            "grammar_ref": 5.92126,
            "grammar_hyp": 5.80117,
            "nubia_score": 0.35258
        },
        "meteor": 0.14615020083633987,
        "bertscore": {
            "precision": 0.82666,
            "recall": 0.85941,
            "f1": 0.8426
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 316,
        "msttr-100": 0.43368,
        "msttr-100_nopunct": 0.42843,
        "total_length": 15235,
        "mean_pred_length": 48.212025316455694,
        "std_pred_length": 16.362468081584698,
        "median_pred_length": 48.5,
        "min_pred_length": 12,
        "max_pred_length": 83,
        "distinct-1": 0.09386281588447654,
        "vocab_size-1": 1430,
        "unique-1": 639,
        "entropy-1": 5.787750780217137,
        "distinct-2": 0.24713452644279107,
        "vocab_size-2": 3687,
        "unique-2": 2034,
        "entropy-2": 9.991387484000631,
        "cond_entropy-2": 4.201727338947752,
        "distinct-3": 0.4399780866945148,
        "vocab_size-3": 6425,
        "unique-3": 4209,
        "entropy-3": 11.64226074270274,
        "cond_entropy-3": 1.6823761949924712,
        "total_length-nopunct": 14055,
        "mean_pred_length-nopunct": 44.47784810126582,
        "std_pred_length-nopunct": 15.800260867169177,
        "median_pred_length-nopunct": 44.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 78,
        "distinct-1-nopunct": 0.10117395944503735,
        "vocab_size-1-nopunct": 1422,
        "unique-1-nopunct": 638,
        "entropy-1-nopunct": 5.6815935374151865,
        "distinct-2-nopunct": 0.24812577334594949,
        "vocab_size-2-nopunct": 3409,
        "unique-2-nopunct": 1882,
        "entropy-2-nopunct": 9.85532333249231,
        "cond_entropy-2-nopunct": 4.247984022237079,
        "distinct-3-nopunct": 0.4376070923042539,
        "vocab_size-3-nopunct": 5874,
        "unique-3-nopunct": 3905,
        "entropy-3-nopunct": 11.472629090029752,
        "cond_entropy-3-nopunct": 1.6489922745955352,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.38839,
            "recall": 0.39046,
            "fmeasure": 0.38556
        },
        "rouge2": {
            "precision": 0.1756,
            "recall": 0.17438,
            "fmeasure": 0.17252
        },
        "rougeL": {
            "precision": 0.36967,
            "recall": 0.37305,
            "fmeasure": 0.36733
        },
        "rougeLsum": {
            "precision": 0.36967,
            "recall": 0.37305,
            "fmeasure": 0.36733
        },
        "local_recall": {
            "1": 0.09653233364573571,
            "2": 0.1890979257115292,
            "3": 0.23309859154929577,
            "4": 0.15789473684210525,
            "5": 0.22727272727272727,
            "6": 0.0,
            "7": 0.2
        },
        "nist": 0.9958152560383579,
        "bleu": 1.59639,
        "bleurt": -0.50981,
        "nubia": {
            "semantic_relation": 3.31764,
            "contradiction": 32.35579,
            "irrelevancy": 17.04488,
            "logical_agreement": 50.59933,
            "grammar_ref": 2.6064,
            "grammar_hyp": 2.53497,
            "nubia_score": 0.14653
        },
        "meteor": 0.11833169592281244,
        "bertscore": {
            "precision": 0.85609,
            "recall": 0.8705,
            "f1": 0.86263
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_38": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 70,
        "mean_pred_length": 11.666666666666666,
        "std_pred_length": 2.357022603955158,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.7,
        "vocab_size-1": 49,
        "unique-1": 39,
        "entropy-1": 5.332505338219007,
        "distinct-2": 0.9375,
        "vocab_size-2": 60,
        "unique-2": 56,
        "entropy-2": 5.875,
        "cond_entropy-2": 0.37485233471894586,
        "distinct-3": 0.9655172413793104,
        "vocab_size-3": 56,
        "unique-3": 54,
        "entropy-3": 5.789015477886191,
        "cond_entropy-3": -0.07305348763104856,
        "total_length-nopunct": 63,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 2.362907813126304,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.746031746031746,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.338158296412769,
        "distinct-2-nopunct": 0.9298245614035088,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.692539136971756,
        "cond_entropy-2-nopunct": 0.40411294165588496,
        "distinct-3-nopunct": 0.9607843137254902,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.59399396942248,
        "cond_entropy-3-nopunct": -0.10164114278148127,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73573,
            "recall": 0.82453,
            "fmeasure": 0.76788
        },
        "rouge2": {
            "precision": 0.54582,
            "recall": 0.58532,
            "fmeasure": 0.55941
        },
        "rougeL": {
            "precision": 0.70448,
            "recall": 0.78465,
            "fmeasure": 0.73367
        },
        "rougeLsum": {
            "precision": 0.70448,
            "recall": 0.78465,
            "fmeasure": 0.73367
        },
        "local_recall": {
            "1": 0.23809523809523808,
            "2": 0.7333333333333333,
            "3": 0.9090909090909091
        },
        "nist": 4.414135260548502,
        "bleu": 47.06774,
        "bleurt": 0.33474,
        "nubia": {
            "semantic_relation": 4.23284,
            "contradiction": 3.54624,
            "irrelevancy": 30.43088,
            "logical_agreement": 66.02289,
            "grammar_ref": 5.1808,
            "grammar_hyp": 5.13511,
            "nubia_score": 0.70051
        },
        "meteor": 0.45169669784122624,
        "bertscore": {
            "precision": 0.92584,
            "recall": 0.92816,
            "f1": 0.92685
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_39": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 26,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.74667,
        "total_length": 419,
        "mean_pred_length": 16.115384615384617,
        "std_pred_length": 5.486535428293265,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 32,
        "distinct-1": 0.568019093078759,
        "vocab_size-1": 238,
        "unique-1": 194,
        "entropy-1": 7.038122856415497,
        "distinct-2": 0.9185750636132316,
        "vocab_size-2": 361,
        "unique-2": 338,
        "entropy-2": 8.429416895371906,
        "cond_entropy-2": 1.1873823289134062,
        "distinct-3": 0.9836512261580381,
        "vocab_size-3": 361,
        "unique-3": 355,
        "entropy-3": 8.486938705159218,
        "cond_entropy-3": 0.05456045768675997,
        "total_length-nopunct": 352,
        "mean_pred_length-nopunct": 13.538461538461538,
        "std_pred_length-nopunct": 4.153133842059412,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6534090909090909,
        "vocab_size-1-nopunct": 230,
        "unique-1-nopunct": 191,
        "entropy-1-nopunct": 7.190514235695851,
        "distinct-2-nopunct": 0.9355828220858896,
        "vocab_size-2-nopunct": 305,
        "unique-2-nopunct": 292,
        "entropy-2-nopunct": 8.190722709432567,
        "cond_entropy-2-nopunct": 1.0604906883182337,
        "distinct-3-nopunct": 0.9833333333333333,
        "vocab_size-3-nopunct": 295,
        "unique-3-nopunct": 290,
        "entropy-3-nopunct": 8.195485357162601,
        "cond_entropy-3-nopunct": 0.01512311961255967,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74036,
            "recall": 0.7496,
            "fmeasure": 0.73042
        },
        "rouge2": {
            "precision": 0.50456,
            "recall": 0.50379,
            "fmeasure": 0.49209
        },
        "rougeL": {
            "precision": 0.6554,
            "recall": 0.66414,
            "fmeasure": 0.64712
        },
        "rougeLsum": {
            "precision": 0.6554,
            "recall": 0.66414,
            "fmeasure": 0.64712
        },
        "local_recall": {
            "1": 0.2413793103448276,
            "2": 0.5161290322580645,
            "3": 0.7725321888412017
        },
        "nist": 6.333299010920958,
        "bleu": 46.60611,
        "bleurt": 0.15374,
        "nubia": {
            "semantic_relation": 3.93908,
            "contradiction": 5.90465,
            "irrelevancy": 48.53734,
            "logical_agreement": 45.55801,
            "grammar_ref": 4.64456,
            "grammar_hyp": 4.44993,
            "nubia_score": 0.6836
        },
        "meteor": 0.3832764456903215,
        "bertscore": {
            "precision": 0.91725,
            "recall": 0.92218,
            "f1": 0.91861
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_no_match": {
        "predictions_file": "T5-large (Baseline)/cs_restaurants_test",
        "N": 34,
        "msttr-100": 0.518,
        "msttr-100_nopunct": 0.5,
        "total_length": 596,
        "mean_pred_length": 17.529411764705884,
        "std_pred_length": 5.253767802688607,
        "median_pred_length": 17.0,
        "min_pred_length": 10,
        "max_pred_length": 29,
        "distinct-1": 0.21476510067114093,
        "vocab_size-1": 128,
        "unique-1": 49,
        "entropy-1": 5.454448932023245,
        "distinct-2": 0.4377224199288256,
        "vocab_size-2": 246,
        "unique-2": 124,
        "entropy-2": 7.484987835745989,
        "cond_entropy-2": 1.9479852443468935,
        "distinct-3": 0.5416666666666666,
        "vocab_size-3": 286,
        "unique-3": 166,
        "entropy-3": 7.8336523806099825,
        "cond_entropy-3": 0.31446367930484015,
        "total_length-nopunct": 552,
        "mean_pred_length-nopunct": 16.235294117647058,
        "std_pred_length-nopunct": 4.923286943217866,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.22826086956521738,
        "vocab_size-1-nopunct": 126,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.4206283623877205,
        "distinct-2-nopunct": 0.4420849420849421,
        "vocab_size-2-nopunct": 229,
        "unique-2-nopunct": 114,
        "entropy-2-nopunct": 7.395011810301681,
        "cond_entropy-2-nopunct": 1.97684838165677,
        "distinct-3-nopunct": 0.5433884297520661,
        "vocab_size-3-nopunct": 263,
        "unique-3-nopunct": 154,
        "entropy-3-nopunct": 7.706998398212718,
        "cond_entropy-3-nopunct": 0.3170633123620465,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.48741,
            "recall": 0.4514,
            "fmeasure": 0.45647
        },
        "rouge2": {
            "precision": 0.30149,
            "recall": 0.28565,
            "fmeasure": 0.28432
        },
        "rougeL": {
            "precision": 0.41518,
            "recall": 0.38942,
            "fmeasure": 0.39108
        },
        "rougeLsum": {
            "precision": 0.41518,
            "recall": 0.38942,
            "fmeasure": 0.39108
        },
        "local_recall": {
            "1": 0.23283582089552238
        },
        "nist": 1.0496023830370438,
        "bleu": 2.93221,
        "bleurt": -0.74834,
        "nubia": {
            "semantic_relation": 2.61252,
            "contradiction": 33.48716,
            "irrelevancy": 22.31704,
            "logical_agreement": 44.1958,
            "grammar_ref": 6.46033,
            "grammar_hyp": 5.85182,
            "nubia_score": 0.31775
        },
        "meteor": 0.11476300208646084,
        "bertscore": {
            "precision": 0.82611,
            "recall": 0.84921,
            "f1": 0.83736
        }
    },
    "web_nlg_ru_test": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 1102,
        "msttr-100": 0.46101,
        "msttr-100_nopunct": 0.45869,
        "total_length": 49712,
        "mean_pred_length": 45.11070780399274,
        "std_pred_length": 19.641535623279925,
        "median_pred_length": 44.0,
        "min_pred_length": 6,
        "max_pred_length": 85,
        "distinct-1": 0.050893144512391374,
        "vocab_size-1": 2530,
        "unique-1": 885,
        "entropy-1": 5.988797786848164,
        "distinct-2": 0.15157375025714873,
        "vocab_size-2": 7368,
        "unique-2": 3488,
        "entropy-2": 10.416999546548626,
        "cond_entropy-2": 4.423967350307877,
        "distinct-3": 0.29291908731161065,
        "vocab_size-3": 13916,
        "unique-3": 7874,
        "entropy-3": 12.29179730429788,
        "cond_entropy-3": 1.9146354605578233,
        "total_length-nopunct": 45855,
        "mean_pred_length-nopunct": 41.61070780399274,
        "std_pred_length-nopunct": 18.6043433458976,
        "median_pred_length-nopunct": 41.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 80,
        "distinct-1-nopunct": 0.0549558390578999,
        "vocab_size-1-nopunct": 2520,
        "unique-1-nopunct": 885,
        "entropy-1-nopunct": 5.900122794549885,
        "distinct-2-nopunct": 0.15232498379996873,
        "vocab_size-2-nopunct": 6817,
        "unique-2-nopunct": 3237,
        "entropy-2-nopunct": 10.292882547431697,
        "cond_entropy-2-nopunct": 4.479006202514046,
        "distinct-3-nopunct": 0.29438042656525626,
        "vocab_size-3-nopunct": 12850,
        "unique-3-nopunct": 7415,
        "entropy-3-nopunct": 12.129124973070164,
        "cond_entropy-3-nopunct": 1.8758681379376925,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.42047,
            "recall": 0.40539,
            "fmeasure": 0.4062
        },
        "rouge2": {
            "precision": 0.20853,
            "recall": 0.20231,
            "fmeasure": 0.20213
        },
        "rougeL": {
            "precision": 0.39713,
            "recall": 0.38417,
            "fmeasure": 0.38408
        },
        "rougeLsum": {
            "precision": 0.39713,
            "recall": 0.38417,
            "fmeasure": 0.38408
        },
        "local_recall": {
            "1": 0.0896438512597245,
            "2": 0.18301912756295582,
            "3": 0.25937674939354355,
            "4": 0.19480519480519481,
            "5": 0.2702702702702703,
            "6": 0.15384615384615385,
            "7": 0.2222222222222222
        },
        "nist": 1.1290860013061081,
        "bleu": 1.98811,
        "bleurt": -0.48399,
        "nubia": {
            "semantic_relation": 3.30962,
            "contradiction": 33.78806,
            "irrelevancy": 17.12988,
            "logical_agreement": 49.08205,
            "grammar_ref": 2.65213,
            "grammar_hyp": 2.62914,
            "nubia_score": 0.15592
        },
        "meteor": 0.12443297078139244,
        "bertscore": {
            "precision": 0.8603,
            "recall": 0.87209,
            "f1": 0.86565
        }
    },
    "web_nlg_ru_challenge_train_sample": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_challenge_train_sample",
        "N": 501
    },
    "web_nlg_ru_challenge_validation_sample": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_challenge_validation_sample",
        "N": 500
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 217,
        "msttr-100": 0.44522,
        "msttr-100_nopunct": 0.43792,
        "total_length": 11565,
        "mean_pred_length": 53.294930875576036,
        "std_pred_length": 13.871218822842012,
        "median_pred_length": 53.0,
        "min_pred_length": 23,
        "max_pred_length": 84,
        "distinct-1": 0.11552096843925638,
        "vocab_size-1": 1336,
        "unique-1": 660,
        "entropy-1": 5.87145146341509,
        "distinct-2": 0.29141698977793445,
        "vocab_size-2": 3307,
        "unique-2": 1952,
        "entropy-2": 10.029355556750604,
        "cond_entropy-2": 4.157111053140438,
        "distinct-3": 0.49510376426197106,
        "vocab_size-3": 5511,
        "unique-3": 3776,
        "entropy-3": 11.597845125658433,
        "cond_entropy-3": 1.587682099869927,
        "total_length-nopunct": 10674,
        "mean_pred_length-nopunct": 49.1889400921659,
        "std_pred_length-nopunct": 13.456749879141514,
        "median_pred_length-nopunct": 49.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 80,
        "distinct-1-nopunct": 0.1244144650552745,
        "vocab_size-1-nopunct": 1328,
        "unique-1-nopunct": 658,
        "entropy-1-nopunct": 5.776898000242592,
        "distinct-2-nopunct": 0.29597398871569286,
        "vocab_size-2-nopunct": 3095,
        "unique-2-nopunct": 1817,
        "entropy-2-nopunct": 9.924399256938882,
        "cond_entropy-2-nopunct": 4.2098518202989155,
        "distinct-3-nopunct": 0.4953125,
        "vocab_size-3-nopunct": 5072,
        "unique-3-nopunct": 3494,
        "entropy-3-nopunct": 11.448951444389596,
        "cond_entropy-3-nopunct": 1.5435561535090354,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.49025,
            "recall": 0.47818,
            "fmeasure": 0.47772
        },
        "rouge2": {
            "precision": 0.21985,
            "recall": 0.21867,
            "fmeasure": 0.21716
        },
        "rougeL": {
            "precision": 0.45585,
            "recall": 0.44637,
            "fmeasure": 0.44456
        },
        "rougeLsum": {
            "precision": 0.45585,
            "recall": 0.44637,
            "fmeasure": 0.44456
        },
        "local_recall": {
            "1": 0.08282208588957055,
            "2": 0.19356913183279742,
            "3": 0.280997798972854,
            "4": 0.18181818181818182
        },
        "nist": 1.0793240267812003,
        "bleu": 1.90836,
        "bleurt": -0.52492,
        "nubia": {
            "semantic_relation": 3.29925,
            "contradiction": 32.26106,
            "irrelevancy": 17.4942,
            "logical_agreement": 50.24474,
            "grammar_ref": 2.56565,
            "grammar_hyp": 2.5046,
            "nubia_score": 0.12748
        },
        "meteor": 0.12541266608973917,
        "bertscore": {
            "precision": 0.85806,
            "recall": 0.87076,
            "f1": 0.86381
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 143,
        "msttr-100": 0.45068,
        "msttr-100_nopunct": 0.44506,
        "total_length": 8863,
        "mean_pred_length": 61.97902097902098,
        "std_pred_length": 10.894579733655927,
        "median_pred_length": 63.0,
        "min_pred_length": 32,
        "max_pred_length": 84,
        "distinct-1": 0.12794764752341195,
        "vocab_size-1": 1134,
        "unique-1": 524,
        "entropy-1": 5.889725032248073,
        "distinct-2": 0.31261467889908257,
        "vocab_size-2": 2726,
        "unique-2": 1522,
        "entropy-2": 9.970740681371794,
        "cond_entropy-2": 4.088586572621486,
        "distinct-3": 0.5072869301620613,
        "vocab_size-3": 4351,
        "unique-3": 2831,
        "entropy-3": 11.421842271095423,
        "cond_entropy-3": 1.4676225416261564,
        "total_length-nopunct": 8185,
        "mean_pred_length-nopunct": 57.23776223776224,
        "std_pred_length-nopunct": 10.68883349229403,
        "median_pred_length-nopunct": 59.0,
        "min_pred_length-nopunct": 29,
        "max_pred_length-nopunct": 77,
        "distinct-1-nopunct": 0.1376908979841173,
        "vocab_size-1-nopunct": 1127,
        "unique-1-nopunct": 523,
        "entropy-1-nopunct": 5.7949459949875965,
        "distinct-2-nopunct": 0.3174583436955981,
        "vocab_size-2-nopunct": 2553,
        "unique-2-nopunct": 1424,
        "entropy-2-nopunct": 9.881064162262922,
        "cond_entropy-2-nopunct": 4.127619984874797,
        "distinct-3-nopunct": 0.5071528041524244,
        "vocab_size-3-nopunct": 4006,
        "unique-3-nopunct": 2626,
        "entropy-3-nopunct": 11.284469038943659,
        "cond_entropy-3-nopunct": 1.4244713081628584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.52685,
            "recall": 0.47201,
            "fmeasure": 0.48643
        },
        "rouge2": {
            "precision": 0.30065,
            "recall": 0.27033,
            "fmeasure": 0.27719
        },
        "rougeL": {
            "precision": 0.47852,
            "recall": 0.42573,
            "fmeasure": 0.43965
        },
        "rougeLsum": {
            "precision": 0.47852,
            "recall": 0.42573,
            "fmeasure": 0.43965
        },
        "local_recall": {
            "1": 0.08368849283223556,
            "2": 0.1929107021131561,
            "3": 0.27504725897920607
        },
        "nist": 1.2045470614114553,
        "bleu": 2.20164,
        "bleurt": -0.51688,
        "nubia": {
            "semantic_relation": 3.33457,
            "contradiction": 32.98121,
            "irrelevancy": 17.75725,
            "logical_agreement": 49.26155,
            "grammar_ref": 2.5384,
            "grammar_hyp": 2.47938,
            "nubia_score": 0.12417
        },
        "meteor": 0.12357134550656257,
        "bertscore": {
            "precision": 0.86091,
            "recall": 0.86988,
            "f1": 0.86506
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 56,
        "msttr-100": 0.45222,
        "msttr-100_nopunct": 0.44758,
        "total_length": 3649,
        "mean_pred_length": 65.16071428571429,
        "std_pred_length": 8.105943114500015,
        "median_pred_length": 66.5,
        "min_pred_length": 42,
        "max_pred_length": 85,
        "distinct-1": 0.1696355165798849,
        "vocab_size-1": 619,
        "unique-1": 337,
        "entropy-1": 5.680331061781594,
        "distinct-2": 0.3927080434177567,
        "vocab_size-2": 1411,
        "unique-2": 903,
        "entropy-2": 9.345825123815231,
        "cond_entropy-2": 3.685394743316417,
        "distinct-3": 0.5948543963811139,
        "vocab_size-3": 2104,
        "unique-3": 1536,
        "entropy-3": 10.507585828172784,
        "cond_entropy-3": 1.1734171119766204,
        "total_length-nopunct": 3397,
        "mean_pred_length-nopunct": 60.660714285714285,
        "std_pred_length-nopunct": 7.971549378244854,
        "median_pred_length-nopunct": 62.0,
        "min_pred_length-nopunct": 37,
        "max_pred_length-nopunct": 79,
        "distinct-1-nopunct": 0.1801589637915808,
        "vocab_size-1-nopunct": 612,
        "unique-1-nopunct": 336,
        "entropy-1-nopunct": 5.580349151699426,
        "distinct-2-nopunct": 0.400179586950015,
        "vocab_size-2-nopunct": 1337,
        "unique-2-nopunct": 854,
        "entropy-2-nopunct": 9.28090257413939,
        "cond_entropy-2-nopunct": 3.7369274470458587,
        "distinct-3-nopunct": 0.5969558599695586,
        "vocab_size-3-nopunct": 1961,
        "unique-3-nopunct": 1440,
        "entropy-3-nopunct": 10.401411856369243,
        "cond_entropy-3-nopunct": 1.1332454952685151,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.71039,
            "recall": 0.61771,
            "fmeasure": 0.63138
        },
        "rouge2": {
            "precision": 0.42496,
            "recall": 0.40619,
            "fmeasure": 0.4041
        },
        "rougeL": {
            "precision": 0.64473,
            "recall": 0.56931,
            "fmeasure": 0.57699
        },
        "rougeLsum": {
            "precision": 0.64473,
            "recall": 0.56931,
            "fmeasure": 0.57699
        },
        "local_recall": {
            "1": 0.07897153351698806,
            "2": 0.17011128775834658,
            "3": 0.31569664902998235
        },
        "nist": 1.2779396035136743,
        "bleu": 2.32525,
        "bleurt": -0.52188,
        "nubia": {
            "semantic_relation": 3.26079,
            "contradiction": 34.20792,
            "irrelevancy": 20.64419,
            "logical_agreement": 45.14788,
            "grammar_ref": 2.50981,
            "grammar_hyp": 2.48962,
            "nubia_score": 0.15318
        },
        "meteor": 0.12912224642480222,
        "bertscore": {
            "precision": 0.86418,
            "recall": 0.86767,
            "f1": 0.86549
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?select": {
        "predictions_file": "T5-large (Baseline)/cs_restaurants_test",
        "N": 12,
        "msttr-100": 0.5,
        "msttr-100_nopunct": 0.47,
        "total_length": 165,
        "mean_pred_length": 13.75,
        "std_pred_length": 6.339361166552983,
        "median_pred_length": 10.5,
        "min_pred_length": 5,
        "max_pred_length": 23,
        "distinct-1": 0.3151515151515151,
        "vocab_size-1": 52,
        "unique-1": 24,
        "entropy-1": 4.890618413817373,
        "distinct-2": 0.5294117647058824,
        "vocab_size-2": 81,
        "unique-2": 49,
        "entropy-2": 6.071907940857598,
        "cond_entropy-2": 1.1177199721200162,
        "distinct-3": 0.5460992907801419,
        "vocab_size-3": 77,
        "unique-3": 46,
        "entropy-3": 6.041167043504566,
        "cond_entropy-3": 0.002705796389472657,
        "total_length-nopunct": 143,
        "mean_pred_length-nopunct": 11.916666666666666,
        "std_pred_length-nopunct": 5.619287222494405,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.34265734265734266,
        "vocab_size-1-nopunct": 49,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.803631811959805,
        "distinct-2-nopunct": 0.5114503816793893,
        "vocab_size-2-nopunct": 67,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.7940422765595185,
        "cond_entropy-2-nopunct": 1.1015112471264108,
        "distinct-3-nopunct": 0.5294117647058824,
        "vocab_size-3-nopunct": 63,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.753198960405145,
        "cond_entropy-3-nopunct": -0.022760148818994148,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.39562,
            "recall": 0.41691,
            "fmeasure": 0.38823
        },
        "rouge2": {
            "precision": 0.22897,
            "recall": 0.29573,
            "fmeasure": 0.24708
        },
        "rougeL": {
            "precision": 0.38521,
            "recall": 0.4117,
            "fmeasure": 0.38129
        },
        "rougeLsum": {
            "precision": 0.38521,
            "recall": 0.4117,
            "fmeasure": 0.38129
        },
        "local_recall": {
            "1": 0.1951219512195122
        },
        "nist": 0.8096078519371493,
        "bleu": 1.99337,
        "bleurt": -0.70446,
        "nubia": {
            "semantic_relation": 2.28357,
            "contradiction": 36.41084,
            "irrelevancy": 40.02774,
            "logical_agreement": 23.56143,
            "grammar_ref": 6.83527,
            "grammar_hyp": 6.70266,
            "nubia_score": 0.13801
        },
        "meteor": 0.09560288913933242,
        "bertscore": {
            "precision": 0.82133,
            "recall": 0.85605,
            "f1": 0.83803
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 19,
        "msttr-100": 0.4425,
        "msttr-100_nopunct": 0.44636,
        "total_length": 1263,
        "mean_pred_length": 66.47368421052632,
        "std_pred_length": 7.982668206167077,
        "median_pred_length": 69.0,
        "min_pred_length": 43,
        "max_pred_length": 79,
        "distinct-1": 0.1828978622327791,
        "vocab_size-1": 231,
        "unique-1": 106,
        "entropy-1": 5.068106850429841,
        "distinct-2": 0.407556270096463,
        "vocab_size-2": 507,
        "unique-2": 288,
        "entropy-2": 8.271776083874313,
        "cond_entropy-2": 3.2161831951729076,
        "distinct-3": 0.5755102040816327,
        "vocab_size-3": 705,
        "unique-3": 474,
        "entropy-3": 9.075617069666434,
        "cond_entropy-3": 0.8165757568950165,
        "total_length-nopunct": 1174,
        "mean_pred_length-nopunct": 61.78947368421053,
        "std_pred_length-nopunct": 7.585158273812167,
        "median_pred_length-nopunct": 63.0,
        "min_pred_length-nopunct": 40,
        "max_pred_length-nopunct": 75,
        "distinct-1-nopunct": 0.19165247018739354,
        "vocab_size-1-nopunct": 225,
        "unique-1-nopunct": 104,
        "entropy-1-nopunct": 4.928373664759982,
        "distinct-2-nopunct": 0.4155844155844156,
        "vocab_size-2-nopunct": 480,
        "unique-2-nopunct": 269,
        "entropy-2-nopunct": 8.211363477385927,
        "cond_entropy-2-nopunct": 3.304253489890618,
        "distinct-3-nopunct": 0.5862676056338029,
        "vocab_size-3-nopunct": 666,
        "unique-3-nopunct": 452,
        "entropy-3-nopunct": 9.010555948057684,
        "cond_entropy-3-nopunct": 0.8134793227834016,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.8114,
            "recall": 0.74692,
            "fmeasure": 0.75642
        },
        "rouge2": {
            "precision": 0.35175,
            "recall": 0.37886,
            "fmeasure": 0.35303
        },
        "rougeL": {
            "precision": 0.74942,
            "recall": 0.6842,
            "fmeasure": 0.69412
        },
        "rougeLsum": {
            "precision": 0.74942,
            "recall": 0.6842,
            "fmeasure": 0.69412
        },
        "local_recall": {
            "1": 0.1152542372881356,
            "2": 0.17293233082706766,
            "3": 0.2376237623762376
        },
        "nist": 1.2374501984170942,
        "bleu": 1.84299,
        "bleurt": -0.51039,
        "nubia": {
            "semantic_relation": 3.22055,
            "contradiction": 33.74898,
            "irrelevancy": 21.57813,
            "logical_agreement": 44.67289,
            "grammar_ref": 2.51721,
            "grammar_hyp": 2.45135,
            "nubia_score": 0.16276
        },
        "meteor": 0.12378300414494443,
        "bertscore": {
            "precision": 0.86467,
            "recall": 0.86521,
            "f1": 0.86477
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_12": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 158,
        "msttr-100": 0.714,
        "msttr-100_nopunct": 0.76619,
        "total_length": 2551,
        "mean_pred_length": 16.145569620253166,
        "std_pred_length": 6.463946701049892,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 46,
        "distinct-1": 0.42022736181889453,
        "vocab_size-1": 1072,
        "unique-1": 840,
        "entropy-1": 8.374857554938325,
        "distinct-2": 0.8040117007939824,
        "vocab_size-2": 1924,
        "unique-2": 1715,
        "entropy-2": 10.649225450100394,
        "cond_entropy-2": 1.986376672060586,
        "distinct-3": 0.9212527964205817,
        "vocab_size-3": 2059,
        "unique-3": 1961,
        "entropy-3": 10.92549619541791,
        "cond_entropy-3": 0.2813539862767111,
        "total_length-nopunct": 2191,
        "mean_pred_length-nopunct": 13.867088607594937,
        "std_pred_length-nopunct": 5.608655641601894,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.4837973528069375,
        "vocab_size-1-nopunct": 1060,
        "unique-1-nopunct": 838,
        "entropy-1-nopunct": 8.71769831876167,
        "distinct-2-nopunct": 0.8263649778652238,
        "vocab_size-2-nopunct": 1680,
        "unique-2-nopunct": 1521,
        "entropy-2-nopunct": 10.47686584623125,
        "cond_entropy-2-nopunct": 1.879510518427343,
        "distinct-3-nopunct": 0.9301333333333334,
        "vocab_size-3-nopunct": 1744,
        "unique-3-nopunct": 1672,
        "entropy-3-nopunct": 10.694345380405435,
        "cond_entropy-3-nopunct": 0.248089968718031,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74206,
            "recall": 0.69918,
            "fmeasure": 0.7074
        },
        "rouge2": {
            "precision": 0.48252,
            "recall": 0.45824,
            "fmeasure": 0.46126
        },
        "rougeL": {
            "precision": 0.62649,
            "recall": 0.5961,
            "fmeasure": 0.60019
        },
        "rougeLsum": {
            "precision": 0.62649,
            "recall": 0.5961,
            "fmeasure": 0.60019
        },
        "local_recall": {
            "1": 0.24558303886925795,
            "2": 0.42292490118577075,
            "3": 0.7269881026925485
        },
        "nist": 7.451533160031045,
        "bleu": 39.65861,
        "bleurt": 0.19387,
        "nubia": {
            "semantic_relation": 4.06539,
            "contradiction": 6.79029,
            "irrelevancy": 31.90266,
            "logical_agreement": 61.30704,
            "grammar_ref": 4.68014,
            "grammar_hyp": 4.67046,
            "nubia_score": 0.69341
        },
        "meteor": 0.3732179902337181,
        "bertscore": {
            "precision": 0.92094,
            "recall": 0.91252,
            "f1": 0.91507
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_challenge_test_asset_bfp02",
        "N": 359,
        "msttr-100": 0.7159,
        "msttr-100_nopunct": 0.76333,
        "total_length": 6150,
        "mean_pred_length": 17.13091922005571,
        "std_pred_length": 8.27434313454777,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 61,
        "distinct-1": 0.3791869918699187,
        "vocab_size-1": 2332,
        "unique-1": 1796,
        "entropy-1": 8.982866368589757,
        "distinct-2": 0.8181661198411327,
        "vocab_size-2": 4738,
        "unique-2": 4360,
        "entropy-2": 11.826910970646002,
        "cond_entropy-2": 2.527571390003587,
        "distinct-3": 0.9432989690721649,
        "vocab_size-3": 5124,
        "unique-3": 5013,
        "entropy-3": 12.182151217905586,
        "cond_entropy-3": 0.38593869797911845,
        "total_length-nopunct": 5435,
        "mean_pred_length-nopunct": 15.139275766016713,
        "std_pred_length-nopunct": 7.215550410094194,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.42723091076356945,
        "vocab_size-1-nopunct": 2322,
        "unique-1-nopunct": 1793,
        "entropy-1-nopunct": 9.353453393246392,
        "distinct-2-nopunct": 0.8400315208825847,
        "vocab_size-2-nopunct": 4264,
        "unique-2-nopunct": 3952,
        "entropy-2-nopunct": 11.752668002964047,
        "cond_entropy-2-nopunct": 2.5651474181261933,
        "distinct-3-nopunct": 0.9658681365274538,
        "vocab_size-3-nopunct": 4556,
        "unique-3-nopunct": 4465,
        "entropy-3-nopunct": 12.11196131548777,
        "cond_entropy-3-nopunct": 0.39275391802846216,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp02.json",
        "rouge1": {
            "precision": 0.74963,
            "recall": 0.68975,
            "fmeasure": 0.70305
        },
        "rouge2": {
            "precision": 0.55301,
            "recall": 0.50925,
            "fmeasure": 0.51473
        },
        "rougeL": {
            "precision": 0.70754,
            "recall": 0.65689,
            "fmeasure": 0.66625
        },
        "rougeLsum": {
            "precision": 0.70754,
            "recall": 0.65689,
            "fmeasure": 0.66625
        },
        "local_recall": {
            "1": 0.044057971014492756,
            "2": 0.14560439560439561,
            "3": 0.2508792497069168,
            "4": 0.35410764872521244,
            "5": 0.450199203187251,
            "6": 0.5098522167487685,
            "7": 0.6038812785388128,
            "8": 0.7113095238095238,
            "9": 0.7964028776978417
        },
        "nist": 9.93665610908721,
        "bleu": 53.62225,
        "sari": 46.57188,
        "bleurt": -0.30833,
        "nubia": {
            "semantic_relation": 3.75584,
            "contradiction": 6.06551,
            "irrelevancy": 27.06121,
            "logical_agreement": 66.87327,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.57663,
            "nubia_score": 0.47882
        },
        "meteor": 0.3654049177404494,
        "bertscore": {
            "precision": 0.91079,
            "recall": 0.91702,
            "f1": 0.90943
        }
    },
    "totto_test_contrast_challenge_ethnicity-all_usa": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 128,
        "msttr-100": 0.692,
        "msttr-100_nopunct": 0.74944,
        "total_length": 2069,
        "mean_pred_length": 16.1640625,
        "std_pred_length": 5.599633559090608,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 33,
        "distinct-1": 0.41904301594973414,
        "vocab_size-1": 867,
        "unique-1": 681,
        "entropy-1": 8.185383872681864,
        "distinct-2": 0.8227717671303452,
        "vocab_size-2": 1597,
        "unique-2": 1450,
        "entropy-2": 10.395038607553882,
        "cond_entropy-2": 1.93603806208696,
        "distinct-3": 0.948703805846663,
        "vocab_size-3": 1720,
        "unique-3": 1661,
        "entropy-3": 10.701290536842839,
        "cond_entropy-3": 0.27716961398489726,
        "total_length-nopunct": 1811,
        "mean_pred_length-nopunct": 14.1484375,
        "std_pred_length-nopunct": 5.1175095318517725,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.4754279403644395,
        "vocab_size-1-nopunct": 861,
        "unique-1-nopunct": 680,
        "entropy-1-nopunct": 8.500836324397355,
        "distinct-2-nopunct": 0.8419489007724302,
        "vocab_size-2-nopunct": 1417,
        "unique-2-nopunct": 1308,
        "entropy-2-nopunct": 10.239644714749234,
        "cond_entropy-2-nopunct": 1.8117734150081666,
        "distinct-3-nopunct": 0.9614147909967846,
        "vocab_size-3-nopunct": 1495,
        "unique-3-nopunct": 1457,
        "entropy-3-nopunct": 10.512172719698912,
        "cond_entropy-3-nopunct": 0.28318918199189735,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80741,
            "recall": 0.79014,
            "fmeasure": 0.78969
        },
        "rouge2": {
            "precision": 0.57156,
            "recall": 0.55921,
            "fmeasure": 0.55807
        },
        "rougeL": {
            "precision": 0.68784,
            "recall": 0.67826,
            "fmeasure": 0.67466
        },
        "rougeLsum": {
            "precision": 0.68784,
            "recall": 0.67826,
            "fmeasure": 0.67466
        },
        "local_recall": {
            "1": 0.23008849557522124,
            "2": 0.35918367346938773,
            "3": 0.810391363022942
        },
        "nist": 7.963953115444406,
        "bleu": 46.23327,
        "bleurt": 0.39353,
        "nubia": {
            "semantic_relation": 4.50557,
            "contradiction": 4.4159,
            "irrelevancy": 19.57117,
            "logical_agreement": 76.01293,
            "grammar_ref": 4.60573,
            "grammar_hyp": 4.60313,
            "nubia_score": 0.82019
        },
        "meteor": 0.4128200750982549,
        "bertscore": {
            "precision": 0.93656,
            "recall": 0.93668,
            "f1": 0.9354
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_40": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 110,
        "msttr-100": 0.73294,
        "msttr-100_nopunct": 0.77733,
        "total_length": 1751,
        "mean_pred_length": 15.918181818181818,
        "std_pred_length": 6.394787391706153,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 37,
        "distinct-1": 0.47972587093089664,
        "vocab_size-1": 840,
        "unique-1": 681,
        "entropy-1": 8.294308043721557,
        "distinct-2": 0.8647166361974405,
        "vocab_size-2": 1419,
        "unique-2": 1308,
        "entropy-2": 10.299245698474197,
        "cond_entropy-2": 1.7165845269228823,
        "distinct-3": 0.9601567602873938,
        "vocab_size-3": 1470,
        "unique-3": 1425,
        "entropy-3": 10.491402199101694,
        "cond_entropy-3": 0.19765143580046252,
        "total_length-nopunct": 1548,
        "mean_pred_length-nopunct": 14.072727272727272,
        "std_pred_length-nopunct": 5.828938919359151,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.537467700258398,
        "vocab_size-1-nopunct": 832,
        "unique-1-nopunct": 680,
        "entropy-1-nopunct": 8.547728772473842,
        "distinct-2-nopunct": 0.868567454798331,
        "vocab_size-2-nopunct": 1249,
        "unique-2-nopunct": 1159,
        "entropy-2-nopunct": 10.1081522289537,
        "cond_entropy-2-nopunct": 1.6782402585707314,
        "distinct-3-nopunct": 0.9593373493975904,
        "vocab_size-3-nopunct": 1274,
        "unique-3-nopunct": 1234,
        "entropy-3-nopunct": 10.284279397451682,
        "cond_entropy-3-nopunct": 0.19964497193272293,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.769,
            "recall": 0.73095,
            "fmeasure": 0.73498
        },
        "rouge2": {
            "precision": 0.56037,
            "recall": 0.53167,
            "fmeasure": 0.53411
        },
        "rougeL": {
            "precision": 0.67433,
            "recall": 0.64342,
            "fmeasure": 0.64506
        },
        "rougeLsum": {
            "precision": 0.67433,
            "recall": 0.64342,
            "fmeasure": 0.64506
        },
        "local_recall": {
            "1": 0.21957671957671956,
            "2": 0.5384615384615384,
            "3": 0.7952830188679245
        },
        "nist": 7.880983494843302,
        "bleu": 49.14654,
        "bleurt": 0.24887,
        "nubia": {
            "semantic_relation": 4.1944,
            "contradiction": 8.48337,
            "irrelevancy": 30.56053,
            "logical_agreement": 60.9561,
            "grammar_ref": 4.79734,
            "grammar_hyp": 4.84071,
            "nubia_score": 0.71965
        },
        "meteor": 0.4076804112005923,
        "bertscore": {
            "precision": 0.93407,
            "recall": 0.92832,
            "f1": 0.92999
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "T5-large (Baseline)/cs_restaurants_test",
        "N": 183,
        "msttr-100": 0.22091,
        "msttr-100_nopunct": 0.21036,
        "total_length": 3345,
        "mean_pred_length": 18.278688524590162,
        "std_pred_length": 2.6599507835188665,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 26,
        "distinct-1": 0.02062780269058296,
        "vocab_size-1": 69,
        "unique-1": 20,
        "entropy-1": 4.178656835943182,
        "distinct-2": 0.03573687539531942,
        "vocab_size-2": 113,
        "unique-2": 44,
        "entropy-2": 4.894418609388284,
        "cond_entropy-2": 0.7189161343358256,
        "distinct-3": 0.03726082578046324,
        "vocab_size-3": 111,
        "unique-3": 42,
        "entropy-3": 4.84684556862986,
        "cond_entropy-3": -0.03158652948570932,
        "total_length-nopunct": 2831,
        "mean_pred_length-nopunct": 15.469945355191257,
        "std_pred_length-nopunct": 2.2171520888274867,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.023313316849169905,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.032022671063336,
        "distinct-2-nopunct": 0.03625377643504532,
        "vocab_size-2-nopunct": 96,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 4.65468445937528,
        "cond_entropy-2-nopunct": 0.6643874171415844,
        "distinct-3-nopunct": 0.03813387423935091,
        "vocab_size-3-nopunct": 94,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 4.599022560816875,
        "cond_entropy-3-nopunct": -0.040830112858157595,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.14584,
            "recall": 0.20209,
            "fmeasure": 0.16357
        },
        "rouge2": {
            "precision": 0.07822,
            "recall": 0.10645,
            "fmeasure": 0.08735
        },
        "rougeL": {
            "precision": 0.1335,
            "recall": 0.18717,
            "fmeasure": 0.15038
        },
        "rougeLsum": {
            "precision": 0.1335,
            "recall": 0.18717,
            "fmeasure": 0.15038
        },
        "local_recall": {
            "1": 0.12662013958125623
        },
        "nist": 0.4501883162219519,
        "bleu": 0.95463,
        "bleurt": -1.01275,
        "nubia": {
            "semantic_relation": 1.32414,
            "contradiction": 47.83652,
            "irrelevancy": 37.05588,
            "logical_agreement": 15.10759,
            "grammar_ref": 6.72681,
            "grammar_hyp": 5.68259,
            "nubia_score": 0.06314
        },
        "meteor": 0.06796888911108225,
        "bertscore": {
            "precision": 0.78417,
            "recall": 0.84105,
            "f1": 0.81146
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_41": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.71429,
            "fmeasure": 0.68966
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.61538,
            "fmeasure": 0.59259
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.71429,
            "fmeasure": 0.68966
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.71429,
            "fmeasure": 0.68966
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.5
        },
        "nist": 2.5393678939929654,
        "bleu": 47.85544,
        "bleurt": 0.33952,
        "nubia": {
            "semantic_relation": 3.84108,
            "contradiction": 0.15622,
            "irrelevancy": 99.75212,
            "logical_agreement": 0.09167,
            "grammar_ref": 4.76643,
            "grammar_hyp": 4.16449,
            "nubia_score": 0.71077
        },
        "meteor": 0.42850759341086025,
        "bertscore": {
            "precision": 0.92908,
            "recall": 0.94116,
            "f1": 0.93508
        }
    },
    "totto_test_contrast_challenge_continent-africa": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 45,
        "msttr-100": 0.67714,
        "msttr-100_nopunct": 0.70667,
        "total_length": 746,
        "mean_pred_length": 16.57777777777778,
        "std_pred_length": 5.964669643041204,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 32,
        "distinct-1": 0.4477211796246649,
        "vocab_size-1": 334,
        "unique-1": 256,
        "entropy-1": 7.214151966845674,
        "distinct-2": 0.7860199714693296,
        "vocab_size-2": 551,
        "unique-2": 476,
        "entropy-2": 8.829506124346278,
        "cond_entropy-2": 1.412310226071978,
        "distinct-3": 0.9222560975609756,
        "vocab_size-3": 605,
        "unique-3": 559,
        "entropy-3": 9.195563189821597,
        "cond_entropy-3": 0.35835887562190816,
        "total_length-nopunct": 675,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 5.800383129108321,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.49037037037037035,
        "vocab_size-1-nopunct": 331,
        "unique-1-nopunct": 255,
        "entropy-1-nopunct": 7.363018393324465,
        "distinct-2-nopunct": 0.7904761904761904,
        "vocab_size-2-nopunct": 498,
        "unique-2-nopunct": 432,
        "entropy-2-nopunct": 8.679938961568245,
        "cond_entropy-2-nopunct": 1.3577618462539827,
        "distinct-3-nopunct": 0.9196581196581196,
        "vocab_size-3-nopunct": 538,
        "unique-3-nopunct": 496,
        "entropy-3-nopunct": 9.024319032408345,
        "cond_entropy-3-nopunct": 0.3682130538371166,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79381,
            "recall": 0.76623,
            "fmeasure": 0.76843
        },
        "rouge2": {
            "precision": 0.565,
            "recall": 0.54756,
            "fmeasure": 0.54668
        },
        "rougeL": {
            "precision": 0.66301,
            "recall": 0.6337,
            "fmeasure": 0.6371
        },
        "rougeLsum": {
            "precision": 0.66301,
            "recall": 0.6337,
            "fmeasure": 0.6371
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.4609375,
            "3": 0.8137651821862348
        },
        "nist": 7.202779708308561,
        "bleu": 47.16412,
        "bleurt": 0.35351,
        "nubia": {
            "semantic_relation": 4.429,
            "contradiction": 3.43931,
            "irrelevancy": 28.44582,
            "logical_agreement": 68.11488,
            "grammar_ref": 4.86201,
            "grammar_hyp": 4.89764,
            "nubia_score": 0.7758
        },
        "meteor": 0.41089402032404204,
        "bertscore": {
            "precision": 0.943,
            "recall": 0.93701,
            "f1": 0.93909
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 12,
        "msttr-100": 0.44125,
        "msttr-100_nopunct": 0.43857,
        "total_length": 831,
        "mean_pred_length": 69.25,
        "std_pred_length": 3.1655699855370965,
        "median_pred_length": 70.5,
        "min_pred_length": 63,
        "max_pred_length": 75,
        "distinct-1": 0.22743682310469315,
        "vocab_size-1": 189,
        "unique-1": 104,
        "entropy-1": 4.93271730876444,
        "distinct-2": 0.47985347985347987,
        "vocab_size-2": 393,
        "unique-2": 238,
        "entropy-2": 8.050146223549776,
        "cond_entropy-2": 3.133862608450853,
        "distinct-3": 0.6691449814126395,
        "vocab_size-3": 540,
        "unique-3": 390,
        "entropy-3": 8.80723256294169,
        "cond_entropy-3": 0.760681784741368,
        "total_length-nopunct": 764,
        "mean_pred_length-nopunct": 63.666666666666664,
        "std_pred_length-nopunct": 2.9814239699997196,
        "median_pred_length-nopunct": 63.0,
        "min_pred_length-nopunct": 60,
        "max_pred_length-nopunct": 69,
        "distinct-1-nopunct": 0.24345549738219896,
        "vocab_size-1-nopunct": 186,
        "unique-1-nopunct": 104,
        "entropy-1-nopunct": 4.800210586127028,
        "distinct-2-nopunct": 0.5013297872340425,
        "vocab_size-2-nopunct": 377,
        "unique-2-nopunct": 234,
        "entropy-2-nopunct": 8.017784660898307,
        "cond_entropy-2-nopunct": 3.235651156844208,
        "distinct-3-nopunct": 0.6905405405405406,
        "vocab_size-3-nopunct": 511,
        "unique-3-nopunct": 382,
        "entropy-3-nopunct": 8.74301801526446,
        "cond_entropy-3-nopunct": 0.72745277148475,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.69775,
            "recall": 0.58198,
            "fmeasure": 0.61687
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.33631,
            "fmeasure": 0.35769
        },
        "rougeL": {
            "precision": 0.69158,
            "recall": 0.57503,
            "fmeasure": 0.61034
        },
        "rougeLsum": {
            "precision": 0.69158,
            "recall": 0.57503,
            "fmeasure": 0.61034
        },
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.14367816091954022,
            "3": 0.23417721518987342
        },
        "nist": 1.1482075091440116,
        "bleu": 1.41218,
        "bleurt": -0.54405,
        "nubia": {
            "semantic_relation": 3.09911,
            "contradiction": 36.99855,
            "irrelevancy": 23.31171,
            "logical_agreement": 39.68974,
            "grammar_ref": 2.55511,
            "grammar_hyp": 2.43808,
            "nubia_score": 0.18605
        },
        "meteor": 0.1020271502030021,
        "bertscore": {
            "precision": 0.85725,
            "recall": 0.85346,
            "f1": 0.85531
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_42": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 54,
        "msttr-100": 0.75333,
        "msttr-100_nopunct": 0.81286,
        "total_length": 904,
        "mean_pred_length": 16.74074074074074,
        "std_pred_length": 6.563606690276047,
        "median_pred_length": 16.0,
        "min_pred_length": 4,
        "max_pred_length": 34,
        "distinct-1": 0.5176991150442478,
        "vocab_size-1": 468,
        "unique-1": 371,
        "entropy-1": 7.809098477286762,
        "distinct-2": 0.9,
        "vocab_size-2": 765,
        "unique-2": 713,
        "entropy-2": 9.477384680734772,
        "cond_entropy-2": 1.4287625818791003,
        "distinct-3": 0.9798994974874372,
        "vocab_size-3": 780,
        "unique-3": 764,
        "entropy-3": 9.59642361551859,
        "cond_entropy-3": 0.12621538568294546,
        "total_length-nopunct": 791,
        "mean_pred_length-nopunct": 14.648148148148149,
        "std_pred_length-nopunct": 6.12873440928334,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.5815423514538559,
        "vocab_size-1-nopunct": 460,
        "unique-1-nopunct": 369,
        "entropy-1-nopunct": 8.046278888709951,
        "distinct-2-nopunct": 0.903663500678426,
        "vocab_size-2-nopunct": 666,
        "unique-2-nopunct": 625,
        "entropy-2-nopunct": 9.274381989224379,
        "cond_entropy-2-nopunct": 1.2928823209768021,
        "distinct-3-nopunct": 0.9809663250366032,
        "vocab_size-3-nopunct": 670,
        "unique-3-nopunct": 657,
        "entropy-3-nopunct": 9.377674418363332,
        "cond_entropy-3-nopunct": 0.11582756277432804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76167,
            "recall": 0.7127,
            "fmeasure": 0.72411
        },
        "rouge2": {
            "precision": 0.53629,
            "recall": 0.51078,
            "fmeasure": 0.51318
        },
        "rougeL": {
            "precision": 0.66357,
            "recall": 0.62144,
            "fmeasure": 0.62956
        },
        "rougeLsum": {
            "precision": 0.66357,
            "recall": 0.62144,
            "fmeasure": 0.62956
        },
        "local_recall": {
            "1": 0.22346368715083798,
            "2": 0.38285714285714284,
            "3": 0.7322580645161291
        },
        "nist": 6.85960515587639,
        "bleu": 44.05912,
        "bleurt": 0.21728,
        "nubia": {
            "semantic_relation": 4.13894,
            "contradiction": 9.76992,
            "irrelevancy": 31.1403,
            "logical_agreement": 59.08978,
            "grammar_ref": 4.68502,
            "grammar_hyp": 4.57613,
            "nubia_score": 0.71561
        },
        "meteor": 0.38442795134464475,
        "bertscore": {
            "precision": 0.93071,
            "recall": 0.92411,
            "f1": 0.92645
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_13": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 35,
        "msttr-100": 0.588,
        "msttr-100_nopunct": 0.6025,
        "total_length": 546,
        "mean_pred_length": 15.6,
        "std_pred_length": 6.356998393222116,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 39,
        "distinct-1": 0.37545787545787546,
        "vocab_size-1": 205,
        "unique-1": 163,
        "entropy-1": 6.49597221114715,
        "distinct-2": 0.7123287671232876,
        "vocab_size-2": 364,
        "unique-2": 319,
        "entropy-2": 8.128053270830055,
        "cond_entropy-2": 1.4586222865889436,
        "distinct-3": 0.8319327731092437,
        "vocab_size-3": 396,
        "unique-3": 367,
        "entropy-3": 8.404277402123745,
        "cond_entropy-3": 0.28130694086036023,
        "total_length-nopunct": 462,
        "mean_pred_length-nopunct": 13.2,
        "std_pred_length-nopunct": 5.5693036240757126,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.4329004329004329,
        "vocab_size-1-nopunct": 200,
        "unique-1-nopunct": 163,
        "entropy-1-nopunct": 6.583633094418648,
        "distinct-2-nopunct": 0.7447306791569087,
        "vocab_size-2-nopunct": 318,
        "unique-2-nopunct": 281,
        "entropy-2-nopunct": 7.9782421507690815,
        "cond_entropy-2-nopunct": 1.4898348841276434,
        "distinct-3-nopunct": 0.8418367346938775,
        "vocab_size-3-nopunct": 330,
        "unique-3-nopunct": 309,
        "entropy-3-nopunct": 8.147534629964458,
        "cond_entropy-3-nopunct": 0.22693215728158564,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8211,
            "recall": 0.77566,
            "fmeasure": 0.79094
        },
        "rouge2": {
            "precision": 0.61415,
            "recall": 0.57068,
            "fmeasure": 0.5857
        },
        "rougeL": {
            "precision": 0.72077,
            "recall": 0.68272,
            "fmeasure": 0.69518
        },
        "rougeLsum": {
            "precision": 0.72077,
            "recall": 0.68272,
            "fmeasure": 0.69518
        },
        "local_recall": {
            "1": 0.1724137931034483,
            "2": 0.40384615384615385,
            "3": 0.8097982708933718
        },
        "nist": 6.618504612422911,
        "bleu": 52.21627,
        "bleurt": 0.44798,
        "nubia": {
            "semantic_relation": 4.24555,
            "contradiction": 1.252,
            "irrelevancy": 22.51897,
            "logical_agreement": 76.22903,
            "grammar_ref": 4.23324,
            "grammar_hyp": 4.27256,
            "nubia_score": 0.78257
        },
        "meteor": 0.4281964576156755,
        "bertscore": {
            "precision": 0.94205,
            "recall": 0.93462,
            "f1": 0.93768
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-large (Baseline)/cs_restaurants_test",
        "N": 267,
        "msttr-100": 0.44682,
        "msttr-100_nopunct": 0.45875,
        "total_length": 4416,
        "mean_pred_length": 16.53932584269663,
        "std_pred_length": 5.580308167645087,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 55,
        "distinct-1": 0.0948822463768116,
        "vocab_size-1": 419,
        "unique-1": 176,
        "entropy-1": 5.845430730343778,
        "distinct-2": 0.2386117136659436,
        "vocab_size-2": 990,
        "unique-2": 531,
        "entropy-2": 8.448523367891852,
        "cond_entropy-2": 2.504367600794132,
        "distinct-3": 0.3562596599690881,
        "vocab_size-3": 1383,
        "unique-3": 915,
        "entropy-3": 9.160184441117414,
        "cond_entropy-3": 0.8638999546848515,
        "total_length-nopunct": 4025,
        "mean_pred_length-nopunct": 15.074906367041198,
        "std_pred_length-nopunct": 5.3647838623852575,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 53,
        "distinct-1-nopunct": 0.10335403726708074,
        "vocab_size-1-nopunct": 416,
        "unique-1-nopunct": 176,
        "entropy-1-nopunct": 5.884709067327203,
        "distinct-2-nopunct": 0.23390101117615753,
        "vocab_size-2-nopunct": 879,
        "unique-2-nopunct": 494,
        "entropy-2-nopunct": 8.213921457553536,
        "cond_entropy-2-nopunct": 2.5981695972496257,
        "distinct-3-nopunct": 0.34861071326267545,
        "vocab_size-3-nopunct": 1217,
        "unique-3-nopunct": 813,
        "entropy-3-nopunct": 8.941133678076604,
        "cond_entropy-3-nopunct": 0.9287309152998795,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.43377,
            "recall": 0.58634,
            "fmeasure": 0.48103
        },
        "rouge2": {
            "precision": 0.22901,
            "recall": 0.32044,
            "fmeasure": 0.25502
        },
        "rougeL": {
            "precision": 0.39056,
            "recall": 0.5242,
            "fmeasure": 0.43157
        },
        "rougeLsum": {
            "precision": 0.39056,
            "recall": 0.5242,
            "fmeasure": 0.43157
        },
        "local_recall": {
            "1": 0.35358565737051795
        },
        "nist": 1.548425162690841,
        "bleu": 5.12923,
        "bleurt": -0.67832,
        "nubia": {
            "semantic_relation": 3.29334,
            "contradiction": 30.6658,
            "irrelevancy": 26.74313,
            "logical_agreement": 42.59107,
            "grammar_ref": 7.44295,
            "grammar_hyp": 6.03057,
            "nubia_score": 0.36097
        },
        "meteor": 0.16672675440297102,
        "bertscore": {
            "precision": 0.82303,
            "recall": 0.86446,
            "f1": 0.84287
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_43": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 84,
        "mean_pred_length": 14.0,
        "std_pred_length": 9.0,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 34,
        "distinct-1": 0.7261904761904762,
        "vocab_size-1": 61,
        "unique-1": 52,
        "entropy-1": 5.655718577767722,
        "distinct-2": 0.8333333333333334,
        "vocab_size-2": 65,
        "unique-2": 60,
        "entropy-2": 5.855789718806781,
        "cond_entropy-2": 0.057889321369043706,
        "distinct-3": 0.875,
        "vocab_size-3": 63,
        "unique-3": 59,
        "entropy-3": 5.860693577741061,
        "cond_entropy-3": -0.07040621050553955,
        "total_length-nopunct": 74,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 7.520342781785652,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.7702702702702703,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.609932717296517,
        "distinct-2-nopunct": 0.8529411764705882,
        "vocab_size-2-nopunct": 58,
        "unique-2-nopunct": 54,
        "entropy-2-nopunct": 5.712319091186712,
        "cond_entropy-2-nopunct": 0.03763819580188008,
        "distinct-3-nopunct": 0.9032258064516129,
        "vocab_size-3-nopunct": 56,
        "unique-3-nopunct": 53,
        "entropy-3-nopunct": 5.724121108669287,
        "cond_entropy-3-nopunct": -0.08092600670481048,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.92514,
            "recall": 0.90591,
            "fmeasure": 0.91453
        },
        "rouge2": {
            "precision": 0.85278,
            "recall": 0.84444,
            "fmeasure": 0.84815
        },
        "rougeL": {
            "precision": 0.86394,
            "recall": 0.84711,
            "fmeasure": 0.85465
        },
        "rougeLsum": {
            "precision": 0.86394,
            "recall": 0.84711,
            "fmeasure": 0.85465
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8783783783783784
        },
        "nist": 5.169639970459882,
        "bleu": 74.70399,
        "bleurt": 0.69329,
        "nubia": {
            "semantic_relation": 4.57061,
            "contradiction": 15.65679,
            "irrelevancy": 3.584,
            "logical_agreement": 80.75921,
            "grammar_ref": 5.92578,
            "grammar_hyp": 6.05921,
            "nubia_score": 0.79616
        },
        "meteor": 0.5214287938554629,
        "bertscore": {
            "precision": 0.96984,
            "recall": 0.96858,
            "f1": 0.96901
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_44": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 47,
        "msttr-100": 0.69143,
        "msttr-100_nopunct": 0.74167,
        "total_length": 783,
        "mean_pred_length": 16.659574468085108,
        "std_pred_length": 6.925981290777443,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 43,
        "distinct-1": 0.5172413793103449,
        "vocab_size-1": 405,
        "unique-1": 321,
        "entropy-1": 7.57204573345545,
        "distinct-2": 0.8899456521739131,
        "vocab_size-2": 655,
        "unique-2": 602,
        "entropy-2": 9.255087666119827,
        "cond_entropy-2": 1.4586574134678554,
        "distinct-3": 0.9593613933236574,
        "vocab_size-3": 661,
        "unique-3": 637,
        "entropy-3": 9.340748375931195,
        "cond_entropy-3": 0.08131912948150484,
        "total_length-nopunct": 676,
        "mean_pred_length-nopunct": 14.382978723404255,
        "std_pred_length-nopunct": 5.966406636199336,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.5887573964497042,
        "vocab_size-1-nopunct": 398,
        "unique-1-nopunct": 320,
        "entropy-1-nopunct": 7.783602272946276,
        "distinct-2-nopunct": 0.9030206677265501,
        "vocab_size-2-nopunct": 568,
        "unique-2-nopunct": 527,
        "entropy-2-nopunct": 9.060242086941882,
        "cond_entropy-2-nopunct": 1.364020065390498,
        "distinct-3-nopunct": 0.9673539518900344,
        "vocab_size-3-nopunct": 563,
        "unique-3-nopunct": 544,
        "entropy-3-nopunct": 9.119583246688352,
        "cond_entropy-3-nopunct": 0.06299010070359601,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76534,
            "recall": 0.69957,
            "fmeasure": 0.7239
        },
        "rouge2": {
            "precision": 0.5099,
            "recall": 0.46754,
            "fmeasure": 0.48323
        },
        "rougeL": {
            "precision": 0.65612,
            "recall": 0.6067,
            "fmeasure": 0.62494
        },
        "rougeLsum": {
            "precision": 0.65612,
            "recall": 0.6067,
            "fmeasure": 0.62494
        },
        "local_recall": {
            "1": 0.11504424778761062,
            "2": 0.4176470588235294,
            "3": 0.7666666666666667
        },
        "nist": 6.414716728811513,
        "bleu": 39.17453,
        "bleurt": 0.25285,
        "nubia": {
            "semantic_relation": 4.23138,
            "contradiction": 9.24891,
            "irrelevancy": 25.26826,
            "logical_agreement": 65.48283,
            "grammar_ref": 4.69178,
            "grammar_hyp": 4.89306,
            "nubia_score": 0.70935
        },
        "meteor": 0.35830395991880765,
        "bertscore": {
            "precision": 0.92584,
            "recall": 0.91333,
            "f1": 0.91835
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 349,
        "msttr-100": 0.63656,
        "msttr-100_nopunct": 0.68887,
        "total_length": 6197,
        "mean_pred_length": 17.75644699140401,
        "std_pred_length": 4.875027880096411,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 57,
        "distinct-1": 0.17573019202840084,
        "vocab_size-1": 1089,
        "unique-1": 509,
        "entropy-1": 7.697592723101307,
        "distinct-2": 0.4587893296853625,
        "vocab_size-2": 2683,
        "unique-2": 1732,
        "entropy-2": 10.656316875057206,
        "cond_entropy-2": 2.741068647069109,
        "distinct-3": 0.6552100381887616,
        "vocab_size-3": 3603,
        "unique-3": 2746,
        "entropy-3": 11.46366110249417,
        "cond_entropy-3": 0.8790183946062764,
        "total_length-nopunct": 5392,
        "mean_pred_length-nopunct": 15.449856733524355,
        "std_pred_length-nopunct": 4.330994609338862,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.20048219584569732,
        "vocab_size-1-nopunct": 1081,
        "unique-1-nopunct": 508,
        "entropy-1-nopunct": 8.014309746919945,
        "distinct-2-nopunct": 0.46857029545905216,
        "vocab_size-2-nopunct": 2363,
        "unique-2-nopunct": 1563,
        "entropy-2-nopunct": 10.499989589929763,
        "cond_entropy-2-nopunct": 2.676419596651396,
        "distinct-3-nopunct": 0.6621218576906689,
        "vocab_size-3-nopunct": 3108,
        "unique-3-nopunct": 2411,
        "entropy-3-nopunct": 11.24782234423234,
        "cond_entropy-3-nopunct": 0.8079436006944106,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.68442,
            "recall": 0.69488,
            "fmeasure": 0.68253
        },
        "rouge2": {
            "precision": 0.42158,
            "recall": 0.42815,
            "fmeasure": 0.42013
        },
        "rougeL": {
            "precision": 0.55442,
            "recall": 0.56484,
            "fmeasure": 0.55325
        },
        "rougeLsum": {
            "precision": 0.55442,
            "recall": 0.56484,
            "fmeasure": 0.55325
        },
        "local_recall": {
            "1": 0.2214257268020709,
            "2": 0.5020215633423181,
            "3": 0.7819548872180451,
            "4": 1.0
        },
        "nist": 7.417051827564561,
        "bleu": 39.33232,
        "bleurt": 0.0344,
        "nubia": {
            "semantic_relation": 4.15609,
            "contradiction": 17.59188,
            "irrelevancy": 9.1605,
            "logical_agreement": 73.24761,
            "grammar_ref": 4.75348,
            "grammar_hyp": 4.75036,
            "nubia_score": 0.69914
        },
        "meteor": 0.3663750590969963,
        "bertscore": {
            "precision": 0.89903,
            "recall": 0.90395,
            "f1": 0.89993
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_50": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 55,
        "msttr-100": 0.74625,
        "msttr-100_nopunct": 0.79143,
        "total_length": 852,
        "mean_pred_length": 15.49090909090909,
        "std_pred_length": 5.066369427267786,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.534037558685446,
        "vocab_size-1": 455,
        "unique-1": 365,
        "entropy-1": 7.806805885532904,
        "distinct-2": 0.903387703889586,
        "vocab_size-2": 720,
        "unique-2": 668,
        "entropy-2": 9.410625515680941,
        "cond_entropy-2": 1.3378973229513262,
        "distinct-3": 0.9690026954177897,
        "vocab_size-3": 719,
        "unique-3": 699,
        "entropy-3": 9.470228661652529,
        "cond_entropy-3": 0.04197502121754327,
        "total_length-nopunct": 736,
        "mean_pred_length-nopunct": 13.381818181818181,
        "std_pred_length-nopunct": 4.2916024093186245,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6086956521739131,
        "vocab_size-1-nopunct": 448,
        "unique-1-nopunct": 364,
        "entropy-1-nopunct": 8.053235005219166,
        "distinct-2-nopunct": 0.9192364170337739,
        "vocab_size-2-nopunct": 626,
        "unique-2-nopunct": 590,
        "entropy-2-nopunct": 9.218852604053197,
        "cond_entropy-2-nopunct": 1.236738589712346,
        "distinct-3-nopunct": 0.9712460063897763,
        "vocab_size-3-nopunct": 608,
        "unique-3-nopunct": 593,
        "entropy-3-nopunct": 9.228893187976428,
        "cond_entropy-3-nopunct": 0.020577662386277725,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74701,
            "recall": 0.6917,
            "fmeasure": 0.70463
        },
        "rouge2": {
            "precision": 0.51052,
            "recall": 0.47263,
            "fmeasure": 0.48227
        },
        "rougeL": {
            "precision": 0.66142,
            "recall": 0.61368,
            "fmeasure": 0.62498
        },
        "rougeLsum": {
            "precision": 0.66142,
            "recall": 0.61368,
            "fmeasure": 0.62498
        },
        "local_recall": {
            "1": 0.25980392156862747,
            "2": 0.3770491803278688,
            "3": 0.7360594795539034
        },
        "nist": 6.839371939556257,
        "bleu": 45.46247,
        "bleurt": 0.19187,
        "nubia": {
            "semantic_relation": 4.12867,
            "contradiction": 6.37699,
            "irrelevancy": 32.52595,
            "logical_agreement": 61.09705,
            "grammar_ref": 4.83026,
            "grammar_hyp": 4.93193,
            "nubia_score": 0.69378
        },
        "meteor": 0.3836069066448408,
        "bertscore": {
            "precision": 0.9249,
            "recall": 0.91854,
            "f1": 0.92022
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_14": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 79,
        "msttr-100": 0.69929,
        "msttr-100_nopunct": 0.73833,
        "total_length": 1434,
        "mean_pred_length": 18.151898734177216,
        "std_pred_length": 9.229957564798067,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 59,
        "distinct-1": 0.4093444909344491,
        "vocab_size-1": 587,
        "unique-1": 447,
        "entropy-1": 7.782616698954056,
        "distinct-2": 0.7498154981549815,
        "vocab_size-2": 1016,
        "unique-2": 881,
        "entropy-2": 9.645900616090026,
        "cond_entropy-2": 1.652303457116868,
        "distinct-3": 0.8761755485893417,
        "vocab_size-3": 1118,
        "unique-3": 1048,
        "entropy-3": 9.949054218273249,
        "cond_entropy-3": 0.3250156281174948,
        "total_length-nopunct": 1256,
        "mean_pred_length-nopunct": 15.89873417721519,
        "std_pred_length-nopunct": 8.063976681308052,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 53,
        "distinct-1-nopunct": 0.46178343949044587,
        "vocab_size-1-nopunct": 580,
        "unique-1-nopunct": 446,
        "entropy-1-nopunct": 7.9971870746279015,
        "distinct-2-nopunct": 0.7663551401869159,
        "vocab_size-2-nopunct": 902,
        "unique-2-nopunct": 791,
        "entropy-2-nopunct": 9.488167137646403,
        "cond_entropy-2-nopunct": 1.5944235595860132,
        "distinct-3-nopunct": 0.8852459016393442,
        "vocab_size-3-nopunct": 972,
        "unique-3-nopunct": 917,
        "entropy-3-nopunct": 9.758180286791703,
        "cond_entropy-3-nopunct": 0.30862780791449723,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78224,
            "recall": 0.7501,
            "fmeasure": 0.75469
        },
        "rouge2": {
            "precision": 0.5591,
            "recall": 0.54709,
            "fmeasure": 0.54582
        },
        "rougeL": {
            "precision": 0.6713,
            "recall": 0.64819,
            "fmeasure": 0.64957
        },
        "rougeLsum": {
            "precision": 0.6713,
            "recall": 0.64819,
            "fmeasure": 0.64957
        },
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.4420289855072464,
            "3": 0.8179749715585893
        },
        "nist": 7.590528220961959,
        "bleu": 50.69377,
        "bleurt": 0.28405,
        "nubia": {
            "semantic_relation": 4.11485,
            "contradiction": 9.78322,
            "irrelevancy": 28.22944,
            "logical_agreement": 61.98734,
            "grammar_ref": 4.4104,
            "grammar_hyp": 4.44566,
            "nubia_score": 0.71971
        },
        "meteor": 0.4031949357850909,
        "bertscore": {
            "precision": 0.93359,
            "recall": 0.92704,
            "f1": 0.92825
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 1099,
        "msttr-100": 0.4417,
        "msttr-100_nopunct": 0.43751,
        "total_length": 49564,
        "mean_pred_length": 45.09918107370336,
        "std_pred_length": 19.63678812634558,
        "median_pred_length": 44.0,
        "min_pred_length": 6,
        "max_pred_length": 85,
        "distinct-1": 0.05084335404729239,
        "vocab_size-1": 2520,
        "unique-1": 876,
        "entropy-1": 5.988042270584082,
        "distinct-2": 0.1514082327452801,
        "vocab_size-2": 7338,
        "unique-2": 3464,
        "entropy-2": 10.414185735772977,
        "cond_entropy-2": 4.421997668568979,
        "distinct-3": 0.2925938436853439,
        "vocab_size-3": 13859,
        "unique-3": 7828,
        "entropy-3": 12.287504336928448,
        "cond_entropy-3": 1.913248766008997,
        "total_length-nopunct": 45723,
        "mean_pred_length-nopunct": 41.6041856232939,
        "std_pred_length-nopunct": 18.604225765387586,
        "median_pred_length-nopunct": 41.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 80,
        "distinct-1-nopunct": 0.054895785490890796,
        "vocab_size-1-nopunct": 2510,
        "unique-1-nopunct": 876,
        "entropy-1-nopunct": 5.899263227996277,
        "distinct-2-nopunct": 0.1522050914306203,
        "vocab_size-2-nopunct": 6792,
        "unique-2-nopunct": 3216,
        "entropy-2-nopunct": 10.290655193689195,
        "cond_entropy-2-nopunct": 4.477922313601784,
        "distinct-3-nopunct": 0.29410683515221137,
        "vocab_size-3-nopunct": 12801,
        "unique-3-nopunct": 7375,
        "entropy-3-nopunct": 12.125190184794462,
        "cond_entropy-3-nopunct": 1.874397845301656,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.42161,
            "recall": 0.4065,
            "fmeasure": 0.40731
        },
        "rouge2": {
            "precision": 0.2091,
            "recall": 0.20286,
            "fmeasure": 0.20269
        },
        "rougeL": {
            "precision": 0.39821,
            "recall": 0.38522,
            "fmeasure": 0.38513
        },
        "rougeLsum": {
            "precision": 0.39821,
            "recall": 0.38522,
            "fmeasure": 0.38513
        },
        "local_recall": {
            "1": 0.08959496207242021,
            "2": 0.183184011026878,
            "3": 0.2601763271431251,
            "4": 0.19480519480519481,
            "5": 0.2702702702702703,
            "6": 0.15384615384615385,
            "7": 0.2222222222222222
        },
        "nist": 1.129752835752733,
        "bleu": 1.99219,
        "bleurt": -0.48396,
        "nubia": {
            "semantic_relation": 3.30963,
            "contradiction": 33.79316,
            "irrelevancy": 17.13447,
            "logical_agreement": 49.07237,
            "grammar_ref": 2.65247,
            "grammar_hyp": 2.62947,
            "nubia_score": 0.15601
        },
        "meteor": 0.12448114756038796,
        "bertscore": {
            "precision": 0.86031,
            "recall": 0.87207,
            "f1": 0.86564
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 3,
        "msttr-100": 0.46,
        "msttr-100_nopunct": 0.48,
        "total_length": 148,
        "mean_pred_length": 49.333333333333336,
        "std_pred_length": 20.885933597094056,
        "median_pred_length": 47.0,
        "min_pred_length": 25,
        "max_pred_length": 76,
        "distinct-1": 0.40540540540540543,
        "vocab_size-1": 60,
        "unique-1": 47,
        "entropy-1": 4.25731195211186,
        "distinct-2": 0.7862068965517242,
        "vocab_size-2": 114,
        "unique-2": 99,
        "entropy-2": 6.64508926227954,
        "cond_entropy-2": 2.3943258180638174,
        "distinct-3": 0.9084507042253521,
        "vocab_size-3": 129,
        "unique-3": 122,
        "entropy-3": 6.931299584232477,
        "cond_entropy-3": 0.29750933239806315,
        "total_length-nopunct": 132,
        "mean_pred_length-nopunct": 44.0,
        "std_pred_length-nopunct": 18.49324200890693,
        "median_pred_length-nopunct": 41.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 68,
        "distinct-1-nopunct": 0.4166666666666667,
        "vocab_size-1-nopunct": 55,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 4.016381632603487,
        "distinct-2-nopunct": 0.7674418604651163,
        "vocab_size-2-nopunct": 99,
        "unique-2-nopunct": 85,
        "entropy-2-nopunct": 6.418951069423956,
        "cond_entropy-2-nopunct": 2.4026254202562445,
        "distinct-3-nopunct": 0.8888888888888888,
        "vocab_size-3-nopunct": 112,
        "unique-3-nopunct": 104,
        "entropy-3-nopunct": 6.715220002796324,
        "cond_entropy-3-nopunct": 0.28521261239262913,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "local_recall": {
            "1": 0.10810810810810811,
            "2": 0.08333333333333333,
            "3": 0.10714285714285714
        },
        "nist": 0.7154750298992646,
        "bleu": 0.91738,
        "bleurt": -0.49367,
        "nubia": {
            "semantic_relation": 3.30515,
            "contradiction": 31.92214,
            "irrelevancy": 15.4505,
            "logical_agreement": 52.62736,
            "grammar_ref": 2.52713,
            "grammar_hyp": 2.50927,
            "nubia_score": 0.12383
        },
        "meteor": 0.10838917069949751,
        "bertscore": {
            "precision": 0.85742,
            "recall": 0.87953,
            "f1": 0.86782
        }
    },
    "totto_test_contrast_challenge_continent-asia": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 150,
        "msttr-100": 0.7172,
        "msttr-100_nopunct": 0.76955,
        "total_length": 2543,
        "mean_pred_length": 16.953333333333333,
        "std_pred_length": 5.676074543399005,
        "median_pred_length": 16.0,
        "min_pred_length": 4,
        "max_pred_length": 40,
        "distinct-1": 0.4270546598505702,
        "vocab_size-1": 1086,
        "unique-1": 867,
        "entropy-1": 8.396575099449088,
        "distinct-2": 0.7973255328040117,
        "vocab_size-2": 1908,
        "unique-2": 1711,
        "entropy-2": 10.585489414912598,
        "cond_entropy-2": 1.9185583996729323,
        "distinct-3": 0.927775300936246,
        "vocab_size-3": 2081,
        "unique-3": 1989,
        "entropy-3": 10.950013321540542,
        "cond_entropy-3": 0.37099249492777464,
        "total_length-nopunct": 2218,
        "mean_pred_length-nopunct": 14.786666666666667,
        "std_pred_length-nopunct": 5.1154493665974465,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.48647430117222723,
        "vocab_size-1-nopunct": 1079,
        "unique-1-nopunct": 865,
        "entropy-1-nopunct": 8.723709642318106,
        "distinct-2-nopunct": 0.8123791102514507,
        "vocab_size-2-nopunct": 1680,
        "unique-2-nopunct": 1538,
        "entropy-2-nopunct": 10.400190981106029,
        "cond_entropy-2-nopunct": 1.7756659612113215,
        "distinct-3-nopunct": 0.9395203336809176,
        "vocab_size-3-nopunct": 1802,
        "unique-3-nopunct": 1741,
        "entropy-3-nopunct": 10.749522059534694,
        "cond_entropy-3-nopunct": 0.37765683568595765,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82692,
            "recall": 0.7957,
            "fmeasure": 0.8023
        },
        "rouge2": {
            "precision": 0.59297,
            "recall": 0.5815,
            "fmeasure": 0.58103
        },
        "rougeL": {
            "precision": 0.69601,
            "recall": 0.67651,
            "fmeasure": 0.67909
        },
        "rougeLsum": {
            "precision": 0.69601,
            "recall": 0.67651,
            "fmeasure": 0.67909
        },
        "local_recall": {
            "1": 0.20620842572062084,
            "2": 0.46756756756756757,
            "3": 0.8109965635738832
        },
        "nist": 8.45503351311341,
        "bleu": 49.75124,
        "bleurt": 0.37084,
        "nubia": {
            "semantic_relation": 4.50332,
            "contradiction": 4.77051,
            "irrelevancy": 26.50605,
            "logical_agreement": 68.72345,
            "grammar_ref": 5.14336,
            "grammar_hyp": 5.2047,
            "nubia_score": 0.79269
        },
        "meteor": 0.4172937718071012,
        "bertscore": {
            "precision": 0.94707,
            "recall": 0.94462,
            "f1": 0.9449
        }
    },
    "schema_guided_dialog_challenge_test_bfp05": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_challenge_test_bfp05",
        "N": 500,
        "msttr-100": 0.68567,
        "msttr-100_nopunct": 0.71811,
        "total_length": 6076,
        "mean_pred_length": 12.152,
        "std_pred_length": 7.047616334619812,
        "median_pred_length": 10.0,
        "min_pred_length": 2,
        "max_pred_length": 42,
        "distinct-1": 0.16063199473337722,
        "vocab_size-1": 976,
        "unique-1": 550,
        "entropy-1": 7.793592175873443,
        "distinct-2": 0.48565279770444764,
        "vocab_size-2": 2708,
        "unique-2": 1922,
        "entropy-2": 10.580153819485863,
        "cond_entropy-2": 2.5480865217778015,
        "distinct-3": 0.6999605988967691,
        "vocab_size-3": 3553,
        "unique-3": 2956,
        "entropy-3": 11.385526029059776,
        "cond_entropy-3": 0.8298757824538754,
        "total_length-nopunct": 5357,
        "mean_pred_length-nopunct": 10.714,
        "std_pred_length-nopunct": 6.5069350696007415,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.1801381370169871,
        "vocab_size-1-nopunct": 965,
        "unique-1-nopunct": 547,
        "entropy-1-nopunct": 7.967550248386435,
        "distinct-2-nopunct": 0.4990735021618283,
        "vocab_size-2-nopunct": 2424,
        "unique-2-nopunct": 1760,
        "entropy-2-nopunct": 10.402753567610599,
        "cond_entropy-2-nopunct": 2.570892690159277,
        "distinct-3-nopunct": 0.7150068838916934,
        "vocab_size-3-nopunct": 3116,
        "unique-3-nopunct": 2635,
        "entropy-3-nopunct": 11.197704483805238,
        "cond_entropy-3-nopunct": 0.8195651948223219,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp05.json",
        "rouge1": {
            "precision": 0.58125,
            "recall": 0.53844,
            "fmeasure": 0.54684
        },
        "rouge2": {
            "precision": 0.35379,
            "recall": 0.32475,
            "fmeasure": 0.33094
        },
        "rougeL": {
            "precision": 0.51841,
            "recall": 0.48047,
            "fmeasure": 0.48797
        },
        "rougeLsum": {
            "precision": 0.51841,
            "recall": 0.48047,
            "fmeasure": 0.48797
        },
        "local_recall": {
            "1": 0.5547819714181018
        },
        "nist": 5.972615757603128,
        "bleu": 31.14641,
        "bleurt": -0.08906,
        "nubia": {
            "semantic_relation": 3.59694,
            "contradiction": 7.27844,
            "irrelevancy": 21.67114,
            "logical_agreement": 71.05042,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.68484,
            "nubia_score": 0.62863
        },
        "meteor": 0.31120389197693005,
        "bertscore": {
            "precision": 0.87163,
            "recall": 0.86231,
            "f1": 0.86646
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_51": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.72,
        "total_length": 151,
        "mean_pred_length": 13.727272727272727,
        "std_pred_length": 3.670296225124791,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.6158940397350994,
        "vocab_size-1": 93,
        "unique-1": 77,
        "entropy-1": 5.9206860833605734,
        "distinct-2": 0.9285714285714286,
        "vocab_size-2": 130,
        "unique-2": 123,
        "entropy-2": 6.960642727841858,
        "cond_entropy-2": 0.8716791974141155,
        "distinct-3": 0.9844961240310077,
        "vocab_size-3": 127,
        "unique-3": 125,
        "entropy-3": 6.980219503485251,
        "cond_entropy-3": 0.0339569553343871,
        "total_length-nopunct": 132,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.668043818514912,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6818181818181818,
        "vocab_size-1-nopunct": 90,
        "unique-1-nopunct": 77,
        "entropy-1-nopunct": 5.957939617530406,
        "distinct-2-nopunct": 0.9256198347107438,
        "vocab_size-2-nopunct": 112,
        "unique-2-nopunct": 106,
        "entropy-2-nopunct": 6.740271167237934,
        "cond_entropy-2-nopunct": 0.8728356779728741,
        "distinct-3-nopunct": 0.9818181818181818,
        "vocab_size-3-nopunct": 108,
        "unique-3-nopunct": 106,
        "entropy-3-nopunct": 6.744996077161032,
        "cond_entropy-3-nopunct": 0.02258411692676356,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78308,
            "recall": 0.75513,
            "fmeasure": 0.75656
        },
        "rouge2": {
            "precision": 0.54915,
            "recall": 0.52916,
            "fmeasure": 0.5302
        },
        "rougeL": {
            "precision": 0.63177,
            "recall": 0.6497,
            "fmeasure": 0.62888
        },
        "rougeLsum": {
            "precision": 0.63177,
            "recall": 0.6497,
            "fmeasure": 0.62888
        },
        "local_recall": {
            "1": 0.25925925925925924,
            "2": 0.45161290322580644,
            "3": 0.8043478260869565
        },
        "nist": 6.389243143419727,
        "bleu": 57.60926,
        "bleurt": 0.2457,
        "nubia": {
            "semantic_relation": 3.9452,
            "contradiction": 28.32353,
            "irrelevancy": 21.91249,
            "logical_agreement": 49.76398,
            "grammar_ref": 4.58752,
            "grammar_hyp": 4.48239,
            "nubia_score": 0.67208
        },
        "meteor": 0.42853639996963344,
        "bertscore": {
            "precision": 0.93696,
            "recall": 0.94718,
            "f1": 0.93865
        }
    },
    "web_nlg_ru_challenge_test_scramble": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.44103,
        "msttr-100_nopunct": 0.43374,
        "total_length": 22336,
        "mean_pred_length": 44.672,
        "std_pred_length": 20.16552543327349,
        "median_pred_length": 44.0,
        "min_pred_length": 8,
        "max_pred_length": 85,
        "distinct-1": 0.08184097421203439,
        "vocab_size-1": 1828,
        "unique-1": 780,
        "entropy-1": 5.916954171528232,
        "distinct-2": 0.22453746107345668,
        "vocab_size-2": 4903,
        "unique-2": 2672,
        "entropy-2": 10.241117567998836,
        "cond_entropy-2": 4.32053389787285,
        "distinct-3": 0.4006374203224597,
        "vocab_size-3": 8548,
        "unique-3": 5477,
        "entropy-3": 11.932421451276866,
        "cond_entropy-3": 1.7330502900524487,
        "total_length-nopunct": 20612,
        "mean_pred_length-nopunct": 41.224,
        "std_pred_length-nopunct": 19.04105627322182,
        "median_pred_length-nopunct": 40.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 80,
        "distinct-1-nopunct": 0.08820104793324277,
        "vocab_size-1-nopunct": 1818,
        "unique-1-nopunct": 779,
        "entropy-1-nopunct": 5.823056969722944,
        "distinct-2-nopunct": 0.22320007955449483,
        "vocab_size-2-nopunct": 4489,
        "unique-2-nopunct": 2415,
        "entropy-2-nopunct": 10.104113467418987,
        "cond_entropy-2-nopunct": 4.374727375033893,
        "distinct-3-nopunct": 0.39730777075260043,
        "vocab_size-3-nopunct": 7792,
        "unique-3-nopunct": 5023,
        "entropy-3-nopunct": 11.765556696804502,
        "cond_entropy-3-nopunct": 1.6991995434511946,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_challenge_test_scramble.json",
        "rouge1": {
            "precision": 0.42179,
            "recall": 0.40602,
            "fmeasure": 0.40583
        },
        "rouge2": {
            "precision": 0.19364,
            "recall": 0.18692,
            "fmeasure": 0.18695
        },
        "rougeL": {
            "precision": 0.39775,
            "recall": 0.38421,
            "fmeasure": 0.38311
        },
        "rougeLsum": {
            "precision": 0.39775,
            "recall": 0.38421,
            "fmeasure": 0.38311
        },
        "local_recall": {
            "1": 0.08816818774445893,
            "2": 0.17909090909090908,
            "3": 0.25612848689771767,
            "4": 0.17777777777777778,
            "5": 0.4,
            "6": 0.3333333333333333
        },
        "nist": 1.1048425146883494,
        "bleu": 2.02299,
        "bleurt": -0.4826,
        "nubia": {
            "semantic_relation": 3.29857,
            "contradiction": 34.37179,
            "irrelevancy": 17.2552,
            "logical_agreement": 48.37301,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.64002,
            "nubia_score": 0.1565
        },
        "meteor": 0.1234113051768985,
        "bertscore": {
            "precision": 0.86,
            "recall": 0.87153,
            "f1": 0.86521
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_45": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 79,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.788,
        "total_length": 1224,
        "mean_pred_length": 15.49367088607595,
        "std_pred_length": 6.596649356084273,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 38,
        "distinct-1": 0.5220588235294118,
        "vocab_size-1": 639,
        "unique-1": 520,
        "entropy-1": 8.076761881748817,
        "distinct-2": 0.9117903930131004,
        "vocab_size-2": 1044,
        "unique-2": 985,
        "entropy-2": 9.921299983379336,
        "cond_entropy-2": 1.5575698052869418,
        "distinct-3": 0.9849906191369606,
        "vocab_size-3": 1050,
        "unique-3": 1035,
        "entropy-3": 10.027264811406104,
        "cond_entropy-3": 0.09347144862940997,
        "total_length-nopunct": 1066,
        "mean_pred_length-nopunct": 13.49367088607595,
        "std_pred_length-nopunct": 6.03129689376986,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.5947467166979362,
        "vocab_size-1-nopunct": 634,
        "unique-1-nopunct": 520,
        "entropy-1-nopunct": 8.369188124389389,
        "distinct-2-nopunct": 0.916919959473151,
        "vocab_size-2-nopunct": 905,
        "unique-2-nopunct": 858,
        "entropy-2-nopunct": 9.715555856481632,
        "cond_entropy-2-nopunct": 1.4451771419025727,
        "distinct-3-nopunct": 0.9889867841409692,
        "vocab_size-3-nopunct": 898,
        "unique-3-nopunct": 889,
        "entropy-3-nopunct": 9.803690681671805,
        "cond_entropy-3-nopunct": 0.10055407961749532,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72131,
            "recall": 0.6604,
            "fmeasure": 0.67055
        },
        "rouge2": {
            "precision": 0.46355,
            "recall": 0.42748,
            "fmeasure": 0.43027
        },
        "rougeL": {
            "precision": 0.61886,
            "recall": 0.56859,
            "fmeasure": 0.57516
        },
        "rougeLsum": {
            "precision": 0.61886,
            "recall": 0.56859,
            "fmeasure": 0.57516
        },
        "local_recall": {
            "1": 0.22508038585209003,
            "2": 0.3835616438356164,
            "3": 0.7325428194993412
        },
        "nist": 6.6097366900813945,
        "bleu": 38.80956,
        "bleurt": 0.1227,
        "nubia": {
            "semantic_relation": 4.03012,
            "contradiction": 10.95881,
            "irrelevancy": 32.73839,
            "logical_agreement": 56.30279,
            "grammar_ref": 4.80224,
            "grammar_hyp": 5.10385,
            "nubia_score": 0.64756
        },
        "meteor": 0.35143307377151434,
        "bertscore": {
            "precision": 0.91811,
            "recall": 0.90521,
            "f1": 0.90965
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_46": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 41,
        "mean_pred_length": 10.25,
        "std_pred_length": 3.5619517121937516,
        "median_pred_length": 10.5,
        "min_pred_length": 5,
        "max_pred_length": 15,
        "distinct-1": 0.8048780487804879,
        "vocab_size-1": 33,
        "unique-1": 29,
        "entropy-1": 4.88170383378084,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.16297636112781017,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.16505924627049623,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 2.8722813232690143,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.807763576417193,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": 0.1364202545024104,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.20645087746742646,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83102,
            "recall": 0.70118,
            "fmeasure": 0.75079
        },
        "rouge2": {
            "precision": 0.69186,
            "recall": 0.58017,
            "fmeasure": 0.62151
        },
        "rougeL": {
            "precision": 0.80556,
            "recall": 0.67988,
            "fmeasure": 0.72769
        },
        "rougeLsum": {
            "precision": 0.80556,
            "recall": 0.67988,
            "fmeasure": 0.72769
        },
        "local_recall": {
            "1": 0.11538461538461539,
            "2": 0.1111111111111111,
            "3": 0.7333333333333333
        },
        "nist": 3.793011046369877,
        "bleu": 48.27511,
        "bleurt": 0.23682,
        "nubia": {
            "semantic_relation": 4.31937,
            "contradiction": 30.02967,
            "irrelevancy": 15.21588,
            "logical_agreement": 54.75445,
            "grammar_ref": 6.02061,
            "grammar_hyp": 6.52684,
            "nubia_score": 0.58969
        },
        "meteor": 0.3800219366225044,
        "bertscore": {
            "precision": 0.93921,
            "recall": 0.93928,
            "f1": 0.93887
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_52": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 43,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.78,
        "total_length": 681,
        "mean_pred_length": 15.837209302325581,
        "std_pred_length": 5.430020911168521,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.5477239353891337,
        "vocab_size-1": 373,
        "unique-1": 312,
        "entropy-1": 7.557088827112116,
        "distinct-2": 0.9169278996865203,
        "vocab_size-2": 585,
        "unique-2": 557,
        "entropy-2": 9.101247405303692,
        "cond_entropy-2": 1.303423105568588,
        "distinct-3": 0.9764705882352941,
        "vocab_size-3": 581,
        "unique-3": 571,
        "entropy-3": 9.162964345590254,
        "cond_entropy-3": 0.05717089652831047,
        "total_length-nopunct": 590,
        "mean_pred_length-nopunct": 13.720930232558139,
        "std_pred_length-nopunct": 4.900524800540642,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6186440677966102,
        "vocab_size-1-nopunct": 365,
        "unique-1-nopunct": 309,
        "entropy-1-nopunct": 7.75615455620371,
        "distinct-2-nopunct": 0.9195612431444241,
        "vocab_size-2-nopunct": 503,
        "unique-2-nopunct": 482,
        "entropy-2-nopunct": 8.879833214751908,
        "cond_entropy-2-nopunct": 1.2058396517531396,
        "distinct-3-nopunct": 0.9781746031746031,
        "vocab_size-3-nopunct": 493,
        "unique-3-nopunct": 486,
        "entropy-3-nopunct": 8.925692621912548,
        "cond_entropy-3-nopunct": 0.04804059514544055,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79841,
            "recall": 0.79122,
            "fmeasure": 0.78374
        },
        "rouge2": {
            "precision": 0.60189,
            "recall": 0.60125,
            "fmeasure": 0.59359
        },
        "rougeL": {
            "precision": 0.69952,
            "recall": 0.7053,
            "fmeasure": 0.69182
        },
        "rougeLsum": {
            "precision": 0.69952,
            "recall": 0.7053,
            "fmeasure": 0.69182
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.42105263157894735,
            "3": 0.8419811320754716
        },
        "nist": 7.087688699543685,
        "bleu": 54.09339,
        "bleurt": 0.31366,
        "nubia": {
            "semantic_relation": 4.28708,
            "contradiction": 9.37355,
            "irrelevancy": 27.50915,
            "logical_agreement": 63.11731,
            "grammar_ref": 4.51918,
            "grammar_hyp": 4.48384,
            "nubia_score": 0.76887
        },
        "meteor": 0.4186998394222635,
        "bertscore": {
            "precision": 0.93388,
            "recall": 0.93648,
            "f1": 0.93325
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_47": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 0.5,
        "median_pred_length": 15.5,
        "min_pred_length": 15,
        "max_pred_length": 16,
        "distinct-1": 0.7741935483870968,
        "vocab_size-1": 24,
        "unique-1": 20,
        "entropy-1": 4.413716068381602,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 28,
        "unique-2": 27,
        "entropy-2": 4.789015477886192,
        "cond_entropy-2": 0.3436083917118512,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.029019418890029347,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7931034482758621,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.349191770915039,
        "distinct-2-nopunct": 0.9629629629629629,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.6808134280893965,
        "cond_entropy-2-nopunct": 0.3693097478567659,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.031031312388743983,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76261,
            "recall": 0.76623,
            "fmeasure": 0.75474
        },
        "rouge2": {
            "precision": 0.55048,
            "recall": 0.575,
            "fmeasure": 0.55435
        },
        "rougeL": {
            "precision": 0.61555,
            "recall": 0.64719,
            "fmeasure": 0.62316
        },
        "rougeLsum": {
            "precision": 0.61555,
            "recall": 0.64719,
            "fmeasure": 0.62316
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7692307692307693
        },
        "nist": 3.5804241896377875,
        "bleu": 39.83704,
        "bleurt": 0.47875,
        "nubia": {
            "semantic_relation": 4.62266,
            "contradiction": 0.33145,
            "irrelevancy": 2.74251,
            "logical_agreement": 96.92604,
            "grammar_ref": 5.14789,
            "grammar_hyp": 5.11288,
            "nubia_score": 0.80103
        },
        "meteor": 0.37989027778728746,
        "bertscore": {
            "precision": 0.94668,
            "recall": 0.95226,
            "f1": 0.94913
        }
    },
    "schema_guided_dialog_challenge_test_backtranslation_parent": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.68906,
        "msttr-100_nopunct": 0.71643,
        "total_length": 6413,
        "mean_pred_length": 12.826,
        "std_pred_length": 7.338100844223933,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 40,
        "distinct-1": 0.15577732730391392,
        "vocab_size-1": 999,
        "unique-1": 570,
        "entropy-1": 7.796863430805654,
        "distinct-2": 0.4828344326061221,
        "vocab_size-2": 2855,
        "unique-2": 2020,
        "entropy-2": 10.64572623343344,
        "cond_entropy-2": 2.6014659939243727,
        "distinct-3": 0.6938850914465177,
        "vocab_size-3": 3756,
        "unique-3": 3117,
        "entropy-3": 11.433583879857524,
        "cond_entropy-3": 0.8070709335627287,
        "total_length-nopunct": 5605,
        "mean_pred_length-nopunct": 11.21,
        "std_pred_length-nopunct": 6.724128196279426,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.175914362176628,
        "vocab_size-1-nopunct": 986,
        "unique-1-nopunct": 566,
        "entropy-1-nopunct": 7.986878422711142,
        "distinct-2-nopunct": 0.5030362389813908,
        "vocab_size-2-nopunct": 2568,
        "unique-2-nopunct": 1874,
        "entropy-2-nopunct": 10.480842601892235,
        "cond_entropy-2-nopunct": 2.62583398298365,
        "distinct-3-nopunct": 0.7105320304017373,
        "vocab_size-3-nopunct": 3272,
        "unique-3-nopunct": 2772,
        "entropy-3-nopunct": 11.230772575875172,
        "cond_entropy-3-nopunct": 0.7829544501145577,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.55874,
            "recall": 0.55341,
            "fmeasure": 0.54353
        },
        "rouge2": {
            "precision": 0.34605,
            "recall": 0.34605,
            "fmeasure": 0.33769
        },
        "rougeL": {
            "precision": 0.50031,
            "recall": 0.49519,
            "fmeasure": 0.48698
        },
        "rougeLsum": {
            "precision": 0.50031,
            "recall": 0.49519,
            "fmeasure": 0.48698
        },
        "local_recall": {
            "1": 0.5723293768545994
        },
        "nist": 5.975664225257276,
        "bleu": 32.18938,
        "bleurt": -0.07655,
        "nubia": {
            "semantic_relation": 3.61505,
            "contradiction": 6.36006,
            "irrelevancy": 23.62368,
            "logical_agreement": 70.01625,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.54235,
            "nubia_score": 0.64734
        },
        "meteor": 0.3202588331679364,
        "bertscore": {
            "precision": 0.87025,
            "recall": 0.867,
            "f1": 0.86808
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 136,
        "msttr-100": 0.65409,
        "msttr-100_nopunct": 0.69316,
        "total_length": 2266,
        "mean_pred_length": 16.66176470588235,
        "std_pred_length": 7.2255883011404585,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 54,
        "distinct-1": 0.3702559576345984,
        "vocab_size-1": 839,
        "unique-1": 657,
        "entropy-1": 7.7695307449517585,
        "distinct-2": 0.7018779342723005,
        "vocab_size-2": 1495,
        "unique-2": 1332,
        "entropy-2": 9.880479441119745,
        "cond_entropy-2": 1.8719884166506577,
        "distinct-3": 0.8104312938816449,
        "vocab_size-3": 1616,
        "unique-3": 1516,
        "entropy-3": 10.22280365695814,
        "cond_entropy-3": 0.3896204970676894,
        "total_length-nopunct": 1960,
        "mean_pred_length-nopunct": 14.411764705882353,
        "std_pred_length-nopunct": 6.167360227839038,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.42397959183673467,
        "vocab_size-1-nopunct": 831,
        "unique-1-nopunct": 656,
        "entropy-1-nopunct": 8.03761518496413,
        "distinct-2-nopunct": 0.7110745614035088,
        "vocab_size-2-nopunct": 1297,
        "unique-2-nopunct": 1172,
        "entropy-2-nopunct": 9.664951989532948,
        "cond_entropy-2-nopunct": 1.7635330362382886,
        "distinct-3-nopunct": 0.8145734597156398,
        "vocab_size-3-nopunct": 1375,
        "unique-3-nopunct": 1301,
        "entropy-3-nopunct": 9.988178504768165,
        "cond_entropy-3-nopunct": 0.39520005621874565,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77255,
            "recall": 0.75759,
            "fmeasure": 0.7562
        },
        "rouge2": {
            "precision": 0.56063,
            "recall": 0.55002,
            "fmeasure": 0.54899
        },
        "rougeL": {
            "precision": 0.68509,
            "recall": 0.67198,
            "fmeasure": 0.67042
        },
        "rougeLsum": {
            "precision": 0.68509,
            "recall": 0.67198,
            "fmeasure": 0.67042
        },
        "local_recall": {
            "1": 0.2623376623376623,
            "2": 0.474025974025974,
            "3": 0.8025122121423587
        },
        "nist": 7.770031324522535,
        "bleu": 51.64081,
        "bleurt": 0.3702,
        "nubia": {
            "semantic_relation": 4.2378,
            "contradiction": 7.9132,
            "irrelevancy": 24.28557,
            "logical_agreement": 67.80123,
            "grammar_ref": 4.4992,
            "grammar_hyp": 4.39247,
            "nubia_score": 0.76186
        },
        "meteor": 0.41353921201399507,
        "bertscore": {
            "precision": 0.93598,
            "recall": 0.93217,
            "f1": 0.93243
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 986,
        "msttr-100": 0.44265,
        "msttr-100_nopunct": 0.4382,
        "total_length": 43487,
        "mean_pred_length": 44.10446247464503,
        "std_pred_length": 19.93000531691253,
        "median_pred_length": 43.0,
        "min_pred_length": 6,
        "max_pred_length": 85,
        "distinct-1": 0.05502793938418378,
        "vocab_size-1": 2393,
        "unique-1": 877,
        "entropy-1": 5.992630861764926,
        "distinct-2": 0.16154914002023482,
        "vocab_size-2": 6866,
        "unique-2": 3352,
        "entropy-2": 10.384565591270382,
        "cond_entropy-2": 4.3880587881964095,
        "distinct-3": 0.3062507527399735,
        "vocab_size-3": 12714,
        "unique-3": 7363,
        "entropy-3": 12.209471818446186,
        "cond_entropy-3": 1.8660457360548133,
        "total_length-nopunct": 40067,
        "mean_pred_length-nopunct": 40.63590263691684,
        "std_pred_length-nopunct": 18.838167662998504,
        "median_pred_length-nopunct": 39.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 80,
        "distinct-1-nopunct": 0.05947537874060948,
        "vocab_size-1-nopunct": 2383,
        "unique-1-nopunct": 877,
        "entropy-1-nopunct": 5.90265190143697,
        "distinct-2-nopunct": 0.16230393285739875,
        "vocab_size-2-nopunct": 6343,
        "unique-2-nopunct": 3094,
        "entropy-2-nopunct": 10.257795680583962,
        "cond_entropy-2-nopunct": 4.444383847456429,
        "distinct-3-nopunct": 0.30765192282451764,
        "vocab_size-3-nopunct": 11720,
        "unique-3-nopunct": 6909,
        "entropy-3-nopunct": 12.043951926331642,
        "cond_entropy-3-nopunct": 1.826476310506197,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.45387,
            "recall": 0.43825,
            "fmeasure": 0.43885
        },
        "rouge2": {
            "precision": 0.22765,
            "recall": 0.22142,
            "fmeasure": 0.22107
        },
        "rougeL": {
            "precision": 0.42796,
            "recall": 0.4147,
            "fmeasure": 0.41429
        },
        "rougeLsum": {
            "precision": 0.42796,
            "recall": 0.4147,
            "fmeasure": 0.41429
        },
        "local_recall": {
            "1": 0.09178586023702492,
            "2": 0.18632185698706963,
            "3": 0.2697340650063318,
            "4": 0.19480519480519481,
            "5": 0.2702702702702703,
            "6": 0.15384615384615385,
            "7": 0.2222222222222222
        },
        "nist": 1.1702163416419626,
        "bleu": 2.1705,
        "bleurt": -0.47985,
        "nubia": {
            "semantic_relation": 3.30684,
            "contradiction": 33.88588,
            "irrelevancy": 17.19544,
            "logical_agreement": 48.91868,
            "grammar_ref": 2.66553,
            "grammar_hyp": 2.65966,
            "nubia_score": 0.15793
        },
        "meteor": 0.12915567647729828,
        "bertscore": {
            "precision": 0.86132,
            "recall": 0.87281,
            "f1": 0.86652
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_48": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 114,
        "msttr-100": 0.73444,
        "msttr-100_nopunct": 0.7775,
        "total_length": 1863,
        "mean_pred_length": 16.342105263157894,
        "std_pred_length": 6.360278250793448,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 49,
        "distinct-1": 0.47611379495437467,
        "vocab_size-1": 887,
        "unique-1": 713,
        "entropy-1": 8.333618901523769,
        "distinct-2": 0.8822184105202973,
        "vocab_size-2": 1543,
        "unique-2": 1434,
        "entropy-2": 10.44110062542392,
        "cond_entropy-2": 1.8270054214019371,
        "distinct-3": 0.9779816513761468,
        "vocab_size-3": 1599,
        "unique-3": 1569,
        "entropy-3": 10.627445377277521,
        "cond_entropy-3": 0.18005685589789786,
        "total_length-nopunct": 1631,
        "mean_pred_length-nopunct": 14.307017543859649,
        "std_pred_length-nopunct": 5.766094474678704,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.5383200490496628,
        "vocab_size-1-nopunct": 878,
        "unique-1-nopunct": 711,
        "entropy-1-nopunct": 8.62554663063739,
        "distinct-2-nopunct": 0.8938694792353329,
        "vocab_size-2-nopunct": 1356,
        "unique-2-nopunct": 1273,
        "entropy-2-nopunct": 10.260469269424268,
        "cond_entropy-2-nopunct": 1.7412264157067907,
        "distinct-3-nopunct": 0.9843193157519601,
        "vocab_size-3-nopunct": 1381,
        "unique-3-nopunct": 1360,
        "entropy-3-nopunct": 10.42239987273476,
        "cond_entropy-3-nopunct": 0.1804232016665212,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74925,
            "recall": 0.69451,
            "fmeasure": 0.70758
        },
        "rouge2": {
            "precision": 0.48748,
            "recall": 0.45074,
            "fmeasure": 0.45959
        },
        "rougeL": {
            "precision": 0.62465,
            "recall": 0.58387,
            "fmeasure": 0.59235
        },
        "rougeLsum": {
            "precision": 0.62465,
            "recall": 0.58387,
            "fmeasure": 0.59235
        },
        "local_recall": {
            "1": 0.1890547263681592,
            "2": 0.4746192893401015,
            "3": 0.7436347673397717
        },
        "nist": 7.128889186505508,
        "bleu": 38.13952,
        "bleurt": 0.18305,
        "nubia": {
            "semantic_relation": 4.10786,
            "contradiction": 10.37577,
            "irrelevancy": 31.07334,
            "logical_agreement": 58.55089,
            "grammar_ref": 4.6714,
            "grammar_hyp": 4.72267,
            "nubia_score": 0.69138
        },
        "meteor": 0.36233783726390684,
        "bertscore": {
            "precision": 0.91925,
            "recall": 0.91678,
            "f1": 0.91704
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_54": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 80,
        "msttr-100": 0.71071,
        "msttr-100_nopunct": 0.76917,
        "total_length": 1493,
        "mean_pred_length": 18.6625,
        "std_pred_length": 9.135020183338403,
        "median_pred_length": 15.5,
        "min_pred_length": 6,
        "max_pred_length": 60,
        "distinct-1": 0.4608171466845278,
        "vocab_size-1": 688,
        "unique-1": 540,
        "entropy-1": 8.082477736223359,
        "distinct-2": 0.8527954706298655,
        "vocab_size-2": 1205,
        "unique-2": 1098,
        "entropy-2": 10.066297114398807,
        "cond_entropy-2": 1.7652542044469128,
        "distinct-3": 0.9549887471867967,
        "vocab_size-3": 1273,
        "unique-3": 1227,
        "entropy-3": 10.282142497927643,
        "cond_entropy-3": 0.21797617187582177,
        "total_length-nopunct": 1290,
        "mean_pred_length-nopunct": 16.125,
        "std_pred_length-nopunct": 7.386431817867136,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.5279069767441861,
        "vocab_size-1-nopunct": 681,
        "unique-1-nopunct": 538,
        "entropy-1-nopunct": 8.369239160903504,
        "distinct-2-nopunct": 0.8652892561983471,
        "vocab_size-2-nopunct": 1047,
        "unique-2-nopunct": 967,
        "entropy-2-nopunct": 9.864071109362897,
        "cond_entropy-2-nopunct": 1.5836956480051994,
        "distinct-3-nopunct": 0.9584070796460177,
        "vocab_size-3-nopunct": 1083,
        "unique-3-nopunct": 1046,
        "entropy-3-nopunct": 10.052240796221437,
        "cond_entropy-3-nopunct": 0.21130032210112534,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71546,
            "recall": 0.69768,
            "fmeasure": 0.69248
        },
        "rouge2": {
            "precision": 0.4586,
            "recall": 0.4502,
            "fmeasure": 0.44448
        },
        "rougeL": {
            "precision": 0.60617,
            "recall": 0.5986,
            "fmeasure": 0.5896
        },
        "rougeLsum": {
            "precision": 0.60617,
            "recall": 0.5986,
            "fmeasure": 0.5896
        },
        "local_recall": {
            "1": 0.2937853107344633,
            "2": 0.5146198830409356,
            "3": 0.7296248382923674
        },
        "nist": 7.108261953452079,
        "bleu": 43.04445,
        "bleurt": 0.13515,
        "nubia": {
            "semantic_relation": 3.96217,
            "contradiction": 12.7235,
            "irrelevancy": 35.06921,
            "logical_agreement": 52.2073,
            "grammar_ref": 4.56456,
            "grammar_hyp": 4.4677,
            "nubia_score": 0.65122
        },
        "meteor": 0.3641420204923981,
        "bertscore": {
            "precision": 0.9111,
            "recall": 0.91139,
            "f1": 0.90905
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_49": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.775,
        "total_length": 291,
        "mean_pred_length": 16.166666666666668,
        "std_pred_length": 7.71182353417285,
        "median_pred_length": 12.5,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.6323024054982818,
        "vocab_size-1": 184,
        "unique-1": 154,
        "entropy-1": 6.895766002135262,
        "distinct-2": 0.9487179487179487,
        "vocab_size-2": 259,
        "unique-2": 249,
        "entropy-2": 7.970010712332538,
        "cond_entropy-2": 0.8791577977135377,
        "distinct-3": 0.996078431372549,
        "vocab_size-3": 254,
        "unique-3": 253,
        "entropy-3": 7.986510299603968,
        "cond_entropy-3": 0.02516404105401317,
        "total_length-nopunct": 256,
        "mean_pred_length-nopunct": 14.222222222222221,
        "std_pred_length-nopunct": 6.964637308539919,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6953125,
        "vocab_size-1-nopunct": 178,
        "unique-1-nopunct": 152,
        "entropy-1-nopunct": 6.973006170292209,
        "distinct-2-nopunct": 0.9495798319327731,
        "vocab_size-2-nopunct": 226,
        "unique-2-nopunct": 218,
        "entropy-2-nopunct": 7.770827112029304,
        "cond_entropy-2-nopunct": 0.8520265149892293,
        "distinct-3-nopunct": 0.9954545454545455,
        "vocab_size-3-nopunct": 219,
        "unique-3-nopunct": 218,
        "entropy-3-nopunct": 7.772268804433734,
        "cond_entropy-3-nopunct": 0.011586382054565863,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73766,
            "recall": 0.60988,
            "fmeasure": 0.64517
        },
        "rouge2": {
            "precision": 0.48092,
            "recall": 0.39008,
            "fmeasure": 0.41352
        },
        "rougeL": {
            "precision": 0.62449,
            "recall": 0.51989,
            "fmeasure": 0.5465
        },
        "rougeLsum": {
            "precision": 0.62449,
            "recall": 0.51989,
            "fmeasure": 0.5465
        },
        "local_recall": {
            "1": 0.21359223300970873,
            "2": 0.36363636363636365,
            "3": 0.6989795918367347
        },
        "nist": 5.601623926728097,
        "bleu": 35.11604,
        "bleurt": -0.03615,
        "nubia": {
            "semantic_relation": 3.82191,
            "contradiction": 9.29017,
            "irrelevancy": 40.3223,
            "logical_agreement": 50.38753,
            "grammar_ref": 4.5439,
            "grammar_hyp": 4.78914,
            "nubia_score": 0.59799
        },
        "meteor": 0.33284928376965267,
        "bertscore": {
            "precision": 0.91208,
            "recall": 0.89085,
            "f1": 0.9001
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_99": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.765,
        "total_length": 268,
        "mean_pred_length": 19.142857142857142,
        "std_pred_length": 8.500900312463909,
        "median_pred_length": 16.5,
        "min_pred_length": 8,
        "max_pred_length": 39,
        "distinct-1": 0.6194029850746269,
        "vocab_size-1": 166,
        "unique-1": 138,
        "entropy-1": 6.749373822983726,
        "distinct-2": 0.9409448818897638,
        "vocab_size-2": 239,
        "unique-2": 227,
        "entropy-2": 7.861658456431618,
        "cond_entropy-2": 0.9750052879196814,
        "distinct-3": 0.9916666666666667,
        "vocab_size-3": 238,
        "unique-3": 236,
        "entropy-3": 7.890223928941896,
        "cond_entropy-3": 0.0359753359467294,
        "total_length-nopunct": 234,
        "mean_pred_length-nopunct": 16.714285714285715,
        "std_pred_length-nopunct": 7.468300355775846,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.688034188034188,
        "vocab_size-1-nopunct": 161,
        "unique-1-nopunct": 136,
        "entropy-1-nopunct": 6.872173482086671,
        "distinct-2-nopunct": 0.9454545454545454,
        "vocab_size-2-nopunct": 208,
        "unique-2-nopunct": 199,
        "entropy-2-nopunct": 7.661974883949689,
        "cond_entropy-2-nopunct": 0.827936469245895,
        "distinct-3-nopunct": 0.9902912621359223,
        "vocab_size-3-nopunct": 204,
        "unique-3-nopunct": 202,
        "entropy-3-nopunct": 7.667083051455062,
        "cond_entropy-3-nopunct": 0.005527706890448421,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.6924,
            "recall": 0.66619,
            "fmeasure": 0.66881
        },
        "rouge2": {
            "precision": 0.4107,
            "recall": 0.41039,
            "fmeasure": 0.40201
        },
        "rougeL": {
            "precision": 0.59058,
            "recall": 0.58252,
            "fmeasure": 0.57611
        },
        "rougeLsum": {
            "precision": 0.59058,
            "recall": 0.58252,
            "fmeasure": 0.57611
        },
        "local_recall": {
            "1": 0.1864406779661017,
            "2": 0.2391304347826087,
            "3": 0.7151515151515152
        },
        "nist": 5.097415325548312,
        "bleu": 30.27747,
        "bleurt": 0.14557,
        "nubia": {
            "semantic_relation": 3.81314,
            "contradiction": 13.87673,
            "irrelevancy": 27.46771,
            "logical_agreement": 58.65556,
            "grammar_ref": 4.70274,
            "grammar_hyp": 4.2661,
            "nubia_score": 0.65888
        },
        "meteor": 0.3363381532487653,
        "bertscore": {
            "precision": 0.90301,
            "recall": 0.90266,
            "f1": 0.90096
        }
    },
    "totto_test_contrast_challenge_continent-europe": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 150,
        "msttr-100": 0.71083,
        "msttr-100_nopunct": 0.76333,
        "total_length": 2467,
        "mean_pred_length": 16.446666666666665,
        "std_pred_length": 6.6898297603318895,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 42,
        "distinct-1": 0.40535062829347385,
        "vocab_size-1": 1000,
        "unique-1": 783,
        "entropy-1": 8.230487614792333,
        "distinct-2": 0.8006042296072508,
        "vocab_size-2": 1855,
        "unique-2": 1671,
        "entropy-2": 10.553520327889435,
        "cond_entropy-2": 2.051106708318857,
        "distinct-3": 0.9395477618827872,
        "vocab_size-3": 2036,
        "unique-3": 1955,
        "entropy-3": 10.934574363384199,
        "cond_entropy-3": 0.3796849063903536,
        "total_length-nopunct": 2156,
        "mean_pred_length-nopunct": 14.373333333333333,
        "std_pred_length-nopunct": 5.805223701307488,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.461038961038961,
        "vocab_size-1-nopunct": 994,
        "unique-1-nopunct": 782,
        "entropy-1-nopunct": 8.535504613076478,
        "distinct-2-nopunct": 0.8175473579262214,
        "vocab_size-2-nopunct": 1640,
        "unique-2-nopunct": 1501,
        "entropy-2-nopunct": 10.37713268427875,
        "cond_entropy-2-nopunct": 1.9453370646100472,
        "distinct-3-nopunct": 0.9515086206896551,
        "vocab_size-3-nopunct": 1766,
        "unique-3-nopunct": 1712,
        "entropy-3-nopunct": 10.738111565216391,
        "cond_entropy-3-nopunct": 0.38843700311270124,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7874,
            "recall": 0.76336,
            "fmeasure": 0.76564
        },
        "rouge2": {
            "precision": 0.54605,
            "recall": 0.53002,
            "fmeasure": 0.53043
        },
        "rougeL": {
            "precision": 0.67145,
            "recall": 0.65407,
            "fmeasure": 0.65405
        },
        "rougeLsum": {
            "precision": 0.67145,
            "recall": 0.65407,
            "fmeasure": 0.65405
        },
        "local_recall": {
            "1": 0.20043103448275862,
            "2": 0.42162162162162165,
            "3": 0.8095238095238095
        },
        "nist": 8.082103614578545,
        "bleu": 46.07391,
        "bleurt": 0.34553,
        "nubia": {
            "semantic_relation": 4.43171,
            "contradiction": 4.07202,
            "irrelevancy": 25.04606,
            "logical_agreement": 70.88192,
            "grammar_ref": 4.85127,
            "grammar_hyp": 4.8512,
            "nubia_score": 0.78495
        },
        "meteor": 0.4111625376116683,
        "bertscore": {
            "precision": 0.93511,
            "recall": 0.93587,
            "f1": 0.93392
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_75": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 44,
        "msttr-100": 0.72286,
        "msttr-100_nopunct": 0.78333,
        "total_length": 781,
        "mean_pred_length": 17.75,
        "std_pred_length": 8.110388960519039,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 43,
        "distinct-1": 0.5198463508322664,
        "vocab_size-1": 406,
        "unique-1": 325,
        "entropy-1": 7.667030686730565,
        "distinct-2": 0.8900949796472184,
        "vocab_size-2": 656,
        "unique-2": 600,
        "entropy-2": 9.26440448886271,
        "cond_entropy-2": 1.3873867234917536,
        "distinct-3": 0.9552669552669553,
        "vocab_size-3": 662,
        "unique-3": 634,
        "entropy-3": 9.343977541406456,
        "cond_entropy-3": 0.08351855122765828,
        "total_length-nopunct": 675,
        "mean_pred_length-nopunct": 15.340909090909092,
        "std_pred_length-nopunct": 7.153966419909313,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.5925925925925926,
        "vocab_size-1-nopunct": 400,
        "unique-1-nopunct": 325,
        "entropy-1-nopunct": 7.891984938045335,
        "distinct-2-nopunct": 0.9001584786053882,
        "vocab_size-2-nopunct": 568,
        "unique-2-nopunct": 529,
        "entropy-2-nopunct": 9.053987374848253,
        "cond_entropy-2-nopunct": 1.2276882690757336,
        "distinct-3-nopunct": 0.9659284497444633,
        "vocab_size-3-nopunct": 567,
        "unique-3-nopunct": 548,
        "entropy-3-nopunct": 9.127787583225713,
        "cond_entropy-3-nopunct": 0.08084535417588148,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77171,
            "recall": 0.78858,
            "fmeasure": 0.77045
        },
        "rouge2": {
            "precision": 0.53858,
            "recall": 0.56337,
            "fmeasure": 0.54427
        },
        "rougeL": {
            "precision": 0.6914,
            "recall": 0.70668,
            "fmeasure": 0.68991
        },
        "rougeLsum": {
            "precision": 0.6914,
            "recall": 0.70668,
            "fmeasure": 0.68991
        },
        "local_recall": {
            "1": 0.25742574257425743,
            "2": 0.56,
            "3": 0.8056155507559395
        },
        "nist": 6.962108959687219,
        "bleu": 48.93156,
        "bleurt": 0.36718,
        "nubia": {
            "semantic_relation": 4.44109,
            "contradiction": 4.38164,
            "irrelevancy": 28.51993,
            "logical_agreement": 67.09843,
            "grammar_ref": 4.70505,
            "grammar_hyp": 4.58585,
            "nubia_score": 0.80618
        },
        "meteor": 0.42037675325481016,
        "bertscore": {
            "precision": 0.92869,
            "recall": 0.93466,
            "f1": 0.93028
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_100": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 48,
        "msttr-100": 0.72286,
        "msttr-100_nopunct": 0.785,
        "total_length": 765,
        "mean_pred_length": 15.9375,
        "std_pred_length": 6.388160435524456,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 35,
        "distinct-1": 0.5320261437908497,
        "vocab_size-1": 407,
        "unique-1": 336,
        "entropy-1": 7.598527423134442,
        "distinct-2": 0.9065550906555091,
        "vocab_size-2": 650,
        "unique-2": 612,
        "entropy-2": 9.243427141662984,
        "cond_entropy-2": 1.403616104384697,
        "distinct-3": 0.9865470852017937,
        "vocab_size-3": 660,
        "unique-3": 653,
        "entropy-3": 9.356699807211914,
        "cond_entropy-3": 0.11032148997857041,
        "total_length-nopunct": 665,
        "mean_pred_length-nopunct": 13.854166666666666,
        "std_pred_length-nopunct": 5.450495326624504,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.6045112781954888,
        "vocab_size-1-nopunct": 402,
        "unique-1-nopunct": 335,
        "entropy-1-nopunct": 7.837809992717125,
        "distinct-2-nopunct": 0.9092382495948136,
        "vocab_size-2-nopunct": 561,
        "unique-2-nopunct": 530,
        "entropy-2-nopunct": 9.030167480137662,
        "cond_entropy-2-nopunct": 1.2788752358871514,
        "distinct-3-nopunct": 0.9929701230228472,
        "vocab_size-3-nopunct": 565,
        "unique-3-nopunct": 562,
        "entropy-3-nopunct": 9.136898396784451,
        "cond_entropy-3-nopunct": 0.12161675417315906,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79364,
            "recall": 0.75977,
            "fmeasure": 0.76592
        },
        "rouge2": {
            "precision": 0.55019,
            "recall": 0.54354,
            "fmeasure": 0.53915
        },
        "rougeL": {
            "precision": 0.65322,
            "recall": 0.62996,
            "fmeasure": 0.63248
        },
        "rougeLsum": {
            "precision": 0.65322,
            "recall": 0.62996,
            "fmeasure": 0.63248
        },
        "local_recall": {
            "1": 0.19463087248322147,
            "2": 0.3875,
            "3": 0.805940594059406
        },
        "nist": 7.163948854522909,
        "bleu": 45.14366,
        "bleurt": 0.30959,
        "nubia": {
            "semantic_relation": 4.2469,
            "contradiction": 9.594,
            "irrelevancy": 23.11955,
            "logical_agreement": 67.28645,
            "grammar_ref": 4.77611,
            "grammar_hyp": 4.934,
            "nubia_score": 0.72907
        },
        "meteor": 0.3974016393179882,
        "bertscore": {
            "precision": 0.93574,
            "recall": 0.93212,
            "f1": 0.93329
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_16": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 111,
        "msttr-100": 0.67316,
        "msttr-100_nopunct": 0.70875,
        "total_length": 1923,
        "mean_pred_length": 17.324324324324323,
        "std_pred_length": 7.8409437772654105,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 53,
        "distinct-1": 0.39469578783151327,
        "vocab_size-1": 759,
        "unique-1": 618,
        "entropy-1": 7.758444134381069,
        "distinct-2": 0.7251655629139073,
        "vocab_size-2": 1314,
        "unique-2": 1186,
        "entropy-2": 9.79985087153054,
        "cond_entropy-2": 1.8181989105345895,
        "distinct-3": 0.8342151675485009,
        "vocab_size-3": 1419,
        "unique-3": 1354,
        "entropy-3": 10.116208078932713,
        "cond_entropy-3": 0.33828072685744787,
        "total_length-nopunct": 1643,
        "mean_pred_length-nopunct": 14.801801801801801,
        "std_pred_length-nopunct": 6.582559292828311,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.45587340231284235,
        "vocab_size-1-nopunct": 749,
        "unique-1-nopunct": 615,
        "entropy-1-nopunct": 8.007484650891739,
        "distinct-2-nopunct": 0.7447780678851175,
        "vocab_size-2-nopunct": 1141,
        "unique-2-nopunct": 1053,
        "entropy-2-nopunct": 9.592141735297227,
        "cond_entropy-2-nopunct": 1.6964062617299083,
        "distinct-3-nopunct": 0.8409570724841661,
        "vocab_size-3-nopunct": 1195,
        "unique-3-nopunct": 1149,
        "entropy-3-nopunct": 9.867864277869126,
        "cond_entropy-3-nopunct": 0.32201931698742625,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80039,
            "recall": 0.76567,
            "fmeasure": 0.77177
        },
        "rouge2": {
            "precision": 0.59599,
            "recall": 0.56704,
            "fmeasure": 0.57465
        },
        "rougeL": {
            "precision": 0.70837,
            "recall": 0.67669,
            "fmeasure": 0.6827
        },
        "rougeLsum": {
            "precision": 0.70837,
            "recall": 0.67669,
            "fmeasure": 0.6827
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.46296296296296297,
            "3": 0.8036711891460495
        },
        "nist": 7.8806856173870665,
        "bleu": 54.04203,
        "bleurt": 0.39583,
        "nubia": {
            "semantic_relation": 4.32128,
            "contradiction": 4.04718,
            "irrelevancy": 21.29177,
            "logical_agreement": 74.66106,
            "grammar_ref": 4.48776,
            "grammar_hyp": 4.53278,
            "nubia_score": 0.77218
        },
        "meteor": 0.42014584305628905,
        "bertscore": {
            "precision": 0.93762,
            "recall": 0.93317,
            "f1": 0.93328
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_102": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 24,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.78667,
        "total_length": 398,
        "mean_pred_length": 16.583333333333332,
        "std_pred_length": 4.75146176338281,
        "median_pred_length": 16.5,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.6080402010050251,
        "vocab_size-1": 242,
        "unique-1": 209,
        "entropy-1": 7.094137665421767,
        "distinct-2": 0.9331550802139037,
        "vocab_size-2": 349,
        "unique-2": 335,
        "entropy-2": 8.375063811474513,
        "cond_entropy-2": 1.0856870736079232,
        "distinct-3": 0.9857142857142858,
        "vocab_size-3": 345,
        "unique-3": 340,
        "entropy-3": 8.422639683260922,
        "cond_entropy-3": 0.053644259106093196,
        "total_length-nopunct": 346,
        "mean_pred_length-nopunct": 14.416666666666666,
        "std_pred_length-nopunct": 4.261422558515199,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.684971098265896,
        "vocab_size-1-nopunct": 237,
        "unique-1-nopunct": 207,
        "entropy-1-nopunct": 7.292796159342703,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 299,
        "unique-2-nopunct": 287,
        "entropy-2-nopunct": 8.143759541137978,
        "cond_entropy-2-nopunct": 0.9200132098623425,
        "distinct-3-nopunct": 0.9865771812080537,
        "vocab_size-3-nopunct": 294,
        "unique-3-nopunct": 290,
        "entropy-3-nopunct": 8.19232288287824,
        "cond_entropy-3-nopunct": 0.06363641585925757,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79753,
            "recall": 0.7316,
            "fmeasure": 0.75042
        },
        "rouge2": {
            "precision": 0.48767,
            "recall": 0.45574,
            "fmeasure": 0.46274
        },
        "rougeL": {
            "precision": 0.65205,
            "recall": 0.60673,
            "fmeasure": 0.61941
        },
        "rougeLsum": {
            "precision": 0.65205,
            "recall": 0.60673,
            "fmeasure": 0.61941
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.40860215053763443,
            "3": 0.831275720164609
        },
        "nist": 6.409001608470418,
        "bleu": 43.42021,
        "bleurt": 0.15223,
        "nubia": {
            "semantic_relation": 4.18125,
            "contradiction": 8.5714,
            "irrelevancy": 30.61083,
            "logical_agreement": 60.81777,
            "grammar_ref": 4.72162,
            "grammar_hyp": 4.73905,
            "nubia_score": 0.71312
        },
        "meteor": 0.3852844650989374,
        "bertscore": {
            "precision": 0.9267,
            "recall": 0.91708,
            "f1": 0.92044
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_55": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 73,
        "msttr-100": 0.7075,
        "msttr-100_nopunct": 0.759,
        "total_length": 1228,
        "mean_pred_length": 16.82191780821918,
        "std_pred_length": 7.181296990028886,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.46986970684039087,
        "vocab_size-1": 577,
        "unique-1": 439,
        "entropy-1": 7.938773343935898,
        "distinct-2": 0.8467532467532467,
        "vocab_size-2": 978,
        "unique-2": 872,
        "entropy-2": 9.779254473759933,
        "cond_entropy-2": 1.593640181943847,
        "distinct-3": 0.9371534195933456,
        "vocab_size-3": 1014,
        "unique-3": 955,
        "entropy-3": 9.945816400755461,
        "cond_entropy-3": 0.14843483125545393,
        "total_length-nopunct": 1053,
        "mean_pred_length-nopunct": 14.424657534246576,
        "std_pred_length-nopunct": 6.296156270839122,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.540360873694207,
        "vocab_size-1-nopunct": 569,
        "unique-1-nopunct": 438,
        "entropy-1-nopunct": 8.199590801799145,
        "distinct-2-nopunct": 0.863265306122449,
        "vocab_size-2-nopunct": 846,
        "unique-2-nopunct": 768,
        "entropy-2-nopunct": 9.577421216755187,
        "cond_entropy-2-nopunct": 1.4582625010641492,
        "distinct-3-nopunct": 0.9470782800441014,
        "vocab_size-3-nopunct": 859,
        "unique-3-nopunct": 817,
        "entropy-3-nopunct": 9.713581066869718,
        "cond_entropy-3-nopunct": 0.14393592037084613,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80757,
            "recall": 0.7596,
            "fmeasure": 0.77042
        },
        "rouge2": {
            "precision": 0.61129,
            "recall": 0.5738,
            "fmeasure": 0.58109
        },
        "rougeL": {
            "precision": 0.72371,
            "recall": 0.6879,
            "fmeasure": 0.69273
        },
        "rougeLsum": {
            "precision": 0.72371,
            "recall": 0.6879,
            "fmeasure": 0.69273
        },
        "local_recall": {
            "1": 0.26976744186046514,
            "2": 0.463855421686747,
            "3": 0.7854545454545454
        },
        "nist": 7.7509540525728395,
        "bleu": 53.20071,
        "bleurt": 0.27708,
        "nubia": {
            "semantic_relation": 4.2141,
            "contradiction": 5.42107,
            "irrelevancy": 30.52099,
            "logical_agreement": 64.05793,
            "grammar_ref": 4.56245,
            "grammar_hyp": 4.60631,
            "nubia_score": 0.75192
        },
        "meteor": 0.41290377296182457,
        "bertscore": {
            "precision": 0.93906,
            "recall": 0.92736,
            "f1": 0.93146
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_76": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 33,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.7725,
        "total_length": 558,
        "mean_pred_length": 16.90909090909091,
        "std_pred_length": 5.333505506862775,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 34,
        "distinct-1": 0.5698924731182796,
        "vocab_size-1": 318,
        "unique-1": 275,
        "entropy-1": 7.296879029242588,
        "distinct-2": 0.9238095238095239,
        "vocab_size-2": 485,
        "unique-2": 463,
        "entropy-2": 8.829451088719216,
        "cond_entropy-2": 1.3303510868796105,
        "distinct-3": 0.9857723577235772,
        "vocab_size-3": 485,
        "unique-3": 478,
        "entropy-3": 8.914059220786294,
        "cond_entropy-3": 0.08880926171018089,
        "total_length-nopunct": 482,
        "mean_pred_length-nopunct": 14.606060606060606,
        "std_pred_length-nopunct": 4.605263088851605,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6473029045643154,
        "vocab_size-1-nopunct": 312,
        "unique-1-nopunct": 274,
        "entropy-1-nopunct": 7.481509037966868,
        "distinct-2-nopunct": 0.933184855233853,
        "vocab_size-2-nopunct": 419,
        "unique-2-nopunct": 404,
        "entropy-2-nopunct": 8.619537252757173,
        "cond_entropy-2-nopunct": 1.2298668558652617,
        "distinct-3-nopunct": 0.9903846153846154,
        "vocab_size-3-nopunct": 412,
        "unique-3-nopunct": 408,
        "entropy-3-nopunct": 8.6812089489103,
        "cond_entropy-3-nopunct": 0.07682586587787103,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81667,
            "recall": 0.77914,
            "fmeasure": 0.79023
        },
        "rouge2": {
            "precision": 0.58018,
            "recall": 0.55525,
            "fmeasure": 0.56123
        },
        "rougeL": {
            "precision": 0.6821,
            "recall": 0.65313,
            "fmeasure": 0.66056
        },
        "rougeLsum": {
            "precision": 0.6821,
            "recall": 0.65313,
            "fmeasure": 0.66056
        },
        "local_recall": {
            "1": 0.1875,
            "2": 0.1791044776119403,
            "3": 0.8048780487804879
        },
        "nist": 7.13359042328488,
        "bleu": 49.7238,
        "bleurt": 0.36246,
        "nubia": {
            "semantic_relation": 4.48042,
            "contradiction": 2.60454,
            "irrelevancy": 16.57819,
            "logical_agreement": 80.81727,
            "grammar_ref": 4.92209,
            "grammar_hyp": 4.99015,
            "nubia_score": 0.79438
        },
        "meteor": 0.4138127213935752,
        "bertscore": {
            "precision": 0.94212,
            "recall": 0.93367,
            "f1": 0.93731
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_17": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 48,
        "msttr-100": 0.53286,
        "msttr-100_nopunct": 0.55167,
        "total_length": 714,
        "mean_pred_length": 14.875,
        "std_pred_length": 5.309680624419263,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 44,
        "distinct-1": 0.33473389355742295,
        "vocab_size-1": 239,
        "unique-1": 191,
        "entropy-1": 6.3132787117556335,
        "distinct-2": 0.5930930930930931,
        "vocab_size-2": 395,
        "unique-2": 344,
        "entropy-2": 7.923668954011337,
        "cond_entropy-2": 1.4339427977985884,
        "distinct-3": 0.7119741100323624,
        "vocab_size-3": 440,
        "unique-3": 397,
        "entropy-3": 8.321750879909859,
        "cond_entropy-3": 0.4229115809373401,
        "total_length-nopunct": 617,
        "mean_pred_length-nopunct": 12.854166666666666,
        "std_pred_length-nopunct": 4.577979827997887,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.37925445705024313,
        "vocab_size-1-nopunct": 234,
        "unique-1-nopunct": 191,
        "entropy-1-nopunct": 6.415181456837985,
        "distinct-2-nopunct": 0.6045694200351494,
        "vocab_size-2-nopunct": 344,
        "unique-2-nopunct": 301,
        "entropy-2-nopunct": 7.74738999336808,
        "cond_entropy-2-nopunct": 1.4133580724368981,
        "distinct-3-nopunct": 0.7216890595009597,
        "vocab_size-3-nopunct": 376,
        "unique-3-nopunct": 341,
        "entropy-3-nopunct": 8.099000446219568,
        "cond_entropy-3-nopunct": 0.42713404528469257,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83718,
            "recall": 0.80402,
            "fmeasure": 0.81555
        },
        "rouge2": {
            "precision": 0.66475,
            "recall": 0.64328,
            "fmeasure": 0.65087
        },
        "rougeL": {
            "precision": 0.77485,
            "recall": 0.74791,
            "fmeasure": 0.75732
        },
        "rougeLsum": {
            "precision": 0.77485,
            "recall": 0.74791,
            "fmeasure": 0.75732
        },
        "local_recall": {
            "1": 0.25675675675675674,
            "2": 0.5875,
            "3": 0.8205128205128205
        },
        "nist": 7.526206453104433,
        "bleu": 65.91347,
        "bleurt": 0.60033,
        "nubia": {
            "semantic_relation": 4.49033,
            "contradiction": 3.10076,
            "irrelevancy": 14.72252,
            "logical_agreement": 82.17672,
            "grammar_ref": 4.06325,
            "grammar_hyp": 4.0084,
            "nubia_score": 0.87295
        },
        "meteor": 0.4639058930522833,
        "bertscore": {
            "precision": 0.95343,
            "recall": 0.94566,
            "f1": 0.94877
        }
    },
    "totto_test_contrast_challenge_continent-north_ameria": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 150,
        "msttr-100": 0.704,
        "msttr-100_nopunct": 0.77318,
        "total_length": 2582,
        "mean_pred_length": 17.213333333333335,
        "std_pred_length": 6.2584201059230775,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 45,
        "distinct-1": 0.4217660728117738,
        "vocab_size-1": 1089,
        "unique-1": 851,
        "entropy-1": 8.32526982246896,
        "distinct-2": 0.8141447368421053,
        "vocab_size-2": 1980,
        "unique-2": 1795,
        "entropy-2": 10.666262004631225,
        "cond_entropy-2": 2.0783822061429933,
        "distinct-3": 0.9504820333041192,
        "vocab_size-3": 2169,
        "unique-3": 2089,
        "entropy-3": 11.04307362341841,
        "cond_entropy-3": 0.3505835147914731,
        "total_length-nopunct": 2205,
        "mean_pred_length-nopunct": 14.7,
        "std_pred_length-nopunct": 5.312563725107995,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.4888888888888889,
        "vocab_size-1-nopunct": 1078,
        "unique-1-nopunct": 849,
        "entropy-1-nopunct": 8.687723485476491,
        "distinct-2-nopunct": 0.8437956204379562,
        "vocab_size-2-nopunct": 1734,
        "unique-2-nopunct": 1606,
        "entropy-2-nopunct": 10.504576762418042,
        "cond_entropy-2-nopunct": 1.9124529792968792,
        "distinct-3-nopunct": 0.9627296587926509,
        "vocab_size-3-nopunct": 1834,
        "unique-3-nopunct": 1781,
        "entropy-3-nopunct": 10.81261512489089,
        "cond_entropy-3-nopunct": 0.33654072463640966,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81693,
            "recall": 0.77482,
            "fmeasure": 0.78888
        },
        "rouge2": {
            "precision": 0.57758,
            "recall": 0.54912,
            "fmeasure": 0.5578
        },
        "rougeL": {
            "precision": 0.70743,
            "recall": 0.67127,
            "fmeasure": 0.68269
        },
        "rougeLsum": {
            "precision": 0.70743,
            "recall": 0.67127,
            "fmeasure": 0.68269
        },
        "local_recall": {
            "1": 0.18138424821002386,
            "2": 0.31095406360424027,
            "3": 0.8071965628356605
        },
        "nist": 8.3385315072777,
        "bleu": 49.73044,
        "bleurt": 0.4073,
        "nubia": {
            "semantic_relation": 4.49027,
            "contradiction": 2.65783,
            "irrelevancy": 20.5613,
            "logical_agreement": 76.78087,
            "grammar_ref": 4.5685,
            "grammar_hyp": 4.59909,
            "nubia_score": 0.81931
        },
        "meteor": 0.41641615123639575,
        "bertscore": {
            "precision": 0.9405,
            "recall": 0.93646,
            "f1": 0.93746
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_77": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 30,
        "msttr-100": 0.726,
        "msttr-100_nopunct": 0.78,
        "total_length": 511,
        "mean_pred_length": 17.033333333333335,
        "std_pred_length": 5.2566360176658815,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.5812133072407045,
        "vocab_size-1": 297,
        "unique-1": 240,
        "entropy-1": 7.3897398947939665,
        "distinct-2": 0.9064449064449065,
        "vocab_size-2": 436,
        "unique-2": 406,
        "entropy-2": 8.684569714939252,
        "cond_entropy-2": 1.086092394516827,
        "distinct-3": 0.975609756097561,
        "vocab_size-3": 440,
        "unique-3": 430,
        "entropy-3": 8.766529327241644,
        "cond_entropy-3": 0.08807868339984017,
        "total_length-nopunct": 452,
        "mean_pred_length-nopunct": 15.066666666666666,
        "std_pred_length-nopunct": 4.343065993307288,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6438053097345132,
        "vocab_size-1-nopunct": 291,
        "unique-1-nopunct": 240,
        "entropy-1-nopunct": 7.538645515806459,
        "distinct-2-nopunct": 0.9052132701421801,
        "vocab_size-2-nopunct": 382,
        "unique-2-nopunct": 357,
        "entropy-2-nopunct": 8.487969946035118,
        "cond_entropy-2-nopunct": 1.0053401849115855,
        "distinct-3-nopunct": 0.9744897959183674,
        "vocab_size-3-nopunct": 382,
        "unique-3-nopunct": 373,
        "entropy-3-nopunct": 8.561763702528093,
        "cond_entropy-3-nopunct": 0.083982218942309,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77622,
            "recall": 0.75758,
            "fmeasure": 0.75625
        },
        "rouge2": {
            "precision": 0.55051,
            "recall": 0.53798,
            "fmeasure": 0.536
        },
        "rougeL": {
            "precision": 0.65254,
            "recall": 0.64603,
            "fmeasure": 0.63969
        },
        "rougeLsum": {
            "precision": 0.65254,
            "recall": 0.64603,
            "fmeasure": 0.63969
        },
        "local_recall": {
            "1": 0.19387755102040816,
            "2": 0.37383177570093457,
            "3": 0.8208955223880597
        },
        "nist": 6.628451899950463,
        "bleu": 49.32959,
        "bleurt": 0.26926,
        "nubia": {
            "semantic_relation": 4.16109,
            "contradiction": 9.14591,
            "irrelevancy": 27.58216,
            "logical_agreement": 63.27193,
            "grammar_ref": 4.79957,
            "grammar_hyp": 4.79225,
            "nubia_score": 0.70601
        },
        "meteor": 0.41099475231301774,
        "bertscore": {
            "precision": 0.92994,
            "recall": 0.92998,
            "f1": 0.92744
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_56": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 64,
        "msttr-100": 0.734,
        "msttr-100_nopunct": 0.79333,
        "total_length": 1078,
        "mean_pred_length": 16.84375,
        "std_pred_length": 5.828858030309196,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.5074211502782932,
        "vocab_size-1": 547,
        "unique-1": 431,
        "entropy-1": 7.9417465932256714,
        "distinct-2": 0.9211045364891519,
        "vocab_size-2": 934,
        "unique-2": 886,
        "entropy-2": 9.779669698318958,
        "cond_entropy-2": 1.5938139055368992,
        "distinct-3": 0.991578947368421,
        "vocab_size-3": 942,
        "unique-3": 934,
        "entropy-3": 9.874941597955033,
        "cond_entropy-3": 0.09152467413475804,
        "total_length-nopunct": 940,
        "mean_pred_length-nopunct": 14.6875,
        "std_pred_length-nopunct": 5.198782910451253,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.574468085106383,
        "vocab_size-1-nopunct": 540,
        "unique-1-nopunct": 429,
        "entropy-1-nopunct": 8.2019690271128,
        "distinct-2-nopunct": 0.9337899543378996,
        "vocab_size-2-nopunct": 818,
        "unique-2-nopunct": 786,
        "entropy-2-nopunct": 9.59209402305179,
        "cond_entropy-2-nopunct": 1.4837726643851972,
        "distinct-3-nopunct": 0.9938423645320197,
        "vocab_size-3-nopunct": 807,
        "unique-3-nopunct": 802,
        "entropy-3-nopunct": 9.653020646249205,
        "cond_entropy-3-nopunct": 0.07286302016689249,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76513,
            "recall": 0.72793,
            "fmeasure": 0.73662
        },
        "rouge2": {
            "precision": 0.52392,
            "recall": 0.50542,
            "fmeasure": 0.50791
        },
        "rougeL": {
            "precision": 0.63008,
            "recall": 0.60748,
            "fmeasure": 0.61065
        },
        "rougeLsum": {
            "precision": 0.63008,
            "recall": 0.60748,
            "fmeasure": 0.61065
        },
        "local_recall": {
            "1": 0.21367521367521367,
            "2": 0.43612334801762115,
            "3": 0.7622377622377622
        },
        "nist": 7.156475742694571,
        "bleu": 44.49784,
        "bleurt": 0.24731,
        "nubia": {
            "semantic_relation": 4.20797,
            "contradiction": 9.94285,
            "irrelevancy": 30.15818,
            "logical_agreement": 59.89897,
            "grammar_ref": 4.72038,
            "grammar_hyp": 4.66704,
            "nubia_score": 0.72818
        },
        "meteor": 0.3880892597113999,
        "bertscore": {
            "precision": 0.92919,
            "recall": 0.92123,
            "f1": 0.92331
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 369,
        "msttr-100": 0.61179,
        "msttr-100_nopunct": 0.65441,
        "total_length": 3939,
        "mean_pred_length": 10.674796747967479,
        "std_pred_length": 2.728438811156022,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 23,
        "distinct-1": 0.21731403909621733,
        "vocab_size-1": 856,
        "unique-1": 483,
        "entropy-1": 7.339199656708288,
        "distinct-2": 0.5310924369747899,
        "vocab_size-2": 1896,
        "unique-2": 1330,
        "entropy-2": 10.302388881652012,
        "cond_entropy-2": 2.557696162573034,
        "distinct-3": 0.7129022180568573,
        "vocab_size-3": 2282,
        "unique-3": 1850,
        "entropy-3": 10.851305504413043,
        "cond_entropy-3": 0.6527975162937224,
        "total_length-nopunct": 3445,
        "mean_pred_length-nopunct": 9.336043360433605,
        "std_pred_length-nopunct": 2.380095090051292,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.2467343976777939,
        "vocab_size-1-nopunct": 850,
        "unique-1-nopunct": 483,
        "entropy-1-nopunct": 7.596832733391967,
        "distinct-2-nopunct": 0.5074772431729518,
        "vocab_size-2-nopunct": 1561,
        "unique-2-nopunct": 1062,
        "entropy-2-nopunct": 10.004685447607784,
        "cond_entropy-2-nopunct": 2.7606254144555096,
        "distinct-3-nopunct": 0.69449575175471,
        "vocab_size-3-nopunct": 1880,
        "unique-3-nopunct": 1494,
        "entropy-3-nopunct": 10.56421626939091,
        "cond_entropy-3-nopunct": 0.707102902402916,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.69056,
            "recall": 0.69904,
            "fmeasure": 0.68713
        },
        "rouge2": {
            "precision": 0.42363,
            "recall": 0.43103,
            "fmeasure": 0.42208
        },
        "rougeL": {
            "precision": 0.59674,
            "recall": 0.60735,
            "fmeasure": 0.595
        },
        "rougeLsum": {
            "precision": 0.59674,
            "recall": 0.60735,
            "fmeasure": 0.595
        },
        "local_recall": {
            "1": 0.2590042372881356,
            "2": 0.6125611745513866,
            "3": 0.7250996015936255,
            "4": 1.0
        },
        "nist": 7.194591503946401,
        "bleu": 40.48916,
        "bleurt": 0.0606,
        "nubia": {
            "semantic_relation": 4.04236,
            "contradiction": 24.10638,
            "irrelevancy": 9.51901,
            "logical_agreement": 66.37461,
            "grammar_ref": 5.18632,
            "grammar_hyp": 5.30023,
            "nubia_score": 0.64591
        },
        "meteor": 0.36998606160772596,
        "bertscore": {
            "precision": 0.90656,
            "recall": 0.91046,
            "f1": 0.90745
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_57": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.8,
        "total_length": 150,
        "mean_pred_length": 12.5,
        "std_pred_length": 5.107184482014854,
        "median_pred_length": 11.5,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.66,
        "vocab_size-1": 99,
        "unique-1": 82,
        "entropy-1": 6.207876831992592,
        "distinct-2": 0.9782608695652174,
        "vocab_size-2": 135,
        "unique-2": 133,
        "entropy-2": 7.059575996617562,
        "cond_entropy-2": 0.6186993507434114,
        "distinct-3": 1.0,
        "vocab_size-3": 126,
        "unique-3": 126,
        "entropy-3": 6.977279923499926,
        "cond_entropy-3": -0.07763431500711385,
        "total_length-nopunct": 124,
        "mean_pred_length-nopunct": 10.333333333333334,
        "std_pred_length-nopunct": 3.8801489089409387,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7580645161290323,
        "vocab_size-1-nopunct": 94,
        "unique-1-nopunct": 81,
        "entropy-1-nopunct": 6.308905887556191,
        "distinct-2-nopunct": 0.9732142857142857,
        "vocab_size-2-nopunct": 109,
        "unique-2-nopunct": 107,
        "entropy-2-nopunct": 6.747043426502561,
        "cond_entropy-2-nopunct": 0.4841957762075043,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 100,
        "unique-3-nopunct": 100,
        "entropy-3-nopunct": 6.6438561897747395,
        "cond_entropy-3-nopunct": -0.09594985726124487,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74072,
            "recall": 0.68819,
            "fmeasure": 0.69915
        },
        "rouge2": {
            "precision": 0.51903,
            "recall": 0.46503,
            "fmeasure": 0.47579
        },
        "rougeL": {
            "precision": 0.6473,
            "recall": 0.59591,
            "fmeasure": 0.60742
        },
        "rougeLsum": {
            "precision": 0.6473,
            "recall": 0.59591,
            "fmeasure": 0.60742
        },
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.5,
            "3": 0.7391304347826086
        },
        "nist": 4.946197319158028,
        "bleu": 43.00818,
        "bleurt": 0.14109,
        "nubia": {
            "semantic_relation": 4.13567,
            "contradiction": 8.92803,
            "irrelevancy": 31.54061,
            "logical_agreement": 59.53136,
            "grammar_ref": 5.5602,
            "grammar_hyp": 5.41393,
            "nubia_score": 0.71421
        },
        "meteor": 0.35902302259430857,
        "bertscore": {
            "precision": 0.90367,
            "recall": 0.90793,
            "f1": 0.90453
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_58": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82051,
            "recall": 0.78022,
            "fmeasure": 0.79962
        },
        "rouge2": {
            "precision": 0.47222,
            "recall": 0.46154,
            "fmeasure": 0.46667
        },
        "rougeL": {
            "precision": 0.51282,
            "recall": 0.48718,
            "fmeasure": 0.49953
        },
        "rougeLsum": {
            "precision": 0.51282,
            "recall": 0.48718,
            "fmeasure": 0.49953
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.9
        },
        "nist": 4.070010409234077,
        "bleu": 39.33173,
        "bleurt": 0.402,
        "nubia": {
            "semantic_relation": 4.14425,
            "contradiction": 0.22345,
            "irrelevancy": 0.49636,
            "logical_agreement": 99.28019,
            "grammar_ref": 5.12321,
            "grammar_hyp": 5.36159,
            "nubia_score": 0.64795
        },
        "meteor": 0.3888734180898412,
        "bertscore": {
            "precision": 0.91421,
            "recall": 0.88146,
            "f1": 0.89539
        }
    },
    "totto_test_contrast_challenge_continent-oceania": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 105,
        "msttr-100": 0.70294,
        "msttr-100_nopunct": 0.75714,
        "total_length": 1734,
        "mean_pred_length": 16.514285714285716,
        "std_pred_length": 8.510066068474199,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 65,
        "distinct-1": 0.447520184544406,
        "vocab_size-1": 776,
        "unique-1": 625,
        "entropy-1": 7.99184422924055,
        "distinct-2": 0.8385512584407612,
        "vocab_size-2": 1366,
        "unique-2": 1254,
        "entropy-2": 10.183135842308433,
        "cond_entropy-2": 1.9343127471627442,
        "distinct-3": 0.9553805774278216,
        "vocab_size-3": 1456,
        "unique-3": 1412,
        "entropy-3": 10.46882526757063,
        "cond_entropy-3": 0.2853830978632727,
        "total_length-nopunct": 1495,
        "mean_pred_length-nopunct": 14.238095238095237,
        "std_pred_length-nopunct": 7.173395038047332,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.51438127090301,
        "vocab_size-1-nopunct": 769,
        "unique-1-nopunct": 624,
        "entropy-1-nopunct": 8.318496122871299,
        "distinct-2-nopunct": 0.858273381294964,
        "vocab_size-2-nopunct": 1193,
        "unique-2-nopunct": 1110,
        "entropy-2-nopunct": 10.00226124560193,
        "cond_entropy-2-nopunct": 1.8015266327649573,
        "distinct-3-nopunct": 0.9704280155642023,
        "vocab_size-3-nopunct": 1247,
        "unique-3-nopunct": 1218,
        "entropy-3-nopunct": 10.262358529286525,
        "cond_entropy-3-nopunct": 0.28038531918532156,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79615,
            "recall": 0.75741,
            "fmeasure": 0.76573
        },
        "rouge2": {
            "precision": 0.54526,
            "recall": 0.51295,
            "fmeasure": 0.51998
        },
        "rougeL": {
            "precision": 0.68084,
            "recall": 0.64892,
            "fmeasure": 0.65517
        },
        "rougeLsum": {
            "precision": 0.68084,
            "recall": 0.64892,
            "fmeasure": 0.65517
        },
        "local_recall": {
            "1": 0.22151898734177214,
            "2": 0.3305084745762712,
            "3": 0.7856532877882152
        },
        "nist": 7.657684188512669,
        "bleu": 45.18264,
        "bleurt": 0.36167,
        "nubia": {
            "semantic_relation": 4.43691,
            "contradiction": 5.06197,
            "irrelevancy": 25.60792,
            "logical_agreement": 69.33011,
            "grammar_ref": 5.02637,
            "grammar_hyp": 5.07743,
            "nubia_score": 0.78617
        },
        "meteor": 0.39769642323654636,
        "bertscore": {
            "precision": 0.93765,
            "recall": 0.93479,
            "f1": 0.93507
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_104": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.7375,
        "msttr-100_nopunct": 0.8025,
        "total_length": 488,
        "mean_pred_length": 16.82758620689655,
        "std_pred_length": 6.873582439522581,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 35,
        "distinct-1": 0.5860655737704918,
        "vocab_size-1": 286,
        "unique-1": 233,
        "entropy-1": 7.352526562625569,
        "distinct-2": 0.9237472766884531,
        "vocab_size-2": 424,
        "unique-2": 397,
        "entropy-2": 8.671262489355122,
        "cond_entropy-2": 1.111517328939718,
        "distinct-3": 0.986046511627907,
        "vocab_size-3": 424,
        "unique-3": 418,
        "entropy-3": 8.720285872845308,
        "cond_entropy-3": 0.05591070388025924,
        "total_length-nopunct": 409,
        "mean_pred_length-nopunct": 14.10344827586207,
        "std_pred_length-nopunct": 5.208380697366882,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.687041564792176,
        "vocab_size-1-nopunct": 281,
        "unique-1-nopunct": 232,
        "entropy-1-nopunct": 7.626978911548723,
        "distinct-2-nopunct": 0.9447368421052632,
        "vocab_size-2-nopunct": 359,
        "unique-2-nopunct": 343,
        "entropy-2-nopunct": 8.442843338577031,
        "cond_entropy-2-nopunct": 0.880373571567257,
        "distinct-3-nopunct": 0.9943019943019943,
        "vocab_size-3-nopunct": 349,
        "unique-3-nopunct": 347,
        "entropy-3-nopunct": 8.443931208908566,
        "cond_entropy-3-nopunct": 0.0042171960356333586,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74205,
            "recall": 0.72334,
            "fmeasure": 0.71682
        },
        "rouge2": {
            "precision": 0.50275,
            "recall": 0.49028,
            "fmeasure": 0.48632
        },
        "rougeL": {
            "precision": 0.63312,
            "recall": 0.6123,
            "fmeasure": 0.60967
        },
        "rougeLsum": {
            "precision": 0.63312,
            "recall": 0.6123,
            "fmeasure": 0.60967
        },
        "local_recall": {
            "1": 0.18446601941747573,
            "2": 0.4418604651162791,
            "3": 0.7417218543046358
        },
        "nist": 6.274005948436761,
        "bleu": 41.43709,
        "bleurt": 0.2976,
        "nubia": {
            "semantic_relation": 4.30165,
            "contradiction": 6.19962,
            "irrelevancy": 24.99697,
            "logical_agreement": 68.80341,
            "grammar_ref": 4.69384,
            "grammar_hyp": 4.58732,
            "nubia_score": 0.75271
        },
        "meteor": 0.3823992664903231,
        "bertscore": {
            "precision": 0.92477,
            "recall": 0.92488,
            "f1": 0.92306
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_78": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 66,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.79111,
        "total_length": 1080,
        "mean_pred_length": 16.363636363636363,
        "std_pred_length": 6.620986751590603,
        "median_pred_length": 14.5,
        "min_pred_length": 6,
        "max_pred_length": 42,
        "distinct-1": 0.5037037037037037,
        "vocab_size-1": 544,
        "unique-1": 441,
        "entropy-1": 7.9091018542956455,
        "distinct-2": 0.8816568047337278,
        "vocab_size-2": 894,
        "unique-2": 831,
        "entropy-2": 9.651108988531618,
        "cond_entropy-2": 1.4896788256995588,
        "distinct-3": 0.9620253164556962,
        "vocab_size-3": 912,
        "unique-3": 889,
        "entropy-3": 9.787715361228827,
        "cond_entropy-3": 0.10529617975218732,
        "total_length-nopunct": 944,
        "mean_pred_length-nopunct": 14.303030303030303,
        "std_pred_length-nopunct": 5.918562727272347,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.5677966101694916,
        "vocab_size-1-nopunct": 536,
        "unique-1-nopunct": 438,
        "entropy-1-nopunct": 8.159863978608557,
        "distinct-2-nopunct": 0.8940774487471527,
        "vocab_size-2-nopunct": 785,
        "unique-2-nopunct": 731,
        "entropy-2-nopunct": 9.488790924768733,
        "cond_entropy-2-nopunct": 1.3703317086968823,
        "distinct-3-nopunct": 0.9729064039408867,
        "vocab_size-3-nopunct": 790,
        "unique-3-nopunct": 771,
        "entropy-3-nopunct": 9.607756006468211,
        "cond_entropy-3-nopunct": 0.07721957726130621,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75407,
            "recall": 0.73008,
            "fmeasure": 0.73133
        },
        "rouge2": {
            "precision": 0.5107,
            "recall": 0.50624,
            "fmeasure": 0.50111
        },
        "rougeL": {
            "precision": 0.63985,
            "recall": 0.61752,
            "fmeasure": 0.61807
        },
        "rougeLsum": {
            "precision": 0.63985,
            "recall": 0.61752,
            "fmeasure": 0.61807
        },
        "local_recall": {
            "1": 0.23383084577114427,
            "2": 0.4489795918367347,
            "3": 0.7557471264367817
        },
        "nist": 6.920584408217403,
        "bleu": 41.86597,
        "bleurt": 0.25232,
        "nubia": {
            "semantic_relation": 4.21474,
            "contradiction": 6.91303,
            "irrelevancy": 35.78714,
            "logical_agreement": 57.29983,
            "grammar_ref": 4.35949,
            "grammar_hyp": 4.32596,
            "nubia_score": 0.75246
        },
        "meteor": 0.3954752177024148,
        "bertscore": {
            "precision": 0.92131,
            "recall": 0.92171,
            "f1": 0.91965
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_79": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966058,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7963,
            "recall": 0.5119,
            "fmeasure": 0.62319
        },
        "rouge2": {
            "precision": 0.56863,
            "recall": 0.38827,
            "fmeasure": 0.45946
        },
        "rougeL": {
            "precision": 0.57407,
            "recall": 0.44841,
            "fmeasure": 0.5013
        },
        "rougeLsum": {
            "precision": 0.57407,
            "recall": 0.44841,
            "fmeasure": 0.5013
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.4,
            "3": 0.5
        },
        "nist": 2.449168228420069,
        "bleu": 39.36323,
        "bleurt": 0.02385,
        "nubia": {
            "semantic_relation": 3.94705,
            "contradiction": 0.11662,
            "irrelevancy": 61.82925,
            "logical_agreement": 38.05413,
            "grammar_ref": 3.5675,
            "grammar_hyp": 3.9727,
            "nubia_score": 0.6589
        },
        "meteor": 0.2701792732679323,
        "bertscore": {
            "precision": 0.9263,
            "recall": 0.88024,
            "f1": 0.90268
        }
    },
    "totto_test_contrast_challenge_continent-south_america": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 79,
        "msttr-100": 0.72692,
        "msttr-100_nopunct": 0.78455,
        "total_length": 1338,
        "mean_pred_length": 16.936708860759495,
        "std_pred_length": 5.58782984108853,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 34,
        "distinct-1": 0.46263079222720477,
        "vocab_size-1": 619,
        "unique-1": 485,
        "entropy-1": 7.95258263990705,
        "distinct-2": 0.8451151707704527,
        "vocab_size-2": 1064,
        "unique-2": 962,
        "entropy-2": 9.871482727365967,
        "cond_entropy-2": 1.6760330675957626,
        "distinct-3": 0.9601694915254237,
        "vocab_size-3": 1133,
        "unique-3": 1093,
        "entropy-3": 10.119292169263508,
        "cond_entropy-3": 0.25402578038151996,
        "total_length-nopunct": 1159,
        "mean_pred_length-nopunct": 14.670886075949367,
        "std_pred_length-nopunct": 4.864548892110159,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5280414150129422,
        "vocab_size-1-nopunct": 612,
        "unique-1-nopunct": 484,
        "entropy-1-nopunct": 8.24951399505221,
        "distinct-2-nopunct": 0.8629629629629629,
        "vocab_size-2-nopunct": 932,
        "unique-2-nopunct": 863,
        "entropy-2-nopunct": 9.679301325715288,
        "cond_entropy-2-nopunct": 1.5152389041005594,
        "distinct-3-nopunct": 0.968031968031968,
        "vocab_size-3-nopunct": 969,
        "unique-3-nopunct": 942,
        "entropy-3-nopunct": 9.899029792795488,
        "cond_entropy-3-nopunct": 0.23755202853010607,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82388,
            "recall": 0.77689,
            "fmeasure": 0.79278
        },
        "rouge2": {
            "precision": 0.60106,
            "recall": 0.57006,
            "fmeasure": 0.57965
        },
        "rougeL": {
            "precision": 0.69984,
            "recall": 0.65849,
            "fmeasure": 0.67237
        },
        "rougeLsum": {
            "precision": 0.69984,
            "recall": 0.65849,
            "fmeasure": 0.67237
        },
        "local_recall": {
            "1": 0.19696969696969696,
            "2": 0.38349514563106796,
            "3": 0.7939590075512406
        },
        "nist": 7.473983468778259,
        "bleu": 44.18645,
        "bleurt": 0.33832,
        "nubia": {
            "semantic_relation": 4.37568,
            "contradiction": 8.35007,
            "irrelevancy": 23.83537,
            "logical_agreement": 67.81456,
            "grammar_ref": 4.82253,
            "grammar_hyp": 4.9849,
            "nubia_score": 0.74585
        },
        "meteor": 0.3992788504622585,
        "bertscore": {
            "precision": 0.93811,
            "recall": 0.93711,
            "f1": 0.93679
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_18": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 123,
        "msttr-100": 0.64579,
        "msttr-100_nopunct": 0.68875,
        "total_length": 1947,
        "mean_pred_length": 15.829268292682928,
        "std_pred_length": 8.412831196030092,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 53,
        "distinct-1": 0.39496661530559835,
        "vocab_size-1": 769,
        "unique-1": 642,
        "entropy-1": 7.689387157484514,
        "distinct-2": 0.7286184210526315,
        "vocab_size-2": 1329,
        "unique-2": 1225,
        "entropy-2": 9.792890191022808,
        "cond_entropy-2": 1.8536684212717527,
        "distinct-3": 0.831275720164609,
        "vocab_size-3": 1414,
        "unique-3": 1353,
        "entropy-3": 10.115363411177045,
        "cond_entropy-3": 0.3294960360244067,
        "total_length-nopunct": 1689,
        "mean_pred_length-nopunct": 13.731707317073171,
        "std_pred_length-nopunct": 7.005309450674008,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.4511545293072824,
        "vocab_size-1-nopunct": 762,
        "unique-1-nopunct": 641,
        "entropy-1-nopunct": 7.938925328344461,
        "distinct-2-nopunct": 0.7464878671775224,
        "vocab_size-2-nopunct": 1169,
        "unique-2-nopunct": 1089,
        "entropy-2-nopunct": 9.624936922225581,
        "cond_entropy-2-nopunct": 1.7966890913760818,
        "distinct-3-nopunct": 0.8440748440748441,
        "vocab_size-3-nopunct": 1218,
        "unique-3-nopunct": 1170,
        "entropy-3-nopunct": 9.918100426291135,
        "cond_entropy-3-nopunct": 0.335876272386111,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78979,
            "recall": 0.75895,
            "fmeasure": 0.76302
        },
        "rouge2": {
            "precision": 0.57626,
            "recall": 0.55993,
            "fmeasure": 0.56013
        },
        "rougeL": {
            "precision": 0.69692,
            "recall": 0.67358,
            "fmeasure": 0.67502
        },
        "rougeLsum": {
            "precision": 0.69692,
            "recall": 0.67358,
            "fmeasure": 0.67502
        },
        "local_recall": {
            "1": 0.22614840989399293,
            "2": 0.4013377926421405,
            "3": 0.7875288683602771
        },
        "nist": 7.822977214952483,
        "bleu": 54.00678,
        "bleurt": 0.4085,
        "nubia": {
            "semantic_relation": 4.31514,
            "contradiction": 8.44417,
            "irrelevancy": 20.73976,
            "logical_agreement": 70.81607,
            "grammar_ref": 4.71387,
            "grammar_hyp": 4.6936,
            "nubia_score": 0.77282
        },
        "meteor": 0.42256755315725675,
        "bertscore": {
            "precision": 0.93885,
            "recall": 0.93271,
            "f1": 0.93396
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_105": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.775,
        "total_length": 564,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 3.7712361663282534,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.5780141843971631,
        "vocab_size-1": 326,
        "unique-1": 273,
        "entropy-1": 7.432785367364913,
        "distinct-2": 0.9450757575757576,
        "vocab_size-2": 499,
        "unique-2": 485,
        "entropy-2": 8.89748572652636,
        "cond_entropy-2": 1.2285758807699951,
        "distinct-3": 0.9979674796747967,
        "vocab_size-3": 491,
        "unique-3": 490,
        "entropy-3": 8.93844946468873,
        "cond_entropy-3": 0.042048727267642694,
        "total_length-nopunct": 484,
        "mean_pred_length-nopunct": 13.444444444444445,
        "std_pred_length-nopunct": 3.419262789650915,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6590909090909091,
        "vocab_size-1-nopunct": 319,
        "unique-1-nopunct": 271,
        "entropy-1-nopunct": 7.645186345766707,
        "distinct-2-nopunct": 0.9419642857142857,
        "vocab_size-2-nopunct": 422,
        "unique-2-nopunct": 410,
        "entropy-2-nopunct": 8.649290761537195,
        "cond_entropy-2-nopunct": 1.088497214821747,
        "distinct-3-nopunct": 0.9975728155339806,
        "vocab_size-3-nopunct": 411,
        "unique-3-nopunct": 410,
        "entropy-3-nopunct": 8.681646158251148,
        "cond_entropy-3-nopunct": 0.04616682821574368,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74962,
            "recall": 0.75966,
            "fmeasure": 0.74551
        },
        "rouge2": {
            "precision": 0.52699,
            "recall": 0.54547,
            "fmeasure": 0.52799
        },
        "rougeL": {
            "precision": 0.63405,
            "recall": 0.64923,
            "fmeasure": 0.63365
        },
        "rougeLsum": {
            "precision": 0.63405,
            "recall": 0.64923,
            "fmeasure": 0.63365
        },
        "local_recall": {
            "1": 0.16049382716049382,
            "2": 0.5423728813559322,
            "3": 0.803076923076923
        },
        "nist": 6.811834540570471,
        "bleu": 47.58513,
        "bleurt": 0.27991,
        "nubia": {
            "semantic_relation": 4.22067,
            "contradiction": 4.57472,
            "irrelevancy": 45.37216,
            "logical_agreement": 50.05312,
            "grammar_ref": 4.61474,
            "grammar_hyp": 4.48236,
            "nubia_score": 0.73149
        },
        "meteor": 0.41439340724422385,
        "bertscore": {
            "precision": 0.9282,
            "recall": 0.93401,
            "f1": 0.93014
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_106": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 42,
        "mean_pred_length": 21.0,
        "std_pred_length": 7.0,
        "median_pred_length": 21.0,
        "min_pred_length": 14,
        "max_pred_length": 28,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 35,
        "unique-1": 29,
        "entropy-1": 5.041010577489156,
        "distinct-2": 0.975,
        "vocab_size-2": 39,
        "unique-2": 38,
        "entropy-2": 5.271928094887364,
        "cond_entropy-2": 0.1984828596626887,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.021369002496408367,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 18.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8918918918918919,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.993237149412736,
        "distinct-2-nopunct": 0.9714285714285714,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.072140159802107,
        "cond_entropy-2-nopunct": 0.09125822274458809,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.024282836980452627,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.71795,
            "fmeasure": 0.68094
        },
        "rouge2": {
            "precision": 0.48548,
            "recall": 0.50698,
            "fmeasure": 0.48777
        },
        "rougeL": {
            "precision": 0.59167,
            "recall": 0.62963,
            "fmeasure": 0.60116
        },
        "rougeLsum": {
            "precision": 0.59167,
            "recall": 0.62963,
            "fmeasure": 0.60116
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.25,
            "3": 0.8888888888888888
        },
        "nist": 3.2914592992770753,
        "bleu": 39.1661,
        "bleurt": 0.22199,
        "nubia": {
            "semantic_relation": 4.10318,
            "contradiction": 0.21428,
            "irrelevancy": 50.11252,
            "logical_agreement": 49.6732,
            "grammar_ref": 4.99819,
            "grammar_hyp": 5.06489,
            "nubia_score": 0.6847
        },
        "meteor": 0.3281324446293497,
        "bertscore": {
            "precision": 0.86932,
            "recall": 0.91366,
            "f1": 0.88743
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_19": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.524,
        "msttr-100_nopunct": 0.5325,
        "total_length": 510,
        "mean_pred_length": 17.586206896551722,
        "std_pred_length": 10.206547058322199,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 53,
        "distinct-1": 0.3235294117647059,
        "vocab_size-1": 165,
        "unique-1": 123,
        "entropy-1": 6.026101931961895,
        "distinct-2": 0.5717255717255717,
        "vocab_size-2": 275,
        "unique-2": 228,
        "entropy-2": 7.41408063689097,
        "cond_entropy-2": 1.2740449102997509,
        "distinct-3": 0.6637168141592921,
        "vocab_size-3": 300,
        "unique-3": 259,
        "entropy-3": 7.68551568489885,
        "cond_entropy-3": 0.33309165410342245,
        "total_length-nopunct": 437,
        "mean_pred_length-nopunct": 15.068965517241379,
        "std_pred_length-nopunct": 8.1067491442912,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.36155606407322655,
        "vocab_size-1-nopunct": 158,
        "unique-1-nopunct": 121,
        "entropy-1-nopunct": 5.998730119481331,
        "distinct-2-nopunct": 0.5686274509803921,
        "vocab_size-2-nopunct": 232,
        "unique-2-nopunct": 192,
        "entropy-2-nopunct": 7.151933869902094,
        "cond_entropy-2-nopunct": 1.2738531521780814,
        "distinct-3-nopunct": 0.6675461741424802,
        "vocab_size-3-nopunct": 253,
        "unique-3-nopunct": 220,
        "entropy-3-nopunct": 7.431470403344245,
        "cond_entropy-3-nopunct": 0.35833556510922,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88798,
            "recall": 0.86522,
            "fmeasure": 0.87311
        },
        "rouge2": {
            "precision": 0.74764,
            "recall": 0.72834,
            "fmeasure": 0.73509
        },
        "rougeL": {
            "precision": 0.82458,
            "recall": 0.80273,
            "fmeasure": 0.81045
        },
        "rougeLsum": {
            "precision": 0.82458,
            "recall": 0.80273,
            "fmeasure": 0.81045
        },
        "local_recall": {
            "1": 0.325,
            "2": 0.5087719298245614,
            "3": 0.8816568047337278
        },
        "nist": 7.416176478303313,
        "bleu": 72.34488,
        "bleurt": 0.45775,
        "nubia": {
            "semantic_relation": 4.32593,
            "contradiction": 7.50981,
            "irrelevancy": 13.16865,
            "logical_agreement": 79.32154,
            "grammar_ref": 4.31347,
            "grammar_hyp": 4.36375,
            "nubia_score": 0.79025
        },
        "meteor": 0.46823137347039584,
        "bertscore": {
            "precision": 0.9554,
            "recall": 0.94779,
            "f1": 0.95024
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_80": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 83,
        "msttr-100": 0.73643,
        "msttr-100_nopunct": 0.7875,
        "total_length": 1474,
        "mean_pred_length": 17.759036144578314,
        "std_pred_length": 6.672349636626693,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 41,
        "distinct-1": 0.48507462686567165,
        "vocab_size-1": 715,
        "unique-1": 576,
        "entropy-1": 8.145739541951551,
        "distinct-2": 0.8749101365923796,
        "vocab_size-2": 1217,
        "unique-2": 1117,
        "entropy-2": 10.11213580005386,
        "cond_entropy-2": 1.7259522591616339,
        "distinct-3": 0.9663608562691132,
        "vocab_size-3": 1264,
        "unique-3": 1230,
        "entropy-3": 10.278972857601334,
        "cond_entropy-3": 0.15930777935464077,
        "total_length-nopunct": 1263,
        "mean_pred_length-nopunct": 15.216867469879517,
        "std_pred_length-nopunct": 5.5472737095749824,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.5597783056215361,
        "vocab_size-1-nopunct": 707,
        "unique-1-nopunct": 575,
        "entropy-1-nopunct": 8.464094853714752,
        "distinct-2-nopunct": 0.885593220338983,
        "vocab_size-2-nopunct": 1045,
        "unique-2-nopunct": 970,
        "entropy-2-nopunct": 9.89981034406838,
        "cond_entropy-2-nopunct": 1.5318557671518171,
        "distinct-3-nopunct": 0.9699179580674567,
        "vocab_size-3-nopunct": 1064,
        "unique-3-nopunct": 1039,
        "entropy-3-nopunct": 10.032337988156803,
        "cond_entropy-3-nopunct": 0.14958341793913774,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76395,
            "recall": 0.74075,
            "fmeasure": 0.73969
        },
        "rouge2": {
            "precision": 0.52361,
            "recall": 0.50053,
            "fmeasure": 0.50334
        },
        "rougeL": {
            "precision": 0.66763,
            "recall": 0.64602,
            "fmeasure": 0.64525
        },
        "rougeLsum": {
            "precision": 0.66763,
            "recall": 0.64602,
            "fmeasure": 0.64525
        },
        "local_recall": {
            "1": 0.22983870967741934,
            "2": 0.5365853658536586,
            "3": 0.7788461538461539
        },
        "nist": 7.681033025426602,
        "bleu": 48.91457,
        "bleurt": 0.32622,
        "nubia": {
            "semantic_relation": 4.27599,
            "contradiction": 7.85913,
            "irrelevancy": 30.20851,
            "logical_agreement": 61.93236,
            "grammar_ref": 4.65999,
            "grammar_hyp": 4.61442,
            "nubia_score": 0.7491
        },
        "meteor": 0.3995630483557599,
        "bertscore": {
            "precision": 0.93225,
            "recall": 0.92861,
            "f1": 0.9289
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_60": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 114,
        "msttr-100": 0.73737,
        "msttr-100_nopunct": 0.78706,
        "total_length": 1984,
        "mean_pred_length": 17.403508771929825,
        "std_pred_length": 6.53293853745262,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 37,
        "distinct-1": 0.4621975806451613,
        "vocab_size-1": 917,
        "unique-1": 721,
        "entropy-1": 8.400748433343507,
        "distinct-2": 0.8673796791443851,
        "vocab_size-2": 1622,
        "unique-2": 1494,
        "entropy-2": 10.506441415656857,
        "cond_entropy-2": 1.842522650736316,
        "distinct-3": 0.9703872437357631,
        "vocab_size-3": 1704,
        "unique-3": 1660,
        "entropy-3": 10.714367389796713,
        "cond_entropy-3": 0.20852209450025666,
        "total_length-nopunct": 1730,
        "mean_pred_length-nopunct": 15.175438596491228,
        "std_pred_length-nopunct": 5.775394896553991,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.5248554913294797,
        "vocab_size-1-nopunct": 908,
        "unique-1-nopunct": 718,
        "entropy-1-nopunct": 8.714816196488256,
        "distinct-2-nopunct": 0.8811881188118812,
        "vocab_size-2-nopunct": 1424,
        "unique-2-nopunct": 1331,
        "entropy-2-nopunct": 10.322509617247647,
        "cond_entropy-2-nopunct": 1.6903302018733333,
        "distinct-3-nopunct": 0.974034620505992,
        "vocab_size-3-nopunct": 1463,
        "unique-3-nopunct": 1430,
        "entropy-3-nopunct": 10.496500969700204,
        "cond_entropy-3-nopunct": 0.18842880263017636,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73305,
            "recall": 0.73641,
            "fmeasure": 0.72292
        },
        "rouge2": {
            "precision": 0.48359,
            "recall": 0.49136,
            "fmeasure": 0.47933
        },
        "rougeL": {
            "precision": 0.592,
            "recall": 0.60641,
            "fmeasure": 0.58853
        },
        "rougeLsum": {
            "precision": 0.592,
            "recall": 0.60641,
            "fmeasure": 0.58853
        },
        "local_recall": {
            "1": 0.272,
            "2": 0.5246305418719212,
            "3": 0.7856510186005314
        },
        "nist": 7.5117259796208025,
        "bleu": 42.664,
        "bleurt": 0.24556,
        "nubia": {
            "semantic_relation": 4.20423,
            "contradiction": 6.60218,
            "irrelevancy": 33.08052,
            "logical_agreement": 60.31731,
            "grammar_ref": 4.84845,
            "grammar_hyp": 4.69992,
            "nubia_score": 0.72694
        },
        "meteor": 0.3889875825186915,
        "bertscore": {
            "precision": 0.92171,
            "recall": 0.92025,
            "f1": 0.91946
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_61": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 56,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.743416490252569,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.7857142857142857,
        "vocab_size-1": 44,
        "unique-1": 37,
        "entropy-1": 5.293874788090402,
        "distinct-2": 1.0,
        "vocab_size-2": 52,
        "unique-2": 52,
        "entropy-2": 5.700439718141095,
        "cond_entropy-2": 0.29221724804816995,
        "distinct-3": 1.0,
        "vocab_size-3": 48,
        "unique-3": 48,
        "entropy-3": 5.5849625007211605,
        "cond_entropy-3": -0.11547721741993597,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 4.743416490252569,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8269230769230769,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.301307266176413,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.5849625007211605,
        "cond_entropy-2-nopunct": 0.29608293887513637,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.4594316186372955,
        "cond_entropy-3-nopunct": -0.12553088208385924,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74644,
            "recall": 0.88515,
            "fmeasure": 0.78106
        },
        "rouge2": {
            "precision": 0.53598,
            "recall": 0.66097,
            "fmeasure": 0.56821
        },
        "rougeL": {
            "precision": 0.68196,
            "recall": 0.84633,
            "fmeasure": 0.7344
        },
        "rougeLsum": {
            "precision": 0.68196,
            "recall": 0.84633,
            "fmeasure": 0.7344
        },
        "local_recall": {
            "1": 0.3684210526315789,
            "2": 0.8285714285714286,
            "3": 0.625
        },
        "nist": 5.11413484498044,
        "bleu": 62.25316,
        "bleurt": 0.22388,
        "nubia": {
            "semantic_relation": 4.22945,
            "contradiction": 1.37073,
            "irrelevancy": 48.17953,
            "logical_agreement": 50.44974,
            "grammar_ref": 5.36601,
            "grammar_hyp": 4.94128,
            "nubia_score": 0.70958
        },
        "meteor": 0.49399790759517825,
        "bertscore": {
            "precision": 0.91612,
            "recall": 0.94035,
            "f1": 0.9227
        }
    },
    "schema_guided_dialog_challenge_test_nopunc": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_challenge_test_nopunc",
        "N": 500,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.72554,
        "total_length": 6232,
        "mean_pred_length": 12.464,
        "std_pred_length": 7.0302705495592415,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 45,
        "distinct-1": 0.1676829268292683,
        "vocab_size-1": 1045,
        "unique-1": 605,
        "entropy-1": 7.987189602251121,
        "distinct-2": 0.4846475924633636,
        "vocab_size-2": 2778,
        "unique-2": 1980,
        "entropy-2": 10.603192632157546,
        "cond_entropy-2": 2.6040340274057896,
        "distinct-3": 0.6907492354740061,
        "vocab_size-3": 3614,
        "unique-3": 2963,
        "entropy-3": 11.399772787109706,
        "cond_entropy-3": 0.8476031093081804,
        "total_length-nopunct": 5674,
        "mean_pred_length-nopunct": 11.348,
        "std_pred_length-nopunct": 6.531377802577341,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.1820585125132182,
        "vocab_size-1-nopunct": 1033,
        "unique-1-nopunct": 604,
        "entropy-1-nopunct": 8.051439407686694,
        "distinct-2-nopunct": 0.49806725937379204,
        "vocab_size-2-nopunct": 2577,
        "unique-2-nopunct": 1882,
        "entropy-2-nopunct": 10.482697592061136,
        "cond_entropy-2-nopunct": 2.5711253919047925,
        "distinct-3-nopunct": 0.7047496790757382,
        "vocab_size-3-nopunct": 3294,
        "unique-3-nopunct": 2743,
        "entropy-3-nopunct": 11.27666113824187,
        "cond_entropy-3-nopunct": 0.8347453186424403,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_nopunc.json",
        "rouge1": {
            "precision": 0.58286,
            "recall": 0.52613,
            "fmeasure": 0.54036
        },
        "rouge2": {
            "precision": 0.35978,
            "recall": 0.32096,
            "fmeasure": 0.33065
        },
        "rougeL": {
            "precision": 0.52164,
            "recall": 0.47056,
            "fmeasure": 0.48341
        },
        "rougeLsum": {
            "precision": 0.52164,
            "recall": 0.47056,
            "fmeasure": 0.48341
        },
        "local_recall": {
            "1": 0.5378650387724798
        },
        "nist": 5.798926586449597,
        "bleu": 28.24504,
        "bleurt": -0.12755,
        "nubia": {
            "semantic_relation": 3.60693,
            "contradiction": 9.58445,
            "irrelevancy": 21.20649,
            "logical_agreement": 69.20906,
            "grammar_ref": 4.79983,
            "grammar_hyp": 4.8539,
            "nubia_score": 0.6117
        },
        "meteor": 0.29995325625843733,
        "bertscore": {
            "precision": 0.87086,
            "recall": 0.85267,
            "f1": 0.86117
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_108": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 51,
        "msttr-100": 0.71333,
        "msttr-100_nopunct": 0.765,
        "total_length": 921,
        "mean_pred_length": 18.058823529411764,
        "std_pred_length": 7.797465059941916,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 55,
        "distinct-1": 0.5363735070575462,
        "vocab_size-1": 494,
        "unique-1": 415,
        "entropy-1": 7.75449603396851,
        "distinct-2": 0.9,
        "vocab_size-2": 783,
        "unique-2": 733,
        "entropy-2": 9.492470954264558,
        "cond_entropy-2": 1.5362827564220087,
        "distinct-3": 0.9804639804639804,
        "vocab_size-3": 803,
        "unique-3": 787,
        "entropy-3": 9.638647602568877,
        "cond_entropy-3": 0.14652193766416902,
        "total_length-nopunct": 805,
        "mean_pred_length-nopunct": 15.784313725490197,
        "std_pred_length-nopunct": 6.285101354698365,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.6062111801242236,
        "vocab_size-1-nopunct": 488,
        "unique-1-nopunct": 413,
        "entropy-1-nopunct": 7.972928300819501,
        "distinct-2-nopunct": 0.9098143236074271,
        "vocab_size-2-nopunct": 686,
        "unique-2-nopunct": 648,
        "entropy-2-nopunct": 9.303302194373103,
        "cond_entropy-2-nopunct": 1.420779696308379,
        "distinct-3-nopunct": 0.984352773826458,
        "vocab_size-3-nopunct": 692,
        "unique-3-nopunct": 681,
        "entropy-3-nopunct": 9.426086426725469,
        "cond_entropy-3-nopunct": 0.13844716900041912,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76904,
            "recall": 0.79028,
            "fmeasure": 0.76854
        },
        "rouge2": {
            "precision": 0.5477,
            "recall": 0.55985,
            "fmeasure": 0.54501
        },
        "rougeL": {
            "precision": 0.65643,
            "recall": 0.66593,
            "fmeasure": 0.65111
        },
        "rougeLsum": {
            "precision": 0.65643,
            "recall": 0.66593,
            "fmeasure": 0.65111
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.4420289855072464,
            "3": 0.833634719710669
        },
        "nist": 7.341791913556753,
        "bleu": 50.70544,
        "bleurt": 0.31348,
        "nubia": {
            "semantic_relation": 4.23011,
            "contradiction": 3.98321,
            "irrelevancy": 34.10698,
            "logical_agreement": 61.90981,
            "grammar_ref": 4.80362,
            "grammar_hyp": 4.75482,
            "nubia_score": 0.72479
        },
        "meteor": 0.4189218254763898,
        "bertscore": {
            "precision": 0.93346,
            "recall": 0.93524,
            "f1": 0.93283
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_63": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 39,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.79333,
        "total_length": 748,
        "mean_pred_length": 19.17948717948718,
        "std_pred_length": 8.037960561823215,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 45,
        "distinct-1": 0.5481283422459893,
        "vocab_size-1": 410,
        "unique-1": 342,
        "entropy-1": 7.617145477542222,
        "distinct-2": 0.9153737658674189,
        "vocab_size-2": 649,
        "unique-2": 613,
        "entropy-2": 9.253777972014296,
        "cond_entropy-2": 1.4500387210035552,
        "distinct-3": 0.9776119402985075,
        "vocab_size-3": 655,
        "unique-3": 642,
        "entropy-3": 9.340987770413342,
        "cond_entropy-3": 0.0997750073002065,
        "total_length-nopunct": 628,
        "mean_pred_length-nopunct": 16.102564102564102,
        "std_pred_length-nopunct": 5.860755494289075,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.643312101910828,
        "vocab_size-1-nopunct": 404,
        "unique-1-nopunct": 341,
        "entropy-1-nopunct": 7.924606164277889,
        "distinct-2-nopunct": 0.9286926994906621,
        "vocab_size-2-nopunct": 547,
        "unique-2-nopunct": 519,
        "entropy-2-nopunct": 9.02161718493153,
        "cond_entropy-2-nopunct": 1.1692074182840964,
        "distinct-3-nopunct": 0.98,
        "vocab_size-3-nopunct": 539,
        "unique-3-nopunct": 529,
        "entropy-3-nopunct": 9.061915285680739,
        "cond_entropy-3-nopunct": 0.05127948059853732,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76805,
            "recall": 0.72119,
            "fmeasure": 0.73561
        },
        "rouge2": {
            "precision": 0.54534,
            "recall": 0.51513,
            "fmeasure": 0.52324
        },
        "rougeL": {
            "precision": 0.67119,
            "recall": 0.63326,
            "fmeasure": 0.64347
        },
        "rougeLsum": {
            "precision": 0.67119,
            "recall": 0.63326,
            "fmeasure": 0.64347
        },
        "local_recall": {
            "1": 0.16541353383458646,
            "2": 0.6772486772486772,
            "3": 0.749379652605459
        },
        "nist": 7.115180429217589,
        "bleu": 50.39486,
        "bleurt": 0.31044,
        "nubia": {
            "semantic_relation": 4.16163,
            "contradiction": 7.48103,
            "irrelevancy": 37.33974,
            "logical_agreement": 55.17923,
            "grammar_ref": 4.28467,
            "grammar_hyp": 4.14167,
            "nubia_score": 0.74018
        },
        "meteor": 0.4032379516176448,
        "bertscore": {
            "precision": 0.93213,
            "recall": 0.92631,
            "f1": 0.92833
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_81": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.77,
        "total_length": 216,
        "mean_pred_length": 18.0,
        "std_pred_length": 9.626352718795768,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 39,
        "distinct-1": 0.6342592592592593,
        "vocab_size-1": 137,
        "unique-1": 105,
        "entropy-1": 6.6568021699777296,
        "distinct-2": 0.9558823529411765,
        "vocab_size-2": 195,
        "unique-2": 186,
        "entropy-2": 7.584190047853849,
        "cond_entropy-2": 0.7811009856093257,
        "distinct-3": 0.9895833333333334,
        "vocab_size-3": 190,
        "unique-3": 188,
        "entropy-3": 7.564129167387845,
        "cond_entropy-3": -0.0145461745836727,
        "total_length-nopunct": 187,
        "mean_pred_length-nopunct": 15.583333333333334,
        "std_pred_length-nopunct": 8.567947375084783,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.7058823529411765,
        "vocab_size-1-nopunct": 132,
        "unique-1-nopunct": 104,
        "entropy-1-nopunct": 6.737066514485142,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 168,
        "unique-2-nopunct": 161,
        "entropy-2-nopunct": 7.3712111118323085,
        "cond_entropy-2-nopunct": 0.6634758707420816,
        "distinct-3-nopunct": 0.9938650306748467,
        "vocab_size-3-nopunct": 162,
        "unique-3-nopunct": 161,
        "entropy-3-nopunct": 7.336458215580796,
        "cond_entropy-3-nopunct": -0.041133264349717535,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76171,
            "recall": 0.73102,
            "fmeasure": 0.73295
        },
        "rouge2": {
            "precision": 0.52538,
            "recall": 0.49757,
            "fmeasure": 0.50118
        },
        "rougeL": {
            "precision": 0.65923,
            "recall": 0.63703,
            "fmeasure": 0.63711
        },
        "rougeLsum": {
            "precision": 0.65923,
            "recall": 0.63703,
            "fmeasure": 0.63711
        },
        "local_recall": {
            "1": 0.16071428571428573,
            "2": 0.425,
            "3": 0.8384615384615385
        },
        "nist": 5.88756469512257,
        "bleu": 39.03329,
        "bleurt": 0.23634,
        "nubia": {
            "semantic_relation": 4.18064,
            "contradiction": 9.34759,
            "irrelevancy": 27.20233,
            "logical_agreement": 63.45008,
            "grammar_ref": 4.67736,
            "grammar_hyp": 4.49617,
            "nubia_score": 0.73679
        },
        "meteor": 0.36488210582482317,
        "bertscore": {
            "precision": 0.92988,
            "recall": 0.92406,
            "f1": 0.92489
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_82": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.7735572622751845,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.04332146930622849,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.59921,
            "fmeasure": 0.60087
        },
        "rouge2": {
            "precision": 0.17949,
            "recall": 0.24048,
            "fmeasure": 0.19394
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.38889,
            "fmeasure": 0.38788
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.38889,
            "fmeasure": 0.38788
        },
        "local_recall": {
            "1": 0.625,
            "2": 0.0,
            "3": 0.75
        },
        "nist": 3.6436468038883905,
        "bleu": 11.63327,
        "bleurt": -0.20162,
        "nubia": {
            "semantic_relation": 3.72756,
            "contradiction": 0.11996,
            "irrelevancy": 99.29786,
            "logical_agreement": 0.58218,
            "grammar_ref": 5.89248,
            "grammar_hyp": 5.95557,
            "nubia_score": 0.4958
        },
        "meteor": 0.33234714788475855,
        "bertscore": {
            "precision": 0.86038,
            "recall": 0.94601,
            "f1": 0.88668
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_64": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.724,
        "total_length": 686,
        "mean_pred_length": 19.055555555555557,
        "std_pred_length": 7.055118096674547,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 39,
        "distinct-1": 0.5291545189504373,
        "vocab_size-1": 363,
        "unique-1": 296,
        "entropy-1": 7.457002939229756,
        "distinct-2": 0.9030769230769231,
        "vocab_size-2": 587,
        "unique-2": 553,
        "entropy-2": 9.085304296695329,
        "cond_entropy-2": 1.450801243185544,
        "distinct-3": 0.9804560260586319,
        "vocab_size-3": 602,
        "unique-3": 591,
        "entropy-3": 9.221777439014897,
        "cond_entropy-3": 0.13862900226087455,
        "total_length-nopunct": 589,
        "mean_pred_length-nopunct": 16.36111111111111,
        "std_pred_length-nopunct": 5.836440971163551,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6044142614601019,
        "vocab_size-1-nopunct": 356,
        "unique-1-nopunct": 294,
        "entropy-1-nopunct": 7.661527886182149,
        "distinct-2-nopunct": 0.9150090415913201,
        "vocab_size-2-nopunct": 506,
        "unique-2-nopunct": 480,
        "entropy-2-nopunct": 8.879707063875225,
        "cond_entropy-2-nopunct": 1.3011384747177883,
        "distinct-3-nopunct": 0.9806576402321083,
        "vocab_size-3-nopunct": 507,
        "unique-3-nopunct": 498,
        "entropy-3-nopunct": 8.973875620214123,
        "cond_entropy-3-nopunct": 0.10834927167519409,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74711,
            "recall": 0.69643,
            "fmeasure": 0.71169
        },
        "rouge2": {
            "precision": 0.47657,
            "recall": 0.43707,
            "fmeasure": 0.44979
        },
        "rougeL": {
            "precision": 0.61805,
            "recall": 0.57424,
            "fmeasure": 0.58739
        },
        "rougeLsum": {
            "precision": 0.61805,
            "recall": 0.57424,
            "fmeasure": 0.58739
        },
        "local_recall": {
            "1": 0.3162393162393162,
            "2": 0.47058823529411764,
            "3": 0.7462311557788944
        },
        "nist": 6.854946517994356,
        "bleu": 40.90988,
        "bleurt": 0.2662,
        "nubia": {
            "semantic_relation": 4.24622,
            "contradiction": 7.38594,
            "irrelevancy": 24.75338,
            "logical_agreement": 67.86068,
            "grammar_ref": 4.71629,
            "grammar_hyp": 4.81656,
            "nubia_score": 0.74492
        },
        "meteor": 0.36793421902300594,
        "bertscore": {
            "precision": 0.92887,
            "recall": 0.92321,
            "f1": 0.92419
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_challenge_test_asset_bfp05",
        "N": 359,
        "msttr-100": 0.7318,
        "msttr-100_nopunct": 0.78148,
        "total_length": 6122,
        "mean_pred_length": 17.05292479108635,
        "std_pred_length": 8.129521570920364,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 59,
        "distinct-1": 0.41734727213328976,
        "vocab_size-1": 2555,
        "unique-1": 2069,
        "entropy-1": 9.161792285557278,
        "distinct-2": 0.8420961304875932,
        "vocab_size-2": 4853,
        "unique-2": 4541,
        "entropy-2": 11.899246724227943,
        "cond_entropy-2": 2.4081743480783477,
        "distinct-3": 0.9511472982975574,
        "vocab_size-3": 5140,
        "unique-3": 5043,
        "entropy-3": 12.204174340158138,
        "cond_entropy-3": 0.3309035142216282,
        "total_length-nopunct": 5400,
        "mean_pred_length-nopunct": 15.041782729805014,
        "std_pred_length-nopunct": 7.076654163358539,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.4709259259259259,
        "vocab_size-1-nopunct": 2543,
        "unique-1-nopunct": 2065,
        "entropy-1-nopunct": 9.55865614983821,
        "distinct-2-nopunct": 0.8647093830589169,
        "vocab_size-2-nopunct": 4359,
        "unique-2-nopunct": 4107,
        "entropy-2-nopunct": 11.82098435139545,
        "cond_entropy-2-nopunct": 2.4208646654180574,
        "distinct-3-nopunct": 0.9724476719350705,
        "vocab_size-3-nopunct": 4553,
        "unique-3-nopunct": 4474,
        "entropy-3-nopunct": 12.12115174037424,
        "cond_entropy-3-nopunct": 0.3299579518511312,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp05.json",
        "rouge1": {
            "precision": 0.68907,
            "recall": 0.62943,
            "fmeasure": 0.64494
        },
        "rouge2": {
            "precision": 0.47193,
            "recall": 0.42779,
            "fmeasure": 0.4352
        },
        "rougeL": {
            "precision": 0.65255,
            "recall": 0.60021,
            "fmeasure": 0.61207
        },
        "rougeLsum": {
            "precision": 0.65255,
            "recall": 0.60021,
            "fmeasure": 0.61207
        },
        "local_recall": {
            "1": 0.04115942028985507,
            "2": 0.13186813186813187,
            "3": 0.2250879249706917,
            "4": 0.33994334277620397,
            "5": 0.39707835325365204,
            "6": 0.4642857142857143,
            "7": 0.5707762557077626,
            "8": 0.625,
            "9": 0.739568345323741
        },
        "nist": 8.853813272268699,
        "bleu": 44.3461,
        "sari": 46.02373,
        "bleurt": -0.59595,
        "nubia": {
            "semantic_relation": 3.53945,
            "contradiction": 8.42246,
            "irrelevancy": 27.58713,
            "logical_agreement": 63.99042,
            "grammar_ref": 4.57404,
            "grammar_hyp": 6.11285,
            "nubia_score": 0.4031
        },
        "meteor": 0.3203676673400658,
        "bertscore": {
            "precision": 0.87864,
            "recall": 0.89707,
            "f1": 0.8833
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 350,
        "msttr-100": 0.64024,
        "msttr-100_nopunct": 0.68219,
        "total_length": 8329,
        "mean_pred_length": 23.797142857142855,
        "std_pred_length": 5.701277336291064,
        "median_pred_length": 23.0,
        "min_pred_length": 12,
        "max_pred_length": 50,
        "distinct-1": 0.1395125465241926,
        "vocab_size-1": 1162,
        "unique-1": 448,
        "entropy-1": 7.85088156387959,
        "distinct-2": 0.39390901115428,
        "vocab_size-2": 3143,
        "unique-2": 1835,
        "entropy-2": 10.805332062733768,
        "cond_entropy-2": 2.788208175604134,
        "distinct-3": 0.5986367807052039,
        "vocab_size-3": 4567,
        "unique-3": 3295,
        "entropy-3": 11.739177576183785,
        "cond_entropy-3": 0.9777867005670794,
        "total_length-nopunct": 7335,
        "mean_pred_length-nopunct": 20.957142857142856,
        "std_pred_length-nopunct": 5.205040727947461,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.1574642126789366,
        "vocab_size-1-nopunct": 1155,
        "unique-1-nopunct": 448,
        "entropy-1-nopunct": 8.13341920576638,
        "distinct-2-nopunct": 0.4107372942018611,
        "vocab_size-2-nopunct": 2869,
        "unique-2-nopunct": 1753,
        "entropy-2-nopunct": 10.701029342627704,
        "cond_entropy-2-nopunct": 2.6974673010985053,
        "distinct-3-nopunct": 0.6108515448379804,
        "vocab_size-3-nopunct": 4053,
        "unique-3-nopunct": 3003,
        "entropy-3-nopunct": 11.567965147425133,
        "cond_entropy-3-nopunct": 0.9039335900459529,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.67949,
            "recall": 0.69141,
            "fmeasure": 0.67892
        },
        "rouge2": {
            "precision": 0.41194,
            "recall": 0.41586,
            "fmeasure": 0.40975
        },
        "rougeL": {
            "precision": 0.52405,
            "recall": 0.53297,
            "fmeasure": 0.52293
        },
        "rougeLsum": {
            "precision": 0.52405,
            "recall": 0.53297,
            "fmeasure": 0.52293
        },
        "local_recall": {
            "1": 0.21705655907610305,
            "2": 0.536689876807713,
            "3": 0.7795950155763239,
            "4": 0.5,
            "5": 0.6896551724137931
        },
        "nist": 7.368987083369136,
        "bleu": 37.26107,
        "bleurt": -0.01058,
        "nubia": {
            "semantic_relation": 4.06049,
            "contradiction": 22.21508,
            "irrelevancy": 10.97499,
            "logical_agreement": 66.80993,
            "grammar_ref": 4.50573,
            "grammar_hyp": 4.5255,
            "nubia_score": 0.67883
        },
        "meteor": 0.3492124778831607,
        "bertscore": {
            "precision": 0.89451,
            "recall": 0.89579,
            "f1": 0.89374
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_110": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.794,
        "total_length": 591,
        "mean_pred_length": 19.06451612903226,
        "std_pred_length": 6.838861836408292,
        "median_pred_length": 18.0,
        "min_pred_length": 9,
        "max_pred_length": 36,
        "distinct-1": 0.5482233502538071,
        "vocab_size-1": 324,
        "unique-1": 255,
        "entropy-1": 7.480081664815109,
        "distinct-2": 0.9053571428571429,
        "vocab_size-2": 507,
        "unique-2": 466,
        "entropy-2": 8.922070338342607,
        "cond_entropy-2": 1.2608010169492878,
        "distinct-3": 0.9546313799621928,
        "vocab_size-3": 505,
        "unique-3": 485,
        "entropy-3": 8.950678637995608,
        "cond_entropy-3": 0.036970479306401224,
        "total_length-nopunct": 511,
        "mean_pred_length-nopunct": 16.483870967741936,
        "std_pred_length-nopunct": 5.763460921165537,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.6262230919765166,
        "vocab_size-1-nopunct": 320,
        "unique-1-nopunct": 255,
        "entropy-1-nopunct": 7.7284113912941255,
        "distinct-2-nopunct": 0.9145833333333333,
        "vocab_size-2-nopunct": 439,
        "unique-2-nopunct": 409,
        "entropy-2-nopunct": 8.716715152868666,
        "cond_entropy-2-nopunct": 1.0481930288208152,
        "distinct-3-nopunct": 0.955456570155902,
        "vocab_size-3-nopunct": 429,
        "unique-3-nopunct": 412,
        "entropy-3-nopunct": 8.716440983279057,
        "cond_entropy-3-nopunct": 0.012855983472614836,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75278,
            "recall": 0.76126,
            "fmeasure": 0.74948
        },
        "rouge2": {
            "precision": 0.53772,
            "recall": 0.54321,
            "fmeasure": 0.5356
        },
        "rougeL": {
            "precision": 0.66948,
            "recall": 0.66969,
            "fmeasure": 0.66354
        },
        "rougeLsum": {
            "precision": 0.66948,
            "recall": 0.66969,
            "fmeasure": 0.66354
        },
        "local_recall": {
            "1": 0.23423423423423423,
            "2": 0.4457831325301205,
            "3": 0.792
        },
        "nist": 6.865107513669043,
        "bleu": 48.96282,
        "bleurt": 0.38143,
        "nubia": {
            "semantic_relation": 4.41353,
            "contradiction": 7.04696,
            "irrelevancy": 25.38704,
            "logical_agreement": 67.566,
            "grammar_ref": 4.88113,
            "grammar_hyp": 4.65775,
            "nubia_score": 0.82022
        },
        "meteor": 0.4104527149105765,
        "bertscore": {
            "precision": 0.93672,
            "recall": 0.93758,
            "f1": 0.93653
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_111": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.070656113151927,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.26735504721677544,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.9057645846554525,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.19723710464117222,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7037,
            "recall": 0.86905,
            "fmeasure": 0.77696
        },
        "rouge2": {
            "precision": 0.41176,
            "recall": 0.51453,
            "fmeasure": 0.45694
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.75298,
            "fmeasure": 0.67402
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.75298,
            "fmeasure": 0.67402
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 2.8356607153159366,
        "bleu": 25.91669,
        "bleurt": 0.21279,
        "nubia": {
            "semantic_relation": 3.85297,
            "contradiction": 0.19944,
            "irrelevancy": 99.70324,
            "logical_agreement": 0.09732,
            "grammar_ref": 3.66146,
            "grammar_hyp": 3.08355,
            "nubia_score": 0.81532
        },
        "meteor": 0.4251510080826981,
        "bertscore": {
            "precision": 0.93292,
            "recall": 0.95525,
            "f1": 0.94396
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_20": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 112,
        "msttr-100": 0.70778,
        "msttr-100_nopunct": 0.76375,
        "total_length": 1839,
        "mean_pred_length": 16.419642857142858,
        "std_pred_length": 6.648896783969319,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 46,
        "distinct-1": 0.44045676998368677,
        "vocab_size-1": 810,
        "unique-1": 671,
        "entropy-1": 8.05691760444778,
        "distinct-2": 0.8123914302258252,
        "vocab_size-2": 1403,
        "unique-2": 1291,
        "entropy-2": 10.147434834888912,
        "cond_entropy-2": 1.829007230513609,
        "distinct-3": 0.9126934984520124,
        "vocab_size-3": 1474,
        "unique-3": 1423,
        "entropy-3": 10.39574027233976,
        "cond_entropy-3": 0.2518202988434891,
        "total_length-nopunct": 1600,
        "mean_pred_length-nopunct": 14.285714285714286,
        "std_pred_length-nopunct": 5.954333013247837,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.499375,
        "vocab_size-1-nopunct": 799,
        "unique-1-nopunct": 667,
        "entropy-1-nopunct": 8.312834573671296,
        "distinct-2-nopunct": 0.823252688172043,
        "vocab_size-2-nopunct": 1225,
        "unique-2-nopunct": 1137,
        "entropy-2-nopunct": 9.954165556152994,
        "cond_entropy-2-nopunct": 1.749017107022536,
        "distinct-3-nopunct": 0.9186046511627907,
        "vocab_size-3-nopunct": 1264,
        "unique-3-nopunct": 1222,
        "entropy-3-nopunct": 10.184833122952279,
        "cond_entropy-3-nopunct": 0.2602239763545419,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7527,
            "recall": 0.72641,
            "fmeasure": 0.72563
        },
        "rouge2": {
            "precision": 0.51672,
            "recall": 0.49671,
            "fmeasure": 0.49847
        },
        "rougeL": {
            "precision": 0.64064,
            "recall": 0.62128,
            "fmeasure": 0.61925
        },
        "rougeLsum": {
            "precision": 0.64064,
            "recall": 0.62128,
            "fmeasure": 0.61925
        },
        "local_recall": {
            "1": 0.2195845697329377,
            "2": 0.47435897435897434,
            "3": 0.7891513560804899
        },
        "nist": 7.396135211648591,
        "bleu": 44.56273,
        "bleurt": 0.28753,
        "nubia": {
            "semantic_relation": 4.16961,
            "contradiction": 9.35696,
            "irrelevancy": 25.80722,
            "logical_agreement": 64.83582,
            "grammar_ref": 4.71051,
            "grammar_hyp": 4.65354,
            "nubia_score": 0.72795
        },
        "meteor": 0.3864643990863347,
        "bertscore": {
            "precision": 0.92453,
            "recall": 0.92137,
            "f1": 0.92175
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 114,
        "msttr-100": 0.63848,
        "msttr-100_nopunct": 0.66366,
        "total_length": 4693,
        "mean_pred_length": 41.166666666666664,
        "std_pred_length": 9.496921631130597,
        "median_pred_length": 39.5,
        "min_pred_length": 20,
        "max_pred_length": 66,
        "distinct-1": 0.17408906882591094,
        "vocab_size-1": 817,
        "unique-1": 324,
        "entropy-1": 7.7449798331611674,
        "distinct-2": 0.4369949770692291,
        "vocab_size-2": 2001,
        "unique-2": 1172,
        "entropy-2": 10.330341915530518,
        "cond_entropy-2": 2.4935387684971446,
        "distinct-3": 0.6053751399776036,
        "vocab_size-3": 2703,
        "unique-3": 1907,
        "entropy-3": 11.041340401646995,
        "cond_entropy-3": 0.7305183662288911,
        "total_length-nopunct": 4166,
        "mean_pred_length-nopunct": 36.54385964912281,
        "std_pred_length-nopunct": 8.500918785097758,
        "median_pred_length-nopunct": 36.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 59,
        "distinct-1-nopunct": 0.19371099375900144,
        "vocab_size-1-nopunct": 807,
        "unique-1-nopunct": 321,
        "entropy-1-nopunct": 7.959283488147869,
        "distinct-2-nopunct": 0.45582428430404737,
        "vocab_size-2-nopunct": 1847,
        "unique-2-nopunct": 1123,
        "entropy-2-nopunct": 10.264796979551353,
        "cond_entropy-2-nopunct": 2.366090861154383,
        "distinct-3-nopunct": 0.6175723717623159,
        "vocab_size-3-nopunct": 2432,
        "unique-3-nopunct": 1749,
        "entropy-3-nopunct": 10.898458806845662,
        "cond_entropy-3-nopunct": 0.6468363498225351,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.6936,
            "recall": 0.63568,
            "fmeasure": 0.65756
        },
        "rouge2": {
            "precision": 0.38198,
            "recall": 0.34893,
            "fmeasure": 0.36126
        },
        "rougeL": {
            "precision": 0.46558,
            "recall": 0.43087,
            "fmeasure": 0.44348
        },
        "rougeLsum": {
            "precision": 0.46558,
            "recall": 0.43087,
            "fmeasure": 0.44348
        },
        "local_recall": {
            "1": 0.2089467723669309,
            "2": 0.5698924731182796,
            "3": 0.7578947368421053
        },
        "nist": 7.180495739738263,
        "bleu": 37.14016,
        "bleurt": -0.12112,
        "nubia": {
            "semantic_relation": 3.79036,
            "contradiction": 21.25387,
            "irrelevancy": 12.69854,
            "logical_agreement": 66.04759,
            "grammar_ref": 4.06233,
            "grammar_hyp": 4.2417,
            "nubia_score": 0.62208
        },
        "meteor": 0.31179483909648226,
        "bertscore": {
            "precision": 0.88989,
            "recall": 0.87922,
            "f1": 0.8831
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_84": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 80,
        "msttr-100": 0.71615,
        "msttr-100_nopunct": 0.77091,
        "total_length": 1325,
        "mean_pred_length": 16.5625,
        "std_pred_length": 7.1113355813096035,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 44,
        "distinct-1": 0.5011320754716981,
        "vocab_size-1": 664,
        "unique-1": 533,
        "entropy-1": 8.109930249512477,
        "distinct-2": 0.9060240963855422,
        "vocab_size-2": 1128,
        "unique-2": 1059,
        "entropy-2": 10.038540263584741,
        "cond_entropy-2": 1.6665696215866974,
        "distinct-3": 0.9819742489270387,
        "vocab_size-3": 1144,
        "unique-3": 1125,
        "entropy-3": 10.148766793186022,
        "cond_entropy-3": 0.09327537090652649,
        "total_length-nopunct": 1133,
        "mean_pred_length-nopunct": 14.1625,
        "std_pred_length-nopunct": 6.251887215073541,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.5789938217122683,
        "vocab_size-1-nopunct": 656,
        "unique-1-nopunct": 529,
        "entropy-1-nopunct": 8.445548259826642,
        "distinct-2-nopunct": 0.9278252611585945,
        "vocab_size-2-nopunct": 977,
        "unique-2-nopunct": 930,
        "entropy-2-nopunct": 9.853664116151544,
        "cond_entropy-2-nopunct": 1.495717421313942,
        "distinct-3-nopunct": 0.9897225077081192,
        "vocab_size-3-nopunct": 963,
        "unique-3-nopunct": 953,
        "entropy-3-nopunct": 9.905741010197438,
        "cond_entropy-3-nopunct": 0.06536574131178033,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75253,
            "recall": 0.69062,
            "fmeasure": 0.70749
        },
        "rouge2": {
            "precision": 0.50323,
            "recall": 0.45529,
            "fmeasure": 0.46975
        },
        "rougeL": {
            "precision": 0.64848,
            "recall": 0.59345,
            "fmeasure": 0.60818
        },
        "rougeLsum": {
            "precision": 0.64848,
            "recall": 0.59345,
            "fmeasure": 0.60818
        },
        "local_recall": {
            "1": 0.21610169491525424,
            "2": 0.4131455399061033,
            "3": 0.732519422863485
        },
        "nist": 7.158390627798772,
        "bleu": 43.04863,
        "bleurt": 0.24196,
        "nubia": {
            "semantic_relation": 4.25362,
            "contradiction": 5.79938,
            "irrelevancy": 25.83917,
            "logical_agreement": 68.36145,
            "grammar_ref": 4.79239,
            "grammar_hyp": 4.82238,
            "nubia_score": 0.7394
        },
        "meteor": 0.3761446006566168,
        "bertscore": {
            "precision": 0.92578,
            "recall": 0.91775,
            "f1": 0.91985
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_65": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 62,
        "msttr-100": 0.70455,
        "msttr-100_nopunct": 0.77444,
        "total_length": 1107,
        "mean_pred_length": 17.85483870967742,
        "std_pred_length": 7.555913672455392,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 45,
        "distinct-1": 0.45528455284552843,
        "vocab_size-1": 504,
        "unique-1": 382,
        "entropy-1": 7.808003915445142,
        "distinct-2": 0.8229665071770335,
        "vocab_size-2": 860,
        "unique-2": 756,
        "entropy-2": 9.578436626719292,
        "cond_entropy-2": 1.5538918839238365,
        "distinct-3": 0.91353001017294,
        "vocab_size-3": 898,
        "unique-3": 842,
        "entropy-3": 9.738402276253243,
        "cond_entropy-3": 0.15136581765061416,
        "total_length-nopunct": 934,
        "mean_pred_length-nopunct": 15.064516129032258,
        "std_pred_length-nopunct": 5.758222641725079,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.5289079229122056,
        "vocab_size-1-nopunct": 494,
        "unique-1-nopunct": 377,
        "entropy-1-nopunct": 8.102652593057165,
        "distinct-2-nopunct": 0.8451834862385321,
        "vocab_size-2-nopunct": 737,
        "unique-2-nopunct": 662,
        "entropy-2-nopunct": 9.369963496969381,
        "cond_entropy-2-nopunct": 1.3362918960297434,
        "distinct-3-nopunct": 0.9259259259259259,
        "vocab_size-3-nopunct": 750,
        "unique-3-nopunct": 710,
        "entropy-3-nopunct": 9.491359455775331,
        "cond_entropy-3-nopunct": 0.11854372587273068,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76062,
            "recall": 0.76989,
            "fmeasure": 0.75802
        },
        "rouge2": {
            "precision": 0.53843,
            "recall": 0.53727,
            "fmeasure": 0.53304
        },
        "rougeL": {
            "precision": 0.6698,
            "recall": 0.67943,
            "fmeasure": 0.66742
        },
        "rougeLsum": {
            "precision": 0.6698,
            "recall": 0.67943,
            "fmeasure": 0.66742
        },
        "local_recall": {
            "1": 0.19186046511627908,
            "2": 0.3954802259887006,
            "3": 0.8250728862973761
        },
        "nist": 7.319836114562735,
        "bleu": 49.35963,
        "bleurt": 0.32591,
        "nubia": {
            "semantic_relation": 4.32573,
            "contradiction": 4.28999,
            "irrelevancy": 32.16902,
            "logical_agreement": 63.54099,
            "grammar_ref": 4.56742,
            "grammar_hyp": 4.3708,
            "nubia_score": 0.78463
        },
        "meteor": 0.4100665541332536,
        "bertscore": {
            "precision": 0.93014,
            "recall": 0.93073,
            "f1": 0.92827
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_85": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 25,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.75333,
        "total_length": 409,
        "mean_pred_length": 16.36,
        "std_pred_length": 5.237403937066531,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.5770171149144254,
        "vocab_size-1": 236,
        "unique-1": 192,
        "entropy-1": 7.183774777042198,
        "distinct-2": 0.9270833333333334,
        "vocab_size-2": 356,
        "unique-2": 336,
        "entropy-2": 8.419572461647457,
        "cond_entropy-2": 1.0306105795352123,
        "distinct-3": 0.9860724233983287,
        "vocab_size-3": 354,
        "unique-3": 349,
        "entropy-3": 8.459984880619723,
        "cond_entropy-3": 0.02964570860141335,
        "total_length-nopunct": 349,
        "mean_pred_length-nopunct": 13.96,
        "std_pred_length-nopunct": 4.26595827452637,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6590257879656161,
        "vocab_size-1-nopunct": 230,
        "unique-1-nopunct": 192,
        "entropy-1-nopunct": 7.343811674471102,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 306,
        "unique-2-nopunct": 294,
        "entropy-2-nopunct": 8.211733413365065,
        "cond_entropy-2-nopunct": 0.9370941580051921,
        "distinct-3-nopunct": 0.9933110367892977,
        "vocab_size-3-nopunct": 297,
        "unique-3-nopunct": 295,
        "entropy-3-nopunct": 8.210623747776658,
        "cond_entropy-3-nopunct": 0.004301545907479625,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75934,
            "recall": 0.71799,
            "fmeasure": 0.72266
        },
        "rouge2": {
            "precision": 0.5446,
            "recall": 0.51376,
            "fmeasure": 0.51688
        },
        "rougeL": {
            "precision": 0.63204,
            "recall": 0.60272,
            "fmeasure": 0.60449
        },
        "rougeLsum": {
            "precision": 0.63204,
            "recall": 0.60272,
            "fmeasure": 0.60449
        },
        "local_recall": {
            "1": 0.21739130434782608,
            "2": 0.34782608695652173,
            "3": 0.7491166077738516
        },
        "nist": 6.37163585100113,
        "bleu": 43.84599,
        "bleurt": 0.13688,
        "nubia": {
            "semantic_relation": 3.9737,
            "contradiction": 7.84143,
            "irrelevancy": 32.0229,
            "logical_agreement": 60.13567,
            "grammar_ref": 4.78896,
            "grammar_hyp": 4.87537,
            "nubia_score": 0.64296
        },
        "meteor": 0.39227345062427665,
        "bertscore": {
            "precision": 0.92695,
            "recall": 0.92337,
            "f1": 0.92399
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 305,
        "msttr-100": 0.63613,
        "msttr-100_nopunct": 0.68024,
        "total_length": 9308,
        "mean_pred_length": 30.518032786885247,
        "std_pred_length": 7.176955567093875,
        "median_pred_length": 30.0,
        "min_pred_length": 14,
        "max_pred_length": 50,
        "distinct-1": 0.1415986248388483,
        "vocab_size-1": 1318,
        "unique-1": 523,
        "entropy-1": 7.9258456543895655,
        "distinct-2": 0.4117516383427746,
        "vocab_size-2": 3707,
        "unique-2": 2259,
        "entropy-2": 11.014049864404159,
        "cond_entropy-2": 2.956203263469531,
        "distinct-3": 0.6287652333869855,
        "vocab_size-3": 5469,
        "unique-3": 4076,
        "entropy-3": 12.024165594450956,
        "cond_entropy-3": 1.0433970638450996,
        "total_length-nopunct": 8214,
        "mean_pred_length-nopunct": 26.931147540983606,
        "std_pred_length-nopunct": 6.69170127069824,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.15936206476747017,
        "vocab_size-1-nopunct": 1309,
        "unique-1-nopunct": 521,
        "entropy-1-nopunct": 8.215976693511825,
        "distinct-2-nopunct": 0.4346946516626628,
        "vocab_size-2-nopunct": 3438,
        "unique-2-nopunct": 2178,
        "entropy-2-nopunct": 10.964540161848014,
        "cond_entropy-2-nopunct": 2.8508111320722533,
        "distinct-3-nopunct": 0.6467648605996844,
        "vocab_size-3-nopunct": 4918,
        "unique-3-nopunct": 3764,
        "entropy-3-nopunct": 11.887782374088069,
        "cond_entropy-3-nopunct": 0.9516682860538269,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.65706,
            "recall": 0.65879,
            "fmeasure": 0.65096
        },
        "rouge2": {
            "precision": 0.36643,
            "recall": 0.36791,
            "fmeasure": 0.36313
        },
        "rougeL": {
            "precision": 0.4799,
            "recall": 0.48099,
            "fmeasure": 0.47518
        },
        "rougeLsum": {
            "precision": 0.4799,
            "recall": 0.48099,
            "fmeasure": 0.47518
        },
        "local_recall": {
            "1": 0.210688304420817,
            "2": 0.520776874435411,
            "3": 0.7751686235323507
        },
        "nist": 7.269200086991024,
        "bleu": 35.41205,
        "bleurt": -0.07276,
        "nubia": {
            "semantic_relation": 3.89606,
            "contradiction": 26.98374,
            "irrelevancy": 11.94289,
            "logical_agreement": 61.07337,
            "grammar_ref": 4.27079,
            "grammar_hyp": 4.35874,
            "nubia_score": 0.62705
        },
        "meteor": 0.3255683951359665,
        "bertscore": {
            "precision": 0.88415,
            "recall": 0.88558,
            "f1": 0.88346
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_112": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 47,
        "msttr-100": 0.70625,
        "msttr-100_nopunct": 0.77286,
        "total_length": 837,
        "mean_pred_length": 17.80851063829787,
        "std_pred_length": 6.170066029069569,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 35,
        "distinct-1": 0.5089605734767025,
        "vocab_size-1": 426,
        "unique-1": 326,
        "entropy-1": 7.670433045997857,
        "distinct-2": 0.8860759493670886,
        "vocab_size-2": 700,
        "unique-2": 635,
        "entropy-2": 9.35085734439717,
        "cond_entropy-2": 1.4694411952273574,
        "distinct-3": 0.9623149394347241,
        "vocab_size-3": 715,
        "unique-3": 688,
        "entropy-3": 9.460832280078094,
        "cond_entropy-3": 0.10851870477553692,
        "total_length-nopunct": 724,
        "mean_pred_length-nopunct": 15.404255319148936,
        "std_pred_length-nopunct": 5.475903012942482,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.5814917127071824,
        "vocab_size-1-nopunct": 421,
        "unique-1-nopunct": 326,
        "entropy-1-nopunct": 7.924562235466456,
        "distinct-2-nopunct": 0.8995568685376661,
        "vocab_size-2-nopunct": 609,
        "unique-2-nopunct": 561,
        "entropy-2-nopunct": 9.15357624596688,
        "cond_entropy-2-nopunct": 1.296789637434239,
        "distinct-3-nopunct": 0.9698412698412698,
        "vocab_size-3-nopunct": 611,
        "unique-3-nopunct": 592,
        "entropy-3-nopunct": 9.23889055806981,
        "cond_entropy-3-nopunct": 0.09598650503548521,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76365,
            "recall": 0.72814,
            "fmeasure": 0.7309
        },
        "rouge2": {
            "precision": 0.5258,
            "recall": 0.5004,
            "fmeasure": 0.50071
        },
        "rougeL": {
            "precision": 0.67618,
            "recall": 0.64966,
            "fmeasure": 0.64837
        },
        "rougeLsum": {
            "precision": 0.67618,
            "recall": 0.64966,
            "fmeasure": 0.64837
        },
        "local_recall": {
            "1": 0.1875,
            "2": 0.3643410852713178,
            "3": 0.7763636363636364
        },
        "nist": 6.720773542429744,
        "bleu": 44.68344,
        "bleurt": 0.27058,
        "nubia": {
            "semantic_relation": 4.17217,
            "contradiction": 7.11799,
            "irrelevancy": 29.51381,
            "logical_agreement": 63.36819,
            "grammar_ref": 4.39993,
            "grammar_hyp": 4.37065,
            "nubia_score": 0.7248
        },
        "meteor": 0.3944169303104831,
        "bertscore": {
            "precision": 0.92559,
            "recall": 0.92154,
            "f1": 0.92218
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_21": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 91,
        "msttr-100": 0.69429,
        "msttr-100_nopunct": 0.74833,
        "total_length": 1418,
        "mean_pred_length": 15.582417582417582,
        "std_pred_length": 6.9930356785482735,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 53,
        "distinct-1": 0.4076163610719323,
        "vocab_size-1": 578,
        "unique-1": 464,
        "entropy-1": 7.6463108346976405,
        "distinct-2": 0.7467972871137905,
        "vocab_size-2": 991,
        "unique-2": 882,
        "entropy-2": 9.579285860872506,
        "cond_entropy-2": 1.6781594026636346,
        "distinct-3": 0.8648867313915858,
        "vocab_size-3": 1069,
        "unique-3": 1000,
        "entropy-3": 9.88098589943208,
        "cond_entropy-3": 0.30916047089739473,
        "total_length-nopunct": 1233,
        "mean_pred_length-nopunct": 13.54945054945055,
        "std_pred_length-nopunct": 6.075104550746407,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.4630981346309814,
        "vocab_size-1-nopunct": 571,
        "unique-1-nopunct": 463,
        "entropy-1-nopunct": 7.874854322380441,
        "distinct-2-nopunct": 0.7661996497373029,
        "vocab_size-2-nopunct": 875,
        "unique-2-nopunct": 790,
        "entropy-2-nopunct": 9.417398778003106,
        "cond_entropy-2-nopunct": 1.652434390327704,
        "distinct-3-nopunct": 0.8753568030447193,
        "vocab_size-3-nopunct": 920,
        "unique-3-nopunct": 869,
        "entropy-3-nopunct": 9.67289837850417,
        "cond_entropy-3-nopunct": 0.29125639861492875,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79349,
            "recall": 0.73385,
            "fmeasure": 0.75168
        },
        "rouge2": {
            "precision": 0.58579,
            "recall": 0.53876,
            "fmeasure": 0.55239
        },
        "rougeL": {
            "precision": 0.70397,
            "recall": 0.65482,
            "fmeasure": 0.6689
        },
        "rougeLsum": {
            "precision": 0.70397,
            "recall": 0.65482,
            "fmeasure": 0.6689
        },
        "local_recall": {
            "1": 0.2072072072072072,
            "2": 0.42105263157894735,
            "3": 0.7689075630252101
        },
        "nist": 7.376943927128729,
        "bleu": 50.13865,
        "bleurt": 0.29521,
        "nubia": {
            "semantic_relation": 4.16252,
            "contradiction": 5.39486,
            "irrelevancy": 24.43939,
            "logical_agreement": 70.16575,
            "grammar_ref": 4.3909,
            "grammar_hyp": 4.46081,
            "nubia_score": 0.73965
        },
        "meteor": 0.3941157849829866,
        "bertscore": {
            "precision": 0.93499,
            "recall": 0.92343,
            "f1": 0.92777
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_86": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.76923,
            "fmeasure": 0.71429
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.58333,
            "fmeasure": 0.53846
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.76923,
            "fmeasure": 0.71429
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.76923,
            "fmeasure": 0.71429
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7692307692307693
        },
        "nist": 2.888888888888889,
        "bleu": 49.89071,
        "bleurt": 0.42875,
        "nubia": {
            "semantic_relation": 3.99492,
            "contradiction": 0.12898,
            "irrelevancy": 99.76509,
            "logical_agreement": 0.10593,
            "grammar_ref": 3.82301,
            "grammar_hyp": 3.70802,
            "nubia_score": 0.80894
        },
        "meteor": 0.5454973925806863,
        "bertscore": {
            "precision": 0.94068,
            "recall": 0.97453,
            "f1": 0.95731
        }
    },
    "schema_guided_dialog_challenge_test_bfp02_parent": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.68875,
        "msttr-100_nopunct": 0.72246,
        "total_length": 6479,
        "mean_pred_length": 12.958,
        "std_pred_length": 7.3503901937244125,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 42,
        "distinct-1": 0.15202963420280907,
        "vocab_size-1": 985,
        "unique-1": 533,
        "entropy-1": 7.842755670108265,
        "distinct-2": 0.4768355912359926,
        "vocab_size-2": 2851,
        "unique-2": 1961,
        "entropy-2": 10.688802771603383,
        "cond_entropy-2": 2.6174857801624385,
        "distinct-3": 0.6972075196203686,
        "vocab_size-3": 3820,
        "unique-3": 3119,
        "entropy-3": 11.518649046996924,
        "cond_entropy-3": 0.8519220068409887,
        "total_length-nopunct": 5700,
        "mean_pred_length-nopunct": 11.4,
        "std_pred_length-nopunct": 6.7421064957474535,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.17035087719298245,
        "vocab_size-1-nopunct": 971,
        "unique-1-nopunct": 528,
        "entropy-1-nopunct": 8.014064501635385,
        "distinct-2-nopunct": 0.49403846153846154,
        "vocab_size-2-nopunct": 2569,
        "unique-2-nopunct": 1811,
        "entropy-2-nopunct": 10.52594534085047,
        "cond_entropy-2-nopunct": 2.638773149402421,
        "distinct-3-nopunct": 0.7088472990216929,
        "vocab_size-3-nopunct": 3333,
        "unique-3-nopunct": 2760,
        "entropy-3-nopunct": 11.31912978220647,
        "cond_entropy-3-nopunct": 0.8357910640783212,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.57091,
            "recall": 0.54555,
            "fmeasure": 0.5477
        },
        "rouge2": {
            "precision": 0.35793,
            "recall": 0.34205,
            "fmeasure": 0.34283
        },
        "rougeL": {
            "precision": 0.51765,
            "recall": 0.49467,
            "fmeasure": 0.49668
        },
        "rougeLsum": {
            "precision": 0.51765,
            "recall": 0.49467,
            "fmeasure": 0.49668
        },
        "local_recall": {
            "1": 0.5602231131253268
        },
        "nist": 6.144462444305595,
        "bleu": 32.22122,
        "bleurt": -0.0762,
        "nubia": {
            "semantic_relation": 3.63381,
            "contradiction": 6.248,
            "irrelevancy": 22.81932,
            "logical_agreement": 70.93268,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.67038,
            "nubia_score": 0.64295
        },
        "meteor": 0.31472410991873645,
        "bertscore": {
            "precision": 0.87181,
            "recall": 0.8635,
            "f1": 0.86713
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_114": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 28,
        "msttr-100": 0.7575,
        "msttr-100_nopunct": 0.8,
        "total_length": 497,
        "mean_pred_length": 17.75,
        "std_pred_length": 5.822523998601097,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.5855130784708249,
        "vocab_size-1": 291,
        "unique-1": 238,
        "entropy-1": 7.386947726253399,
        "distinct-2": 0.9317697228144989,
        "vocab_size-2": 437,
        "unique-2": 416,
        "entropy-2": 8.702785050644794,
        "cond_entropy-2": 1.1225716165258321,
        "distinct-3": 0.9931972789115646,
        "vocab_size-3": 438,
        "unique-3": 435,
        "entropy-3": 8.771029403380695,
        "cond_entropy-3": 0.0745447013353585,
        "total_length-nopunct": 438,
        "mean_pred_length-nopunct": 15.642857142857142,
        "std_pred_length-nopunct": 4.79742703148771,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6552511415525114,
        "vocab_size-1-nopunct": 287,
        "unique-1-nopunct": 238,
        "entropy-1-nopunct": 7.555539150635803,
        "distinct-2-nopunct": 0.9365853658536586,
        "vocab_size-2-nopunct": 384,
        "unique-2-nopunct": 368,
        "entropy-2-nopunct": 8.515372264102703,
        "cond_entropy-2-nopunct": 1.0207331535878283,
        "distinct-3-nopunct": 0.9921465968586387,
        "vocab_size-3-nopunct": 379,
        "unique-3-nopunct": 376,
        "entropy-3-nopunct": 8.561722021753054,
        "cond_entropy-3-nopunct": 0.055760803177277406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76275,
            "recall": 0.69996,
            "fmeasure": 0.72134
        },
        "rouge2": {
            "precision": 0.53346,
            "recall": 0.50015,
            "fmeasure": 0.51087
        },
        "rougeL": {
            "precision": 0.68742,
            "recall": 0.63173,
            "fmeasure": 0.65102
        },
        "rougeLsum": {
            "precision": 0.68742,
            "recall": 0.63173,
            "fmeasure": 0.65102
        },
        "local_recall": {
            "1": 0.11538461538461539,
            "2": 0.56,
            "3": 0.7309941520467836
        },
        "nist": 6.407548173272781,
        "bleu": 44.07855,
        "bleurt": 0.23597,
        "nubia": {
            "semantic_relation": 4.05472,
            "contradiction": 8.02455,
            "irrelevancy": 36.52513,
            "logical_agreement": 55.45032,
            "grammar_ref": 4.55489,
            "grammar_hyp": 4.74683,
            "nubia_score": 0.66877
        },
        "meteor": 0.374020901867296,
        "bertscore": {
            "precision": 0.92288,
            "recall": 0.91751,
            "f1": 0.91785
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_22": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.665,
        "msttr-100_nopunct": 0.695,
        "total_length": 294,
        "mean_pred_length": 17.294117647058822,
        "std_pred_length": 9.522510209605528,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 45,
        "distinct-1": 0.5748299319727891,
        "vocab_size-1": 169,
        "unique-1": 139,
        "entropy-1": 6.636283313297698,
        "distinct-2": 0.8989169675090253,
        "vocab_size-2": 249,
        "unique-2": 230,
        "entropy-2": 7.867299341116052,
        "cond_entropy-2": 1.0710481163079506,
        "distinct-3": 0.9692307692307692,
        "vocab_size-3": 252,
        "unique-3": 244,
        "entropy-3": 7.960829351489991,
        "cond_entropy-3": 0.10195127200422895,
        "total_length-nopunct": 261,
        "mean_pred_length-nopunct": 15.352941176470589,
        "std_pred_length-nopunct": 8.567662708735531,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.6360153256704981,
        "vocab_size-1-nopunct": 166,
        "unique-1-nopunct": 139,
        "entropy-1-nopunct": 6.74640404672096,
        "distinct-2-nopunct": 0.9057377049180327,
        "vocab_size-2-nopunct": 221,
        "unique-2-nopunct": 207,
        "entropy-2-nopunct": 7.691947737126411,
        "cond_entropy-2-nopunct": 1.0157964648220943,
        "distinct-3-nopunct": 0.973568281938326,
        "vocab_size-3-nopunct": 221,
        "unique-3-nopunct": 215,
        "entropy-3-nopunct": 7.773685051167549,
        "cond_entropy-3-nopunct": 0.09521494931609178,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71973,
            "recall": 0.66331,
            "fmeasure": 0.66426
        },
        "rouge2": {
            "precision": 0.44901,
            "recall": 0.42872,
            "fmeasure": 0.42832
        },
        "rougeL": {
            "precision": 0.62075,
            "recall": 0.58512,
            "fmeasure": 0.5802
        },
        "rougeLsum": {
            "precision": 0.62075,
            "recall": 0.58512,
            "fmeasure": 0.5802
        },
        "local_recall": {
            "1": 0.05263157894736842,
            "2": 0.578125,
            "3": 0.7426900584795322
        },
        "nist": 5.8340590000367625,
        "bleu": 52.7646,
        "bleurt": 0.25465,
        "nubia": {
            "semantic_relation": 4.06733,
            "contradiction": 2.63128,
            "irrelevancy": 22.62136,
            "logical_agreement": 74.74736,
            "grammar_ref": 4.31337,
            "grammar_hyp": 4.40345,
            "nubia_score": 0.66853
        },
        "meteor": 0.39701078663909345,
        "bertscore": {
            "precision": 0.91809,
            "recall": 0.90906,
            "f1": 0.91213
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_23": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.64,
        "msttr-100_nopunct": 0.71,
        "total_length": 123,
        "mean_pred_length": 17.571428571428573,
        "std_pred_length": 7.594305062858293,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 34,
        "distinct-1": 0.6341463414634146,
        "vocab_size-1": 78,
        "unique-1": 61,
        "entropy-1": 5.894256806399821,
        "distinct-2": 0.896551724137931,
        "vocab_size-2": 104,
        "unique-2": 96,
        "entropy-2": 6.6250538398805405,
        "cond_entropy-2": 0.6246446148442835,
        "distinct-3": 0.9541284403669725,
        "vocab_size-3": 104,
        "unique-3": 101,
        "entropy-3": 6.662590058682173,
        "cond_entropy-3": 0.05249484345051886,
        "total_length-nopunct": 105,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 7.050835816716038,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.6952380952380952,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.902014922283789,
        "distinct-2-nopunct": 0.9081632653061225,
        "vocab_size-2-nopunct": 89,
        "unique-2-nopunct": 83,
        "entropy-2-nopunct": 6.407927573640825,
        "cond_entropy-2-nopunct": 0.5639291224557578,
        "distinct-3-nopunct": 0.967032967032967,
        "vocab_size-3-nopunct": 88,
        "unique-3-nopunct": 86,
        "entropy-3-nopunct": 6.433565107207895,
        "cond_entropy-3-nopunct": 0.04154386206510244,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76827,
            "recall": 0.75589,
            "fmeasure": 0.75602
        },
        "rouge2": {
            "precision": 0.52804,
            "recall": 0.5108,
            "fmeasure": 0.51489
        },
        "rougeL": {
            "precision": 0.6151,
            "recall": 0.62166,
            "fmeasure": 0.61197
        },
        "rougeLsum": {
            "precision": 0.6151,
            "recall": 0.62166,
            "fmeasure": 0.61197
        },
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.46153846153846156,
            "3": 0.7066666666666667
        },
        "nist": 4.746577494443653,
        "bleu": 38.47604,
        "bleurt": 0.27108,
        "nubia": {
            "semantic_relation": 4.11056,
            "contradiction": 3.88141,
            "irrelevancy": 44.30452,
            "logical_agreement": 51.81407,
            "grammar_ref": 4.51794,
            "grammar_hyp": 4.3316,
            "nubia_score": 0.73601
        },
        "meteor": 0.35127400980565604,
        "bertscore": {
            "precision": 0.91777,
            "recall": 0.91576,
            "f1": 0.91315
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 79,
        "msttr-100": 0.64081,
        "msttr-100_nopunct": 0.67375,
        "total_length": 3704,
        "mean_pred_length": 46.88607594936709,
        "std_pred_length": 10.811371582176914,
        "median_pred_length": 48.0,
        "min_pred_length": 20,
        "max_pred_length": 80,
        "distinct-1": 0.17818574514038876,
        "vocab_size-1": 660,
        "unique-1": 287,
        "entropy-1": 7.554826341618419,
        "distinct-2": 0.4162758620689655,
        "vocab_size-2": 1509,
        "unique-2": 889,
        "entropy-2": 9.935142154163204,
        "cond_entropy-2": 2.303462292763606,
        "distinct-3": 0.5634517766497462,
        "vocab_size-3": 1998,
        "unique-3": 1371,
        "entropy-3": 10.57360210500177,
        "cond_entropy-3": 0.6555679245121152,
        "total_length-nopunct": 3283,
        "mean_pred_length-nopunct": 41.55696202531646,
        "std_pred_length-nopunct": 9.680656473506929,
        "median_pred_length-nopunct": 43.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 71,
        "distinct-1-nopunct": 0.19890344197380444,
        "vocab_size-1-nopunct": 653,
        "unique-1-nopunct": 284,
        "entropy-1-nopunct": 7.767829010610454,
        "distinct-2-nopunct": 0.4419475655430712,
        "vocab_size-2-nopunct": 1416,
        "unique-2-nopunct": 872,
        "entropy-2-nopunct": 9.885655559263876,
        "cond_entropy-2-nopunct": 2.1629532657765886,
        "distinct-3-nopunct": 0.58624,
        "vocab_size-3-nopunct": 1832,
        "unique-3-nopunct": 1299,
        "entropy-3-nopunct": 10.459902253235281,
        "cond_entropy-3-nopunct": 0.5775695286024258,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.71219,
            "recall": 0.63593,
            "fmeasure": 0.66639
        },
        "rouge2": {
            "precision": 0.41006,
            "recall": 0.3674,
            "fmeasure": 0.38402
        },
        "rougeL": {
            "precision": 0.47629,
            "recall": 0.42447,
            "fmeasure": 0.44458
        },
        "rougeLsum": {
            "precision": 0.47629,
            "recall": 0.42447,
            "fmeasure": 0.44458
        },
        "local_recall": {
            "1": 0.24859943977591037,
            "2": 0.4623513870541612,
            "3": 0.7684391080617495
        },
        "nist": 7.20826519180437,
        "bleu": 41.59368,
        "bleurt": -0.14052,
        "nubia": {
            "semantic_relation": 3.72194,
            "contradiction": 17.7354,
            "irrelevancy": 10.08289,
            "logical_agreement": 72.18171,
            "grammar_ref": 3.96506,
            "grammar_hyp": 4.01937,
            "nubia_score": 0.64109
        },
        "meteor": 0.3173190795861418,
        "bertscore": {
            "precision": 0.89371,
            "recall": 0.87836,
            "f1": 0.88484
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_87": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 49,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 8.993825042154695,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.7755102040816326,
        "vocab_size-1": 38,
        "unique-1": 30,
        "entropy-1": 5.10950805835677,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 44,
        "unique-2": 42,
        "entropy-2": 5.43660543431788,
        "cond_entropy-2": 0.25667819889832605,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.004273945540961598,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 8.524474568362947,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 5.047408651885229,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.297079327540667,
        "cond_entropy-2-nopunct": 0.2576071835919427,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": -0.0043511013524093305,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.54894,
            "recall": 0.60794,
            "fmeasure": 0.57141
        },
        "rouge2": {
            "precision": 0.3179,
            "recall": 0.37478,
            "fmeasure": 0.34027
        },
        "rougeL": {
            "precision": 0.51323,
            "recall": 0.57222,
            "fmeasure": 0.5357
        },
        "rougeLsum": {
            "precision": 0.51323,
            "recall": 0.57222,
            "fmeasure": 0.5357
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.18181818181818182,
            "3": 0.625
        },
        "nist": 2.7804779083303317,
        "bleu": 14.29744,
        "bleurt": 0.2114,
        "nubia": {
            "semantic_relation": 3.80949,
            "contradiction": 1.83705,
            "irrelevancy": 34.17449,
            "logical_agreement": 63.98847,
            "grammar_ref": 5.04645,
            "grammar_hyp": 4.57881,
            "nubia_score": 0.63005
        },
        "meteor": 0.2973599299893998,
        "bertscore": {
            "precision": 0.90148,
            "recall": 0.91522,
            "f1": 0.90826
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_115": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.79667,
        "total_length": 360,
        "mean_pred_length": 18.0,
        "std_pred_length": 7.6681158050723255,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 35,
        "distinct-1": 0.5722222222222222,
        "vocab_size-1": 206,
        "unique-1": 162,
        "entropy-1": 6.991748366362196,
        "distinct-2": 0.9,
        "vocab_size-2": 306,
        "unique-2": 283,
        "entropy-2": 8.183526266962767,
        "cond_entropy-2": 1.025788290899407,
        "distinct-3": 0.9625,
        "vocab_size-3": 308,
        "unique-3": 300,
        "entropy-3": 8.237492001110287,
        "cond_entropy-3": 0.05322325252670419,
        "total_length-nopunct": 303,
        "mean_pred_length-nopunct": 15.15,
        "std_pred_length-nopunct": 5.876010551386034,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6633663366336634,
        "vocab_size-1-nopunct": 201,
        "unique-1-nopunct": 162,
        "entropy-1-nopunct": 7.217983156025061,
        "distinct-2-nopunct": 0.9257950530035336,
        "vocab_size-2-nopunct": 262,
        "unique-2-nopunct": 246,
        "entropy-2-nopunct": 7.982911113818373,
        "cond_entropy-2-nopunct": 0.8091110551394652,
        "distinct-3-nopunct": 0.9657794676806084,
        "vocab_size-3-nopunct": 254,
        "unique-3-nopunct": 248,
        "entropy-3-nopunct": 7.961867040598447,
        "cond_entropy-3-nopunct": -0.012546192686625785,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80347,
            "recall": 0.81492,
            "fmeasure": 0.80504
        },
        "rouge2": {
            "precision": 0.64029,
            "recall": 0.646,
            "fmeasure": 0.63976
        },
        "rougeL": {
            "precision": 0.69457,
            "recall": 0.6931,
            "fmeasure": 0.68969
        },
        "rougeLsum": {
            "precision": 0.69457,
            "recall": 0.6931,
            "fmeasure": 0.68969
        },
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.5,
            "3": 0.8933333333333333
        },
        "nist": 6.604821615409235,
        "bleu": 59.17122,
        "bleurt": 0.497,
        "nubia": {
            "semantic_relation": 4.53108,
            "contradiction": 5.11413,
            "irrelevancy": 10.6337,
            "logical_agreement": 84.25218,
            "grammar_ref": 4.56897,
            "grammar_hyp": 4.51123,
            "nubia_score": 0.85352
        },
        "meteor": 0.45818397604356914,
        "bertscore": {
            "precision": 0.94222,
            "recall": 0.94715,
            "f1": 0.94357
        }
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 297,
        "msttr-100": 0.603,
        "msttr-100_nopunct": 0.64923,
        "total_length": 3075,
        "mean_pred_length": 10.353535353535353,
        "std_pred_length": 2.53452841819187,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 21,
        "distinct-1": 0.23479674796747968,
        "vocab_size-1": 722,
        "unique-1": 409,
        "entropy-1": 7.202610627896408,
        "distinct-2": 0.5550755939524838,
        "vocab_size-2": 1542,
        "unique-2": 1107,
        "entropy-2": 10.048511510013302,
        "cond_entropy-2": 2.436370270556957,
        "distinct-3": 0.731962918178154,
        "vocab_size-3": 1816,
        "unique-3": 1502,
        "entropy-3": 10.543921961512163,
        "cond_entropy-3": 0.5931852983816017,
        "total_length-nopunct": 2697,
        "mean_pred_length-nopunct": 9.080808080808081,
        "std_pred_length-nopunct": 2.2217630379581568,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.26548016314423434,
        "vocab_size-1-nopunct": 716,
        "unique-1-nopunct": 409,
        "entropy-1-nopunct": 7.454879947919586,
        "distinct-2-nopunct": 0.5295833333333333,
        "vocab_size-2-nopunct": 1271,
        "unique-2-nopunct": 882,
        "entropy-2-nopunct": 9.74542449276149,
        "cond_entropy-2-nopunct": 2.634266061471058,
        "distinct-3-nopunct": 0.7118402282453637,
        "vocab_size-3-nopunct": 1497,
        "unique-3-nopunct": 1214,
        "entropy-3-nopunct": 10.250084823287574,
        "cond_entropy-3-nopunct": 0.6477777543164885,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.71353,
            "recall": 0.7239,
            "fmeasure": 0.71074
        },
        "rouge2": {
            "precision": 0.456,
            "recall": 0.46548,
            "fmeasure": 0.45494
        },
        "rougeL": {
            "precision": 0.62283,
            "recall": 0.63538,
            "fmeasure": 0.62173
        },
        "rougeLsum": {
            "precision": 0.62283,
            "recall": 0.63538,
            "fmeasure": 0.62173
        },
        "local_recall": {
            "1": 0.2551299589603283,
            "2": 0.6414507772020726,
            "3": 0.756159728122345,
            "4": 1.0
        },
        "nist": 7.462866150909234,
        "bleu": 44.52008,
        "bleurt": 0.15184,
        "nubia": {
            "semantic_relation": 4.15782,
            "contradiction": 21.91078,
            "irrelevancy": 8.01148,
            "logical_agreement": 70.07774,
            "grammar_ref": 5.16054,
            "grammar_hyp": 5.27203,
            "nubia_score": 0.68036
        },
        "meteor": 0.39213040649490954,
        "bertscore": {
            "precision": 0.91728,
            "recall": 0.9214,
            "f1": 0.91838
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_66": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 48,
        "msttr-100": 0.73125,
        "msttr-100_nopunct": 0.78286,
        "total_length": 851,
        "mean_pred_length": 17.729166666666668,
        "std_pred_length": 7.707516848649909,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.5252643948296122,
        "vocab_size-1": 447,
        "unique-1": 367,
        "entropy-1": 7.721812235387883,
        "distinct-2": 0.900373599003736,
        "vocab_size-2": 723,
        "unique-2": 671,
        "entropy-2": 9.402739984471848,
        "cond_entropy-2": 1.467303275992685,
        "distinct-3": 0.9814569536423841,
        "vocab_size-3": 741,
        "unique-3": 727,
        "entropy-3": 9.523246741497118,
        "cond_entropy-3": 0.12823228982829465,
        "total_length-nopunct": 739,
        "mean_pred_length-nopunct": 15.395833333333334,
        "std_pred_length-nopunct": 6.960422590539233,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.5967523680649527,
        "vocab_size-1-nopunct": 441,
        "unique-1-nopunct": 366,
        "entropy-1-nopunct": 7.9520025593688555,
        "distinct-2-nopunct": 0.9059334298118669,
        "vocab_size-2-nopunct": 626,
        "unique-2-nopunct": 588,
        "entropy-2-nopunct": 9.190577189081061,
        "cond_entropy-2-nopunct": 1.3118333941754203,
        "distinct-3-nopunct": 0.9828926905132193,
        "vocab_size-3-nopunct": 632,
        "unique-3-nopunct": 621,
        "entropy-3-nopunct": 9.294460308354287,
        "cond_entropy-3-nopunct": 0.1170159048742737,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73787,
            "recall": 0.6872,
            "fmeasure": 0.70391
        },
        "rouge2": {
            "precision": 0.48183,
            "recall": 0.44313,
            "fmeasure": 0.45605
        },
        "rougeL": {
            "precision": 0.60189,
            "recall": 0.55926,
            "fmeasure": 0.57322
        },
        "rougeLsum": {
            "precision": 0.60189,
            "recall": 0.55926,
            "fmeasure": 0.57322
        },
        "local_recall": {
            "1": 0.22807017543859648,
            "2": 0.532051282051282,
            "3": 0.7181467181467182
        },
        "nist": 6.486888063900862,
        "bleu": 36.1445,
        "bleurt": 0.14419,
        "nubia": {
            "semantic_relation": 4.04928,
            "contradiction": 10.45547,
            "irrelevancy": 33.00054,
            "logical_agreement": 56.544,
            "grammar_ref": 4.63301,
            "grammar_hyp": 4.60521,
            "nubia_score": 0.7002
        },
        "meteor": 0.3586021205125473,
        "bertscore": {
            "precision": 0.919,
            "recall": 0.90754,
            "f1": 0.91087
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_67": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.48148,
            "recall": 0.37963,
            "fmeasure": 0.41124
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.20175,
            "fmeasure": 0.21605
        },
        "rougeL": {
            "precision": 0.48148,
            "recall": 0.37963,
            "fmeasure": 0.41124
        },
        "rougeLsum": {
            "precision": 0.48148,
            "recall": 0.37963,
            "fmeasure": 0.41124
        },
        "local_recall": {
            "1": 0,
            "2": 0.1111111111111111,
            "3": 0.375
        },
        "nist": 0.49043337177251445,
        "bleu": 11.99015,
        "bleurt": -0.37268,
        "nubia": {
            "semantic_relation": 3.39642,
            "contradiction": 0.48295,
            "irrelevancy": 47.67573,
            "logical_agreement": 51.84132,
            "grammar_ref": 4.8547,
            "grammar_hyp": 6.2731,
            "nubia_score": 0.31983
        },
        "meteor": 0.19099008512029023,
        "bertscore": {
            "precision": 0.86707,
            "recall": 0.86368,
            "f1": 0.86537
        }
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 72,
        "msttr-100": 0.635,
        "msttr-100_nopunct": 0.66286,
        "total_length": 864,
        "mean_pred_length": 12.0,
        "std_pred_length": 3.0776975521032313,
        "median_pred_length": 11.5,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.3576388888888889,
        "vocab_size-1": 309,
        "unique-1": 205,
        "entropy-1": 6.766521037610211,
        "distinct-2": 0.7121212121212122,
        "vocab_size-2": 564,
        "unique-2": 441,
        "entropy-2": 8.881354805975,
        "cond_entropy-2": 1.825601174102242,
        "distinct-3": 0.8305555555555556,
        "vocab_size-3": 598,
        "unique-3": 522,
        "entropy-3": 9.082008747822377,
        "cond_entropy-3": 0.26712078992436483,
        "total_length-nopunct": 748,
        "mean_pred_length-nopunct": 10.38888888888889,
        "std_pred_length-nopunct": 2.7005943561636965,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.40641711229946526,
        "vocab_size-1-nopunct": 304,
        "unique-1-nopunct": 204,
        "entropy-1-nopunct": 6.911915445853579,
        "distinct-2-nopunct": 0.7011834319526628,
        "vocab_size-2-nopunct": 474,
        "unique-2-nopunct": 362,
        "entropy-2-nopunct": 8.636064935702533,
        "cond_entropy-2-nopunct": 1.9641633300716723,
        "distinct-3-nopunct": 0.8245033112582781,
        "vocab_size-3-nopunct": 498,
        "unique-3-nopunct": 427,
        "entropy-3-nopunct": 8.831241375969787,
        "cond_entropy-3-nopunct": 0.2678531274201574,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.59582,
            "recall": 0.59651,
            "fmeasure": 0.5897
        },
        "rouge2": {
            "precision": 0.2901,
            "recall": 0.28893,
            "fmeasure": 0.28656
        },
        "rougeL": {
            "precision": 0.48912,
            "recall": 0.49176,
            "fmeasure": 0.48474
        },
        "rougeLsum": {
            "precision": 0.48912,
            "recall": 0.49176,
            "fmeasure": 0.48474
        },
        "local_recall": {
            "1": 0.27230046948356806,
            "2": 0.5057471264367817,
            "3": 0.6139817629179332
        },
        "nist": 5.03284700622793,
        "bleu": 25.47654,
        "bleurt": -0.31576,
        "nubia": {
            "semantic_relation": 3.56611,
            "contradiction": 33.16323,
            "irrelevancy": 15.73759,
            "logical_agreement": 51.09918,
            "grammar_ref": 5.29268,
            "grammar_hyp": 5.41652,
            "nubia_score": 0.50381
        },
        "meteor": 0.29562302566799553,
        "bertscore": {
            "precision": 0.86234,
            "recall": 0.86532,
            "f1": 0.86237
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_88": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 35,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.746,
        "total_length": 637,
        "mean_pred_length": 18.2,
        "std_pred_length": 8.324833760673972,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 41,
        "distinct-1": 0.5321821036106751,
        "vocab_size-1": 339,
        "unique-1": 262,
        "entropy-1": 7.461093881194253,
        "distinct-2": 0.8853820598006644,
        "vocab_size-2": 533,
        "unique-2": 491,
        "entropy-2": 8.940774861539552,
        "cond_entropy-2": 1.28689788032323,
        "distinct-3": 0.9541446208112875,
        "vocab_size-3": 541,
        "unique-3": 523,
        "entropy-3": 9.042249413470833,
        "cond_entropy-3": 0.1089693817948914,
        "total_length-nopunct": 559,
        "mean_pred_length-nopunct": 15.971428571428572,
        "std_pred_length-nopunct": 7.587530049027678,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.59391771019678,
        "vocab_size-1-nopunct": 332,
        "unique-1-nopunct": 261,
        "entropy-1-nopunct": 7.595030866350838,
        "distinct-2-nopunct": 0.8969465648854962,
        "vocab_size-2-nopunct": 470,
        "unique-2-nopunct": 439,
        "entropy-2-nopunct": 8.761872278708202,
        "cond_entropy-2-nopunct": 1.248155489126825,
        "distinct-3-nopunct": 0.9652351738241309,
        "vocab_size-3-nopunct": 472,
        "unique-3-nopunct": 459,
        "entropy-3-nopunct": 8.856983548603901,
        "cond_entropy-3-nopunct": 0.11045743615141157,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78547,
            "recall": 0.76038,
            "fmeasure": 0.76399
        },
        "rouge2": {
            "precision": 0.54064,
            "recall": 0.53308,
            "fmeasure": 0.52976
        },
        "rougeL": {
            "precision": 0.65822,
            "recall": 0.65274,
            "fmeasure": 0.64604
        },
        "rougeLsum": {
            "precision": 0.65822,
            "recall": 0.65274,
            "fmeasure": 0.64604
        },
        "local_recall": {
            "1": 0.19148936170212766,
            "2": 0.5309734513274337,
            "3": 0.760705289672544
        },
        "nist": 6.578070554604566,
        "bleu": 44.10085,
        "bleurt": 0.22785,
        "nubia": {
            "semantic_relation": 4.18436,
            "contradiction": 13.68079,
            "irrelevancy": 25.26933,
            "logical_agreement": 61.04987,
            "grammar_ref": 4.59802,
            "grammar_hyp": 4.6267,
            "nubia_score": 0.69681
        },
        "meteor": 0.3719554092829539,
        "bertscore": {
            "precision": 0.93258,
            "recall": 0.92439,
            "f1": 0.92623
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_116": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.73,
        "total_length": 305,
        "mean_pred_length": 17.941176470588236,
        "std_pred_length": 6.592960490377723,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 39,
        "distinct-1": 0.5573770491803278,
        "vocab_size-1": 170,
        "unique-1": 135,
        "entropy-1": 6.625702996322316,
        "distinct-2": 0.9166666666666666,
        "vocab_size-2": 264,
        "unique-2": 243,
        "entropy-2": 7.995394923294747,
        "cond_entropy-2": 1.2244540558367334,
        "distinct-3": 0.966789667896679,
        "vocab_size-3": 262,
        "unique-3": 253,
        "entropy-3": 8.015728377147196,
        "cond_entropy-3": 0.02390176133772297,
        "total_length-nopunct": 251,
        "mean_pred_length-nopunct": 14.764705882352942,
        "std_pred_length-nopunct": 5.082026133283571,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6613545816733067,
        "vocab_size-1-nopunct": 166,
        "unique-1-nopunct": 135,
        "entropy-1-nopunct": 6.857516781182907,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 221,
        "unique-2-nopunct": 210,
        "entropy-2-nopunct": 7.752801578539257,
        "cond_entropy-2-nopunct": 0.9498511654572613,
        "distinct-3-nopunct": 0.9861751152073732,
        "vocab_size-3-nopunct": 214,
        "unique-3-nopunct": 211,
        "entropy-3-nopunct": 7.73390146285924,
        "cond_entropy-3-nopunct": -0.014298394953086685,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79777,
            "recall": 0.76221,
            "fmeasure": 0.7733
        },
        "rouge2": {
            "precision": 0.56456,
            "recall": 0.534,
            "fmeasure": 0.54318
        },
        "rougeL": {
            "precision": 0.72349,
            "recall": 0.68432,
            "fmeasure": 0.69738
        },
        "rougeLsum": {
            "precision": 0.72349,
            "recall": 0.68432,
            "fmeasure": 0.69738
        },
        "local_recall": {
            "1": 0.041666666666666664,
            "2": 0.5,
            "3": 0.7751196172248804
        },
        "nist": 6.378979994508728,
        "bleu": 49.93854,
        "bleurt": 0.34014,
        "nubia": {
            "semantic_relation": 4.30609,
            "contradiction": 6.04427,
            "irrelevancy": 24.01293,
            "logical_agreement": 69.9428,
            "grammar_ref": 4.34644,
            "grammar_hyp": 4.49051,
            "nubia_score": 0.76252
        },
        "meteor": 0.4076942797588335,
        "bertscore": {
            "precision": 0.93596,
            "recall": 0.93406,
            "f1": 0.93411
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_68": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.738,
        "total_length": 667,
        "mean_pred_length": 18.52777777777778,
        "std_pred_length": 8.626464806728675,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 43,
        "distinct-1": 0.5367316341829086,
        "vocab_size-1": 358,
        "unique-1": 298,
        "entropy-1": 7.374987029885123,
        "distinct-2": 0.9128367670364501,
        "vocab_size-2": 576,
        "unique-2": 542,
        "entropy-2": 9.063358853450834,
        "cond_entropy-2": 1.5078943483119498,
        "distinct-3": 0.9747899159663865,
        "vocab_size-3": 580,
        "unique-3": 566,
        "entropy-3": 9.165056971637036,
        "cond_entropy-3": 0.10938373885028017,
        "total_length-nopunct": 582,
        "mean_pred_length-nopunct": 16.166666666666668,
        "std_pred_length-nopunct": 7.977398629182879,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.6030927835051546,
        "vocab_size-1-nopunct": 351,
        "unique-1-nopunct": 297,
        "entropy-1-nopunct": 7.532391128685333,
        "distinct-2-nopunct": 0.9139194139194139,
        "vocab_size-2-nopunct": 499,
        "unique-2-nopunct": 473,
        "entropy-2-nopunct": 8.846851165633248,
        "cond_entropy-2-nopunct": 1.4008145822027516,
        "distinct-3-nopunct": 0.9764705882352941,
        "vocab_size-3-nopunct": 498,
        "unique-3-nopunct": 487,
        "entropy-3-nopunct": 8.945814441756466,
        "cond_entropy-3-nopunct": 0.11239977633964551,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78291,
            "recall": 0.73541,
            "fmeasure": 0.74612
        },
        "rouge2": {
            "precision": 0.54829,
            "recall": 0.50954,
            "fmeasure": 0.51908
        },
        "rougeL": {
            "precision": 0.67575,
            "recall": 0.64044,
            "fmeasure": 0.64716
        },
        "rougeLsum": {
            "precision": 0.67575,
            "recall": 0.64044,
            "fmeasure": 0.64716
        },
        "local_recall": {
            "1": 0.2702702702702703,
            "2": 0.3258426966292135,
            "3": 0.7941888619854721
        },
        "nist": 7.035192553785571,
        "bleu": 46.58185,
        "bleurt": 0.31642,
        "nubia": {
            "semantic_relation": 4.27238,
            "contradiction": 7.36667,
            "irrelevancy": 25.23762,
            "logical_agreement": 67.39572,
            "grammar_ref": 4.82696,
            "grammar_hyp": 4.77676,
            "nubia_score": 0.7405
        },
        "meteor": 0.38559200222018924,
        "bertscore": {
            "precision": 0.93699,
            "recall": 0.92713,
            "f1": 0.93033
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_117": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.8,
        "total_length": 152,
        "mean_pred_length": 19.0,
        "std_pred_length": 9.40744386111339,
        "median_pred_length": 17.5,
        "min_pred_length": 10,
        "max_pred_length": 42,
        "distinct-1": 0.6907894736842105,
        "vocab_size-1": 105,
        "unique-1": 91,
        "entropy-1": 6.2968660011081266,
        "distinct-2": 0.9652777777777778,
        "vocab_size-2": 139,
        "unique-2": 135,
        "entropy-2": 7.095238282677307,
        "cond_entropy-2": 0.6845423655877837,
        "distinct-3": 1.0,
        "vocab_size-3": 136,
        "unique-3": 136,
        "entropy-3": 7.0874628412503275,
        "cond_entropy-3": -0.00338210502900628,
        "total_length-nopunct": 125,
        "mean_pred_length-nopunct": 15.625,
        "std_pred_length-nopunct": 6.243746871871088,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.808,
        "vocab_size-1-nopunct": 101,
        "unique-1-nopunct": 91,
        "entropy-1-nopunct": 6.415282333357029,
        "distinct-2-nopunct": 0.9914529914529915,
        "vocab_size-2-nopunct": 116,
        "unique-2-nopunct": 115,
        "entropy-2-nopunct": 6.853270702489366,
        "cond_entropy-2-nopunct": 0.4670825196489527,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 109,
        "unique-3-nopunct": 109,
        "entropy-3-nopunct": 6.7681843247769145,
        "cond_entropy-3-nopunct": -0.08383177095326728,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77962,
            "recall": 0.72404,
            "fmeasure": 0.74475
        },
        "rouge2": {
            "precision": 0.51412,
            "recall": 0.48105,
            "fmeasure": 0.49232
        },
        "rougeL": {
            "precision": 0.65499,
            "recall": 0.61902,
            "fmeasure": 0.63098
        },
        "rougeLsum": {
            "precision": 0.65499,
            "recall": 0.61902,
            "fmeasure": 0.63098
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.5128205128205128,
            "3": 0.7931034482758621
        },
        "nist": 5.130647070308332,
        "bleu": 33.94797,
        "bleurt": 0.19742,
        "nubia": {
            "semantic_relation": 4.03545,
            "contradiction": 12.41983,
            "irrelevancy": 43.88532,
            "logical_agreement": 43.69486,
            "grammar_ref": 4.12019,
            "grammar_hyp": 4.26307,
            "nubia_score": 0.68952
        },
        "meteor": 0.3581964264253891,
        "bertscore": {
            "precision": 0.92467,
            "recall": 0.92779,
            "f1": 0.92466
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_69": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 87,
        "mean_pred_length": 14.5,
        "std_pred_length": 5.5901699437494745,
        "median_pred_length": 13.5,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.7011494252873564,
        "vocab_size-1": 61,
        "unique-1": 48,
        "entropy-1": 5.681280708417802,
        "distinct-2": 0.9629629629629629,
        "vocab_size-2": 78,
        "unique-2": 75,
        "entropy-2": 6.26577592881054,
        "cond_entropy-2": 0.44943598237124843,
        "distinct-3": 1.0,
        "vocab_size-3": 75,
        "unique-3": 75,
        "entropy-3": 6.228818690495891,
        "cond_entropy-3": -0.031031312388743987,
        "total_length-nopunct": 76,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 5.280993172584954,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7631578947368421,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.685363204204596,
        "distinct-2-nopunct": 0.9714285714285714,
        "vocab_size-2-nopunct": 68,
        "unique-2-nopunct": 66,
        "entropy-2-nopunct": 6.072140159802115,
        "cond_entropy-2-nopunct": 0.39213961067514475,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 64,
        "unique-3-nopunct": 64,
        "entropy-3-nopunct": 6.0,
        "cond_entropy-3-nopunct": -0.08240801694496637,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74215,
            "recall": 0.57127,
            "fmeasure": 0.63518
        },
        "rouge2": {
            "precision": 0.41453,
            "recall": 0.33488,
            "fmeasure": 0.36479
        },
        "rougeL": {
            "precision": 0.60264,
            "recall": 0.46694,
            "fmeasure": 0.51615
        },
        "rougeLsum": {
            "precision": 0.60264,
            "recall": 0.46694,
            "fmeasure": 0.51615
        },
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.5,
            "3": 0.6896551724137931
        },
        "nist": 4.470793573162614,
        "bleu": 36.59248,
        "bleurt": 0.13057,
        "nubia": {
            "semantic_relation": 3.86801,
            "contradiction": 12.85168,
            "irrelevancy": 39.1603,
            "logical_agreement": 47.98802,
            "grammar_ref": 3.92533,
            "grammar_hyp": 4.35893,
            "nubia_score": 0.67642
        },
        "meteor": 0.316670242958439,
        "bertscore": {
            "precision": 0.91977,
            "recall": 0.89044,
            "f1": 0.9045
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_119": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.77,
        "msttr-100_nopunct": NaN,
        "total_length": 102,
        "mean_pred_length": 14.571428571428571,
        "std_pred_length": 3.0169588688489823,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 18,
        "distinct-1": 0.7647058823529411,
        "vocab_size-1": 78,
        "unique-1": 64,
        "entropy-1": 6.076632205371823,
        "distinct-2": 0.9894736842105263,
        "vocab_size-2": 94,
        "unique-2": 93,
        "entropy-2": 6.548802976752,
        "cond_entropy-2": 0.3092135871885444,
        "distinct-3": 1.0,
        "vocab_size-3": 88,
        "unique-3": 88,
        "entropy-3": 6.459431618637305,
        "cond_entropy-3": -0.08769671696637776,
        "total_length-nopunct": 87,
        "mean_pred_length-nopunct": 12.428571428571429,
        "std_pred_length-nopunct": 2.6108095546424375,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8390804597701149,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 63,
        "entropy-1-nopunct": 6.07093742715217,
        "distinct-2-nopunct": 0.9875,
        "vocab_size-2-nopunct": 79,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.296928094887356,
        "cond_entropy-2-nopunct": 0.2460411987461374,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 73,
        "entropy-3-nopunct": 6.189824558880028,
        "cond_entropy-3-nopunct": -0.11840490587035891,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75397,
            "recall": 0.75358,
            "fmeasure": 0.74889
        },
        "rouge2": {
            "precision": 0.54014,
            "recall": 0.54162,
            "fmeasure": 0.53667
        },
        "rougeL": {
            "precision": 0.65147,
            "recall": 0.6471,
            "fmeasure": 0.64639
        },
        "rougeLsum": {
            "precision": 0.65147,
            "recall": 0.6471,
            "fmeasure": 0.64639
        },
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.5,
            "3": 0.7936507936507936
        },
        "nist": 5.120051814485277,
        "bleu": 45.28488,
        "bleurt": 0.28368,
        "nubia": {
            "semantic_relation": 4.39702,
            "contradiction": 1.94581,
            "irrelevancy": 38.89921,
            "logical_agreement": 59.15499,
            "grammar_ref": 4.57228,
            "grammar_hyp": 4.44079,
            "nubia_score": 0.79184
        },
        "meteor": 0.4111025983882565,
        "bertscore": {
            "precision": 0.93149,
            "recall": 0.94583,
            "f1": 0.93679
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_24": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 169,
        "msttr-100": 0.70714,
        "msttr-100_nopunct": 0.755,
        "total_length": 2829,
        "mean_pred_length": 16.7396449704142,
        "std_pred_length": 6.542778836514329,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 40,
        "distinct-1": 0.39908094733121247,
        "vocab_size-1": 1129,
        "unique-1": 857,
        "entropy-1": 8.38917828737323,
        "distinct-2": 0.7875939849624061,
        "vocab_size-2": 2095,
        "unique-2": 1864,
        "entropy-2": 10.707827678646147,
        "cond_entropy-2": 2.0412577899992455,
        "distinct-3": 0.9100762745885187,
        "vocab_size-3": 2267,
        "unique-3": 2161,
        "entropy-3": 11.026143377558121,
        "cond_entropy-3": 0.3327040929021423,
        "total_length-nopunct": 2458,
        "mean_pred_length-nopunct": 14.544378698224852,
        "std_pred_length-nopunct": 5.668305508340001,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.4544344995931652,
        "vocab_size-1-nopunct": 1117,
        "unique-1-nopunct": 856,
        "entropy-1-nopunct": 8.69497785738129,
        "distinct-2-nopunct": 0.8051550895587593,
        "vocab_size-2-nopunct": 1843,
        "unique-2-nopunct": 1666,
        "entropy-2-nopunct": 10.526803135767963,
        "cond_entropy-2-nopunct": 1.940497319027305,
        "distinct-3-nopunct": 0.9150943396226415,
        "vocab_size-3-nopunct": 1940,
        "unique-3-nopunct": 1858,
        "entropy-3-nopunct": 10.804636022969586,
        "cond_entropy-3-nopunct": 0.30617884818891167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7794,
            "recall": 0.7525,
            "fmeasure": 0.75455
        },
        "rouge2": {
            "precision": 0.55961,
            "recall": 0.54142,
            "fmeasure": 0.54236
        },
        "rougeL": {
            "precision": 0.6788,
            "recall": 0.65605,
            "fmeasure": 0.65742
        },
        "rougeLsum": {
            "precision": 0.6788,
            "recall": 0.65605,
            "fmeasure": 0.65742
        },
        "local_recall": {
            "1": 0.2196652719665272,
            "2": 0.41797752808988764,
            "3": 0.7948717948717948
        },
        "nist": 8.128363946923448,
        "bleu": 47.74719,
        "bleurt": 0.3173,
        "nubia": {
            "semantic_relation": 4.23552,
            "contradiction": 6.97124,
            "irrelevancy": 26.245,
            "logical_agreement": 66.78375,
            "grammar_ref": 4.66226,
            "grammar_hyp": 4.64205,
            "nubia_score": 0.75226
        },
        "meteor": 0.40297378433510617,
        "bertscore": {
            "precision": 0.93401,
            "recall": 0.92774,
            "f1": 0.92925
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_90": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 78,
        "msttr-100": 0.73077,
        "msttr-100_nopunct": 0.77,
        "total_length": 1334,
        "mean_pred_length": 17.102564102564102,
        "std_pred_length": 6.856757369960398,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 35,
        "distinct-1": 0.4790104947526237,
        "vocab_size-1": 639,
        "unique-1": 479,
        "entropy-1": 8.106552565885199,
        "distinct-2": 0.8590764331210191,
        "vocab_size-2": 1079,
        "unique-2": 963,
        "entropy-2": 9.933579245001733,
        "cond_entropy-2": 1.5768310992564982,
        "distinct-3": 0.9490662139219015,
        "vocab_size-3": 1118,
        "unique-3": 1061,
        "entropy-3": 10.097917637495804,
        "cond_entropy-3": 0.1574594237308032,
        "total_length-nopunct": 1166,
        "mean_pred_length-nopunct": 14.948717948717949,
        "std_pred_length-nopunct": 5.937489402738042,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.5394511149228131,
        "vocab_size-1-nopunct": 629,
        "unique-1-nopunct": 476,
        "entropy-1-nopunct": 8.340859436975146,
        "distinct-2-nopunct": 0.8676470588235294,
        "vocab_size-2-nopunct": 944,
        "unique-2-nopunct": 851,
        "entropy-2-nopunct": 9.741011734749783,
        "cond_entropy-2-nopunct": 1.479534179942834,
        "distinct-3-nopunct": 0.9534653465346534,
        "vocab_size-3-nopunct": 963,
        "unique-3-nopunct": 918,
        "entropy-3-nopunct": 9.885090072688651,
        "cond_entropy-3-nopunct": 0.1619230768567492,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76621,
            "recall": 0.74214,
            "fmeasure": 0.74406
        },
        "rouge2": {
            "precision": 0.53821,
            "recall": 0.51741,
            "fmeasure": 0.52083
        },
        "rougeL": {
            "precision": 0.69395,
            "recall": 0.66852,
            "fmeasure": 0.67223
        },
        "rougeLsum": {
            "precision": 0.69395,
            "recall": 0.66852,
            "fmeasure": 0.67223
        },
        "local_recall": {
            "1": 0.21030042918454936,
            "2": 0.5148936170212766,
            "3": 0.7883211678832117
        },
        "nist": 7.431811092525514,
        "bleu": 48.61596,
        "bleurt": 0.30494,
        "nubia": {
            "semantic_relation": 4.3533,
            "contradiction": 4.51437,
            "irrelevancy": 37.17779,
            "logical_agreement": 58.30784,
            "grammar_ref": 4.66269,
            "grammar_hyp": 4.7085,
            "nubia_score": 0.76452
        },
        "meteor": 0.413586702285325,
        "bertscore": {
            "precision": 0.92678,
            "recall": 0.92911,
            "f1": 0.92649
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_91": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.765,
        "total_length": 263,
        "mean_pred_length": 14.61111111111111,
        "std_pred_length": 5.100532530899635,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.623574144486692,
        "vocab_size-1": 164,
        "unique-1": 134,
        "entropy-1": 6.74387988220917,
        "distinct-2": 0.9346938775510204,
        "vocab_size-2": 229,
        "unique-2": 216,
        "entropy-2": 7.794781255320297,
        "cond_entropy-2": 0.8396852665867719,
        "distinct-3": 0.986784140969163,
        "vocab_size-3": 224,
        "unique-3": 221,
        "entropy-3": 7.800116769229222,
        "cond_entropy-3": 0.016584061513734163,
        "total_length-nopunct": 235,
        "mean_pred_length-nopunct": 13.055555555555555,
        "std_pred_length-nopunct": 4.89299070351573,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6851063829787234,
        "vocab_size-1-nopunct": 161,
        "unique-1-nopunct": 133,
        "entropy-1-nopunct": 6.867975201356795,
        "distinct-2-nopunct": 0.9308755760368663,
        "vocab_size-2-nopunct": 202,
        "unique-2-nopunct": 190,
        "entropy-2-nopunct": 7.6106070504068715,
        "cond_entropy-2-nopunct": 0.8024651504892508,
        "distinct-3-nopunct": 0.9899497487437185,
        "vocab_size-3-nopunct": 197,
        "unique-3-nopunct": 195,
        "entropy-3-nopunct": 7.616524118031097,
        "cond_entropy-3-nopunct": 0.004494933336172017,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73823,
            "recall": 0.68834,
            "fmeasure": 0.70707
        },
        "rouge2": {
            "precision": 0.4754,
            "recall": 0.43749,
            "fmeasure": 0.44985
        },
        "rougeL": {
            "precision": 0.6054,
            "recall": 0.56352,
            "fmeasure": 0.57837
        },
        "rougeLsum": {
            "precision": 0.6054,
            "recall": 0.56352,
            "fmeasure": 0.57837
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.42857142857142855,
            "3": 0.7705882352941177
        },
        "nist": 5.570511360375506,
        "bleu": 36.65475,
        "bleurt": 0.20627,
        "nubia": {
            "semantic_relation": 4.18132,
            "contradiction": 5.60604,
            "irrelevancy": 40.61164,
            "logical_agreement": 53.78232,
            "grammar_ref": 4.90853,
            "grammar_hyp": 4.79768,
            "nubia_score": 0.70825
        },
        "meteor": 0.35325587517687124,
        "bertscore": {
            "precision": 0.92209,
            "recall": 0.91845,
            "f1": 0.91916
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_120": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 75,
        "msttr-100": 0.71846,
        "msttr-100_nopunct": 0.78455,
        "total_length": 1302,
        "mean_pred_length": 17.36,
        "std_pred_length": 6.7124560830344855,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 47,
        "distinct-1": 0.4731182795698925,
        "vocab_size-1": 616,
        "unique-1": 475,
        "entropy-1": 8.021956345215711,
        "distinct-2": 0.8329258353708231,
        "vocab_size-2": 1022,
        "unique-2": 900,
        "entropy-2": 9.823042517538456,
        "cond_entropy-2": 1.5589807425603055,
        "distinct-3": 0.9236111111111112,
        "vocab_size-3": 1064,
        "unique-3": 992,
        "entropy-3": 10.003902101298001,
        "cond_entropy-3": 0.17602833745142515,
        "total_length-nopunct": 1113,
        "mean_pred_length-nopunct": 14.84,
        "std_pred_length-nopunct": 5.174398515769732,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.5462713387241689,
        "vocab_size-1-nopunct": 608,
        "unique-1-nopunct": 474,
        "entropy-1-nopunct": 8.31763603033988,
        "distinct-2-nopunct": 0.8477842003853564,
        "vocab_size-2-nopunct": 880,
        "unique-2-nopunct": 789,
        "entropy-2-nopunct": 9.609331405795649,
        "cond_entropy-2-nopunct": 1.369875443416043,
        "distinct-3-nopunct": 0.936656282450675,
        "vocab_size-3-nopunct": 902,
        "unique-3-nopunct": 852,
        "entropy-3-nopunct": 9.773288438041105,
        "cond_entropy-3-nopunct": 0.17894103971103487,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77695,
            "recall": 0.75119,
            "fmeasure": 0.75434
        },
        "rouge2": {
            "precision": 0.56729,
            "recall": 0.55916,
            "fmeasure": 0.55525
        },
        "rougeL": {
            "precision": 0.66702,
            "recall": 0.65746,
            "fmeasure": 0.65364
        },
        "rougeLsum": {
            "precision": 0.66702,
            "recall": 0.65746,
            "fmeasure": 0.65364
        },
        "local_recall": {
            "1": 0.2528301886792453,
            "2": 0.42592592592592593,
            "3": 0.780891719745223
        },
        "nist": 7.353075784374874,
        "bleu": 47.6293,
        "bleurt": 0.18825,
        "nubia": {
            "semantic_relation": 4.1277,
            "contradiction": 8.13617,
            "irrelevancy": 34.33613,
            "logical_agreement": 57.5277,
            "grammar_ref": 4.90125,
            "grammar_hyp": 4.99154,
            "nubia_score": 0.68696
        },
        "meteor": 0.3964739246455198,
        "bertscore": {
            "precision": 0.92627,
            "recall": 0.92634,
            "f1": 0.92457
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_121": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 52,
        "mean_pred_length": 13.0,
        "std_pred_length": 3.6742346141747673,
        "median_pred_length": 12.5,
        "min_pred_length": 9,
        "max_pred_length": 18,
        "distinct-1": 0.7115384615384616,
        "vocab_size-1": 37,
        "unique-1": 31,
        "entropy-1": 4.8994496324794925,
        "distinct-2": 0.9791666666666666,
        "vocab_size-2": 47,
        "unique-2": 46,
        "entropy-2": 5.5432958340544936,
        "cond_entropy-2": 0.5439287087134651,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": -0.08007633662931368,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.6742346141747673,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 4.883889907921091,
        "distinct-2-nopunct": 0.9772727272727273,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.413977073182751,
        "cond_entropy-2-nopunct": 0.5938210373343962,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.08750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.61475,
            "recall": 0.60094,
            "fmeasure": 0.5954
        },
        "rouge2": {
            "precision": 0.3009,
            "recall": 0.33397,
            "fmeasure": 0.30906
        },
        "rougeL": {
            "precision": 0.4871,
            "recall": 0.50273,
            "fmeasure": 0.48593
        },
        "rougeLsum": {
            "precision": 0.4871,
            "recall": 0.50273,
            "fmeasure": 0.48593
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.5714285714285714,
            "3": 0.5675675675675675
        },
        "nist": 3.3755113107158703,
        "bleu": 28.38361,
        "bleurt": 0.03753,
        "nubia": {
            "semantic_relation": 3.357,
            "contradiction": 13.53938,
            "irrelevancy": 49.28532,
            "logical_agreement": 37.1753,
            "grammar_ref": 5.13429,
            "grammar_hyp": 4.58104,
            "nubia_score": 0.57459
        },
        "meteor": 0.32745524117082475,
        "bertscore": {
            "precision": 0.88887,
            "recall": 0.86453,
            "f1": 0.87395
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_123": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 81,
        "mean_pred_length": 20.25,
        "std_pred_length": 6.7592529172978875,
        "median_pred_length": 20.5,
        "min_pred_length": 13,
        "max_pred_length": 27,
        "distinct-1": 0.7283950617283951,
        "vocab_size-1": 59,
        "unique-1": 47,
        "entropy-1": 5.660596299074076,
        "distinct-2": 0.935064935064935,
        "vocab_size-2": 72,
        "unique-2": 67,
        "entropy-2": 6.1369164108247745,
        "cond_entropy-2": 0.4077099145460409,
        "distinct-3": 0.9726027397260274,
        "vocab_size-3": 71,
        "unique-3": 69,
        "entropy-3": 6.135030038332083,
        "cond_entropy-3": 0.005229799007033957,
        "total_length-nopunct": 69,
        "mean_pred_length-nopunct": 17.25,
        "std_pred_length-nopunct": 5.3091901453988255,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7971014492753623,
        "vocab_size-1-nopunct": 55,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.651861050918354,
        "distinct-2-nopunct": 0.9538461538461539,
        "vocab_size-2-nopunct": 62,
        "unique-2-nopunct": 59,
        "entropy-2-nopunct": 5.930060120720766,
        "cond_entropy-2-nopunct": 0.3063014332399306,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 61,
        "unique-3-nopunct": 61,
        "entropy-3-nopunct": 5.930737337562883,
        "cond_entropy-3-nopunct": 0.006730180272136583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79312,
            "recall": 0.89276,
            "fmeasure": 0.83462
        },
        "rouge2": {
            "precision": 0.66262,
            "recall": 0.74936,
            "fmeasure": 0.6982
        },
        "rougeL": {
            "precision": 0.73077,
            "recall": 0.80776,
            "fmeasure": 0.76366
        },
        "rougeLsum": {
            "precision": 0.73077,
            "recall": 0.80776,
            "fmeasure": 0.76366
        },
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.5,
            "3": 0.8775510204081632
        },
        "nist": 5.441131578961176,
        "bleu": 58.54027,
        "bleurt": 0.44785,
        "nubia": {
            "semantic_relation": 4.16729,
            "contradiction": 9.18899,
            "irrelevancy": 32.00321,
            "logical_agreement": 58.8078,
            "grammar_ref": 5.56433,
            "grammar_hyp": 4.87744,
            "nubia_score": 0.79064
        },
        "meteor": 0.4616549303216627,
        "bertscore": {
            "precision": 0.95536,
            "recall": 0.95666,
            "f1": 0.95444
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_92": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 22,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.77,
        "total_length": 331,
        "mean_pred_length": 15.045454545454545,
        "std_pred_length": 5.085427243401864,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 26,
        "distinct-1": 0.5921450151057401,
        "vocab_size-1": 196,
        "unique-1": 163,
        "entropy-1": 6.821709884354392,
        "distinct-2": 0.9320388349514563,
        "vocab_size-2": 288,
        "unique-2": 277,
        "entropy-2": 8.089053552251931,
        "cond_entropy-2": 1.0601268714054255,
        "distinct-3": 0.9860627177700348,
        "vocab_size-3": 283,
        "unique-3": 279,
        "entropy-3": 8.137032362215722,
        "cond_entropy-3": 0.06196141785354432,
        "total_length-nopunct": 289,
        "mean_pred_length-nopunct": 13.136363636363637,
        "std_pred_length-nopunct": 4.673867918792106,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6539792387543253,
        "vocab_size-1-nopunct": 189,
        "unique-1-nopunct": 158,
        "entropy-1-nopunct": 6.943089331678084,
        "distinct-2-nopunct": 0.9288389513108615,
        "vocab_size-2-nopunct": 248,
        "unique-2-nopunct": 239,
        "entropy-2-nopunct": 7.864574104059803,
        "cond_entropy-2-nopunct": 1.004257805033788,
        "distinct-3-nopunct": 0.9918367346938776,
        "vocab_size-3-nopunct": 243,
        "unique-3-nopunct": 241,
        "entropy-3-nopunct": 7.920311408390358,
        "cond_entropy-3-nopunct": 0.07334824395420095,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7418,
            "recall": 0.7594,
            "fmeasure": 0.74178
        },
        "rouge2": {
            "precision": 0.49716,
            "recall": 0.50463,
            "fmeasure": 0.4944
        },
        "rougeL": {
            "precision": 0.63762,
            "recall": 0.66095,
            "fmeasure": 0.64039
        },
        "rougeLsum": {
            "precision": 0.63762,
            "recall": 0.66095,
            "fmeasure": 0.64039
        },
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.4727272727272727,
            "3": 0.8206521739130435
        },
        "nist": 5.871669924868802,
        "bleu": 39.92087,
        "bleurt": 0.24684,
        "nubia": {
            "semantic_relation": 4.18653,
            "contradiction": 8.74312,
            "irrelevancy": 31.98821,
            "logical_agreement": 59.26867,
            "grammar_ref": 5.03776,
            "grammar_hyp": 5.02964,
            "nubia_score": 0.70821
        },
        "meteor": 0.38008728788789925,
        "bertscore": {
            "precision": 0.92157,
            "recall": 0.93296,
            "f1": 0.92619
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_70": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 81,
        "msttr-100": 0.72643,
        "msttr-100_nopunct": 0.78667,
        "total_length": 1459,
        "mean_pred_length": 18.012345679012345,
        "std_pred_length": 7.227338063591898,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 43,
        "distinct-1": 0.46675805346127486,
        "vocab_size-1": 681,
        "unique-1": 532,
        "entropy-1": 8.099874224474384,
        "distinct-2": 0.8497822931785196,
        "vocab_size-2": 1171,
        "unique-2": 1055,
        "entropy-2": 10.0397311162315,
        "cond_entropy-2": 1.7038297802096123,
        "distinct-3": 0.938319198149576,
        "vocab_size-3": 1217,
        "unique-3": 1157,
        "entropy-3": 10.205582675555696,
        "cond_entropy-3": 0.14425943142825076,
        "total_length-nopunct": 1233,
        "mean_pred_length-nopunct": 15.222222222222221,
        "std_pred_length-nopunct": 5.956633401635649,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.5450121654501217,
        "vocab_size-1-nopunct": 672,
        "unique-1-nopunct": 529,
        "entropy-1-nopunct": 8.444315501388589,
        "distinct-2-nopunct": 0.8706597222222222,
        "vocab_size-2-nopunct": 1003,
        "unique-2-nopunct": 919,
        "entropy-2-nopunct": 9.835361020642484,
        "cond_entropy-2-nopunct": 1.4745447715857216,
        "distinct-3-nopunct": 0.942110177404295,
        "vocab_size-3-nopunct": 1009,
        "unique-3-nopunct": 964,
        "entropy-3-nopunct": 9.936523051834792,
        "cond_entropy-3-nopunct": 0.11806182805943853,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77418,
            "recall": 0.75534,
            "fmeasure": 0.74987
        },
        "rouge2": {
            "precision": 0.58356,
            "recall": 0.56334,
            "fmeasure": 0.56144
        },
        "rougeL": {
            "precision": 0.67256,
            "recall": 0.65739,
            "fmeasure": 0.65135
        },
        "rougeLsum": {
            "precision": 0.67256,
            "recall": 0.65739,
            "fmeasure": 0.65135
        },
        "local_recall": {
            "1": 0.2354948805460751,
            "2": 0.5193798449612403,
            "3": 0.8079625292740047
        },
        "nist": 7.644280207126137,
        "bleu": 52.71164,
        "bleurt": 0.27446,
        "nubia": {
            "semantic_relation": 4.18212,
            "contradiction": 5.66146,
            "irrelevancy": 30.66079,
            "logical_agreement": 63.67776,
            "grammar_ref": 4.67017,
            "grammar_hyp": 4.64905,
            "nubia_score": 0.72788
        },
        "meteor": 0.4230460319242427,
        "bertscore": {
            "precision": 0.93309,
            "recall": 0.93218,
            "f1": 0.93101
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_93": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 99,
        "mean_pred_length": 19.8,
        "std_pred_length": 11.373653766490344,
        "median_pred_length": 19.0,
        "min_pred_length": 9,
        "max_pred_length": 40,
        "distinct-1": 0.696969696969697,
        "vocab_size-1": 69,
        "unique-1": 52,
        "entropy-1": 5.846267858106581,
        "distinct-2": 0.925531914893617,
        "vocab_size-2": 87,
        "unique-2": 80,
        "entropy-2": 6.405652681464862,
        "cond_entropy-2": 0.47753166735221586,
        "distinct-3": 0.9550561797752809,
        "vocab_size-3": 85,
        "unique-3": 81,
        "entropy-3": 6.38584579051697,
        "cond_entropy-3": -0.011439690374160871,
        "total_length-nopunct": 87,
        "mean_pred_length-nopunct": 17.4,
        "std_pred_length-nopunct": 9.871170143402452,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.7586206896551724,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.863559910141063,
        "distinct-2-nopunct": 0.926829268292683,
        "vocab_size-2-nopunct": 76,
        "unique-2-nopunct": 70,
        "entropy-2-nopunct": 6.211210541203451,
        "cond_entropy-2-nopunct": 0.346393532629925,
        "distinct-3-nopunct": 0.961038961038961,
        "vocab_size-3-nopunct": 74,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 6.188864462772826,
        "cond_entropy-3-nopunct": -0.012843386001104563,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70786,
            "recall": 0.87078,
            "fmeasure": 0.7763
        },
        "rouge2": {
            "precision": 0.49895,
            "recall": 0.62409,
            "fmeasure": 0.54992
        },
        "rougeL": {
            "precision": 0.64214,
            "recall": 0.78893,
            "fmeasure": 0.70358
        },
        "rougeLsum": {
            "precision": 0.64214,
            "recall": 0.78893,
            "fmeasure": 0.70358
        },
        "local_recall": {
            "1": 0.19047619047619047,
            "2": 0.75,
            "3": 0.9130434782608695
        },
        "nist": 4.809858306920404,
        "bleu": 41.25339,
        "bleurt": 0.38474,
        "nubia": {
            "semantic_relation": 4.2982,
            "contradiction": 1.80918,
            "irrelevancy": 38.47098,
            "logical_agreement": 59.71983,
            "grammar_ref": 4.96303,
            "grammar_hyp": 4.43664,
            "nubia_score": 0.77174
        },
        "meteor": 0.3854343715216753,
        "bertscore": {
            "precision": 0.93615,
            "recall": 0.94995,
            "f1": 0.94239
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_25": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 56,
        "msttr-100": 0.73222,
        "msttr-100_nopunct": 0.78571,
        "total_length": 916,
        "mean_pred_length": 16.357142857142858,
        "std_pred_length": 4.9223563297200155,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.5152838427947598,
        "vocab_size-1": 472,
        "unique-1": 384,
        "entropy-1": 7.769621540860197,
        "distinct-2": 0.9058139534883721,
        "vocab_size-2": 779,
        "unique-2": 731,
        "entropy-2": 9.51699981193656,
        "cond_entropy-2": 1.5023256722996463,
        "distinct-3": 0.9701492537313433,
        "vocab_size-3": 780,
        "unique-3": 761,
        "entropy-3": 9.586045892041557,
        "cond_entropy-3": 0.07674747638153868,
        "total_length-nopunct": 794,
        "mean_pred_length-nopunct": 14.178571428571429,
        "std_pred_length-nopunct": 4.3797714505649346,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5831234256926953,
        "vocab_size-1-nopunct": 463,
        "unique-1-nopunct": 382,
        "entropy-1-nopunct": 8.001417269582959,
        "distinct-2-nopunct": 0.907859078590786,
        "vocab_size-2-nopunct": 670,
        "unique-2-nopunct": 631,
        "entropy-2-nopunct": 9.297386948644558,
        "cond_entropy-2-nopunct": 1.3985531287170558,
        "distinct-3-nopunct": 0.969208211143695,
        "vocab_size-3-nopunct": 661,
        "unique-3-nopunct": 644,
        "entropy-3-nopunct": 9.346898053651222,
        "cond_entropy-3-nopunct": 0.06608013831242239,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77548,
            "recall": 0.71716,
            "fmeasure": 0.73326
        },
        "rouge2": {
            "precision": 0.53038,
            "recall": 0.49054,
            "fmeasure": 0.50171
        },
        "rougeL": {
            "precision": 0.68394,
            "recall": 0.63124,
            "fmeasure": 0.64562
        },
        "rougeLsum": {
            "precision": 0.68394,
            "recall": 0.63124,
            "fmeasure": 0.64562
        },
        "local_recall": {
            "1": 0.17989417989417988,
            "2": 0.4050632911392405,
            "3": 0.7601246105919003
        },
        "nist": 6.815405396157785,
        "bleu": 44.02164,
        "bleurt": 0.26217,
        "nubia": {
            "semantic_relation": 4.20988,
            "contradiction": 9.25492,
            "irrelevancy": 26.07085,
            "logical_agreement": 64.67423,
            "grammar_ref": 4.75668,
            "grammar_hyp": 4.76895,
            "nubia_score": 0.7188
        },
        "meteor": 0.3894927708441344,
        "bertscore": {
            "precision": 0.92791,
            "recall": 0.91783,
            "f1": 0.9216
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_94": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 24.0,
        "std_pred_length": 15.0,
        "median_pred_length": 24.0,
        "min_pred_length": 9,
        "max_pred_length": 39,
        "distinct-1": 0.625,
        "vocab_size-1": 30,
        "unique-1": 21,
        "entropy-1": 4.6271673246578855,
        "distinct-2": 0.8478260869565217,
        "vocab_size-2": 39,
        "unique-2": 34,
        "entropy-2": 5.175735869100489,
        "cond_entropy-2": 0.5467335520975329,
        "distinct-3": 0.9090909090909091,
        "vocab_size-3": 40,
        "unique-3": 36,
        "entropy-3": 5.277613436819113,
        "cond_entropy-3": 0.1176878443984663,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 8.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.601409765557392,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": 0.3320535123473009,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.09953567355091442,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70833,
            "recall": 0.613,
            "fmeasure": 0.65658
        },
        "rouge2": {
            "precision": 0.51967,
            "recall": 0.44988,
            "fmeasure": 0.48167
        },
        "rougeL": {
            "precision": 0.65972,
            "recall": 0.61363,
            "fmeasure": 0.63183
        },
        "rougeLsum": {
            "precision": 0.65972,
            "recall": 0.61363,
            "fmeasure": 0.63183
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.6296296296296297
        },
        "nist": 5.289685058976778,
        "bleu": 66.34376,
        "bleurt": 0.26442,
        "nubia": {
            "semantic_relation": 4.46761,
            "contradiction": 0.33499,
            "irrelevancy": 17.54806,
            "logical_agreement": 82.11694,
            "grammar_ref": 4.15024,
            "grammar_hyp": 4.23063,
            "nubia_score": 0.86186
        },
        "meteor": 0.4092187667561949,
        "bertscore": {
            "precision": 0.93634,
            "recall": 0.89955,
            "f1": 0.91737
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_124": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.62,
        "msttr-100_nopunct": 0.725,
        "total_length": 281,
        "mean_pred_length": 20.071428571428573,
        "std_pred_length": 14.058369574813462,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 65,
        "distinct-1": 0.5409252669039146,
        "vocab_size-1": 152,
        "unique-1": 121,
        "entropy-1": 6.4151610184760415,
        "distinct-2": 0.850187265917603,
        "vocab_size-2": 227,
        "unique-2": 199,
        "entropy-2": 7.710942830619155,
        "cond_entropy-2": 1.1862939668833048,
        "distinct-3": 0.924901185770751,
        "vocab_size-3": 234,
        "unique-3": 216,
        "entropy-3": 7.829812201167944,
        "cond_entropy-3": 0.08443025173661328,
        "total_length-nopunct": 228,
        "mean_pred_length-nopunct": 16.285714285714285,
        "std_pred_length-nopunct": 9.85921303313064,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.6491228070175439,
        "vocab_size-1-nopunct": 148,
        "unique-1-nopunct": 121,
        "entropy-1-nopunct": 6.593147048251033,
        "distinct-2-nopunct": 0.897196261682243,
        "vocab_size-2-nopunct": 192,
        "unique-2-nopunct": 174,
        "entropy-2-nopunct": 7.510112897595852,
        "cond_entropy-2-nopunct": 0.9739120013137933,
        "distinct-3-nopunct": 0.935,
        "vocab_size-3-nopunct": 187,
        "unique-3-nopunct": 174,
        "entropy-3-nopunct": 7.513856189774739,
        "cond_entropy-3-nopunct": 0.009938078395212237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7624,
            "recall": 0.73599,
            "fmeasure": 0.7377
        },
        "rouge2": {
            "precision": 0.5106,
            "recall": 0.49345,
            "fmeasure": 0.49595
        },
        "rougeL": {
            "precision": 0.63388,
            "recall": 0.61048,
            "fmeasure": 0.61294
        },
        "rougeLsum": {
            "precision": 0.63388,
            "recall": 0.61048,
            "fmeasure": 0.61294
        },
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.4444444444444444,
            "3": 0.7294117647058823
        },
        "nist": 5.361100664470583,
        "bleu": 40.29008,
        "bleurt": 0.36423,
        "nubia": {
            "semantic_relation": 4.47785,
            "contradiction": 10.04151,
            "irrelevancy": 17.61843,
            "logical_agreement": 72.34006,
            "grammar_ref": 4.7817,
            "grammar_hyp": 4.8596,
            "nubia_score": 0.78481
        },
        "meteor": 0.38766234423224083,
        "bertscore": {
            "precision": 0.93158,
            "recall": 0.93496,
            "f1": 0.93213
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_125": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.76,
        "total_length": 133,
        "mean_pred_length": 22.166666666666668,
        "std_pred_length": 10.542243067245646,
        "median_pred_length": 17.5,
        "min_pred_length": 12,
        "max_pred_length": 39,
        "distinct-1": 0.6766917293233082,
        "vocab_size-1": 90,
        "unique-1": 72,
        "entropy-1": 6.157852011168178,
        "distinct-2": 0.9448818897637795,
        "vocab_size-2": 120,
        "unique-2": 115,
        "entropy-2": 6.8665604741396535,
        "cond_entropy-2": 0.6289825381027658,
        "distinct-3": 0.9917355371900827,
        "vocab_size-3": 120,
        "unique-3": 119,
        "entropy-3": 6.902334311654768,
        "cond_entropy-3": 0.04182958359603974,
        "total_length-nopunct": 109,
        "mean_pred_length-nopunct": 18.166666666666668,
        "std_pred_length-nopunct": 7.536946036396675,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.7706422018348624,
        "vocab_size-1-nopunct": 84,
        "unique-1-nopunct": 71,
        "entropy-1-nopunct": 6.153326067816792,
        "distinct-2-nopunct": 0.970873786407767,
        "vocab_size-2-nopunct": 100,
        "unique-2-nopunct": 98,
        "entropy-2-nopunct": 6.620919095123395,
        "cond_entropy-2-nopunct": 0.4937012752848396,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 97,
        "unique-3-nopunct": 97,
        "entropy-3-nopunct": 6.599912842187142,
        "cond_entropy-3-nopunct": -0.016949669509869356,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83784,
            "recall": 0.84304,
            "fmeasure": 0.83386
        },
        "rouge2": {
            "precision": 0.62976,
            "recall": 0.62966,
            "fmeasure": 0.62483
        },
        "rougeL": {
            "precision": 0.71743,
            "recall": 0.71073,
            "fmeasure": 0.70873
        },
        "rougeLsum": {
            "precision": 0.71743,
            "recall": 0.71073,
            "fmeasure": 0.70873
        },
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.5,
            "3": 0.9012345679012346
        },
        "nist": 5.430624295990215,
        "bleu": 49.90151,
        "bleurt": 0.42494,
        "nubia": {
            "semantic_relation": 4.65848,
            "contradiction": 1.26746,
            "irrelevancy": 21.88769,
            "logical_agreement": 76.84484,
            "grammar_ref": 5.04309,
            "grammar_hyp": 4.78647,
            "nubia_score": 0.88564
        },
        "meteor": 0.435273661823577,
        "bertscore": {
            "precision": 0.94729,
            "recall": 0.95083,
            "f1": 0.94858
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_26": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.64,
        "msttr-100_nopunct": 0.675,
        "total_length": 251,
        "mean_pred_length": 20.916666666666668,
        "std_pred_length": 11.521417254641703,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 53,
        "distinct-1": 0.4940239043824701,
        "vocab_size-1": 124,
        "unique-1": 92,
        "entropy-1": 6.213711706696537,
        "distinct-2": 0.7866108786610879,
        "vocab_size-2": 188,
        "unique-2": 159,
        "entropy-2": 7.366082132130895,
        "cond_entropy-2": 1.0606316478543794,
        "distinct-3": 0.8854625550660793,
        "vocab_size-3": 201,
        "unique-3": 183,
        "entropy-3": 7.564390888152895,
        "cond_entropy-3": 0.200147593511921,
        "total_length-nopunct": 208,
        "mean_pred_length-nopunct": 17.333333333333332,
        "std_pred_length-nopunct": 9.222556888171281,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.5673076923076923,
        "vocab_size-1-nopunct": 118,
        "unique-1-nopunct": 92,
        "entropy-1-nopunct": 6.202299473746045,
        "distinct-2-nopunct": 0.826530612244898,
        "vocab_size-2-nopunct": 162,
        "unique-2-nopunct": 144,
        "entropy-2-nopunct": 7.1641804434835725,
        "cond_entropy-2-nopunct": 0.9923793520474239,
        "distinct-3-nopunct": 0.907608695652174,
        "vocab_size-3-nopunct": 167,
        "unique-3-nopunct": 155,
        "entropy-3-nopunct": 7.312937567458312,
        "cond_entropy-3-nopunct": 0.15096556314634055,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76557,
            "recall": 0.76466,
            "fmeasure": 0.75982
        },
        "rouge2": {
            "precision": 0.61103,
            "recall": 0.61221,
            "fmeasure": 0.60603
        },
        "rougeL": {
            "precision": 0.73437,
            "recall": 0.73597,
            "fmeasure": 0.72795
        },
        "rougeLsum": {
            "precision": 0.73437,
            "recall": 0.73597,
            "fmeasure": 0.72795
        },
        "local_recall": {
            "1": 0.13513513513513514,
            "2": 0.5277777777777778,
            "3": 0.8776978417266187
        },
        "nist": 6.2291149879887975,
        "bleu": 64.95864,
        "bleurt": 0.44568,
        "nubia": {
            "semantic_relation": 4.07071,
            "contradiction": 8.52256,
            "irrelevancy": 30.67526,
            "logical_agreement": 60.80218,
            "grammar_ref": 4.07585,
            "grammar_hyp": 3.96064,
            "nubia_score": 0.73902
        },
        "meteor": 0.46978091869575717,
        "bertscore": {
            "precision": 0.93911,
            "recall": 0.93905,
            "f1": 0.93854
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_95": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.748,
        "msttr-100_nopunct": 0.805,
        "total_length": 565,
        "mean_pred_length": 18.225806451612904,
        "std_pred_length": 7.263295605943159,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 35,
        "distinct-1": 0.5858407079646017,
        "vocab_size-1": 331,
        "unique-1": 275,
        "entropy-1": 7.567693837240638,
        "distinct-2": 0.8932584269662921,
        "vocab_size-2": 477,
        "unique-2": 437,
        "entropy-2": 8.812248301606937,
        "cond_entropy-2": 1.0483498280364825,
        "distinct-3": 0.9642147117296223,
        "vocab_size-3": 485,
        "unique-3": 469,
        "entropy-3": 8.898867870123585,
        "cond_entropy-3": 0.09247839362670979,
        "total_length-nopunct": 482,
        "mean_pred_length-nopunct": 15.548387096774194,
        "std_pred_length-nopunct": 6.063314911921022,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6701244813278008,
        "vocab_size-1-nopunct": 323,
        "unique-1-nopunct": 271,
        "entropy-1-nopunct": 7.79744440794931,
        "distinct-2-nopunct": 0.9068736141906873,
        "vocab_size-2-nopunct": 409,
        "unique-2-nopunct": 379,
        "entropy-2-nopunct": 8.599874649949564,
        "cond_entropy-2-nopunct": 0.868935408909327,
        "distinct-3-nopunct": 0.9714285714285714,
        "vocab_size-3-nopunct": 408,
        "unique-3-nopunct": 396,
        "entropy-3-nopunct": 8.657102660523277,
        "cond_entropy-3-nopunct": 0.06709804788734193,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83787,
            "recall": 0.80988,
            "fmeasure": 0.81297
        },
        "rouge2": {
            "precision": 0.65989,
            "recall": 0.64191,
            "fmeasure": 0.64295
        },
        "rougeL": {
            "precision": 0.74821,
            "recall": 0.72777,
            "fmeasure": 0.72917
        },
        "rougeLsum": {
            "precision": 0.74821,
            "recall": 0.72777,
            "fmeasure": 0.72917
        },
        "local_recall": {
            "1": 0.26548672566371684,
            "2": 0.4897959183673469,
            "3": 0.8347107438016529
        },
        "nist": 7.54843281524762,
        "bleu": 63.46353,
        "bleurt": 0.41073,
        "nubia": {
            "semantic_relation": 4.29916,
            "contradiction": 11.63368,
            "irrelevancy": 21.87067,
            "logical_agreement": 66.49565,
            "grammar_ref": 4.87083,
            "grammar_hyp": 4.8061,
            "nubia_score": 0.74762
        },
        "meteor": 0.46650564026843794,
        "bertscore": {
            "precision": 0.94753,
            "recall": 0.94125,
            "f1": 0.94367
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_27": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 40,
        "msttr-100": 0.65167,
        "msttr-100_nopunct": 0.686,
        "total_length": 659,
        "mean_pred_length": 16.475,
        "std_pred_length": 8.03737363819799,
        "median_pred_length": 14.5,
        "min_pred_length": 7,
        "max_pred_length": 45,
        "distinct-1": 0.44916540212443096,
        "vocab_size-1": 296,
        "unique-1": 239,
        "entropy-1": 6.950761791738995,
        "distinct-2": 0.7867528271405493,
        "vocab_size-2": 487,
        "unique-2": 435,
        "entropy-2": 8.648986047416315,
        "cond_entropy-2": 1.5102723828747333,
        "distinct-3": 0.8791018998272885,
        "vocab_size-3": 509,
        "unique-3": 480,
        "entropy-3": 8.848615053628361,
        "cond_entropy-3": 0.2345815011512504,
        "total_length-nopunct": 567,
        "mean_pred_length-nopunct": 14.175,
        "std_pred_length-nopunct": 6.967379349511551,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.5114638447971781,
        "vocab_size-1-nopunct": 290,
        "unique-1-nopunct": 238,
        "entropy-1-nopunct": 7.097940963719731,
        "distinct-2-nopunct": 0.7874762808349146,
        "vocab_size-2-nopunct": 415,
        "unique-2-nopunct": 373,
        "entropy-2-nopunct": 8.410082366813567,
        "cond_entropy-2-nopunct": 1.4215625115594215,
        "distinct-3-nopunct": 0.8829568788501027,
        "vocab_size-3-nopunct": 430,
        "unique-3-nopunct": 407,
        "entropy-3-nopunct": 8.607217112106047,
        "cond_entropy-3-nopunct": 0.22487228921609148,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7503,
            "recall": 0.74004,
            "fmeasure": 0.73105
        },
        "rouge2": {
            "precision": 0.53216,
            "recall": 0.52592,
            "fmeasure": 0.51692
        },
        "rougeL": {
            "precision": 0.6633,
            "recall": 0.65736,
            "fmeasure": 0.64721
        },
        "rougeLsum": {
            "precision": 0.6633,
            "recall": 0.65736,
            "fmeasure": 0.64721
        },
        "local_recall": {
            "1": 0.1794871794871795,
            "2": 0.38461538461538464,
            "3": 0.7659574468085106
        },
        "nist": 6.30405058770347,
        "bleu": 45.49587,
        "bleurt": 0.31645,
        "nubia": {
            "semantic_relation": 4.11009,
            "contradiction": 8.76226,
            "irrelevancy": 27.81406,
            "logical_agreement": 63.42367,
            "grammar_ref": 4.3823,
            "grammar_hyp": 4.40222,
            "nubia_score": 0.70965
        },
        "meteor": 0.3965064183030569,
        "bertscore": {
            "precision": 0.92822,
            "recall": 0.93396,
            "f1": 0.92916
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 898,
        "msttr-100": 0.70786,
        "msttr-100_nopunct": 0.76247,
        "total_length": 9857,
        "mean_pred_length": 10.976614699331849,
        "std_pred_length": 3.7949252406411964,
        "median_pred_length": 10.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.33204829055493557,
        "vocab_size-1": 3273,
        "unique-1": 2458,
        "entropy-1": 9.0334759820201,
        "distinct-2": 0.6885813148788927,
        "vocab_size-2": 6169,
        "unique-2": 5362,
        "entropy-2": 11.943574072041942,
        "cond_entropy-2": 2.350116352511499,
        "distinct-3": 0.8393499565810694,
        "vocab_size-3": 6766,
        "unique-3": 6179,
        "entropy-3": 12.510854224163069,
        "cond_entropy-3": 0.54045701739033,
        "total_length-nopunct": 8573,
        "mean_pred_length-nopunct": 9.546770601336302,
        "std_pred_length-nopunct": 3.347461165196506,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.38038026361833666,
        "vocab_size-1-nopunct": 3261,
        "unique-1-nopunct": 2456,
        "entropy-1-nopunct": 9.513354588305615,
        "distinct-2-nopunct": 0.710358306188925,
        "vocab_size-2-nopunct": 5452,
        "unique-2-nopunct": 4806,
        "entropy-2-nopunct": 11.786625405191057,
        "cond_entropy-2-nopunct": 2.4832380044886597,
        "distinct-3-nopunct": 0.8450641876936698,
        "vocab_size-3-nopunct": 5727,
        "unique-3-nopunct": 5246,
        "entropy-3-nopunct": 12.278039480635659,
        "cond_entropy-3-nopunct": 0.5715080355486982,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75195,
            "recall": 0.71982,
            "fmeasure": 0.72055
        },
        "rouge2": {
            "precision": 0.55807,
            "recall": 0.53532,
            "fmeasure": 0.53518
        },
        "rougeL": {
            "precision": 0.70739,
            "recall": 0.68189,
            "fmeasure": 0.68059
        },
        "rougeLsum": {
            "precision": 0.70739,
            "recall": 0.68189,
            "fmeasure": 0.68059
        },
        "local_recall": {
            "1": 0.23104549082202713,
            "2": 0.5472636815920398,
            "3": 0.7431107823192158
        },
        "nist": 8.728409216518624,
        "bleu": 49.81213,
        "bleurt": 0.30474,
        "nubia": {
            "semantic_relation": 4.08998,
            "contradiction": 11.00222,
            "irrelevancy": 28.88157,
            "logical_agreement": 60.11621,
            "grammar_ref": 5.09815,
            "grammar_hyp": 5.12565,
            "nubia_score": 0.69931
        },
        "meteor": 0.39931416796531594,
        "bertscore": {
            "precision": 0.93033,
            "recall": 0.92506,
            "f1": 0.92625
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_96": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 50,
        "msttr-100": 0.7075,
        "msttr-100_nopunct": 0.75714,
        "total_length": 854,
        "mean_pred_length": 17.08,
        "std_pred_length": 8.05689766597541,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 50,
        "distinct-1": 0.5374707259953162,
        "vocab_size-1": 459,
        "unique-1": 383,
        "entropy-1": 7.708149848226926,
        "distinct-2": 0.9029850746268657,
        "vocab_size-2": 726,
        "unique-2": 685,
        "entropy-2": 9.385363768511272,
        "cond_entropy-2": 1.452468038544133,
        "distinct-3": 0.986737400530504,
        "vocab_size-3": 744,
        "unique-3": 734,
        "entropy-3": 9.531895514329557,
        "cond_entropy-3": 0.13814282759422614,
        "total_length-nopunct": 738,
        "mean_pred_length-nopunct": 14.76,
        "std_pred_length-nopunct": 6.2755398174181,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.6138211382113821,
        "vocab_size-1-nopunct": 453,
        "unique-1-nopunct": 382,
        "entropy-1-nopunct": 7.951261333390101,
        "distinct-2-nopunct": 0.9258720930232558,
        "vocab_size-2-nopunct": 637,
        "unique-2-nopunct": 610,
        "entropy-2-nopunct": 9.216835536112693,
        "cond_entropy-2-nopunct": 1.3414219080293566,
        "distinct-3-nopunct": 0.9937304075235109,
        "vocab_size-3-nopunct": 634,
        "unique-3-nopunct": 630,
        "entropy-3-nopunct": 9.304873428811888,
        "cond_entropy-3-nopunct": 0.09818124838799307,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76497,
            "recall": 0.71044,
            "fmeasure": 0.72855
        },
        "rouge2": {
            "precision": 0.51745,
            "recall": 0.49476,
            "fmeasure": 0.49906
        },
        "rougeL": {
            "precision": 0.67778,
            "recall": 0.64136,
            "fmeasure": 0.65129
        },
        "rougeLsum": {
            "precision": 0.67778,
            "recall": 0.64136,
            "fmeasure": 0.65129
        },
        "local_recall": {
            "1": 0.24,
            "2": 0.4591194968553459,
            "3": 0.7427007299270073
        },
        "nist": 6.7906594491821055,
        "bleu": 43.56705,
        "bleurt": 0.2382,
        "nubia": {
            "semantic_relation": 4.22065,
            "contradiction": 13.85125,
            "irrelevancy": 23.10014,
            "logical_agreement": 63.0486,
            "grammar_ref": 4.7145,
            "grammar_hyp": 4.83125,
            "nubia_score": 0.71995
        },
        "meteor": 0.37532597091385833,
        "bertscore": {
            "precision": 0.9253,
            "recall": 0.91643,
            "f1": 0.91961
        }
    },
    "web_nlg_en_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 1295,
        "msttr-100": 0.63876,
        "msttr-100_nopunct": 0.67976,
        "total_length": 37817,
        "mean_pred_length": 29.202316602316603,
        "std_pred_length": 11.273674978865879,
        "median_pred_length": 27.0,
        "min_pred_length": 8,
        "max_pred_length": 80,
        "distinct-1": 0.055636354020678534,
        "vocab_size-1": 2104,
        "unique-1": 694,
        "entropy-1": 8.071494978924932,
        "distinct-2": 0.20801160944088495,
        "vocab_size-2": 7597,
        "unique-2": 3783,
        "entropy-2": 11.449187836424233,
        "cond_entropy-2": 3.2353015683298327,
        "distinct-3": 0.379793908081869,
        "vocab_size-3": 13379,
        "unique-3": 8292,
        "entropy-3": 12.775071562756562,
        "cond_entropy-3": 1.3710066205101619,
        "total_length-nopunct": 33404,
        "mean_pred_length-nopunct": 25.794594594594596,
        "std_pred_length-nopunct": 10.183693611319873,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 71,
        "distinct-1-nopunct": 0.0626571668063705,
        "vocab_size-1-nopunct": 2093,
        "unique-1-nopunct": 693,
        "entropy-1-nopunct": 8.366800183725584,
        "distinct-2-nopunct": 0.22710143573452926,
        "vocab_size-2-nopunct": 7292,
        "unique-2-nopunct": 3857,
        "entropy-2-nopunct": 11.415049513233276,
        "cond_entropy-2-nopunct": 3.16532915621497,
        "distinct-3-nopunct": 0.4025118452651392,
        "vocab_size-3-nopunct": 12403,
        "unique-3-nopunct": 8048,
        "entropy-3-nopunct": 12.670564117492457,
        "cond_entropy-3-nopunct": 1.2946369865070604,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.67382,
            "recall": 0.66777,
            "fmeasure": 0.66385
        },
        "rouge2": {
            "precision": 0.39064,
            "recall": 0.38645,
            "fmeasure": 0.38425
        },
        "rougeL": {
            "precision": 0.49904,
            "recall": 0.49539,
            "fmeasure": 0.49158
        },
        "rougeLsum": {
            "precision": 0.49904,
            "recall": 0.49539,
            "fmeasure": 0.49158
        },
        "local_recall": {
            "1": 0.21693301598095885,
            "2": 0.5125204774163351,
            "3": 0.7753435921531775,
            "4": 0.7058823529411765,
            "5": 0.6896551724137931
        },
        "nist": 7.731559858513238,
        "bleu": 37.90439,
        "bleurt": -0.05987,
        "nubia": {
            "semantic_relation": 3.95066,
            "contradiction": 22.55095,
            "irrelevancy": 11.66882,
            "logical_agreement": 65.78023,
            "grammar_ref": 4.37017,
            "grammar_hyp": 4.44179,
            "nubia_score": 0.64995
        },
        "meteor": 0.3308819370724231,
        "bertscore": {
            "precision": 0.89003,
            "recall": 0.88972,
            "f1": 0.88852
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_126": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 57,
        "msttr-100": 0.70889,
        "msttr-100_nopunct": 0.7525,
        "total_length": 977,
        "mean_pred_length": 17.140350877192983,
        "std_pred_length": 6.311889634180732,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 38,
        "distinct-1": 0.5015353121801432,
        "vocab_size-1": 490,
        "unique-1": 391,
        "entropy-1": 7.768429361979001,
        "distinct-2": 0.8565217391304348,
        "vocab_size-2": 788,
        "unique-2": 720,
        "entropy-2": 9.451720364143391,
        "cond_entropy-2": 1.4559660417536302,
        "distinct-3": 0.9490150637311703,
        "vocab_size-3": 819,
        "unique-3": 792,
        "entropy-3": 9.631832175016433,
        "cond_entropy-3": 0.1788778562303897,
        "total_length-nopunct": 871,
        "mean_pred_length-nopunct": 15.280701754385966,
        "std_pred_length-nopunct": 5.730051241205355,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.5545350172215844,
        "vocab_size-1-nopunct": 483,
        "unique-1-nopunct": 388,
        "entropy-1-nopunct": 7.937718804531346,
        "distinct-2-nopunct": 0.8648648648648649,
        "vocab_size-2-nopunct": 704,
        "unique-2-nopunct": 651,
        "entropy-2-nopunct": 9.285588363442647,
        "cond_entropy-2-nopunct": 1.4278529331690923,
        "distinct-3-nopunct": 0.9484808454425363,
        "vocab_size-3-nopunct": 718,
        "unique-3-nopunct": 696,
        "entropy-3-nopunct": 9.438977908080608,
        "cond_entropy-3-nopunct": 0.170909947393859,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75371,
            "recall": 0.75464,
            "fmeasure": 0.74372
        },
        "rouge2": {
            "precision": 0.5541,
            "recall": 0.55812,
            "fmeasure": 0.54776
        },
        "rougeL": {
            "precision": 0.65275,
            "recall": 0.65131,
            "fmeasure": 0.64319
        },
        "rougeLsum": {
            "precision": 0.65275,
            "recall": 0.65131,
            "fmeasure": 0.64319
        },
        "local_recall": {
            "1": 0.2488479262672811,
            "2": 0.5073170731707317,
            "3": 0.7950664136622391
        },
        "nist": 6.932268610347161,
        "bleu": 46.2124,
        "bleurt": 0.19555,
        "nubia": {
            "semantic_relation": 4.17968,
            "contradiction": 5.32696,
            "irrelevancy": 37.44676,
            "logical_agreement": 57.22628,
            "grammar_ref": 4.80748,
            "grammar_hyp": 4.73164,
            "nubia_score": 0.719
        },
        "meteor": 0.4000775128066541,
        "bertscore": {
            "precision": 0.92011,
            "recall": 0.92496,
            "f1": 0.91999
        }
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 1654,
        "msttr-100": 0.52389,
        "msttr-100_nopunct": 0.54122,
        "total_length": 40135,
        "mean_pred_length": 24.265417170495766,
        "std_pred_length": 12.474411096401578,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 80,
        "distinct-1": 0.05553756073252772,
        "vocab_size-1": 2229,
        "unique-1": 674,
        "entropy-1": 8.098152129168247,
        "distinct-2": 0.21041552974195057,
        "vocab_size-2": 8097,
        "unique-2": 3964,
        "entropy-2": 11.536848851685562,
        "cond_entropy-2": 3.261384149837024,
        "distinct-3": 0.38325141879599206,
        "vocab_size-3": 14114,
        "unique-3": 8767,
        "entropy-3": 12.845559678580562,
        "cond_entropy-3": 1.3670268976721913,
        "total_length-nopunct": 35378,
        "mean_pred_length-nopunct": 21.389359129383312,
        "std_pred_length-nopunct": 11.219672347895084,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 71,
        "distinct-1-nopunct": 0.06269432980948612,
        "vocab_size-1-nopunct": 2218,
        "unique-1-nopunct": 673,
        "entropy-1-nopunct": 8.404647477003289,
        "distinct-2-nopunct": 0.2261297592219191,
        "vocab_size-2-nopunct": 7626,
        "unique-2-nopunct": 3945,
        "entropy-2-nopunct": 11.464111841288494,
        "cond_entropy-2-nopunct": 3.207777812561883,
        "distinct-3-nopunct": 0.40277517929529155,
        "vocab_size-3-nopunct": 12917,
        "unique-3-nopunct": 8378,
        "entropy-3-nopunct": 12.71638072296271,
        "cond_entropy-3-nopunct": 1.3071709861985923,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.68666,
            "recall": 0.68401,
            "fmeasure": 0.67839
        },
        "rouge2": {
            "precision": 0.40877,
            "recall": 0.40792,
            "fmeasure": 0.40389
        },
        "rougeL": {
            "precision": 0.53176,
            "recall": 0.53216,
            "fmeasure": 0.52614
        },
        "rougeLsum": {
            "precision": 0.53176,
            "recall": 0.53216,
            "fmeasure": 0.52614
        },
        "local_recall": {
            "1": 0.22603989679692907,
            "2": 0.5349620893007582,
            "3": 0.7836139169472502,
            "4": 0.9090909090909091,
            "5": 0.6896551724137931
        },
        "nist": 7.978413006633546,
        "bleu": 39.56236,
        "bleurt": -0.00225,
        "nubia": {
            "semantic_relation": 4.03275,
            "contradiction": 20.98353,
            "irrelevancy": 10.36733,
            "logical_agreement": 68.64914,
            "grammar_ref": 4.57661,
            "grammar_hyp": 4.64412,
            "nubia_score": 0.66638
        },
        "meteor": 0.3433694581009788,
        "bertscore": {
            "precision": 0.89696,
            "recall": 0.89839,
            "f1": 0.89638
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_72": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 76,
        "msttr-100": 0.72583,
        "msttr-100_nopunct": 0.8,
        "total_length": 1244,
        "mean_pred_length": 16.36842105263158,
        "std_pred_length": 6.123385083052205,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 34,
        "distinct-1": 0.5112540192926045,
        "vocab_size-1": 636,
        "unique-1": 520,
        "entropy-1": 8.065444981347229,
        "distinct-2": 0.8946917808219178,
        "vocab_size-2": 1045,
        "unique-2": 971,
        "entropy-2": 9.922096676835416,
        "cond_entropy-2": 1.5942563777877032,
        "distinct-3": 0.9771062271062271,
        "vocab_size-3": 1067,
        "unique-3": 1046,
        "entropy-3": 10.042972774640738,
        "cond_entropy-3": 0.12713758501346248,
        "total_length-nopunct": 1070,
        "mean_pred_length-nopunct": 14.078947368421053,
        "std_pred_length-nopunct": 5.113869576931103,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5887850467289719,
        "vocab_size-1-nopunct": 630,
        "unique-1-nopunct": 520,
        "entropy-1-nopunct": 8.399454097730377,
        "distinct-2-nopunct": 0.9114688128772636,
        "vocab_size-2-nopunct": 906,
        "unique-2-nopunct": 855,
        "entropy-2-nopunct": 9.72573673947498,
        "cond_entropy-2-nopunct": 1.4119144693570542,
        "distinct-3-nopunct": 0.9825708061002179,
        "vocab_size-3-nopunct": 902,
        "unique-3-nopunct": 887,
        "entropy-3-nopunct": 9.806669638073588,
        "cond_entropy-3-nopunct": 0.09509281195178973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7163,
            "recall": 0.69112,
            "fmeasure": 0.68703
        },
        "rouge2": {
            "precision": 0.45368,
            "recall": 0.44285,
            "fmeasure": 0.43599
        },
        "rougeL": {
            "precision": 0.60719,
            "recall": 0.59731,
            "fmeasure": 0.58695
        },
        "rougeLsum": {
            "precision": 0.60719,
            "recall": 0.59731,
            "fmeasure": 0.58695
        },
        "local_recall": {
            "1": 0.18729096989966554,
            "2": 0.4715447154471545,
            "3": 0.724376731301939
        },
        "nist": 6.724966012019344,
        "bleu": 38.06155,
        "bleurt": 0.18983,
        "nubia": {
            "semantic_relation": 4.09049,
            "contradiction": 6.5903,
            "irrelevancy": 34.0099,
            "logical_agreement": 59.3998,
            "grammar_ref": 4.73156,
            "grammar_hyp": 4.70328,
            "nubia_score": 0.68662
        },
        "meteor": 0.36284795368395795,
        "bertscore": {
            "precision": 0.91774,
            "recall": 0.91604,
            "f1": 0.91447
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_127": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.55556,
            "fmeasure": 0.55556
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.625
        },
        "nist": 1.7887305126316566,
        "bleu": 15.7278,
        "bleurt": -0.26935,
        "nubia": {
            "semantic_relation": 3.92325,
            "contradiction": 0.65628,
            "irrelevancy": 96.75888,
            "logical_agreement": 2.58483,
            "grammar_ref": 6.33221,
            "grammar_hyp": 6.20705,
            "nubia_score": 0.56012
        },
        "meteor": 0.3279709129282155,
        "bertscore": {
            "precision": 0.86484,
            "recall": 0.88864,
            "f1": 0.87658
        }
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 125,
        "msttr-100": 0.50297,
        "msttr-100_nopunct": 0.52152,
        "total_length": 3744,
        "mean_pred_length": 29.952,
        "std_pred_length": 10.482637835964765,
        "median_pred_length": 30.0,
        "min_pred_length": 8,
        "max_pred_length": 59,
        "distinct-1": 0.15197649572649571,
        "vocab_size-1": 569,
        "unique-1": 217,
        "entropy-1": 7.150462464176574,
        "distinct-2": 0.41530809615916,
        "vocab_size-2": 1503,
        "unique-2": 882,
        "entropy-2": 9.86524525521906,
        "cond_entropy-2": 2.60904027038379,
        "distinct-3": 0.6036061820263309,
        "vocab_size-3": 2109,
        "unique-3": 1493,
        "entropy-3": 10.677390502064329,
        "cond_entropy-3": 0.8445281673007102,
        "total_length-nopunct": 3301,
        "mean_pred_length-nopunct": 26.408,
        "std_pred_length-nopunct": 9.169598464491235,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 50,
        "distinct-1-nopunct": 0.17055437746137533,
        "vocab_size-1-nopunct": 563,
        "unique-1-nopunct": 217,
        "entropy-1-nopunct": 7.3345043930046305,
        "distinct-2-nopunct": 0.43261964735516373,
        "vocab_size-2-nopunct": 1374,
        "unique-2-nopunct": 819,
        "entropy-2-nopunct": 9.77793585265985,
        "cond_entropy-2-nopunct": 2.534049472548958,
        "distinct-3-nopunct": 0.6181579809898394,
        "vocab_size-3-nopunct": 1886,
        "unique-3-nopunct": 1363,
        "entropy-3-nopunct": 10.520458105345886,
        "cond_entropy-3-nopunct": 0.7638980389898339,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.58894,
            "recall": 0.58519,
            "fmeasure": 0.57832
        },
        "rouge2": {
            "precision": 0.29832,
            "recall": 0.28913,
            "fmeasure": 0.28858
        },
        "rougeL": {
            "precision": 0.42847,
            "recall": 0.42024,
            "fmeasure": 0.4168
        },
        "rougeLsum": {
            "precision": 0.42847,
            "recall": 0.42024,
            "fmeasure": 0.4168
        },
        "local_recall": {
            "1": 0.1801040312093628,
            "2": 0.4232209737827715,
            "3": 0.669047619047619
        },
        "nist": 5.558795521187526,
        "bleu": 26.07728,
        "bleurt": -0.2932,
        "nubia": {
            "semantic_relation": 3.47215,
            "contradiction": 39.8807,
            "irrelevancy": 17.58561,
            "logical_agreement": 42.53369,
            "grammar_ref": 4.33462,
            "grammar_hyp": 4.44867,
            "nubia_score": 0.51719
        },
        "meteor": 0.2682644922896116,
        "bertscore": {
            "precision": 0.863,
            "recall": 0.85853,
            "f1": 0.85893
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_73": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.794653473544342,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.3148841634647016,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6901165175936654,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.3347176276348774,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.94118,
            "recall": 0.84211,
            "fmeasure": 0.88889
        },
        "rouge2": {
            "precision": 0.5625,
            "recall": 0.5,
            "fmeasure": 0.52941
        },
        "rougeL": {
            "precision": 0.70588,
            "recall": 0.63158,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.70588,
            "recall": 0.63158,
            "fmeasure": 0.66667
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.7647058823529411
        },
        "nist": 3.7743341976970783,
        "bleu": 25.57539,
        "bleurt": 0.29696,
        "nubia": {
            "semantic_relation": 4.72571,
            "contradiction": 0.72242,
            "irrelevancy": 15.78281,
            "logical_agreement": 83.49478,
            "grammar_ref": 4.70075,
            "grammar_hyp": 4.99898,
            "nubia_score": 0.80715
        },
        "meteor": 0.4046709964870007,
        "bertscore": {
            "precision": 0.9589,
            "recall": 0.92407,
            "f1": 0.94116
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_74": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7037,
            "recall": 0.6,
            "fmeasure": 0.63889
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.32143,
            "fmeasure": 0.34091
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.48148,
            "fmeasure": 0.50926
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.48148,
            "fmeasure": 0.50926
        },
        "local_recall": {
            "1": 0,
            "2": 0.2,
            "3": 0.6666666666666666
        },
        "nist": 1.6476388007204534,
        "bleu": 22.08959,
        "bleurt": 0.27507,
        "nubia": {
            "semantic_relation": 4.03669,
            "contradiction": 0.06382,
            "irrelevancy": 34.0709,
            "logical_agreement": 65.86528,
            "grammar_ref": 4.68314,
            "grammar_hyp": 5.46374,
            "nubia_score": 0.65321
        },
        "meteor": 0.3387350864807313,
        "bertscore": {
            "precision": 0.92614,
            "recall": 0.93439,
            "f1": 0.93025
        }
    },
    "schema_guided_dialog_challenge_test_scramble": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.68652,
        "msttr-100_nopunct": 0.70828,
        "total_length": 6606,
        "mean_pred_length": 13.212,
        "std_pred_length": 7.433105407566881,
        "median_pred_length": 11.5,
        "min_pred_length": 2,
        "max_pred_length": 40,
        "distinct-1": 0.1522858007871632,
        "vocab_size-1": 1006,
        "unique-1": 552,
        "entropy-1": 7.803088876046867,
        "distinct-2": 0.4682279724860793,
        "vocab_size-2": 2859,
        "unique-2": 1985,
        "entropy-2": 10.659158879903458,
        "cond_entropy-2": 2.618519229928554,
        "distinct-3": 0.6839100963253657,
        "vocab_size-3": 3834,
        "unique-3": 3111,
        "entropy-3": 11.50303817190911,
        "cond_entropy-3": 0.8831949096278773,
        "total_length-nopunct": 5820,
        "mean_pred_length-nopunct": 11.64,
        "std_pred_length-nopunct": 6.8025289415040335,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.17096219931271478,
        "vocab_size-1-nopunct": 995,
        "unique-1-nopunct": 550,
        "entropy-1-nopunct": 7.983421973978909,
        "distinct-2-nopunct": 0.48120300751879697,
        "vocab_size-2-nopunct": 2560,
        "unique-2-nopunct": 1812,
        "entropy-2-nopunct": 10.483326870743843,
        "cond_entropy-2-nopunct": 2.6470467921285756,
        "distinct-3-nopunct": 0.6938394523957685,
        "vocab_size-3-nopunct": 3345,
        "unique-3-nopunct": 2745,
        "entropy-3-nopunct": 11.303281509934195,
        "cond_entropy-3-nopunct": 0.8750718235754786,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_scramble.json",
        "rouge1": {
            "precision": 0.56142,
            "recall": 0.53724,
            "fmeasure": 0.53816
        },
        "rouge2": {
            "precision": 0.33347,
            "recall": 0.31807,
            "fmeasure": 0.31859
        },
        "rougeL": {
            "precision": 0.49563,
            "recall": 0.47448,
            "fmeasure": 0.4751
        },
        "rougeLsum": {
            "precision": 0.49563,
            "recall": 0.47448,
            "fmeasure": 0.4751
        },
        "local_recall": {
            "1": 0.5548098434004475
        },
        "nist": 5.950196405638225,
        "bleu": 29.75893,
        "bleurt": -0.11244,
        "nubia": {
            "semantic_relation": 3.52896,
            "contradiction": 7.92747,
            "irrelevancy": 25.18561,
            "logical_agreement": 66.88692,
            "grammar_ref": 4.7801,
            "grammar_hyp": 4.60042,
            "nubia_score": 0.62231
        },
        "meteor": 0.30534868045709246,
        "bertscore": {
            "precision": 0.86886,
            "recall": 0.86072,
            "f1": 0.86434
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_98": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.78,
        "total_length": 195,
        "mean_pred_length": 17.727272727272727,
        "std_pred_length": 5.462115958472655,
        "median_pred_length": 18.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.6820512820512821,
        "vocab_size-1": 133,
        "unique-1": 108,
        "entropy-1": 6.677442410148633,
        "distinct-2": 0.9619565217391305,
        "vocab_size-2": 177,
        "unique-2": 171,
        "entropy-2": 7.443372350067006,
        "cond_entropy-2": 0.6147072178238229,
        "distinct-3": 0.9942196531791907,
        "vocab_size-3": 172,
        "unique-3": 171,
        "entropy-3": 7.423067533995107,
        "cond_entropy-3": -0.015206054997377929,
        "total_length-nopunct": 174,
        "mean_pred_length-nopunct": 15.818181818181818,
        "std_pred_length-nopunct": 4.914138818814393,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7413793103448276,
        "vocab_size-1-nopunct": 129,
        "unique-1-nopunct": 108,
        "entropy-1-nopunct": 6.731652585544933,
        "distinct-2-nopunct": 0.9631901840490797,
        "vocab_size-2-nopunct": 157,
        "unique-2-nopunct": 152,
        "entropy-2-nopunct": 7.270477310659548,
        "cond_entropy-2-nopunct": 0.5480411172523315,
        "distinct-3-nopunct": 0.993421052631579,
        "vocab_size-3-nopunct": 151,
        "unique-3-nopunct": 150,
        "entropy-3-nopunct": 7.234769618706724,
        "cond_entropy-3-nopunct": -0.043202696694311093,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78854,
            "recall": 0.75065,
            "fmeasure": 0.76619
        },
        "rouge2": {
            "precision": 0.56,
            "recall": 0.53442,
            "fmeasure": 0.54436
        },
        "rougeL": {
            "precision": 0.62745,
            "recall": 0.58962,
            "fmeasure": 0.6046
        },
        "rougeLsum": {
            "precision": 0.62745,
            "recall": 0.58962,
            "fmeasure": 0.6046
        },
        "local_recall": {
            "1": 0.3488372093023256,
            "2": 0.47368421052631576,
            "3": 0.7573529411764706
        },
        "nist": 5.845636140503661,
        "bleu": 42.76814,
        "bleurt": 0.23138,
        "nubia": {
            "semantic_relation": 4.3201,
            "contradiction": 8.76911,
            "irrelevancy": 17.01556,
            "logical_agreement": 74.21533,
            "grammar_ref": 4.3854,
            "grammar_hyp": 4.7731,
            "nubia_score": 0.72199
        },
        "meteor": 0.3974446914702078,
        "bertscore": {
            "precision": 0.91692,
            "recall": 0.92155,
            "f1": 0.91699
        }
    },
    "web_nlg_en_test_contrast_challenge_combinations-seen": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 115,
        "msttr-100": 0.64333,
        "msttr-100_nopunct": 0.69278,
        "total_length": 2123,
        "mean_pred_length": 18.46086956521739,
        "std_pred_length": 6.063844320190658,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 57,
        "distinct-1": 0.2623645784267546,
        "vocab_size-1": 557,
        "unique-1": 285,
        "entropy-1": 7.331406253297284,
        "distinct-2": 0.5796812749003984,
        "vocab_size-2": 1164,
        "unique-2": 831,
        "entropy-2": 9.715640351894207,
        "cond_entropy-2": 2.193247044920291,
        "distinct-3": 0.745377707342842,
        "vocab_size-3": 1411,
        "unique-3": 1145,
        "entropy-3": 10.24183808743532,
        "cond_entropy-3": 0.5747420647850061,
        "total_length-nopunct": 1830,
        "mean_pred_length-nopunct": 15.91304347826087,
        "std_pred_length-nopunct": 5.344749910595003,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.3005464480874317,
        "vocab_size-1-nopunct": 550,
        "unique-1-nopunct": 284,
        "entropy-1-nopunct": 7.620271483053031,
        "distinct-2-nopunct": 0.5836734693877551,
        "vocab_size-2-nopunct": 1001,
        "unique-2-nopunct": 721,
        "entropy-2-nopunct": 9.51034109334653,
        "cond_entropy-2-nopunct": 2.0257698438805254,
        "distinct-3-nopunct": 0.740625,
        "vocab_size-3-nopunct": 1185,
        "unique-3-nopunct": 959,
        "entropy-3-nopunct": 9.982016502950417,
        "cond_entropy-3-nopunct": 0.5118144790405862,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.7125,
            "recall": 0.71127,
            "fmeasure": 0.70529
        },
        "rouge2": {
            "precision": 0.44515,
            "recall": 0.44638,
            "fmeasure": 0.44131
        },
        "rougeL": {
            "precision": 0.57954,
            "recall": 0.58334,
            "fmeasure": 0.57545
        },
        "rougeLsum": {
            "precision": 0.57954,
            "recall": 0.58334,
            "fmeasure": 0.57545
        },
        "local_recall": {
            "1": 0.22727272727272727,
            "2": 0.5485714285714286,
            "3": 0.8212809917355371
        },
        "nist": 7.290267993462792,
        "bleu": 44.73746,
        "bleurt": 0.12876,
        "nubia": {
            "semantic_relation": 4.31693,
            "contradiction": 13.85317,
            "irrelevancy": 6.27938,
            "logical_agreement": 79.86745,
            "grammar_ref": 4.68186,
            "grammar_hyp": 4.60479,
            "nubia_score": 0.75502
        },
        "meteor": 0.38794201775706105,
        "bertscore": {
            "precision": 0.90722,
            "recall": 0.914,
            "f1": 0.90874
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_185": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.78,
        "total_length": 111,
        "mean_pred_length": 13.875,
        "std_pred_length": 3.2572035551988456,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.7207207207207207,
        "vocab_size-1": 80,
        "unique-1": 68,
        "entropy-1": 5.9878772408066,
        "distinct-2": 0.9611650485436893,
        "vocab_size-2": 99,
        "unique-2": 97,
        "entropy-2": 6.589413148542459,
        "cond_entropy-2": 0.43116997573923327,
        "distinct-3": 1.0,
        "vocab_size-3": 95,
        "unique-3": 95,
        "entropy-3": 6.569855608330948,
        "cond_entropy-3": -0.011381760957533776,
        "total_length-nopunct": 100,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 3.122498999199199,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.78,
        "vocab_size-1-nopunct": 78,
        "unique-1-nopunct": 68,
        "entropy-1-nopunct": 6.036147190443066,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 88,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.414866303883113,
        "cond_entropy-2-nopunct": 0.43156337425149455,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 84,
        "entropy-3-nopunct": 6.39231742277876,
        "cond_entropy-3-nopunct": -0.012196914230633411,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72689,
            "recall": 0.74386,
            "fmeasure": 0.72838
        },
        "rouge2": {
            "precision": 0.49028,
            "recall": 0.50591,
            "fmeasure": 0.49171
        },
        "rougeL": {
            "precision": 0.61534,
            "recall": 0.63125,
            "fmeasure": 0.61668
        },
        "rougeLsum": {
            "precision": 0.61534,
            "recall": 0.63125,
            "fmeasure": 0.61668
        },
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.2,
            "3": 0.7857142857142857
        },
        "nist": 4.768636368372497,
        "bleu": 41.96466,
        "bleurt": 0.26191,
        "nubia": {
            "semantic_relation": 3.93488,
            "contradiction": 25.39761,
            "irrelevancy": 22.27198,
            "logical_agreement": 52.33041,
            "grammar_ref": 5.14697,
            "grammar_hyp": 5.05754,
            "nubia_score": 0.64055
        },
        "meteor": 0.3798082669635397,
        "bertscore": {
            "precision": 0.92111,
            "recall": 0.91908,
            "f1": 0.91986
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_28": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 77,
        "msttr-100": 0.72667,
        "msttr-100_nopunct": 0.771,
        "total_length": 1210,
        "mean_pred_length": 15.714285714285714,
        "std_pred_length": 5.062870041905528,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 30,
        "distinct-1": 0.4909090909090909,
        "vocab_size-1": 594,
        "unique-1": 478,
        "entropy-1": 7.9453308545617665,
        "distinct-2": 0.8729037952338923,
        "vocab_size-2": 989,
        "unique-2": 912,
        "entropy-2": 9.810823405949042,
        "cond_entropy-2": 1.5943314621753273,
        "distinct-3": 0.9498106060606061,
        "vocab_size-3": 1003,
        "unique-3": 971,
        "entropy-3": 9.92587279786584,
        "cond_entropy-3": 0.11532742029355242,
        "total_length-nopunct": 1059,
        "mean_pred_length-nopunct": 13.753246753246753,
        "std_pred_length-nopunct": 4.794899465803718,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.550519357884797,
        "vocab_size-1-nopunct": 583,
        "unique-1-nopunct": 472,
        "entropy-1-nopunct": 8.18269500946677,
        "distinct-2-nopunct": 0.884928716904277,
        "vocab_size-2-nopunct": 869,
        "unique-2-nopunct": 810,
        "entropy-2-nopunct": 9.628439461985879,
        "cond_entropy-2-nopunct": 1.544543321437678,
        "distinct-3-nopunct": 0.9569060773480663,
        "vocab_size-3-nopunct": 866,
        "unique-3-nopunct": 842,
        "entropy-3-nopunct": 9.72144913388254,
        "cond_entropy-3-nopunct": 0.11331110662462343,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78434,
            "recall": 0.72732,
            "fmeasure": 0.74606
        },
        "rouge2": {
            "precision": 0.55416,
            "recall": 0.5132,
            "fmeasure": 0.52677
        },
        "rougeL": {
            "precision": 0.68971,
            "recall": 0.64343,
            "fmeasure": 0.65709
        },
        "rougeLsum": {
            "precision": 0.68971,
            "recall": 0.64343,
            "fmeasure": 0.65709
        },
        "local_recall": {
            "1": 0.22178988326848248,
            "2": 0.4069767441860465,
            "3": 0.7893368010403121
        },
        "nist": 7.294161316591634,
        "bleu": 48.9651,
        "bleurt": 0.27069,
        "nubia": {
            "semantic_relation": 4.16212,
            "contradiction": 4.87926,
            "irrelevancy": 25.92833,
            "logical_agreement": 69.1924,
            "grammar_ref": 4.69344,
            "grammar_hyp": 4.70771,
            "nubia_score": 0.72672
        },
        "meteor": 0.3983300688521989,
        "bertscore": {
            "precision": 0.93518,
            "recall": 0.92733,
            "f1": 0.92925
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_155": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.82,
        "total_length": 295,
        "mean_pred_length": 17.352941176470587,
        "std_pred_length": 7.14506144929397,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 35,
        "distinct-1": 0.6169491525423729,
        "vocab_size-1": 182,
        "unique-1": 149,
        "entropy-1": 6.897559219888976,
        "distinct-2": 0.9028776978417267,
        "vocab_size-2": 251,
        "unique-2": 231,
        "entropy-2": 7.903925110454342,
        "cond_entropy-2": 0.8363383165109326,
        "distinct-3": 0.9540229885057471,
        "vocab_size-3": 249,
        "unique-3": 239,
        "entropy-3": 7.930167395020706,
        "cond_entropy-3": 0.02202919589360678,
        "total_length-nopunct": 244,
        "mean_pred_length-nopunct": 14.352941176470589,
        "std_pred_length-nopunct": 4.588235294117647,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7254098360655737,
        "vocab_size-1-nopunct": 177,
        "unique-1-nopunct": 148,
        "entropy-1-nopunct": 7.109345368608303,
        "distinct-2-nopunct": 0.9383259911894273,
        "vocab_size-2-nopunct": 213,
        "unique-2-nopunct": 202,
        "entropy-2-nopunct": 7.691064401378284,
        "cond_entropy-2-nopunct": 0.6388276824273604,
        "distinct-3-nopunct": 0.9714285714285714,
        "vocab_size-3-nopunct": 204,
        "unique-3-nopunct": 198,
        "entropy-3-nopunct": 7.657102660523253,
        "cond_entropy-3-nopunct": -0.02299398151925195,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82248,
            "recall": 0.77504,
            "fmeasure": 0.78738
        },
        "rouge2": {
            "precision": 0.61321,
            "recall": 0.58436,
            "fmeasure": 0.59142
        },
        "rougeL": {
            "precision": 0.68296,
            "recall": 0.65574,
            "fmeasure": 0.66224
        },
        "rougeLsum": {
            "precision": 0.68296,
            "recall": 0.65574,
            "fmeasure": 0.66224
        },
        "local_recall": {
            "1": 0.19148936170212766,
            "2": 0.2894736842105263,
            "3": 0.8341013824884793
        },
        "nist": 6.824442695001183,
        "bleu": 59.85289,
        "bleurt": 0.41958,
        "nubia": {
            "semantic_relation": 4.39944,
            "contradiction": 2.71073,
            "irrelevancy": 25.43042,
            "logical_agreement": 71.85884,
            "grammar_ref": 4.52442,
            "grammar_hyp": 4.51006,
            "nubia_score": 0.80355
        },
        "meteor": 0.467559890381185,
        "bertscore": {
            "precision": 0.94915,
            "recall": 0.94177,
            "f1": 0.94192
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_128": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.73333,
        "msttr-100_nopunct": 0.77,
        "total_length": 318,
        "mean_pred_length": 15.9,
        "std_pred_length": 4.988987873306569,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.60062893081761,
        "vocab_size-1": 191,
        "unique-1": 154,
        "entropy-1": 6.9089738255969575,
        "distinct-2": 0.9496644295302014,
        "vocab_size-2": 283,
        "unique-2": 274,
        "entropy-2": 8.093296792259695,
        "cond_entropy-2": 0.9837586516901983,
        "distinct-3": 0.9928057553956835,
        "vocab_size-3": 276,
        "unique-3": 274,
        "entropy-3": 8.104552583514828,
        "cond_entropy-3": 0.020311311269716137,
        "total_length-nopunct": 278,
        "mean_pred_length-nopunct": 13.9,
        "std_pred_length-nopunct": 4.437341546466758,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6690647482014388,
        "vocab_size-1-nopunct": 186,
        "unique-1-nopunct": 154,
        "entropy-1-nopunct": 7.01562994356205,
        "distinct-2-nopunct": 0.9457364341085271,
        "vocab_size-2-nopunct": 244,
        "unique-2-nopunct": 236,
        "entropy-2-nopunct": 7.873592468584745,
        "cond_entropy-2-nopunct": 0.9179674090634278,
        "distinct-3-nopunct": 0.9957983193277311,
        "vocab_size-3-nopunct": 237,
        "unique-3-nopunct": 236,
        "entropy-3-nopunct": 7.886414401963453,
        "cond_entropy-3-nopunct": 0.020186201180180843,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73043,
            "recall": 0.75202,
            "fmeasure": 0.727
        },
        "rouge2": {
            "precision": 0.48756,
            "recall": 0.48124,
            "fmeasure": 0.47733
        },
        "rougeL": {
            "precision": 0.60949,
            "recall": 0.62006,
            "fmeasure": 0.60437
        },
        "rougeLsum": {
            "precision": 0.60949,
            "recall": 0.62006,
            "fmeasure": 0.60437
        },
        "local_recall": {
            "1": 0.3,
            "2": 0.5081967213114754,
            "3": 0.7486910994764397
        },
        "nist": 5.547538533550578,
        "bleu": 38.62634,
        "bleurt": 0.24187,
        "nubia": {
            "semantic_relation": 4.23279,
            "contradiction": 6.56517,
            "irrelevancy": 32.17907,
            "logical_agreement": 61.25577,
            "grammar_ref": 4.72495,
            "grammar_hyp": 4.68344,
            "nubia_score": 0.7316
        },
        "meteor": 0.38862653981420103,
        "bertscore": {
            "precision": 0.91769,
            "recall": 0.92835,
            "f1": 0.92192
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_156": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 32,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.766,
        "total_length": 616,
        "mean_pred_length": 19.25,
        "std_pred_length": 7.599342076785332,
        "median_pred_length": 17.5,
        "min_pred_length": 8,
        "max_pred_length": 40,
        "distinct-1": 0.5340909090909091,
        "vocab_size-1": 329,
        "unique-1": 261,
        "entropy-1": 7.416467809079606,
        "distinct-2": 0.8647260273972602,
        "vocab_size-2": 505,
        "unique-2": 452,
        "entropy-2": 8.855341750112558,
        "cond_entropy-2": 1.2662886660529684,
        "distinct-3": 0.9293478260869565,
        "vocab_size-3": 513,
        "unique-3": 474,
        "entropy-3": 8.967220108952118,
        "cond_entropy-3": 0.12265473995972878,
        "total_length-nopunct": 544,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 6.670832032063167,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.59375,
        "vocab_size-1-nopunct": 323,
        "unique-1-nopunct": 259,
        "entropy-1-nopunct": 7.576486517889164,
        "distinct-2-nopunct": 0.857421875,
        "vocab_size-2-nopunct": 439,
        "unique-2-nopunct": 390,
        "entropy-2-nopunct": 8.644866825555024,
        "cond_entropy-2-nopunct": 1.135951313223304,
        "distinct-3-nopunct": 0.9270833333333334,
        "vocab_size-3-nopunct": 445,
        "unique-3-nopunct": 410,
        "entropy-3-nopunct": 8.76105726227522,
        "cond_entropy-3-nopunct": 0.13361598168315958,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77838,
            "recall": 0.74226,
            "fmeasure": 0.7499
        },
        "rouge2": {
            "precision": 0.55395,
            "recall": 0.52568,
            "fmeasure": 0.53276
        },
        "rougeL": {
            "precision": 0.6574,
            "recall": 0.6353,
            "fmeasure": 0.63746
        },
        "rougeLsum": {
            "precision": 0.6574,
            "recall": 0.6353,
            "fmeasure": 0.63746
        },
        "local_recall": {
            "1": 0.22448979591836735,
            "2": 0.3373493975903614,
            "3": 0.7806122448979592
        },
        "nist": 6.509635806080272,
        "bleu": 45.99458,
        "bleurt": 0.23682,
        "nubia": {
            "semantic_relation": 4.273,
            "contradiction": 13.47928,
            "irrelevancy": 20.55679,
            "logical_agreement": 65.96393,
            "grammar_ref": 4.40347,
            "grammar_hyp": 4.37407,
            "nubia_score": 0.75275
        },
        "meteor": 0.38460888542313376,
        "bertscore": {
            "precision": 0.92549,
            "recall": 0.92114,
            "f1": 0.92205
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_159": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 43,
        "mean_pred_length": 21.5,
        "std_pred_length": 11.5,
        "median_pred_length": 21.5,
        "min_pred_length": 10,
        "max_pred_length": 33,
        "distinct-1": 0.813953488372093,
        "vocab_size-1": 35,
        "unique-1": 31,
        "entropy-1": 4.952671080827673,
        "distinct-2": 0.975609756097561,
        "vocab_size-2": 40,
        "unique-2": 39,
        "entropy-2": 5.308771516813203,
        "cond_entropy-2": 0.3304220786135536,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.02086773447378382,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 11.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.825,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.862814895472356,
        "distinct-2-nopunct": 0.9736842105263158,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.19529593449622,
        "cond_entropy-2-nopunct": 0.3566448916246516,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.0224469564457176,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65412,
            "recall": 0.58922,
            "fmeasure": 0.61889
        },
        "rouge2": {
            "precision": 0.44167,
            "recall": 0.38056,
            "fmeasure": 0.40817
        },
        "rougeL": {
            "precision": 0.63799,
            "recall": 0.57309,
            "fmeasure": 0.60276
        },
        "rougeLsum": {
            "precision": 0.63799,
            "recall": 0.57309,
            "fmeasure": 0.60276
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.8181818181818182,
            "3": 0.38461538461538464
        },
        "nist": 2.8983097674197036,
        "bleu": 21.42197,
        "bleurt": 0.043,
        "nubia": {
            "semantic_relation": 3.95422,
            "contradiction": 26.43902,
            "irrelevancy": 12.4777,
            "logical_agreement": 61.08328,
            "grammar_ref": 4.83168,
            "grammar_hyp": 5.19566,
            "nubia_score": 0.62034
        },
        "meteor": 0.23488248156180547,
        "bertscore": {
            "precision": 0.88271,
            "recall": 0.86216,
            "f1": 0.87227
        }
    },
    "web_nlg_en_test_contrast_challenge_args-both_seen": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 518,
        "msttr-100": 0.65838,
        "msttr-100_nopunct": 0.68993,
        "total_length": 15423,
        "mean_pred_length": 29.774131274131275,
        "std_pred_length": 13.984172890335078,
        "median_pred_length": 27.0,
        "min_pred_length": 5,
        "max_pred_length": 80,
        "distinct-1": 0.061855670103092786,
        "vocab_size-1": 954,
        "unique-1": 266,
        "entropy-1": 7.705244299800471,
        "distinct-2": 0.20040254948004024,
        "vocab_size-2": 2987,
        "unique-2": 1387,
        "entropy-2": 10.312876813620383,
        "cond_entropy-2": 2.4788592833351246,
        "distinct-3": 0.32654479738652953,
        "vocab_size-3": 4698,
        "unique-3": 2678,
        "entropy-3": 11.218110247646361,
        "cond_entropy-3": 0.939518240494251,
        "total_length-nopunct": 13657,
        "mean_pred_length-nopunct": 26.364864864864863,
        "std_pred_length-nopunct": 12.533202278135978,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 71,
        "distinct-1-nopunct": 0.06919528446950282,
        "vocab_size-1-nopunct": 945,
        "unique-1-nopunct": 266,
        "entropy-1-nopunct": 7.933490890935018,
        "distinct-2-nopunct": 0.21181216226501257,
        "vocab_size-2-nopunct": 2783,
        "unique-2-nopunct": 1366,
        "entropy-2-nopunct": 10.199627150533454,
        "cond_entropy-2-nopunct": 2.3472738743152846,
        "distinct-3-nopunct": 0.3407020045955154,
        "vocab_size-3-nopunct": 4300,
        "unique-3-nopunct": 2560,
        "entropy-3-nopunct": 11.071662452656472,
        "cond_entropy-3-nopunct": 0.8921718955104265,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.79691,
            "recall": 0.77422,
            "fmeasure": 0.78024
        },
        "rouge2": {
            "precision": 0.55585,
            "recall": 0.5398,
            "fmeasure": 0.54383
        },
        "rougeL": {
            "precision": 0.62172,
            "recall": 0.60335,
            "fmeasure": 0.60798
        },
        "rougeLsum": {
            "precision": 0.62172,
            "recall": 0.60335,
            "fmeasure": 0.60798
        },
        "local_recall": {
            "1": 0.25993348503413266,
            "2": 0.6077411900635471,
            "3": 0.9028293798228065,
            "4": 1.0
        },
        "nist": 8.7419168594325,
        "bleu": 54.52972,
        "bleurt": 0.27131,
        "nubia": {
            "semantic_relation": 4.58257,
            "contradiction": 3.54715,
            "irrelevancy": 5.52778,
            "logical_agreement": 90.92507,
            "grammar_ref": 4.28317,
            "grammar_hyp": 4.27224,
            "nubia_score": 0.84625
        },
        "meteor": 0.40651031767049395,
        "bertscore": {
            "precision": 0.93645,
            "recall": 0.93178,
            "f1": 0.93302
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_186": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.715,
        "total_length": 245,
        "mean_pred_length": 17.5,
        "std_pred_length": 5.30161700400386,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.6040816326530613,
        "vocab_size-1": 148,
        "unique-1": 118,
        "entropy-1": 6.563686463779621,
        "distinct-2": 0.9090909090909091,
        "vocab_size-2": 210,
        "unique-2": 197,
        "entropy-2": 7.630885188564713,
        "cond_entropy-2": 0.9196591219466747,
        "distinct-3": 0.9861751152073732,
        "vocab_size-3": 214,
        "unique-3": 211,
        "entropy-3": 7.733901462859239,
        "cond_entropy-3": 0.11726555512360111,
        "total_length-nopunct": 224,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 5.196152422706632,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6428571428571429,
        "vocab_size-1-nopunct": 144,
        "unique-1-nopunct": 116,
        "entropy-1-nopunct": 6.5954776807790845,
        "distinct-2-nopunct": 0.9047619047619048,
        "vocab_size-2-nopunct": 190,
        "unique-2-nopunct": 178,
        "entropy-2-nopunct": 7.480819089053473,
        "cond_entropy-2-nopunct": 0.9538238791180825,
        "distinct-3-nopunct": 0.9897959183673469,
        "vocab_size-3-nopunct": 194,
        "unique-3-nopunct": 192,
        "entropy-3-nopunct": 7.594301680849886,
        "cond_entropy-3-nopunct": 0.12505386730956453,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74776,
            "recall": 0.81454,
            "fmeasure": 0.77232
        },
        "rouge2": {
            "precision": 0.56905,
            "recall": 0.62217,
            "fmeasure": 0.58685
        },
        "rougeL": {
            "precision": 0.66325,
            "recall": 0.72354,
            "fmeasure": 0.68531
        },
        "rougeLsum": {
            "precision": 0.66325,
            "recall": 0.72354,
            "fmeasure": 0.68531
        },
        "local_recall": {
            "1": 0.1891891891891892,
            "2": 0.5192307692307693,
            "3": 0.8650793650793651
        },
        "nist": 5.752955102658576,
        "bleu": 47.37465,
        "bleurt": 0.17449,
        "nubia": {
            "semantic_relation": 4.21443,
            "contradiction": 15.1064,
            "irrelevancy": 30.57449,
            "logical_agreement": 54.31912,
            "grammar_ref": 4.72137,
            "grammar_hyp": 4.58557,
            "nubia_score": 0.73649
        },
        "meteor": 0.4293827247937452,
        "bertscore": {
            "precision": 0.91324,
            "recall": 0.93062,
            "f1": 0.92023
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_187": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 15,
        "unique-1": 12,
        "entropy-1": 3.8365916681089787,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.27047901627861526,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.5068905956085183,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.25760718359194273,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70588,
            "recall": 0.78333,
            "fmeasure": 0.74242
        },
        "rouge2": {
            "precision": 0.47917,
            "recall": 0.53651,
            "fmeasure": 0.50609
        },
        "rougeL": {
            "precision": 0.41176,
            "recall": 0.45694,
            "fmeasure": 0.43308
        },
        "rougeLsum": {
            "precision": 0.41176,
            "recall": 0.45694,
            "fmeasure": 0.43308
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7272727272727273
        },
        "nist": 2.414540694907983,
        "bleu": 21.39917,
        "bleurt": 0.07998,
        "nubia": {
            "semantic_relation": 3.61007,
            "contradiction": 0.76132,
            "irrelevancy": 62.03989,
            "logical_agreement": 37.19878,
            "grammar_ref": 5.18542,
            "grammar_hyp": 4.56475,
            "nubia_score": 0.5918
        },
        "meteor": 0.3672780894402366,
        "bertscore": {
            "precision": 0.88277,
            "recall": 0.9308,
            "f1": 0.90615
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_188": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 46,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 4.784233364802441,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 22,
        "distinct-1": 0.7608695652173914,
        "vocab_size-1": 35,
        "unique-1": 30,
        "entropy-1": 4.906941782652657,
        "distinct-2": 1.0,
        "vocab_size-2": 43,
        "unique-2": 43,
        "entropy-2": 5.426264754702098,
        "cond_entropy-2": 0.45176420502733605,
        "distinct-3": 1.0,
        "vocab_size-3": 40,
        "unique-3": 40,
        "entropy-3": 5.3219280948873635,
        "cond_entropy-3": -0.1043366598147359,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 3.858612300930075,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.837147500958408,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.129283016944964,
        "cond_entropy-2-nopunct": 0.32734523134243254,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.12928301694496638,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86448,
            "recall": 0.79516,
            "fmeasure": 0.82745
        },
        "rouge2": {
            "precision": 0.61608,
            "recall": 0.56247,
            "fmeasure": 0.5874
        },
        "rougeL": {
            "precision": 0.67811,
            "recall": 0.62137,
            "fmeasure": 0.64785
        },
        "rougeLsum": {
            "precision": 0.67811,
            "recall": 0.62137,
            "fmeasure": 0.64785
        },
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 0.8484848484848485
        },
        "nist": 4.716206988513583,
        "bleu": 48.39751,
        "bleurt": 0.47676,
        "nubia": {
            "semantic_relation": 4.6941,
            "contradiction": 1.29542,
            "irrelevancy": 30.00845,
            "logical_agreement": 68.69613,
            "grammar_ref": 5.15044,
            "grammar_hyp": 5.24073,
            "nubia_score": 0.85319
        },
        "meteor": 0.4690237898240994,
        "bertscore": {
            "precision": 0.9598,
            "recall": 0.9644,
            "f1": 0.96208
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_130": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.792,
        "total_length": 634,
        "mean_pred_length": 20.451612903225808,
        "std_pred_length": 7.6699611374606125,
        "median_pred_length": 20.0,
        "min_pred_length": 8,
        "max_pred_length": 39,
        "distinct-1": 0.5583596214511041,
        "vocab_size-1": 354,
        "unique-1": 281,
        "entropy-1": 7.681392126442345,
        "distinct-2": 0.9137645107794361,
        "vocab_size-2": 551,
        "unique-2": 515,
        "entropy-2": 9.036613145536016,
        "cond_entropy-2": 1.184168396195827,
        "distinct-3": 0.9755244755244755,
        "vocab_size-3": 558,
        "unique-3": 547,
        "entropy-3": 9.106961087641222,
        "cond_entropy-3": 0.07765813867382425,
        "total_length-nopunct": 553,
        "mean_pred_length-nopunct": 17.838709677419356,
        "std_pred_length-nopunct": 6.872557744244195,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.6292947558770343,
        "vocab_size-1-nopunct": 348,
        "unique-1-nopunct": 281,
        "entropy-1-nopunct": 7.86586592588695,
        "distinct-2-nopunct": 0.9195402298850575,
        "vocab_size-2-nopunct": 480,
        "unique-2-nopunct": 451,
        "entropy-2-nopunct": 8.840216018694285,
        "cond_entropy-2-nopunct": 1.0257839521418641,
        "distinct-3-nopunct": 0.9816700610997964,
        "vocab_size-3-nopunct": 482,
        "unique-3-nopunct": 475,
        "entropy-3-nopunct": 8.899844438338523,
        "cond_entropy-3-nopunct": 0.06333186020246662,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82586,
            "recall": 0.79137,
            "fmeasure": 0.79948
        },
        "rouge2": {
            "precision": 0.60055,
            "recall": 0.59178,
            "fmeasure": 0.59016
        },
        "rougeL": {
            "precision": 0.71342,
            "recall": 0.6901,
            "fmeasure": 0.69223
        },
        "rougeLsum": {
            "precision": 0.71342,
            "recall": 0.6901,
            "fmeasure": 0.69223
        },
        "local_recall": {
            "1": 0.308411214953271,
            "2": 0.4177215189873418,
            "3": 0.8135198135198135
        },
        "nist": 7.291825241787767,
        "bleu": 53.30199,
        "bleurt": 0.31396,
        "nubia": {
            "semantic_relation": 4.40193,
            "contradiction": 3.88432,
            "irrelevancy": 20.792,
            "logical_agreement": 75.32368,
            "grammar_ref": 4.57329,
            "grammar_hyp": 4.71792,
            "nubia_score": 0.77817
        },
        "meteor": 0.4358916248017297,
        "bertscore": {
            "precision": 0.94201,
            "recall": 0.93969,
            "f1": 0.93981
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_189": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.655,
        "msttr-100_nopunct": 0.715,
        "total_length": 297,
        "mean_pred_length": 16.5,
        "std_pred_length": 6.075908711186061,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.5488215488215489,
        "vocab_size-1": 163,
        "unique-1": 127,
        "entropy-1": 6.598671673709533,
        "distinct-2": 0.8924731182795699,
        "vocab_size-2": 249,
        "unique-2": 230,
        "entropy-2": 7.846401084390614,
        "cond_entropy-2": 1.077904890271267,
        "distinct-3": 0.9846743295019157,
        "vocab_size-3": 257,
        "unique-3": 253,
        "entropy-3": 7.997254655573681,
        "cond_entropy-3": 0.1623438550677623,
        "total_length-nopunct": 265,
        "mean_pred_length-nopunct": 14.722222222222221,
        "std_pred_length-nopunct": 5.372828300868853,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6075471698113207,
        "vocab_size-1-nopunct": 161,
        "unique-1-nopunct": 127,
        "entropy-1-nopunct": 6.725203444941706,
        "distinct-2-nopunct": 0.8906882591093117,
        "vocab_size-2-nopunct": 220,
        "unique-2-nopunct": 204,
        "entropy-2-nopunct": 7.658958553627767,
        "cond_entropy-2-nopunct": 0.9972113308710955,
        "distinct-3-nopunct": 0.9868995633187773,
        "vocab_size-3-nopunct": 226,
        "unique-3-nopunct": 223,
        "entropy-3-nopunct": 7.813002914734502,
        "cond_entropy-3-nopunct": 0.17679264147018836,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72971,
            "recall": 0.72696,
            "fmeasure": 0.71727
        },
        "rouge2": {
            "precision": 0.48252,
            "recall": 0.48822,
            "fmeasure": 0.47595
        },
        "rougeL": {
            "precision": 0.62638,
            "recall": 0.61645,
            "fmeasure": 0.6113
        },
        "rougeLsum": {
            "precision": 0.62638,
            "recall": 0.61645,
            "fmeasure": 0.6113
        },
        "local_recall": {
            "1": 0.22727272727272727,
            "2": 0.4915254237288136,
            "3": 0.7639751552795031
        },
        "nist": 5.9023011990515375,
        "bleu": 43.66367,
        "bleurt": 0.2298,
        "nubia": {
            "semantic_relation": 4.38589,
            "contradiction": 7.08265,
            "irrelevancy": 32.15052,
            "logical_agreement": 60.76683,
            "grammar_ref": 4.82101,
            "grammar_hyp": 4.56718,
            "nubia_score": 0.78207
        },
        "meteor": 0.37804057056222634,
        "bertscore": {
            "precision": 0.92366,
            "recall": 0.92571,
            "f1": 0.92261
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_216": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 35,
        "msttr-100": 0.728,
        "msttr-100_nopunct": 0.772,
        "total_length": 586,
        "mean_pred_length": 16.742857142857144,
        "std_pred_length": 6.6045129901253645,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 39,
        "distinct-1": 0.5614334470989761,
        "vocab_size-1": 329,
        "unique-1": 263,
        "entropy-1": 7.454208342503823,
        "distinct-2": 0.9019963702359347,
        "vocab_size-2": 497,
        "unique-2": 459,
        "entropy-2": 8.866800330781906,
        "cond_entropy-2": 1.1973366204452782,
        "distinct-3": 0.9593023255813954,
        "vocab_size-3": 495,
        "unique-3": 476,
        "entropy-3": 8.926905986034985,
        "cond_entropy-3": 0.07244826421164596,
        "total_length-nopunct": 517,
        "mean_pred_length-nopunct": 14.771428571428572,
        "std_pred_length-nopunct": 5.914078671324237,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.6228239845261122,
        "vocab_size-1-nopunct": 322,
        "unique-1-nopunct": 262,
        "entropy-1-nopunct": 7.628449643145186,
        "distinct-2-nopunct": 0.8941908713692946,
        "vocab_size-2-nopunct": 431,
        "unique-2-nopunct": 396,
        "entropy-2-nopunct": 8.65200011224266,
        "cond_entropy-2-nopunct": 1.0944117324752876,
        "distinct-3-nopunct": 0.9552572706935123,
        "vocab_size-3-nopunct": 427,
        "unique-3-nopunct": 409,
        "entropy-3-nopunct": 8.711267989853772,
        "cond_entropy-3-nopunct": 0.07745830901941304,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75261,
            "recall": 0.70673,
            "fmeasure": 0.71544
        },
        "rouge2": {
            "precision": 0.52573,
            "recall": 0.49075,
            "fmeasure": 0.49745
        },
        "rougeL": {
            "precision": 0.67327,
            "recall": 0.63295,
            "fmeasure": 0.64084
        },
        "rougeLsum": {
            "precision": 0.67327,
            "recall": 0.63295,
            "fmeasure": 0.64084
        },
        "local_recall": {
            "1": 0.24742268041237114,
            "2": 0.45045045045045046,
            "3": 0.7541899441340782
        },
        "nist": 6.7576063829390645,
        "bleu": 42.95759,
        "bleurt": 0.21577,
        "nubia": {
            "semantic_relation": 3.99436,
            "contradiction": 10.73093,
            "irrelevancy": 33.78296,
            "logical_agreement": 55.48612,
            "grammar_ref": 4.80535,
            "grammar_hyp": 4.69215,
            "nubia_score": 0.67095
        },
        "meteor": 0.3700789296387298,
        "bertscore": {
            "precision": 0.93225,
            "recall": 0.92057,
            "f1": 0.92463
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_217": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 73,
        "mean_pred_length": 24.333333333333332,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 25,
        "distinct-1": 0.684931506849315,
        "vocab_size-1": 50,
        "unique-1": 36,
        "entropy-1": 5.425791168320881,
        "distinct-2": 0.9285714285714286,
        "vocab_size-2": 65,
        "unique-2": 62,
        "entropy-2": 5.957854445516401,
        "cond_entropy-2": 0.4968806010457192,
        "distinct-3": 1.0,
        "vocab_size-3": 67,
        "unique-3": 67,
        "entropy-3": 6.066089190457767,
        "cond_entropy-3": 0.11591065112474633,
        "total_length-nopunct": 66,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 1.4142135623730951,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7121212121212122,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.343414384411633,
        "distinct-2-nopunct": 0.9206349206349206,
        "vocab_size-2-nopunct": 58,
        "unique-2-nopunct": 55,
        "entropy-2-nopunct": 5.78680373302373,
        "cond_entropy-2-nopunct": 0.46089632011750203,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 60,
        "unique-3-nopunct": 60,
        "entropy-3-nopunct": 5.906890595608517,
        "cond_entropy-3-nopunct": 0.12961067210860194,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.50323,
            "recall": 0.64762,
            "fmeasure": 0.55553
        },
        "rouge2": {
            "precision": 0.30357,
            "recall": 0.38616,
            "fmeasure": 0.33428
        },
        "rougeL": {
            "precision": 0.35192,
            "recall": 0.46373,
            "fmeasure": 0.39209
        },
        "rougeLsum": {
            "precision": 0.35192,
            "recall": 0.46373,
            "fmeasure": 0.39209
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.5,
            "3": 0.6944444444444444
        },
        "nist": 2.696201523645528,
        "bleu": 15.45308,
        "bleurt": -0.08047,
        "nubia": {
            "semantic_relation": 3.78713,
            "contradiction": 0.26847,
            "irrelevancy": 87.14793,
            "logical_agreement": 12.5836,
            "grammar_ref": 4.57112,
            "grammar_hyp": 3.99572,
            "nubia_score": 0.61987
        },
        "meteor": 0.34000559307589284,
        "bertscore": {
            "precision": 0.84716,
            "recall": 0.90075,
            "f1": 0.87221
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_219": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 2.5,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 16,
        "distinct-1": 0.8518518518518519,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.430632409490749,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.15916418769779478,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.303508854797679,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.18150945892357132,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.98333,
            "recall": 1.0,
            "fmeasure": 0.99123
        },
        "rouge2": {
            "precision": 0.96296,
            "recall": 0.97917,
            "fmeasure": 0.97059
        },
        "rougeL": {
            "precision": 0.98333,
            "recall": 1.0,
            "fmeasure": 0.99123
        },
        "rougeLsum": {
            "precision": 0.98333,
            "recall": 1.0,
            "fmeasure": 0.99123
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 5.016137706633773,
        "bleu": 100.0,
        "bleurt": 0.95532,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.56394,
            "irrelevancy": 0.56148,
            "logical_agreement": 98.87458,
            "grammar_ref": 4.84371,
            "grammar_hyp": 4.6994,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_190": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.82,
        "total_length": 194,
        "mean_pred_length": 14.923076923076923,
        "std_pred_length": 2.4949653446502853,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 20,
        "distinct-1": 0.6494845360824743,
        "vocab_size-1": 126,
        "unique-1": 105,
        "entropy-1": 6.5140968122017515,
        "distinct-2": 0.9502762430939227,
        "vocab_size-2": 172,
        "unique-2": 167,
        "entropy-2": 7.378298925757208,
        "cond_entropy-2": 0.6764114619199764,
        "distinct-3": 1.0,
        "vocab_size-3": 168,
        "unique-3": 168,
        "entropy-3": 7.392317422778791,
        "cond_entropy-3": 0.023423916647936006,
        "total_length-nopunct": 171,
        "mean_pred_length-nopunct": 13.153846153846153,
        "std_pred_length-nopunct": 2.2819072267986655,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7192982456140351,
        "vocab_size-1-nopunct": 123,
        "unique-1-nopunct": 104,
        "entropy-1-nopunct": 6.634149190509606,
        "distinct-2-nopunct": 0.9493670886075949,
        "vocab_size-2-nopunct": 150,
        "unique-2-nopunct": 146,
        "entropy-2-nopunct": 7.177198469696105,
        "cond_entropy-2-nopunct": 0.594872970432628,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 145,
        "unique-3-nopunct": 145,
        "entropy-3-nopunct": 7.179909090014958,
        "cond_entropy-3-nopunct": 0.014059376320590226,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.90338,
            "recall": 0.88233,
            "fmeasure": 0.88817
        },
        "rouge2": {
            "precision": 0.71775,
            "recall": 0.70832,
            "fmeasure": 0.70837
        },
        "rougeL": {
            "precision": 0.76853,
            "recall": 0.75092,
            "fmeasure": 0.75467
        },
        "rougeLsum": {
            "precision": 0.76853,
            "recall": 0.75092,
            "fmeasure": 0.75467
        },
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.09090909090909091,
            "3": 0.9210526315789473
        },
        "nist": 6.882356966321469,
        "bleu": 62.25504,
        "bleurt": 0.5364,
        "nubia": {
            "semantic_relation": 4.74998,
            "contradiction": 2.79982,
            "irrelevancy": 7.85404,
            "logical_agreement": 89.34614,
            "grammar_ref": 5.1809,
            "grammar_hyp": 5.12887,
            "nubia_score": 0.89457
        },
        "meteor": 0.4880498696147429,
        "bertscore": {
            "precision": 0.96158,
            "recall": 0.95643,
            "f1": 0.95853
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_132": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 43,
        "msttr-100": 0.68714,
        "msttr-100_nopunct": 0.73833,
        "total_length": 759,
        "mean_pred_length": 17.651162790697676,
        "std_pred_length": 6.3351500814814585,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 33,
        "distinct-1": 0.49538866930171277,
        "vocab_size-1": 376,
        "unique-1": 290,
        "entropy-1": 7.415580920322536,
        "distinct-2": 0.8645251396648045,
        "vocab_size-2": 619,
        "unique-2": 554,
        "entropy-2": 9.142979045396437,
        "cond_entropy-2": 1.5287899855036646,
        "distinct-3": 0.9554234769687965,
        "vocab_size-3": 643,
        "unique-3": 614,
        "entropy-3": 9.304187973210471,
        "cond_entropy-3": 0.16700549834603068,
        "total_length-nopunct": 666,
        "mean_pred_length-nopunct": 15.488372093023257,
        "std_pred_length-nopunct": 5.895887778677278,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.5570570570570571,
        "vocab_size-1-nopunct": 371,
        "unique-1-nopunct": 289,
        "entropy-1-nopunct": 7.59383424754981,
        "distinct-2-nopunct": 0.8667736757624398,
        "vocab_size-2-nopunct": 540,
        "unique-2-nopunct": 487,
        "entropy-2-nopunct": 8.938739516726997,
        "cond_entropy-2-nopunct": 1.4467327926709905,
        "distinct-3-nopunct": 0.9586206896551724,
        "vocab_size-3-nopunct": 556,
        "unique-3-nopunct": 533,
        "entropy-3-nopunct": 9.095848939149173,
        "cond_entropy-3-nopunct": 0.17919045683717047,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80853,
            "recall": 0.79251,
            "fmeasure": 0.79172
        },
        "rouge2": {
            "precision": 0.58679,
            "recall": 0.57202,
            "fmeasure": 0.57228
        },
        "rougeL": {
            "precision": 0.7054,
            "recall": 0.68476,
            "fmeasure": 0.68793
        },
        "rougeLsum": {
            "precision": 0.7054,
            "recall": 0.68476,
            "fmeasure": 0.68793
        },
        "local_recall": {
            "1": 0.27906976744186046,
            "2": 0.6637931034482759,
            "3": 0.8296943231441049
        },
        "nist": 7.394265333436576,
        "bleu": 51.69695,
        "bleurt": 0.41531,
        "nubia": {
            "semantic_relation": 4.56935,
            "contradiction": 2.33861,
            "irrelevancy": 24.05684,
            "logical_agreement": 73.60455,
            "grammar_ref": 4.66047,
            "grammar_hyp": 4.52891,
            "nubia_score": 0.84385
        },
        "meteor": 0.43384764497712763,
        "bertscore": {
            "precision": 0.94458,
            "recall": 0.94193,
            "f1": 0.94243
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_220": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 16,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.79,
        "total_length": 280,
        "mean_pred_length": 17.5,
        "std_pred_length": 5.5677643628300215,
        "median_pred_length": 17.5,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.6357142857142857,
        "vocab_size-1": 178,
        "unique-1": 152,
        "entropy-1": 6.852904454040814,
        "distinct-2": 0.9393939393939394,
        "vocab_size-2": 248,
        "unique-2": 238,
        "entropy-2": 7.899073937628915,
        "cond_entropy-2": 0.8811015177035103,
        "distinct-3": 0.9919354838709677,
        "vocab_size-3": 246,
        "unique-3": 244,
        "entropy-3": 7.938067278128836,
        "cond_entropy-3": 0.04836883609535857,
        "total_length-nopunct": 248,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 4.949747468305833,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6975806451612904,
        "vocab_size-1-nopunct": 173,
        "unique-1-nopunct": 151,
        "entropy-1-nopunct": 6.9407598192249775,
        "distinct-2-nopunct": 0.9439655172413793,
        "vocab_size-2-nopunct": 219,
        "unique-2-nopunct": 211,
        "entropy-2-nopunct": 7.721732544806705,
        "cond_entropy-2-nopunct": 0.8440331624691347,
        "distinct-3-nopunct": 0.9953703703703703,
        "vocab_size-3-nopunct": 215,
        "unique-3-nopunct": 214,
        "entropy-3-nopunct": 7.745628242904204,
        "cond_entropy-3-nopunct": 0.033988175899029964,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79291,
            "recall": 0.80098,
            "fmeasure": 0.78378
        },
        "rouge2": {
            "precision": 0.56984,
            "recall": 0.59227,
            "fmeasure": 0.57314
        },
        "rougeL": {
            "precision": 0.65732,
            "recall": 0.67179,
            "fmeasure": 0.65571
        },
        "rougeLsum": {
            "precision": 0.65732,
            "recall": 0.67179,
            "fmeasure": 0.65571
        },
        "local_recall": {
            "1": 0.22727272727272727,
            "2": 0.325,
            "3": 0.8502673796791443
        },
        "nist": 6.447181432558277,
        "bleu": 52.00842,
        "bleurt": 0.31399,
        "nubia": {
            "semantic_relation": 4.36157,
            "contradiction": 2.39991,
            "irrelevancy": 32.89146,
            "logical_agreement": 64.70864,
            "grammar_ref": 4.78068,
            "grammar_hyp": 4.80479,
            "nubia_score": 0.78614
        },
        "meteor": 0.4177539128879572,
        "bertscore": {
            "precision": 0.937,
            "recall": 0.94101,
            "f1": 0.93733
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_221": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 74,
        "mean_pred_length": 14.8,
        "std_pred_length": 4.915282290977803,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 22,
        "distinct-1": 0.6621621621621622,
        "vocab_size-1": 49,
        "unique-1": 38,
        "entropy-1": 5.323185677446872,
        "distinct-2": 0.9130434782608695,
        "vocab_size-2": 63,
        "unique-2": 57,
        "entropy-2": 5.934611413299903,
        "cond_entropy-2": 0.5073923730483075,
        "distinct-3": 0.96875,
        "vocab_size-3": 62,
        "unique-3": 60,
        "entropy-3": 5.9375,
        "cond_entropy-3": 0.016475543221830896,
        "total_length-nopunct": 68,
        "mean_pred_length-nopunct": 13.6,
        "std_pred_length-nopunct": 5.083306010855534,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6911764705882353,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.293725069911562,
        "distinct-2-nopunct": 0.9047619047619048,
        "vocab_size-2-nopunct": 57,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 5.78680373302373,
        "cond_entropy-2-nopunct": 0.5033447069503663,
        "distinct-3-nopunct": 0.9655172413793104,
        "vocab_size-3-nopunct": 56,
        "unique-3-nopunct": 54,
        "entropy-3-nopunct": 5.789015477886191,
        "cond_entropy-3-nopunct": 0.0013907268000693694,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73675,
            "recall": 0.73722,
            "fmeasure": 0.72319
        },
        "rouge2": {
            "precision": 0.61916,
            "recall": 0.62265,
            "fmeasure": 0.60754
        },
        "rougeL": {
            "precision": 0.60152,
            "recall": 0.62383,
            "fmeasure": 0.60024
        },
        "rougeLsum": {
            "precision": 0.60152,
            "recall": 0.62383,
            "fmeasure": 0.60024
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.6904761904761905
        },
        "nist": 3.620824127872225,
        "bleu": 28.86687,
        "bleurt": 0.09252,
        "nubia": {
            "semantic_relation": 4.26379,
            "contradiction": 6.58792,
            "irrelevancy": 31.24222,
            "logical_agreement": 62.16986,
            "grammar_ref": 3.91039,
            "grammar_hyp": 3.79262,
            "nubia_score": 0.77605
        },
        "meteor": 0.3361697136883234,
        "bertscore": {
            "precision": 0.90746,
            "recall": 0.90973,
            "f1": 0.90498
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_160": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.7325,
        "msttr-100_nopunct": 0.80333,
        "total_length": 442,
        "mean_pred_length": 15.241379310344827,
        "std_pred_length": 4.847005278155625,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 30,
        "distinct-1": 0.5904977375565611,
        "vocab_size-1": 261,
        "unique-1": 208,
        "entropy-1": 7.272720568631235,
        "distinct-2": 0.927360774818402,
        "vocab_size-2": 383,
        "unique-2": 361,
        "entropy-2": 8.52288041691908,
        "cond_entropy-2": 1.0154354629932505,
        "distinct-3": 0.9817708333333334,
        "vocab_size-3": 377,
        "unique-3": 370,
        "entropy-3": 8.548504167387893,
        "cond_entropy-3": 0.03303627411591393,
        "total_length-nopunct": 377,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 4.051393970406763,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6763925729442971,
        "vocab_size-1-nopunct": 255,
        "unique-1-nopunct": 207,
        "entropy-1-nopunct": 7.511384675303315,
        "distinct-2-nopunct": 0.9281609195402298,
        "vocab_size-2-nopunct": 323,
        "unique-2-nopunct": 305,
        "entropy-2-nopunct": 8.275516304738158,
        "cond_entropy-2-nopunct": 0.827907836617415,
        "distinct-3-nopunct": 0.9843260188087775,
        "vocab_size-3-nopunct": 314,
        "unique-3-nopunct": 309,
        "entropy-3-nopunct": 8.286064651382485,
        "cond_entropy-3-nopunct": 0.02263420414338393,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8504,
            "recall": 0.80888,
            "fmeasure": 0.82004
        },
        "rouge2": {
            "precision": 0.63932,
            "recall": 0.60865,
            "fmeasure": 0.61636
        },
        "rougeL": {
            "precision": 0.73808,
            "recall": 0.69677,
            "fmeasure": 0.70881
        },
        "rougeLsum": {
            "precision": 0.73808,
            "recall": 0.69677,
            "fmeasure": 0.70881
        },
        "local_recall": {
            "1": 0.13846153846153847,
            "2": 0.42857142857142855,
            "3": 0.826865671641791
        },
        "nist": 7.289950466889649,
        "bleu": 56.64599,
        "bleurt": 0.48204,
        "nubia": {
            "semantic_relation": 4.60507,
            "contradiction": 3.13791,
            "irrelevancy": 18.45883,
            "logical_agreement": 78.40325,
            "grammar_ref": 4.52589,
            "grammar_hyp": 4.5856,
            "nubia_score": 0.85997
        },
        "meteor": 0.4476776407900958,
        "bertscore": {
            "precision": 0.95928,
            "recall": 0.95251,
            "f1": 0.95327
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_161": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.72,
        "total_length": 138,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 4.163331998932265,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 92,
        "unique-1": 74,
        "entropy-1": 6.152043681448391,
        "distinct-2": 0.9302325581395349,
        "vocab_size-2": 120,
        "unique-2": 111,
        "entropy-2": 6.8716923717023075,
        "cond_entropy-2": 0.565222348897243,
        "distinct-3": 0.9916666666666667,
        "vocab_size-3": 119,
        "unique-3": 118,
        "entropy-3": 6.890223928941868,
        "cond_entropy-3": 0.028996673518597808,
        "total_length-nopunct": 123,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 4.189935029992179,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7154471544715447,
        "vocab_size-1-nopunct": 88,
        "unique-1-nopunct": 72,
        "entropy-1-nopunct": 6.166376115237376,
        "distinct-2-nopunct": 0.9210526315789473,
        "vocab_size-2-nopunct": 105,
        "unique-2-nopunct": 96,
        "entropy-2-nopunct": 6.674995277322647,
        "cond_entropy-2-nopunct": 0.5384462060343368,
        "distinct-3-nopunct": 0.9904761904761905,
        "vocab_size-3-nopunct": 104,
        "unique-3-nopunct": 103,
        "entropy-3-nopunct": 6.695197898618494,
        "cond_entropy-3-nopunct": 0.033736455882333136,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71259,
            "recall": 0.70824,
            "fmeasure": 0.70094
        },
        "rouge2": {
            "precision": 0.42162,
            "recall": 0.41572,
            "fmeasure": 0.41149
        },
        "rougeL": {
            "precision": 0.59332,
            "recall": 0.60315,
            "fmeasure": 0.58844
        },
        "rougeLsum": {
            "precision": 0.59332,
            "recall": 0.60315,
            "fmeasure": 0.58844
        },
        "local_recall": {
            "1": 0.21621621621621623,
            "2": 0.5454545454545454,
            "3": 0.8059701492537313
        },
        "nist": 4.986853064908626,
        "bleu": 30.68507,
        "bleurt": 0.26849,
        "nubia": {
            "semantic_relation": 4.18712,
            "contradiction": 3.05231,
            "irrelevancy": 40.23358,
            "logical_agreement": 56.71412,
            "grammar_ref": 5.14381,
            "grammar_hyp": 4.91554,
            "nubia_score": 0.71033
        },
        "meteor": 0.3587120606150366,
        "bertscore": {
            "precision": 0.91316,
            "recall": 0.92115,
            "f1": 0.91611
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_222": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.79,
        "total_length": 209,
        "mean_pred_length": 19.0,
        "std_pred_length": 8.517361947543062,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 41,
        "distinct-1": 0.6172248803827751,
        "vocab_size-1": 129,
        "unique-1": 102,
        "entropy-1": 6.447444834268092,
        "distinct-2": 0.9191919191919192,
        "vocab_size-2": 182,
        "unique-2": 173,
        "entropy-2": 7.425999738733684,
        "cond_entropy-2": 0.8493855598595992,
        "distinct-3": 0.9893048128342246,
        "vocab_size-3": 185,
        "unique-3": 183,
        "entropy-3": 7.525504085556066,
        "cond_entropy-3": 0.11146651631332352,
        "total_length-nopunct": 180,
        "mean_pred_length-nopunct": 16.363636363636363,
        "std_pred_length-nopunct": 8.160578491891004,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.6944444444444444,
        "vocab_size-1-nopunct": 125,
        "unique-1-nopunct": 102,
        "entropy-1-nopunct": 6.557426308005289,
        "distinct-2-nopunct": 0.9112426035502958,
        "vocab_size-2-nopunct": 154,
        "unique-2-nopunct": 146,
        "entropy-2-nopunct": 7.174461314941999,
        "cond_entropy-2-nopunct": 0.6660213659400669,
        "distinct-3-nopunct": 0.9936708860759493,
        "vocab_size-3-nopunct": 157,
        "unique-3-nopunct": 156,
        "entropy-3-nopunct": 7.291122520329018,
        "cond_entropy-3-nopunct": 0.11976626446764288,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.64404,
            "recall": 0.63247,
            "fmeasure": 0.62805
        },
        "rouge2": {
            "precision": 0.40147,
            "recall": 0.39353,
            "fmeasure": 0.38892
        },
        "rougeL": {
            "precision": 0.49872,
            "recall": 0.48712,
            "fmeasure": 0.48387
        },
        "rougeLsum": {
            "precision": 0.49872,
            "recall": 0.48712,
            "fmeasure": 0.48387
        },
        "local_recall": {
            "1": 0.10810810810810811,
            "2": 0.475,
            "3": 0.6638655462184874
        },
        "nist": 4.470909864141877,
        "bleu": 29.4051,
        "bleurt": -0.13545,
        "nubia": {
            "semantic_relation": 3.46633,
            "contradiction": 25.20694,
            "irrelevancy": 24.77174,
            "logical_agreement": 50.02132,
            "grammar_ref": 4.70623,
            "grammar_hyp": 4.77907,
            "nubia_score": 0.5748
        },
        "meteor": 0.3207237690522713,
        "bertscore": {
            "precision": 0.88077,
            "recall": 0.89074,
            "f1": 0.88344
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_challenge_test_asset_nopunc",
        "N": 359,
        "msttr-100": 0.70952,
        "msttr-100_nopunct": 0.75745,
        "total_length": 6271,
        "mean_pred_length": 17.467966573816156,
        "std_pred_length": 8.360169130980793,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 57,
        "distinct-1": 0.3592728432466911,
        "vocab_size-1": 2253,
        "unique-1": 1672,
        "entropy-1": 8.921952373516007,
        "distinct-2": 0.8134303112313938,
        "vocab_size-2": 4809,
        "unique-2": 4404,
        "entropy-2": 11.83790981428958,
        "cond_entropy-2": 2.613956417797903,
        "distinct-3": 0.9420133261300198,
        "vocab_size-3": 5231,
        "unique-3": 5104,
        "entropy-3": 12.210640111249456,
        "cond_entropy-3": 0.40184710748119545,
        "total_length-nopunct": 5534,
        "mean_pred_length-nopunct": 15.415041782729805,
        "std_pred_length-nopunct": 7.26788616366188,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.4053126129382002,
        "vocab_size-1-nopunct": 2243,
        "unique-1-nopunct": 1669,
        "entropy-1-nopunct": 9.284204223951537,
        "distinct-2-nopunct": 0.8367149758454107,
        "vocab_size-2-nopunct": 4330,
        "unique-2-nopunct": 3997,
        "entropy-2-nopunct": 11.765958098081981,
        "cond_entropy-2-nopunct": 2.6439568758867473,
        "distinct-3-nopunct": 0.9649086378737541,
        "vocab_size-3-nopunct": 4647,
        "unique-3-nopunct": 4542,
        "entropy-3-nopunct": 12.141340455127715,
        "cond_entropy-3-nopunct": 0.40728677427300547,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_nopunc.json",
        "rouge1": {
            "precision": 0.79715,
            "recall": 0.73716,
            "fmeasure": 0.7526
        },
        "rouge2": {
            "precision": 0.62094,
            "recall": 0.5777,
            "fmeasure": 0.58319
        },
        "rougeL": {
            "precision": 0.75462,
            "recall": 0.70486,
            "fmeasure": 0.71554
        },
        "rougeLsum": {
            "precision": 0.75462,
            "recall": 0.70486,
            "fmeasure": 0.71554
        },
        "local_recall": {
            "1": 0.043285024154589374,
            "2": 0.1565934065934066,
            "3": 0.2661195779601407,
            "4": 0.3909348441926346,
            "5": 0.48339973439575035,
            "6": 0.5566502463054187,
            "7": 0.6769406392694064,
            "8": 0.7589285714285714,
            "9": 0.8726618705035971
        },
        "nist": 11.01665268327294,
        "bleu": 62.97065,
        "sari": 46.51981,
        "bleurt": 0.03069,
        "nubia": {
            "semantic_relation": 3.92503,
            "contradiction": 4.06518,
            "irrelevancy": 28.04594,
            "logical_agreement": 67.88888,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.04491,
            "nubia_score": 0.56527
        },
        "meteor": 0.4108414257377845,
        "bertscore": {
            "precision": 0.94007,
            "recall": 0.93292,
            "f1": 0.93201
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_133": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.8,
        "total_length": 161,
        "mean_pred_length": 14.636363636363637,
        "std_pred_length": 7.189294152642743,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 36,
        "distinct-1": 0.6708074534161491,
        "vocab_size-1": 108,
        "unique-1": 91,
        "entropy-1": 6.31518136522491,
        "distinct-2": 0.96,
        "vocab_size-2": 144,
        "unique-2": 138,
        "entropy-2": 7.1488186904958635,
        "cond_entropy-2": 0.6544329441828021,
        "distinct-3": 0.9784172661870504,
        "vocab_size-3": 136,
        "unique-3": 133,
        "entropy-3": 7.075775605097623,
        "cond_entropy-3": -0.06671215014647405,
        "total_length-nopunct": 131,
        "mean_pred_length-nopunct": 11.909090909090908,
        "std_pred_length-nopunct": 4.399474048204677,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7938931297709924,
        "vocab_size-1-nopunct": 104,
        "unique-1-nopunct": 91,
        "entropy-1-nopunct": 6.4881869560014165,
        "distinct-2-nopunct": 0.975,
        "vocab_size-2-nopunct": 117,
        "unique-2-nopunct": 114,
        "entropy-2-nopunct": 6.856890595608535,
        "cond_entropy-2-nopunct": 0.40201694378124037,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 109,
        "unique-3-nopunct": 109,
        "entropy-3-nopunct": 6.7681843247769145,
        "cond_entropy-3-nopunct": -0.0928347111985648,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7733,
            "recall": 0.6629,
            "fmeasure": 0.69754
        },
        "rouge2": {
            "precision": 0.51059,
            "recall": 0.44173,
            "fmeasure": 0.46206
        },
        "rougeL": {
            "precision": 0.66022,
            "recall": 0.57799,
            "fmeasure": 0.60209
        },
        "rougeLsum": {
            "precision": 0.66022,
            "recall": 0.57799,
            "fmeasure": 0.60209
        },
        "local_recall": {
            "1": 0.1388888888888889,
            "2": 0.18181818181818182,
            "3": 0.7063492063492064
        },
        "nist": 4.973343196339342,
        "bleu": 37.29938,
        "bleurt": 0.15968,
        "nubia": {
            "semantic_relation": 4.12964,
            "contradiction": 13.77532,
            "irrelevancy": 20.8628,
            "logical_agreement": 65.36188,
            "grammar_ref": 4.38413,
            "grammar_hyp": 4.70045,
            "nubia_score": 0.67484
        },
        "meteor": 0.370496185946238,
        "bertscore": {
            "precision": 0.91554,
            "recall": 0.90748,
            "f1": 0.90936
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_162": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 26,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.7275,
        "total_length": 495,
        "mean_pred_length": 19.03846153846154,
        "std_pred_length": 6.618626218313849,
        "median_pred_length": 18.5,
        "min_pred_length": 8,
        "max_pred_length": 34,
        "distinct-1": 0.5555555555555556,
        "vocab_size-1": 275,
        "unique-1": 228,
        "entropy-1": 7.192860072207254,
        "distinct-2": 0.8976545842217484,
        "vocab_size-2": 421,
        "unique-2": 387,
        "entropy-2": 8.64308355810748,
        "cond_entropy-2": 1.2871267013375138,
        "distinct-3": 0.9774266365688488,
        "vocab_size-3": 433,
        "unique-3": 423,
        "entropy-3": 8.746016161692735,
        "cond_entropy-3": 0.10571925575780036,
        "total_length-nopunct": 434,
        "mean_pred_length-nopunct": 16.692307692307693,
        "std_pred_length-nopunct": 5.921078583977174,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.619815668202765,
        "vocab_size-1-nopunct": 269,
        "unique-1-nopunct": 227,
        "entropy-1-nopunct": 7.325118161009119,
        "distinct-2-nopunct": 0.9142156862745098,
        "vocab_size-2-nopunct": 373,
        "unique-2-nopunct": 348,
        "entropy-2-nopunct": 8.479951506155453,
        "cond_entropy-2-nopunct": 1.222461708761779,
        "distinct-3-nopunct": 0.981675392670157,
        "vocab_size-3-nopunct": 375,
        "unique-3-nopunct": 368,
        "entropy-3-nopunct": 8.540779613376088,
        "cond_entropy-3-nopunct": 0.0713106196060872,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72739,
            "recall": 0.74259,
            "fmeasure": 0.72295
        },
        "rouge2": {
            "precision": 0.51348,
            "recall": 0.52469,
            "fmeasure": 0.51064
        },
        "rougeL": {
            "precision": 0.59823,
            "recall": 0.62389,
            "fmeasure": 0.60083
        },
        "rougeLsum": {
            "precision": 0.59823,
            "recall": 0.62389,
            "fmeasure": 0.60083
        },
        "local_recall": {
            "1": 0.18823529411764706,
            "2": 0.6194029850746269,
            "3": 0.7480314960629921
        },
        "nist": 6.394642209264441,
        "bleu": 47.2746,
        "bleurt": 0.20843,
        "nubia": {
            "semantic_relation": 4.13236,
            "contradiction": 11.78924,
            "irrelevancy": 34.79428,
            "logical_agreement": 53.41648,
            "grammar_ref": 4.52061,
            "grammar_hyp": 4.46983,
            "nubia_score": 0.72598
        },
        "meteor": 0.4098484969336889,
        "bertscore": {
            "precision": 0.92466,
            "recall": 0.93459,
            "f1": 0.92727
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_134": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85,
            "recall": 0.78333,
            "fmeasure": 0.81364
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.4596,
            "fmeasure": 0.47778
        },
        "rougeL": {
            "precision": 0.45,
            "recall": 0.425,
            "fmeasure": 0.43636
        },
        "rougeLsum": {
            "precision": 0.45,
            "recall": 0.425,
            "fmeasure": 0.43636
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 1.0
        },
        "nist": 3.2447217676556668,
        "bleu": 33.52113,
        "bleurt": 0.25113,
        "nubia": {
            "semantic_relation": 4.78961,
            "contradiction": 0.66608,
            "irrelevancy": 45.96287,
            "logical_agreement": 53.37104,
            "grammar_ref": 5.93899,
            "grammar_hyp": 5.65637,
            "nubia_score": 0.88138
        },
        "meteor": 0.45312537108837203,
        "bertscore": {
            "precision": 0.9692,
            "recall": 0.9692,
            "f1": 0.9692
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_192": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.714,
        "msttr-100_nopunct": 0.7625,
        "total_length": 548,
        "mean_pred_length": 17.677419354838708,
        "std_pred_length": 7.484983232140994,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 39,
        "distinct-1": 0.5547445255474452,
        "vocab_size-1": 304,
        "unique-1": 254,
        "entropy-1": 7.320382498412967,
        "distinct-2": 0.8955512572533849,
        "vocab_size-2": 463,
        "unique-2": 426,
        "entropy-2": 8.764902506060714,
        "cond_entropy-2": 1.254050087916536,
        "distinct-3": 0.9629629629629629,
        "vocab_size-3": 468,
        "unique-3": 450,
        "entropy-3": 8.850738429531706,
        "cond_entropy-3": 0.08782721851164468,
        "total_length-nopunct": 487,
        "mean_pred_length-nopunct": 15.709677419354838,
        "std_pred_length-nopunct": 6.663301266407626,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.6098562628336756,
        "vocab_size-1-nopunct": 297,
        "unique-1-nopunct": 250,
        "entropy-1-nopunct": 7.466227501674496,
        "distinct-2-nopunct": 0.8947368421052632,
        "vocab_size-2-nopunct": 408,
        "unique-2-nopunct": 376,
        "entropy-2-nopunct": 8.578418303600518,
        "cond_entropy-2-nopunct": 1.1852348025238677,
        "distinct-3-nopunct": 0.9576470588235294,
        "vocab_size-3-nopunct": 407,
        "unique-3-nopunct": 389,
        "entropy-3-nopunct": 8.646613148672182,
        "cond_entropy-3-nopunct": 0.08205042866575185,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70479,
            "recall": 0.66077,
            "fmeasure": 0.66931
        },
        "rouge2": {
            "precision": 0.45302,
            "recall": 0.42286,
            "fmeasure": 0.42858
        },
        "rougeL": {
            "precision": 0.57264,
            "recall": 0.54315,
            "fmeasure": 0.54689
        },
        "rougeLsum": {
            "precision": 0.57264,
            "recall": 0.54315,
            "fmeasure": 0.54689
        },
        "local_recall": {
            "1": 0.24050632911392406,
            "2": 0.37777777777777777,
            "3": 0.6845070422535211
        },
        "nist": 5.662712139061228,
        "bleu": 34.72668,
        "bleurt": 0.1837,
        "nubia": {
            "semantic_relation": 4.02923,
            "contradiction": 5.70656,
            "irrelevancy": 31.28206,
            "logical_agreement": 63.01138,
            "grammar_ref": 4.61479,
            "grammar_hyp": 4.63834,
            "nubia_score": 0.67378
        },
        "meteor": 0.35649077294307735,
        "bertscore": {
            "precision": 0.9112,
            "recall": 0.90552,
            "f1": 0.90645
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_194": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322706,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.037503523749935014,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.36364,
            "recall": 0.33333,
            "fmeasure": 0.34783
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.27273,
            "recall": 0.25,
            "fmeasure": 0.26087
        },
        "rougeLsum": {
            "precision": 0.27273,
            "recall": 0.25,
            "fmeasure": 0.26087
        },
        "local_recall": {
            "1": 0,
            "2": 0.5
        },
        "nist": 1.4196459763390796,
        "bleu": 4.6591,
        "bleurt": -0.76543,
        "nubia": {
            "semantic_relation": 2.84478,
            "contradiction": 0.33993,
            "irrelevancy": 99.58435,
            "logical_agreement": 0.07572,
            "grammar_ref": 3.85254,
            "grammar_hyp": 5.67447,
            "nubia_score": 0.20891
        },
        "meteor": 0.24343142877361829,
        "bertscore": {
            "precision": 0.8351,
            "recall": 0.84599,
            "f1": 0.84051
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_224": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.70333,
        "msttr-100_nopunct": 0.76,
        "total_length": 320,
        "mean_pred_length": 17.77777777777778,
        "std_pred_length": 6.267691011631313,
        "median_pred_length": 17.5,
        "min_pred_length": 8,
        "max_pred_length": 32,
        "distinct-1": 0.58125,
        "vocab_size-1": 186,
        "unique-1": 147,
        "entropy-1": 6.897879794972012,
        "distinct-2": 0.9337748344370861,
        "vocab_size-2": 282,
        "unique-2": 266,
        "entropy-2": 8.09595589823685,
        "cond_entropy-2": 1.0344145780082143,
        "distinct-3": 0.9753521126760564,
        "vocab_size-3": 277,
        "unique-3": 270,
        "entropy-3": 8.100451344856817,
        "cond_entropy-3": -0.003218667332754584,
        "total_length-nopunct": 278,
        "mean_pred_length-nopunct": 15.444444444444445,
        "std_pred_length-nopunct": 5.346049654986404,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6474820143884892,
        "vocab_size-1-nopunct": 180,
        "unique-1-nopunct": 145,
        "entropy-1-nopunct": 6.988013105135657,
        "distinct-2-nopunct": 0.9307692307692308,
        "vocab_size-2-nopunct": 242,
        "unique-2-nopunct": 227,
        "entropy-2-nopunct": 7.875196034157336,
        "cond_entropy-2-nopunct": 0.9516896248518918,
        "distinct-3-nopunct": 0.9710743801652892,
        "vocab_size-3-nopunct": 235,
        "unique-3-nopunct": 228,
        "entropy-3-nopunct": 7.861011997605175,
        "cond_entropy-3-nopunct": -0.013919038539937582,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72489,
            "recall": 0.69675,
            "fmeasure": 0.70142
        },
        "rouge2": {
            "precision": 0.51179,
            "recall": 0.48124,
            "fmeasure": 0.4885
        },
        "rougeL": {
            "precision": 0.60785,
            "recall": 0.59498,
            "fmeasure": 0.59104
        },
        "rougeLsum": {
            "precision": 0.60785,
            "recall": 0.59498,
            "fmeasure": 0.59104
        },
        "local_recall": {
            "1": 0.23333333333333334,
            "2": 0.22,
            "3": 0.7474747474747475
        },
        "nist": 5.789250749865573,
        "bleu": 43.48871,
        "bleurt": 0.21029,
        "nubia": {
            "semantic_relation": 4.04743,
            "contradiction": 21.49103,
            "irrelevancy": 20.68203,
            "logical_agreement": 57.82694,
            "grammar_ref": 4.41455,
            "grammar_hyp": 4.30943,
            "nubia_score": 0.70046
        },
        "meteor": 0.39959709961688517,
        "bertscore": {
            "precision": 0.91076,
            "recall": 0.91462,
            "f1": 0.9096
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_195": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.8,
        "total_length": 215,
        "mean_pred_length": 14.333333333333334,
        "std_pred_length": 7.947046970765654,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 38,
        "distinct-1": 0.641860465116279,
        "vocab_size-1": 138,
        "unique-1": 112,
        "entropy-1": 6.583960496859947,
        "distinct-2": 0.94,
        "vocab_size-2": 188,
        "unique-2": 178,
        "entropy-2": 7.5138561897747405,
        "cond_entropy-2": 0.7241963246988373,
        "distinct-3": 0.9837837837837838,
        "vocab_size-3": 182,
        "unique-3": 179,
        "entropy-3": 7.498949028083868,
        "cond_entropy-3": -0.025988242771926087,
        "total_length-nopunct": 185,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 6.538773245460922,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.7189189189189189,
        "vocab_size-1-nopunct": 133,
        "unique-1-nopunct": 112,
        "entropy-1-nopunct": 6.655181696039127,
        "distinct-2-nopunct": 0.9470588235294117,
        "vocab_size-2-nopunct": 161,
        "unique-2-nopunct": 154,
        "entropy-2-nopunct": 7.291743877314143,
        "cond_entropy-2-nopunct": 0.6834626016615984,
        "distinct-3-nopunct": 0.9870967741935484,
        "vocab_size-3-nopunct": 153,
        "unique-3-nopunct": 151,
        "entropy-3-nopunct": 7.250317953661354,
        "cond_entropy-3-nopunct": -0.04294395021830259,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79844,
            "recall": 0.69882,
            "fmeasure": 0.73337
        },
        "rouge2": {
            "precision": 0.53808,
            "recall": 0.49788,
            "fmeasure": 0.51168
        },
        "rougeL": {
            "precision": 0.71754,
            "recall": 0.6315,
            "fmeasure": 0.66118
        },
        "rougeLsum": {
            "precision": 0.71754,
            "recall": 0.6315,
            "fmeasure": 0.66118
        },
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.2727272727272727,
            "3": 0.7707006369426752
        },
        "nist": 5.183229306647002,
        "bleu": 47.87384,
        "bleurt": 0.23824,
        "nubia": {
            "semantic_relation": 4.17787,
            "contradiction": 4.11767,
            "irrelevancy": 32.42561,
            "logical_agreement": 63.45671,
            "grammar_ref": 4.60593,
            "grammar_hyp": 4.80715,
            "nubia_score": 0.69815
        },
        "meteor": 0.37747257599640976,
        "bertscore": {
            "precision": 0.9257,
            "recall": 0.9072,
            "f1": 0.91532
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_164": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.73,
        "total_length": 173,
        "mean_pred_length": 14.416666666666666,
        "std_pred_length": 4.940619619260546,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.5953757225433526,
        "vocab_size-1": 103,
        "unique-1": 82,
        "entropy-1": 6.075429038857972,
        "distinct-2": 0.9254658385093167,
        "vocab_size-2": 149,
        "unique-2": 139,
        "entropy-2": 7.16942619488479,
        "cond_entropy-2": 0.9194947563228081,
        "distinct-3": 0.9865771812080537,
        "vocab_size-3": 147,
        "unique-3": 145,
        "entropy-3": 7.192322882878277,
        "cond_entropy-3": 0.022479830267007502,
        "total_length-nopunct": 149,
        "mean_pred_length-nopunct": 12.416666666666666,
        "std_pred_length-nopunct": 4.698551786336816,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6577181208053692,
        "vocab_size-1-nopunct": 98,
        "unique-1-nopunct": 79,
        "entropy-1-nopunct": 6.1249689008454515,
        "distinct-2-nopunct": 0.927007299270073,
        "vocab_size-2-nopunct": 127,
        "unique-2-nopunct": 119,
        "entropy-2-nopunct": 6.937448141354674,
        "cond_entropy-2-nopunct": 0.8718251925924545,
        "distinct-3-nopunct": 0.992,
        "vocab_size-3-nopunct": 124,
        "unique-3-nopunct": 123,
        "entropy-3-nopunct": 6.949784284662096,
        "cond_entropy-3-nopunct": 0.01975220170156023,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80554,
            "recall": 0.71331,
            "fmeasure": 0.74688
        },
        "rouge2": {
            "precision": 0.52542,
            "recall": 0.43535,
            "fmeasure": 0.46686
        },
        "rougeL": {
            "precision": 0.68095,
            "recall": 0.59968,
            "fmeasure": 0.62945
        },
        "rougeLsum": {
            "precision": 0.68095,
            "recall": 0.59968,
            "fmeasure": 0.62945
        },
        "local_recall": {
            "1": 0.2413793103448276,
            "2": 0.42857142857142855,
            "3": 0.7009345794392523
        },
        "nist": 5.004854805047733,
        "bleu": 36.27418,
        "bleurt": 0.00989,
        "nubia": {
            "semantic_relation": 4.24241,
            "contradiction": 12.62241,
            "irrelevancy": 17.60554,
            "logical_agreement": 69.77205,
            "grammar_ref": 4.9625,
            "grammar_hyp": 5.25367,
            "nubia_score": 0.70315
        },
        "meteor": 0.3533070499610063,
        "bertscore": {
            "precision": 0.90628,
            "recall": 0.90737,
            "f1": 0.9049
        }
    },
    "web_nlg_en_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 1177,
        "msttr-100": 0.61668,
        "msttr-100_nopunct": 0.66369,
        "total_length": 27468,
        "mean_pred_length": 23.33729821580289,
        "std_pred_length": 10.985395905548264,
        "median_pred_length": 22.0,
        "min_pred_length": 6,
        "max_pred_length": 71,
        "distinct-1": 0.062035823503713415,
        "vocab_size-1": 1704,
        "unique-1": 591,
        "entropy-1": 7.713277501857419,
        "distinct-2": 0.22950819672131148,
        "vocab_size-2": 6034,
        "unique-2": 3124,
        "entropy-2": 11.150022635822893,
        "cond_entropy-2": 3.2702363074853786,
        "distinct-3": 0.42195588118181093,
        "vocab_size-3": 10597,
        "unique-3": 6888,
        "entropy-3": 12.511223026462758,
        "cond_entropy-3": 1.4241998482874472,
        "total_length-nopunct": 24149,
        "mean_pred_length-nopunct": 20.517417162276974,
        "std_pred_length-nopunct": 9.889100139559753,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 65,
        "distinct-1-nopunct": 0.07014783220837302,
        "vocab_size-1-nopunct": 1694,
        "unique-1-nopunct": 590,
        "entropy-1-nopunct": 7.9837039791367355,
        "distinct-2-nopunct": 0.24795403099425387,
        "vocab_size-2-nopunct": 5696,
        "unique-2-nopunct": 3105,
        "entropy-2-nopunct": 11.085099929634412,
        "cond_entropy-2-nopunct": 3.2621897759646705,
        "distinct-3-nopunct": 0.44441385638908004,
        "vocab_size-3-nopunct": 9686,
        "unique-3-nopunct": 6535,
        "entropy-3-nopunct": 12.383739743696935,
        "cond_entropy-3-nopunct": 1.359288665076161,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.6261,
            "recall": 0.63192,
            "fmeasure": 0.62123
        },
        "rouge2": {
            "precision": 0.33042,
            "recall": 0.3349,
            "fmeasure": 0.32799
        },
        "rougeL": {
            "precision": 0.47778,
            "recall": 0.48556,
            "fmeasure": 0.47519
        },
        "rougeLsum": {
            "precision": 0.47778,
            "recall": 0.48556,
            "fmeasure": 0.47519
        },
        "local_recall": {
            "1": 0.20386705871870267,
            "2": 0.4783936478851733,
            "3": 0.6994458688280539,
            "4": 0.5,
            "5": 0.6896551724137931
        },
        "nist": 6.472126402704386,
        "bleu": 27.66121,
        "bleurt": -0.1632,
        "nubia": {
            "semantic_relation": 3.71984,
            "contradiction": 31.11724,
            "irrelevancy": 13.37189,
            "logical_agreement": 55.51087,
            "grammar_ref": 4.6454,
            "grammar_hyp": 4.74639,
            "nubia_score": 0.56931
        },
        "meteor": 0.29593312049517567,
        "bertscore": {
            "precision": 0.87501,
            "recall": 0.87846,
            "f1": 0.87528
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_225": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.71333,
        "msttr-100_nopunct": 0.74333,
        "total_length": 348,
        "mean_pred_length": 20.470588235294116,
        "std_pred_length": 9.419114777057928,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 51,
        "distinct-1": 0.5488505747126436,
        "vocab_size-1": 191,
        "unique-1": 145,
        "entropy-1": 6.905103353541712,
        "distinct-2": 0.9063444108761329,
        "vocab_size-2": 300,
        "unique-2": 275,
        "entropy-2": 8.16414804736125,
        "cond_entropy-2": 1.1280973044478968,
        "distinct-3": 0.9745222929936306,
        "vocab_size-3": 306,
        "unique-3": 298,
        "entropy-3": 8.24366533487891,
        "cond_entropy-3": 0.09069935474874206,
        "total_length-nopunct": 304,
        "mean_pred_length-nopunct": 17.88235294117647,
        "std_pred_length-nopunct": 7.474524206310837,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.6118421052631579,
        "vocab_size-1-nopunct": 186,
        "unique-1-nopunct": 145,
        "entropy-1-nopunct": 6.994879441998084,
        "distinct-2-nopunct": 0.8989547038327527,
        "vocab_size-2-nopunct": 258,
        "unique-2-nopunct": 235,
        "entropy-2-nopunct": 7.940640278673563,
        "cond_entropy-2-nopunct": 0.9970390760965946,
        "distinct-3-nopunct": 0.9703703703703703,
        "vocab_size-3-nopunct": 262,
        "unique-3-nopunct": 254,
        "entropy-3-nopunct": 8.017556337791584,
        "cond_entropy-3-nopunct": 0.08362914436255155,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70374,
            "recall": 0.79583,
            "fmeasure": 0.73476
        },
        "rouge2": {
            "precision": 0.50229,
            "recall": 0.57602,
            "fmeasure": 0.52477
        },
        "rougeL": {
            "precision": 0.6204,
            "recall": 0.68091,
            "fmeasure": 0.63652
        },
        "rougeLsum": {
            "precision": 0.6204,
            "recall": 0.68091,
            "fmeasure": 0.63652
        },
        "local_recall": {
            "1": 0.18,
            "2": 0.42857142857142855,
            "3": 0.8443396226415094
        },
        "nist": 5.88898633926079,
        "bleu": 43.45916,
        "bleurt": 0.17991,
        "nubia": {
            "semantic_relation": 3.97233,
            "contradiction": 9.18518,
            "irrelevancy": 47.06084,
            "logical_agreement": 43.75398,
            "grammar_ref": 4.59976,
            "grammar_hyp": 4.38952,
            "nubia_score": 0.65852
        },
        "meteor": 0.41300565522451516,
        "bertscore": {
            "precision": 0.90834,
            "recall": 0.92901,
            "f1": 0.91485
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_135": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.74333,
        "msttr-100_nopunct": 0.79667,
        "total_length": 393,
        "mean_pred_length": 17.08695652173913,
        "std_pred_length": 4.959953045695185,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.5852417302798982,
        "vocab_size-1": 230,
        "unique-1": 182,
        "entropy-1": 7.1355265914074035,
        "distinct-2": 0.8945945945945946,
        "vocab_size-2": 331,
        "unique-2": 301,
        "entropy-2": 8.294153251027643,
        "cond_entropy-2": 0.9696099838371822,
        "distinct-3": 0.9481268011527377,
        "vocab_size-3": 329,
        "unique-3": 312,
        "entropy-3": 8.332869986577796,
        "cond_entropy-3": 0.04867710678429462,
        "total_length-nopunct": 349,
        "mean_pred_length-nopunct": 15.173913043478262,
        "std_pred_length-nopunct": 4.705705823443108,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6418338108882522,
        "vocab_size-1-nopunct": 224,
        "unique-1-nopunct": 179,
        "entropy-1-nopunct": 7.264499767827943,
        "distinct-2-nopunct": 0.8957055214723927,
        "vocab_size-2-nopunct": 292,
        "unique-2-nopunct": 266,
        "entropy-2-nopunct": 8.11247186586101,
        "cond_entropy-2-nopunct": 0.9007310536857481,
        "distinct-3-nopunct": 0.9570957095709571,
        "vocab_size-3-nopunct": 290,
        "unique-3-nopunct": 277,
        "entropy-3-nopunct": 8.157365402614866,
        "cond_entropy-3-nopunct": 0.0430252022077279,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76105,
            "recall": 0.76882,
            "fmeasure": 0.7601
        },
        "rouge2": {
            "precision": 0.55709,
            "recall": 0.55944,
            "fmeasure": 0.55527
        },
        "rougeL": {
            "precision": 0.68137,
            "recall": 0.69021,
            "fmeasure": 0.68181
        },
        "rougeLsum": {
            "precision": 0.68137,
            "recall": 0.69021,
            "fmeasure": 0.68181
        },
        "local_recall": {
            "1": 0.2077922077922078,
            "2": 0.5072463768115942,
            "3": 0.8552631578947368
        },
        "nist": 6.314490945931552,
        "bleu": 48.50911,
        "bleurt": 0.26196,
        "nubia": {
            "semantic_relation": 4.27913,
            "contradiction": 7.59595,
            "irrelevancy": 31.84257,
            "logical_agreement": 60.56149,
            "grammar_ref": 4.82223,
            "grammar_hyp": 4.69869,
            "nubia_score": 0.75885
        },
        "meteor": 0.42956540096358076,
        "bertscore": {
            "precision": 0.92853,
            "recall": 0.93793,
            "f1": 0.93257
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_228": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.79,
        "total_length": 180,
        "mean_pred_length": 16.363636363636363,
        "std_pred_length": 6.197840199657931,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.6888888888888889,
        "vocab_size-1": 124,
        "unique-1": 105,
        "entropy-1": 6.520403075258406,
        "distinct-2": 0.9644970414201184,
        "vocab_size-2": 163,
        "unique-2": 158,
        "entropy-2": 7.325406729168783,
        "cond_entropy-2": 0.6430640232995655,
        "distinct-3": 1.0,
        "vocab_size-3": 158,
        "unique-3": 158,
        "entropy-3": 7.303780748177119,
        "cond_entropy-3": -0.02902977986354029,
        "total_length-nopunct": 154,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.704862359904448,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.7792207792207793,
        "vocab_size-1-nopunct": 120,
        "unique-1-nopunct": 105,
        "entropy-1-nopunct": 6.625434878548758,
        "distinct-2-nopunct": 0.965034965034965,
        "vocab_size-2-nopunct": 138,
        "unique-2-nopunct": 134,
        "entropy-2-nopunct": 7.084662333266764,
        "cond_entropy-2-nopunct": 0.5015691909670172,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 132,
        "unique-3-nopunct": 132,
        "entropy-3-nopunct": 7.044394119358443,
        "cond_entropy-3-nopunct": -0.041576554524758065,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82371,
            "recall": 0.79432,
            "fmeasure": 0.7992
        },
        "rouge2": {
            "precision": 0.60371,
            "recall": 0.58446,
            "fmeasure": 0.58647
        },
        "rougeL": {
            "precision": 0.74242,
            "recall": 0.70385,
            "fmeasure": 0.71458
        },
        "rougeLsum": {
            "precision": 0.74242,
            "recall": 0.70385,
            "fmeasure": 0.71458
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.3684210526315789,
            "3": 0.7928571428571428
        },
        "nist": 6.053833260929186,
        "bleu": 50.72622,
        "bleurt": 0.22315,
        "nubia": {
            "semantic_relation": 4.3643,
            "contradiction": 15.33084,
            "irrelevancy": 32.32958,
            "logical_agreement": 52.33958,
            "grammar_ref": 4.46209,
            "grammar_hyp": 4.54814,
            "nubia_score": 0.74563
        },
        "meteor": 0.44501148377097843,
        "bertscore": {
            "precision": 0.92677,
            "recall": 0.92821,
            "f1": 0.92549
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_230": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.84,
        "total_length": 169,
        "mean_pred_length": 16.9,
        "std_pred_length": 5.262128846769148,
        "median_pred_length": 15.5,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.727810650887574,
        "vocab_size-1": 123,
        "unique-1": 108,
        "entropy-1": 6.559725720788562,
        "distinct-2": 0.9811320754716981,
        "vocab_size-2": 156,
        "unique-2": 153,
        "entropy-2": 7.275147106227721,
        "cond_entropy-2": 0.559397839565363,
        "distinct-3": 1.0,
        "vocab_size-3": 149,
        "unique-3": 149,
        "entropy-3": 7.21916852046217,
        "cond_entropy-3": -0.053445978446354854,
        "total_length-nopunct": 150,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 5.039841267341661,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7933333333333333,
        "vocab_size-1-nopunct": 119,
        "unique-1-nopunct": 106,
        "entropy-1-nopunct": 6.6335906070615716,
        "distinct-2-nopunct": 0.9785714285714285,
        "vocab_size-2-nopunct": 137,
        "unique-2-nopunct": 134,
        "entropy-2-nopunct": 7.086425874087835,
        "cond_entropy-2-nopunct": 0.49535155870011593,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 130,
        "unique-3-nopunct": 130,
        "entropy-3-nopunct": 7.022367813028455,
        "cond_entropy-3-nopunct": -0.06076135776266604,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7471,
            "recall": 0.70943,
            "fmeasure": 0.71494
        },
        "rouge2": {
            "precision": 0.52959,
            "recall": 0.50589,
            "fmeasure": 0.51111
        },
        "rougeL": {
            "precision": 0.6533,
            "recall": 0.62028,
            "fmeasure": 0.62806
        },
        "rougeLsum": {
            "precision": 0.6533,
            "recall": 0.62028,
            "fmeasure": 0.62806
        },
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.5526315789473685,
            "3": 0.7821782178217822
        },
        "nist": 5.481443317612956,
        "bleu": 48.86527,
        "bleurt": 0.29243,
        "nubia": {
            "semantic_relation": 4.30604,
            "contradiction": 11.18749,
            "irrelevancy": 30.48838,
            "logical_agreement": 58.32413,
            "grammar_ref": 5.06465,
            "grammar_hyp": 4.83148,
            "nubia_score": 0.7598
        },
        "meteor": 0.40493843346707453,
        "bertscore": {
            "precision": 0.9216,
            "recall": 0.9141,
            "f1": 0.91499
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_196": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.665,
        "msttr-100_nopunct": 0.75,
        "total_length": 283,
        "mean_pred_length": 15.722222222222221,
        "std_pred_length": 8.568712826683646,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 47,
        "distinct-1": 0.568904593639576,
        "vocab_size-1": 161,
        "unique-1": 129,
        "entropy-1": 6.627893334540977,
        "distinct-2": 0.8679245283018868,
        "vocab_size-2": 230,
        "unique-2": 203,
        "entropy-2": 7.757833160826921,
        "cond_entropy-2": 0.9497251784492649,
        "distinct-3": 0.9352226720647774,
        "vocab_size-3": 231,
        "unique-3": 217,
        "entropy-3": 7.812700126304031,
        "cond_entropy-3": 0.04879971646109484,
        "total_length-nopunct": 238,
        "mean_pred_length-nopunct": 13.222222222222221,
        "std_pred_length-nopunct": 6.232134961057848,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.6596638655462185,
        "vocab_size-1-nopunct": 157,
        "unique-1-nopunct": 129,
        "entropy-1-nopunct": 6.768212422067001,
        "distinct-2-nopunct": 0.8863636363636364,
        "vocab_size-2-nopunct": 195,
        "unique-2-nopunct": 177,
        "entropy-2-nopunct": 7.523954302237873,
        "cond_entropy-2-nopunct": 0.8225324876327995,
        "distinct-3-nopunct": 0.9405940594059405,
        "vocab_size-3-nopunct": 190,
        "unique-3-nopunct": 180,
        "entropy-3-nopunct": 7.53192546787886,
        "cond_entropy-3-nopunct": 0.025957786448737762,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77753,
            "recall": 0.75236,
            "fmeasure": 0.75665
        },
        "rouge2": {
            "precision": 0.51622,
            "recall": 0.50208,
            "fmeasure": 0.50232
        },
        "rougeL": {
            "precision": 0.66653,
            "recall": 0.65267,
            "fmeasure": 0.65136
        },
        "rougeLsum": {
            "precision": 0.66653,
            "recall": 0.65267,
            "fmeasure": 0.65136
        },
        "local_recall": {
            "1": 0.2692307692307692,
            "2": 0.3103448275862069,
            "3": 0.7880434782608695
        },
        "nist": 5.714982587772742,
        "bleu": 40.59404,
        "bleurt": 0.24045,
        "nubia": {
            "semantic_relation": 4.40369,
            "contradiction": 6.70133,
            "irrelevancy": 25.54434,
            "logical_agreement": 67.75432,
            "grammar_ref": 4.68102,
            "grammar_hyp": 4.68482,
            "nubia_score": 0.7661
        },
        "meteor": 0.4032771003095241,
        "bertscore": {
            "precision": 0.92927,
            "recall": 0.92684,
            "f1": 0.92683
        }
    },
    "schema_guided_dialog_challenge_test_bfp05_parent": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.68774,
        "msttr-100_nopunct": 0.70964,
        "total_length": 6249,
        "mean_pred_length": 12.498,
        "std_pred_length": 7.2579608706578185,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 41,
        "distinct-1": 0.1581052968474956,
        "vocab_size-1": 988,
        "unique-1": 558,
        "entropy-1": 7.790140608433183,
        "distinct-2": 0.4781701165420073,
        "vocab_size-2": 2749,
        "unique-2": 1938,
        "entropy-2": 10.56778467011692,
        "cond_entropy-2": 2.5386305891391006,
        "distinct-3": 0.692893884549438,
        "vocab_size-3": 3637,
        "unique-3": 3025,
        "entropy-3": 11.377127063323089,
        "cond_entropy-3": 0.8352443288280825,
        "total_length-nopunct": 5521,
        "mean_pred_length-nopunct": 11.042,
        "std_pred_length-nopunct": 6.7240044616285015,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.1769606955261728,
        "vocab_size-1-nopunct": 977,
        "unique-1-nopunct": 555,
        "entropy-1-nopunct": 7.95531646776007,
        "distinct-2-nopunct": 0.48894642501493724,
        "vocab_size-2-nopunct": 2455,
        "unique-2-nopunct": 1772,
        "entropy-2-nopunct": 10.377117164321136,
        "cond_entropy-2-nopunct": 2.546439757134674,
        "distinct-3-nopunct": 0.6998451669984517,
        "vocab_size-3-nopunct": 3164,
        "unique-3-nopunct": 2659,
        "entropy-3-nopunct": 11.165535029277194,
        "cond_entropy-3-nopunct": 0.8208657493425081,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.59143,
            "recall": 0.56589,
            "fmeasure": 0.56585
        },
        "rouge2": {
            "precision": 0.37401,
            "recall": 0.35363,
            "fmeasure": 0.35476
        },
        "rougeL": {
            "precision": 0.53091,
            "recall": 0.50691,
            "fmeasure": 0.50756
        },
        "rougeLsum": {
            "precision": 0.53091,
            "recall": 0.50691,
            "fmeasure": 0.50756
        },
        "local_recall": {
            "1": 0.5818981311835837
        },
        "nist": 6.185335212536089,
        "bleu": 33.5457,
        "bleurt": -0.05632,
        "nubia": {
            "semantic_relation": 3.62144,
            "contradiction": 6.63634,
            "irrelevancy": 23.16402,
            "logical_agreement": 70.19964,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.61838,
            "nubia_score": 0.64124
        },
        "meteor": 0.32227349703951147,
        "bertscore": {
            "precision": 0.87708,
            "recall": 0.8703,
            "f1": 0.87316
        }
    },
    "web_nlg_en_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 56,
        "msttr-100": 0.575,
        "msttr-100_nopunct": 0.59667,
        "total_length": 685,
        "mean_pred_length": 12.232142857142858,
        "std_pred_length": 5.158180297313369,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.29635036496350364,
        "vocab_size-1": 203,
        "unique-1": 123,
        "entropy-1": 6.168577494206714,
        "distinct-2": 0.5961844197138315,
        "vocab_size-2": 375,
        "unique-2": 271,
        "entropy-2": 8.153156677773108,
        "cond_entropy-2": 1.7503175293846098,
        "distinct-3": 0.7556719022687609,
        "vocab_size-3": 433,
        "unique-3": 353,
        "entropy-3": 8.552448550530555,
        "cond_entropy-3": 0.4296956129788351,
        "total_length-nopunct": 604,
        "mean_pred_length-nopunct": 10.785714285714286,
        "std_pred_length-nopunct": 4.620274751084637,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.3294701986754967,
        "vocab_size-1-nopunct": 199,
        "unique-1-nopunct": 123,
        "entropy-1-nopunct": 6.256513102974237,
        "distinct-2-nopunct": 0.5821167883211679,
        "vocab_size-2-nopunct": 319,
        "unique-2-nopunct": 228,
        "entropy-2-nopunct": 7.902437351481974,
        "cond_entropy-2-nopunct": 1.8069194182743584,
        "distinct-3-nopunct": 0.75,
        "vocab_size-3-nopunct": 369,
        "unique-3-nopunct": 299,
        "entropy-3-nopunct": 8.31399306343426,
        "cond_entropy-3-nopunct": 0.45057193666904405,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.67596,
            "recall": 0.68152,
            "fmeasure": 0.66982
        },
        "rouge2": {
            "precision": 0.38027,
            "recall": 0.39558,
            "fmeasure": 0.38212
        },
        "rougeL": {
            "precision": 0.54075,
            "recall": 0.5495,
            "fmeasure": 0.53745
        },
        "rougeLsum": {
            "precision": 0.54075,
            "recall": 0.5495,
            "fmeasure": 0.53745
        },
        "local_recall": {
            "1": 0.2138728323699422,
            "2": 0.6458333333333334,
            "3": 0.7137681159420289
        },
        "nist": 5.66763413105165,
        "bleu": 34.93164,
        "bleurt": 0.03268,
        "nubia": {
            "semantic_relation": 4.13838,
            "contradiction": 13.5711,
            "irrelevancy": 9.92318,
            "logical_agreement": 76.50572,
            "grammar_ref": 5.25554,
            "grammar_hyp": 5.23865,
            "nubia_score": 0.69183
        },
        "meteor": 0.3516752006107958,
        "bertscore": {
            "precision": 0.90162,
            "recall": 0.90555,
            "f1": 0.90268
        }
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 1510,
        "msttr-100": 0.51586,
        "msttr-100_nopunct": 0.52882,
        "total_length": 35578,
        "mean_pred_length": 23.56158940397351,
        "std_pred_length": 12.575224569385778,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 80,
        "distinct-1": 0.0570296250491877,
        "vocab_size-1": 2029,
        "unique-1": 634,
        "entropy-1": 8.04535078699964,
        "distinct-2": 0.211400727955853,
        "vocab_size-2": 7202,
        "unique-2": 3555,
        "entropy-2": 11.415241840373119,
        "cond_entropy-2": 3.1883179415219334,
        "distinct-3": 0.3787394803120585,
        "vocab_size-3": 12331,
        "unique-3": 7665,
        "entropy-3": 12.657466454566425,
        "cond_entropy-3": 1.3042620442663289,
        "total_length-nopunct": 31380,
        "mean_pred_length-nopunct": 20.781456953642383,
        "std_pred_length-nopunct": 11.30005804341601,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 71,
        "distinct-1-nopunct": 0.06430847673677502,
        "vocab_size-1-nopunct": 2018,
        "unique-1-nopunct": 633,
        "entropy-1-nopunct": 8.344366642374641,
        "distinct-2-nopunct": 0.22524271844660193,
        "vocab_size-2-nopunct": 6728,
        "unique-2-nopunct": 3478,
        "entropy-2-nopunct": 11.327945041856509,
        "cond_entropy-2-nopunct": 3.1367161386149127,
        "distinct-3-nopunct": 0.3954513399153738,
        "vocab_size-3-nopunct": 11215,
        "unique-3-nopunct": 7225,
        "entropy-3-nopunct": 12.516283972304214,
        "cond_entropy-3-nopunct": 1.2453843499871864,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.69476,
            "recall": 0.69313,
            "fmeasure": 0.68721
        },
        "rouge2": {
            "precision": 0.42216,
            "recall": 0.42076,
            "fmeasure": 0.41699
        },
        "rougeL": {
            "precision": 0.54353,
            "recall": 0.54433,
            "fmeasure": 0.53816
        },
        "rougeLsum": {
            "precision": 0.54353,
            "recall": 0.54433,
            "fmeasure": 0.53816
        },
        "local_recall": {
            "1": 0.22929120409906062,
            "2": 0.5467091295116773,
            "3": 0.7986133197633738,
            "4": 0.9607843137254902,
            "5": 0.6190476190476191
        },
        "nist": 8.090891302666778,
        "bleu": 41.55346,
        "bleurt": 0.03427,
        "nubia": {
            "semantic_relation": 4.09244,
            "contradiction": 20.17773,
            "irrelevancy": 9.33544,
            "logical_agreement": 70.48683,
            "grammar_ref": 4.59892,
            "grammar_hyp": 4.65162,
            "nubia_score": 0.68457
        },
        "meteor": 0.35319061870978125,
        "bertscore": {
            "precision": 0.90135,
            "recall": 0.9025,
            "f1": 0.90064
        }
    },
    "web_nlg_en_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 28,
        "msttr-100": 0.53333,
        "msttr-100_nopunct": 0.55,
        "total_length": 303,
        "mean_pred_length": 10.821428571428571,
        "std_pred_length": 3.910184243271221,
        "median_pred_length": 10.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.38943894389438943,
        "vocab_size-1": 118,
        "unique-1": 80,
        "entropy-1": 5.7584417256488685,
        "distinct-2": 0.7345454545454545,
        "vocab_size-2": 202,
        "unique-2": 161,
        "entropy-2": 7.435146765343311,
        "cond_entropy-2": 1.435065168259898,
        "distinct-3": 0.8340080971659919,
        "vocab_size-3": 206,
        "unique-3": 177,
        "entropy-3": 7.563372964662433,
        "cond_entropy-3": 0.17967538638761182,
        "total_length-nopunct": 269,
        "mean_pred_length-nopunct": 9.607142857142858,
        "std_pred_length-nopunct": 3.2550980423492812,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.4275092936802974,
        "vocab_size-1-nopunct": 115,
        "unique-1-nopunct": 79,
        "entropy-1-nopunct": 5.8261373615826475,
        "distinct-2-nopunct": 0.7136929460580913,
        "vocab_size-2-nopunct": 172,
        "unique-2-nopunct": 135,
        "entropy-2-nopunct": 7.183682751815476,
        "cond_entropy-2-nopunct": 1.5381646849397939,
        "distinct-3-nopunct": 0.8215962441314554,
        "vocab_size-3-nopunct": 175,
        "unique-3-nopunct": 149,
        "entropy-3-nopunct": 7.316429883466239,
        "cond_entropy-3-nopunct": 0.18920472292224016,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.77792,
            "recall": 0.76888,
            "fmeasure": 0.76712
        },
        "rouge2": {
            "precision": 0.54523,
            "recall": 0.53209,
            "fmeasure": 0.53397
        },
        "rougeL": {
            "precision": 0.65787,
            "recall": 0.63968,
            "fmeasure": 0.64264
        },
        "rougeLsum": {
            "precision": 0.65787,
            "recall": 0.63968,
            "fmeasure": 0.64264
        },
        "local_recall": {
            "1": 0.14965986394557823,
            "2": 0.6170212765957447,
            "3": 0.8592592592592593,
            "4": 1.0
        },
        "nist": 6.408266561904219,
        "bleu": 52.57871,
        "bleurt": 0.33362,
        "nubia": {
            "semantic_relation": 4.30049,
            "contradiction": 16.766,
            "irrelevancy": 6.71302,
            "logical_agreement": 76.52099,
            "grammar_ref": 4.67502,
            "grammar_hyp": 5.1634,
            "nubia_score": 0.70238
        },
        "meteor": 0.40533431926335617,
        "bertscore": {
            "precision": 0.92802,
            "recall": 0.92607,
            "f1": 0.92571
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_136": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.76667,
        "total_length": 405,
        "mean_pred_length": 17.608695652173914,
        "std_pred_length": 8.666472781506315,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 51,
        "distinct-1": 0.5975308641975309,
        "vocab_size-1": 242,
        "unique-1": 206,
        "entropy-1": 7.15990205851498,
        "distinct-2": 0.9293193717277487,
        "vocab_size-2": 355,
        "unique-2": 338,
        "entropy-2": 8.4061567810064,
        "cond_entropy-2": 1.0643207536787809,
        "distinct-3": 0.9860724233983287,
        "vocab_size-3": 354,
        "unique-3": 351,
        "entropy-3": 8.455779379214915,
        "cond_entropy-3": 0.04388236723826011,
        "total_length-nopunct": 349,
        "mean_pred_length-nopunct": 15.173913043478262,
        "std_pred_length-nopunct": 6.754400651897369,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.6790830945558739,
        "vocab_size-1-nopunct": 237,
        "unique-1-nopunct": 206,
        "entropy-1-nopunct": 7.3199061964876675,
        "distinct-2-nopunct": 0.950920245398773,
        "vocab_size-2-nopunct": 310,
        "unique-2-nopunct": 301,
        "entropy-2-nopunct": 8.222466622149122,
        "cond_entropy-2-nopunct": 0.9582971869542066,
        "distinct-3-nopunct": 0.9933993399339934,
        "vocab_size-3-nopunct": 301,
        "unique-3-nopunct": 300,
        "entropy-3-nopunct": 8.22748128544601,
        "cond_entropy-3-nopunct": 0.014598872002819733,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78488,
            "recall": 0.72516,
            "fmeasure": 0.73972
        },
        "rouge2": {
            "precision": 0.55294,
            "recall": 0.51962,
            "fmeasure": 0.52468
        },
        "rougeL": {
            "precision": 0.67429,
            "recall": 0.63772,
            "fmeasure": 0.64272
        },
        "rougeLsum": {
            "precision": 0.67429,
            "recall": 0.63772,
            "fmeasure": 0.64272
        },
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.39759036144578314,
            "3": 0.7325102880658436
        },
        "nist": 6.5500736391591206,
        "bleu": 48.76913,
        "bleurt": 0.22689,
        "nubia": {
            "semantic_relation": 4.20966,
            "contradiction": 6.87588,
            "irrelevancy": 33.91937,
            "logical_agreement": 59.20474,
            "grammar_ref": 4.55066,
            "grammar_hyp": 4.4229,
            "nubia_score": 0.71618
        },
        "meteor": 0.38942556931983807,
        "bertscore": {
            "precision": 0.93113,
            "recall": 0.92112,
            "f1": 0.92403
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_165": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 19,
        "msttr-100": 0.67667,
        "msttr-100_nopunct": 0.72,
        "total_length": 351,
        "mean_pred_length": 18.473684210526315,
        "std_pred_length": 7.147825735311562,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 33,
        "distinct-1": 0.5498575498575499,
        "vocab_size-1": 193,
        "unique-1": 149,
        "entropy-1": 6.915126969264644,
        "distinct-2": 0.8825301204819277,
        "vocab_size-2": 293,
        "unique-2": 263,
        "entropy-2": 8.112135176783223,
        "cond_entropy-2": 1.037812939346611,
        "distinct-3": 0.9584664536741214,
        "vocab_size-3": 300,
        "unique-3": 287,
        "entropy-3": 8.206951754280825,
        "cond_entropy-3": 0.0740031776010842,
        "total_length-nopunct": 307,
        "mean_pred_length-nopunct": 16.157894736842106,
        "std_pred_length-nopunct": 5.94061097243051,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.6123778501628665,
        "vocab_size-1-nopunct": 188,
        "unique-1-nopunct": 148,
        "entropy-1-nopunct": 7.003071256566035,
        "distinct-2-nopunct": 0.8958333333333334,
        "vocab_size-2-nopunct": 258,
        "unique-2-nopunct": 235,
        "entropy-2-nopunct": 7.934597093418613,
        "cond_entropy-2-nopunct": 0.9708886343753454,
        "distinct-3-nopunct": 0.9553903345724907,
        "vocab_size-3-nopunct": 257,
        "unique-3-nopunct": 245,
        "entropy-3-nopunct": 7.982243031701577,
        "cond_entropy-3-nopunct": 0.05248350427183948,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71921,
            "recall": 0.73489,
            "fmeasure": 0.71916
        },
        "rouge2": {
            "precision": 0.43633,
            "recall": 0.45501,
            "fmeasure": 0.44021
        },
        "rougeL": {
            "precision": 0.6256,
            "recall": 0.64267,
            "fmeasure": 0.62743
        },
        "rougeLsum": {
            "precision": 0.6256,
            "recall": 0.64267,
            "fmeasure": 0.62743
        },
        "local_recall": {
            "1": 0.19672131147540983,
            "2": 0.423728813559322,
            "3": 0.7632850241545893
        },
        "nist": 5.854818323753279,
        "bleu": 40.13971,
        "bleurt": 0.20124,
        "nubia": {
            "semantic_relation": 4.04793,
            "contradiction": 5.8588,
            "irrelevancy": 37.25831,
            "logical_agreement": 56.88288,
            "grammar_ref": 4.52561,
            "grammar_hyp": 4.30293,
            "nubia_score": 0.71702
        },
        "meteor": 0.37108372377043997,
        "bertscore": {
            "precision": 0.9128,
            "recall": 0.91625,
            "f1": 0.91279
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_138": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 19,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.75,
        "total_length": 292,
        "mean_pred_length": 15.368421052631579,
        "std_pred_length": 6.1832586053479455,
        "median_pred_length": 13.0,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.565068493150685,
        "vocab_size-1": 165,
        "unique-1": 127,
        "entropy-1": 6.7612414232247575,
        "distinct-2": 0.9157509157509157,
        "vocab_size-2": 250,
        "unique-2": 232,
        "entropy-2": 7.905506534770497,
        "cond_entropy-2": 0.9480470046667612,
        "distinct-3": 0.984251968503937,
        "vocab_size-3": 250,
        "unique-3": 246,
        "entropy-3": 7.957188623780003,
        "cond_entropy-3": 0.04696899457908607,
        "total_length-nopunct": 260,
        "mean_pred_length-nopunct": 13.68421052631579,
        "std_pred_length-nopunct": 5.938745495552223,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6153846153846154,
        "vocab_size-1-nopunct": 160,
        "unique-1-nopunct": 126,
        "entropy-1-nopunct": 6.836076840505704,
        "distinct-2-nopunct": 0.9128630705394191,
        "vocab_size-2-nopunct": 220,
        "unique-2-nopunct": 203,
        "entropy-2-nopunct": 7.720505402717127,
        "cond_entropy-2-nopunct": 0.9407511522249659,
        "distinct-3-nopunct": 0.9819819819819819,
        "vocab_size-3-nopunct": 218,
        "unique-3-nopunct": 214,
        "entropy-3-nopunct": 7.758379830314057,
        "cond_entropy-3-nopunct": 0.04983521469942462,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75677,
            "recall": 0.62918,
            "fmeasure": 0.6729
        },
        "rouge2": {
            "precision": 0.52191,
            "recall": 0.44684,
            "fmeasure": 0.47109
        },
        "rougeL": {
            "precision": 0.66719,
            "recall": 0.56432,
            "fmeasure": 0.59868
        },
        "rougeLsum": {
            "precision": 0.66719,
            "recall": 0.56432,
            "fmeasure": 0.59868
        },
        "local_recall": {
            "1": 0.15584415584415584,
            "2": 0.29411764705882354,
            "3": 0.6551724137931034
        },
        "nist": 4.691745115961451,
        "bleu": 37.92634,
        "bleurt": 0.20922,
        "nubia": {
            "semantic_relation": 4.17728,
            "contradiction": 6.22174,
            "irrelevancy": 31.56589,
            "logical_agreement": 62.21237,
            "grammar_ref": 4.44575,
            "grammar_hyp": 4.81463,
            "nubia_score": 0.67896
        },
        "meteor": 0.36181803762073833,
        "bertscore": {
            "precision": 0.92535,
            "recall": 0.89753,
            "f1": 0.90842
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_231": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 16,
        "msttr-100": 0.685,
        "msttr-100_nopunct": 0.75,
        "total_length": 235,
        "mean_pred_length": 14.6875,
        "std_pred_length": 4.3691925741491415,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.5914893617021276,
        "vocab_size-1": 139,
        "unique-1": 112,
        "entropy-1": 6.466770538785469,
        "distinct-2": 0.9360730593607306,
        "vocab_size-2": 205,
        "unique-2": 194,
        "entropy-2": 7.634353783335596,
        "cond_entropy-2": 0.9783409729723597,
        "distinct-3": 0.9655172413793104,
        "vocab_size-3": 196,
        "unique-3": 189,
        "entropy-3": 7.596370399943803,
        "cond_entropy-3": -0.026914750779724116,
        "total_length-nopunct": 201,
        "mean_pred_length-nopunct": 12.5625,
        "std_pred_length-nopunct": 3.936507811499934,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6716417910447762,
        "vocab_size-1-nopunct": 135,
        "unique-1-nopunct": 112,
        "entropy-1-nopunct": 6.606338074664598,
        "distinct-2-nopunct": 0.9351351351351351,
        "vocab_size-2-nopunct": 173,
        "unique-2-nopunct": 164,
        "entropy-2-nopunct": 7.386760446991094,
        "cond_entropy-2-nopunct": 0.837425036449687,
        "distinct-3-nopunct": 0.9704142011834319,
        "vocab_size-3-nopunct": 164,
        "unique-3-nopunct": 159,
        "entropy-3-nopunct": 7.34170783864904,
        "cond_entropy-3-nopunct": -0.03136067806747988,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8025,
            "recall": 0.78472,
            "fmeasure": 0.78807
        },
        "rouge2": {
            "precision": 0.56261,
            "recall": 0.55063,
            "fmeasure": 0.55249
        },
        "rougeL": {
            "precision": 0.71923,
            "recall": 0.70084,
            "fmeasure": 0.70567
        },
        "rougeLsum": {
            "precision": 0.71923,
            "recall": 0.70084,
            "fmeasure": 0.70567
        },
        "local_recall": {
            "1": 0.21951219512195122,
            "2": 0.43478260869565216,
            "3": 0.7804878048780488
        },
        "nist": 5.996036913859436,
        "bleu": 44.69672,
        "bleurt": 0.43408,
        "nubia": {
            "semantic_relation": 4.60807,
            "contradiction": 0.93116,
            "irrelevancy": 25.91937,
            "logical_agreement": 73.14947,
            "grammar_ref": 4.58203,
            "grammar_hyp": 4.61581,
            "nubia_score": 0.83455
        },
        "meteor": 0.41089327858090413,
        "bertscore": {
            "precision": 0.93399,
            "recall": 0.9405,
            "f1": 0.93578
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_198": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.70333,
        "msttr-100_nopunct": 0.77,
        "total_length": 344,
        "mean_pred_length": 19.11111111111111,
        "std_pred_length": 7.80945928480248,
        "median_pred_length": 18.5,
        "min_pred_length": 9,
        "max_pred_length": 37,
        "distinct-1": 0.5988372093023255,
        "vocab_size-1": 206,
        "unique-1": 172,
        "entropy-1": 7.054736737149549,
        "distinct-2": 0.9601226993865031,
        "vocab_size-2": 313,
        "unique-2": 302,
        "entropy-2": 8.264342341334407,
        "cond_entropy-2": 1.055092887282932,
        "distinct-3": 0.9902597402597403,
        "vocab_size-3": 305,
        "unique-3": 302,
        "entropy-3": 8.247306021214339,
        "cond_entropy-3": -0.012104681703945963,
        "total_length-nopunct": 297,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 6.759766596891082,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.67003367003367,
        "vocab_size-1-nopunct": 199,
        "unique-1-nopunct": 169,
        "entropy-1-nopunct": 7.172138288938024,
        "distinct-2-nopunct": 0.956989247311828,
        "vocab_size-2-nopunct": 267,
        "unique-2-nopunct": 257,
        "entropy-2-nopunct": 8.032688426509026,
        "cond_entropy-2-nopunct": 0.9277876105944224,
        "distinct-3-nopunct": 0.9885057471264368,
        "vocab_size-3-nopunct": 258,
        "unique-3-nopunct": 255,
        "entropy-3-nopunct": 8.004917490822724,
        "cond_entropy-3-nopunct": -0.02146521945728407,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65004,
            "recall": 0.66987,
            "fmeasure": 0.64542
        },
        "rouge2": {
            "precision": 0.38725,
            "recall": 0.39216,
            "fmeasure": 0.37972
        },
        "rougeL": {
            "precision": 0.55309,
            "recall": 0.57269,
            "fmeasure": 0.5509
        },
        "rougeLsum": {
            "precision": 0.55309,
            "recall": 0.57269,
            "fmeasure": 0.5509
        },
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.5070422535211268,
            "3": 0.6881720430107527
        },
        "nist": 5.102160474034814,
        "bleu": 29.49432,
        "bleurt": 0.06559,
        "nubia": {
            "semantic_relation": 3.82138,
            "contradiction": 15.92716,
            "irrelevancy": 35.38499,
            "logical_agreement": 48.68785,
            "grammar_ref": 4.71491,
            "grammar_hyp": 4.43381,
            "nubia_score": 0.62246
        },
        "meteor": 0.3442339519221884,
        "bertscore": {
            "precision": 0.89528,
            "recall": 0.90509,
            "f1": 0.89851
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_232": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.77,
        "total_length": 192,
        "mean_pred_length": 21.333333333333332,
        "std_pred_length": 8.366600265340756,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 34,
        "distinct-1": 0.65625,
        "vocab_size-1": 126,
        "unique-1": 107,
        "entropy-1": 6.437085104696654,
        "distinct-2": 0.9344262295081968,
        "vocab_size-2": 171,
        "unique-2": 163,
        "entropy-2": 7.368052024029097,
        "cond_entropy-2": 0.8315219551315903,
        "distinct-3": 0.9712643678160919,
        "vocab_size-3": 169,
        "unique-3": 166,
        "entropy-3": 7.376795363639933,
        "cond_entropy-3": 0.016380295520587812,
        "total_length-nopunct": 171,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 7.483314773547883,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.7076023391812866,
        "vocab_size-1-nopunct": 121,
        "unique-1-nopunct": 106,
        "entropy-1-nopunct": 6.434158651907397,
        "distinct-2-nopunct": 0.9382716049382716,
        "vocab_size-2-nopunct": 152,
        "unique-2-nopunct": 146,
        "entropy-2-nopunct": 7.197754015176867,
        "cond_entropy-2-nopunct": 0.8182450223238446,
        "distinct-3-nopunct": 0.9738562091503268,
        "vocab_size-3-nopunct": 149,
        "unique-3-nopunct": 147,
        "entropy-3-nopunct": 7.19523245050749,
        "cond_entropy-3-nopunct": 0.005837022842843655,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73007,
            "recall": 0.7802,
            "fmeasure": 0.75015
        },
        "rouge2": {
            "precision": 0.45673,
            "recall": 0.49566,
            "fmeasure": 0.47248
        },
        "rougeL": {
            "precision": 0.57838,
            "recall": 0.63151,
            "fmeasure": 0.59955
        },
        "rougeLsum": {
            "precision": 0.57838,
            "recall": 0.63151,
            "fmeasure": 0.59955
        },
        "local_recall": {
            "1": 0.36363636363636365,
            "2": 0.25,
            "3": 0.7913043478260869
        },
        "nist": 4.990529107121295,
        "bleu": 30.89708,
        "bleurt": 0.26907,
        "nubia": {
            "semantic_relation": 4.40471,
            "contradiction": 5.11628,
            "irrelevancy": 28.82879,
            "logical_agreement": 66.05493,
            "grammar_ref": 4.7133,
            "grammar_hyp": 4.38539,
            "nubia_score": 0.81406
        },
        "meteor": 0.3709638621317427,
        "bertscore": {
            "precision": 0.91737,
            "recall": 0.92855,
            "f1": 0.92259
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_140": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 42,
        "msttr-100": 0.72667,
        "msttr-100_nopunct": 0.77667,
        "total_length": 684,
        "mean_pred_length": 16.285714285714285,
        "std_pred_length": 4.782337116862395,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 30,
        "distinct-1": 0.543859649122807,
        "vocab_size-1": 372,
        "unique-1": 289,
        "entropy-1": 7.604859477378683,
        "distinct-2": 0.881619937694704,
        "vocab_size-2": 566,
        "unique-2": 509,
        "entropy-2": 9.038146922605685,
        "cond_entropy-2": 1.1991260368448224,
        "distinct-3": 0.9633333333333334,
        "vocab_size-3": 578,
        "unique-3": 557,
        "entropy-3": 9.154227211325626,
        "cond_entropy-3": 0.11959340156934532,
        "total_length-nopunct": 601,
        "mean_pred_length-nopunct": 14.30952380952381,
        "std_pred_length-nopunct": 4.2228860320767945,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6089850249584027,
        "vocab_size-1-nopunct": 366,
        "unique-1-nopunct": 289,
        "entropy-1-nopunct": 7.822701970608208,
        "distinct-2-nopunct": 0.8872987477638641,
        "vocab_size-2-nopunct": 496,
        "unique-2-nopunct": 451,
        "entropy-2-nopunct": 8.843479930951473,
        "cond_entropy-2-nopunct": 1.091400691682412,
        "distinct-3-nopunct": 0.9748549323017408,
        "vocab_size-3-nopunct": 504,
        "unique-3-nopunct": 491,
        "entropy-3-nopunct": 8.963730334918502,
        "cond_entropy-3-nopunct": 0.13052210272655948,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76812,
            "recall": 0.76239,
            "fmeasure": 0.7592
        },
        "rouge2": {
            "precision": 0.54701,
            "recall": 0.54561,
            "fmeasure": 0.54036
        },
        "rougeL": {
            "precision": 0.67832,
            "recall": 0.67379,
            "fmeasure": 0.66955
        },
        "rougeLsum": {
            "precision": 0.67832,
            "recall": 0.67379,
            "fmeasure": 0.66955
        },
        "local_recall": {
            "1": 0.23275862068965517,
            "2": 0.49056603773584906,
            "3": 0.7820224719101123
        },
        "nist": 6.963344147319436,
        "bleu": 46.48009,
        "bleurt": 0.25832,
        "nubia": {
            "semantic_relation": 4.32029,
            "contradiction": 3.87832,
            "irrelevancy": 31.02935,
            "logical_agreement": 65.09233,
            "grammar_ref": 4.66791,
            "grammar_hyp": 4.60036,
            "nubia_score": 0.7656
        },
        "meteor": 0.4071467631874077,
        "bertscore": {
            "precision": 0.93015,
            "recall": 0.92787,
            "f1": 0.92664
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_234": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.72,
        "total_length": 180,
        "mean_pred_length": 12.857142857142858,
        "std_pred_length": 4.307089551908953,
        "median_pred_length": 13.5,
        "min_pred_length": 5,
        "max_pred_length": 23,
        "distinct-1": 0.6222222222222222,
        "vocab_size-1": 112,
        "unique-1": 93,
        "entropy-1": 6.212353341680542,
        "distinct-2": 0.9337349397590361,
        "vocab_size-2": 155,
        "unique-2": 145,
        "entropy-2": 7.2379617957917075,
        "cond_entropy-2": 0.8124158496309387,
        "distinct-3": 0.9736842105263158,
        "vocab_size-3": 148,
        "unique-3": 144,
        "entropy-3": 7.1952959344961975,
        "cond_entropy-3": -0.030040289599632126,
        "total_length-nopunct": 163,
        "mean_pred_length-nopunct": 11.642857142857142,
        "std_pred_length-nopunct": 4.302941566236867,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6748466257668712,
        "vocab_size-1-nopunct": 110,
        "unique-1-nopunct": 93,
        "entropy-1-nopunct": 6.291966808060096,
        "distinct-2-nopunct": 0.9261744966442953,
        "vocab_size-2-nopunct": 138,
        "unique-2-nopunct": 128,
        "entropy-2-nopunct": 7.066451154675838,
        "cond_entropy-2-nopunct": 0.8497172079961025,
        "distinct-3-nopunct": 0.9703703703703703,
        "vocab_size-3-nopunct": 131,
        "unique-3-nopunct": 127,
        "entropy-3-nopunct": 7.017556337791596,
        "cond_entropy-3-nopunct": -0.04046486783974953,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75576,
            "recall": 0.70716,
            "fmeasure": 0.71135
        },
        "rouge2": {
            "precision": 0.52752,
            "recall": 0.52051,
            "fmeasure": 0.50609
        },
        "rougeL": {
            "precision": 0.68415,
            "recall": 0.66445,
            "fmeasure": 0.6506
        },
        "rougeLsum": {
            "precision": 0.68415,
            "recall": 0.66445,
            "fmeasure": 0.6506
        },
        "local_recall": {
            "1": 0.13513513513513514,
            "2": 0.36666666666666664,
            "3": 0.734375
        },
        "nist": 5.193544410356247,
        "bleu": 41.83105,
        "bleurt": 0.27864,
        "nubia": {
            "semantic_relation": 4.20248,
            "contradiction": 9.81513,
            "irrelevancy": 17.52634,
            "logical_agreement": 72.65853,
            "grammar_ref": 4.23107,
            "grammar_hyp": 4.30195,
            "nubia_score": 0.75421
        },
        "meteor": 0.40434315084921857,
        "bertscore": {
            "precision": 0.93054,
            "recall": 0.92091,
            "f1": 0.92444
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_141": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 87,
        "mean_pred_length": 17.4,
        "std_pred_length": 6.529931086925803,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 30,
        "distinct-1": 0.7816091954022989,
        "vocab_size-1": 68,
        "unique-1": 62,
        "entropy-1": 5.835714513971593,
        "distinct-2": 1.0,
        "vocab_size-2": 82,
        "unique-2": 82,
        "entropy-2": 6.357552004618087,
        "cond_entropy-2": 0.41728266668244884,
        "distinct-3": 1.0,
        "vocab_size-3": 77,
        "unique-3": 77,
        "entropy-3": 6.266786540694905,
        "cond_entropy-3": -0.09076546392318265,
        "total_length-nopunct": 78,
        "mean_pred_length-nopunct": 15.6,
        "std_pred_length-nopunct": 6.086049621881176,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 5.8595140015690035,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 73,
        "unique-2-nopunct": 73,
        "entropy-2-nopunct": 6.189824558880028,
        "cond_entropy-2-nopunct": 0.35948098315302346,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 68,
        "unique-3-nopunct": 68,
        "entropy-3-nopunct": 6.087462841250345,
        "cond_entropy-3-nopunct": -0.10236171762967769,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77152,
            "recall": 0.70003,
            "fmeasure": 0.73218
        },
        "rouge2": {
            "precision": 0.47385,
            "recall": 0.43636,
            "fmeasure": 0.45319
        },
        "rougeL": {
            "precision": 0.60237,
            "recall": 0.55018,
            "fmeasure": 0.57377
        },
        "rougeLsum": {
            "precision": 0.60237,
            "recall": 0.55018,
            "fmeasure": 0.57377
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.7638888888888888
        },
        "nist": 4.2162497298985215,
        "bleu": 30.88269,
        "bleurt": 0.2644,
        "nubia": {
            "semantic_relation": 4.33874,
            "contradiction": 0.29881,
            "irrelevancy": 21.91609,
            "logical_agreement": 77.7851,
            "grammar_ref": 4.6156,
            "grammar_hyp": 4.68963,
            "nubia_score": 0.79838
        },
        "meteor": 0.36498014963879954,
        "bertscore": {
            "precision": 0.91771,
            "recall": 0.90467,
            "f1": 0.91104
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_235": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.68,
        "msttr-100_nopunct": NaN,
        "total_length": 100,
        "mean_pred_length": 14.285714285714286,
        "std_pred_length": 5.283783431116266,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.68,
        "vocab_size-1": 68,
        "unique-1": 56,
        "entropy-1": 5.747181220920666,
        "distinct-2": 0.9354838709677419,
        "vocab_size-2": 87,
        "unique-2": 82,
        "entropy-2": 6.402009483127782,
        "cond_entropy-2": 0.5110136420735224,
        "distinct-3": 0.9651162790697675,
        "vocab_size-3": 83,
        "unique-3": 80,
        "entropy-3": 6.3564973128416336,
        "cond_entropy-3": -0.05760466684589313,
        "total_length-nopunct": 90,
        "mean_pred_length-nopunct": 12.857142857142858,
        "std_pred_length-nopunct": 4.997958767010258,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7333333333333333,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.766729486009221,
        "distinct-2-nopunct": 0.9397590361445783,
        "vocab_size-2-nopunct": 78,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.245462473489539,
        "cond_entropy-2-nopunct": 0.5157916052181725,
        "distinct-3-nopunct": 0.9736842105263158,
        "vocab_size-3-nopunct": 74,
        "unique-3-nopunct": 72,
        "entropy-3-nopunct": 6.195295934496223,
        "cond_entropy-3-nopunct": -0.06454760866434618,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75419,
            "recall": 0.71992,
            "fmeasure": 0.73506
        },
        "rouge2": {
            "precision": 0.56828,
            "recall": 0.51973,
            "fmeasure": 0.53981
        },
        "rougeL": {
            "precision": 0.67522,
            "recall": 0.62141,
            "fmeasure": 0.64301
        },
        "rougeLsum": {
            "precision": 0.67522,
            "recall": 0.62141,
            "fmeasure": 0.64301
        },
        "local_recall": {
            "1": 0.17142857142857143,
            "2": 0.35,
            "3": 0.7846153846153846
        },
        "nist": 5.104196168523067,
        "bleu": 49.34317,
        "bleurt": 0.0627,
        "nubia": {
            "semantic_relation": 4.17161,
            "contradiction": 20.5138,
            "irrelevancy": 29.17051,
            "logical_agreement": 50.31569,
            "grammar_ref": 5.24762,
            "grammar_hyp": 5.34645,
            "nubia_score": 0.64675
        },
        "meteor": 0.3748840948255269,
        "bertscore": {
            "precision": 0.9102,
            "recall": 0.91169,
            "f1": 0.9099
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_238": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.74,
        "total_length": 120,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 4.618802153517006,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.6583333333333333,
        "vocab_size-1": 79,
        "unique-1": 57,
        "entropy-1": 6.0116974455871794,
        "distinct-2": 0.8828828828828829,
        "vocab_size-2": 98,
        "unique-2": 86,
        "entropy-2": 6.5533808438081085,
        "cond_entropy-2": 0.35724568053814265,
        "distinct-3": 0.9117647058823529,
        "vocab_size-3": 93,
        "unique-3": 84,
        "entropy-3": 6.495954753736206,
        "cond_entropy-3": -0.03615829396524297,
        "total_length-nopunct": 105,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 4.496912521077347,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7333333333333333,
        "vocab_size-1-nopunct": 77,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 6.110587632092266,
        "distinct-2-nopunct": 0.875,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 73,
        "entropy-2-nopunct": 6.327099089240289,
        "cond_entropy-2-nopunct": 0.2626877172538952,
        "distinct-3-nopunct": 0.9080459770114943,
        "vocab_size-3-nopunct": 79,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 6.2590354498717105,
        "cond_entropy-3-nopunct": -0.05288236691652589,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.91129,
            "recall": 0.80494,
            "fmeasure": 0.8465
        },
        "rouge2": {
            "precision": 0.69541,
            "recall": 0.62644,
            "fmeasure": 0.65251
        },
        "rougeL": {
            "precision": 0.82775,
            "recall": 0.74245,
            "fmeasure": 0.77566
        },
        "rougeLsum": {
            "precision": 0.82775,
            "recall": 0.74245,
            "fmeasure": 0.77566
        },
        "local_recall": {
            "1": 0.35135135135135137,
            "2": 0.65,
            "3": 0.8588235294117647
        },
        "nist": 6.055180253733431,
        "bleu": 59.31249,
        "bleurt": 0.38403,
        "nubia": {
            "semantic_relation": 4.26265,
            "contradiction": 0.5076,
            "irrelevancy": 20.04769,
            "logical_agreement": 79.44471,
            "grammar_ref": 4.78166,
            "grammar_hyp": 5.1396,
            "nubia_score": 0.73477
        },
        "meteor": 0.42819120450676207,
        "bertscore": {
            "precision": 0.97637,
            "recall": 0.94493,
            "f1": 0.96001
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_143": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.71,
        "total_length": 166,
        "mean_pred_length": 16.6,
        "std_pred_length": 5.782732917920384,
        "median_pred_length": 16.5,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.6144578313253012,
        "vocab_size-1": 102,
        "unique-1": 76,
        "entropy-1": 6.208729482573492,
        "distinct-2": 0.8461538461538461,
        "vocab_size-2": 132,
        "unique-2": 115,
        "entropy-2": 6.918983888998607,
        "cond_entropy-2": 0.5720737560331722,
        "distinct-3": 0.910958904109589,
        "vocab_size-3": 133,
        "unique-3": 121,
        "entropy-3": 7.006571904755613,
        "cond_entropy-3": 0.08528790136411572,
        "total_length-nopunct": 149,
        "mean_pred_length-nopunct": 14.9,
        "std_pred_length-nopunct": 5.281098370604357,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6711409395973155,
        "vocab_size-1-nopunct": 100,
        "unique-1-nopunct": 76,
        "entropy-1-nopunct": 6.274627003058737,
        "distinct-2-nopunct": 0.841726618705036,
        "vocab_size-2-nopunct": 117,
        "unique-2-nopunct": 102,
        "entropy-2-nopunct": 6.736485968703879,
        "cond_entropy-2-nopunct": 0.4842011611210318,
        "distinct-3-nopunct": 0.9069767441860465,
        "vocab_size-3-nopunct": 117,
        "unique-3-nopunct": 106,
        "entropy-3-nopunct": 6.819328902693288,
        "cond_entropy-3-nopunct": 0.08791755444489685,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.59828,
            "recall": 0.63635,
            "fmeasure": 0.59467
        },
        "rouge2": {
            "precision": 0.39346,
            "recall": 0.40567,
            "fmeasure": 0.37901
        },
        "rougeL": {
            "precision": 0.49954,
            "recall": 0.52596,
            "fmeasure": 0.49671
        },
        "rougeLsum": {
            "precision": 0.49954,
            "recall": 0.52596,
            "fmeasure": 0.49671
        },
        "local_recall": {
            "1": 0.1864406779661017,
            "2": 0.23076923076923078,
            "3": 0.6470588235294118
        },
        "nist": 4.198571071733466,
        "bleu": 26.48706,
        "bleurt": 0.11147,
        "nubia": {
            "semantic_relation": 3.67008,
            "contradiction": 18.94265,
            "irrelevancy": 55.71861,
            "logical_agreement": 25.33874,
            "grammar_ref": 4.73444,
            "grammar_hyp": 4.56662,
            "nubia_score": 0.54952
        },
        "meteor": 0.30601817161227307,
        "bertscore": {
            "precision": 0.89989,
            "recall": 0.90609,
            "f1": 0.89926
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_200": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 25,
        "msttr-100": 0.7175,
        "msttr-100_nopunct": 0.75,
        "total_length": 444,
        "mean_pred_length": 17.76,
        "std_pred_length": 9.030083056096439,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 45,
        "distinct-1": 0.6081081081081081,
        "vocab_size-1": 270,
        "unique-1": 227,
        "entropy-1": 7.340461284073956,
        "distinct-2": 0.9021479713603818,
        "vocab_size-2": 378,
        "unique-2": 352,
        "entropy-2": 8.471811289337955,
        "cond_entropy-2": 0.9410217470600616,
        "distinct-3": 0.9695431472081218,
        "vocab_size-3": 382,
        "unique-3": 371,
        "entropy-3": 8.559222155745351,
        "cond_entropy-3": 0.1025755329277206,
        "total_length-nopunct": 392,
        "mean_pred_length-nopunct": 15.68,
        "std_pred_length-nopunct": 8.577738629732197,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.6760204081632653,
        "vocab_size-1-nopunct": 265,
        "unique-1-nopunct": 227,
        "entropy-1-nopunct": 7.491913626631064,
        "distinct-2-nopunct": 0.9073569482288828,
        "vocab_size-2-nopunct": 333,
        "unique-2-nopunct": 313,
        "entropy-2-nopunct": 8.286982089395584,
        "cond_entropy-2-nopunct": 0.8617849285313282,
        "distinct-3-nopunct": 0.9707602339181286,
        "vocab_size-3-nopunct": 332,
        "unique-3-nopunct": 323,
        "entropy-3-nopunct": 8.35716570932401,
        "cond_entropy-3-nopunct": 0.08719050322131235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.84476,
            "recall": 0.83577,
            "fmeasure": 0.8331
        },
        "rouge2": {
            "precision": 0.67113,
            "recall": 0.67682,
            "fmeasure": 0.66969
        },
        "rougeL": {
            "precision": 0.76832,
            "recall": 0.75757,
            "fmeasure": 0.75689
        },
        "rougeLsum": {
            "precision": 0.76832,
            "recall": 0.75757,
            "fmeasure": 0.75689
        },
        "local_recall": {
            "1": 0.23214285714285715,
            "2": 0.3488372093023256,
            "3": 0.8928571428571429
        },
        "nist": 7.12427201419565,
        "bleu": 62.4698,
        "bleurt": 0.47345,
        "nubia": {
            "semantic_relation": 4.45568,
            "contradiction": 7.2251,
            "irrelevancy": 21.62825,
            "logical_agreement": 71.14665,
            "grammar_ref": 4.85173,
            "grammar_hyp": 4.96221,
            "nubia_score": 0.79063
        },
        "meteor": 0.47550087277445885,
        "bertscore": {
            "precision": 0.95454,
            "recall": 0.95271,
            "f1": 0.95291
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_240": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.745,
        "msttr-100_nopunct": 0.798,
        "total_length": 601,
        "mean_pred_length": 19.387096774193548,
        "std_pred_length": 9.188623468654011,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 52,
        "distinct-1": 0.5574043261231281,
        "vocab_size-1": 335,
        "unique-1": 270,
        "entropy-1": 7.549060195361771,
        "distinct-2": 0.9070175438596492,
        "vocab_size-2": 517,
        "unique-2": 479,
        "entropy-2": 8.935021244990502,
        "cond_entropy-2": 1.208008251249479,
        "distinct-3": 0.9591836734693877,
        "vocab_size-3": 517,
        "unique-3": 496,
        "entropy-3": 8.991108276292051,
        "cond_entropy-3": 0.06872840938311119,
        "total_length-nopunct": 520,
        "mean_pred_length-nopunct": 16.774193548387096,
        "std_pred_length-nopunct": 7.860516593954199,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.6346153846153846,
        "vocab_size-1-nopunct": 330,
        "unique-1-nopunct": 270,
        "entropy-1-nopunct": 7.778375881830017,
        "distinct-2-nopunct": 0.9141104294478528,
        "vocab_size-2-nopunct": 447,
        "unique-2-nopunct": 418,
        "entropy-2-nopunct": 8.725562970881022,
        "cond_entropy-2-nopunct": 1.0125833822339823,
        "distinct-3-nopunct": 0.9606986899563319,
        "vocab_size-3-nopunct": 440,
        "unique-3-nopunct": 422,
        "entropy-3-nopunct": 8.760601168009627,
        "cond_entropy-3-nopunct": 0.04475862989321943,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77854,
            "recall": 0.81794,
            "fmeasure": 0.78549
        },
        "rouge2": {
            "precision": 0.58185,
            "recall": 0.60662,
            "fmeasure": 0.58515
        },
        "rougeL": {
            "precision": 0.67047,
            "recall": 0.71345,
            "fmeasure": 0.67836
        },
        "rougeLsum": {
            "precision": 0.67047,
            "recall": 0.71345,
            "fmeasure": 0.67836
        },
        "local_recall": {
            "1": 0.23148148148148148,
            "2": 0.3625,
            "3": 0.8783783783783784
        },
        "nist": 6.908218523354672,
        "bleu": 52.36985,
        "bleurt": 0.40453,
        "nubia": {
            "semantic_relation": 4.3724,
            "contradiction": 4.61288,
            "irrelevancy": 21.7468,
            "logical_agreement": 73.64032,
            "grammar_ref": 4.66938,
            "grammar_hyp": 4.57291,
            "nubia_score": 0.76288
        },
        "meteor": 0.43966338391324733,
        "bertscore": {
            "precision": 0.93861,
            "recall": 0.94408,
            "f1": 0.93973
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_243": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 3.0,
        "median_pred_length": 18.0,
        "min_pred_length": 15,
        "max_pred_length": 21,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 28,
        "unique-1": 22,
        "entropy-1": 4.66992500144231,
        "distinct-2": 0.9705882352941176,
        "vocab_size-2": 33,
        "unique-2": 32,
        "entropy-2": 5.028639311838573,
        "cond_entropy-2": 0.3293025456903801,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.024962841250339412,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7931034482758621,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.375222374437917,
        "distinct-2-nopunct": 0.9629629629629629,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.6808134280893965,
        "cond_entropy-2-nopunct": 0.3043139144433039,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.031031312388743945,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72151,
            "recall": 0.92857,
            "fmeasure": 0.79524
        },
        "rouge2": {
            "precision": 0.52451,
            "recall": 0.62623,
            "fmeasure": 0.5612
        },
        "rougeL": {
            "precision": 0.58761,
            "recall": 0.70503,
            "fmeasure": 0.63122
        },
        "rougeLsum": {
            "precision": 0.58761,
            "recall": 0.70503,
            "fmeasure": 0.63122
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8947368421052632
        },
        "nist": 2.9771919463631344,
        "bleu": 37.96005,
        "bleurt": 0.10745,
        "nubia": {
            "semantic_relation": 4.35709,
            "contradiction": 0.27594,
            "irrelevancy": 47.78862,
            "logical_agreement": 51.93544,
            "grammar_ref": 5.56806,
            "grammar_hyp": 5.39174,
            "nubia_score": 0.71851
        },
        "meteor": 0.45100825220207563,
        "bertscore": {
            "precision": 0.91015,
            "recall": 0.9495,
            "f1": 0.92934
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_203": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 97,
        "mean_pred_length": 19.4,
        "std_pred_length": 7.08801805866774,
        "median_pred_length": 17.0,
        "min_pred_length": 13,
        "max_pred_length": 33,
        "distinct-1": 0.7319587628865979,
        "vocab_size-1": 71,
        "unique-1": 59,
        "entropy-1": 5.908226409921148,
        "distinct-2": 0.9891304347826086,
        "vocab_size-2": 91,
        "unique-2": 90,
        "entropy-2": 6.501822825622244,
        "cond_entropy-2": 0.5049963253412336,
        "distinct-3": 1.0,
        "vocab_size-3": 87,
        "unique-3": 87,
        "entropy-3": 6.442943495848723,
        "cond_entropy-3": -0.05762995446115817,
        "total_length-nopunct": 81,
        "mean_pred_length-nopunct": 16.2,
        "std_pred_length-nopunct": 5.491812087098392,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.8271604938271605,
        "vocab_size-1-nopunct": 67,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 5.915596571074736,
        "distinct-2-nopunct": 0.9868421052631579,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.221611723969907,
        "cond_entropy-2-nopunct": 0.3207686681458067,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 71,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 6.149747119504677,
        "cond_entropy-3-nopunct": -0.0700113798543965,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.62226,
            "recall": 0.76821,
            "fmeasure": 0.66486
        },
        "rouge2": {
            "precision": 0.38402,
            "recall": 0.48087,
            "fmeasure": 0.41343
        },
        "rougeL": {
            "precision": 0.47832,
            "recall": 0.58145,
            "fmeasure": 0.51001
        },
        "rougeLsum": {
            "precision": 0.47832,
            "recall": 0.58145,
            "fmeasure": 0.51001
        },
        "local_recall": {
            "1": 0.2962962962962963,
            "2": 0.28125,
            "3": 0.775
        },
        "nist": 4.101483637546664,
        "bleu": 29.79712,
        "bleurt": -0.08862,
        "nubia": {
            "semantic_relation": 3.66001,
            "contradiction": 18.58154,
            "irrelevancy": 51.84713,
            "logical_agreement": 29.57133,
            "grammar_ref": 4.63083,
            "grammar_hyp": 4.12034,
            "nubia_score": 0.53362
        },
        "meteor": 0.3587312237802629,
        "bertscore": {
            "precision": 0.90517,
            "recall": 0.92043,
            "f1": 0.90242
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_168": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 44,
        "msttr-100": 0.75143,
        "msttr-100_nopunct": 0.79167,
        "total_length": 704,
        "mean_pred_length": 16.0,
        "std_pred_length": 5.704862359904448,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 34,
        "distinct-1": 0.5284090909090909,
        "vocab_size-1": 372,
        "unique-1": 297,
        "entropy-1": 7.615737726877035,
        "distinct-2": 0.8757575757575757,
        "vocab_size-2": 578,
        "unique-2": 530,
        "entropy-2": 9.061814946083816,
        "cond_entropy-2": 1.2050280374151432,
        "distinct-3": 0.9415584415584416,
        "vocab_size-3": 580,
        "unique-3": 555,
        "entropy-3": 9.136423289844535,
        "cond_entropy-3": 0.08986535642158139,
        "total_length-nopunct": 628,
        "mean_pred_length-nopunct": 14.272727272727273,
        "std_pred_length-nopunct": 5.340086977345953,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.5828025477707006,
        "vocab_size-1-nopunct": 366,
        "unique-1-nopunct": 296,
        "entropy-1-nopunct": 7.794312136494254,
        "distinct-2-nopunct": 0.8698630136986302,
        "vocab_size-2-nopunct": 508,
        "unique-2-nopunct": 466,
        "entropy-2-nopunct": 8.866237577738065,
        "cond_entropy-2-nopunct": 1.1538495062166336,
        "distinct-3-nopunct": 0.9407407407407408,
        "vocab_size-3-nopunct": 508,
        "unique-3-nopunct": 487,
        "entropy-3-nopunct": 8.94291974052521,
        "cond_entropy-3-nopunct": 0.09347457421084068,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77061,
            "recall": 0.74776,
            "fmeasure": 0.75013
        },
        "rouge2": {
            "precision": 0.55661,
            "recall": 0.5465,
            "fmeasure": 0.54638
        },
        "rougeL": {
            "precision": 0.69029,
            "recall": 0.67339,
            "fmeasure": 0.67324
        },
        "rougeLsum": {
            "precision": 0.69029,
            "recall": 0.67339,
            "fmeasure": 0.67324
        },
        "local_recall": {
            "1": 0.2571428571428571,
            "2": 0.5769230769230769,
            "3": 0.7946859903381642
        },
        "nist": 6.968044326055164,
        "bleu": 49.93105,
        "bleurt": 0.29131,
        "nubia": {
            "semantic_relation": 4.36348,
            "contradiction": 4.28038,
            "irrelevancy": 37.9573,
            "logical_agreement": 57.76232,
            "grammar_ref": 4.41204,
            "grammar_hyp": 4.57162,
            "nubia_score": 0.75998
        },
        "meteor": 0.413554678252997,
        "bertscore": {
            "precision": 0.93142,
            "recall": 0.93101,
            "f1": 0.92955
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_244": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.76,
        "total_length": 112,
        "mean_pred_length": 18.666666666666668,
        "std_pred_length": 7.630348761506398,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 35,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 80,
        "unique-1": 70,
        "entropy-1": 5.944451324610324,
        "distinct-2": 0.9811320754716981,
        "vocab_size-2": 104,
        "unique-2": 103,
        "entropy-2": 6.683063025297491,
        "cond_entropy-2": 0.641136668426387,
        "distinct-3": 1.0,
        "vocab_size-3": 100,
        "unique-3": 100,
        "entropy-3": 6.6438561897747395,
        "cond_entropy-3": -0.03651538976683986,
        "total_length-nopunct": 100,
        "mean_pred_length-nopunct": 16.666666666666668,
        "std_pred_length-nopunct": 7.2033942616581035,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.76,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 68,
        "entropy-1-nopunct": 5.912501910677062,
        "distinct-2-nopunct": 0.9787234042553191,
        "vocab_size-2-nopunct": 92,
        "unique-2-nopunct": 91,
        "entropy-2-nopunct": 6.50400494208014,
        "cond_entropy-2-nopunct": 0.6381852194306112,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 88,
        "unique-3-nopunct": 88,
        "entropy-3-nopunct": 6.459431618637305,
        "cond_entropy-3-nopunct": -0.04112442051575547,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83212,
            "recall": 0.81352,
            "fmeasure": 0.81959
        },
        "rouge2": {
            "precision": 0.64145,
            "recall": 0.63103,
            "fmeasure": 0.63326
        },
        "rougeL": {
            "precision": 0.73168,
            "recall": 0.73772,
            "fmeasure": 0.73332
        },
        "rougeLsum": {
            "precision": 0.73168,
            "recall": 0.73772,
            "fmeasure": 0.73332
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5555555555555556,
            "3": 0.8611111111111112
        },
        "nist": 6.041162143722945,
        "bleu": 54.68046,
        "bleurt": 0.14421,
        "nubia": {
            "semantic_relation": 4.27411,
            "contradiction": 28.25279,
            "irrelevancy": 23.13,
            "logical_agreement": 48.61721,
            "grammar_ref": 4.74863,
            "grammar_hyp": 5.12216,
            "nubia_score": 0.65846
        },
        "meteor": 0.4247932686293057,
        "bertscore": {
            "precision": 0.94035,
            "recall": 0.93867,
            "f1": 0.93874
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_169": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 7.71722460186015,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 23,
        "distinct-1": 0.723404255319149,
        "vocab_size-1": 34,
        "unique-1": 25,
        "entropy-1": 4.937151617450961,
        "distinct-2": 0.9090909090909091,
        "vocab_size-2": 40,
        "unique-2": 36,
        "entropy-2": 5.277613436819114,
        "cond_entropy-2": 0.2744941875617143,
        "distinct-3": 0.926829268292683,
        "vocab_size-3": 38,
        "unique-3": 35,
        "entropy-3": 5.211210541203447,
        "cond_entropy-3": -0.05309912621433559,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 7.483314773547883,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7619047619047619,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.862206410719467,
        "distinct-2-nopunct": 0.8974358974358975,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 5.0802740137340425,
        "cond_entropy-2-nopunct": 0.25884537317298584,
        "distinct-3-nopunct": 0.9166666666666666,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 5.003258334775643,
        "cond_entropy-3-nopunct": -0.059921661864380305,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.63821,
            "recall": 0.56685,
            "fmeasure": 0.59188
        },
        "rouge2": {
            "precision": 0.39842,
            "recall": 0.38017,
            "fmeasure": 0.37812
        },
        "rougeL": {
            "precision": 0.51467,
            "recall": 0.48217,
            "fmeasure": 0.4869
        },
        "rougeLsum": {
            "precision": 0.51467,
            "recall": 0.48217,
            "fmeasure": 0.4869
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.18181818181818182,
            "3": 0.625
        },
        "nist": 3.3021925225789186,
        "bleu": 28.39559,
        "bleurt": -0.1895,
        "nubia": {
            "semantic_relation": 4.0195,
            "contradiction": 0.67638,
            "irrelevancy": 53.45246,
            "logical_agreement": 45.87116,
            "grammar_ref": 4.07664,
            "grammar_hyp": 4.10867,
            "nubia_score": 0.72135
        },
        "meteor": 0.3018568082363764,
        "bertscore": {
            "precision": 0.89706,
            "recall": 0.87143,
            "f1": 0.87805
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_144": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 46,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.79167,
        "total_length": 777,
        "mean_pred_length": 16.891304347826086,
        "std_pred_length": 6.900624612149771,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 37,
        "distinct-1": 0.5456885456885456,
        "vocab_size-1": 424,
        "unique-1": 344,
        "entropy-1": 7.749423405662432,
        "distinct-2": 0.93296853625171,
        "vocab_size-2": 682,
        "unique-2": 648,
        "entropy-2": 9.355689583045026,
        "cond_entropy-2": 1.3752458348759358,
        "distinct-3": 0.9824817518248176,
        "vocab_size-3": 673,
        "unique-3": 661,
        "entropy-3": 9.38492368149769,
        "cond_entropy-3": 0.031087746034620944,
        "total_length-nopunct": 669,
        "mean_pred_length-nopunct": 14.543478260869565,
        "std_pred_length-nopunct": 6.009798237730037,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.624813153961136,
        "vocab_size-1-nopunct": 418,
        "unique-1-nopunct": 342,
        "entropy-1-nopunct": 8.031790082672567,
        "distinct-2-nopunct": 0.9390048154093098,
        "vocab_size-2-nopunct": 585,
        "unique-2-nopunct": 561,
        "entropy-2-nopunct": 9.134178401285274,
        "cond_entropy-2-nopunct": 1.1699924945761007,
        "distinct-3-nopunct": 0.9861351819757366,
        "vocab_size-3-nopunct": 569,
        "unique-3-nopunct": 561,
        "entropy-3-nopunct": 9.144697872596819,
        "cond_entropy-3-nopunct": 0.01892477075695198,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77309,
            "recall": 0.73624,
            "fmeasure": 0.74429
        },
        "rouge2": {
            "precision": 0.5555,
            "recall": 0.53527,
            "fmeasure": 0.53693
        },
        "rougeL": {
            "precision": 0.68553,
            "recall": 0.66047,
            "fmeasure": 0.66343
        },
        "rougeLsum": {
            "precision": 0.68553,
            "recall": 0.66047,
            "fmeasure": 0.66343
        },
        "local_recall": {
            "1": 0.17272727272727273,
            "2": 0.3722627737226277,
            "3": 0.7371541501976284
        },
        "nist": 6.516166836564198,
        "bleu": 44.64249,
        "bleurt": 0.26923,
        "nubia": {
            "semantic_relation": 4.19057,
            "contradiction": 9.91551,
            "irrelevancy": 35.72797,
            "logical_agreement": 54.35652,
            "grammar_ref": 4.63942,
            "grammar_hyp": 4.68521,
            "nubia_score": 0.71772
        },
        "meteor": 0.3786345269607553,
        "bertscore": {
            "precision": 0.92277,
            "recall": 0.92326,
            "f1": 0.92164
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_245": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.77667,
        "msttr-100_nopunct": 0.83,
        "total_length": 346,
        "mean_pred_length": 17.3,
        "std_pred_length": 5.710516614107694,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.6213872832369942,
        "vocab_size-1": 215,
        "unique-1": 178,
        "entropy-1": 7.159629956637176,
        "distinct-2": 0.9570552147239264,
        "vocab_size-2": 312,
        "unique-2": 302,
        "entropy-2": 8.253576160339538,
        "cond_entropy-2": 0.9070179936478421,
        "distinct-3": 0.9901960784313726,
        "vocab_size-3": 303,
        "unique-3": 300,
        "entropy-3": 8.237779999555437,
        "cond_entropy-3": -0.025115924262313363,
        "total_length-nopunct": 298,
        "mean_pred_length-nopunct": 14.9,
        "std_pred_length-nopunct": 4.877499359302879,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.697986577181208,
        "vocab_size-1-nopunct": 208,
        "unique-1-nopunct": 177,
        "entropy-1-nopunct": 7.267097643252744,
        "distinct-2-nopunct": 0.960431654676259,
        "vocab_size-2-nopunct": 267,
        "unique-2-nopunct": 259,
        "entropy-2-nopunct": 8.031658114067023,
        "cond_entropy-2-nopunct": 0.8330547785272082,
        "distinct-3-nopunct": 0.9883720930232558,
        "vocab_size-3-nopunct": 255,
        "unique-3-nopunct": 252,
        "entropy-3-nopunct": 7.987971441469731,
        "cond_entropy-3-nopunct": -0.03692055177122067,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78003,
            "recall": 0.78877,
            "fmeasure": 0.77008
        },
        "rouge2": {
            "precision": 0.57346,
            "recall": 0.57587,
            "fmeasure": 0.56256
        },
        "rougeL": {
            "precision": 0.68549,
            "recall": 0.69146,
            "fmeasure": 0.6765
        },
        "rougeLsum": {
            "precision": 0.68549,
            "recall": 0.69146,
            "fmeasure": 0.6765
        },
        "local_recall": {
            "1": 0.3181818181818182,
            "2": 0.4090909090909091,
            "3": 0.8495145631067961
        },
        "nist": 6.084516388832397,
        "bleu": 49.84346,
        "bleurt": 0.36498,
        "nubia": {
            "semantic_relation": 4.31666,
            "contradiction": 11.61736,
            "irrelevancy": 24.54586,
            "logical_agreement": 63.83678,
            "grammar_ref": 4.67668,
            "grammar_hyp": 4.53871,
            "nubia_score": 0.76374
        },
        "meteor": 0.43459822859852076,
        "bertscore": {
            "precision": 0.93542,
            "recall": 0.93741,
            "f1": 0.9343
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_145": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.805,
        "total_length": 272,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.392506988845757,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.6102941176470589,
        "vocab_size-1": 166,
        "unique-1": 136,
        "entropy-1": 6.7279518641595075,
        "distinct-2": 0.9058823529411765,
        "vocab_size-2": 231,
        "unique-2": 211,
        "entropy-2": 7.789002346754556,
        "cond_entropy-2": 0.8791870249844075,
        "distinct-3": 0.9495798319327731,
        "vocab_size-3": 226,
        "unique-3": 214,
        "entropy-3": 7.7939774271735365,
        "cond_entropy-3": 0.011239654081859883,
        "total_length-nopunct": 233,
        "mean_pred_length-nopunct": 13.705882352941176,
        "std_pred_length-nopunct": 4.040452884958682,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6952789699570815,
        "vocab_size-1-nopunct": 162,
        "unique-1-nopunct": 136,
        "entropy-1-nopunct": 6.872782073587154,
        "distinct-2-nopunct": 0.9212962962962963,
        "vocab_size-2-nopunct": 199,
        "unique-2-nopunct": 186,
        "entropy-2-nopunct": 7.57727394671624,
        "cond_entropy-2-nopunct": 0.754741267611252,
        "distinct-3-nopunct": 0.9597989949748744,
        "vocab_size-3-nopunct": 191,
        "unique-3-nopunct": 183,
        "entropy-3-nopunct": 7.556222610493407,
        "cond_entropy-3-nopunct": -0.010903444551476559,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82419,
            "recall": 0.75064,
            "fmeasure": 0.77821
        },
        "rouge2": {
            "precision": 0.53979,
            "recall": 0.50993,
            "fmeasure": 0.51966
        },
        "rougeL": {
            "precision": 0.63792,
            "recall": 0.58421,
            "fmeasure": 0.60547
        },
        "rougeLsum": {
            "precision": 0.63792,
            "recall": 0.58421,
            "fmeasure": 0.60547
        },
        "local_recall": {
            "1": 0.13846153846153847,
            "2": 0.5614035087719298,
            "3": 0.8023255813953488
        },
        "nist": 6.1773699174447865,
        "bleu": 39.64151,
        "bleurt": 0.17678,
        "nubia": {
            "semantic_relation": 4.20426,
            "contradiction": 9.1433,
            "irrelevancy": 33.77419,
            "logical_agreement": 57.08251,
            "grammar_ref": 4.90086,
            "grammar_hyp": 5.09856,
            "nubia_score": 0.6918
        },
        "meteor": 0.4003227280019541,
        "bertscore": {
            "precision": 0.93678,
            "recall": 0.93185,
            "f1": 0.93176
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_246": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 73,
        "mean_pred_length": 14.6,
        "std_pred_length": 5.535341001239219,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 21,
        "distinct-1": 0.821917808219178,
        "vocab_size-1": 60,
        "unique-1": 51,
        "entropy-1": 5.773872120844404,
        "distinct-2": 1.0,
        "vocab_size-2": 68,
        "unique-2": 68,
        "entropy-2": 6.087462841250345,
        "cond_entropy-2": 0.1734454515197848,
        "distinct-3": 1.0,
        "vocab_size-3": 63,
        "unique-3": 63,
        "entropy-3": 5.97727992349992,
        "cond_entropy-3": -0.11018291775042297,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 12.8,
        "std_pred_length-nopunct": 4.833218389437829,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.738204882778696,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 59,
        "unique-2-nopunct": 59,
        "entropy-2-nopunct": 5.882643049361836,
        "cond_entropy-2-nopunct": 0.16662419346630666,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 54,
        "unique-3-nopunct": 54,
        "entropy-3-nopunct": 5.7548875021634665,
        "cond_entropy-3-nopunct": -0.12775554719837257,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77077,
            "recall": 0.77757,
            "fmeasure": 0.76795
        },
        "rouge2": {
            "precision": 0.53696,
            "recall": 0.5481,
            "fmeasure": 0.53677
        },
        "rougeL": {
            "precision": 0.6803,
            "recall": 0.70648,
            "fmeasure": 0.68415
        },
        "rougeLsum": {
            "precision": 0.6803,
            "recall": 0.70648,
            "fmeasure": 0.68415
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.75,
            "3": 0.7755102040816326
        },
        "nist": 5.050365404094999,
        "bleu": 47.50502,
        "bleurt": 0.37657,
        "nubia": {
            "semantic_relation": 4.06442,
            "contradiction": 39.45665,
            "irrelevancy": 40.39581,
            "logical_agreement": 20.14754,
            "grammar_ref": 5.41078,
            "grammar_hyp": 5.44703,
            "nubia_score": 0.65614
        },
        "meteor": 0.40484101796502625,
        "bertscore": {
            "precision": 0.94037,
            "recall": 0.94903,
            "f1": 0.94327
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_146": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518525,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.640223928941851,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.18617861216337128,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.51111,
            "recall": 0.71818,
            "fmeasure": 0.59692
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.48148,
            "fmeasure": 0.39372
        },
        "rougeL": {
            "precision": 0.51111,
            "recall": 0.71818,
            "fmeasure": 0.59692
        },
        "rougeLsum": {
            "precision": 0.51111,
            "recall": 0.71818,
            "fmeasure": 0.59692
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6
        },
        "nist": 1.8603729828066586,
        "bleu": 19.56475,
        "bleurt": 0.1144,
        "nubia": {
            "semantic_relation": 3.81224,
            "contradiction": 0.27703,
            "irrelevancy": 26.62703,
            "logical_agreement": 73.09594,
            "grammar_ref": 5.00001,
            "grammar_hyp": 4.42918,
            "nubia_score": 0.58772
        },
        "meteor": 0.35532072173131407,
        "bertscore": {
            "precision": 0.87805,
            "recall": 0.90489,
            "f1": 0.89127
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_247": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 57,
        "mean_pred_length": 14.25,
        "std_pred_length": 1.7853571071357126,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 17,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 42,
        "unique-1": 32,
        "entropy-1": 5.231755584226311,
        "distinct-2": 0.9433962264150944,
        "vocab_size-2": 50,
        "unique-2": 47,
        "entropy-2": 5.614712907393384,
        "cond_entropy-2": 0.2773825631624272,
        "distinct-3": 1.0,
        "vocab_size-3": 49,
        "unique-3": 49,
        "entropy-3": 5.614709844115208,
        "cond_entropy-3": 0.009238369143845945,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 1.118033988749895,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.213660689688187,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.43660543431788,
        "cond_entropy-2-nopunct": 0.23861391855026504,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.3923174227787625,
        "cond_entropy-3-nopunct": -0.059815961849681,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85093,
            "recall": 0.66775,
            "fmeasure": 0.71762
        },
        "rouge2": {
            "precision": 0.59228,
            "recall": 0.53102,
            "fmeasure": 0.5327
        },
        "rougeL": {
            "precision": 0.81786,
            "recall": 0.66574,
            "fmeasure": 0.6991
        },
        "rougeLsum": {
            "precision": 0.81786,
            "recall": 0.66574,
            "fmeasure": 0.6991
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.375,
            "3": 0.6379310344827587
        },
        "nist": 3.183746568985735,
        "bleu": 32.24628,
        "bleurt": 0.13557,
        "nubia": {
            "semantic_relation": 4.27601,
            "contradiction": 0.91028,
            "irrelevancy": 38.18572,
            "logical_agreement": 60.904,
            "grammar_ref": 3.32258,
            "grammar_hyp": 3.42584,
            "nubia_score": 0.77383
        },
        "meteor": 0.34346371159250383,
        "bertscore": {
            "precision": 0.94023,
            "recall": 0.90266,
            "f1": 0.91818
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_170": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.735,
        "total_length": 278,
        "mean_pred_length": 18.533333333333335,
        "std_pred_length": 6.888315388314395,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 30,
        "distinct-1": 0.5863309352517986,
        "vocab_size-1": 163,
        "unique-1": 129,
        "entropy-1": 6.684733228631082,
        "distinct-2": 0.9315589353612167,
        "vocab_size-2": 245,
        "unique-2": 230,
        "entropy-2": 7.893425975959665,
        "cond_entropy-2": 1.0676652139721066,
        "distinct-3": 0.9798387096774194,
        "vocab_size-3": 243,
        "unique-3": 238,
        "entropy-3": 7.913873729741737,
        "cond_entropy-3": 0.029247734427195464,
        "total_length-nopunct": 248,
        "mean_pred_length-nopunct": 16.533333333333335,
        "std_pred_length-nopunct": 6.671997868371628,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6411290322580645,
        "vocab_size-1-nopunct": 159,
        "unique-1-nopunct": 127,
        "entropy-1-nopunct": 6.776774111242828,
        "distinct-2-nopunct": 0.9356223175965666,
        "vocab_size-2-nopunct": 218,
        "unique-2-nopunct": 205,
        "entropy-2-nopunct": 7.728951058798834,
        "cond_entropy-2-nopunct": 1.01939296896011,
        "distinct-3-nopunct": 0.9862385321100917,
        "vocab_size-3-nopunct": 215,
        "unique-3-nopunct": 212,
        "entropy-3-nopunct": 7.740661388997098,
        "cond_entropy-3-nopunct": 0.016428340692952993,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81581,
            "recall": 0.77923,
            "fmeasure": 0.78836
        },
        "rouge2": {
            "precision": 0.59075,
            "recall": 0.56775,
            "fmeasure": 0.57317
        },
        "rougeL": {
            "precision": 0.71922,
            "recall": 0.67751,
            "fmeasure": 0.68967
        },
        "rougeLsum": {
            "precision": 0.71922,
            "recall": 0.67751,
            "fmeasure": 0.68967
        },
        "local_recall": {
            "1": 0.22857142857142856,
            "2": 0.4230769230769231,
            "3": 0.8177083333333334
        },
        "nist": 6.387240144811991,
        "bleu": 46.71632,
        "bleurt": 0.4184,
        "nubia": {
            "semantic_relation": 4.35003,
            "contradiction": 7.44022,
            "irrelevancy": 32.84348,
            "logical_agreement": 59.7163,
            "grammar_ref": 4.2734,
            "grammar_hyp": 4.38026,
            "nubia_score": 0.77408
        },
        "meteor": 0.4036755481285531,
        "bertscore": {
            "precision": 0.94625,
            "recall": 0.94018,
            "f1": 0.94083
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_204": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.665,
        "msttr-100_nopunct": 0.715,
        "total_length": 247,
        "mean_pred_length": 20.583333333333332,
        "std_pred_length": 11.294971840995837,
        "median_pred_length": 19.0,
        "min_pred_length": 9,
        "max_pred_length": 52,
        "distinct-1": 0.611336032388664,
        "vocab_size-1": 151,
        "unique-1": 120,
        "entropy-1": 6.623648406029037,
        "distinct-2": 0.9148936170212766,
        "vocab_size-2": 215,
        "unique-2": 201,
        "entropy-2": 7.679221082834772,
        "cond_entropy-2": 0.9401559784994389,
        "distinct-3": 0.968609865470852,
        "vocab_size-3": 216,
        "unique-3": 209,
        "entropy-3": 7.738119630862018,
        "cond_entropy-3": 0.06951536580642724,
        "total_length-nopunct": 218,
        "mean_pred_length-nopunct": 18.166666666666668,
        "std_pred_length-nopunct": 10.229315172038103,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.6697247706422018,
        "vocab_size-1-nopunct": 146,
        "unique-1-nopunct": 120,
        "entropy-1-nopunct": 6.666660232581585,
        "distinct-2-nopunct": 0.9174757281553398,
        "vocab_size-2-nopunct": 189,
        "unique-2-nopunct": 178,
        "entropy-2-nopunct": 7.490556216617199,
        "cond_entropy-2-nopunct": 0.8832080670761109,
        "distinct-3-nopunct": 0.9742268041237113,
        "vocab_size-3-nopunct": 189,
        "unique-3-nopunct": 184,
        "entropy-3-nopunct": 7.548366450434526,
        "cond_entropy-3-nopunct": 0.06993050045030233,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74325,
            "recall": 0.66965,
            "fmeasure": 0.68853
        },
        "rouge2": {
            "precision": 0.49832,
            "recall": 0.45345,
            "fmeasure": 0.46357
        },
        "rougeL": {
            "precision": 0.61852,
            "recall": 0.5745,
            "fmeasure": 0.58358
        },
        "rougeLsum": {
            "precision": 0.61852,
            "recall": 0.5745,
            "fmeasure": 0.58358
        },
        "local_recall": {
            "1": 0.16,
            "2": 0.19230769230769232,
            "3": 0.7176470588235294
        },
        "nist": 5.095788456449129,
        "bleu": 32.07084,
        "bleurt": 0.08425,
        "nubia": {
            "semantic_relation": 3.95927,
            "contradiction": 17.49449,
            "irrelevancy": 22.98107,
            "logical_agreement": 59.52443,
            "grammar_ref": 4.36261,
            "grammar_hyp": 4.43662,
            "nubia_score": 0.66093
        },
        "meteor": 0.3217090366272798,
        "bertscore": {
            "precision": 0.91939,
            "recall": 0.90735,
            "f1": 0.9117
        }
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 269,
        "msttr-100": 0.55386,
        "msttr-100_nopunct": 0.58042,
        "total_length": 8301,
        "mean_pred_length": 30.858736059479554,
        "std_pred_length": 9.431938143272241,
        "median_pred_length": 30.0,
        "min_pred_length": 11,
        "max_pred_length": 71,
        "distinct-1": 0.1343211661245633,
        "vocab_size-1": 1115,
        "unique-1": 507,
        "entropy-1": 7.629396557268786,
        "distinct-2": 0.38881972111553786,
        "vocab_size-2": 3123,
        "unique-2": 1956,
        "entropy-2": 10.672962716519041,
        "cond_entropy-2": 2.9265829697971215,
        "distinct-3": 0.603761432435914,
        "vocab_size-3": 4687,
        "unique-3": 3499,
        "entropy-3": 11.729940036581295,
        "cond_entropy-3": 1.0925704646986694,
        "total_length-nopunct": 7299,
        "mean_pred_length-nopunct": 27.133828996282528,
        "std_pred_length-nopunct": 8.539691312803386,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 65,
        "distinct-1-nopunct": 0.1515276065214413,
        "vocab_size-1-nopunct": 1106,
        "unique-1-nopunct": 506,
        "entropy-1-nopunct": 7.8772603049199015,
        "distinct-2-nopunct": 0.4113798008534851,
        "vocab_size-2-nopunct": 2892,
        "unique-2-nopunct": 1877,
        "entropy-2-nopunct": 10.606656316611568,
        "cond_entropy-2-nopunct": 2.831273259548419,
        "distinct-3-nopunct": 0.6272740718828576,
        "vocab_size-3-nopunct": 4241,
        "unique-3-nopunct": 3268,
        "entropy-3-nopunct": 11.596975467686892,
        "cond_entropy-3-nopunct": 1.0204643884085578,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.59578,
            "recall": 0.58691,
            "fmeasure": 0.58235
        },
        "rouge2": {
            "precision": 0.2823,
            "recall": 0.28067,
            "fmeasure": 0.27674
        },
        "rougeL": {
            "precision": 0.41773,
            "recall": 0.41188,
            "fmeasure": 0.40786
        },
        "rougeLsum": {
            "precision": 0.41773,
            "recall": 0.41188,
            "fmeasure": 0.40786
        },
        "local_recall": {
            "1": 0.19159016878886587,
            "2": 0.43100604727872455,
            "3": 0.6702831436888066,
            "4": 0.25,
            "5": 0.875
        },
        "nist": 5.992840557370671,
        "bleu": 24.18793,
        "bleurt": -0.34243,
        "nubia": {
            "semantic_relation": 3.43715,
            "contradiction": 34.28805,
            "irrelevancy": 19.51392,
            "logical_agreement": 46.19804,
            "grammar_ref": 4.33889,
            "grammar_hyp": 4.51119,
            "nubia_score": 0.49494
        },
        "meteor": 0.26879720862465556,
        "bertscore": {
            "precision": 0.85655,
            "recall": 0.85679,
            "f1": 0.8551
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_248": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.81,
        "total_length": 125,
        "mean_pred_length": 15.625,
        "std_pred_length": 6.040229714174784,
        "median_pred_length": 14.5,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.736,
        "vocab_size-1": 92,
        "unique-1": 77,
        "entropy-1": 6.239617085196759,
        "distinct-2": 0.9914529914529915,
        "vocab_size-2": 116,
        "unique-2": 115,
        "entropy-2": 6.853270702489366,
        "cond_entropy-2": 0.45817787024753015,
        "distinct-3": 1.0,
        "vocab_size-3": 109,
        "unique-3": 109,
        "entropy-3": 6.7681843247769145,
        "cond_entropy-3": -0.08383177095326728,
        "total_length-nopunct": 108,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 5.338539126015656,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8148148148148148,
        "vocab_size-1-nopunct": 88,
        "unique-1-nopunct": 77,
        "entropy-1-nopunct": 6.281172136804847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 100,
        "unique-2-nopunct": 100,
        "entropy-2-nopunct": 6.6438561897747395,
        "cond_entropy-2-nopunct": 0.39058128219855826,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 92,
        "unique-3-nopunct": 92,
        "entropy-3-nopunct": 6.523561956057027,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74057,
            "recall": 0.71431,
            "fmeasure": 0.7043
        },
        "rouge2": {
            "precision": 0.44464,
            "recall": 0.41951,
            "fmeasure": 0.41687
        },
        "rougeL": {
            "precision": 0.61643,
            "recall": 0.60826,
            "fmeasure": 0.59323
        },
        "rougeLsum": {
            "precision": 0.61643,
            "recall": 0.60826,
            "fmeasure": 0.59323
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.375,
            "3": 0.7894736842105263
        },
        "nist": 5.032213504749899,
        "bleu": 39.9142,
        "bleurt": 0.21572,
        "nubia": {
            "semantic_relation": 4.20031,
            "contradiction": 0.56194,
            "irrelevancy": 47.59572,
            "logical_agreement": 51.84234,
            "grammar_ref": 4.75129,
            "grammar_hyp": 4.59103,
            "nubia_score": 0.76727
        },
        "meteor": 0.361641595471463,
        "bertscore": {
            "precision": 0.90246,
            "recall": 0.90652,
            "f1": 0.89929
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_147": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.765,
        "total_length": 287,
        "mean_pred_length": 16.88235294117647,
        "std_pred_length": 5.5506475821578585,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 33,
        "distinct-1": 0.6062717770034843,
        "vocab_size-1": 174,
        "unique-1": 140,
        "entropy-1": 6.797713998238774,
        "distinct-2": 0.9518518518518518,
        "vocab_size-2": 257,
        "unique-2": 244,
        "entropy-2": 7.980519300754548,
        "cond_entropy-2": 1.0063369868079894,
        "distinct-3": 0.9881422924901185,
        "vocab_size-3": 250,
        "unique-3": 247,
        "entropy-3": 7.959278159674512,
        "cond_entropy-3": -0.022675777297232063,
        "total_length-nopunct": 253,
        "mean_pred_length-nopunct": 14.882352941176471,
        "std_pred_length-nopunct": 5.454435355919356,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6679841897233202,
        "vocab_size-1-nopunct": 169,
        "unique-1-nopunct": 139,
        "entropy-1-nopunct": 6.894962062321101,
        "distinct-2-nopunct": 0.9491525423728814,
        "vocab_size-2-nopunct": 224,
        "unique-2-nopunct": 212,
        "entropy-2-nopunct": 7.780948134107582,
        "cond_entropy-2-nopunct": 0.9135137654743761,
        "distinct-3-nopunct": 0.9863013698630136,
        "vocab_size-3-nopunct": 216,
        "unique-3-nopunct": 213,
        "entropy-3-nopunct": 7.747389799327211,
        "cond_entropy-3-nopunct": -0.034796629030073814,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78258,
            "recall": 0.78942,
            "fmeasure": 0.77842
        },
        "rouge2": {
            "precision": 0.5705,
            "recall": 0.59225,
            "fmeasure": 0.57506
        },
        "rougeL": {
            "precision": 0.68605,
            "recall": 0.70415,
            "fmeasure": 0.68834
        },
        "rougeLsum": {
            "precision": 0.68605,
            "recall": 0.70415,
            "fmeasure": 0.68834
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5714285714285714,
            "3": 0.8118279569892473
        },
        "nist": 6.475614161712086,
        "bleu": 52.75506,
        "bleurt": 0.40502,
        "nubia": {
            "semantic_relation": 4.45092,
            "contradiction": 9.52108,
            "irrelevancy": 23.51769,
            "logical_agreement": 66.96124,
            "grammar_ref": 4.21928,
            "grammar_hyp": 3.98575,
            "nubia_score": 0.84287
        },
        "meteor": 0.4154950162080374,
        "bertscore": {
            "precision": 0.9401,
            "recall": 0.94112,
            "f1": 0.93887
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_205": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.71,
        "total_length": 190,
        "mean_pred_length": 15.833333333333334,
        "std_pred_length": 3.8908725099762504,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 24,
        "distinct-1": 0.6421052631578947,
        "vocab_size-1": 122,
        "unique-1": 102,
        "entropy-1": 6.405801638636522,
        "distinct-2": 0.9269662921348315,
        "vocab_size-2": 165,
        "unique-2": 155,
        "entropy-2": 7.314189119156467,
        "cond_entropy-2": 0.7451801638215411,
        "distinct-3": 0.9759036144578314,
        "vocab_size-3": 162,
        "unique-3": 158,
        "entropy-3": 7.326846660262572,
        "cond_entropy-3": 0.024335443164644296,
        "total_length-nopunct": 169,
        "mean_pred_length-nopunct": 14.083333333333334,
        "std_pred_length-nopunct": 3.707162736589204,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6982248520710059,
        "vocab_size-1-nopunct": 118,
        "unique-1-nopunct": 100,
        "entropy-1-nopunct": 6.463014230489962,
        "distinct-2-nopunct": 0.9235668789808917,
        "vocab_size-2-nopunct": 145,
        "unique-2-nopunct": 136,
        "entropy-2-nopunct": 7.1242074526995,
        "cond_entropy-2-nopunct": 0.713768906728686,
        "distinct-3-nopunct": 0.9793103448275862,
        "vocab_size-3-nopunct": 142,
        "unique-3-nopunct": 139,
        "entropy-3-nopunct": 7.138529779670129,
        "cond_entropy-3-nopunct": 0.014632392862365957,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77737,
            "recall": 0.74651,
            "fmeasure": 0.74944
        },
        "rouge2": {
            "precision": 0.48297,
            "recall": 0.46968,
            "fmeasure": 0.4704
        },
        "rougeL": {
            "precision": 0.67834,
            "recall": 0.65016,
            "fmeasure": 0.6545
        },
        "rougeLsum": {
            "precision": 0.67834,
            "recall": 0.65016,
            "fmeasure": 0.6545
        },
        "local_recall": {
            "1": 0.2571428571428571,
            "2": 0.41379310344827586,
            "3": 0.743801652892562
        },
        "nist": 5.456890820351611,
        "bleu": 42.09313,
        "bleurt": 0.26587,
        "nubia": {
            "semantic_relation": 4.46903,
            "contradiction": 8.53687,
            "irrelevancy": 24.4565,
            "logical_agreement": 67.00663,
            "grammar_ref": 4.24445,
            "grammar_hyp": 4.32627,
            "nubia_score": 0.79073
        },
        "meteor": 0.3664709150064653,
        "bertscore": {
            "precision": 0.92437,
            "recall": 0.924,
            "f1": 0.92182
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_148": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.71,
        "total_length": 147,
        "mean_pred_length": 14.7,
        "std_pred_length": 3.8223029707232783,
        "median_pred_length": 14.5,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.6122448979591837,
        "vocab_size-1": 90,
        "unique-1": 73,
        "entropy-1": 5.928812764273825,
        "distinct-2": 0.9124087591240876,
        "vocab_size-2": 125,
        "unique-2": 117,
        "entropy-2": 6.88263226541068,
        "cond_entropy-2": 0.8041064708941744,
        "distinct-3": 0.9763779527559056,
        "vocab_size-3": 124,
        "unique-3": 121,
        "entropy-3": 6.941440592283958,
        "cond_entropy-3": 0.06002091093232353,
        "total_length-nopunct": 127,
        "mean_pred_length-nopunct": 12.7,
        "std_pred_length-nopunct": 3.2878564445547194,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6771653543307087,
        "vocab_size-1-nopunct": 86,
        "unique-1-nopunct": 73,
        "entropy-1-nopunct": 5.932879156146234,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 108,
        "unique-2-nopunct": 103,
        "entropy-2-nopunct": 6.669426471683156,
        "cond_entropy-2-nopunct": 0.818240095932306,
        "distinct-3-nopunct": 0.9906542056074766,
        "vocab_size-3-nopunct": 106,
        "unique-3-nopunct": 105,
        "entropy-3-nopunct": 6.7227753976160916,
        "cond_entropy-3-nopunct": 0.0721282014376205,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7327,
            "recall": 0.70452,
            "fmeasure": 0.70964
        },
        "rouge2": {
            "precision": 0.46144,
            "recall": 0.44349,
            "fmeasure": 0.4461
        },
        "rougeL": {
            "precision": 0.66597,
            "recall": 0.64793,
            "fmeasure": 0.64837
        },
        "rougeLsum": {
            "precision": 0.66597,
            "recall": 0.64793,
            "fmeasure": 0.64837
        },
        "local_recall": {
            "1": 0.25925925925925924,
            "2": 0.29411764705882354,
            "3": 0.7641509433962265
        },
        "nist": 5.315617110320822,
        "bleu": 39.2225,
        "bleurt": 0.25532,
        "nubia": {
            "semantic_relation": 4.49754,
            "contradiction": 3.7666,
            "irrelevancy": 24.3519,
            "logical_agreement": 71.8815,
            "grammar_ref": 5.26168,
            "grammar_hyp": 5.26033,
            "nubia_score": 0.77833
        },
        "meteor": 0.3669317348470727,
        "bertscore": {
            "precision": 0.91905,
            "recall": 0.91604,
            "f1": 0.9163
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 453,
        "msttr-100": 0.53164,
        "msttr-100_nopunct": 0.56,
        "total_length": 5506,
        "mean_pred_length": 12.154525386313466,
        "std_pred_length": 4.2874587951882654,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 28,
        "distinct-1": 0.18034871049763893,
        "vocab_size-1": 993,
        "unique-1": 514,
        "entropy-1": 7.4079517746091454,
        "distinct-2": 0.4737779536908767,
        "vocab_size-2": 2394,
        "unique-2": 1609,
        "entropy-2": 10.496677912489277,
        "cond_entropy-2": 2.7456678007090094,
        "distinct-3": 0.6660869565217391,
        "vocab_size-3": 3064,
        "unique-3": 2396,
        "entropy-3": 11.1934842071195,
        "cond_entropy-3": 0.7995238602407209,
        "total_length-nopunct": 4819,
        "mean_pred_length-nopunct": 10.637969094922738,
        "std_pred_length-nopunct": 3.7858301312538227,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.2046067648889811,
        "vocab_size-1-nopunct": 986,
        "unique-1-nopunct": 513,
        "entropy-1-nopunct": 7.65724349633107,
        "distinct-2-nopunct": 0.45900137425561155,
        "vocab_size-2-nopunct": 2004,
        "unique-2-nopunct": 1325,
        "entropy-2-nopunct": 10.220616070893092,
        "cond_entropy-2-nopunct": 2.877702622888228,
        "distinct-3-nopunct": 0.6547406082289803,
        "vocab_size-3-nopunct": 2562,
        "unique-3-nopunct": 1985,
        "entropy-3-nopunct": 10.925901140080832,
        "cond_entropy-3-nopunct": 0.8302770046266197,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.68012,
            "recall": 0.69081,
            "fmeasure": 0.67767
        },
        "rouge2": {
            "precision": 0.41161,
            "recall": 0.41998,
            "fmeasure": 0.41056
        },
        "rougeL": {
            "precision": 0.57543,
            "recall": 0.58715,
            "fmeasure": 0.57424
        },
        "rougeLsum": {
            "precision": 0.57543,
            "recall": 0.58715,
            "fmeasure": 0.57424
        },
        "local_recall": {
            "1": 0.24423076923076922,
            "2": 0.5799748110831234,
            "3": 0.7288365776369398,
            "4": 1.0
        },
        "nist": 7.178174782588842,
        "bleu": 38.06179,
        "bleurt": 0.01735,
        "nubia": {
            "semantic_relation": 4.00939,
            "contradiction": 23.64384,
            "irrelevancy": 9.76456,
            "logical_agreement": 66.5916,
            "grammar_ref": 5.12238,
            "grammar_hyp": 5.20874,
            "nubia_score": 0.64004
        },
        "meteor": 0.3592491568144113,
        "bertscore": {
            "precision": 0.90168,
            "recall": 0.90538,
            "f1": 0.90226
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_207": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 42,
        "mean_pred_length": 14.0,
        "std_pred_length": 3.559026084010437,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 36,
        "unique-1": 33,
        "entropy-1": 5.041010577489155,
        "distinct-2": 1.0,
        "vocab_size-2": 39,
        "unique-2": 39,
        "entropy-2": 5.285402218862247,
        "cond_entropy-2": 0.1494950524937446,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.1154772174199358,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 3.39934634239519,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 4.984769618706745,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.129283016944964,
        "cond_entropy-2-nopunct": 0.16706978921566668,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.12928301694496638,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.62897,
            "recall": 0.74824,
            "fmeasure": 0.66466
        },
        "rouge2": {
            "precision": 0.36011,
            "recall": 0.38333,
            "fmeasure": 0.37047
        },
        "rougeL": {
            "precision": 0.58135,
            "recall": 0.69696,
            "fmeasure": 0.61528
        },
        "rougeLsum": {
            "precision": 0.58135,
            "recall": 0.69696,
            "fmeasure": 0.61528
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.5555555555555556,
            "3": 0.7272727272727273
        },
        "nist": 3.2516167466773007,
        "bleu": 32.26035,
        "bleurt": 0.16201,
        "nubia": {
            "semantic_relation": 4.18105,
            "contradiction": 0.28865,
            "irrelevancy": 49.03078,
            "logical_agreement": 50.68056,
            "grammar_ref": 5.944,
            "grammar_hyp": 5.7648,
            "nubia_score": 0.72567
        },
        "meteor": 0.3548058714633646,
        "bertscore": {
            "precision": 0.88759,
            "recall": 0.91203,
            "f1": 0.89938
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_208": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.72,
        "total_length": 393,
        "mean_pred_length": 17.08695652173913,
        "std_pred_length": 5.428692239655168,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.5597964376590331,
        "vocab_size-1": 220,
        "unique-1": 178,
        "entropy-1": 6.997970068776865,
        "distinct-2": 0.8945945945945946,
        "vocab_size-2": 331,
        "unique-2": 308,
        "entropy-2": 8.26029021045202,
        "cond_entropy-2": 1.078037486144062,
        "distinct-3": 0.962536023054755,
        "vocab_size-3": 334,
        "unique-3": 323,
        "entropy-3": 8.359512962075884,
        "cond_entropy-3": 0.09772480133372895,
        "total_length-nopunct": 352,
        "mean_pred_length-nopunct": 15.304347826086957,
        "std_pred_length-nopunct": 4.92054064375482,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6079545454545454,
        "vocab_size-1-nopunct": 214,
        "unique-1-nopunct": 175,
        "entropy-1-nopunct": 7.090782143261219,
        "distinct-2-nopunct": 0.8966565349544073,
        "vocab_size-2-nopunct": 295,
        "unique-2-nopunct": 276,
        "entropy-2-nopunct": 8.089758743274366,
        "cond_entropy-2-nopunct": 1.041400118231734,
        "distinct-3-nopunct": 0.9738562091503268,
        "vocab_size-3-nopunct": 298,
        "unique-3-nopunct": 291,
        "entropy-3-nopunct": 8.202633308371896,
        "cond_entropy-3-nopunct": 0.0968298941797269,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76963,
            "recall": 0.79752,
            "fmeasure": 0.77407
        },
        "rouge2": {
            "precision": 0.57773,
            "recall": 0.59958,
            "fmeasure": 0.58293
        },
        "rougeL": {
            "precision": 0.65828,
            "recall": 0.69734,
            "fmeasure": 0.66995
        },
        "rougeLsum": {
            "precision": 0.65828,
            "recall": 0.69734,
            "fmeasure": 0.66995
        },
        "local_recall": {
            "1": 0.29333333333333333,
            "2": 0.5573770491803278,
            "3": 0.8050847457627118
        },
        "nist": 6.326364588564533,
        "bleu": 47.65762,
        "bleurt": 0.25905,
        "nubia": {
            "semantic_relation": 4.23824,
            "contradiction": 7.54248,
            "irrelevancy": 33.80012,
            "logical_agreement": 58.6574,
            "grammar_ref": 4.22562,
            "grammar_hyp": 4.19783,
            "nubia_score": 0.75505
        },
        "meteor": 0.41032238095104423,
        "bertscore": {
            "precision": 0.9213,
            "recall": 0.92811,
            "f1": 0.92263
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_171": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.74,
        "msttr-100_nopunct": NaN,
        "total_length": 100,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 4.570436400267363,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 22,
        "distinct-1": 0.74,
        "vocab_size-1": 74,
        "unique-1": 64,
        "entropy-1": 5.9463701301561915,
        "distinct-2": 1.0,
        "vocab_size-2": 94,
        "unique-2": 94,
        "entropy-2": 6.554588851677623,
        "cond_entropy-2": 0.48774150187660836,
        "distinct-3": 1.0,
        "vocab_size-3": 88,
        "unique-3": 88,
        "entropy-3": 6.459431618637305,
        "cond_entropy-3": -0.09515723304034043,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 13.833333333333334,
        "std_pred_length-nopunct": 4.297932319409209,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8433734939759037,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 64,
        "entropy-1-nopunct": 5.976010329193151,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 77,
        "unique-2-nopunct": 77,
        "entropy-2-nopunct": 6.266786540694905,
        "cond_entropy-2-nopunct": 0.3218693882929605,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 71,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 6.149747119504677,
        "cond_entropy-3-nopunct": -0.11703942119021936,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81781,
            "recall": 0.80014,
            "fmeasure": 0.79402
        },
        "rouge2": {
            "precision": 0.60978,
            "recall": 0.57753,
            "fmeasure": 0.58536
        },
        "rougeL": {
            "precision": 0.74019,
            "recall": 0.72798,
            "fmeasure": 0.72095
        },
        "rougeLsum": {
            "precision": 0.74019,
            "recall": 0.72798,
            "fmeasure": 0.72095
        },
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.0,
            "3": 0.8076923076923077
        },
        "nist": 5.500870819774932,
        "bleu": 52.46473,
        "bleurt": 0.46903,
        "nubia": {
            "semantic_relation": 4.62978,
            "contradiction": 0.24924,
            "irrelevancy": 14.91895,
            "logical_agreement": 84.83181,
            "grammar_ref": 4.66241,
            "grammar_hyp": 4.8543,
            "nubia_score": 0.83951
        },
        "meteor": 0.44252733310974357,
        "bertscore": {
            "precision": 0.94328,
            "recall": 0.93944,
            "f1": 0.93715
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_172": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.78,
        "total_length": 191,
        "mean_pred_length": 19.1,
        "std_pred_length": 7.751773990513397,
        "median_pred_length": 15.5,
        "min_pred_length": 11,
        "max_pred_length": 35,
        "distinct-1": 0.6178010471204188,
        "vocab_size-1": 118,
        "unique-1": 95,
        "entropy-1": 6.366619538615718,
        "distinct-2": 0.9281767955801105,
        "vocab_size-2": 168,
        "unique-2": 160,
        "entropy-2": 7.329929381546367,
        "cond_entropy-2": 0.8725848036003935,
        "distinct-3": 0.9532163742690059,
        "vocab_size-3": 163,
        "unique-3": 159,
        "entropy-3": 7.3037602633986,
        "cond_entropy-3": -0.01623248039709379,
        "total_length-nopunct": 166,
        "mean_pred_length-nopunct": 16.6,
        "std_pred_length-nopunct": 6.16765757804371,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.6867469879518072,
        "vocab_size-1-nopunct": 114,
        "unique-1-nopunct": 93,
        "entropy-1-nopunct": 6.474844971362351,
        "distinct-2-nopunct": 0.9423076923076923,
        "vocab_size-2-nopunct": 147,
        "unique-2-nopunct": 141,
        "entropy-2-nopunct": 7.15235806820737,
        "cond_entropy-2-nopunct": 0.7352178699209316,
        "distinct-3-nopunct": 0.9657534246575342,
        "vocab_size-3-nopunct": 141,
        "unique-3-nopunct": 138,
        "entropy-3-nopunct": 7.110990483507918,
        "cond_entropy-3-nopunct": -0.03225497164088494,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72868,
            "recall": 0.7405,
            "fmeasure": 0.72793
        },
        "rouge2": {
            "precision": 0.47711,
            "recall": 0.49341,
            "fmeasure": 0.48044
        },
        "rougeL": {
            "precision": 0.61998,
            "recall": 0.64068,
            "fmeasure": 0.62467
        },
        "rougeLsum": {
            "precision": 0.61998,
            "recall": 0.64068,
            "fmeasure": 0.62467
        },
        "local_recall": {
            "1": 0.3870967741935484,
            "2": 0.475,
            "3": 0.7297297297297297
        },
        "nist": 5.63656387291,
        "bleu": 39.72138,
        "bleurt": 0.20298,
        "nubia": {
            "semantic_relation": 4.13262,
            "contradiction": 3.25284,
            "irrelevancy": 55.06906,
            "logical_agreement": 41.67809,
            "grammar_ref": 4.7085,
            "grammar_hyp": 4.57941,
            "nubia_score": 0.70541
        },
        "meteor": 0.3711696718256766,
        "bertscore": {
            "precision": 0.92832,
            "recall": 0.92717,
            "f1": 0.92562
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_209": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.66667,
            "fmeasure": 0.61538
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.2,
            "fmeasure": 0.18182
        },
        "rougeL": {
            "precision": 0.28571,
            "recall": 0.33333,
            "fmeasure": 0.30769
        },
        "rougeLsum": {
            "precision": 0.28571,
            "recall": 0.33333,
            "fmeasure": 0.30769
        },
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666
        },
        "nist": 1.7545968262860026,
        "bleu": 13.8881,
        "bleurt": -0.14096,
        "nubia": {
            "semantic_relation": 4.27503,
            "contradiction": 1.18597,
            "irrelevancy": 32.4938,
            "logical_agreement": 66.32023,
            "grammar_ref": 6.80479,
            "grammar_hyp": 5.41931,
            "nubia_score": 0.89248
        },
        "meteor": 0.30051753214011256,
        "bertscore": {
            "precision": 0.84094,
            "recall": 0.87423,
            "f1": 0.85726
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_150": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 37,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.77,
        "total_length": 660,
        "mean_pred_length": 17.83783783783784,
        "std_pred_length": 7.265295193175133,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 37,
        "distinct-1": 0.5636363636363636,
        "vocab_size-1": 372,
        "unique-1": 312,
        "entropy-1": 7.589023140944096,
        "distinct-2": 0.913322632423756,
        "vocab_size-2": 569,
        "unique-2": 537,
        "entropy-2": 9.068403592250467,
        "cond_entropy-2": 1.2755446426128092,
        "distinct-3": 0.9812286689419796,
        "vocab_size-3": 575,
        "unique-3": 564,
        "entropy-3": 9.157214192306236,
        "cond_entropy-3": 0.10236578119663253,
        "total_length-nopunct": 582,
        "mean_pred_length-nopunct": 15.72972972972973,
        "std_pred_length-nopunct": 6.386847332281624,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.6288659793814433,
        "vocab_size-1-nopunct": 366,
        "unique-1-nopunct": 310,
        "entropy-1-nopunct": 7.761807148988159,
        "distinct-2-nopunct": 0.908256880733945,
        "vocab_size-2-nopunct": 495,
        "unique-2-nopunct": 466,
        "entropy-2-nopunct": 8.860766147261236,
        "cond_entropy-2-nopunct": 1.174314155473623,
        "distinct-3-nopunct": 0.9822834645669292,
        "vocab_size-3-nopunct": 499,
        "unique-3-nopunct": 490,
        "entropy-3-nopunct": 8.953251615906101,
        "cond_entropy-3-nopunct": 0.10525281525687467,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7537,
            "recall": 0.7435,
            "fmeasure": 0.73633
        },
        "rouge2": {
            "precision": 0.52055,
            "recall": 0.51918,
            "fmeasure": 0.51097
        },
        "rougeL": {
            "precision": 0.65171,
            "recall": 0.65178,
            "fmeasure": 0.64034
        },
        "rougeLsum": {
            "precision": 0.65171,
            "recall": 0.65178,
            "fmeasure": 0.64034
        },
        "local_recall": {
            "1": 0.3161764705882353,
            "2": 0.41836734693877553,
            "3": 0.7536231884057971
        },
        "nist": 6.628608878121217,
        "bleu": 44.06132,
        "bleurt": 0.20103,
        "nubia": {
            "semantic_relation": 4.15131,
            "contradiction": 9.90422,
            "irrelevancy": 34.86994,
            "logical_agreement": 55.22584,
            "grammar_ref": 4.9523,
            "grammar_hyp": 4.82382,
            "nubia_score": 0.71172
        },
        "meteor": 0.40124173105982763,
        "bertscore": {
            "precision": 0.92745,
            "recall": 0.92662,
            "f1": 0.9254
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_250": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 16,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.835,
        "total_length": 267,
        "mean_pred_length": 16.6875,
        "std_pred_length": 8.43888877459586,
        "median_pred_length": 14.5,
        "min_pred_length": 9,
        "max_pred_length": 47,
        "distinct-1": 0.6254681647940075,
        "vocab_size-1": 167,
        "unique-1": 139,
        "entropy-1": 6.788107944457843,
        "distinct-2": 0.9362549800796812,
        "vocab_size-2": 235,
        "unique-2": 223,
        "entropy-2": 7.822102219272173,
        "cond_entropy-2": 0.8545600211715648,
        "distinct-3": 0.9787234042553191,
        "vocab_size-3": 230,
        "unique-3": 225,
        "entropy-3": 7.8339637550756205,
        "cond_entropy-3": 0.022036264973065746,
        "total_length-nopunct": 215,
        "mean_pred_length-nopunct": 13.4375,
        "std_pred_length-nopunct": 3.983854132620822,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7581395348837209,
        "vocab_size-1-nopunct": 163,
        "unique-1-nopunct": 139,
        "entropy-1-nopunct": 7.079594682325003,
        "distinct-2-nopunct": 0.964824120603015,
        "vocab_size-2-nopunct": 192,
        "unique-2-nopunct": 185,
        "entropy-2-nopunct": 7.566272861749689,
        "cond_entropy-2-nopunct": 0.5354096903604928,
        "distinct-3-nopunct": 0.9890710382513661,
        "vocab_size-3-nopunct": 181,
        "unique-3-nopunct": 179,
        "entropy-3-nopunct": 7.493841914786769,
        "cond_entropy-3-nopunct": -0.06627997351643691,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78262,
            "recall": 0.73904,
            "fmeasure": 0.74801
        },
        "rouge2": {
            "precision": 0.5459,
            "recall": 0.5311,
            "fmeasure": 0.53153
        },
        "rougeL": {
            "precision": 0.68946,
            "recall": 0.65713,
            "fmeasure": 0.66452
        },
        "rougeLsum": {
            "precision": 0.68946,
            "recall": 0.65713,
            "fmeasure": 0.66452
        },
        "local_recall": {
            "1": 0.18518518518518517,
            "2": 0.24390243902439024,
            "3": 0.7621621621621621
        },
        "nist": 6.334945318191285,
        "bleu": 53.27584,
        "bleurt": 0.3707,
        "nubia": {
            "semantic_relation": 4.3523,
            "contradiction": 6.89645,
            "irrelevancy": 27.89227,
            "logical_agreement": 65.21128,
            "grammar_ref": 4.44923,
            "grammar_hyp": 4.47229,
            "nubia_score": 0.78557
        },
        "meteor": 0.41049155471674253,
        "bertscore": {
            "precision": 0.9356,
            "recall": 0.93533,
            "f1": 0.93396
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_174": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.8,
        "total_length": 192,
        "mean_pred_length": 17.454545454545453,
        "std_pred_length": 7.152413913734889,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 128,
        "unique-1": 105,
        "entropy-1": 6.567275955246564,
        "distinct-2": 0.9337016574585635,
        "vocab_size-2": 169,
        "unique-2": 158,
        "entropy-2": 7.363078552817085,
        "cond_entropy-2": 0.6474092505827722,
        "distinct-3": 0.9823529411764705,
        "vocab_size-3": 167,
        "unique-3": 164,
        "entropy-3": 7.374096818490614,
        "cond_entropy-3": 0.01986791671428155,
        "total_length-nopunct": 170,
        "mean_pred_length-nopunct": 15.454545454545455,
        "std_pred_length-nopunct": 6.499841066079811,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.7176470588235294,
        "vocab_size-1-nopunct": 122,
        "unique-1-nopunct": 101,
        "entropy-1-nopunct": 6.599446321598211,
        "distinct-2-nopunct": 0.9371069182389937,
        "vocab_size-2-nopunct": 149,
        "unique-2-nopunct": 140,
        "entropy-2-nopunct": 7.182349071622923,
        "cond_entropy-2-nopunct": 0.6137794214708518,
        "distinct-3-nopunct": 0.9797297297297297,
        "vocab_size-3-nopunct": 145,
        "unique-3-nopunct": 142,
        "entropy-3-nopunct": 7.168912825088407,
        "cond_entropy-3-nopunct": -0.010491160586733621,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.61044,
            "recall": 0.61567,
            "fmeasure": 0.59549
        },
        "rouge2": {
            "precision": 0.33477,
            "recall": 0.35891,
            "fmeasure": 0.33818
        },
        "rougeL": {
            "precision": 0.50312,
            "recall": 0.52203,
            "fmeasure": 0.49826
        },
        "rougeLsum": {
            "precision": 0.50312,
            "recall": 0.52203,
            "fmeasure": 0.49826
        },
        "local_recall": {
            "1": 0.15151515151515152,
            "2": 0.19047619047619047,
            "3": 0.6299212598425197
        },
        "nist": 4.680226065454912,
        "bleu": 35.11089,
        "bleurt": 0.09093,
        "nubia": {
            "semantic_relation": 3.85797,
            "contradiction": 15.39747,
            "irrelevancy": 42.16536,
            "logical_agreement": 42.43717,
            "grammar_ref": 4.8345,
            "grammar_hyp": 4.55753,
            "nubia_score": 0.61087
        },
        "meteor": 0.3212922403453974,
        "bertscore": {
            "precision": 0.88603,
            "recall": 0.89341,
            "f1": 0.88541
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_252": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 19,
        "msttr-100": 0.69333,
        "msttr-100_nopunct": 0.735,
        "total_length": 321,
        "mean_pred_length": 16.894736842105264,
        "std_pred_length": 6.406368023032816,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 34,
        "distinct-1": 0.5950155763239875,
        "vocab_size-1": 191,
        "unique-1": 158,
        "entropy-1": 6.857959614268698,
        "distinct-2": 0.9238410596026491,
        "vocab_size-2": 279,
        "unique-2": 262,
        "entropy-2": 8.069465832011685,
        "cond_entropy-2": 1.0366396774409101,
        "distinct-3": 0.9787985865724381,
        "vocab_size-3": 277,
        "unique-3": 272,
        "entropy-3": 8.099587968972624,
        "cond_entropy-3": 0.027330049466133346,
        "total_length-nopunct": 283,
        "mean_pred_length-nopunct": 14.894736842105264,
        "std_pred_length-nopunct": 5.599762559271741,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.657243816254417,
        "vocab_size-1-nopunct": 186,
        "unique-1-nopunct": 157,
        "entropy-1-nopunct": 6.949821206020598,
        "distinct-2-nopunct": 0.9242424242424242,
        "vocab_size-2-nopunct": 244,
        "unique-2-nopunct": 230,
        "entropy-2-nopunct": 7.873865520840833,
        "cond_entropy-2-nopunct": 0.9948848591361773,
        "distinct-3-nopunct": 0.9755102040816327,
        "vocab_size-3-nopunct": 239,
        "unique-3-nopunct": 234,
        "entropy-3-nopunct": 7.8845771736876475,
        "cond_entropy-3-nopunct": 0.023936319670608504,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.68919,
            "recall": 0.653,
            "fmeasure": 0.66442
        },
        "rouge2": {
            "precision": 0.45208,
            "recall": 0.43764,
            "fmeasure": 0.44122
        },
        "rougeL": {
            "precision": 0.60902,
            "recall": 0.57915,
            "fmeasure": 0.58888
        },
        "rougeLsum": {
            "precision": 0.60902,
            "recall": 0.57915,
            "fmeasure": 0.58888
        },
        "local_recall": {
            "1": 0.20588235294117646,
            "2": 0.4065934065934066,
            "3": 0.7109826589595376
        },
        "nist": 5.307488114908764,
        "bleu": 37.87344,
        "bleurt": 0.1225,
        "nubia": {
            "semantic_relation": 4.03027,
            "contradiction": 10.66284,
            "irrelevancy": 35.64022,
            "logical_agreement": 53.69694,
            "grammar_ref": 4.62734,
            "grammar_hyp": 4.63927,
            "nubia_score": 0.67859
        },
        "meteor": 0.32846182139209196,
        "bertscore": {
            "precision": 0.9025,
            "recall": 0.89972,
            "f1": 0.90039
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_152": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 24,
        "msttr-100": 0.72333,
        "msttr-100_nopunct": 0.79,
        "total_length": 360,
        "mean_pred_length": 15.0,
        "std_pred_length": 6.13052471924984,
        "median_pred_length": 13.5,
        "min_pred_length": 7,
        "max_pred_length": 35,
        "distinct-1": 0.6166666666666667,
        "vocab_size-1": 222,
        "unique-1": 191,
        "entropy-1": 7.047514532254504,
        "distinct-2": 0.9583333333333334,
        "vocab_size-2": 322,
        "unique-2": 310,
        "entropy-2": 8.303031708493103,
        "cond_entropy-2": 1.0311868950495255,
        "distinct-3": 1.0,
        "vocab_size-3": 312,
        "unique-3": 312,
        "entropy-3": 8.285402218862195,
        "cond_entropy-3": -0.01717161417292206,
        "total_length-nopunct": 311,
        "mean_pred_length-nopunct": 12.958333333333334,
        "std_pred_length-nopunct": 5.05370463675466,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.7009646302250804,
        "vocab_size-1-nopunct": 218,
        "unique-1-nopunct": 191,
        "entropy-1-nopunct": 7.237568471903949,
        "distinct-2-nopunct": 0.9581881533101045,
        "vocab_size-2-nopunct": 275,
        "unique-2-nopunct": 265,
        "entropy-2-nopunct": 8.07431459218088,
        "cond_entropy-2-nopunct": 0.8999167285063522,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 263,
        "unique-3-nopunct": 263,
        "entropy-3-nopunct": 8.038918989292329,
        "cond_entropy-3-nopunct": -0.030930903162853105,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78517,
            "recall": 0.72827,
            "fmeasure": 0.74662
        },
        "rouge2": {
            "precision": 0.52341,
            "recall": 0.48436,
            "fmeasure": 0.49702
        },
        "rougeL": {
            "precision": 0.71807,
            "recall": 0.65789,
            "fmeasure": 0.67842
        },
        "rougeLsum": {
            "precision": 0.71807,
            "recall": 0.65789,
            "fmeasure": 0.67842
        },
        "local_recall": {
            "1": 0.1702127659574468,
            "2": 0.38372093023255816,
            "3": 0.759493670886076
        },
        "nist": 5.891311156193582,
        "bleu": 41.71173,
        "bleurt": 0.23308,
        "nubia": {
            "semantic_relation": 4.27749,
            "contradiction": 6.00249,
            "irrelevancy": 32.10397,
            "logical_agreement": 61.89354,
            "grammar_ref": 4.6818,
            "grammar_hyp": 4.87406,
            "nubia_score": 0.72475
        },
        "meteor": 0.38523081087193783,
        "bertscore": {
            "precision": 0.93348,
            "recall": 0.92869,
            "f1": 0.9304
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_253": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 22.0,
        "std_pred_length": 8.0,
        "median_pred_length": 22.0,
        "min_pred_length": 14,
        "max_pred_length": 30,
        "distinct-1": 0.75,
        "vocab_size-1": 33,
        "unique-1": 26,
        "entropy-1": 4.834209459448047,
        "distinct-2": 0.9285714285714286,
        "vocab_size-2": 39,
        "unique-2": 36,
        "entropy-2": 5.249460279921619,
        "cond_entropy-2": 0.3974042566254381,
        "distinct-3": 0.95,
        "vocab_size-3": 38,
        "unique-3": 36,
        "entropy-3": 5.221928094887364,
        "cond_entropy-3": -0.020389327891397996,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.843568731230678,
        "distinct-2-nopunct": 0.9696969696969697,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.9837880587523955,
        "cond_entropy-2-nopunct": 0.15753534483772907,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.025681679939320096,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76786,
            "recall": 0.67644,
            "fmeasure": 0.69858
        },
        "rouge2": {
            "precision": 0.56856,
            "recall": 0.51396,
            "fmeasure": 0.52371
        },
        "rougeL": {
            "precision": 0.68452,
            "recall": 0.62741,
            "fmeasure": 0.63693
        },
        "rougeLsum": {
            "precision": 0.68452,
            "recall": 0.62741,
            "fmeasure": 0.63693
        },
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.5789473684210527
        },
        "nist": 3.4011783751549847,
        "bleu": 37.71981,
        "bleurt": -0.01544,
        "nubia": {
            "semantic_relation": 3.70237,
            "contradiction": 22.174,
            "irrelevancy": 66.06605,
            "logical_agreement": 11.75995,
            "grammar_ref": 4.45404,
            "grammar_hyp": 4.52664,
            "nubia_score": 0.46793
        },
        "meteor": 0.30981809647869935,
        "bertscore": {
            "precision": 0.9497,
            "recall": 0.9229,
            "f1": 0.93515
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_175": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 21,
        "msttr-100": 0.72333,
        "msttr-100_nopunct": 0.745,
        "total_length": 317,
        "mean_pred_length": 15.095238095238095,
        "std_pred_length": 3.877956775524254,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.6246056782334385,
        "vocab_size-1": 198,
        "unique-1": 166,
        "entropy-1": 6.962087349522515,
        "distinct-2": 0.956081081081081,
        "vocab_size-2": 283,
        "unique-2": 274,
        "entropy-2": 8.109758179803482,
        "cond_entropy-2": 0.9315648147898203,
        "distinct-3": 0.9963636363636363,
        "vocab_size-3": 274,
        "unique-3": 273,
        "entropy-3": 8.0960150811393,
        "cond_entropy-3": -0.01340273901937538,
        "total_length-nopunct": 278,
        "mean_pred_length-nopunct": 13.238095238095237,
        "std_pred_length-nopunct": 3.5038042169804102,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6942446043165468,
        "vocab_size-1-nopunct": 193,
        "unique-1-nopunct": 165,
        "entropy-1-nopunct": 7.10305114271853,
        "distinct-2-nopunct": 0.9649805447470817,
        "vocab_size-2-nopunct": 248,
        "unique-2-nopunct": 242,
        "entropy-2-nopunct": 7.924866232064864,
        "cond_entropy-2-nopunct": 0.8645926711642559,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 236,
        "unique-3-nopunct": 236,
        "entropy-3-nopunct": 7.882643049361818,
        "cond_entropy-3-nopunct": -0.039274349399140734,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72178,
            "recall": 0.65764,
            "fmeasure": 0.67763
        },
        "rouge2": {
            "precision": 0.47953,
            "recall": 0.45348,
            "fmeasure": 0.4591
        },
        "rougeL": {
            "precision": 0.60272,
            "recall": 0.56081,
            "fmeasure": 0.57328
        },
        "rougeLsum": {
            "precision": 0.60272,
            "recall": 0.56081,
            "fmeasure": 0.57328
        },
        "local_recall": {
            "1": 0.21212121212121213,
            "2": 0.46808510638297873,
            "3": 0.6907216494845361
        },
        "nist": 5.922319543776657,
        "bleu": 39.53602,
        "bleurt": 0.24553,
        "nubia": {
            "semantic_relation": 4.01861,
            "contradiction": 18.72204,
            "irrelevancy": 27.64157,
            "logical_agreement": 53.63639,
            "grammar_ref": 4.90831,
            "grammar_hyp": 4.89807,
            "nubia_score": 0.66034
        },
        "meteor": 0.35631842726713403,
        "bertscore": {
            "precision": 0.92744,
            "recall": 0.91736,
            "f1": 0.92125
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_255": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.76,
        "msttr-100_nopunct": NaN,
        "total_length": 106,
        "mean_pred_length": 17.666666666666668,
        "std_pred_length": 4.606758320361751,
        "median_pred_length": 17.0,
        "min_pred_length": 12,
        "max_pred_length": 25,
        "distinct-1": 0.7452830188679245,
        "vocab_size-1": 79,
        "unique-1": 70,
        "entropy-1": 6.002506747114309,
        "distinct-2": 0.99,
        "vocab_size-2": 99,
        "unique-2": 98,
        "entropy-2": 6.62385618977474,
        "cond_entropy-2": 0.5097765150640667,
        "distinct-3": 1.0,
        "vocab_size-3": 94,
        "unique-3": 94,
        "entropy-3": 6.554588851677623,
        "cond_entropy-3": -0.06799074235240642,
        "total_length-nopunct": 92,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 4.346134936801766,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8152173913043478,
        "vocab_size-1-nopunct": 75,
        "unique-1-nopunct": 68,
        "entropy-1-nopunct": 6.024928228003468,
        "distinct-2-nopunct": 0.9883720930232558,
        "vocab_size-2-nopunct": 85,
        "unique-2-nopunct": 84,
        "entropy-2-nopunct": 6.40300894074861,
        "cond_entropy-2-nopunct": 0.41286911237679685,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 80,
        "unique-3-nopunct": 80,
        "entropy-3-nopunct": 6.321928094887356,
        "cond_entropy-3-nopunct": -0.07933665981473584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7481,
            "recall": 0.79551,
            "fmeasure": 0.76616
        },
        "rouge2": {
            "precision": 0.44152,
            "recall": 0.49647,
            "fmeasure": 0.46387
        },
        "rougeL": {
            "precision": 0.56973,
            "recall": 0.6433,
            "fmeasure": 0.60061
        },
        "rougeLsum": {
            "precision": 0.56973,
            "recall": 0.6433,
            "fmeasure": 0.60061
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.3333333333333333,
            "3": 0.8571428571428571
        },
        "nist": 4.619594907751464,
        "bleu": 29.28551,
        "bleurt": 0.41708,
        "nubia": {
            "semantic_relation": 4.28161,
            "contradiction": 19.53799,
            "irrelevancy": 32.20146,
            "logical_agreement": 48.26055,
            "grammar_ref": 5.40206,
            "grammar_hyp": 5.00367,
            "nubia_score": 0.77261
        },
        "meteor": 0.39737925113319983,
        "bertscore": {
            "precision": 0.92364,
            "recall": 0.93647,
            "f1": 0.92841
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_153": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.71,
        "total_length": 143,
        "mean_pred_length": 13.0,
        "std_pred_length": 1.8586407545691703,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 15,
        "distinct-1": 0.6433566433566433,
        "vocab_size-1": 92,
        "unique-1": 72,
        "entropy-1": 6.128837589993329,
        "distinct-2": 0.8863636363636364,
        "vocab_size-2": 117,
        "unique-2": 104,
        "entropy-2": 6.805683702659,
        "cond_entropy-2": 0.4744796233446648,
        "distinct-3": 0.9173553719008265,
        "vocab_size-3": 111,
        "unique-3": 102,
        "entropy-3": 6.747335241388956,
        "cond_entropy-3": -0.05317643991721861,
        "total_length-nopunct": 129,
        "mean_pred_length-nopunct": 11.727272727272727,
        "std_pred_length-nopunct": 1.656442468935327,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.6821705426356589,
        "vocab_size-1-nopunct": 88,
        "unique-1-nopunct": 69,
        "entropy-1-nopunct": 6.163288666390266,
        "distinct-2-nopunct": 0.8813559322033898,
        "vocab_size-2-nopunct": 104,
        "unique-2-nopunct": 92,
        "entropy-2-nopunct": 6.632560210342114,
        "cond_entropy-2-nopunct": 0.5144183615735632,
        "distinct-3-nopunct": 0.9158878504672897,
        "vocab_size-3-nopunct": 98,
        "unique-3-nopunct": 90,
        "entropy-3-nopunct": 6.5661876639510135,
        "cond_entropy-3-nopunct": -0.05935468443580184,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65422,
            "recall": 0.65023,
            "fmeasure": 0.64461
        },
        "rouge2": {
            "precision": 0.4091,
            "recall": 0.4234,
            "fmeasure": 0.4088
        },
        "rougeL": {
            "precision": 0.55353,
            "recall": 0.56906,
            "fmeasure": 0.55373
        },
        "rougeLsum": {
            "precision": 0.55353,
            "recall": 0.56906,
            "fmeasure": 0.55373
        },
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.20689655172413793,
            "3": 0.7096774193548387
        },
        "nist": 4.632842797926513,
        "bleu": 31.36049,
        "bleurt": 0.26837,
        "nubia": {
            "semantic_relation": 4.19886,
            "contradiction": 19.19944,
            "irrelevancy": 33.04656,
            "logical_agreement": 47.754,
            "grammar_ref": 5.00152,
            "grammar_hyp": 4.93475,
            "nubia_score": 0.7003
        },
        "meteor": 0.3489669614301773,
        "bertscore": {
            "precision": 0.91788,
            "recall": 0.9138,
            "f1": 0.91529
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_176": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.79,
        "total_length": 351,
        "mean_pred_length": 15.26086956521739,
        "std_pred_length": 6.1092758505218425,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.6153846153846154,
        "vocab_size-1": 216,
        "unique-1": 184,
        "entropy-1": 7.003535935377368,
        "distinct-2": 0.9603658536585366,
        "vocab_size-2": 315,
        "unique-2": 307,
        "entropy-2": 8.259184131122696,
        "cond_entropy-2": 1.0402496425868413,
        "distinct-3": 1.0,
        "vocab_size-3": 305,
        "unique-3": 305,
        "entropy-3": 8.252665432450202,
        "cond_entropy-3": 0.0008992065419695889,
        "total_length-nopunct": 303,
        "mean_pred_length-nopunct": 13.173913043478262,
        "std_pred_length-nopunct": 5.4585566965847185,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.693069306930693,
        "vocab_size-1-nopunct": 210,
        "unique-1-nopunct": 182,
        "entropy-1-nopunct": 7.184341662467299,
        "distinct-2-nopunct": 0.9571428571428572,
        "vocab_size-2-nopunct": 268,
        "unique-2-nopunct": 261,
        "entropy-2-nopunct": 8.021194936564656,
        "cond_entropy-2-nopunct": 0.9074539201059394,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 257,
        "unique-3-nopunct": 257,
        "entropy-3-nopunct": 8.005624549193906,
        "cond_entropy-3-nopunct": -0.009788185624666735,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78845,
            "recall": 0.72368,
            "fmeasure": 0.73922
        },
        "rouge2": {
            "precision": 0.57315,
            "recall": 0.5269,
            "fmeasure": 0.53945
        },
        "rougeL": {
            "precision": 0.69961,
            "recall": 0.64622,
            "fmeasure": 0.65867
        },
        "rougeLsum": {
            "precision": 0.69961,
            "recall": 0.64622,
            "fmeasure": 0.65867
        },
        "local_recall": {
            "1": 0.1506849315068493,
            "2": 0.20930232558139536,
            "3": 0.811965811965812
        },
        "nist": 5.995869517042767,
        "bleu": 50.33454,
        "bleurt": 0.34159,
        "nubia": {
            "semantic_relation": 4.32812,
            "contradiction": 4.35503,
            "irrelevancy": 22.2447,
            "logical_agreement": 73.40027,
            "grammar_ref": 4.50686,
            "grammar_hyp": 4.7244,
            "nubia_score": 0.75664
        },
        "meteor": 0.3863376164098074,
        "bertscore": {
            "precision": 0.93648,
            "recall": 0.92426,
            "f1": 0.92716
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_177": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 42,
        "mean_pred_length": 14.0,
        "std_pred_length": 2.160246899469287,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 17,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 36,
        "unique-1": 32,
        "entropy-1": 5.070656113151929,
        "distinct-2": 1.0,
        "vocab_size-2": 39,
        "unique-2": 39,
        "entropy-2": 5.285402218862247,
        "cond_entropy-2": 0.11756909101075656,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.1154772174199358,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.160246899469287,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.92673368193777,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.13976873919382182,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.13750352374993471,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82222,
            "recall": 0.76276,
            "fmeasure": 0.78603
        },
        "rouge2": {
            "precision": 0.54305,
            "recall": 0.51729,
            "fmeasure": 0.5262
        },
        "rougeL": {
            "precision": 0.78148,
            "recall": 0.72216,
            "fmeasure": 0.74581
        },
        "rougeLsum": {
            "precision": 0.78148,
            "recall": 0.72216,
            "fmeasure": 0.74581
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.42857142857142855,
            "3": 0.8214285714285714
        },
        "nist": 4.987576507235156,
        "bleu": 40.67689,
        "bleurt": 0.22808,
        "nubia": {
            "semantic_relation": 4.45855,
            "contradiction": 1.0143,
            "irrelevancy": 36.39431,
            "logical_agreement": 62.59139,
            "grammar_ref": 5.80868,
            "grammar_hyp": 5.86233,
            "nubia_score": 0.79114
        },
        "meteor": 0.4084309792269251,
        "bertscore": {
            "precision": 0.93313,
            "recall": 0.93446,
            "f1": 0.93043
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_154": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.675,
        "msttr-100_nopunct": 0.715,
        "total_length": 254,
        "mean_pred_length": 14.941176470588236,
        "std_pred_length": 5.87587879019755,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.5748031496062992,
        "vocab_size-1": 146,
        "unique-1": 115,
        "entropy-1": 6.539292873516526,
        "distinct-2": 0.9367088607594937,
        "vocab_size-2": 222,
        "unique-2": 211,
        "entropy-2": 7.745283333286488,
        "cond_entropy-2": 1.0167617362428547,
        "distinct-3": 0.9818181818181818,
        "vocab_size-3": 216,
        "unique-3": 212,
        "entropy-3": 7.744996077161009,
        "cond_entropy-3": 0.0017073737173094554,
        "total_length-nopunct": 224,
        "mean_pred_length-nopunct": 13.176470588235293,
        "std_pred_length-nopunct": 4.925746215401958,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6383928571428571,
        "vocab_size-1-nopunct": 143,
        "unique-1-nopunct": 114,
        "entropy-1-nopunct": 6.666108929838753,
        "distinct-2-nopunct": 0.9371980676328503,
        "vocab_size-2-nopunct": 194,
        "unique-2-nopunct": 185,
        "entropy-2-nopunct": 7.548559421267414,
        "cond_entropy-2-nopunct": 0.9290509473009244,
        "distinct-3-nopunct": 0.9842105263157894,
        "vocab_size-3-nopunct": 187,
        "unique-3-nopunct": 184,
        "entropy-3-nopunct": 7.53827666096254,
        "cond_entropy-3-nopunct": -0.007841875484166894,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.63949,
            "recall": 0.6252,
            "fmeasure": 0.62368
        },
        "rouge2": {
            "precision": 0.34498,
            "recall": 0.34072,
            "fmeasure": 0.33822
        },
        "rougeL": {
            "precision": 0.51614,
            "recall": 0.51724,
            "fmeasure": 0.50982
        },
        "rougeLsum": {
            "precision": 0.51614,
            "recall": 0.51724,
            "fmeasure": 0.50982
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.4098360655737705,
            "3": 0.6583850931677019
        },
        "nist": 4.993157632121475,
        "bleu": 27.75041,
        "bleurt": 0.19425,
        "nubia": {
            "semantic_relation": 4.00836,
            "contradiction": 9.0348,
            "irrelevancy": 44.26882,
            "logical_agreement": 46.69638,
            "grammar_ref": 4.51289,
            "grammar_hyp": 4.56753,
            "nubia_score": 0.67781
        },
        "meteor": 0.3150417822978122,
        "bertscore": {
            "precision": 0.90378,
            "recall": 0.89882,
            "f1": 0.89941
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_210": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.8025,
        "total_length": 470,
        "mean_pred_length": 15.161290322580646,
        "std_pred_length": 5.18743378780005,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.5702127659574469,
        "vocab_size-1": 268,
        "unique-1": 209,
        "entropy-1": 7.313284128277989,
        "distinct-2": 0.9111617312072893,
        "vocab_size-2": 400,
        "unique-2": 375,
        "entropy-2": 8.566473819764044,
        "cond_entropy-2": 1.0137366886271102,
        "distinct-3": 0.9705882352941176,
        "vocab_size-3": 396,
        "unique-3": 387,
        "entropy-3": 8.608051169161563,
        "cond_entropy-3": 0.04294916950253605,
        "total_length-nopunct": 407,
        "mean_pred_length-nopunct": 13.129032258064516,
        "std_pred_length-nopunct": 4.577236350884958,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6461916461916462,
        "vocab_size-1-nopunct": 263,
        "unique-1-nopunct": 208,
        "entropy-1-nopunct": 7.535967505191113,
        "distinct-2-nopunct": 0.9122340425531915,
        "vocab_size-2-nopunct": 343,
        "unique-2-nopunct": 324,
        "entropy-2-nopunct": 8.339445625641464,
        "cond_entropy-2-nopunct": 0.8704877729709618,
        "distinct-3-nopunct": 0.9710144927536232,
        "vocab_size-3-nopunct": 335,
        "unique-3-nopunct": 328,
        "entropy-3-nopunct": 8.365917298023481,
        "cond_entropy-3-nopunct": 0.027919541963686283,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78148,
            "recall": 0.71983,
            "fmeasure": 0.73611
        },
        "rouge2": {
            "precision": 0.53189,
            "recall": 0.49643,
            "fmeasure": 0.50104
        },
        "rougeL": {
            "precision": 0.65146,
            "recall": 0.60062,
            "fmeasure": 0.6121
        },
        "rougeLsum": {
            "precision": 0.65146,
            "recall": 0.60062,
            "fmeasure": 0.6121
        },
        "local_recall": {
            "1": 0.22448979591836735,
            "2": 0.4845360824742268,
            "3": 0.7953020134228188
        },
        "nist": 6.49943115209495,
        "bleu": 45.10225,
        "bleurt": 0.28394,
        "nubia": {
            "semantic_relation": 4.25246,
            "contradiction": 7.32876,
            "irrelevancy": 29.8412,
            "logical_agreement": 62.83004,
            "grammar_ref": 4.50561,
            "grammar_hyp": 4.5248,
            "nubia_score": 0.73863
        },
        "meteor": 0.39879003328823187,
        "bertscore": {
            "precision": 0.93273,
            "recall": 0.92808,
            "f1": 0.92854
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_256": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.71,
        "total_length": 151,
        "mean_pred_length": 15.1,
        "std_pred_length": 4.459820624195552,
        "median_pred_length": 16.5,
        "min_pred_length": 7,
        "max_pred_length": 21,
        "distinct-1": 0.6821192052980133,
        "vocab_size-1": 103,
        "unique-1": 87,
        "entropy-1": 6.270509150214056,
        "distinct-2": 0.9787234042553191,
        "vocab_size-2": 138,
        "unique-2": 135,
        "entropy-2": 7.09699816090941,
        "cond_entropy-2": 0.6595363507112253,
        "distinct-3": 0.9923664122137404,
        "vocab_size-3": 130,
        "unique-3": 129,
        "entropy-3": 7.018155825964931,
        "cond_entropy-3": -0.075593999716305,
        "total_length-nopunct": 133,
        "mean_pred_length-nopunct": 13.3,
        "std_pred_length-nopunct": 4.124318125460256,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7368421052631579,
        "vocab_size-1-nopunct": 98,
        "unique-1-nopunct": 84,
        "entropy-1-nopunct": 6.293453017963962,
        "distinct-2-nopunct": 0.975609756097561,
        "vocab_size-2-nopunct": 120,
        "unique-2-nopunct": 117,
        "entropy-2-nopunct": 6.893734017534349,
        "cond_entropy-2-nopunct": 0.6540882692888813,
        "distinct-3-nopunct": 0.9911504424778761,
        "vocab_size-3-nopunct": 112,
        "unique-3-nopunct": 111,
        "entropy-3-nopunct": 6.802479847370959,
        "cond_entropy-3-nopunct": -0.08693731283555656,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8091,
            "recall": 0.73935,
            "fmeasure": 0.76484
        },
        "rouge2": {
            "precision": 0.55892,
            "recall": 0.51919,
            "fmeasure": 0.53258
        },
        "rougeL": {
            "precision": 0.73793,
            "recall": 0.67102,
            "fmeasure": 0.6963
        },
        "rougeLsum": {
            "precision": 0.73793,
            "recall": 0.67102,
            "fmeasure": 0.6963
        },
        "local_recall": {
            "1": 0.2647058823529412,
            "2": 0.45161290322580644,
            "3": 0.826530612244898
        },
        "nist": 6.03934867127872,
        "bleu": 51.42744,
        "bleurt": 0.30051,
        "nubia": {
            "semantic_relation": 4.24495,
            "contradiction": 8.1492,
            "irrelevancy": 40.70612,
            "logical_agreement": 51.14468,
            "grammar_ref": 4.57625,
            "grammar_hyp": 4.8921,
            "nubia_score": 0.70543
        },
        "meteor": 0.39567893480674343,
        "bertscore": {
            "precision": 0.93985,
            "recall": 0.92379,
            "f1": 0.92831
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_282": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9545454545454546,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.368522527728205,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.02812389937955851,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.03126257645096009,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.81871,
            "fmeasure": 0.76282
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.46187,
            "fmeasure": 0.42864
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.49123,
            "fmeasure": 0.45769
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.49123,
            "fmeasure": 0.45769
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6923076923076923
        },
        "nist": 2.1157077474846457,
        "bleu": 6.42945,
        "bleurt": 0.37935,
        "nubia": {
            "semantic_relation": 4.9228,
            "contradiction": 0.12479,
            "irrelevancy": 2.30578,
            "logical_agreement": 97.56943,
            "grammar_ref": 4.92793,
            "grammar_hyp": 4.58189,
            "nubia_score": 0.94521
        },
        "meteor": 0.3334542336538618,
        "bertscore": {
            "precision": 0.88287,
            "recall": 0.90695,
            "f1": 0.89444
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_258": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.71,
        "total_length": 134,
        "mean_pred_length": 14.88888888888889,
        "std_pred_length": 5.586580039989571,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 29,
        "distinct-1": 0.6567164179104478,
        "vocab_size-1": 88,
        "unique-1": 73,
        "entropy-1": 6.000102698729006,
        "distinct-2": 0.96,
        "vocab_size-2": 120,
        "unique-2": 115,
        "entropy-2": 6.885784284662096,
        "cond_entropy-2": 0.7232537905056676,
        "distinct-3": 1.0,
        "vocab_size-3": 116,
        "unique-3": 116,
        "entropy-3": 6.857980995127556,
        "cond_entropy-3": -0.02159639298279068,
        "total_length-nopunct": 118,
        "mean_pred_length-nopunct": 13.11111111111111,
        "std_pred_length-nopunct": 4.7945442245314265,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.711864406779661,
        "vocab_size-1-nopunct": 84,
        "unique-1-nopunct": 73,
        "entropy-1-nopunct": 6.004482804084024,
        "distinct-2-nopunct": 0.9541284403669725,
        "vocab_size-2-nopunct": 104,
        "unique-2-nopunct": 99,
        "entropy-2-nopunct": 6.67644120551086,
        "cond_entropy-2-nopunct": 0.744467045532349,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 100,
        "unique-3-nopunct": 100,
        "entropy-3-nopunct": 6.6438561897747395,
        "cond_entropy-3-nopunct": -0.024328135002201493,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70238,
            "recall": 0.71149,
            "fmeasure": 0.6919
        },
        "rouge2": {
            "precision": 0.4472,
            "recall": 0.48464,
            "fmeasure": 0.45475
        },
        "rougeL": {
            "precision": 0.65393,
            "recall": 0.67172,
            "fmeasure": 0.6481
        },
        "rougeLsum": {
            "precision": 0.65393,
            "recall": 0.67172,
            "fmeasure": 0.6481
        },
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.35714285714285715,
            "3": 0.7402597402597403
        },
        "nist": 4.6556923166541555,
        "bleu": 38.56172,
        "bleurt": 0.36486,
        "nubia": {
            "semantic_relation": 3.93285,
            "contradiction": 29.15229,
            "irrelevancy": 27.32964,
            "logical_agreement": 43.51806,
            "grammar_ref": 5.16318,
            "grammar_hyp": 5.0365,
            "nubia_score": 0.61537
        },
        "meteor": 0.34344154583140585,
        "bertscore": {
            "precision": 0.9287,
            "recall": 0.92318,
            "f1": 0.92508
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_259": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 78,
        "mean_pred_length": 15.6,
        "std_pred_length": 3.2,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 21,
        "distinct-1": 0.7051282051282052,
        "vocab_size-1": 55,
        "unique-1": 48,
        "entropy-1": 5.424691604634467,
        "distinct-2": 0.9452054794520548,
        "vocab_size-2": 69,
        "unique-2": 66,
        "entropy-2": 6.069894593096967,
        "cond_entropy-2": 0.5451195993762201,
        "distinct-3": 1.0,
        "vocab_size-3": 68,
        "unique-3": 68,
        "entropy-3": 6.087462841250345,
        "cond_entropy-3": 0.026386627990373307,
        "total_length-nopunct": 68,
        "mean_pred_length-nopunct": 13.6,
        "std_pred_length-nopunct": 2.4979991993593593,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7794117647058824,
        "vocab_size-1-nopunct": 53,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.441637150648966,
        "distinct-2-nopunct": 0.9365079365079365,
        "vocab_size-2-nopunct": 59,
        "unique-2-nopunct": 56,
        "entropy-2-nopunct": 5.838313455211611,
        "cond_entropy-2-nopunct": 0.44793231175323034,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.85798099512757,
        "cond_entropy-3-nopunct": 0.03164740787185325,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77656,
            "recall": 0.87133,
            "fmeasure": 0.81465
        },
        "rouge2": {
            "precision": 0.525,
            "recall": 0.57616,
            "fmeasure": 0.54323
        },
        "rougeL": {
            "precision": 0.66841,
            "recall": 0.73131,
            "fmeasure": 0.69241
        },
        "rougeLsum": {
            "precision": 0.66841,
            "recall": 0.73131,
            "fmeasure": 0.69241
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.2222222222222222,
            "3": 0.9
        },
        "nist": 5.037500218183444,
        "bleu": 48.07095,
        "bleurt": 0.45028,
        "nubia": {
            "semantic_relation": 4.68988,
            "contradiction": 0.71281,
            "irrelevancy": 3.0418,
            "logical_agreement": 96.24538,
            "grammar_ref": 4.84964,
            "grammar_hyp": 4.63296,
            "nubia_score": 0.86813
        },
        "meteor": 0.4696113327568217,
        "bertscore": {
            "precision": 0.94595,
            "recall": 0.94961,
            "f1": 0.94774
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_212": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.7,
        "total_length": 252,
        "mean_pred_length": 16.8,
        "std_pred_length": 8.01831237439234,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 41,
        "distinct-1": 0.5674603174603174,
        "vocab_size-1": 143,
        "unique-1": 114,
        "entropy-1": 6.51368741785526,
        "distinct-2": 0.8987341772151899,
        "vocab_size-2": 213,
        "unique-2": 196,
        "entropy-2": 7.659778428195808,
        "cond_entropy-2": 0.991451890722546,
        "distinct-3": 0.954954954954955,
        "vocab_size-3": 212,
        "unique-3": 203,
        "entropy-3": 7.700925382106114,
        "cond_entropy-3": 0.056617549903769895,
        "total_length-nopunct": 224,
        "mean_pred_length-nopunct": 14.933333333333334,
        "std_pred_length-nopunct": 7.307226255943876,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.6116071428571429,
        "vocab_size-1-nopunct": 137,
        "unique-1-nopunct": 110,
        "entropy-1-nopunct": 6.549798549399788,
        "distinct-2-nopunct": 0.8995215311004785,
        "vocab_size-2-nopunct": 188,
        "unique-2-nopunct": 174,
        "entropy-2-nopunct": 7.476427732528314,
        "cond_entropy-2-nopunct": 0.9958685523490073,
        "distinct-3-nopunct": 0.9587628865979382,
        "vocab_size-3-nopunct": 186,
        "unique-3-nopunct": 179,
        "entropy-3-nopunct": 7.513547442691416,
        "cond_entropy-3-nopunct": 0.05497523074710543,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76077,
            "recall": 0.65281,
            "fmeasure": 0.69381
        },
        "rouge2": {
            "precision": 0.51567,
            "recall": 0.44196,
            "fmeasure": 0.47064
        },
        "rougeL": {
            "precision": 0.66944,
            "recall": 0.57057,
            "fmeasure": 0.60955
        },
        "rougeLsum": {
            "precision": 0.66944,
            "recall": 0.57057,
            "fmeasure": 0.60955
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.2875,
            "3": 0.7309941520467836
        },
        "nist": 5.25453784132848,
        "bleu": 41.04777,
        "bleurt": 0.15503,
        "nubia": {
            "semantic_relation": 4.13005,
            "contradiction": 11.07023,
            "irrelevancy": 30.77606,
            "logical_agreement": 58.15372,
            "grammar_ref": 4.73267,
            "grammar_hyp": 4.92091,
            "nubia_score": 0.66816
        },
        "meteor": 0.35820506143811665,
        "bertscore": {
            "precision": 0.91179,
            "recall": 0.9076,
            "f1": 0.90718
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_284": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.40476,
            "recall": 0.21225,
            "fmeasure": 0.27846
        },
        "rouge2": {
            "precision": 0.15385,
            "recall": 0.08,
            "fmeasure": 0.10526
        },
        "rougeL": {
            "precision": 0.40476,
            "recall": 0.21225,
            "fmeasure": 0.27846
        },
        "rougeLsum": {
            "precision": 0.40476,
            "recall": 0.21225,
            "fmeasure": 0.27846
        },
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.29411764705882354
        },
        "nist": 0.36785566848033113,
        "bleu": 6.01235,
        "bleurt": -0.86324,
        "nubia": {
            "semantic_relation": 2.2197,
            "contradiction": 26.37115,
            "irrelevancy": 64.8392,
            "logical_agreement": 8.78965,
            "grammar_ref": 4.71547,
            "grammar_hyp": 5.14073,
            "nubia_score": 0.11573
        },
        "meteor": 0.11924985522881126,
        "bertscore": {
            "precision": 0.82673,
            "recall": 0.78136,
            "f1": 0.8034
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_180": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 42,
        "msttr-100": 0.755,
        "msttr-100_nopunct": 0.805,
        "total_length": 680,
        "mean_pred_length": 16.19047619047619,
        "std_pred_length": 4.727015041420332,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.5838235294117647,
        "vocab_size-1": 397,
        "unique-1": 333,
        "entropy-1": 7.743365108962219,
        "distinct-2": 0.9278996865203761,
        "vocab_size-2": 592,
        "unique-2": 562,
        "entropy-2": 9.140619529878553,
        "cond_entropy-2": 1.1497151811732578,
        "distinct-3": 0.9899328859060402,
        "vocab_size-3": 590,
        "unique-3": 585,
        "entropy-3": 9.19776770250542,
        "cond_entropy-3": 0.06625104095452053,
        "total_length-nopunct": 600,
        "mean_pred_length-nopunct": 14.285714285714286,
        "std_pred_length-nopunct": 4.266624149448022,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6533333333333333,
        "vocab_size-1-nopunct": 392,
        "unique-1-nopunct": 333,
        "entropy-1-nopunct": 7.965064536606003,
        "distinct-2-nopunct": 0.9247311827956989,
        "vocab_size-2-nopunct": 516,
        "unique-2-nopunct": 490,
        "entropy-2-nopunct": 8.936318466812294,
        "cond_entropy-2-nopunct": 1.0442607840780798,
        "distinct-3-nopunct": 0.9903100775193798,
        "vocab_size-3-nopunct": 511,
        "unique-3-nopunct": 507,
        "entropy-3-nopunct": 8.990384450186465,
        "cond_entropy-3-nopunct": 0.06741427696094184,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76741,
            "recall": 0.75141,
            "fmeasure": 0.74806
        },
        "rouge2": {
            "precision": 0.55144,
            "recall": 0.55094,
            "fmeasure": 0.5428
        },
        "rougeL": {
            "precision": 0.66517,
            "recall": 0.65449,
            "fmeasure": 0.65029
        },
        "rougeLsum": {
            "precision": 0.66517,
            "recall": 0.65449,
            "fmeasure": 0.65029
        },
        "local_recall": {
            "1": 0.17391304347826086,
            "2": 0.5268817204301075,
            "3": 0.7665289256198347
        },
        "nist": 6.881779372543499,
        "bleu": 47.02364,
        "bleurt": 0.34066,
        "nubia": {
            "semantic_relation": 4.30143,
            "contradiction": 10.72217,
            "irrelevancy": 29.43832,
            "logical_agreement": 59.83952,
            "grammar_ref": 4.60727,
            "grammar_hyp": 4.7344,
            "nubia_score": 0.73213
        },
        "meteor": 0.41269645242240727,
        "bertscore": {
            "precision": 0.93547,
            "recall": 0.93434,
            "f1": 0.93344
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_215": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.75,
        "msttr-100_nopunct": NaN,
        "total_length": 108,
        "mean_pred_length": 18.0,
        "std_pred_length": 11.474609652039003,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 42,
        "distinct-1": 0.75,
        "vocab_size-1": 81,
        "unique-1": 67,
        "entropy-1": 6.092611692577068,
        "distinct-2": 0.9705882352941176,
        "vocab_size-2": 99,
        "unique-2": 96,
        "entropy-2": 6.613601812559735,
        "cond_entropy-2": 0.4078909028570817,
        "distinct-3": 0.9895833333333334,
        "vocab_size-3": 95,
        "unique-3": 94,
        "entropy-3": 6.5641291673878275,
        "cond_entropy-3": -0.0457961745836727,
        "total_length-nopunct": 93,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 10.372238588334406,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.8279569892473119,
        "vocab_size-1-nopunct": 77,
        "unique-1-nopunct": 67,
        "entropy-1-nopunct": 6.1046816932954915,
        "distinct-2-nopunct": 0.9885057471264368,
        "vocab_size-2-nopunct": 86,
        "unique-2-nopunct": 85,
        "entropy-2-nopunct": 6.419954990101596,
        "cond_entropy-2-nopunct": 0.34523723596560224,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 81,
        "unique-3-nopunct": 81,
        "entropy-3-nopunct": 6.339850002884614,
        "cond_entropy-3-nopunct": -0.07840213493941198,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72835,
            "recall": 0.53566,
            "fmeasure": 0.59427
        },
        "rouge2": {
            "precision": 0.4355,
            "recall": 0.31939,
            "fmeasure": 0.35266
        },
        "rougeL": {
            "precision": 0.58597,
            "recall": 0.45057,
            "fmeasure": 0.49455
        },
        "rougeLsum": {
            "precision": 0.58597,
            "recall": 0.45057,
            "fmeasure": 0.49455
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.2777777777777778,
            "3": 0.6493506493506493
        },
        "nist": 4.671917629903467,
        "bleu": 34.15392,
        "bleurt": -0.15985,
        "nubia": {
            "semantic_relation": 3.70164,
            "contradiction": 17.52638,
            "irrelevancy": 28.03135,
            "logical_agreement": 54.44227,
            "grammar_ref": 4.85958,
            "grammar_hyp": 5.35075,
            "nubia_score": 0.54742
        },
        "meteor": 0.2883705499247104,
        "bertscore": {
            "precision": 0.88531,
            "recall": 0.85281,
            "f1": 0.86305
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_182": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.79,
        "total_length": 214,
        "mean_pred_length": 15.285714285714286,
        "std_pred_length": 4.65109159888563,
        "median_pred_length": 14.5,
        "min_pred_length": 5,
        "max_pred_length": 23,
        "distinct-1": 0.6355140186915887,
        "vocab_size-1": 136,
        "unique-1": 107,
        "entropy-1": 6.62115999144775,
        "distinct-2": 0.955,
        "vocab_size-2": 191,
        "unique-2": 183,
        "entropy-2": 7.5500817522639245,
        "cond_entropy-2": 0.7408284059188378,
        "distinct-3": 0.9946236559139785,
        "vocab_size-3": 185,
        "unique-3": 184,
        "entropy-3": 7.528406122936004,
        "cond_entropy-3": -0.025370026504524426,
        "total_length-nopunct": 185,
        "mean_pred_length-nopunct": 13.214285714285714,
        "std_pred_length-nopunct": 4.020990841439305,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7135135135135136,
        "vocab_size-1-nopunct": 132,
        "unique-1-nopunct": 107,
        "entropy-1-nopunct": 6.729199687576261,
        "distinct-2-nopunct": 0.9532163742690059,
        "vocab_size-2-nopunct": 163,
        "unique-2-nopunct": 156,
        "entropy-2-nopunct": 7.319870716627625,
        "cond_entropy-2-nopunct": 0.6295340835568578,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 157,
        "unique-3-nopunct": 157,
        "entropy-3-nopunct": 7.294620748891623,
        "cond_entropy-3-nopunct": -0.029251590821255398,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71916,
            "recall": 0.65847,
            "fmeasure": 0.67544
        },
        "rouge2": {
            "precision": 0.46418,
            "recall": 0.4325,
            "fmeasure": 0.44012
        },
        "rougeL": {
            "precision": 0.63183,
            "recall": 0.56664,
            "fmeasure": 0.58833
        },
        "rougeLsum": {
            "precision": 0.63183,
            "recall": 0.56664,
            "fmeasure": 0.58833
        },
        "local_recall": {
            "1": 0.11475409836065574,
            "2": 0.4,
            "3": 0.6289308176100629
        },
        "nist": 4.715242333252484,
        "bleu": 37.53407,
        "bleurt": 0.2037,
        "nubia": {
            "semantic_relation": 3.98671,
            "contradiction": 9.32816,
            "irrelevancy": 41.52064,
            "logical_agreement": 49.15119,
            "grammar_ref": 4.54419,
            "grammar_hyp": 4.5106,
            "nubia_score": 0.692
        },
        "meteor": 0.34004147907234944,
        "bertscore": {
            "precision": 0.91931,
            "recall": 0.90486,
            "f1": 0.90849
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_285": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.82,
        "msttr-100_nopunct": 0.84,
        "total_length": 129,
        "mean_pred_length": 18.428571428571427,
        "std_pred_length": 7.907630001770312,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.751937984496124,
        "vocab_size-1": 97,
        "unique-1": 82,
        "entropy-1": 6.346309135184346,
        "distinct-2": 1.0,
        "vocab_size-2": 122,
        "unique-2": 122,
        "entropy-2": 6.930737337562902,
        "cond_entropy-2": 0.4504480945233805,
        "distinct-3": 1.0,
        "vocab_size-3": 115,
        "unique-3": 115,
        "entropy-3": 6.84549005094439,
        "cond_entropy-3": -0.08524728661851073,
        "total_length-nopunct": 112,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 6.718843437888484,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8214285714285714,
        "vocab_size-1-nopunct": 92,
        "unique-1-nopunct": 79,
        "entropy-1-nopunct": 6.394277578249644,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 105,
        "unique-2-nopunct": 105,
        "entropy-2-nopunct": 6.714245517666113,
        "cond_entropy-2-nopunct": 0.34750642900366463,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 98,
        "unique-3-nopunct": 98,
        "entropy-3-nopunct": 6.614709844115218,
        "cond_entropy-3-nopunct": -0.09953567355091418,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86327,
            "recall": 0.73516,
            "fmeasure": 0.78154
        },
        "rouge2": {
            "precision": 0.57839,
            "recall": 0.50232,
            "fmeasure": 0.5289
        },
        "rougeL": {
            "precision": 0.68679,
            "recall": 0.58719,
            "fmeasure": 0.62255
        },
        "rougeLsum": {
            "precision": 0.68679,
            "recall": 0.58719,
            "fmeasure": 0.62255
        },
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.8064516129032258,
            "3": 0.7530864197530864
        },
        "nist": 5.623875180181559,
        "bleu": 49.69371,
        "bleurt": 0.22618,
        "nubia": {
            "semantic_relation": 4.38993,
            "contradiction": 1.33204,
            "irrelevancy": 21.66227,
            "logical_agreement": 77.00569,
            "grammar_ref": 4.72263,
            "grammar_hyp": 5.13427,
            "nubia_score": 0.72964
        },
        "meteor": 0.4133937128756048,
        "bertscore": {
            "precision": 0.94106,
            "recall": 0.91077,
            "f1": 0.92507
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_183": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 10,
        "unique-1": 8,
        "entropy-1": 3.2516291673878226,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.23810548155250458,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.9219280948873623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.18133023988828356,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.56667,
            "recall": 0.70833,
            "fmeasure": 0.62963
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.28571,
            "fmeasure": 0.25
        },
        "rougeL": {
            "precision": 0.46667,
            "recall": 0.53704,
            "fmeasure": 0.49903
        },
        "rougeLsum": {
            "precision": 0.46667,
            "recall": 0.53704,
            "fmeasure": 0.49903
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nist": 1.8927773671893204,
        "bleu": 10.60031,
        "bleurt": -0.13276,
        "nubia": {
            "semantic_relation": 4.45349,
            "contradiction": 0.31638,
            "irrelevancy": 4.9731,
            "logical_agreement": 94.71052,
            "grammar_ref": 4.0172,
            "grammar_hyp": 3.76575,
            "nubia_score": 0.88104
        },
        "meteor": 0.24992181992221726,
        "bertscore": {
            "precision": 0.8843,
            "recall": 0.89744,
            "f1": 0.88661
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 414,
        "msttr-100": 0.51523,
        "msttr-100_nopunct": 0.53827,
        "total_length": 8616,
        "mean_pred_length": 20.81159420289855,
        "std_pred_length": 7.424548709886254,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 57,
        "distinct-1": 0.15064995357474467,
        "vocab_size-1": 1298,
        "unique-1": 570,
        "entropy-1": 7.854728317779319,
        "distinct-2": 0.42123872226286274,
        "vocab_size-2": 3455,
        "unique-2": 2160,
        "entropy-2": 10.904143722478409,
        "cond_entropy-2": 2.8588058464056707,
        "distinct-3": 0.6296866974833076,
        "vocab_size-3": 4904,
        "unique-3": 3685,
        "entropy-3": 11.85182675239294,
        "cond_entropy-3": 1.0069713451007587,
        "total_length-nopunct": 7529,
        "mean_pred_length-nopunct": 18.185990338164252,
        "std_pred_length-nopunct": 6.666427304391578,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.17133749501925888,
        "vocab_size-1-nopunct": 1290,
        "unique-1-nopunct": 569,
        "entropy-1-nopunct": 8.165604413693003,
        "distinct-2-nopunct": 0.4349964862965566,
        "vocab_size-2-nopunct": 3095,
        "unique-2-nopunct": 1993,
        "entropy-2-nopunct": 10.775729789520655,
        "cond_entropy-2-nopunct": 2.771893354408609,
        "distinct-3-nopunct": 0.6396060289509029,
        "vocab_size-3-nopunct": 4286,
        "unique-3-nopunct": 3294,
        "entropy-3-nopunct": 11.653827790335727,
        "cond_entropy-3-nopunct": 0.9298059407144051,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.68626,
            "recall": 0.6907,
            "fmeasure": 0.68134
        },
        "rouge2": {
            "precision": 0.41863,
            "recall": 0.42165,
            "fmeasure": 0.41564
        },
        "rougeL": {
            "precision": 0.54897,
            "recall": 0.55367,
            "fmeasure": 0.54533
        },
        "rougeLsum": {
            "precision": 0.54897,
            "recall": 0.55367,
            "fmeasure": 0.54533
        },
        "local_recall": {
            "1": 0.21426541631145213,
            "2": 0.527373179306881,
            "3": 0.7814012738853503,
            "4": 0.7272727272727273,
            "5": 0.875
        },
        "nist": 7.504313035531588,
        "bleu": 38.25794,
        "bleurt": 0.03263,
        "nubia": {
            "semantic_relation": 4.1418,
            "contradiction": 17.64055,
            "irrelevancy": 10.29389,
            "logical_agreement": 72.06556,
            "grammar_ref": 4.63681,
            "grammar_hyp": 4.62912,
            "nubia_score": 0.70007
        },
        "meteor": 0.35237767863902697,
        "bertscore": {
            "precision": 0.89955,
            "recall": 0.90328,
            "f1": 0.90008
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_260": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 22,
        "msttr-100": 0.71667,
        "msttr-100_nopunct": 0.775,
        "total_length": 333,
        "mean_pred_length": 15.136363636363637,
        "std_pred_length": 6.009806036390969,
        "median_pred_length": 14.5,
        "min_pred_length": 8,
        "max_pred_length": 36,
        "distinct-1": 0.5945945945945946,
        "vocab_size-1": 198,
        "unique-1": 155,
        "entropy-1": 7.024126949340358,
        "distinct-2": 0.8971061093247589,
        "vocab_size-2": 279,
        "unique-2": 254,
        "entropy-2": 8.056415665594226,
        "cond_entropy-2": 0.812700406221906,
        "distinct-3": 0.9584775086505191,
        "vocab_size-3": 277,
        "unique-3": 267,
        "entropy-3": 8.086656564838627,
        "cond_entropy-3": 0.033479004088035794,
        "total_length-nopunct": 289,
        "mean_pred_length-nopunct": 13.136363636363637,
        "std_pred_length-nopunct": 5.09273506214717,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6643598615916955,
        "vocab_size-1-nopunct": 192,
        "unique-1-nopunct": 154,
        "entropy-1-nopunct": 7.15909268888747,
        "distinct-2-nopunct": 0.9063670411985019,
        "vocab_size-2-nopunct": 242,
        "unique-2-nopunct": 223,
        "entropy-2-nopunct": 7.854630201318029,
        "cond_entropy-2-nopunct": 0.7403165702459802,
        "distinct-3-nopunct": 0.963265306122449,
        "vocab_size-3-nopunct": 236,
        "unique-3-nopunct": 228,
        "entropy-3-nopunct": 7.860087377769283,
        "cond_entropy-3-nopunct": 0.015797772647630267,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85424,
            "recall": 0.83502,
            "fmeasure": 0.84085
        },
        "rouge2": {
            "precision": 0.68408,
            "recall": 0.66397,
            "fmeasure": 0.67144
        },
        "rougeL": {
            "precision": 0.78678,
            "recall": 0.76803,
            "fmeasure": 0.77427
        },
        "rougeLsum": {
            "precision": 0.78678,
            "recall": 0.76803,
            "fmeasure": 0.77427
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.16666666666666666,
            "3": 0.8656126482213439
        },
        "nist": 6.960152918838344,
        "bleu": 64.37513,
        "bleurt": 0.52816,
        "nubia": {
            "semantic_relation": 4.55412,
            "contradiction": 0.94762,
            "irrelevancy": 27.98015,
            "logical_agreement": 71.07223,
            "grammar_ref": 4.36588,
            "grammar_hyp": 4.51199,
            "nubia_score": 0.84311
        },
        "meteor": 0.4963486684163098,
        "bertscore": {
            "precision": 0.96089,
            "recall": 0.95443,
            "f1": 0.95664
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_286": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 10.0,
        "std_pred_length": 4.06201920231798,
        "median_pred_length": 9.5,
        "min_pred_length": 5,
        "max_pred_length": 16,
        "distinct-1": 0.7,
        "vocab_size-1": 28,
        "unique-1": 20,
        "entropy-1": 4.634183719779189,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 34,
        "unique-2": 32,
        "entropy-2": 5.058813890331199,
        "cond_entropy-2": 0.2788239900084761,
        "distinct-3": 0.96875,
        "vocab_size-3": 31,
        "unique-3": 30,
        "entropy-3": 4.9375,
        "cond_entropy-3": -0.16992500144231226,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 8.25,
        "std_pred_length-nopunct": 3.2691742076555053,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7878787878787878,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.597276316262592,
        "distinct-2-nopunct": 0.9655172413793104,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.789015477886192,
        "cond_entropy-2-nopunct": 0.12979118616368115,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.21412480535284767,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86189,
            "recall": 0.66815,
            "fmeasure": 0.72407
        },
        "rouge2": {
            "precision": 0.63575,
            "recall": 0.52181,
            "fmeasure": 0.55323
        },
        "rougeL": {
            "precision": 0.86189,
            "recall": 0.66815,
            "fmeasure": 0.72407
        },
        "rougeLsum": {
            "precision": 0.86189,
            "recall": 0.66815,
            "fmeasure": 0.72407
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.42857142857142855,
            "3": 0.6451612903225806
        },
        "nist": 2.919231523957593,
        "bleu": 41.15819,
        "bleurt": 0.41364,
        "nubia": {
            "semantic_relation": 4.28472,
            "contradiction": 0.43195,
            "irrelevancy": 23.38715,
            "logical_agreement": 76.18091,
            "grammar_ref": 4.09757,
            "grammar_hyp": 4.43884,
            "nubia_score": 0.82427
        },
        "meteor": 0.3751451121394146,
        "bertscore": {
            "precision": 0.95808,
            "recall": 0.93101,
            "f1": 0.94365
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 382,
        "msttr-100": 0.50314,
        "msttr-100_nopunct": 0.52333,
        "total_length": 10292,
        "mean_pred_length": 26.94240837696335,
        "std_pred_length": 8.140573352894533,
        "median_pred_length": 26.0,
        "min_pred_length": 12,
        "max_pred_length": 71,
        "distinct-1": 0.12291099883404587,
        "vocab_size-1": 1265,
        "unique-1": 442,
        "entropy-1": 7.912065431504491,
        "distinct-2": 0.36014127144298685,
        "vocab_size-2": 3569,
        "unique-2": 1982,
        "entropy-2": 10.921141966301937,
        "cond_entropy-2": 2.8590839564924537,
        "distinct-3": 0.5600335852225021,
        "vocab_size-3": 5336,
        "unique-3": 3727,
        "entropy-3": 11.906951719692055,
        "cond_entropy-3": 1.0247397229786295,
        "total_length-nopunct": 9091,
        "mean_pred_length-nopunct": 23.798429319371728,
        "std_pred_length-nopunct": 7.4572918490189215,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 65,
        "distinct-1-nopunct": 0.13815861841381585,
        "vocab_size-1-nopunct": 1256,
        "unique-1-nopunct": 441,
        "entropy-1-nopunct": 8.195762466508654,
        "distinct-2-nopunct": 0.377425651624756,
        "vocab_size-2-nopunct": 3287,
        "unique-2-nopunct": 1908,
        "entropy-2-nopunct": 10.841788392393145,
        "cond_entropy-2-nopunct": 2.7620252953429616,
        "distinct-3-nopunct": 0.5766782754893719,
        "vocab_size-3-nopunct": 4802,
        "unique-3-nopunct": 3450,
        "entropy-3-nopunct": 11.763327785757028,
        "cond_entropy-3-nopunct": 0.9512525023881614,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.67803,
            "recall": 0.68792,
            "fmeasure": 0.67681
        },
        "rouge2": {
            "precision": 0.40308,
            "recall": 0.40782,
            "fmeasure": 0.40148
        },
        "rougeL": {
            "precision": 0.51009,
            "recall": 0.51788,
            "fmeasure": 0.50879
        },
        "rougeLsum": {
            "precision": 0.51009,
            "recall": 0.51788,
            "fmeasure": 0.50879
        },
        "local_recall": {
            "1": 0.2186023377269336,
            "2": 0.5238715277777778,
            "3": 0.7948220064724919,
            "4": 0.6666666666666666,
            "5": 0.6190476190476191
        },
        "nist": 7.502336419072769,
        "bleu": 37.59062,
        "bleurt": -0.00679,
        "nubia": {
            "semantic_relation": 4.07547,
            "contradiction": 20.30491,
            "irrelevancy": 10.63372,
            "logical_agreement": 69.06137,
            "grammar_ref": 4.39371,
            "grammar_hyp": 4.43677,
            "nubia_score": 0.68189
        },
        "meteor": 0.3478183068465101,
        "bertscore": {
            "precision": 0.89377,
            "recall": 0.89481,
            "f1": 0.89295
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_308": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.69,
        "total_length": 162,
        "mean_pred_length": 20.25,
        "std_pred_length": 7.917543811056558,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 38,
        "distinct-1": 0.6172839506172839,
        "vocab_size-1": 100,
        "unique-1": 80,
        "entropy-1": 6.17780000642861,
        "distinct-2": 0.9415584415584416,
        "vocab_size-2": 145,
        "unique-2": 138,
        "entropy-2": 7.140099690017473,
        "cond_entropy-2": 0.8668217613268067,
        "distinct-3": 1.0,
        "vocab_size-3": 146,
        "unique-3": 146,
        "entropy-3": 7.18982455888002,
        "cond_entropy-3": 0.05666661410516389,
        "total_length-nopunct": 149,
        "mean_pred_length-nopunct": 18.625,
        "std_pred_length-nopunct": 7.515608757778707,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.6577181208053692,
        "vocab_size-1-nopunct": 98,
        "unique-1-nopunct": 80,
        "entropy-1-nopunct": 6.194722487231055,
        "distinct-2-nopunct": 0.9361702127659575,
        "vocab_size-2-nopunct": 132,
        "unique-2-nopunct": 125,
        "entropy-2-nopunct": 7.001184153786527,
        "cond_entropy-2-nopunct": 0.8339342918814643,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 133,
        "unique-3-nopunct": 133,
        "entropy-3-nopunct": 7.055282435501199,
        "cond_entropy-3-nopunct": 0.0549023237364333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81459,
            "recall": 0.78314,
            "fmeasure": 0.78809
        },
        "rouge2": {
            "precision": 0.55442,
            "recall": 0.54478,
            "fmeasure": 0.54357
        },
        "rougeL": {
            "precision": 0.71504,
            "recall": 0.69778,
            "fmeasure": 0.69901
        },
        "rougeLsum": {
            "precision": 0.71504,
            "recall": 0.69778,
            "fmeasure": 0.69901
        },
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.68,
            "3": 0.8526315789473684
        },
        "nist": 6.459579288259268,
        "bleu": 52.51378,
        "bleurt": 0.19494,
        "nubia": {
            "semantic_relation": 4.34667,
            "contradiction": 12.45682,
            "irrelevancy": 24.94331,
            "logical_agreement": 62.59986,
            "grammar_ref": 4.94279,
            "grammar_hyp": 4.88362,
            "nubia_score": 0.75689
        },
        "meteor": 0.4093514866653516,
        "bertscore": {
            "precision": 0.9472,
            "recall": 0.93812,
            "f1": 0.94087
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_287": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 72,
        "mean_pred_length": 18.0,
        "std_pred_length": 4.743416490252569,
        "median_pred_length": 16.0,
        "min_pred_length": 14,
        "max_pred_length": 26,
        "distinct-1": 0.7916666666666666,
        "vocab_size-1": 57,
        "unique-1": 51,
        "entropy-1": 5.5982408422932854,
        "distinct-2": 0.9852941176470589,
        "vocab_size-2": 67,
        "unique-2": 66,
        "entropy-2": 6.058051076544463,
        "cond_entropy-2": 0.37579165537758785,
        "distinct-3": 1.0,
        "vocab_size-3": 64,
        "unique-3": 64,
        "entropy-3": 6.0,
        "cond_entropy-3": -0.05621284125033946,
        "total_length-nopunct": 59,
        "mean_pred_length-nopunct": 14.75,
        "std_pred_length-nopunct": 3.6996621467371855,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8983050847457628,
        "vocab_size-1-nopunct": 53,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.653663812000364,
        "distinct-2-nopunct": 0.9818181818181818,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 53,
        "entropy-2-nopunct": 5.744996077161019,
        "cond_entropy-2-nopunct": 0.1079853006051264,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 51,
        "unique-3-nopunct": 51,
        "entropy-3-nopunct": 5.6724253419715005,
        "cond_entropy-3-nopunct": -0.06971868527865421,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77528,
            "recall": 0.71375,
            "fmeasure": 0.74022
        },
        "rouge2": {
            "precision": 0.65093,
            "recall": 0.61137,
            "fmeasure": 0.62819
        },
        "rougeL": {
            "precision": 0.66567,
            "recall": 0.62585,
            "fmeasure": 0.64295
        },
        "rougeLsum": {
            "precision": 0.66567,
            "recall": 0.62585,
            "fmeasure": 0.64295
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.6964285714285714
        },
        "nist": 4.723191225559403,
        "bleu": 51.69784,
        "bleurt": 0.34303,
        "nubia": {
            "semantic_relation": 4.26117,
            "contradiction": 0.25454,
            "irrelevancy": 25.58037,
            "logical_agreement": 74.16509,
            "grammar_ref": 4.68915,
            "grammar_hyp": 4.28438,
            "nubia_score": 0.80129
        },
        "meteor": 0.36307826292404516,
        "bertscore": {
            "precision": 0.92217,
            "recall": 0.91455,
            "f1": 0.91798
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_184": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.72667,
        "msttr-100_nopunct": 0.74,
        "total_length": 325,
        "mean_pred_length": 18.055555555555557,
        "std_pred_length": 10.511751213772467,
        "median_pred_length": 16.5,
        "min_pred_length": 9,
        "max_pred_length": 55,
        "distinct-1": 0.5876923076923077,
        "vocab_size-1": 191,
        "unique-1": 156,
        "entropy-1": 6.865437911148446,
        "distinct-2": 0.8762214983713354,
        "vocab_size-2": 269,
        "unique-2": 248,
        "entropy-2": 7.955453263977903,
        "cond_entropy-2": 0.9322329225879363,
        "distinct-3": 0.9480968858131488,
        "vocab_size-3": 274,
        "unique-3": 262,
        "entropy-3": 8.063283251682353,
        "cond_entropy-3": 0.11308794087073215,
        "total_length-nopunct": 273,
        "mean_pred_length-nopunct": 15.166666666666666,
        "std_pred_length-nopunct": 6.986097305044897,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.6703296703296703,
        "vocab_size-1-nopunct": 183,
        "unique-1-nopunct": 153,
        "entropy-1-nopunct": 6.963785076437599,
        "distinct-2-nopunct": 0.8901960784313725,
        "vocab_size-2-nopunct": 227,
        "unique-2-nopunct": 212,
        "entropy-2-nopunct": 7.717376219278123,
        "cond_entropy-2-nopunct": 0.8090875042492671,
        "distinct-3-nopunct": 0.9535864978902954,
        "vocab_size-3-nopunct": 226,
        "unique-3-nopunct": 217,
        "entropy-3-nopunct": 7.789545886010846,
        "cond_entropy-3-nopunct": 0.08898650182321428,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82311,
            "recall": 0.77374,
            "fmeasure": 0.79227
        },
        "rouge2": {
            "precision": 0.63943,
            "recall": 0.60042,
            "fmeasure": 0.61455
        },
        "rougeL": {
            "precision": 0.74419,
            "recall": 0.69731,
            "fmeasure": 0.71529
        },
        "rougeLsum": {
            "precision": 0.74419,
            "recall": 0.69731,
            "fmeasure": 0.71529
        },
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.20588235294117646,
            "3": 0.8384279475982532
        },
        "nist": 7.060862764176826,
        "bleu": 62.78275,
        "bleurt": 0.38086,
        "nubia": {
            "semantic_relation": 4.46287,
            "contradiction": 0.52264,
            "irrelevancy": 23.73875,
            "logical_agreement": 75.73861,
            "grammar_ref": 4.5077,
            "grammar_hyp": 4.60302,
            "nubia_score": 0.79804
        },
        "meteor": 0.46084700203662393,
        "bertscore": {
            "precision": 0.94772,
            "recall": 0.94531,
            "f1": 0.94592
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_288": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.77,
        "total_length": 221,
        "mean_pred_length": 18.416666666666668,
        "std_pred_length": 6.383028713358225,
        "median_pred_length": 18.5,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.6063348416289592,
        "vocab_size-1": 134,
        "unique-1": 105,
        "entropy-1": 6.48811425062783,
        "distinct-2": 0.9090909090909091,
        "vocab_size-2": 190,
        "unique-2": 175,
        "entropy-2": 7.508747768423831,
        "cond_entropy-2": 0.8894273440950637,
        "distinct-3": 0.9796954314720813,
        "vocab_size-3": 193,
        "unique-3": 189,
        "entropy-3": 7.581442682400499,
        "cond_entropy-3": 0.0847930681081177,
        "total_length-nopunct": 193,
        "mean_pred_length-nopunct": 16.083333333333332,
        "std_pred_length-nopunct": 5.529592108726365,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6735751295336787,
        "vocab_size-1-nopunct": 130,
        "unique-1-nopunct": 105,
        "entropy-1-nopunct": 6.5706222382035815,
        "distinct-2-nopunct": 0.9281767955801105,
        "vocab_size-2-nopunct": 168,
        "unique-2-nopunct": 156,
        "entropy-2-nopunct": 7.352028829060171,
        "cond_entropy-2-nopunct": 0.8293461217298288,
        "distinct-3-nopunct": 0.9822485207100592,
        "vocab_size-3-nopunct": 166,
        "unique-3-nopunct": 163,
        "entropy-3-nopunct": 7.365376477702294,
        "cond_entropy-3-nopunct": 0.017926374655567616,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.68893,
            "recall": 0.72171,
            "fmeasure": 0.69332
        },
        "rouge2": {
            "precision": 0.5295,
            "recall": 0.55412,
            "fmeasure": 0.53187
        },
        "rougeL": {
            "precision": 0.59957,
            "recall": 0.65208,
            "fmeasure": 0.61543
        },
        "rougeLsum": {
            "precision": 0.59957,
            "recall": 0.65208,
            "fmeasure": 0.61543
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.5806451612903226,
            "3": 0.7251908396946565
        },
        "nist": 5.245340560607809,
        "bleu": 44.35665,
        "bleurt": 0.09855,
        "nubia": {
            "semantic_relation": 3.84815,
            "contradiction": 14.02996,
            "irrelevancy": 44.88578,
            "logical_agreement": 41.08425,
            "grammar_ref": 4.5489,
            "grammar_hyp": 4.3122,
            "nubia_score": 0.62228
        },
        "meteor": 0.38776109123290653,
        "bertscore": {
            "precision": 0.91457,
            "recall": 0.92998,
            "f1": 0.92088
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_261": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 3.0,
        "median_pred_length": 17.0,
        "min_pred_length": 14,
        "max_pred_length": 20,
        "distinct-1": 0.7941176470588235,
        "vocab_size-1": 27,
        "unique-1": 21,
        "entropy-1": 4.6534955617749425,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.27456723689719675,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.09310940439148141,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.573557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.2576071835919428,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.55076,
            "recall": 0.61367,
            "fmeasure": 0.5571
        },
        "rouge2": {
            "precision": 0.32018,
            "recall": 0.36966,
            "fmeasure": 0.32207
        },
        "rougeL": {
            "precision": 0.51061,
            "recall": 0.56447,
            "fmeasure": 0.50237
        },
        "rougeLsum": {
            "precision": 0.51061,
            "recall": 0.56447,
            "fmeasure": 0.50237
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.7058823529411765
        },
        "nist": 2.510906563356507,
        "bleu": 20.51879,
        "bleurt": 0.323,
        "nubia": {
            "semantic_relation": 3.86971,
            "contradiction": 9.11876,
            "irrelevancy": 54.06993,
            "logical_agreement": 36.81131,
            "grammar_ref": 5.15434,
            "grammar_hyp": 4.44904,
            "nubia_score": 0.53523
        },
        "meteor": 0.35164625763915003,
        "bertscore": {
            "precision": 0.87767,
            "recall": 0.89363,
            "f1": 0.88389
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_289": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 14,
        "unique-1": 9,
        "entropy-1": 3.7216117239699003,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 16,
        "unique-2": 14,
        "entropy-2": 3.94770277922009,
        "cond_entropy-2": 0.25533082133206014,
        "distinct-3": 0.9411764705882353,
        "vocab_size-3": 16,
        "unique-3": 15,
        "entropy-3": 3.969815782426811,
        "cond_entropy-3": 0.03518489863155644,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7222222222222222,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.6143694458867563,
        "distinct-2-nopunct": 0.8823529411764706,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.8521687236032816,
        "cond_entropy-2-nopunct": 0.2704790162786152,
        "distinct-3-nopunct": 0.9375,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.875,
        "cond_entropy-3-nopunct": 0.03753715874966059,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.61667,
            "recall": 0.57581,
            "fmeasure": 0.59081
        },
        "rouge2": {
            "precision": 0.38596,
            "recall": 0.35802,
            "fmeasure": 0.36819
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.54073,
            "fmeasure": 0.55662
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.54073,
            "fmeasure": 0.55662
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "nist": 2.1947136251436175,
        "bleu": 20.61477,
        "bleurt": -0.07201,
        "nubia": {
            "semantic_relation": 3.71608,
            "contradiction": 57.9656,
            "irrelevancy": 41.41102,
            "logical_agreement": 0.62338,
            "grammar_ref": 3.99891,
            "grammar_hyp": 4.43359,
            "nubia_score": 0.48273
        },
        "meteor": 0.3598337209929245,
        "bertscore": {
            "precision": 0.90281,
            "recall": 0.89914,
            "f1": 0.89639
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_309": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.78333,
            "fmeasure": 0.85464
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.71717,
            "fmeasure": 0.78638
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.78333,
            "fmeasure": 0.85464
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.78333,
            "fmeasure": 0.85464
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.875
        },
        "nist": 3.7642741174382337,
        "bleu": 81.76129,
        "bleurt": 0.69712,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.96713,
            "irrelevancy": 0.64693,
            "logical_agreement": 98.38594,
            "grammar_ref": 4.59758,
            "grammar_hyp": 4.52299,
            "nubia_score": 1.0
        },
        "meteor": 0.5064321156600579,
        "bertscore": {
            "precision": 0.97871,
            "recall": 0.94782,
            "f1": 0.96301
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_264": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.71,
        "msttr-100_nopunct": NaN,
        "total_length": 119,
        "mean_pred_length": 19.833333333333332,
        "std_pred_length": 6.962199524735141,
        "median_pred_length": 22.5,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.6890756302521008,
        "vocab_size-1": 82,
        "unique-1": 70,
        "entropy-1": 5.994737121620512,
        "distinct-2": 0.9646017699115044,
        "vocab_size-2": 109,
        "unique-2": 106,
        "entropy-2": 6.742702081865087,
        "cond_entropy-2": 0.658502206667544,
        "distinct-3": 1.0,
        "vocab_size-3": 107,
        "unique-3": 107,
        "entropy-3": 6.741466986401138,
        "cond_entropy-3": -0.04132879844394725,
        "total_length-nopunct": 96,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 5.131601439446884,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 78,
        "unique-1-nopunct": 70,
        "entropy-1-nopunct": 6.077368167875321,
        "distinct-2-nopunct": 0.9777777777777777,
        "vocab_size-2-nopunct": 88,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.447408651885218,
        "cond_entropy-2-nopunct": 0.403880106199636,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 84,
        "entropy-3-nopunct": 6.39231742277876,
        "cond_entropy-3-nopunct": -0.05191662593186665,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81638,
            "recall": 0.67835,
            "fmeasure": 0.72573
        },
        "rouge2": {
            "precision": 0.56108,
            "recall": 0.48142,
            "fmeasure": 0.50763
        },
        "rougeL": {
            "precision": 0.69339,
            "recall": 0.58478,
            "fmeasure": 0.62066
        },
        "rougeLsum": {
            "precision": 0.69339,
            "recall": 0.58478,
            "fmeasure": 0.62066
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3617021276595745,
            "3": 0.8548387096774194
        },
        "nist": 4.95944500316148,
        "bleu": 45.87945,
        "bleurt": 0.11802,
        "nubia": {
            "semantic_relation": 3.85081,
            "contradiction": 4.65254,
            "irrelevancy": 30.3142,
            "logical_agreement": 65.03326,
            "grammar_ref": 4.79112,
            "grammar_hyp": 4.7727,
            "nubia_score": 0.62253
        },
        "meteor": 0.37454774910684696,
        "bertscore": {
            "precision": 0.92511,
            "recall": 0.89969,
            "f1": 0.91185
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_310": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.82,
        "total_length": 215,
        "mean_pred_length": 15.357142857142858,
        "std_pred_length": 5.135411276576768,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.6232558139534884,
        "vocab_size-1": 134,
        "unique-1": 108,
        "entropy-1": 6.5696013083130484,
        "distinct-2": 0.9154228855721394,
        "vocab_size-2": 184,
        "unique-2": 170,
        "entropy-2": 7.468191554352256,
        "cond_entropy-2": 0.7154922991190974,
        "distinct-3": 0.9625668449197861,
        "vocab_size-3": 180,
        "unique-3": 173,
        "entropy-3": 7.472028149727188,
        "cond_entropy-3": 0.017526659094609206,
        "total_length-nopunct": 188,
        "mean_pred_length-nopunct": 13.428571428571429,
        "std_pred_length-nopunct": 4.79157423749955,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6914893617021277,
        "vocab_size-1-nopunct": 130,
        "unique-1-nopunct": 107,
        "entropy-1-nopunct": 6.667301617898531,
        "distinct-2-nopunct": 0.9137931034482759,
        "vocab_size-2-nopunct": 159,
        "unique-2-nopunct": 147,
        "entropy-2-nopunct": 7.254697015951217,
        "cond_entropy-2-nopunct": 0.6530391984717304,
        "distinct-3-nopunct": 0.96875,
        "vocab_size-3-nopunct": 155,
        "unique-3-nopunct": 150,
        "entropy-3-nopunct": 7.259428094887368,
        "cond_entropy-3-nopunct": 0.021202645927155518,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83272,
            "recall": 0.80824,
            "fmeasure": 0.80158
        },
        "rouge2": {
            "precision": 0.70306,
            "recall": 0.67485,
            "fmeasure": 0.67329
        },
        "rougeL": {
            "precision": 0.76159,
            "recall": 0.73562,
            "fmeasure": 0.73019
        },
        "rougeLsum": {
            "precision": 0.76159,
            "recall": 0.73562,
            "fmeasure": 0.73019
        },
        "local_recall": {
            "1": 0.14705882352941177,
            "2": 0.34375,
            "3": 0.8910256410256411
        },
        "nist": 6.282571056151762,
        "bleu": 66.12509,
        "bleurt": 0.43166,
        "nubia": {
            "semantic_relation": 4.2839,
            "contradiction": 5.07811,
            "irrelevancy": 22.80282,
            "logical_agreement": 72.11907,
            "grammar_ref": 4.89936,
            "grammar_hyp": 4.8937,
            "nubia_score": 0.74917
        },
        "meteor": 0.45737443334513656,
        "bertscore": {
            "precision": 0.9439,
            "recall": 0.92569,
            "f1": 0.9338
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_265": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 95,
        "mean_pred_length": 15.833333333333334,
        "std_pred_length": 4.946940693218609,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 24,
        "distinct-1": 0.7263157894736842,
        "vocab_size-1": 69,
        "unique-1": 59,
        "entropy-1": 5.809006398462591,
        "distinct-2": 0.9887640449438202,
        "vocab_size-2": 88,
        "unique-2": 87,
        "entropy-2": 6.45326152085405,
        "cond_entropy-2": 0.5062884451652052,
        "distinct-3": 1.0,
        "vocab_size-3": 83,
        "unique-3": 83,
        "entropy-3": 6.375039431346932,
        "cond_entropy-3": -0.0765976140773044,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 13.833333333333334,
        "std_pred_length-nopunct": 4.524623986832743,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7951807228915663,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.837338341189211,
        "distinct-2-nopunct": 0.987012987012987,
        "vocab_size-2-nopunct": 76,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 6.240812514720878,
        "cond_entropy-2-nopunct": 0.43238594679071285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 71,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 6.149747119504677,
        "cond_entropy-3-nopunct": -0.0888704071057123,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85548,
            "recall": 0.72489,
            "fmeasure": 0.77642
        },
        "rouge2": {
            "precision": 0.65256,
            "recall": 0.56469,
            "fmeasure": 0.5997
        },
        "rougeL": {
            "precision": 0.65908,
            "recall": 0.5738,
            "fmeasure": 0.60797
        },
        "rougeLsum": {
            "precision": 0.65908,
            "recall": 0.5738,
            "fmeasure": 0.60797
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.08333333333333333,
            "3": 0.7564102564102564
        },
        "nist": 5.214220665230334,
        "bleu": 58.7628,
        "bleurt": 0.31092,
        "nubia": {
            "semantic_relation": 4.24271,
            "contradiction": 0.24529,
            "irrelevancy": 7.83607,
            "logical_agreement": 91.91864,
            "grammar_ref": 4.20009,
            "grammar_hyp": 4.19115,
            "nubia_score": 0.75839
        },
        "meteor": 0.4186750218420687,
        "bertscore": {
            "precision": 0.94489,
            "recall": 0.91684,
            "f1": 0.93021
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_380": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.78,
        "total_length": 154,
        "mean_pred_length": 19.25,
        "std_pred_length": 6.398241946034863,
        "median_pred_length": 17.5,
        "min_pred_length": 12,
        "max_pred_length": 33,
        "distinct-1": 0.6818181818181818,
        "vocab_size-1": 105,
        "unique-1": 89,
        "entropy-1": 6.334529193842338,
        "distinct-2": 0.9657534246575342,
        "vocab_size-2": 141,
        "unique-2": 138,
        "entropy-2": 7.107632778058102,
        "cond_entropy-2": 0.6598026169200266,
        "distinct-3": 1.0,
        "vocab_size-3": 138,
        "unique-3": 138,
        "entropy-3": 7.108524456778167,
        "cond_entropy-3": 0.005656419637282186,
        "total_length-nopunct": 129,
        "mean_pred_length-nopunct": 16.125,
        "std_pred_length-nopunct": 4.166458328124739,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7674418604651163,
        "vocab_size-1-nopunct": 99,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.360714488284531,
        "distinct-2-nopunct": 0.9669421487603306,
        "vocab_size-2-nopunct": 117,
        "unique-2-nopunct": 115,
        "entropy-2-nopunct": 6.836218609175429,
        "cond_entropy-2-nopunct": 0.5185132294620327,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 113,
        "unique-3-nopunct": 113,
        "entropy-3-nopunct": 6.8201789624152065,
        "cond_entropy-3-nopunct": -0.010188699638167703,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8472,
            "recall": 0.88339,
            "fmeasure": 0.86198
        },
        "rouge2": {
            "precision": 0.65436,
            "recall": 0.67405,
            "fmeasure": 0.66189
        },
        "rougeL": {
            "precision": 0.64975,
            "recall": 0.67268,
            "fmeasure": 0.6586
        },
        "rougeLsum": {
            "precision": 0.64975,
            "recall": 0.67268,
            "fmeasure": 0.6586
        },
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.5625,
            "3": 0.9166666666666666
        },
        "nist": 5.546181309478105,
        "bleu": 50.27339,
        "bleurt": 0.33293,
        "nubia": {
            "semantic_relation": 4.38049,
            "contradiction": 7.32599,
            "irrelevancy": 28.99722,
            "logical_agreement": 63.67679,
            "grammar_ref": 4.87577,
            "grammar_hyp": 5.04865,
            "nubia_score": 0.75413
        },
        "meteor": 0.46176233759210206,
        "bertscore": {
            "precision": 0.9394,
            "recall": 0.95535,
            "f1": 0.94726
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_290": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.73,
        "total_length": 195,
        "mean_pred_length": 15.0,
        "std_pred_length": 4.350066312491905,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.5846153846153846,
        "vocab_size-1": 114,
        "unique-1": 90,
        "entropy-1": 6.2464375250926,
        "distinct-2": 0.9340659340659341,
        "vocab_size-2": 170,
        "unique-2": 164,
        "entropy-2": 7.329737651426368,
        "cond_entropy-2": 0.9085528310908768,
        "distinct-3": 0.9881656804733728,
        "vocab_size-3": 167,
        "unique-3": 165,
        "entropy-3": 7.377210797228922,
        "cond_entropy-3": 0.061169837246604776,
        "total_length-nopunct": 166,
        "mean_pred_length-nopunct": 12.76923076923077,
        "std_pred_length-nopunct": 3.5981586349312304,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6686746987951807,
        "vocab_size-1-nopunct": 111,
        "unique-1-nopunct": 89,
        "entropy-1-nopunct": 6.41860475682578,
        "distinct-2-nopunct": 0.934640522875817,
        "vocab_size-2-nopunct": 143,
        "unique-2-nopunct": 139,
        "entropy-2-nopunct": 7.0717252808850075,
        "cond_entropy-2-nopunct": 0.710955087902724,
        "distinct-3-nopunct": 0.9928571428571429,
        "vocab_size-3-nopunct": 139,
        "unique-3-nopunct": 138,
        "entropy-3-nopunct": 7.114997302659264,
        "cond_entropy-3-nopunct": 0.06051211679921984,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79132,
            "recall": 0.75888,
            "fmeasure": 0.77121
        },
        "rouge2": {
            "precision": 0.58572,
            "recall": 0.56919,
            "fmeasure": 0.57469
        },
        "rougeL": {
            "precision": 0.67131,
            "recall": 0.64087,
            "fmeasure": 0.65289
        },
        "rougeLsum": {
            "precision": 0.67131,
            "recall": 0.64087,
            "fmeasure": 0.65289
        },
        "local_recall": {
            "1": 0.05555555555555555,
            "2": 0.23529411764705882,
            "3": 0.8235294117647058
        },
        "nist": 5.769536557304355,
        "bleu": 50.06299,
        "bleurt": 0.50917,
        "nubia": {
            "semantic_relation": 4.44147,
            "contradiction": 10.98422,
            "irrelevancy": 10.78077,
            "logical_agreement": 78.235,
            "grammar_ref": 4.72277,
            "grammar_hyp": 4.78009,
            "nubia_score": 0.79734
        },
        "meteor": 0.42201385196813684,
        "bertscore": {
            "precision": 0.94055,
            "recall": 0.93427,
            "f1": 0.93719
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_382": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.04978793508525296,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.1986532337201607,
        "bleu": 100.0,
        "bleurt": 0.99035,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20913,
            "irrelevancy": 0.49456,
            "logical_agreement": 99.29631,
            "grammar_ref": 4.69221,
            "grammar_hyp": 4.84818,
            "nubia_score": 0.99204
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_344": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 97,
        "mean_pred_length": 13.857142857142858,
        "std_pred_length": 4.642307659791977,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 21,
        "distinct-1": 0.7525773195876289,
        "vocab_size-1": 73,
        "unique-1": 63,
        "entropy-1": 5.916606914996478,
        "distinct-2": 0.9777777777777777,
        "vocab_size-2": 88,
        "unique-2": 86,
        "entropy-2": 6.447408651885218,
        "cond_entropy-2": 0.3655979261768879,
        "distinct-3": 1.0,
        "vocab_size-3": 83,
        "unique-3": 83,
        "entropy-3": 6.375039431346932,
        "cond_entropy-3": -0.06862089389841255,
        "total_length-nopunct": 87,
        "mean_pred_length-nopunct": 12.428571428571429,
        "std_pred_length-nopunct": 4.06578556307363,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8160919540229885,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 63,
        "entropy-1-nopunct": 5.961629668481747,
        "distinct-2-nopunct": 0.975,
        "vocab_size-2-nopunct": 78,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 6.271928094887357,
        "cond_entropy-2-nopunct": 0.352413386300224,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 73,
        "entropy-3-nopunct": 6.189824558880028,
        "cond_entropy-3-nopunct": -0.07730901545939997,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.6604,
            "recall": 0.62553,
            "fmeasure": 0.62646
        },
        "rouge2": {
            "precision": 0.42196,
            "recall": 0.3973,
            "fmeasure": 0.39914
        },
        "rougeL": {
            "precision": 0.59553,
            "recall": 0.56294,
            "fmeasure": 0.56515
        },
        "rougeLsum": {
            "precision": 0.59553,
            "recall": 0.56294,
            "fmeasure": 0.56515
        },
        "local_recall": {
            "1": 0.46153846153846156,
            "2": 0.5925925925925926,
            "3": 0.6
        },
        "nist": 4.70354498185025,
        "bleu": 34.55572,
        "bleurt": 0.23655,
        "nubia": {
            "semantic_relation": 4.231,
            "contradiction": 2.10799,
            "irrelevancy": 37.2199,
            "logical_agreement": 60.67211,
            "grammar_ref": 4.57813,
            "grammar_hyp": 4.00699,
            "nubia_score": 0.75977
        },
        "meteor": 0.31591624121955697,
        "bertscore": {
            "precision": 0.92103,
            "recall": 0.91538,
            "f1": 0.91788
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_312": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.645,
        "msttr-100_nopunct": 0.735,
        "total_length": 286,
        "mean_pred_length": 20.428571428571427,
        "std_pred_length": 6.935563482250489,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 36,
        "distinct-1": 0.5804195804195804,
        "vocab_size-1": 166,
        "unique-1": 139,
        "entropy-1": 6.625935001420491,
        "distinct-2": 0.875,
        "vocab_size-2": 238,
        "unique-2": 225,
        "entropy-2": 7.7371792480156305,
        "cond_entropy-2": 0.9942300546326739,
        "distinct-3": 0.9341085271317829,
        "vocab_size-3": 241,
        "unique-3": 235,
        "entropy-3": 7.826531579243363,
        "cond_entropy-3": 0.10835996806997047,
        "total_length-nopunct": 244,
        "mean_pred_length-nopunct": 17.428571428571427,
        "std_pred_length-nopunct": 5.136901313247201,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6598360655737705,
        "vocab_size-1-nopunct": 161,
        "unique-1-nopunct": 136,
        "entropy-1-nopunct": 6.827022508631748,
        "distinct-2-nopunct": 0.908695652173913,
        "vocab_size-2-nopunct": 209,
        "unique-2-nopunct": 199,
        "entropy-2-nopunct": 7.610819753331161,
        "cond_entropy-2-nopunct": 0.8353930929790294,
        "distinct-3-nopunct": 0.9722222222222222,
        "vocab_size-3-nopunct": 210,
        "unique-3-nopunct": 207,
        "entropy-3-nopunct": 7.686577837801595,
        "cond_entropy-3-nopunct": 0.09096819635276775,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66154,
            "recall": 0.73077,
            "fmeasure": 0.68293
        },
        "rouge2": {
            "precision": 0.45164,
            "recall": 0.52257,
            "fmeasure": 0.47506
        },
        "rougeL": {
            "precision": 0.60372,
            "recall": 0.66582,
            "fmeasure": 0.62301
        },
        "rougeLsum": {
            "precision": 0.60372,
            "recall": 0.66582,
            "fmeasure": 0.62301
        },
        "local_recall": {
            "1": 0.29310344827586204,
            "2": 0.5116279069767442,
            "3": 0.8029197080291971
        },
        "nist": 4.894319313284328,
        "bleu": 36.71831,
        "bleurt": 0.24548,
        "nubia": {
            "semantic_relation": 4.11131,
            "contradiction": 7.59958,
            "irrelevancy": 39.55099,
            "logical_agreement": 52.84944,
            "grammar_ref": 4.5978,
            "grammar_hyp": 4.03522,
            "nubia_score": 0.75752
        },
        "meteor": 0.40047806856148477,
        "bertscore": {
            "precision": 0.91687,
            "recall": 0.93233,
            "f1": 0.92215
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_345": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 91,
        "mean_pred_length": 11.375,
        "std_pred_length": 2.496873044429772,
        "median_pred_length": 10.5,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.5494505494505495,
        "vocab_size-1": 50,
        "unique-1": 37,
        "entropy-1": 5.220592135695759,
        "distinct-2": 0.7349397590361446,
        "vocab_size-2": 61,
        "unique-2": 51,
        "entropy-2": 5.695948732833673,
        "cond_entropy-2": 0.3102676819092762,
        "distinct-3": 0.8,
        "vocab_size-3": 60,
        "unique-3": 53,
        "entropy-3": 5.728688357104862,
        "cond_entropy-3": 0.07850929877926742,
        "total_length-nopunct": 80,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 2.23606797749979,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.6,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.217171339792312,
        "distinct-2-nopunct": 0.6944444444444444,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.3697911059640235,
        "cond_entropy-2-nopunct": 0.21534373764216697,
        "distinct-3-nopunct": 0.75,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.34375,
        "cond_entropy-3-nopunct": 0.04272563097076282,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.90972,
            "recall": 0.82102,
            "fmeasure": 0.8552
        },
        "rouge2": {
            "precision": 0.79613,
            "recall": 0.72988,
            "fmeasure": 0.75273
        },
        "rougeL": {
            "precision": 0.89306,
            "recall": 0.82015,
            "fmeasure": 0.84674
        },
        "rougeLsum": {
            "precision": 0.89306,
            "recall": 0.82015,
            "fmeasure": 0.84674
        },
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.16666666666666666,
            "3": 0.8888888888888888
        },
        "nist": 5.535480153578208,
        "bleu": 69.6694,
        "bleurt": 0.64633,
        "nubia": {
            "semantic_relation": 4.49861,
            "contradiction": 0.66557,
            "irrelevancy": 13.00507,
            "logical_agreement": 86.32936,
            "grammar_ref": 5.07225,
            "grammar_hyp": 5.07684,
            "nubia_score": 0.84863
        },
        "meteor": 0.5113003785818953,
        "bertscore": {
            "precision": 0.96939,
            "recall": 0.95682,
            "f1": 0.96243
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_348": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 3.39934634239519,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 19,
        "distinct-1": 0.7659574468085106,
        "vocab_size-1": 36,
        "unique-1": 31,
        "entropy-1": 4.9510882564308245,
        "distinct-2": 0.9772727272727273,
        "vocab_size-2": 43,
        "unique-2": 42,
        "entropy-2": 5.41397707318275,
        "cond_entropy-2": 0.3959709595604964,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.05309912621433557,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 3.0912061651652345,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7906976744186046,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.8772033483198465,
        "distinct-2-nopunct": 0.975,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.271928094887364,
        "cond_entropy-2-nopunct": 0.4359043520461845,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.05842067520435854,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65748,
            "recall": 0.73834,
            "fmeasure": 0.68891
        },
        "rouge2": {
            "precision": 0.39537,
            "recall": 0.44352,
            "fmeasure": 0.41547
        },
        "rougeL": {
            "precision": 0.59498,
            "recall": 0.64744,
            "fmeasure": 0.61483
        },
        "rougeLsum": {
            "precision": 0.59498,
            "recall": 0.64744,
            "fmeasure": 0.61483
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.625,
            "3": 0.9333333333333333
        },
        "nist": 3.6760658278768648,
        "bleu": 41.82112,
        "bleurt": 0.16779,
        "nubia": {
            "semantic_relation": 3.78602,
            "contradiction": 0.44461,
            "irrelevancy": 66.02809,
            "logical_agreement": 33.5273,
            "grammar_ref": 4.86076,
            "grammar_hyp": 5.346,
            "nubia_score": 0.54087
        },
        "meteor": 0.41668041211143225,
        "bertscore": {
            "precision": 0.9009,
            "recall": 0.92517,
            "f1": 0.91267
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_384": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.78,
        "total_length": 200,
        "mean_pred_length": 22.22222222222222,
        "std_pred_length": 8.429811883729181,
        "median_pred_length": 29.0,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.645,
        "vocab_size-1": 129,
        "unique-1": 106,
        "entropy-1": 6.507483318372648,
        "distinct-2": 0.9319371727748691,
        "vocab_size-2": 178,
        "unique-2": 166,
        "entropy-2": 7.437350882998242,
        "cond_entropy-2": 0.8340457365085318,
        "distinct-3": 0.9725274725274725,
        "vocab_size-3": 177,
        "unique-3": 172,
        "entropy-3": 7.452849585253659,
        "cond_entropy-3": 0.011436622614395129,
        "total_length-nopunct": 174,
        "mean_pred_length-nopunct": 19.333333333333332,
        "std_pred_length-nopunct": 7.7746025264603995,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.7126436781609196,
        "vocab_size-1-nopunct": 124,
        "unique-1-nopunct": 105,
        "entropy-1-nopunct": 6.523310200939311,
        "distinct-2-nopunct": 0.9393939393939394,
        "vocab_size-2-nopunct": 155,
        "unique-2-nopunct": 146,
        "entropy-2-nopunct": 7.240535017263001,
        "cond_entropy-2-nopunct": 0.7613260263490463,
        "distinct-3-nopunct": 0.967948717948718,
        "vocab_size-3-nopunct": 151,
        "unique-3-nopunct": 146,
        "entropy-3-nopunct": 7.221299654759702,
        "cond_entropy-3-nopunct": -0.011978408831237616,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.62699,
            "recall": 0.70589,
            "fmeasure": 0.6532
        },
        "rouge2": {
            "precision": 0.31916,
            "recall": 0.38248,
            "fmeasure": 0.33944
        },
        "rougeL": {
            "precision": 0.52056,
            "recall": 0.59301,
            "fmeasure": 0.54314
        },
        "rougeLsum": {
            "precision": 0.52056,
            "recall": 0.59301,
            "fmeasure": 0.54314
        },
        "local_recall": {
            "1": 0.20754716981132076,
            "2": 0.6122448979591837,
            "3": 0.7746478873239436
        },
        "nist": 4.4935071619508635,
        "bleu": 28.70123,
        "bleurt": 0.165,
        "nubia": {
            "semantic_relation": 3.9319,
            "contradiction": 4.70267,
            "irrelevancy": 42.04656,
            "logical_agreement": 53.25077,
            "grammar_ref": 4.84583,
            "grammar_hyp": 4.57022,
            "nubia_score": 0.65882
        },
        "meteor": 0.34575733482630266,
        "bertscore": {
            "precision": 0.89277,
            "recall": 0.91012,
            "f1": 0.89975
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_266": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.74,
        "total_length": 121,
        "mean_pred_length": 15.125,
        "std_pred_length": 1.6153559979150107,
        "median_pred_length": 14.5,
        "min_pred_length": 13,
        "max_pred_length": 18,
        "distinct-1": 0.7107438016528925,
        "vocab_size-1": 86,
        "unique-1": 73,
        "entropy-1": 6.097507220867541,
        "distinct-2": 0.9469026548672567,
        "vocab_size-2": 107,
        "unique-2": 102,
        "entropy-2": 6.707303851776591,
        "cond_entropy-2": 0.4555563488847591,
        "distinct-3": 0.9809523809523809,
        "vocab_size-3": 103,
        "unique-3": 101,
        "entropy-3": 6.676150279570875,
        "cond_entropy-3": -0.04160118282369897,
        "total_length-nopunct": 108,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 1.8708286933869707,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7592592592592593,
        "vocab_size-1-nopunct": 82,
        "unique-1-nopunct": 71,
        "entropy-1-nopunct": 6.100913516208916,
        "distinct-2-nopunct": 0.95,
        "vocab_size-2-nopunct": 95,
        "unique-2-nopunct": 91,
        "entropy-2-nopunct": 6.536307314753104,
        "cond_entropy-2-nopunct": 0.46771171742052847,
        "distinct-3-nopunct": 0.9782608695652174,
        "vocab_size-3-nopunct": 90,
        "unique-3-nopunct": 88,
        "entropy-3-nopunct": 6.480083695187461,
        "cond_entropy-3-nopunct": -0.04687154347680449,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7576,
            "recall": 0.75334,
            "fmeasure": 0.74965
        },
        "rouge2": {
            "precision": 0.44356,
            "recall": 0.45016,
            "fmeasure": 0.44313
        },
        "rougeL": {
            "precision": 0.60042,
            "recall": 0.61564,
            "fmeasure": 0.60273
        },
        "rougeLsum": {
            "precision": 0.60042,
            "recall": 0.61564,
            "fmeasure": 0.60273
        },
        "local_recall": {
            "1": 0.3142857142857143,
            "2": 0.42857142857142855,
            "3": 0.855072463768116
        },
        "nist": 5.647589548344753,
        "bleu": 36.50026,
        "bleurt": 0.26121,
        "nubia": {
            "semantic_relation": 4.16151,
            "contradiction": 12.95732,
            "irrelevancy": 33.73965,
            "logical_agreement": 53.30303,
            "grammar_ref": 4.49967,
            "grammar_hyp": 4.42699,
            "nubia_score": 0.75078
        },
        "meteor": 0.39945219861868914,
        "bertscore": {
            "precision": 0.92105,
            "recall": 0.93456,
            "f1": 0.92659
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_291": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 0.9545454545454546,
        "vocab_size-2": 21,
        "unique-2": 20,
        "entropy-2": 4.368522527728205,
        "cond_entropy-2": 0.026778753489375334,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": 0.02812389937955851,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.277613436819114,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.297079327540665,
        "cond_entropy-2-nopunct": 0.02812389937955851,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": 0.02961067210860201,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.6,
            "recall": 0.43423,
            "fmeasure": 0.50369
        },
        "rouge2": {
            "precision": 0.26316,
            "recall": 0.18773,
            "fmeasure": 0.21907
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.22046,
            "fmeasure": 0.23352
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.22046,
            "fmeasure": 0.23352
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.14285714285714285,
            "3": 0.5555555555555556
        },
        "nist": 2.176929924861576,
        "bleu": 21.71,
        "bleurt": -0.3754,
        "nubia": {
            "semantic_relation": 2.9648,
            "contradiction": 0.10447,
            "irrelevancy": 99.76156,
            "logical_agreement": 0.13397,
            "grammar_ref": 3.87789,
            "grammar_hyp": 3.37769,
            "nubia_score": 0.43118
        },
        "meteor": 0.21666867546894056,
        "bertscore": {
            "precision": 0.83994,
            "recall": 0.83068,
            "f1": 0.83528
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_385": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 5.0,
        "median_pred_length": 20.0,
        "min_pred_length": 15,
        "max_pred_length": 25,
        "distinct-1": 0.75,
        "vocab_size-1": 30,
        "unique-1": 24,
        "entropy-1": 4.684183719779189,
        "distinct-2": 1.0,
        "vocab_size-2": 38,
        "unique-2": 38,
        "entropy-2": 5.247927513443589,
        "cond_entropy-2": 0.5446777081437745,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.0780025120012732,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.572431251322118,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.087462841250338,
        "cond_entropy-2-nopunct": 0.5501782811117606,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.08746284125033942,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77735,
            "recall": 0.94028,
            "fmeasure": 0.84062
        },
        "rouge2": {
            "precision": 0.65619,
            "recall": 0.73599,
            "fmeasure": 0.68882
        },
        "rougeL": {
            "precision": 0.73889,
            "recall": 0.84366,
            "fmeasure": 0.78215
        },
        "rougeLsum": {
            "precision": 0.73889,
            "recall": 0.84366,
            "fmeasure": 0.78215
        },
        "local_recall": {
            "1": 0.7142857142857143,
            "2": 0.0,
            "3": 0.9473684210526315
        },
        "nist": 4.360789559516272,
        "bleu": 49.43359,
        "bleurt": 0.64213,
        "nubia": {
            "semantic_relation": 4.90469,
            "contradiction": 0.31858,
            "irrelevancy": 26.36385,
            "logical_agreement": 73.31757,
            "grammar_ref": 3.86772,
            "grammar_hyp": 3.49436,
            "nubia_score": 0.88259
        },
        "meteor": 0.5051028366613157,
        "bertscore": {
            "precision": 0.95509,
            "recall": 0.97091,
            "f1": 0.96017
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_268": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.62,
        "msttr-100_nopunct": NaN,
        "total_length": 106,
        "mean_pred_length": 21.2,
        "std_pred_length": 10.107423014794621,
        "median_pred_length": 20.0,
        "min_pred_length": 8,
        "max_pred_length": 39,
        "distinct-1": 0.6132075471698113,
        "vocab_size-1": 65,
        "unique-1": 52,
        "entropy-1": 5.490575968751197,
        "distinct-2": 0.9108910891089109,
        "vocab_size-2": 92,
        "unique-2": 86,
        "entropy-2": 6.457571259915242,
        "cond_entropy-2": 0.9133030332890348,
        "distinct-3": 0.9791666666666666,
        "vocab_size-3": 94,
        "unique-3": 92,
        "entropy-3": 6.5432958340544936,
        "cond_entropy-3": 0.09617458574530348,
        "total_length-nopunct": 92,
        "mean_pred_length-nopunct": 18.4,
        "std_pred_length-nopunct": 9.00222194794152,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.6847826086956522,
        "vocab_size-1-nopunct": 63,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 5.5342190211803475,
        "distinct-2-nopunct": 0.9310344827586207,
        "vocab_size-2-nopunct": 81,
        "unique-2-nopunct": 77,
        "entropy-2-nopunct": 6.287658725684046,
        "cond_entropy-2-nopunct": 0.7988042409908765,
        "distinct-3-nopunct": 0.975609756097561,
        "vocab_size-3-nopunct": 80,
        "unique-3-nopunct": 78,
        "entropy-3-nopunct": 6.30877151681321,
        "cond_entropy-3-nopunct": 0.030581374675781463,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83072,
            "recall": 0.80705,
            "fmeasure": 0.81154
        },
        "rouge2": {
            "precision": 0.60043,
            "recall": 0.59716,
            "fmeasure": 0.59625
        },
        "rougeL": {
            "precision": 0.71338,
            "recall": 0.6854,
            "fmeasure": 0.69231
        },
        "rougeLsum": {
            "precision": 0.71338,
            "recall": 0.6854,
            "fmeasure": 0.69231
        },
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "nist": 5.905273506397688,
        "bleu": 59.0566,
        "bleurt": 0.20565,
        "nubia": {
            "semantic_relation": 4.4164,
            "contradiction": 4.92796,
            "irrelevancy": 32.50016,
            "logical_agreement": 62.57188,
            "grammar_ref": 4.37077,
            "grammar_hyp": 4.16753,
            "nubia_score": 0.81645
        },
        "meteor": 0.4522021719082402,
        "bertscore": {
            "precision": 0.9563,
            "recall": 0.95195,
            "f1": 0.95247
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_350": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.81,
        "msttr-100_nopunct": 0.88,
        "total_length": 120,
        "mean_pred_length": 17.142857142857142,
        "std_pred_length": 6.791351042288407,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.7916666666666666,
        "vocab_size-1": 95,
        "unique-1": 87,
        "entropy-1": 6.297213433452447,
        "distinct-2": 0.9823008849557522,
        "vocab_size-2": 111,
        "unique-2": 110,
        "entropy-2": 6.778100311953583,
        "cond_entropy-2": 0.34474754824174414,
        "distinct-3": 1.0,
        "vocab_size-3": 106,
        "unique-3": 106,
        "entropy-3": 6.727920454563184,
        "cond_entropy-3": -0.047401078586295206,
        "total_length-nopunct": 102,
        "mean_pred_length-nopunct": 14.571428571428571,
        "std_pred_length-nopunct": 5.260557897006277,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 90,
        "unique-1-nopunct": 84,
        "entropy-1-nopunct": 6.383113822321235,
        "distinct-2-nopunct": 0.9789473684210527,
        "vocab_size-2-nopunct": 93,
        "unique-2-nopunct": 92,
        "entropy-2-nopunct": 6.519804160939754,
        "cond_entropy-2-nopunct": 0.1580080295401202,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 88,
        "unique-3-nopunct": 88,
        "entropy-3-nopunct": 6.459431618637305,
        "cond_entropy-3-nopunct": -0.05639117716906579,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81822,
            "recall": 0.8424,
            "fmeasure": 0.82075
        },
        "rouge2": {
            "precision": 0.60465,
            "recall": 0.63628,
            "fmeasure": 0.61331
        },
        "rougeL": {
            "precision": 0.69207,
            "recall": 0.7248,
            "fmeasure": 0.7004
        },
        "rougeLsum": {
            "precision": 0.69207,
            "recall": 0.7248,
            "fmeasure": 0.7004
        },
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.4375,
            "3": 0.8734177215189873
        },
        "nist": 5.368985225691197,
        "bleu": 48.23222,
        "bleurt": 0.3766,
        "nubia": {
            "semantic_relation": 4.43667,
            "contradiction": 1.68484,
            "irrelevancy": 42.06308,
            "logical_agreement": 56.25208,
            "grammar_ref": 4.69419,
            "grammar_hyp": 4.83242,
            "nubia_score": 0.75835
        },
        "meteor": 0.4377815399631825,
        "bertscore": {
            "precision": 0.94542,
            "recall": 0.95126,
            "f1": 0.94789
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_292": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 1.5,
        "median_pred_length": 16.5,
        "min_pred_length": 15,
        "max_pred_length": 18,
        "distinct-1": 0.8484848484848485,
        "vocab_size-1": 28,
        "unique-1": 23,
        "entropy-1": 4.741363816328152,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": 0.1678667071574542,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.09621531525930291,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.52164063634332,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.2007771037757955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.63095,
            "recall": 0.71228,
            "fmeasure": 0.65657
        },
        "rouge2": {
            "precision": 0.31026,
            "recall": 0.38135,
            "fmeasure": 0.33711
        },
        "rougeL": {
            "precision": 0.45536,
            "recall": 0.53679,
            "fmeasure": 0.48275
        },
        "rougeLsum": {
            "precision": 0.45536,
            "recall": 0.53679,
            "fmeasure": 0.48275
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.2,
            "3": 0.6842105263157895
        },
        "nist": 3.368949959881189,
        "bleu": 29.14117,
        "bleurt": -0.02385,
        "nubia": {
            "semantic_relation": 3.92649,
            "contradiction": 29.04513,
            "irrelevancy": 43.69222,
            "logical_agreement": 27.26265,
            "grammar_ref": 4.97036,
            "grammar_hyp": 4.75553,
            "nubia_score": 0.61168
        },
        "meteor": 0.34860340234470333,
        "bertscore": {
            "precision": 0.873,
            "recall": 0.91006,
            "f1": 0.88918
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_294": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.79,
        "total_length": 148,
        "mean_pred_length": 18.5,
        "std_pred_length": 8.573214099741124,
        "median_pred_length": 17.5,
        "min_pred_length": 10,
        "max_pred_length": 40,
        "distinct-1": 0.6621621621621622,
        "vocab_size-1": 98,
        "unique-1": 82,
        "entropy-1": 6.103903506032277,
        "distinct-2": 0.9571428571428572,
        "vocab_size-2": 134,
        "unique-2": 130,
        "entropy-2": 7.0292830169449765,
        "cond_entropy-2": 0.817125217175354,
        "distinct-3": 1.0,
        "vocab_size-3": 132,
        "unique-3": 132,
        "entropy-3": 7.044394119358443,
        "cond_entropy-3": 0.021171708474092818,
        "total_length-nopunct": 122,
        "mean_pred_length-nopunct": 15.25,
        "std_pred_length-nopunct": 5.448623679425842,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.7704918032786885,
        "vocab_size-1-nopunct": 94,
        "unique-1-nopunct": 82,
        "entropy-1-nopunct": 6.255996269435844,
        "distinct-2-nopunct": 0.9649122807017544,
        "vocab_size-2-nopunct": 110,
        "unique-2-nopunct": 108,
        "entropy-2-nopunct": 6.745170715919138,
        "cond_entropy-2-nopunct": 0.536524696878178,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 106,
        "unique-3-nopunct": 106,
        "entropy-3-nopunct": 6.727920454563184,
        "cond_entropy-3-nopunct": -0.010629936960032914,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74948,
            "recall": 0.70515,
            "fmeasure": 0.71272
        },
        "rouge2": {
            "precision": 0.552,
            "recall": 0.50896,
            "fmeasure": 0.52062
        },
        "rougeL": {
            "precision": 0.68032,
            "recall": 0.64082,
            "fmeasure": 0.64883
        },
        "rougeLsum": {
            "precision": 0.68032,
            "recall": 0.64082,
            "fmeasure": 0.64883
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.7291666666666666,
            "3": 0.6197183098591549
        },
        "nist": 5.272674899632591,
        "bleu": 46.70818,
        "bleurt": 0.30924,
        "nubia": {
            "semantic_relation": 4.08069,
            "contradiction": 16.61497,
            "irrelevancy": 40.2571,
            "logical_agreement": 43.12792,
            "grammar_ref": 4.54831,
            "grammar_hyp": 4.15567,
            "nubia_score": 0.74022
        },
        "meteor": 0.37686549716123374,
        "bertscore": {
            "precision": 0.92284,
            "recall": 0.92645,
            "f1": 0.92323
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_387": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 84,
        "mean_pred_length": 21.0,
        "std_pred_length": 3.5355339059327378,
        "median_pred_length": 22.5,
        "min_pred_length": 15,
        "max_pred_length": 24,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 56,
        "unique-1": 42,
        "entropy-1": 5.5016895190509825,
        "distinct-2": 0.9375,
        "vocab_size-2": 75,
        "unique-2": 70,
        "entropy-2": 6.196928094887356,
        "cond_entropy-2": 0.6397699710227694,
        "distinct-3": 0.9736842105263158,
        "vocab_size-3": 74,
        "unique-3": 72,
        "entropy-3": 6.195295934496222,
        "cond_entropy-3": 0.004946786977275855,
        "total_length-nopunct": 67,
        "mean_pred_length-nopunct": 16.75,
        "std_pred_length-nopunct": 2.7726341266023544,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7611940298507462,
        "vocab_size-1-nopunct": 51,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.451742034357318,
        "distinct-2-nopunct": 0.9365079365079365,
        "vocab_size-2-nopunct": 59,
        "unique-2-nopunct": 55,
        "entropy-2-nopunct": 5.850295796515793,
        "cond_entropy-2-nopunct": 0.42168691492675014,
        "distinct-3-nopunct": 0.9830508474576272,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 57,
        "entropy-3-nopunct": 5.848744744277091,
        "cond_entropy-3-nopunct": -0.00989111142621088,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.63183,
            "recall": 0.76019,
            "fmeasure": 0.67963
        },
        "rouge2": {
            "precision": 0.35848,
            "recall": 0.40138,
            "fmeasure": 0.37488
        },
        "rougeL": {
            "precision": 0.51428,
            "recall": 0.62072,
            "fmeasure": 0.55494
        },
        "rougeLsum": {
            "precision": 0.51428,
            "recall": 0.62072,
            "fmeasure": 0.55494
        },
        "local_recall": {
            "1": 0.2962962962962963,
            "2": 0.4666666666666667,
            "3": 0.6923076923076923
        },
        "nist": 4.490982579067212,
        "bleu": 34.11433,
        "bleurt": 0.32216,
        "nubia": {
            "semantic_relation": 4.20709,
            "contradiction": 0.33203,
            "irrelevancy": 37.92098,
            "logical_agreement": 61.74699,
            "grammar_ref": 4.83213,
            "grammar_hyp": 4.24158,
            "nubia_score": 0.7898
        },
        "meteor": 0.37883602912834813,
        "bertscore": {
            "precision": 0.9134,
            "recall": 0.93468,
            "f1": 0.91957
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_315": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.76,
        "total_length": 232,
        "mean_pred_length": 17.846153846153847,
        "std_pred_length": 6.224593330505818,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 31,
        "distinct-1": 0.6293103448275862,
        "vocab_size-1": 146,
        "unique-1": 117,
        "entropy-1": 6.683936536441639,
        "distinct-2": 0.9452054794520548,
        "vocab_size-2": 207,
        "unique-2": 197,
        "entropy-2": 7.656065598413968,
        "cond_entropy-2": 0.8221603936028231,
        "distinct-3": 0.9757281553398058,
        "vocab_size-3": 201,
        "unique-3": 196,
        "entropy-3": 7.637956837862829,
        "cond_entropy-3": -0.020325367369411367,
        "total_length-nopunct": 204,
        "mean_pred_length-nopunct": 15.692307692307692,
        "std_pred_length-nopunct": 5.566170004654014,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.696078431372549,
        "vocab_size-1-nopunct": 142,
        "unique-1-nopunct": 115,
        "entropy-1-nopunct": 6.808862196170198,
        "distinct-2-nopunct": 0.9476439790575916,
        "vocab_size-2-nopunct": 181,
        "unique-2-nopunct": 173,
        "entropy-2-nopunct": 7.46224558196245,
        "cond_entropy-2-nopunct": 0.6755107203232309,
        "distinct-3-nopunct": 0.9775280898876404,
        "vocab_size-3-nopunct": 174,
        "unique-3-nopunct": 170,
        "entropy-3-nopunct": 7.430789610741652,
        "cond_entropy-3-nopunct": -0.045515621788451935,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.6538,
            "recall": 0.66638,
            "fmeasure": 0.64439
        },
        "rouge2": {
            "precision": 0.4091,
            "recall": 0.42974,
            "fmeasure": 0.41014
        },
        "rougeL": {
            "precision": 0.50463,
            "recall": 0.51028,
            "fmeasure": 0.49512
        },
        "rougeLsum": {
            "precision": 0.50463,
            "recall": 0.51028,
            "fmeasure": 0.49512
        },
        "local_recall": {
            "1": 0.15492957746478872,
            "2": 0.4528301886792453,
            "3": 0.7222222222222222
        },
        "nist": 5.038402687990632,
        "bleu": 32.29652,
        "bleurt": 0.07417,
        "nubia": {
            "semantic_relation": 3.78368,
            "contradiction": 34.96364,
            "irrelevancy": 37.73529,
            "logical_agreement": 27.30106,
            "grammar_ref": 4.70766,
            "grammar_hyp": 4.3834,
            "nubia_score": 0.60266
        },
        "meteor": 0.34699071063505327,
        "bertscore": {
            "precision": 0.90602,
            "recall": 0.90392,
            "f1": 0.90314
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_318": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 84,
        "mean_pred_length": 16.8,
        "std_pred_length": 6.368673331236264,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.7261904761904762,
        "vocab_size-1": 61,
        "unique-1": 52,
        "entropy-1": 5.651378958998671,
        "distinct-2": 0.9746835443037974,
        "vocab_size-2": 77,
        "unique-2": 76,
        "entropy-2": 6.24359229878263,
        "cond_entropy-2": 0.49215070490375057,
        "distinct-3": 1.0,
        "vocab_size-3": 74,
        "unique-3": 74,
        "entropy-3": 6.2094533656289554,
        "cond_entropy-3": -0.030072146032430563,
        "total_length-nopunct": 74,
        "mean_pred_length-nopunct": 14.8,
        "std_pred_length-nopunct": 6.079473661428265,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7972972972972973,
        "vocab_size-1-nopunct": 59,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 5.682162149295792,
        "distinct-2-nopunct": 0.9710144927536232,
        "vocab_size-2-nopunct": 67,
        "unique-2-nopunct": 66,
        "entropy-2-nopunct": 6.039613043703331,
        "cond_entropy-2-nopunct": 0.39566040283748616,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 64,
        "unique-3-nopunct": 64,
        "entropy-3-nopunct": 6.0,
        "cond_entropy-3-nopunct": -0.03422933955686489,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.84173,
            "recall": 0.79511,
            "fmeasure": 0.81145
        },
        "rouge2": {
            "precision": 0.71697,
            "recall": 0.66425,
            "fmeasure": 0.68354
        },
        "rougeL": {
            "precision": 0.7977,
            "recall": 0.74986,
            "fmeasure": 0.76687
        },
        "rougeLsum": {
            "precision": 0.7977,
            "recall": 0.74986,
            "fmeasure": 0.76687
        },
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.2,
            "3": 0.8571428571428571
        },
        "nist": 5.241370768636513,
        "bleu": 51.80197,
        "bleurt": 0.3971,
        "nubia": {
            "semantic_relation": 4.41171,
            "contradiction": 2.60736,
            "irrelevancy": 44.22371,
            "logical_agreement": 53.16894,
            "grammar_ref": 4.74509,
            "grammar_hyp": 4.81555,
            "nubia_score": 0.79312
        },
        "meteor": 0.45133852688314513,
        "bertscore": {
            "precision": 0.947,
            "recall": 0.94352,
            "f1": 0.9452
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_351": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 10,
        "unique-1": 8,
        "entropy-1": 3.2516291673878226,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.2381054815525046,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.0957952550009344,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.262496476250065,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75758,
            "recall": 0.93939,
            "fmeasure": 0.83413
        },
        "rouge2": {
            "precision": 0.63333,
            "recall": 0.80476,
            "fmeasure": 0.70392
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.82576,
            "fmeasure": 0.73365
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.82576,
            "fmeasure": 0.73365
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.8
        },
        "nist": 2.306664886548115,
        "bleu": 27.09199,
        "bleurt": 0.67831,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20045,
            "irrelevancy": 22.76085,
            "logical_agreement": 77.0387,
            "grammar_ref": 3.38649,
            "grammar_hyp": 3.17028,
            "nubia_score": 0.92133
        },
        "meteor": 0.4912092865802179,
        "bertscore": {
            "precision": 0.94572,
            "recall": 0.94055,
            "f1": 0.94053
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_295": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.78,
        "msttr-100_nopunct": 0.82,
        "total_length": 178,
        "mean_pred_length": 16.181818181818183,
        "std_pred_length": 7.407835922713951,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.651685393258427,
        "vocab_size-1": 116,
        "unique-1": 93,
        "entropy-1": 6.455768803486733,
        "distinct-2": 0.9041916167664671,
        "vocab_size-2": 151,
        "unique-2": 138,
        "entropy-2": 7.170472912387585,
        "cond_entropy-2": 0.5540206543934677,
        "distinct-3": 0.9551282051282052,
        "vocab_size-3": 149,
        "unique-3": 142,
        "entropy-3": 7.195658629118674,
        "cond_entropy-3": 0.04022126276279113,
        "total_length-nopunct": 157,
        "mean_pred_length-nopunct": 14.272727272727273,
        "std_pred_length-nopunct": 6.648183745011718,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6942675159235668,
        "vocab_size-1-nopunct": 109,
        "unique-1-nopunct": 88,
        "entropy-1-nopunct": 6.454555045630922,
        "distinct-2-nopunct": 0.8904109589041096,
        "vocab_size-2-nopunct": 130,
        "unique-2-nopunct": 117,
        "entropy-2-nopunct": 6.945922911794838,
        "cond_entropy-2-nopunct": 0.5478111725739649,
        "distinct-3-nopunct": 0.9481481481481482,
        "vocab_size-3-nopunct": 128,
        "unique-3-nopunct": 121,
        "entropy-3-nopunct": 6.97311189334715,
        "cond_entropy-3-nopunct": 0.039655041685160465,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85621,
            "recall": 0.86964,
            "fmeasure": 0.85814
        },
        "rouge2": {
            "precision": 0.72377,
            "recall": 0.73302,
            "fmeasure": 0.72413
        },
        "rougeL": {
            "precision": 0.80835,
            "recall": 0.82471,
            "fmeasure": 0.81178
        },
        "rougeLsum": {
            "precision": 0.80835,
            "recall": 0.82471,
            "fmeasure": 0.81178
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.4375,
            "3": 0.9105691056910569
        },
        "nist": 6.420508909291129,
        "bleu": 64.11011,
        "bleurt": 0.567,
        "nubia": {
            "semantic_relation": 4.72974,
            "contradiction": 0.44959,
            "irrelevancy": 12.71447,
            "logical_agreement": 86.83594,
            "grammar_ref": 4.24853,
            "grammar_hyp": 4.14434,
            "nubia_score": 0.92783
        },
        "meteor": 0.4966513452475109,
        "bertscore": {
            "precision": 0.9632,
            "recall": 0.96319,
            "f1": 0.96298
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_270": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.785,
        "total_length": 469,
        "mean_pred_length": 15.129032258064516,
        "std_pred_length": 4.360689021346844,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.582089552238806,
        "vocab_size-1": 273,
        "unique-1": 224,
        "entropy-1": 7.273223568111974,
        "distinct-2": 0.9452054794520548,
        "vocab_size-2": 414,
        "unique-2": 395,
        "entropy-2": 8.65350985531177,
        "cond_entropy-2": 1.1365205775568668,
        "distinct-3": 0.995085995085995,
        "vocab_size-3": 405,
        "unique-3": 403,
        "entropy-3": 8.659056974438228,
        "cond_entropy-3": 0.00987044426891562,
        "total_length-nopunct": 404,
        "mean_pred_length-nopunct": 13.03225806451613,
        "std_pred_length-nopunct": 3.4686045438749287,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6633663366336634,
        "vocab_size-1-nopunct": 268,
        "unique-1-nopunct": 223,
        "entropy-1-nopunct": 7.523478191569371,
        "distinct-2-nopunct": 0.9490616621983914,
        "vocab_size-2-nopunct": 354,
        "unique-2-nopunct": 340,
        "entropy-2-nopunct": 8.427430170178157,
        "cond_entropy-2-nopunct": 0.9709943566923845,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 342,
        "unique-3-nopunct": 342,
        "entropy-3-nopunct": 8.417852514885888,
        "cond_entropy-3-nopunct": -0.004947096367106635,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79732,
            "recall": 0.76532,
            "fmeasure": 0.77209
        },
        "rouge2": {
            "precision": 0.58458,
            "recall": 0.56926,
            "fmeasure": 0.57217
        },
        "rougeL": {
            "precision": 0.66805,
            "recall": 0.64949,
            "fmeasure": 0.65144
        },
        "rougeLsum": {
            "precision": 0.66805,
            "recall": 0.64949,
            "fmeasure": 0.65144
        },
        "local_recall": {
            "1": 0.21333333333333335,
            "2": 0.5316455696202531,
            "3": 0.790625
        },
        "nist": 6.764424125677572,
        "bleu": 50.66356,
        "bleurt": 0.34188,
        "nubia": {
            "semantic_relation": 4.45116,
            "contradiction": 2.14941,
            "irrelevancy": 27.06618,
            "logical_agreement": 70.78441,
            "grammar_ref": 4.63543,
            "grammar_hyp": 4.60017,
            "nubia_score": 0.80839
        },
        "meteor": 0.40864780734646694,
        "bertscore": {
            "precision": 0.93537,
            "recall": 0.93093,
            "f1": 0.93196
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_390": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.82,
        "total_length": 132,
        "mean_pred_length": 16.5,
        "std_pred_length": 4.743416490252569,
        "median_pred_length": 15.5,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.7121212121212122,
        "vocab_size-1": 94,
        "unique-1": 77,
        "entropy-1": 6.23935879733958,
        "distinct-2": 0.9596774193548387,
        "vocab_size-2": 119,
        "unique-2": 114,
        "entropy-2": 6.87355114909654,
        "cond_entropy-2": 0.4925817273710871,
        "distinct-3": 0.9655172413793104,
        "vocab_size-3": 112,
        "unique-3": 108,
        "entropy-3": 6.789015477886179,
        "cond_entropy-3": -0.07897393594895799,
        "total_length-nopunct": 117,
        "mean_pred_length-nopunct": 14.625,
        "std_pred_length-nopunct": 4.121210380458634,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 91,
        "unique-1-nopunct": 76,
        "entropy-1-nopunct": 6.299810125547808,
        "distinct-2-nopunct": 0.9541284403669725,
        "vocab_size-2-nopunct": 104,
        "unique-2-nopunct": 99,
        "entropy-2-nopunct": 6.676441205510862,
        "cond_entropy-2-nopunct": 0.4185066464977734,
        "distinct-3-nopunct": 0.9603960396039604,
        "vocab_size-3-nopunct": 97,
        "unique-3-nopunct": 93,
        "entropy-3-nopunct": 6.579003561959703,
        "cond_entropy-3-nopunct": -0.09017086182711156,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8559,
            "recall": 0.75401,
            "fmeasure": 0.79733
        },
        "rouge2": {
            "precision": 0.61129,
            "recall": 0.53984,
            "fmeasure": 0.56769
        },
        "rougeL": {
            "precision": 0.66336,
            "recall": 0.58112,
            "fmeasure": 0.61357
        },
        "rougeLsum": {
            "precision": 0.66336,
            "recall": 0.58112,
            "fmeasure": 0.61357
        },
        "local_recall": {
            "1": 0.08695652173913043,
            "2": 0.3076923076923077,
            "3": 0.7884615384615384
        },
        "nist": 4.835724819178704,
        "bleu": 43.31517,
        "bleurt": 0.40984,
        "nubia": {
            "semantic_relation": 4.43338,
            "contradiction": 1.13901,
            "irrelevancy": 12.98569,
            "logical_agreement": 85.87529,
            "grammar_ref": 4.47406,
            "grammar_hyp": 4.86053,
            "nubia_score": 0.76695
        },
        "meteor": 0.39144223617684937,
        "bertscore": {
            "precision": 0.95079,
            "recall": 0.93915,
            "f1": 0.94431
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_272": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 94,
        "mean_pred_length": 13.428571428571429,
        "std_pred_length": 2.3211538298959886,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.648936170212766,
        "vocab_size-1": 61,
        "unique-1": 47,
        "entropy-1": 5.597863751763829,
        "distinct-2": 0.8620689655172413,
        "vocab_size-2": 75,
        "unique-2": 64,
        "entropy-2": 6.158404559042246,
        "cond_entropy-2": 0.41163955722086654,
        "distinct-3": 0.8875,
        "vocab_size-3": 71,
        "unique-3": 62,
        "entropy-3": 6.096928094887357,
        "cond_entropy-3": -0.06157930718432282,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 11.857142857142858,
        "std_pred_length-nopunct": 2.356060357495806,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7108433734939759,
        "vocab_size-1-nopunct": 59,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.624669853786762,
        "distinct-2-nopunct": 0.868421052631579,
        "vocab_size-2-nopunct": 66,
        "unique-2-nopunct": 57,
        "entropy-2-nopunct": 5.974836888415124,
        "cond_entropy-2-nopunct": 0.3929642325615345,
        "distinct-3-nopunct": 0.8985507246376812,
        "vocab_size-3-nopunct": 62,
        "unique-3-nopunct": 55,
        "entropy-3-nopunct": 5.905625906053528,
        "cond_entropy-3-nopunct": -0.0704916435905836,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82946,
            "recall": 0.86337,
            "fmeasure": 0.83951
        },
        "rouge2": {
            "precision": 0.67445,
            "recall": 0.69206,
            "fmeasure": 0.67818
        },
        "rougeL": {
            "precision": 0.81336,
            "recall": 0.84589,
            "fmeasure": 0.82281
        },
        "rougeLsum": {
            "precision": 0.81336,
            "recall": 0.84589,
            "fmeasure": 0.82281
        },
        "local_recall": {
            "1": 0.4375,
            "2": 0.46153846153846156,
            "3": 0.8571428571428571
        },
        "nist": 4.674519619467491,
        "bleu": 50.48814,
        "bleurt": 0.3024,
        "nubia": {
            "semantic_relation": 4.55531,
            "contradiction": 10.07516,
            "irrelevancy": 23.38912,
            "logical_agreement": 66.53572,
            "grammar_ref": 5.14386,
            "grammar_hyp": 5.34591,
            "nubia_score": 0.74732
        },
        "meteor": 0.44495874768241805,
        "bertscore": {
            "precision": 0.92766,
            "recall": 0.95083,
            "f1": 0.93575
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_352": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 46,
        "mean_pred_length": 23.0,
        "std_pred_length": 10.0,
        "median_pred_length": 23.0,
        "min_pred_length": 13,
        "max_pred_length": 33,
        "distinct-1": 0.6304347826086957,
        "vocab_size-1": 29,
        "unique-1": 18,
        "entropy-1": 4.646072217435267,
        "distinct-2": 0.8181818181818182,
        "vocab_size-2": 36,
        "unique-2": 28,
        "entropy-2": 5.095795255000931,
        "cond_entropy-2": 0.44415438932119994,
        "distinct-3": 0.8571428571428571,
        "vocab_size-3": 36,
        "unique-3": 30,
        "entropy-3": 5.106603137064475,
        "cond_entropy-3": 0.02812389937955851,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 21.5,
        "std_pred_length-nopunct": 9.5,
        "median_pred_length-nopunct": 21.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.627906976744186,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.5340664296648825,
        "distinct-2-nopunct": 0.8048780487804879,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.967308102179057,
        "cond_entropy-2-nopunct": 0.4523732981257486,
        "distinct-3-nopunct": 0.8461538461538461,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.977709911169939,
        "cond_entropy-3-nopunct": 0.03041431680826746,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.51136,
            "recall": 0.51598,
            "fmeasure": 0.51153
        },
        "rouge2": {
            "precision": 0.21875,
            "recall": 0.25617,
            "fmeasure": 0.23597
        },
        "rougeL": {
            "precision": 0.35227,
            "recall": 0.37192,
            "fmeasure": 0.35996
        },
        "rougeLsum": {
            "precision": 0.35227,
            "recall": 0.37192,
            "fmeasure": 0.35996
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.5294117647058824
        },
        "nist": 2.747258027111945,
        "bleu": 14.69145,
        "bleurt": 0.00582,
        "nubia": {
            "semantic_relation": 2.71553,
            "contradiction": 3.69691,
            "irrelevancy": 32.02723,
            "logical_agreement": 64.27585,
            "grammar_ref": 4.82994,
            "grammar_hyp": 3.93876,
            "nubia_score": 0.41132
        },
        "meteor": 0.28563385143195663,
        "bertscore": {
            "precision": 0.87389,
            "recall": 0.85329,
            "f1": 0.86312
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_354": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "nist": 3.1221860348123966,
        "bleu": 58.59059,
        "bleurt": 0.76706,
        "nubia": {
            "semantic_relation": 4.90953,
            "contradiction": 0.355,
            "irrelevancy": 0.51033,
            "logical_agreement": 99.13468,
            "grammar_ref": 5.11392,
            "grammar_hyp": 4.76303,
            "nubia_score": 1.0
        },
        "meteor": 0.4076949933266327,
        "bertscore": {
            "precision": 0.97545,
            "recall": 0.97545,
            "f1": 0.97545
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_392": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.69,
        "total_length": 197,
        "mean_pred_length": 15.153846153846153,
        "std_pred_length": 3.438384098250309,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 19,
        "distinct-1": 0.6040609137055838,
        "vocab_size-1": 119,
        "unique-1": 87,
        "entropy-1": 6.418502226987568,
        "distinct-2": 0.907608695652174,
        "vocab_size-2": 167,
        "unique-2": 150,
        "entropy-2": 7.338779347361374,
        "cond_entropy-2": 0.7438664049730145,
        "distinct-3": 0.9649122807017544,
        "vocab_size-3": 165,
        "unique-3": 159,
        "entropy-3": 7.347677076289398,
        "cond_entropy-3": -0.0004462832763781153,
        "total_length-nopunct": 174,
        "mean_pred_length-nopunct": 13.384615384615385,
        "std_pred_length-nopunct": 3.076923076923077,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6609195402298851,
        "vocab_size-1-nopunct": 115,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.457404539663714,
        "distinct-2-nopunct": 0.9006211180124224,
        "vocab_size-2-nopunct": 145,
        "unique-2-nopunct": 129,
        "entropy-2-nopunct": 7.132159114139448,
        "cond_entropy-2-nopunct": 0.7170651734223528,
        "distinct-3-nopunct": 0.9594594594594594,
        "vocab_size-3-nopunct": 142,
        "unique-3-nopunct": 136,
        "entropy-3-nopunct": 7.128372284547865,
        "cond_entropy-3-nopunct": -0.006598647620802476,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80037,
            "recall": 0.75145,
            "fmeasure": 0.77066
        },
        "rouge2": {
            "precision": 0.5982,
            "recall": 0.56738,
            "fmeasure": 0.57865
        },
        "rougeL": {
            "precision": 0.68115,
            "recall": 0.63943,
            "fmeasure": 0.65567
        },
        "rougeLsum": {
            "precision": 0.68115,
            "recall": 0.63943,
            "fmeasure": 0.65567
        },
        "local_recall": {
            "1": 0.14705882352941177,
            "2": 0.6274509803921569,
            "3": 0.8211382113821138
        },
        "nist": 6.271336096341872,
        "bleu": 53.30176,
        "bleurt": 0.20936,
        "nubia": {
            "semantic_relation": 4.18884,
            "contradiction": 4.60851,
            "irrelevancy": 34.05764,
            "logical_agreement": 61.33385,
            "grammar_ref": 4.86507,
            "grammar_hyp": 4.9307,
            "nubia_score": 0.72718
        },
        "meteor": 0.4314554750849487,
        "bertscore": {
            "precision": 0.92485,
            "recall": 0.92017,
            "f1": 0.92025
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_395": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.94737
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 4.260329933156776,
        "bleu": 100.0,
        "bleurt": 0.88151,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.5469,
            "irrelevancy": 1.17376,
            "logical_agreement": 98.27934,
            "grammar_ref": 4.07798,
            "grammar_hyp": 4.24873,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_296": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.66,
        "msttr-100_nopunct": NaN,
        "total_length": 114,
        "mean_pred_length": 16.285714285714285,
        "std_pred_length": 6.860118402024554,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.631578947368421,
        "vocab_size-1": 72,
        "unique-1": 54,
        "entropy-1": 5.770298541272051,
        "distinct-2": 0.897196261682243,
        "vocab_size-2": 96,
        "unique-2": 85,
        "entropy-2": 6.535859509765626,
        "cond_entropy-2": 0.6514175652771916,
        "distinct-3": 0.97,
        "vocab_size-3": 97,
        "unique-3": 94,
        "entropy-3": 6.583856189774739,
        "cond_entropy-3": 0.04238920337357766,
        "total_length-nopunct": 98,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.732115042211108,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6836734693877551,
        "vocab_size-1-nopunct": 67,
        "unique-1-nopunct": 53,
        "entropy-1-nopunct": 5.701608380284969,
        "distinct-2-nopunct": 0.9120879120879121,
        "vocab_size-2-nopunct": 83,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 6.331970464374527,
        "cond_entropy-2-nopunct": 0.6657663175551556,
        "distinct-3-nopunct": 0.9642857142857143,
        "vocab_size-3-nopunct": 81,
        "unique-3-nopunct": 78,
        "entropy-3-nopunct": 6.320888851350189,
        "cond_entropy-3-nopunct": -0.008334360277078724,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66223,
            "recall": 0.6926,
            "fmeasure": 0.67259
        },
        "rouge2": {
            "precision": 0.41923,
            "recall": 0.44383,
            "fmeasure": 0.42881
        },
        "rougeL": {
            "precision": 0.5686,
            "recall": 0.59305,
            "fmeasure": 0.57685
        },
        "rougeLsum": {
            "precision": 0.5686,
            "recall": 0.59305,
            "fmeasure": 0.57685
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.5882352941176471,
            "3": 0.6811594202898551
        },
        "nist": 4.103031681020467,
        "bleu": 29.71993,
        "bleurt": 0.08916,
        "nubia": {
            "semantic_relation": 3.85894,
            "contradiction": 0.59207,
            "irrelevancy": 74.14998,
            "logical_agreement": 25.25795,
            "grammar_ref": 4.06397,
            "grammar_hyp": 4.0883,
            "nubia_score": 0.69784
        },
        "meteor": 0.36412566034863236,
        "bertscore": {
            "precision": 0.90395,
            "recall": 0.91125,
            "f1": 0.90677
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_297": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 3.0,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 15,
        "distinct-1": 0.875,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.303508854797679,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.09060036801448042,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.243300368538955,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.1002408513582384,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.53896,
            "recall": 0.77525,
            "fmeasure": 0.63017
        },
        "rouge2": {
            "precision": 0.36923,
            "recall": 0.53939,
            "fmeasure": 0.43345
        },
        "rougeL": {
            "precision": 0.46753,
            "recall": 0.68687,
            "fmeasure": 0.55119
        },
        "rougeLsum": {
            "precision": 0.46753,
            "recall": 0.68687,
            "fmeasure": 0.55119
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "nist": 2.7414221063198942,
        "bleu": 37.16127,
        "bleurt": 0.17103,
        "nubia": {
            "semantic_relation": 3.34477,
            "contradiction": 40.96768,
            "irrelevancy": 14.1389,
            "logical_agreement": 44.89343,
            "grammar_ref": 3.61093,
            "grammar_hyp": 3.71116,
            "nubia_score": 0.53657
        },
        "meteor": 0.44087878493871163,
        "bertscore": {
            "precision": 0.88187,
            "recall": 0.94099,
            "f1": 0.9101
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_299": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5625,
            "recall": 0.81818,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.68889,
            "fmeasure": 0.54
        },
        "rougeL": {
            "precision": 0.54167,
            "recall": 0.81212,
            "fmeasure": 0.64957
        },
        "rougeLsum": {
            "precision": 0.54167,
            "recall": 0.81212,
            "fmeasure": 0.64957
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.75
        },
        "nist": 1.9656538879523529,
        "bleu": 22.89416,
        "bleurt": 0.6102,
        "nubia": {
            "semantic_relation": 3.9036,
            "contradiction": 86.44721,
            "irrelevancy": 2.14634,
            "logical_agreement": 11.40645,
            "grammar_ref": 3.16175,
            "grammar_hyp": 2.59411,
            "nubia_score": 0.71862
        },
        "meteor": 0.3880733091558322,
        "bertscore": {
            "precision": 0.92043,
            "recall": 0.96935,
            "f1": 0.94426
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_320": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.675,
        "msttr-100_nopunct": 0.725,
        "total_length": 234,
        "mean_pred_length": 16.714285714285715,
        "std_pred_length": 7.254836528911212,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 37,
        "distinct-1": 0.6068376068376068,
        "vocab_size-1": 142,
        "unique-1": 120,
        "entropy-1": 6.5237408466507425,
        "distinct-2": 0.9318181818181818,
        "vocab_size-2": 205,
        "unique-2": 194,
        "entropy-2": 7.6290425544140685,
        "cond_entropy-2": 0.9487097319099236,
        "distinct-3": 0.9805825242718447,
        "vocab_size-3": 202,
        "unique-3": 198,
        "entropy-3": 7.647665575726908,
        "cond_entropy-3": 0.028974672902864217,
        "total_length-nopunct": 207,
        "mean_pred_length-nopunct": 14.785714285714286,
        "std_pred_length-nopunct": 7.173150049500782,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 138,
        "unique-1-nopunct": 118,
        "entropy-1-nopunct": 6.612553288163928,
        "distinct-2-nopunct": 0.9326424870466321,
        "vocab_size-2-nopunct": 180,
        "unique-2-nopunct": 171,
        "entropy-2-nopunct": 7.439556648644605,
        "cond_entropy-2-nopunct": 0.8920194686152607,
        "distinct-3-nopunct": 0.9832402234636871,
        "vocab_size-3-nopunct": 176,
        "unique-3-nopunct": 173,
        "entropy-3-nopunct": 7.450296224191622,
        "cond_entropy-3-nopunct": 0.01711167298124272,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83329,
            "recall": 0.81291,
            "fmeasure": 0.81796
        },
        "rouge2": {
            "precision": 0.64779,
            "recall": 0.6407,
            "fmeasure": 0.64091
        },
        "rougeL": {
            "precision": 0.71759,
            "recall": 0.7171,
            "fmeasure": 0.71324
        },
        "rougeLsum": {
            "precision": 0.71759,
            "recall": 0.7171,
            "fmeasure": 0.71324
        },
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.5909090909090909,
            "3": 0.8571428571428571
        },
        "nist": 6.386073201383466,
        "bleu": 60.55524,
        "bleurt": 0.39908,
        "nubia": {
            "semantic_relation": 4.25828,
            "contradiction": 2.2867,
            "irrelevancy": 36.93126,
            "logical_agreement": 60.78204,
            "grammar_ref": 4.83858,
            "grammar_hyp": 4.90527,
            "nubia_score": 0.73255
        },
        "meteor": 0.44971532280770593,
        "bertscore": {
            "precision": 0.9449,
            "recall": 0.93338,
            "f1": 0.93736
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_396": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.64,
        "msttr-100_nopunct": NaN,
        "total_length": 112,
        "mean_pred_length": 14.0,
        "std_pred_length": 2.5495097567963922,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.6160714285714286,
        "vocab_size-1": 69,
        "unique-1": 54,
        "entropy-1": 5.651790832749008,
        "distinct-2": 0.9134615384615384,
        "vocab_size-2": 95,
        "unique-2": 88,
        "entropy-2": 6.508132025833406,
        "cond_entropy-2": 0.7144615076465841,
        "distinct-3": 0.9375,
        "vocab_size-3": 90,
        "unique-3": 84,
        "entropy-3": 6.45996250072116,
        "cond_entropy-3": -0.03214388408660261,
        "total_length-nopunct": 94,
        "mean_pred_length-nopunct": 11.75,
        "std_pred_length-nopunct": 2.6339134382131846,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7021276595744681,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 53,
        "entropy-1-nopunct": 5.736569139022513,
        "distinct-2-nopunct": 0.8953488372093024,
        "vocab_size-2-nopunct": 77,
        "unique-2-nopunct": 70,
        "entropy-2-nopunct": 6.1937066151672155,
        "cond_entropy-2-nopunct": 0.5216044261591252,
        "distinct-3-nopunct": 0.9230769230769231,
        "vocab_size-3-nopunct": 72,
        "unique-3-nopunct": 66,
        "entropy-3-nopunct": 6.131556065016102,
        "cond_entropy-3-nopunct": -0.038298433275747105,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71057,
            "recall": 0.73125,
            "fmeasure": 0.71397
        },
        "rouge2": {
            "precision": 0.53763,
            "recall": 0.56863,
            "fmeasure": 0.54463
        },
        "rougeL": {
            "precision": 0.61976,
            "recall": 0.65045,
            "fmeasure": 0.62782
        },
        "rougeLsum": {
            "precision": 0.61976,
            "recall": 0.65045,
            "fmeasure": 0.62782
        },
        "local_recall": {
            "1": 0.2682926829268293,
            "2": 0.5714285714285714,
            "3": 0.8125
        },
        "nist": 4.92631625301596,
        "bleu": 48.41229,
        "bleurt": 0.11349,
        "nubia": {
            "semantic_relation": 4.00624,
            "contradiction": 24.29613,
            "irrelevancy": 25.11467,
            "logical_agreement": 50.5892,
            "grammar_ref": 5.12618,
            "grammar_hyp": 4.88105,
            "nubia_score": 0.68398
        },
        "meteor": 0.4520544208304741,
        "bertscore": {
            "precision": 0.92339,
            "recall": 0.93019,
            "f1": 0.92312
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_322": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 0.5,
        "median_pred_length": 17.5,
        "min_pred_length": 17,
        "max_pred_length": 18,
        "distinct-1": 0.8857142857142857,
        "vocab_size-1": 31,
        "unique-1": 27,
        "entropy-1": 4.900711588373535,
        "distinct-2": 1.0,
        "vocab_size-2": 33,
        "unique-2": 33,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": 0.09692928423166847,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.09019780897157811,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9354838709677419,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.825164052322361,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.04171571922345572,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.10309349296410335,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.69298,
            "recall": 0.72087,
            "fmeasure": 0.70451
        },
        "rouge2": {
            "precision": 0.30159,
            "recall": 0.31603,
            "fmeasure": 0.30808
        },
        "rougeL": {
            "precision": 0.46316,
            "recall": 0.48954,
            "fmeasure": 0.47519
        },
        "rougeLsum": {
            "precision": 0.46316,
            "recall": 0.48954,
            "fmeasure": 0.47519
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6896551724137931
        },
        "nist": 3.6067002609988332,
        "bleu": 16.12497,
        "bleurt": 0.32556,
        "nubia": {
            "semantic_relation": 4.51773,
            "contradiction": 1.48948,
            "irrelevancy": 1.14507,
            "logical_agreement": 97.36545,
            "grammar_ref": 4.49155,
            "grammar_hyp": 4.27342,
            "nubia_score": 0.90214
        },
        "meteor": 0.36723800376780885,
        "bertscore": {
            "precision": 0.89362,
            "recall": 0.91707,
            "f1": 0.90513
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_399": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.53333,
            "recall": 0.72727,
            "fmeasure": 0.61538
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.4,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.46667,
            "recall": 0.63636,
            "fmeasure": 0.53846
        },
        "rougeLsum": {
            "precision": 0.46667,
            "recall": 0.63636,
            "fmeasure": 0.53846
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7272727272727273
        },
        "nist": 2.184473483563297,
        "bleu": 22.63736,
        "bleurt": 0.05595,
        "nubia": {
            "semantic_relation": 4.1901,
            "contradiction": 0.08595,
            "irrelevancy": 99.68573,
            "logical_agreement": 0.22832,
            "grammar_ref": 4.20968,
            "grammar_hyp": 3.72031,
            "nubia_score": 0.82624
        },
        "meteor": 0.3455898357930964,
        "bertscore": {
            "precision": 0.8417,
            "recall": 0.89837,
            "f1": 0.86911
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_324": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.81,
        "total_length": 180,
        "mean_pred_length": 16.363636363636363,
        "std_pred_length": 5.756778254177296,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.6444444444444445,
        "vocab_size-1": 116,
        "unique-1": 93,
        "entropy-1": 6.416426478120321,
        "distinct-2": 0.9644970414201184,
        "vocab_size-2": 163,
        "unique-2": 158,
        "entropy-2": 7.325406729168784,
        "cond_entropy-2": 0.7538083279436829,
        "distinct-3": 0.9936708860759493,
        "vocab_size-3": 157,
        "unique-3": 156,
        "entropy-3": 7.291122520329018,
        "cond_entropy-3": -0.029029779863540273,
        "total_length-nopunct": 159,
        "mean_pred_length-nopunct": 14.454545454545455,
        "std_pred_length-nopunct": 5.726551181099499,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7044025157232704,
        "vocab_size-1-nopunct": 112,
        "unique-1-nopunct": 91,
        "entropy-1-nopunct": 6.485694002626021,
        "distinct-2-nopunct": 0.9594594594594594,
        "vocab_size-2-nopunct": 142,
        "unique-2-nopunct": 137,
        "entropy-2-nopunct": 7.123271693317032,
        "cond_entropy-2-nopunct": 0.6815919878431572,
        "distinct-3-nopunct": 0.9927007299270073,
        "vocab_size-3-nopunct": 136,
        "unique-3-nopunct": 135,
        "entropy-3-nopunct": 7.083433542814526,
        "cond_entropy-3-nopunct": -0.0402177242584708,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7653,
            "recall": 0.68869,
            "fmeasure": 0.71749
        },
        "rouge2": {
            "precision": 0.52118,
            "recall": 0.4822,
            "fmeasure": 0.49548
        },
        "rougeL": {
            "precision": 0.68648,
            "recall": 0.61704,
            "fmeasure": 0.64331
        },
        "rougeLsum": {
            "precision": 0.68648,
            "recall": 0.61704,
            "fmeasure": 0.64331
        },
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.44,
            "3": 0.7092198581560284
        },
        "nist": 5.430961281271563,
        "bleu": 41.34329,
        "bleurt": 0.3215,
        "nubia": {
            "semantic_relation": 4.3317,
            "contradiction": 5.43786,
            "irrelevancy": 13.46648,
            "logical_agreement": 81.09566,
            "grammar_ref": 4.70918,
            "grammar_hyp": 4.84014,
            "nubia_score": 0.77532
        },
        "meteor": 0.38510906939934203,
        "bertscore": {
            "precision": 0.93717,
            "recall": 0.92026,
            "f1": 0.92826
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_355": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 69,
        "mean_pred_length": 17.25,
        "std_pred_length": 4.264680527307995,
        "median_pred_length": 17.0,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.7536231884057971,
        "vocab_size-1": 52,
        "unique-1": 41,
        "entropy-1": 5.535919021932847,
        "distinct-2": 0.9538461538461539,
        "vocab_size-2": 62,
        "unique-2": 59,
        "entropy-2": 5.930060120720765,
        "cond_entropy-2": 0.3063014332399306,
        "distinct-3": 0.9836065573770492,
        "vocab_size-3": 60,
        "unique-3": 59,
        "entropy-3": 5.897950452316981,
        "cond_entropy-3": -0.026056704973765114,
        "total_length-nopunct": 61,
        "mean_pred_length-nopunct": 15.25,
        "std_pred_length-nopunct": 3.766629793329841,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.819672131147541,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.545331189950966,
        "distinct-2-nopunct": 0.9473684210526315,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 5.727626856270001,
        "cond_entropy-2-nopunct": 0.19179785211636324,
        "distinct-3-nopunct": 0.9811320754716981,
        "vocab_size-3-nopunct": 52,
        "unique-3-nopunct": 51,
        "entropy-3-nopunct": 5.690184605506592,
        "cond_entropy-3-nopunct": -0.029497861488334873,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.87245,
            "recall": 0.88204,
            "fmeasure": 0.87182
        },
        "rouge2": {
            "precision": 0.74347,
            "recall": 0.74335,
            "fmeasure": 0.73992
        },
        "rougeL": {
            "precision": 0.80199,
            "recall": 0.85264,
            "fmeasure": 0.81706
        },
        "rougeLsum": {
            "precision": 0.80199,
            "recall": 0.85264,
            "fmeasure": 0.81706
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.9574468085106383
        },
        "nist": 5.866113278592317,
        "bleu": 70.15017,
        "bleurt": 0.61924,
        "nubia": {
            "semantic_relation": 4.81071,
            "contradiction": 3.08039,
            "irrelevancy": 29.75078,
            "logical_agreement": 67.16883,
            "grammar_ref": 4.25492,
            "grammar_hyp": 4.3065,
            "nubia_score": 0.90945
        },
        "meteor": 0.5247529190815476,
        "bertscore": {
            "precision": 0.98222,
            "recall": 0.98132,
            "f1": 0.97998
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_357": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.63,
        "msttr-100_nopunct": NaN,
        "total_length": 101,
        "mean_pred_length": 12.625,
        "std_pred_length": 3.0388114452858046,
        "median_pred_length": 11.5,
        "min_pred_length": 9,
        "max_pred_length": 18,
        "distinct-1": 0.6237623762376238,
        "vocab_size-1": 63,
        "unique-1": 48,
        "entropy-1": 5.62310913182125,
        "distinct-2": 0.8279569892473119,
        "vocab_size-2": 77,
        "unique-2": 69,
        "entropy-2": 6.130136230276769,
        "cond_entropy-2": 0.3380036447721139,
        "distinct-3": 0.8588235294117647,
        "vocab_size-3": 73,
        "unique-3": 67,
        "entropy-3": 6.073751818337932,
        "cond_entropy-3": -0.017888169037071452,
        "total_length-nopunct": 85,
        "mean_pred_length-nopunct": 10.625,
        "std_pred_length-nopunct": 2.341874249399399,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.6823529411764706,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.5647974074104,
        "distinct-2-nopunct": 0.8181818181818182,
        "vocab_size-2-nopunct": 63,
        "unique-2-nopunct": 56,
        "entropy-2-nopunct": 5.8345240404982235,
        "cond_entropy-2-nopunct": 0.3574766100984538,
        "distinct-3-nopunct": 0.855072463768116,
        "vocab_size-3-nopunct": 59,
        "unique-3-nopunct": 54,
        "entropy-3-nopunct": 5.763967391404001,
        "cond_entropy-3-nopunct": -0.0204392577670664,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.90449,
            "recall": 0.7904,
            "fmeasure": 0.83128
        },
        "rouge2": {
            "precision": 0.78704,
            "recall": 0.7087,
            "fmeasure": 0.73635
        },
        "rougeL": {
            "precision": 0.86936,
            "recall": 0.76283,
            "fmeasure": 0.80034
        },
        "rougeLsum": {
            "precision": 0.86936,
            "recall": 0.76283,
            "fmeasure": 0.80034
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.7340425531914894
        },
        "nist": 4.377769116178216,
        "bleu": 53.75314,
        "bleurt": 0.62641,
        "nubia": {
            "semantic_relation": 4.54232,
            "contradiction": 5.96499,
            "irrelevancy": 1.70041,
            "logical_agreement": 92.3346,
            "grammar_ref": 4.5568,
            "grammar_hyp": 4.86858,
            "nubia_score": 0.83478
        },
        "meteor": 0.4118028700046071,
        "bertscore": {
            "precision": 0.96956,
            "recall": 0.93296,
            "f1": 0.95007
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_325": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 10.8,
        "std_pred_length": 3.919183588453085,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 17,
        "distinct-1": 0.8518518518518519,
        "vocab_size-1": 46,
        "unique-1": 41,
        "entropy-1": 5.391746011896119,
        "distinct-2": 1.0,
        "vocab_size-2": 49,
        "unique-2": 49,
        "entropy-2": 5.614709844115208,
        "cond_entropy-2": 0.023087648074188727,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": -0.15527822547791104,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 2.9664793948382653,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.358519762996339,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.3219280948873635,
        "cond_entropy-2-nopunct": -0.01992500144231235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.1926450779423959,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78295,
            "recall": 0.69003,
            "fmeasure": 0.72467
        },
        "rouge2": {
            "precision": 0.6381,
            "recall": 0.55992,
            "fmeasure": 0.58774
        },
        "rougeL": {
            "precision": 0.75795,
            "recall": 0.6678,
            "fmeasure": 0.70114
        },
        "rougeLsum": {
            "precision": 0.75795,
            "recall": 0.6678,
            "fmeasure": 0.70114
        },
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.375,
            "3": 0.8157894736842105
        },
        "nist": 4.435427674225113,
        "bleu": 56.10872,
        "bleurt": 0.40094,
        "nubia": {
            "semantic_relation": 4.17132,
            "contradiction": 6.63907,
            "irrelevancy": 27.56642,
            "logical_agreement": 65.79451,
            "grammar_ref": 5.12632,
            "grammar_hyp": 5.38274,
            "nubia_score": 0.72066
        },
        "meteor": 0.42735698993563287,
        "bertscore": {
            "precision": 0.94395,
            "recall": 0.92503,
            "f1": 0.93302
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_273": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.775,
        "total_length": 265,
        "mean_pred_length": 18.928571428571427,
        "std_pred_length": 10.673493776067662,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 36,
        "distinct-1": 0.5849056603773585,
        "vocab_size-1": 155,
        "unique-1": 124,
        "entropy-1": 6.586738996678732,
        "distinct-2": 0.9163346613545816,
        "vocab_size-2": 230,
        "unique-2": 213,
        "entropy-2": 7.790229709312013,
        "cond_entropy-2": 1.0727359908404281,
        "distinct-3": 0.9704641350210971,
        "vocab_size-3": 230,
        "unique-3": 223,
        "entropy-3": 7.829671518940494,
        "cond_entropy-3": 0.05015233209654602,
        "total_length-nopunct": 234,
        "mean_pred_length-nopunct": 16.714285714285715,
        "std_pred_length-nopunct": 9.490059245852786,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.6495726495726496,
        "vocab_size-1-nopunct": 152,
        "unique-1-nopunct": 123,
        "entropy-1-nopunct": 6.714719153020484,
        "distinct-2-nopunct": 0.9227272727272727,
        "vocab_size-2-nopunct": 203,
        "unique-2-nopunct": 189,
        "entropy-2-nopunct": 7.614292043060267,
        "cond_entropy-2-nopunct": 0.959477607911972,
        "distinct-3-nopunct": 0.970873786407767,
        "vocab_size-3-nopunct": 200,
        "unique-3-nopunct": 194,
        "entropy-3-nopunct": 7.6282480999987525,
        "cond_entropy-3-nopunct": 0.020455801533138807,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66601,
            "recall": 0.65621,
            "fmeasure": 0.64499
        },
        "rouge2": {
            "precision": 0.42889,
            "recall": 0.4127,
            "fmeasure": 0.40903
        },
        "rougeL": {
            "precision": 0.5665,
            "recall": 0.54563,
            "fmeasure": 0.54206
        },
        "rougeLsum": {
            "precision": 0.5665,
            "recall": 0.54563,
            "fmeasure": 0.54206
        },
        "local_recall": {
            "1": 0.2191780821917808,
            "2": 0.5230769230769231,
            "3": 0.7565217391304347
        },
        "nist": 4.972984192796355,
        "bleu": 29.96281,
        "bleurt": 0.00738,
        "nubia": {
            "semantic_relation": 3.74189,
            "contradiction": 11.15605,
            "irrelevancy": 50.73997,
            "logical_agreement": 38.10399,
            "grammar_ref": 4.00042,
            "grammar_hyp": 4.03979,
            "nubia_score": 0.65644
        },
        "meteor": 0.34595303963034085,
        "bertscore": {
            "precision": 0.90788,
            "recall": 0.91591,
            "f1": 0.91092
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_328": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.77,
        "msttr-100_nopunct": NaN,
        "total_length": 109,
        "mean_pred_length": 18.166666666666668,
        "std_pred_length": 5.2094998693625945,
        "median_pred_length": 19.0,
        "min_pred_length": 11,
        "max_pred_length": 25,
        "distinct-1": 0.7522935779816514,
        "vocab_size-1": 82,
        "unique-1": 73,
        "entropy-1": 6.045303705332228,
        "distinct-2": 1.0,
        "vocab_size-2": 103,
        "unique-2": 103,
        "entropy-2": 6.686500527183236,
        "cond_entropy-2": 0.5327260326504109,
        "distinct-3": 1.0,
        "vocab_size-3": 97,
        "unique-3": 97,
        "entropy-3": 6.599912842187142,
        "cond_entropy-3": -0.08658768499609075,
        "total_length-nopunct": 98,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 4.606758320361751,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8061224489795918,
        "vocab_size-1-nopunct": 79,
        "unique-1-nopunct": 72,
        "entropy-1-nopunct": 6.0505852266137445,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 92,
        "unique-2-nopunct": 92,
        "entropy-2-nopunct": 6.523561956057027,
        "cond_entropy-2-nopunct": 0.5097674653672856,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 86,
        "unique-3-nopunct": 86,
        "entropy-3-nopunct": 6.426264754702099,
        "cond_entropy-3-nopunct": -0.09729720135491499,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79486,
            "recall": 0.81571,
            "fmeasure": 0.80165
        },
        "rouge2": {
            "precision": 0.63536,
            "recall": 0.66193,
            "fmeasure": 0.64575
        },
        "rougeL": {
            "precision": 0.72346,
            "recall": 0.76093,
            "fmeasure": 0.73755
        },
        "rougeLsum": {
            "precision": 0.72346,
            "recall": 0.76093,
            "fmeasure": 0.73755
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5909090909090909,
            "3": 0.8985507246376812
        },
        "nist": 5.7452635933507405,
        "bleu": 60.46681,
        "bleurt": 0.40813,
        "nubia": {
            "semantic_relation": 4.75307,
            "contradiction": 4.33386,
            "irrelevancy": 33.62168,
            "logical_agreement": 62.04445,
            "grammar_ref": 4.71157,
            "grammar_hyp": 4.89417,
            "nubia_score": 0.85771
        },
        "meteor": 0.5024781931031416,
        "bertscore": {
            "precision": 0.94969,
            "recall": 0.95461,
            "f1": 0.95117
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_400": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.79,
        "total_length": 160,
        "mean_pred_length": 16.0,
        "std_pred_length": 6.016643582596529,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.675,
        "vocab_size-1": 108,
        "unique-1": 87,
        "entropy-1": 6.382691026294644,
        "distinct-2": 0.96,
        "vocab_size-2": 144,
        "unique-2": 138,
        "entropy-2": 7.148818690495862,
        "cond_entropy-2": 0.6072815957815955,
        "distinct-3": 0.9785714285714285,
        "vocab_size-3": 137,
        "unique-3": 134,
        "entropy-3": 7.086425874087835,
        "cond_entropy-3": -0.05667853069377161,
        "total_length-nopunct": 137,
        "mean_pred_length-nopunct": 13.7,
        "std_pred_length-nopunct": 5.459853477887479,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7591240875912408,
        "vocab_size-1-nopunct": 104,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.48102971060299,
        "distinct-2-nopunct": 0.9606299212598425,
        "vocab_size-2-nopunct": 122,
        "unique-2-nopunct": 117,
        "entropy-2-nopunct": 6.909944529291833,
        "cond_entropy-2-nopunct": 0.4696236669059754,
        "distinct-3-nopunct": 0.9743589743589743,
        "vocab_size-3-nopunct": 114,
        "unique-3-nopunct": 111,
        "entropy-3-nopunct": 6.819082668301332,
        "cond_entropy-3-nopunct": -0.09267894154773577,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76975,
            "recall": 0.75317,
            "fmeasure": 0.73493
        },
        "rouge2": {
            "precision": 0.54161,
            "recall": 0.51126,
            "fmeasure": 0.5146
        },
        "rougeL": {
            "precision": 0.65621,
            "recall": 0.62239,
            "fmeasure": 0.6217
        },
        "rougeLsum": {
            "precision": 0.65621,
            "recall": 0.62239,
            "fmeasure": 0.6217
        },
        "local_recall": {
            "1": 0.2608695652173913,
            "2": 0.7407407407407407,
            "3": 0.7578947368421053
        },
        "nist": 5.723912150049092,
        "bleu": 52.39529,
        "bleurt": 0.33315,
        "nubia": {
            "semantic_relation": 4.28194,
            "contradiction": 4.06261,
            "irrelevancy": 30.12371,
            "logical_agreement": 65.81369,
            "grammar_ref": 5.10223,
            "grammar_hyp": 5.20343,
            "nubia_score": 0.724
        },
        "meteor": 0.4024759308369976,
        "bertscore": {
            "precision": 0.92926,
            "recall": 0.92686,
            "f1": 0.92602
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_275": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.76,
        "total_length": 154,
        "mean_pred_length": 19.25,
        "std_pred_length": 8.613216588476108,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 37,
        "distinct-1": 0.6233766233766234,
        "vocab_size-1": 96,
        "unique-1": 73,
        "entropy-1": 6.151214592112239,
        "distinct-2": 0.910958904109589,
        "vocab_size-2": 133,
        "unique-2": 122,
        "entropy-2": 7.001401442412028,
        "cond_entropy-2": 0.721756183447488,
        "distinct-3": 0.9565217391304348,
        "vocab_size-3": 132,
        "unique-3": 127,
        "entropy-3": 7.016097735747997,
        "cond_entropy-3": 0.011126618928321806,
        "total_length-nopunct": 130,
        "mean_pred_length-nopunct": 16.25,
        "std_pred_length-nopunct": 5.952940449895329,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6846153846153846,
        "vocab_size-1-nopunct": 89,
        "unique-1-nopunct": 70,
        "entropy-1-nopunct": 6.128255834010038,
        "distinct-2-nopunct": 0.9262295081967213,
        "vocab_size-2-nopunct": 113,
        "unique-2-nopunct": 105,
        "entropy-2-nopunct": 6.777008751479592,
        "cond_entropy-2-nopunct": 0.6650067767376168,
        "distinct-3-nopunct": 0.9649122807017544,
        "vocab_size-3-nopunct": 110,
        "unique-3-nopunct": 106,
        "entropy-3-nopunct": 6.762714575568261,
        "cond_entropy-3-nopunct": -0.01227813478267533,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76518,
            "recall": 0.73773,
            "fmeasure": 0.74462
        },
        "rouge2": {
            "precision": 0.54706,
            "recall": 0.53161,
            "fmeasure": 0.53577
        },
        "rougeL": {
            "precision": 0.66992,
            "recall": 0.64349,
            "fmeasure": 0.6515
        },
        "rougeLsum": {
            "precision": 0.66992,
            "recall": 0.64349,
            "fmeasure": 0.6515
        },
        "local_recall": {
            "1": 0.16,
            "2": 0.4090909090909091,
            "3": 0.8085106382978723
        },
        "nist": 5.578770580494709,
        "bleu": 53.80452,
        "bleurt": 0.29544,
        "nubia": {
            "semantic_relation": 4.0856,
            "contradiction": 23.68757,
            "irrelevancy": 22.24914,
            "logical_agreement": 54.06328,
            "grammar_ref": 5.01189,
            "grammar_hyp": 4.95574,
            "nubia_score": 0.6725
        },
        "meteor": 0.4343021687918558,
        "bertscore": {
            "precision": 0.94333,
            "recall": 0.9431,
            "f1": 0.94287
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_402": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 72,
        "mean_pred_length": 24.0,
        "std_pred_length": 7.2571803523590805,
        "median_pred_length": 27.0,
        "min_pred_length": 14,
        "max_pred_length": 31,
        "distinct-1": 0.75,
        "vocab_size-1": 54,
        "unique-1": 45,
        "entropy-1": 5.49277378613449,
        "distinct-2": 0.9710144927536232,
        "vocab_size-2": 67,
        "unique-2": 65,
        "entropy-2": 6.05055344228541,
        "cond_entropy-2": 0.5183096002633925,
        "distinct-3": 0.9848484848484849,
        "vocab_size-3": 65,
        "unique-3": 64,
        "entropy-3": 6.014091089055431,
        "cond_entropy-3": -0.033827307116685294,
        "total_length-nopunct": 61,
        "mean_pred_length-nopunct": 20.333333333333332,
        "std_pred_length-nopunct": 5.436502143433364,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8524590163934426,
        "vocab_size-1-nopunct": 52,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.602868485103867,
        "distinct-2-nopunct": 0.9827586206896551,
        "vocab_size-2-nopunct": 57,
        "unique-2-nopunct": 56,
        "entropy-2-nopunct": 5.823498236506881,
        "cond_entropy-2-nopunct": 0.2375884851508929,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 55,
        "unique-3-nopunct": 55,
        "entropy-3-nopunct": 5.7813597135246555,
        "cond_entropy-3-nopunct": -0.040257645239276024,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83722,
            "recall": 0.70789,
            "fmeasure": 0.7647
        },
        "rouge2": {
            "precision": 0.6636,
            "recall": 0.54838,
            "fmeasure": 0.59897
        },
        "rougeL": {
            "precision": 0.82207,
            "recall": 0.69522,
            "fmeasure": 0.75091
        },
        "rougeLsum": {
            "precision": 0.82207,
            "recall": 0.69522,
            "fmeasure": 0.75091
        },
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.7301587301587301
        },
        "nist": 4.812541161690954,
        "bleu": 52.73991,
        "bleurt": 0.26632,
        "nubia": {
            "semantic_relation": 3.92615,
            "contradiction": 4.35001,
            "irrelevancy": 36.23753,
            "logical_agreement": 59.41246,
            "grammar_ref": 3.87101,
            "grammar_hyp": 3.705,
            "nubia_score": 0.6853
        },
        "meteor": 0.37475146215389965,
        "bertscore": {
            "precision": 0.95187,
            "recall": 0.92127,
            "f1": 0.93564
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_360": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.71333,
        "msttr-100_nopunct": 0.775,
        "total_length": 332,
        "mean_pred_length": 16.6,
        "std_pred_length": 6.643794096749237,
        "median_pred_length": 14.5,
        "min_pred_length": 10,
        "max_pred_length": 40,
        "distinct-1": 0.5813253012048193,
        "vocab_size-1": 193,
        "unique-1": 154,
        "entropy-1": 6.900473512034059,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 288,
        "unique-2": 271,
        "entropy-2": 8.111477018520885,
        "cond_entropy-2": 1.0196659616583685,
        "distinct-3": 0.9794520547945206,
        "vocab_size-3": 286,
        "unique-3": 280,
        "entropy-3": 8.148728668469099,
        "cond_entropy-3": 0.049164334903009754,
        "total_length-nopunct": 289,
        "mean_pred_length-nopunct": 14.45,
        "std_pred_length-nopunct": 5.995623403783797,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.6539792387543253,
        "vocab_size-1-nopunct": 189,
        "unique-1-nopunct": 154,
        "entropy-1-nopunct": 7.074712806028035,
        "distinct-2-nopunct": 0.9330855018587361,
        "vocab_size-2-nopunct": 251,
        "unique-2-nopunct": 240,
        "entropy-2-nopunct": 7.914344658071501,
        "cond_entropy-2-nopunct": 0.9155400120015902,
        "distinct-3-nopunct": 0.9919678714859438,
        "vocab_size-3-nopunct": 247,
        "unique-3-nopunct": 245,
        "entropy-3-nopunct": 7.9439376750399715,
        "cond_entropy-3-nopunct": 0.0422129129110172,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82171,
            "recall": 0.82374,
            "fmeasure": 0.81751
        },
        "rouge2": {
            "precision": 0.66398,
            "recall": 0.67416,
            "fmeasure": 0.66358
        },
        "rougeL": {
            "precision": 0.72353,
            "recall": 0.73304,
            "fmeasure": 0.72319
        },
        "rougeLsum": {
            "precision": 0.72353,
            "recall": 0.73304,
            "fmeasure": 0.72319
        },
        "local_recall": {
            "1": 0.22972972972972974,
            "2": 0.5538461538461539,
            "3": 0.8421052631578947
        },
        "nist": 6.494763022848644,
        "bleu": 53.70548,
        "bleurt": 0.41602,
        "nubia": {
            "semantic_relation": 4.21426,
            "contradiction": 13.97921,
            "irrelevancy": 12.10072,
            "logical_agreement": 73.92007,
            "grammar_ref": 4.44035,
            "grammar_hyp": 4.49067,
            "nubia_score": 0.75391
        },
        "meteor": 0.4400891767111766,
        "bertscore": {
            "precision": 0.94599,
            "recall": 0.94311,
            "f1": 0.94248
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_276": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75,
        "total_length": 293,
        "mean_pred_length": 16.27777777777778,
        "std_pred_length": 5.9981993182728095,
        "median_pred_length": 14.5,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.5972696245733788,
        "vocab_size-1": 175,
        "unique-1": 148,
        "entropy-1": 6.678764769205283,
        "distinct-2": 0.9418181818181818,
        "vocab_size-2": 259,
        "unique-2": 248,
        "entropy-2": 7.964143581115699,
        "cond_entropy-2": 1.1116668392120546,
        "distinct-3": 0.9922178988326849,
        "vocab_size-3": 255,
        "unique-3": 253,
        "entropy-3": 7.990060346859275,
        "cond_entropy-3": 0.01716076803604664,
        "total_length-nopunct": 251,
        "mean_pred_length-nopunct": 13.944444444444445,
        "std_pred_length-nopunct": 5.016331353381033,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6772908366533864,
        "vocab_size-1-nopunct": 170,
        "unique-1-nopunct": 147,
        "entropy-1-nopunct": 6.798142470251604,
        "distinct-2-nopunct": 0.9399141630901288,
        "vocab_size-2-nopunct": 219,
        "unique-2-nopunct": 209,
        "entropy-2-nopunct": 7.7203673678117095,
        "cond_entropy-2-nopunct": 1.00858206282438,
        "distinct-3-nopunct": 0.9906976744186047,
        "vocab_size-3-nopunct": 213,
        "unique-3-nopunct": 211,
        "entropy-3-nopunct": 7.729588198426644,
        "cond_entropy-3-nopunct": 0.021261472397165814,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.69173,
            "recall": 0.71843,
            "fmeasure": 0.69513
        },
        "rouge2": {
            "precision": 0.46719,
            "recall": 0.47312,
            "fmeasure": 0.46549
        },
        "rougeL": {
            "precision": 0.61544,
            "recall": 0.63147,
            "fmeasure": 0.61484
        },
        "rougeLsum": {
            "precision": 0.61544,
            "recall": 0.63147,
            "fmeasure": 0.61484
        },
        "local_recall": {
            "1": 0.13636363636363635,
            "2": 0.35714285714285715,
            "3": 0.7473684210526316
        },
        "nist": 5.274984420549428,
        "bleu": 39.89513,
        "bleurt": 0.31131,
        "nubia": {
            "semantic_relation": 4.24278,
            "contradiction": 4.93229,
            "irrelevancy": 27.3784,
            "logical_agreement": 67.68931,
            "grammar_ref": 5.08526,
            "grammar_hyp": 4.73067,
            "nubia_score": 0.74662
        },
        "meteor": 0.380319003408096,
        "bertscore": {
            "precision": 0.90405,
            "recall": 0.91442,
            "f1": 0.90765
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_364": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 64,
        "mean_pred_length": 16.0,
        "std_pred_length": 7.245688373094719,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.703125,
        "vocab_size-1": 45,
        "unique-1": 34,
        "entropy-1": 5.296569531114784,
        "distinct-2": 0.95,
        "vocab_size-2": 57,
        "unique-2": 54,
        "entropy-2": 5.806890595608517,
        "cond_entropy-2": 0.42388309575274935,
        "distinct-3": 0.9821428571428571,
        "vocab_size-3": 55,
        "unique-3": 54,
        "entropy-3": 5.771640636343323,
        "cond_entropy-3": -0.028107102122342957,
        "total_length-nopunct": 57,
        "mean_pred_length-nopunct": 14.25,
        "std_pred_length-nopunct": 6.5717197140474575,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7543859649122807,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.266843303524555,
        "distinct-2-nopunct": 0.9433962264150944,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.614712907393385,
        "cond_entropy-2-nopunct": 0.3717221858039366,
        "distinct-3-nopunct": 0.9795918367346939,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.5738935175845965,
        "cond_entropy-3-nopunct": -0.03157795738676629,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70014,
            "recall": 0.67955,
            "fmeasure": 0.6752
        },
        "rouge2": {
            "precision": 0.38766,
            "recall": 0.39541,
            "fmeasure": 0.38254
        },
        "rougeL": {
            "precision": 0.59957,
            "recall": 0.61418,
            "fmeasure": 0.5921
        },
        "rougeLsum": {
            "precision": 0.59957,
            "recall": 0.61418,
            "fmeasure": 0.5921
        },
        "local_recall": {
            "1": 0.3,
            "2": 0.16666666666666666,
            "3": 0.75
        },
        "nist": 4.379964141598235,
        "bleu": 20.73396,
        "bleurt": 0.17854,
        "nubia": {
            "semantic_relation": 4.14217,
            "contradiction": 0.81111,
            "irrelevancy": 33.78321,
            "logical_agreement": 65.40568,
            "grammar_ref": 4.84918,
            "grammar_hyp": 5.31486,
            "nubia_score": 0.67009
        },
        "meteor": 0.31186415657336825,
        "bertscore": {
            "precision": 0.92718,
            "recall": 0.91631,
            "f1": 0.92137
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_300": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.722,
        "msttr-100_nopunct": 0.795,
        "total_length": 509,
        "mean_pred_length": 17.551724137931036,
        "std_pred_length": 5.721021170581784,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.5402750491159135,
        "vocab_size-1": 275,
        "unique-1": 211,
        "entropy-1": 7.328927818686353,
        "distinct-2": 0.8833333333333333,
        "vocab_size-2": 424,
        "unique-2": 392,
        "entropy-2": 8.618811572744312,
        "cond_entropy-2": 1.0968291247571442,
        "distinct-3": 0.9645232815964523,
        "vocab_size-3": 435,
        "unique-3": 421,
        "entropy-3": 8.742682570030638,
        "cond_entropy-3": 0.10800518056522426,
        "total_length-nopunct": 424,
        "mean_pred_length-nopunct": 14.620689655172415,
        "std_pred_length-nopunct": 4.088788650422521,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6320754716981132,
        "vocab_size-1-nopunct": 268,
        "unique-1-nopunct": 209,
        "entropy-1-nopunct": 7.556164236726409,
        "distinct-2-nopunct": 0.9164556962025316,
        "vocab_size-2-nopunct": 362,
        "unique-2-nopunct": 340,
        "entropy-2-nopunct": 8.427888677273579,
        "cond_entropy-2-nopunct": 0.9410813210954023,
        "distinct-3-nopunct": 0.9836065573770492,
        "vocab_size-3-nopunct": 360,
        "unique-3-nopunct": 354,
        "entropy-3-nopunct": 8.482912953038086,
        "cond_entropy-3-nopunct": 0.06796631075897004,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83597,
            "recall": 0.817,
            "fmeasure": 0.81756
        },
        "rouge2": {
            "precision": 0.6749,
            "recall": 0.64948,
            "fmeasure": 0.65511
        },
        "rougeL": {
            "precision": 0.76233,
            "recall": 0.7388,
            "fmeasure": 0.7426
        },
        "rougeLsum": {
            "precision": 0.76233,
            "recall": 0.7388,
            "fmeasure": 0.7426
        },
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.5074626865671642,
            "3": 0.831858407079646
        },
        "nist": 7.2257770793320795,
        "bleu": 58.26328,
        "bleurt": 0.46747,
        "nubia": {
            "semantic_relation": 4.32927,
            "contradiction": 17.09513,
            "irrelevancy": 16.74626,
            "logical_agreement": 66.15861,
            "grammar_ref": 4.69712,
            "grammar_hyp": 4.62739,
            "nubia_score": 0.79243
        },
        "meteor": 0.44250026606475873,
        "bertscore": {
            "precision": 0.95056,
            "recall": 0.94848,
            "f1": 0.94865
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_279": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 6.0,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.875,
        "vocab_size-1": 28,
        "unique-1": 25,
        "entropy-1": 4.726409765557392,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.13205351234730084,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.896551724137931,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.625053839880556,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": 0.14708752563454355,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88611,
            "recall": 0.64469,
            "fmeasure": 0.70429
        },
        "rouge2": {
            "precision": 0.68969,
            "recall": 0.51722,
            "fmeasure": 0.55552
        },
        "rougeL": {
            "precision": 0.775,
            "recall": 0.5982,
            "fmeasure": 0.63863
        },
        "rougeLsum": {
            "precision": 0.775,
            "recall": 0.5982,
            "fmeasure": 0.63863
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.7777777777777778
        },
        "nist": 3.06858625409605,
        "bleu": 42.35494,
        "bleurt": 0.22885,
        "nubia": {
            "semantic_relation": 4.11761,
            "contradiction": 0.15813,
            "irrelevancy": 54.08566,
            "logical_agreement": 45.75621,
            "grammar_ref": 3.10743,
            "grammar_hyp": 3.62294,
            "nubia_score": 0.70631
        },
        "meteor": 0.37690865612421326,
        "bertscore": {
            "precision": 0.96924,
            "recall": 0.94479,
            "f1": 0.95445
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_365": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 18.0,
        "std_pred_length": 2.449489742783178,
        "median_pred_length": 18.0,
        "min_pred_length": 15,
        "max_pred_length": 21,
        "distinct-1": 0.6481481481481481,
        "vocab_size-1": 35,
        "unique-1": 22,
        "entropy-1": 4.942400409924077,
        "distinct-2": 0.7843137254901961,
        "vocab_size-2": 40,
        "unique-2": 29,
        "entropy-2": 5.241052792951887,
        "cond_entropy-2": 0.25321265311712016,
        "distinct-3": 0.7916666666666666,
        "vocab_size-3": 38,
        "unique-3": 28,
        "entropy-3": 5.168295834054489,
        "cond_entropy-3": -0.0874628412503394,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 1.4142135623730951,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.8116413449135775,
        "distinct-2-nopunct": 0.7777777777777778,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 5.047408651885232,
        "cond_entropy-2-nopunct": 0.24287760624771268,
        "distinct-3-nopunct": 0.7857142857142857,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.963745994207333,
        "cond_entropy-3-nopunct": -0.09953567355091439,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.6718,
            "recall": 0.86247,
            "fmeasure": 0.75489
        },
        "rouge2": {
            "precision": 0.53419,
            "recall": 0.70016,
            "fmeasure": 0.60561
        },
        "rougeL": {
            "precision": 0.6718,
            "recall": 0.86247,
            "fmeasure": 0.75489
        },
        "rougeLsum": {
            "precision": 0.6718,
            "recall": 0.86247,
            "fmeasure": 0.75489
        },
        "local_recall": {
            "1": 0.7142857142857143,
            "2": 0.6,
            "3": 0.8620689655172413
        },
        "nist": 4.007828753530573,
        "bleu": 51.53004,
        "bleurt": 0.25048,
        "nubia": {
            "semantic_relation": 4.34298,
            "contradiction": 0.34859,
            "irrelevancy": 52.18047,
            "logical_agreement": 47.47094,
            "grammar_ref": 4.37436,
            "grammar_hyp": 4.20634,
            "nubia_score": 0.79942
        },
        "meteor": 0.4993829287541739,
        "bertscore": {
            "precision": 0.91599,
            "recall": 0.95071,
            "f1": 0.93301
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_403": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 5.5,
        "median_pred_length": 17.5,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.7714285714285715,
        "vocab_size-1": 27,
        "unique-1": 20,
        "entropy-1": 4.65057194545458,
        "distinct-2": 1.0,
        "vocab_size-2": 33,
        "unique-2": 33,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": 0.3622289055093495,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.09019780897157811,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.481727678869737,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.32028173724063796,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.6917,
            "recall": 0.57868,
            "fmeasure": 0.62676
        },
        "rouge2": {
            "precision": 0.48636,
            "recall": 0.37397,
            "fmeasure": 0.41954
        },
        "rougeL": {
            "precision": 0.66996,
            "recall": 0.54548,
            "fmeasure": 0.59693
        },
        "rougeLsum": {
            "precision": 0.66996,
            "recall": 0.54548,
            "fmeasure": 0.59693
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5357142857142857
        },
        "nist": 2.9702686067592055,
        "bleu": 21.89093,
        "bleurt": 0.31345,
        "nubia": {
            "semantic_relation": 3.86489,
            "contradiction": 48.62516,
            "irrelevancy": 8.21611,
            "logical_agreement": 43.15873,
            "grammar_ref": 3.82725,
            "grammar_hyp": 4.00041,
            "nubia_score": 0.61541
        },
        "meteor": 0.2725799732828608,
        "bertscore": {
            "precision": 0.90978,
            "recall": 0.86442,
            "f1": 0.88456
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_404": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 5.5,
        "median_pred_length": 16.5,
        "min_pred_length": 11,
        "max_pred_length": 22,
        "distinct-1": 0.8787878787878788,
        "vocab_size-1": 29,
        "unique-1": 25,
        "entropy-1": 4.801969876934213,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": 0.10335057812519602,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.09621531525930291,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.706890595608519,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.11475004073479991,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88333,
            "recall": 0.91649,
            "fmeasure": 0.89644
        },
        "rouge2": {
            "precision": 0.79912,
            "recall": 0.82435,
            "fmeasure": 0.80848
        },
        "rougeL": {
            "precision": 0.81667,
            "recall": 0.8563,
            "fmeasure": 0.83212
        },
        "rougeLsum": {
            "precision": 0.81667,
            "recall": 0.8563,
            "fmeasure": 0.83212
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.5,
            "3": 1.0
        },
        "nist": 4.793843387589936,
        "bleu": 73.97756,
        "bleurt": 0.60298,
        "nubia": {
            "semantic_relation": 4.8089,
            "contradiction": 0.56751,
            "irrelevancy": 16.55085,
            "logical_agreement": 82.88165,
            "grammar_ref": 4.70227,
            "grammar_hyp": 4.34431,
            "nubia_score": 0.94265
        },
        "meteor": 0.554395898896734,
        "bertscore": {
            "precision": 0.96533,
            "recall": 0.98167,
            "f1": 0.97126
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_280": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 25,
        "msttr-100": 0.7425,
        "msttr-100_nopunct": 0.79333,
        "total_length": 435,
        "mean_pred_length": 17.4,
        "std_pred_length": 7.557777451076473,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 36,
        "distinct-1": 0.593103448275862,
        "vocab_size-1": 258,
        "unique-1": 216,
        "entropy-1": 7.280013188084321,
        "distinct-2": 0.9634146341463414,
        "vocab_size-2": 395,
        "unique-2": 386,
        "entropy-2": 8.592870892177869,
        "cond_entropy-2": 1.1167856726611902,
        "distinct-3": 0.9974025974025974,
        "vocab_size-3": 384,
        "unique-3": 383,
        "entropy-3": 8.583519830387507,
        "cond_entropy-3": -0.0037270872885667816,
        "total_length-nopunct": 373,
        "mean_pred_length-nopunct": 14.92,
        "std_pred_length-nopunct": 6.137882370981053,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.675603217158177,
        "vocab_size-1-nopunct": 252,
        "unique-1-nopunct": 216,
        "entropy-1-nopunct": 7.4563284595392645,
        "distinct-2-nopunct": 0.9597701149425287,
        "vocab_size-2-nopunct": 334,
        "unique-2-nopunct": 326,
        "entropy-2-nopunct": 8.346651038939779,
        "cond_entropy-2-nopunct": 0.9655167863485048,
        "distinct-3-nopunct": 0.9969040247678018,
        "vocab_size-3-nopunct": 322,
        "unique-3-nopunct": 321,
        "entropy-3-nopunct": 8.32919840422955,
        "cond_entropy-3-nopunct": -0.009999658169271106,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77393,
            "recall": 0.76984,
            "fmeasure": 0.7652
        },
        "rouge2": {
            "precision": 0.55004,
            "recall": 0.53309,
            "fmeasure": 0.53447
        },
        "rougeL": {
            "precision": 0.65134,
            "recall": 0.63922,
            "fmeasure": 0.63993
        },
        "rougeLsum": {
            "precision": 0.65134,
            "recall": 0.63922,
            "fmeasure": 0.63993
        },
        "local_recall": {
            "1": 0.1956521739130435,
            "2": 0.421875,
            "3": 0.7992831541218638
        },
        "nist": 6.65225130115759,
        "bleu": 46.72434,
        "bleurt": 0.3323,
        "nubia": {
            "semantic_relation": 4.37478,
            "contradiction": 3.54428,
            "irrelevancy": 23.67301,
            "logical_agreement": 72.78271,
            "grammar_ref": 4.76367,
            "grammar_hyp": 4.72878,
            "nubia_score": 0.77698
        },
        "meteor": 0.41260946399950066,
        "bertscore": {
            "precision": 0.93697,
            "recall": 0.93417,
            "f1": 0.93294
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_366": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 17.666666666666668,
        "std_pred_length": 8.013876853447538,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 29,
        "distinct-1": 0.8113207547169812,
        "vocab_size-1": 43,
        "unique-1": 37,
        "entropy-1": 5.2682123795330025,
        "distinct-2": 1.0,
        "vocab_size-2": 50,
        "unique-2": 50,
        "entropy-2": 5.643856189774728,
        "cond_entropy-2": 0.30812854470026163,
        "distinct-3": 1.0,
        "vocab_size-3": 47,
        "unique-3": 47,
        "entropy-3": 5.55458885167764,
        "cond_entropy-3": -0.08926733809708727,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 7.0710678118654755,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.176428324170393,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.491853096329673,
        "cond_entropy-2-nopunct": 0.3426603839293365,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.3923174227787625,
        "cond_entropy-3-nopunct": -0.0995356735509143,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81187,
            "recall": 0.78503,
            "fmeasure": 0.79369
        },
        "rouge2": {
            "precision": 0.64734,
            "recall": 0.62795,
            "fmeasure": 0.63325
        },
        "rougeL": {
            "precision": 0.72854,
            "recall": 0.69596,
            "fmeasure": 0.70727
        },
        "rougeLsum": {
            "precision": 0.72854,
            "recall": 0.69596,
            "fmeasure": 0.70727
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.2,
            "3": 0.8
        },
        "nist": 3.8800953344029354,
        "bleu": 46.2793,
        "bleurt": 0.14545,
        "nubia": {
            "semantic_relation": 4.22904,
            "contradiction": 2.10405,
            "irrelevancy": 19.44297,
            "logical_agreement": 78.45298,
            "grammar_ref": 5.35172,
            "grammar_hyp": 5.42943,
            "nubia_score": 0.66202
        },
        "meteor": 0.41429580414474987,
        "bertscore": {
            "precision": 0.93881,
            "recall": 0.92987,
            "f1": 0.93405
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_405": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.875
        },
        "nist": 2.9898332363522426,
        "bleu": 61.0195,
        "bleurt": 0.83294,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.30005,
            "irrelevancy": 0.4565,
            "logical_agreement": 99.24345,
            "grammar_ref": 4.34196,
            "grammar_hyp": 4.46114,
            "nubia_score": 0.99737
        },
        "meteor": 0.5064321156600579,
        "bertscore": {
            "precision": 0.99622,
            "recall": 0.98673,
            "f1": 0.99146
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_416": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 57,
        "mean_pred_length": 19.0,
        "std_pred_length": 7.2571803523590805,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 29,
        "distinct-1": 0.6140350877192983,
        "vocab_size-1": 35,
        "unique-1": 24,
        "entropy-1": 4.827903829688524,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 48,
        "unique-2": 43,
        "entropy-2": 5.518685881753032,
        "cond_entropy-2": 0.6585611456064558,
        "distinct-3": 0.9607843137254902,
        "vocab_size-3": 49,
        "unique-3": 47,
        "entropy-3": 5.59399396942248,
        "cond_entropy-3": 0.08920230063476178,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 17.333333333333332,
        "std_pred_length-nopunct": 7.1336448530109,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6346153846153846,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.728721929429923,
        "distinct-2-nopunct": 0.8775510204081632,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.354406017540444,
        "cond_entropy-2-nopunct": 0.6851770139499804,
        "distinct-3-nopunct": 0.9565217391304348,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.43660543431788,
        "cond_entropy-3-nopunct": 0.09917575329318434,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86435,
            "recall": 0.84781,
            "fmeasure": 0.85485
        },
        "rouge2": {
            "precision": 0.67284,
            "recall": 0.65804,
            "fmeasure": 0.66432
        },
        "rougeL": {
            "precision": 0.80482,
            "recall": 0.78371,
            "fmeasure": 0.79312
        },
        "rougeLsum": {
            "precision": 0.80482,
            "recall": 0.78371,
            "fmeasure": 0.79312
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.7352941176470589
        },
        "nist": 4.273540257128497,
        "bleu": 45.41222,
        "bleurt": 0.27996,
        "nubia": {
            "semantic_relation": 4.6902,
            "contradiction": 4.21489,
            "irrelevancy": 1.01629,
            "logical_agreement": 94.76882,
            "grammar_ref": 4.67072,
            "grammar_hyp": 4.62413,
            "nubia_score": 0.85671
        },
        "meteor": 0.44647825839436517,
        "bertscore": {
            "precision": 0.93681,
            "recall": 0.94802,
            "f1": 0.94187
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_329": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75,
        "total_length": 132,
        "mean_pred_length": 22.0,
        "std_pred_length": 6.8068592855540455,
        "median_pred_length": 21.0,
        "min_pred_length": 14,
        "max_pred_length": 31,
        "distinct-1": 0.6742424242424242,
        "vocab_size-1": 89,
        "unique-1": 69,
        "entropy-1": 6.157761070573164,
        "distinct-2": 0.9365079365079365,
        "vocab_size-2": 118,
        "unique-2": 110,
        "entropy-2": 6.850295796515798,
        "cond_entropy-2": 0.6116618948980531,
        "distinct-3": 0.9583333333333334,
        "vocab_size-3": 115,
        "unique-3": 110,
        "entropy-3": 6.823557262275202,
        "cond_entropy-3": -0.020389327891398027,
        "total_length-nopunct": 119,
        "mean_pred_length-nopunct": 19.833333333333332,
        "std_pred_length-nopunct": 6.3879226322455995,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.7142857142857143,
        "vocab_size-1-nopunct": 85,
        "unique-1-nopunct": 67,
        "entropy-1-nopunct": 6.139219889686988,
        "distinct-2-nopunct": 0.9292035398230089,
        "vocab_size-2-nopunct": 105,
        "unique-2-nopunct": 97,
        "entropy-2-nopunct": 6.678586042061223,
        "cond_entropy-2-nopunct": 0.5617872784071878,
        "distinct-3-nopunct": 0.9532710280373832,
        "vocab_size-3-nopunct": 102,
        "unique-3-nopunct": 97,
        "entropy-3-nopunct": 6.648009042475905,
        "cond_entropy-3-nopunct": -0.03198300405142391,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.57817,
            "recall": 0.61215,
            "fmeasure": 0.58089
        },
        "rouge2": {
            "precision": 0.28077,
            "recall": 0.2839,
            "fmeasure": 0.27458
        },
        "rougeL": {
            "precision": 0.42573,
            "recall": 0.47335,
            "fmeasure": 0.43709
        },
        "rougeLsum": {
            "precision": 0.42573,
            "recall": 0.47335,
            "fmeasure": 0.43709
        },
        "local_recall": {
            "1": 0.24528301886792453,
            "2": 0.6216216216216216,
            "3": 0.7142857142857143
        },
        "nist": 4.067788991702463,
        "bleu": 21.52157,
        "bleurt": -0.0318,
        "nubia": {
            "semantic_relation": 3.94258,
            "contradiction": 9.13191,
            "irrelevancy": 59.72641,
            "logical_agreement": 31.14169,
            "grammar_ref": 4.80564,
            "grammar_hyp": 4.32814,
            "nubia_score": 0.64527
        },
        "meteor": 0.30647181199787565,
        "bertscore": {
            "precision": 0.897,
            "recall": 0.90543,
            "f1": 0.8998
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_301": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 1.0,
        "median_pred_length": 15.0,
        "min_pred_length": 14,
        "max_pred_length": 16,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 26,
        "unique-1": 23,
        "entropy-1": 4.6150610122030695,
        "distinct-2": 0.9642857142857143,
        "vocab_size-2": 27,
        "unique-2": 26,
        "entropy-2": 4.735926350629034,
        "cond_entropy-2": 0.07028173724063808,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.029992126993435266,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8928571428571429,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.5661089398374815,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.623516641218013,
        "cond_entropy-2-nopunct": 0.07596508462823659,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.03214388408660255,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.72881,
            "fmeasure": 0.74598
        },
        "rouge2": {
            "precision": 0.61905,
            "recall": 0.58333,
            "fmeasure": 0.59708
        },
        "rougeL": {
            "precision": 0.71111,
            "recall": 0.66676,
            "fmeasure": 0.6833
        },
        "rougeLsum": {
            "precision": 0.71111,
            "recall": 0.66676,
            "fmeasure": 0.6833
        },
        "local_recall": {
            "1": 0.3125,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "nist": 4.451372947709936,
        "bleu": 64.17766,
        "bleurt": 0.28992,
        "nubia": {
            "semantic_relation": 3.76196,
            "contradiction": 3.87437,
            "irrelevancy": 38.55794,
            "logical_agreement": 57.56769,
            "grammar_ref": 4.37461,
            "grammar_hyp": 4.19225,
            "nubia_score": 0.61292
        },
        "meteor": 0.4358678416060197,
        "bertscore": {
            "precision": 0.95109,
            "recall": 0.94676,
            "f1": 0.93824
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_302": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.875,
            "recall": 0.87037,
            "fmeasure": 0.86555
        },
        "rouge2": {
            "precision": 0.80952,
            "recall": 0.78333,
            "fmeasure": 0.78889
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.87037,
            "fmeasure": 0.86555
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.87037,
            "fmeasure": 0.86555
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 4.799940617598301,
        "bleu": 89.48393,
        "bleurt": 0.35553,
        "nubia": {
            "semantic_relation": 4.18222,
            "contradiction": 0.29797,
            "irrelevancy": 34.90959,
            "logical_agreement": 64.79244,
            "grammar_ref": 4.09688,
            "grammar_hyp": 4.63082,
            "nubia_score": 0.73193
        },
        "meteor": 0.5841558009653784,
        "bertscore": {
            "precision": 0.9882,
            "recall": 0.97502,
            "f1": 0.98157
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1850,
        "msttr-100": 0.69875,
        "msttr-100_nopunct": 0.74614,
        "total_length": 24812,
        "mean_pred_length": 13.411891891891893,
        "std_pred_length": 4.504660552252005,
        "median_pred_length": 13.0,
        "min_pred_length": 4,
        "max_pred_length": 39,
        "distinct-1": 0.25838304046429145,
        "vocab_size-1": 6411,
        "unique-1": 4755,
        "entropy-1": 9.20487693177346,
        "distinct-2": 0.6185872310774323,
        "vocab_size-2": 14204,
        "unique-2": 12418,
        "entropy-2": 12.587174428526339,
        "cond_entropy-2": 2.9411302344890187,
        "distinct-3": 0.7873721106479727,
        "vocab_size-3": 16623,
        "unique-3": 15486,
        "entropy-3": 13.36179816792183,
        "cond_entropy-3": 0.8040930456503779,
        "total_length-nopunct": 21555,
        "mean_pred_length-nopunct": 11.651351351351352,
        "std_pred_length-nopunct": 3.889703776786457,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.2965901183020181,
        "vocab_size-1-nopunct": 6393,
        "unique-1-nopunct": 4752,
        "entropy-1-nopunct": 9.67147031436067,
        "distinct-2-nopunct": 0.6419690433900025,
        "vocab_size-2-nopunct": 12650,
        "unique-2-nopunct": 11248,
        "entropy-2-nopunct": 12.428440853702222,
        "cond_entropy-2-nopunct": 2.986464079254194,
        "distinct-3-nopunct": 0.7987678521422571,
        "vocab_size-3-nopunct": 14262,
        "unique-3-nopunct": 13376,
        "entropy-3-nopunct": 13.158438578074186,
        "cond_entropy-3-nopunct": 0.8429136354574208,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76045,
            "recall": 0.73503,
            "fmeasure": 0.73441
        },
        "rouge2": {
            "precision": 0.55756,
            "recall": 0.54081,
            "fmeasure": 0.53944
        },
        "rougeL": {
            "precision": 0.68948,
            "recall": 0.66892,
            "fmeasure": 0.66709
        },
        "rougeLsum": {
            "precision": 0.68948,
            "recall": 0.66892,
            "fmeasure": 0.66709
        },
        "local_recall": {
            "1": 0.2228624535315985,
            "2": 0.4812905689194349,
            "3": 0.7790488859328234
        },
        "nist": 9.488097139987941,
        "bleu": 50.75594,
        "bleurt": 0.31023,
        "nubia": {
            "semantic_relation": 4.18756,
            "contradiction": 7.82956,
            "irrelevancy": 29.32735,
            "logical_agreement": 62.84309,
            "grammar_ref": 4.71357,
            "grammar_hyp": 4.73029,
            "nubia_score": 0.73256
        },
        "meteor": 0.40413109756225996,
        "bertscore": {
            "precision": 0.92884,
            "recall": 0.92603,
            "f1": 0.92565
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_330": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.64,
        "msttr-100_nopunct": 0.68,
        "total_length": 136,
        "mean_pred_length": 19.428571428571427,
        "std_pred_length": 5.499536158548617,
        "median_pred_length": 18.0,
        "min_pred_length": 12,
        "max_pred_length": 28,
        "distinct-1": 0.6470588235294118,
        "vocab_size-1": 88,
        "unique-1": 73,
        "entropy-1": 6.042822217137722,
        "distinct-2": 0.9534883720930233,
        "vocab_size-2": 123,
        "unique-2": 117,
        "entropy-2": 6.918203999609283,
        "cond_entropy-2": 0.779730619017189,
        "distinct-3": 0.9836065573770492,
        "vocab_size-3": 120,
        "unique-3": 118,
        "entropy-3": 6.8979504523170005,
        "cond_entropy-3": -0.03130958999151558,
        "total_length-nopunct": 124,
        "mean_pred_length-nopunct": 17.714285714285715,
        "std_pred_length-nopunct": 5.0061187051243525,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6935483870967742,
        "vocab_size-1-nopunct": 86,
        "unique-1-nopunct": 73,
        "entropy-1-nopunct": 6.060567278528198,
        "distinct-2-nopunct": 0.9572649572649573,
        "vocab_size-2-nopunct": 112,
        "unique-2-nopunct": 107,
        "entropy-2-nopunct": 6.7848946341133,
        "cond_entropy-2-nopunct": 0.7436043062091331,
        "distinct-3-nopunct": 0.9818181818181818,
        "vocab_size-3-nopunct": 108,
        "unique-3-nopunct": 106,
        "entropy-3-nopunct": 6.744996077161032,
        "cond_entropy-3-nopunct": -0.043550460604199356,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71798,
            "recall": 0.71702,
            "fmeasure": 0.71098
        },
        "rouge2": {
            "precision": 0.49069,
            "recall": 0.49068,
            "fmeasure": 0.48648
        },
        "rougeL": {
            "precision": 0.59666,
            "recall": 0.61691,
            "fmeasure": 0.60113
        },
        "rougeLsum": {
            "precision": 0.59666,
            "recall": 0.61691,
            "fmeasure": 0.60113
        },
        "local_recall": {
            "1": 0.3684210526315789,
            "2": 0.7428571428571429,
            "3": 0.782608695652174
        },
        "nist": 5.24111437436806,
        "bleu": 45.73394,
        "bleurt": 0.09245,
        "nubia": {
            "semantic_relation": 4.14138,
            "contradiction": 18.75403,
            "irrelevancy": 25.03962,
            "logical_agreement": 56.20635,
            "grammar_ref": 5.20043,
            "grammar_hyp": 4.48477,
            "nubia_score": 0.74626
        },
        "meteor": 0.38686755715716514,
        "bertscore": {
            "precision": 0.90787,
            "recall": 0.91195,
            "f1": 0.90845
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_406": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 49,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 1.247219128924647,
        "median_pred_length": 16.0,
        "min_pred_length": 15,
        "max_pred_length": 18,
        "distinct-1": 0.8163265306122449,
        "vocab_size-1": 40,
        "unique-1": 35,
        "entropy-1": 5.185739435775334,
        "distinct-2": 1.0,
        "vocab_size-2": 46,
        "unique-2": 46,
        "entropy-2": 5.5235619560570095,
        "cond_entropy-2": 0.26243173164811767,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.09729720135491506,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 1.632993161855452,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8444444444444444,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.130416151740998,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.3923174227787625,
        "cond_entropy-2-nopunct": 0.2877181956512381,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": -0.10691520391651191,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.68896,
            "recall": 0.59976,
            "fmeasure": 0.63936
        },
        "rouge2": {
            "precision": 0.35185,
            "recall": 0.3057,
            "fmeasure": 0.3258
        },
        "rougeL": {
            "precision": 0.60325,
            "recall": 0.52709,
            "fmeasure": 0.56073
        },
        "rougeLsum": {
            "precision": 0.60325,
            "recall": 0.52709,
            "fmeasure": 0.56073
        },
        "local_recall": {
            "1": 0.8333333333333334,
            "2": 0.5238095238095238,
            "3": 0.6818181818181818
        },
        "nist": 4.3025941314150655,
        "bleu": 37.06144,
        "bleurt": 0.25215,
        "nubia": {
            "semantic_relation": 4.18635,
            "contradiction": 13.81759,
            "irrelevancy": 15.53993,
            "logical_agreement": 70.64249,
            "grammar_ref": 4.68806,
            "grammar_hyp": 5.08022,
            "nubia_score": 0.66587
        },
        "meteor": 0.314985375581244,
        "bertscore": {
            "precision": 0.91134,
            "recall": 0.88423,
            "f1": 0.89697
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_407": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.40741,
            "recall": 0.42424,
            "fmeasure": 0.41373
        },
        "rouge2": {
            "precision": 0.20833,
            "recall": 0.22381,
            "fmeasure": 0.21481
        },
        "rougeL": {
            "precision": 0.40741,
            "recall": 0.42424,
            "fmeasure": 0.41373
        },
        "rougeLsum": {
            "precision": 0.40741,
            "recall": 0.42424,
            "fmeasure": 0.41373
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.3333333333333333
        },
        "nist": 1.766019820208258,
        "bleu": 11.33958,
        "bleurt": -0.21751,
        "nubia": {
            "semantic_relation": 3.366,
            "contradiction": 0.55393,
            "irrelevancy": 95.10371,
            "logical_agreement": 4.34235,
            "grammar_ref": 4.68733,
            "grammar_hyp": 3.87325,
            "nubia_score": 0.60321
        },
        "meteor": 0.29529971603612876,
        "bertscore": {
            "precision": 0.80104,
            "recall": 0.82862,
            "f1": 0.8146
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_368": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.8,
        "total_length": 123,
        "mean_pred_length": 17.571428571428573,
        "std_pred_length": 5.341405455954262,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 27,
        "distinct-1": 0.7235772357723578,
        "vocab_size-1": 89,
        "unique-1": 77,
        "entropy-1": 6.108812574900337,
        "distinct-2": 0.9741379310344828,
        "vocab_size-2": 113,
        "unique-2": 110,
        "entropy-2": 6.806256857196523,
        "cond_entropy-2": 0.5783445328019626,
        "distinct-3": 1.0,
        "vocab_size-3": 109,
        "unique-3": 109,
        "entropy-3": 6.7681843247769145,
        "cond_entropy-3": -0.034750798791012706,
        "total_length-nopunct": 109,
        "mean_pred_length-nopunct": 15.571428571428571,
        "std_pred_length-nopunct": 4.923910839889738,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7798165137614679,
        "vocab_size-1-nopunct": 85,
        "unique-1-nopunct": 75,
        "entropy-1-nopunct": 6.1142007237205505,
        "distinct-2-nopunct": 0.9901960784313726,
        "vocab_size-2-nopunct": 101,
        "unique-2-nopunct": 100,
        "entropy-2-nopunct": 6.652817498834245,
        "cond_entropy-2-nopunct": 0.573694081068533,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 95,
        "unique-3-nopunct": 95,
        "entropy-3-nopunct": 6.569855608330948,
        "cond_entropy-3-nopunct": -0.08151710206160055,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77687,
            "recall": 0.82106,
            "fmeasure": 0.79089
        },
        "rouge2": {
            "precision": 0.54442,
            "recall": 0.56162,
            "fmeasure": 0.54768
        },
        "rougeL": {
            "precision": 0.69737,
            "recall": 0.72653,
            "fmeasure": 0.70599
        },
        "rougeLsum": {
            "precision": 0.69737,
            "recall": 0.72653,
            "fmeasure": 0.70599
        },
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.4666666666666667,
            "3": 0.8831168831168831
        },
        "nist": 5.466587193190641,
        "bleu": 49.02263,
        "bleurt": 0.41243,
        "nubia": {
            "semantic_relation": 4.37076,
            "contradiction": 2.10018,
            "irrelevancy": 30.32244,
            "logical_agreement": 67.57738,
            "grammar_ref": 4.94315,
            "grammar_hyp": 4.64487,
            "nubia_score": 0.80684
        },
        "meteor": 0.44831557492678464,
        "bertscore": {
            "precision": 0.93502,
            "recall": 0.94257,
            "f1": 0.93848
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_369": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 13.25,
        "std_pred_length": 1.479019945774904,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 15,
        "distinct-1": 0.6792452830188679,
        "vocab_size-1": 36,
        "unique-1": 26,
        "entropy-1": 4.952082426661996,
        "distinct-2": 0.8775510204081632,
        "vocab_size-2": 43,
        "unique-2": 38,
        "entropy-2": 5.354406017540444,
        "cond_entropy-2": 0.3023920013193619,
        "distinct-3": 0.9111111111111111,
        "vocab_size-3": 41,
        "unique-3": 37,
        "entropy-3": 5.314075318551895,
        "cond_entropy-3": -0.017192581070789876,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 11.75,
        "std_pred_length-nopunct": 1.0897247358851685,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7021276595744681,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.849920437235857,
        "distinct-2-nopunct": 0.8604651162790697,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.12963946395411,
        "cond_entropy-2-nopunct": 0.32201376294539724,
        "distinct-3-nopunct": 0.8974358974358975,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 5.080274013734042,
        "cond_entropy-3-nopunct": -0.044583369117709465,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72355,
            "recall": 0.70971,
            "fmeasure": 0.71198
        },
        "rouge2": {
            "precision": 0.58406,
            "recall": 0.53701,
            "fmeasure": 0.55849
        },
        "rougeL": {
            "precision": 0.65143,
            "recall": 0.62909,
            "fmeasure": 0.63664
        },
        "rougeLsum": {
            "precision": 0.65143,
            "recall": 0.62909,
            "fmeasure": 0.63664
        },
        "local_recall": {
            "1": 0.07142857142857142,
            "2": 0.18181818181818182,
            "3": 0.8611111111111112
        },
        "nist": 4.283499284079436,
        "bleu": 49.10556,
        "bleurt": 0.26243,
        "nubia": {
            "semantic_relation": 4.35413,
            "contradiction": 1.14969,
            "irrelevancy": 49.86642,
            "logical_agreement": 48.98388,
            "grammar_ref": 5.27719,
            "grammar_hyp": 5.11762,
            "nubia_score": 0.75932
        },
        "meteor": 0.3914638893654934,
        "bertscore": {
            "precision": 0.91488,
            "recall": 0.9342,
            "f1": 0.92293
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_304": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.69,
        "msttr-100_nopunct": NaN,
        "total_length": 104,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 3.1972210155418126,
        "median_pred_length": 17.0,
        "min_pred_length": 14,
        "max_pred_length": 24,
        "distinct-1": 0.6634615384615384,
        "vocab_size-1": 69,
        "unique-1": 53,
        "entropy-1": 5.80236192567708,
        "distinct-2": 0.8877551020408163,
        "vocab_size-2": 87,
        "unique-2": 76,
        "entropy-2": 6.39022004819685,
        "cond_entropy-2": 0.4845794669121853,
        "distinct-3": 0.9021739130434783,
        "vocab_size-3": 83,
        "unique-3": 74,
        "entropy-3": 6.327909782143979,
        "cond_entropy-3": -0.06940875762341286,
        "total_length-nopunct": 93,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 2.4324199198877374,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6989247311827957,
        "vocab_size-1-nopunct": 65,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.752756360465378,
        "distinct-2-nopunct": 0.8850574712643678,
        "vocab_size-2-nopunct": 77,
        "unique-2-nopunct": 67,
        "entropy-2-nopunct": 6.213058438377458,
        "cond_entropy-2-nopunct": 0.4915482239334244,
        "distinct-3-nopunct": 0.9012345679012346,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 65,
        "entropy-3-nopunct": 6.142319138687083,
        "cond_entropy-3-nopunct": -0.07840213493941187,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79731,
            "recall": 0.82117,
            "fmeasure": 0.80479
        },
        "rouge2": {
            "precision": 0.64247,
            "recall": 0.67206,
            "fmeasure": 0.65263
        },
        "rougeL": {
            "precision": 0.72187,
            "recall": 0.74865,
            "fmeasure": 0.73164
        },
        "rougeLsum": {
            "precision": 0.72187,
            "recall": 0.74865,
            "fmeasure": 0.73164
        },
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.625,
            "3": 0.875
        },
        "nist": 5.930837040828077,
        "bleu": 65.91414,
        "bleurt": 0.36474,
        "nubia": {
            "semantic_relation": 4.19698,
            "contradiction": 17.07258,
            "irrelevancy": 35.55239,
            "logical_agreement": 47.37503,
            "grammar_ref": 4.63046,
            "grammar_hyp": 4.26417,
            "nubia_score": 0.75703
        },
        "meteor": 0.4704489546194078,
        "bertscore": {
            "precision": 0.9445,
            "recall": 0.95006,
            "f1": 0.9465
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_332": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.69444,
            "fmeasure": 0.80214
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.53333,
            "fmeasure": 0.59259
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.5,
            "fmeasure": 0.54545
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.5,
            "fmeasure": 0.54545
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.5
        },
        "nist": 0.427899183043676,
        "bleu": 13.0442,
        "bleurt": -0.01027,
        "nubia": {
            "semantic_relation": 3.9192,
            "contradiction": 0.33634,
            "irrelevancy": 33.45921,
            "logical_agreement": 66.20444,
            "grammar_ref": 6.47099,
            "grammar_hyp": 8.78862,
            "nubia_score": 0.50144
        },
        "meteor": 0.3274499237462559,
        "bertscore": {
            "precision": 0.89229,
            "recall": 0.85481,
            "f1": 0.87315
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_305": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.625,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.28571,
            "fmeasure": 0.30769
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.625,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.625,
            "fmeasure": 0.66667
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.625
        },
        "nist": 2.242374927264182,
        "bleu": 23.87517,
        "bleurt": 0.4377,
        "nubia": {
            "semantic_relation": 4.08295,
            "contradiction": 0.3975,
            "irrelevancy": 95.42894,
            "logical_agreement": 4.17356,
            "grammar_ref": 5.02153,
            "grammar_hyp": 4.53573,
            "nubia_score": 0.78641
        },
        "meteor": 0.3090046331141728,
        "bertscore": {
            "precision": 0.94727,
            "recall": 0.93527,
            "f1": 0.94123
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_333": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322734,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.96
        },
        "rouge2": {
            "precision": 0.90909,
            "recall": 0.83333,
            "fmeasure": 0.86957
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.96
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.96
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.875
        },
        "nist": 4.00193538757769,
        "bleu": 81.96501,
        "bleurt": 0.86304,
        "nubia": {
            "semantic_relation": 4.91472,
            "contradiction": 0.30946,
            "irrelevancy": 2.79721,
            "logical_agreement": 96.89333,
            "grammar_ref": 3.61542,
            "grammar_hyp": 3.03745,
            "nubia_score": 1.0
        },
        "meteor": 0.5249299242820813,
        "bertscore": {
            "precision": 0.99614,
            "recall": 0.98503,
            "f1": 0.99055
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_370": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.74,
        "msttr-100_nopunct": NaN,
        "total_length": 103,
        "mean_pred_length": 14.714285714285714,
        "std_pred_length": 1.8294640678379568,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.7281553398058253,
        "vocab_size-1": 75,
        "unique-1": 62,
        "entropy-1": 5.976197037292645,
        "distinct-2": 0.9791666666666666,
        "vocab_size-2": 94,
        "unique-2": 92,
        "entropy-2": 6.543295834054494,
        "cond_entropy-2": 0.4141887964996768,
        "distinct-3": 0.9887640449438202,
        "vocab_size-3": 88,
        "unique-3": 87,
        "entropy-3": 6.45326152085405,
        "cond_entropy-3": -0.08675715964239877,
        "total_length-nopunct": 90,
        "mean_pred_length-nopunct": 12.857142857142858,
        "std_pred_length-nopunct": 1.3552618543578767,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 72,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 6.008411151837144,
        "distinct-2-nopunct": 0.9759036144578314,
        "vocab_size-2-nopunct": 81,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.326846660262594,
        "cond_entropy-2-nopunct": 0.35920772061155043,
        "distinct-3-nopunct": 0.9868421052631579,
        "vocab_size-3-nopunct": 75,
        "unique-3-nopunct": 74,
        "entropy-3-nopunct": 6.221611723969907,
        "cond_entropy-3-nopunct": -0.10079612842965495,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.90211,
            "recall": 0.84515,
            "fmeasure": 0.86741
        },
        "rouge2": {
            "precision": 0.72605,
            "recall": 0.69256,
            "fmeasure": 0.70534
        },
        "rougeL": {
            "precision": 0.82845,
            "recall": 0.78836,
            "fmeasure": 0.80372
        },
        "rougeLsum": {
            "precision": 0.82845,
            "recall": 0.78836,
            "fmeasure": 0.80372
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.8351648351648352
        },
        "nist": 5.703409352594742,
        "bleu": 64.51387,
        "bleurt": 0.63184,
        "nubia": {
            "semantic_relation": 4.71829,
            "contradiction": 0.40288,
            "irrelevancy": 6.78524,
            "logical_agreement": 92.81188,
            "grammar_ref": 4.9924,
            "grammar_hyp": 5.23552,
            "nubia_score": 0.86335
        },
        "meteor": 0.48318655799389115,
        "bertscore": {
            "precision": 0.97904,
            "recall": 0.97244,
            "f1": 0.97563
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_306": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.79,
        "total_length": 183,
        "mean_pred_length": 15.25,
        "std_pred_length": 3.788689307223102,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 122,
        "unique-1": 108,
        "entropy-1": 6.378700057955398,
        "distinct-2": 0.9590643274853801,
        "vocab_size-2": 164,
        "unique-2": 160,
        "entropy-2": 7.322737529467817,
        "cond_entropy-2": 0.7722506139410187,
        "distinct-3": 1.0,
        "vocab_size-3": 159,
        "unique-3": 159,
        "entropy-3": 7.312882955284325,
        "cond_entropy-3": -0.002676084717955317,
        "total_length-nopunct": 162,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 3.7969285832981723,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7345679012345679,
        "vocab_size-1-nopunct": 119,
        "unique-1-nopunct": 108,
        "entropy-1-nopunct": 6.45466527858162,
        "distinct-2-nopunct": 0.9533333333333334,
        "vocab_size-2-nopunct": 143,
        "unique-2-nopunct": 139,
        "entropy-2-nopunct": 7.120387607119261,
        "cond_entropy-2-nopunct": 0.7365371064818818,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 138,
        "unique-3-nopunct": 138,
        "entropy-3-nopunct": 7.108524456778167,
        "cond_entropy-3-nopunct": -0.0024343604822740297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65669,
            "recall": 0.69681,
            "fmeasure": 0.66079
        },
        "rouge2": {
            "precision": 0.44256,
            "recall": 0.46188,
            "fmeasure": 0.44089
        },
        "rougeL": {
            "precision": 0.553,
            "recall": 0.60152,
            "fmeasure": 0.56393
        },
        "rougeLsum": {
            "precision": 0.553,
            "recall": 0.60152,
            "fmeasure": 0.56393
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.3870967741935484,
            "3": 0.6634615384615384
        },
        "nist": 4.95860444676594,
        "bleu": 30.44589,
        "bleurt": 0.12527,
        "nubia": {
            "semantic_relation": 3.91093,
            "contradiction": 4.63781,
            "irrelevancy": 39.00574,
            "logical_agreement": 56.35645,
            "grammar_ref": 4.84087,
            "grammar_hyp": 4.4647,
            "nubia_score": 0.68043
        },
        "meteor": 0.3594286802297454,
        "bertscore": {
            "precision": 0.89703,
            "recall": 0.91014,
            "f1": 0.89792
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_335": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 57,
        "mean_pred_length": 14.25,
        "std_pred_length": 3.112474899497183,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 19,
        "distinct-1": 0.7017543859649122,
        "vocab_size-1": 40,
        "unique-1": 32,
        "entropy-1": 5.076409040853093,
        "distinct-2": 1.0,
        "vocab_size-2": 53,
        "unique-2": 53,
        "entropy-2": 5.727920454563195,
        "cond_entropy-2": 0.5576609211298489,
        "distinct-3": 1.0,
        "vocab_size-3": 49,
        "unique-3": 49,
        "entropy-3": 5.614709844115208,
        "cond_entropy-3": -0.11321061044799063,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.391164991562634,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.952368167875318,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.4594316186372955,
        "cond_entropy-2-nopunct": 0.5285501514588485,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.13750352374993507,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78262,
            "recall": 0.87052,
            "fmeasure": 0.82117
        },
        "rouge2": {
            "precision": 0.63114,
            "recall": 0.70704,
            "fmeasure": 0.66412
        },
        "rougeL": {
            "precision": 0.7722,
            "recall": 0.86126,
            "fmeasure": 0.81137
        },
        "rougeLsum": {
            "precision": 0.7722,
            "recall": 0.86126,
            "fmeasure": 0.81137
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.8461538461538461,
            "3": 0.9166666666666666
        },
        "nist": 5.018164354822894,
        "bleu": 66.83035,
        "bleurt": 0.66185,
        "nubia": {
            "semantic_relation": 4.55769,
            "contradiction": 10.24762,
            "irrelevancy": 46.42972,
            "logical_agreement": 43.32266,
            "grammar_ref": 5.05046,
            "grammar_hyp": 5.01134,
            "nubia_score": 0.8009
        },
        "meteor": 0.5241249536430475,
        "bertscore": {
            "precision": 0.96803,
            "recall": 0.98434,
            "f1": 0.97601
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_452": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.85,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 3.9841837197791885,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.28151981340693205,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.892407118592875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.2972690158966973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65,
            "recall": 0.54167,
            "fmeasure": 0.59091
        },
        "rouge2": {
            "precision": 0.31579,
            "recall": 0.26087,
            "fmeasure": 0.28571
        },
        "rougeL": {
            "precision": 0.45,
            "recall": 0.375,
            "fmeasure": 0.40909
        },
        "rougeLsum": {
            "precision": 0.45,
            "recall": 0.375,
            "fmeasure": 0.40909
        },
        "local_recall": {
            "1": 0,
            "2": 0.75,
            "3": 0.4166666666666667
        },
        "nist": 2.7645242106209524,
        "bleu": 9.60059,
        "bleurt": -0.36268,
        "nubia": {
            "semantic_relation": 3.2335,
            "contradiction": 73.92248,
            "irrelevancy": 23.26439,
            "logical_agreement": 2.81313,
            "grammar_ref": 4.791,
            "grammar_hyp": 4.75136,
            "nubia_score": 0.42576
        },
        "meteor": 0.2629380773392699,
        "bertscore": {
            "precision": 0.85317,
            "recall": 0.85095,
            "f1": 0.85206
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_420": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.79,
        "total_length": 158,
        "mean_pred_length": 14.363636363636363,
        "std_pred_length": 5.103879580952073,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.6835443037974683,
        "vocab_size-1": 108,
        "unique-1": 91,
        "entropy-1": 6.312372780130053,
        "distinct-2": 0.9591836734693877,
        "vocab_size-2": 141,
        "unique-2": 137,
        "entropy-2": 7.1077691135144025,
        "cond_entropy-2": 0.601320824136649,
        "distinct-3": 1.0,
        "vocab_size-3": 136,
        "unique-3": 136,
        "entropy-3": 7.0874628412503275,
        "cond_entropy-3": -0.012872922671856257,
        "total_length-nopunct": 142,
        "mean_pred_length-nopunct": 12.909090909090908,
        "std_pred_length-nopunct": 4.561788832834319,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7464788732394366,
        "vocab_size-1-nopunct": 106,
        "unique-1-nopunct": 91,
        "entropy-1-nopunct": 6.4059238170907316,
        "distinct-2-nopunct": 0.9541984732824428,
        "vocab_size-2-nopunct": 125,
        "unique-2-nopunct": 121,
        "entropy-2-nopunct": 6.930294948069307,
        "cond_entropy-2-nopunct": 0.5791959884331865,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 120,
        "unique-3-nopunct": 120,
        "entropy-3-nopunct": 6.906890595608536,
        "cond_entropy-3-nopunct": -0.013950947559540773,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83682,
            "recall": 0.75951,
            "fmeasure": 0.79061
        },
        "rouge2": {
            "precision": 0.64465,
            "recall": 0.57858,
            "fmeasure": 0.60538
        },
        "rougeL": {
            "precision": 0.74243,
            "recall": 0.66865,
            "fmeasure": 0.69853
        },
        "rougeLsum": {
            "precision": 0.74243,
            "recall": 0.66865,
            "fmeasure": 0.69853
        },
        "local_recall": {
            "1": 0.11538461538461539,
            "2": 0.5263157894736842,
            "3": 0.7903225806451613
        },
        "nist": 5.677577021960961,
        "bleu": 49.7955,
        "bleurt": 0.46271,
        "nubia": {
            "semantic_relation": 4.39045,
            "contradiction": 0.63994,
            "irrelevancy": 14.6097,
            "logical_agreement": 84.75036,
            "grammar_ref": 4.45431,
            "grammar_hyp": 4.45275,
            "nubia_score": 0.80776
        },
        "meteor": 0.4159839662662311,
        "bertscore": {
            "precision": 0.94234,
            "recall": 0.92695,
            "f1": 0.93355
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_408": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.79,
        "total_length": 222,
        "mean_pred_length": 14.8,
        "std_pred_length": 4.519587001780878,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.6621621621621622,
        "vocab_size-1": 147,
        "unique-1": 121,
        "entropy-1": 6.7088553985689385,
        "distinct-2": 0.9710144927536232,
        "vocab_size-2": 201,
        "unique-2": 196,
        "entropy-2": 7.631869143479186,
        "cond_entropy-2": 0.7185695327488633,
        "distinct-3": 1.0,
        "vocab_size-3": 192,
        "unique-3": 192,
        "entropy-3": 7.584962500721179,
        "cond_entropy-3": -0.04209275103773427,
        "total_length-nopunct": 197,
        "mean_pred_length-nopunct": 13.133333333333333,
        "std_pred_length-nopunct": 4.34920171474669,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7258883248730964,
        "vocab_size-1-nopunct": 143,
        "unique-1-nopunct": 121,
        "entropy-1-nopunct": 6.795243241238265,
        "distinct-2-nopunct": 0.967032967032967,
        "vocab_size-2-nopunct": 176,
        "unique-2-nopunct": 171,
        "entropy-2-nopunct": 7.437712840736277,
        "cond_entropy-2-nopunct": 0.7051186581423163,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 167,
        "unique-3-nopunct": 167,
        "entropy-3-nopunct": 7.383704292474028,
        "cond_entropy-3-nopunct": -0.047713775855401756,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79556,
            "recall": 0.76412,
            "fmeasure": 0.77411
        },
        "rouge2": {
            "precision": 0.59597,
            "recall": 0.55679,
            "fmeasure": 0.57028
        },
        "rougeL": {
            "precision": 0.70044,
            "recall": 0.6737,
            "fmeasure": 0.68273
        },
        "rougeLsum": {
            "precision": 0.70044,
            "recall": 0.6737,
            "fmeasure": 0.68273
        },
        "local_recall": {
            "1": 0.3829787234042553,
            "2": 0.37037037037037035,
            "3": 0.8
        },
        "nist": 6.430875516621344,
        "bleu": 54.77793,
        "bleurt": 0.33532,
        "nubia": {
            "semantic_relation": 4.46293,
            "contradiction": 5.41162,
            "irrelevancy": 31.06939,
            "logical_agreement": 63.51899,
            "grammar_ref": 4.56596,
            "grammar_hyp": 4.6006,
            "nubia_score": 0.81452
        },
        "meteor": 0.4391330970708712,
        "bertscore": {
            "precision": 0.95149,
            "recall": 0.9508,
            "f1": 0.94927
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_371": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966058,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.55882,
            "recall": 0.67949,
            "fmeasure": 0.6125
        },
        "rouge2": {
            "precision": 0.34375,
            "recall": 0.42262,
            "fmeasure": 0.37857
        },
        "rougeL": {
            "precision": 0.29412,
            "recall": 0.3641,
            "fmeasure": 0.325
        },
        "rougeLsum": {
            "precision": 0.29412,
            "recall": 0.3641,
            "fmeasure": 0.325
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.7272727272727273
        },
        "nist": 2.8832317492884134,
        "bleu": 22.814,
        "bleurt": 0.0275,
        "nubia": {
            "semantic_relation": 3.49167,
            "contradiction": 0.11318,
            "irrelevancy": 99.77589,
            "logical_agreement": 0.11093,
            "grammar_ref": 4.56931,
            "grammar_hyp": 3.98939,
            "nubia_score": 0.61119
        },
        "meteor": 0.35953690599642546,
        "bertscore": {
            "precision": 0.85673,
            "recall": 0.84674,
            "f1": 0.8517
        }
    },
    "schema_guided_dialog_challenge_test_nopunc_parent": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.70162,
        "msttr-100_nopunct": 0.73083,
        "total_length": 6894,
        "mean_pred_length": 13.788,
        "std_pred_length": 7.993188099876043,
        "median_pred_length": 12.0,
        "min_pred_length": 2,
        "max_pred_length": 58,
        "distinct-1": 0.15868871482448507,
        "vocab_size-1": 1094,
        "unique-1": 633,
        "entropy-1": 7.9095246162776975,
        "distinct-2": 0.48780106349702845,
        "vocab_size-2": 3119,
        "unique-2": 2226,
        "entropy-2": 10.782165595668573,
        "cond_entropy-2": 2.6604791195376554,
        "distinct-3": 0.7029182219205972,
        "vocab_size-3": 4143,
        "unique-3": 3431,
        "entropy-3": 11.619006536471831,
        "cond_entropy-3": 0.8670114644970272,
        "total_length-nopunct": 6078,
        "mean_pred_length-nopunct": 12.156,
        "std_pred_length-nopunct": 7.259177914888159,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 50,
        "distinct-1-nopunct": 0.1780190852254031,
        "vocab_size-1-nopunct": 1082,
        "unique-1-nopunct": 632,
        "entropy-1-nopunct": 8.082289173416791,
        "distinct-2-nopunct": 0.5007171029042667,
        "vocab_size-2-nopunct": 2793,
        "unique-2-nopunct": 2036,
        "entropy-2-nopunct": 10.608405878748682,
        "cond_entropy-2-nopunct": 2.6571610609275282,
        "distinct-3-nopunct": 0.7128790862544309,
        "vocab_size-3-nopunct": 3620,
        "unique-3-nopunct": 3042,
        "entropy-3-nopunct": 11.416971210996202,
        "cond_entropy-3-nopunct": 0.8475881702301881,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.58286,
            "recall": 0.55487,
            "fmeasure": 0.55663
        },
        "rouge2": {
            "precision": 0.3608,
            "recall": 0.33948,
            "fmeasure": 0.3419
        },
        "rougeL": {
            "precision": 0.52249,
            "recall": 0.49616,
            "fmeasure": 0.49835
        },
        "rougeLsum": {
            "precision": 0.52249,
            "recall": 0.49616,
            "fmeasure": 0.49835
        },
        "local_recall": {
            "1": 0.5711928724632899
        },
        "nist": 6.2110752734869665,
        "bleu": 31.73001,
        "bleurt": -0.06178,
        "nubia": {
            "semantic_relation": 3.69773,
            "contradiction": 7.9485,
            "irrelevancy": 21.75537,
            "logical_agreement": 70.29613,
            "grammar_ref": 4.79983,
            "grammar_hyp": 4.59999,
            "nubia_score": 0.65536
        },
        "meteor": 0.3170377155410971,
        "bertscore": {
            "precision": 0.87614,
            "recall": 0.86786,
            "f1": 0.87151
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_423": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 2.0,
        "median_pred_length": 16.0,
        "min_pred_length": 14,
        "max_pred_length": 18,
        "distinct-1": 0.90625,
        "vocab_size-1": 29,
        "unique-1": 26,
        "entropy-1": 4.8125,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.04022392894185191,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9259259259259259,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.606739354015323,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.04896868761125603,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.58734,
            "recall": 0.6537,
            "fmeasure": 0.61171
        },
        "rouge2": {
            "precision": 0.29722,
            "recall": 0.31548,
            "fmeasure": 0.30382
        },
        "rougeL": {
            "precision": 0.45353,
            "recall": 0.48687,
            "fmeasure": 0.46417
        },
        "rougeLsum": {
            "precision": 0.45353,
            "recall": 0.48687,
            "fmeasure": 0.46417
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.1,
            "3": 0.8571428571428571
        },
        "nist": 3.611303509350674,
        "bleu": 40.60326,
        "bleurt": 0.3394,
        "nubia": {
            "semantic_relation": 4.23943,
            "contradiction": 0.26974,
            "irrelevancy": 21.64082,
            "logical_agreement": 78.08944,
            "grammar_ref": 4.57807,
            "grammar_hyp": 3.68194,
            "nubia_score": 0.8209
        },
        "meteor": 0.39660775057689984,
        "bertscore": {
            "precision": 0.90639,
            "recall": 0.91698,
            "f1": 0.90742
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_410": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.72,
        "total_length": 171,
        "mean_pred_length": 17.1,
        "std_pred_length": 4.323193264243457,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.6257309941520468,
        "vocab_size-1": 107,
        "unique-1": 89,
        "entropy-1": 6.24286342781613,
        "distinct-2": 0.9192546583850931,
        "vocab_size-2": 148,
        "unique-2": 138,
        "entropy-2": 7.155359968136403,
        "cond_entropy-2": 0.7791462913875115,
        "distinct-3": 1.0,
        "vocab_size-3": 151,
        "unique-3": 151,
        "entropy-3": 7.238404739325059,
        "cond_entropy-3": 0.09467105661768303,
        "total_length-nopunct": 151,
        "mean_pred_length-nopunct": 15.1,
        "std_pred_length-nopunct": 4.158124577258358,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6887417218543046,
        "vocab_size-1-nopunct": 104,
        "unique-1-nopunct": 88,
        "entropy-1-nopunct": 6.316719123913972,
        "distinct-2-nopunct": 0.9219858156028369,
        "vocab_size-2-nopunct": 130,
        "unique-2-nopunct": 122,
        "entropy-2-nopunct": 6.967461547388203,
        "cond_entropy-2-nopunct": 0.7090179990353086,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 131,
        "unique-3-nopunct": 131,
        "entropy-3-nopunct": 7.03342300153745,
        "cond_entropy-3-nopunct": 0.07909808048591196,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8746,
            "recall": 0.89518,
            "fmeasure": 0.87777
        },
        "rouge2": {
            "precision": 0.72699,
            "recall": 0.76586,
            "fmeasure": 0.74092
        },
        "rougeL": {
            "precision": 0.74012,
            "recall": 0.78618,
            "fmeasure": 0.75677
        },
        "rougeLsum": {
            "precision": 0.74012,
            "recall": 0.78618,
            "fmeasure": 0.75677
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6923076923076923,
            "3": 0.944954128440367
        },
        "nist": 6.60358970448169,
        "bleu": 66.96416,
        "bleurt": 0.57333,
        "nubia": {
            "semantic_relation": 4.60792,
            "contradiction": 5.69825,
            "irrelevancy": 28.91561,
            "logical_agreement": 65.38614,
            "grammar_ref": 4.86973,
            "grammar_hyp": 4.84364,
            "nubia_score": 0.85622
        },
        "meteor": 0.5019270029994684,
        "bertscore": {
            "precision": 0.96449,
            "recall": 0.97388,
            "f1": 0.96823
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_455": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 0.5,
        "median_pred_length": 13.5,
        "min_pred_length": 13,
        "max_pred_length": 14,
        "distinct-1": 0.7407407407407407,
        "vocab_size-1": 20,
        "unique-1": 14,
        "entropy-1": 4.208410187268527,
        "distinct-2": 0.92,
        "vocab_size-2": 23,
        "unique-2": 21,
        "entropy-2": 4.483856189774723,
        "cond_entropy-2": 0.23916418769779485,
        "distinct-3": 0.9565217391304348,
        "vocab_size-3": 22,
        "unique-3": 21,
        "entropy-3": 4.436605434317882,
        "cond_entropy-3": -0.03333771197858132,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8095238095238095,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.9754180179138325,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.2637620644629025,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.89103,
            "recall": 0.7364,
            "fmeasure": 0.804
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.48141,
            "fmeasure": 0.52558
        },
        "rougeL": {
            "precision": 0.85737,
            "recall": 0.70808,
            "fmeasure": 0.77328
        },
        "rougeLsum": {
            "precision": 0.85737,
            "recall": 0.70808,
            "fmeasure": 0.77328
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.9411764705882353
        },
        "nist": 4.812385515782415,
        "bleu": 54.8773,
        "bleurt": 0.39395,
        "nubia": {
            "semantic_relation": 4.39625,
            "contradiction": 0.79646,
            "irrelevancy": 26.93849,
            "logical_agreement": 72.26506,
            "grammar_ref": 5.06568,
            "grammar_hyp": 4.84031,
            "nubia_score": 0.82004
        },
        "meteor": 0.41358116724244276,
        "bertscore": {
            "precision": 0.94284,
            "recall": 0.92976,
            "f1": 0.93602
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_413": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.59028,
            "fmeasure": 0.64583
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.26786,
            "fmeasure": 0.2967
        },
        "rougeL": {
            "precision": 0.64286,
            "recall": 0.53472,
            "fmeasure": 0.58333
        },
        "rougeLsum": {
            "precision": 0.64286,
            "recall": 0.53472,
            "fmeasure": 0.58333
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.8333333333333334
        },
        "nist": 2.424045613579025,
        "bleu": 23.87517,
        "bleurt": 0.36479,
        "nubia": {
            "semantic_relation": 4.54461,
            "contradiction": 1.34543,
            "irrelevancy": 1.12655,
            "logical_agreement": 97.52803,
            "grammar_ref": 6.12307,
            "grammar_hyp": 6.75169,
            "nubia_score": 0.70681
        },
        "meteor": 0.3639847537058618,
        "bertscore": {
            "precision": 0.90465,
            "recall": 0.87542,
            "f1": 0.88979
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_414": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 1.5,
        "median_pred_length": 15.5,
        "min_pred_length": 14,
        "max_pred_length": 17,
        "distinct-1": 0.8064516129032258,
        "vocab_size-1": 25,
        "unique-1": 19,
        "entropy-1": 4.567099536193328,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.24861227094759364,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8518518518518519,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.458591205867174,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.20896868761125603,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.61806,
            "recall": 0.63935,
            "fmeasure": 0.61007
        },
        "rouge2": {
            "precision": 0.23434,
            "recall": 0.27422,
            "fmeasure": 0.25
        },
        "rougeL": {
            "precision": 0.51042,
            "recall": 0.52682,
            "fmeasure": 0.51094
        },
        "rougeLsum": {
            "precision": 0.51042,
            "recall": 0.52682,
            "fmeasure": 0.51094
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.45454545454545453,
            "3": 0.6666666666666666
        },
        "nist": 3.2481072755934823,
        "bleu": 12.00402,
        "bleurt": 0.01461,
        "nubia": {
            "semantic_relation": 3.94394,
            "contradiction": 0.26832,
            "irrelevancy": 41.45934,
            "logical_agreement": 58.27234,
            "grammar_ref": 4.46073,
            "grammar_hyp": 4.12935,
            "nubia_score": 0.69453
        },
        "meteor": 0.3348671128764215,
        "bertscore": {
            "precision": 0.89762,
            "recall": 0.89473,
            "f1": 0.89088
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_456": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 1.0,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 13,
        "distinct-1": 0.7916666666666666,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.017894147619623,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.4021800485723598,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 3.931720687981077,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.4429784999719052,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.85198,
            "fmeasure": 0.84188
        },
        "rouge2": {
            "precision": 0.56944,
            "recall": 0.57222,
            "fmeasure": 0.57071
        },
        "rougeL": {
            "precision": 0.67949,
            "recall": 0.68881,
            "fmeasure": 0.68376
        },
        "rougeLsum": {
            "precision": 0.67949,
            "recall": 0.68881,
            "fmeasure": 0.68376
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.75,
            "3": 0.8
        },
        "nist": 4.065388765091914,
        "bleu": 54.38787,
        "bleurt": 0.59222,
        "nubia": {
            "semantic_relation": 4.80561,
            "contradiction": 0.43891,
            "irrelevancy": 0.64051,
            "logical_agreement": 98.92058,
            "grammar_ref": 3.96214,
            "grammar_hyp": 4.0013,
            "nubia_score": 0.94371
        },
        "meteor": 0.45162570518506967,
        "bertscore": {
            "precision": 0.94573,
            "recall": 0.94429,
            "f1": 0.94501
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_336": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.75,
        "total_length": 294,
        "mean_pred_length": 17.294117647058822,
        "std_pred_length": 6.857925478489257,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.6054421768707483,
        "vocab_size-1": 178,
        "unique-1": 146,
        "entropy-1": 6.779715924091581,
        "distinct-2": 0.9097472924187726,
        "vocab_size-2": 252,
        "unique-2": 232,
        "entropy-2": 7.912985341231768,
        "cond_entropy-2": 0.955170072517647,
        "distinct-3": 0.9692307692307692,
        "vocab_size-3": 252,
        "unique-3": 244,
        "entropy-3": 7.960829351489992,
        "cond_entropy-3": 0.05327811034248457,
        "total_length-nopunct": 256,
        "mean_pred_length-nopunct": 15.058823529411764,
        "std_pred_length-nopunct": 5.975150386837869,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6796875,
        "vocab_size-1-nopunct": 174,
        "unique-1-nopunct": 146,
        "entropy-1-nopunct": 6.912112106295979,
        "distinct-2-nopunct": 0.9121338912133892,
        "vocab_size-2-nopunct": 218,
        "unique-2-nopunct": 202,
        "entropy-2-nopunct": 7.70166329135135,
        "cond_entropy-2-nopunct": 0.8418277297957839,
        "distinct-3-nopunct": 0.9684684684684685,
        "vocab_size-3-nopunct": 215,
        "unique-3-nopunct": 208,
        "entropy-3-nopunct": 7.731352803287031,
        "cond_entropy-3-nopunct": 0.03593482627222584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76423,
            "recall": 0.68967,
            "fmeasure": 0.70642
        },
        "rouge2": {
            "precision": 0.52826,
            "recall": 0.4869,
            "fmeasure": 0.49205
        },
        "rougeL": {
            "precision": 0.6742,
            "recall": 0.62249,
            "fmeasure": 0.6303
        },
        "rougeLsum": {
            "precision": 0.6742,
            "recall": 0.62249,
            "fmeasure": 0.6303
        },
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.36470588235294116,
            "3": 0.7158469945355191
        },
        "nist": 5.6096249540792895,
        "bleu": 40.14651,
        "bleurt": 0.1708,
        "nubia": {
            "semantic_relation": 3.9968,
            "contradiction": 8.71102,
            "irrelevancy": 38.91078,
            "logical_agreement": 52.37821,
            "grammar_ref": 4.33068,
            "grammar_hyp": 4.36246,
            "nubia_score": 0.67448
        },
        "meteor": 0.36192773430357594,
        "bertscore": {
            "precision": 0.92229,
            "recall": 0.91539,
            "f1": 0.91543
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_339": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.12336199461765371,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.1219280948873624,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.1365257343456969,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.67677,
            "fmeasure": 0.6716
        },
        "rouge2": {
            "precision": 0.4127,
            "recall": 0.41905,
            "fmeasure": 0.4158
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.51587,
            "fmeasure": 0.50775
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.51587,
            "fmeasure": 0.50775
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.5333333333333333
        },
        "nist": 2.727820309920678,
        "bleu": 16.49603,
        "bleurt": -0.09189,
        "nubia": {
            "semantic_relation": 3.6736,
            "contradiction": 0.13268,
            "irrelevancy": 99.70432,
            "logical_agreement": 0.163,
            "grammar_ref": 3.42286,
            "grammar_hyp": 4.02938,
            "nubia_score": 0.6146
        },
        "meteor": 0.36655958751306444,
        "bertscore": {
            "precision": 0.89467,
            "recall": 0.88698,
            "f1": 0.89081
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_459": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 6.5,
        "median_pred_length": 18.5,
        "min_pred_length": 12,
        "max_pred_length": 25,
        "distinct-1": 0.7567567567567568,
        "vocab_size-1": 28,
        "unique-1": 21,
        "entropy-1": 4.668912825088411,
        "distinct-2": 0.9428571428571428,
        "vocab_size-2": 33,
        "unique-2": 31,
        "entropy-2": 5.014997302659249,
        "cond_entropy-2": 0.3198296513160167,
        "distinct-3": 0.9696969696969697,
        "vocab_size-3": 32,
        "unique-3": 31,
        "entropy-3": 4.9837880587523955,
        "cond_entropy-3": -0.02428283698045265,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 6.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.78125,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.5,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.773557262275186,
        "cond_entropy-2-nopunct": 0.27355726227518523,
        "distinct-3-nopunct": 0.9642857142857143,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.735926350629034,
        "cond_entropy-3-nopunct": -0.028107102122342933,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.9,
            "fmeasure": 0.92105
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 0.9583333333333334
        },
        "nist": 5.47016276840381,
        "bleu": 96.12221,
        "bleurt": 0.81354,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.53906,
            "irrelevancy": 0.72266,
            "logical_agreement": 98.73828,
            "grammar_ref": 3.53925,
            "grammar_hyp": 3.66544,
            "nubia_score": 0.98279
        },
        "meteor": 0.6581712478767607,
        "bertscore": {
            "precision": 0.99581,
            "recall": 0.99056,
            "f1": 0.99317
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_460": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 57,
        "mean_pred_length": 14.25,
        "std_pred_length": 4.264680527307995,
        "median_pred_length": 14.5,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.7017543859649122,
        "vocab_size-1": 40,
        "unique-1": 29,
        "entropy-1": 5.1483365052409855,
        "distinct-2": 0.9056603773584906,
        "vocab_size-2": 48,
        "unique-2": 44,
        "entropy-2": 5.524998048861998,
        "cond_entropy-2": 0.2773825631624272,
        "distinct-3": 0.9591836734693877,
        "vocab_size-3": 47,
        "unique-3": 45,
        "entropy-3": 5.533077191053984,
        "cond_entropy-3": 0.024644236534937133,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 3.905124837953327,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.76,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 5.118562939644918,
        "distinct-2-nopunct": 0.8695652173913043,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.2462817929665,
        "cond_entropy-2-nopunct": 0.13894082070850083,
        "distinct-3-nopunct": 0.9285714285714286,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.249460279921619,
        "cond_entropy-3-nopunct": 0.029586121535163507,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88462,
            "recall": 0.88462,
            "fmeasure": 0.88462
        },
        "rouge2": {
            "precision": 0.8125,
            "recall": 0.8125,
            "fmeasure": 0.8125
        },
        "rougeL": {
            "precision": 0.86538,
            "recall": 0.86538,
            "fmeasure": 0.86538
        },
        "rougeLsum": {
            "precision": 0.86538,
            "recall": 0.86538,
            "fmeasure": 0.86538
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8775510204081632
        },
        "nist": 4.840220922910872,
        "bleu": 74.17077,
        "bleurt": 0.84326,
        "nubia": {
            "semantic_relation": 4.71791,
            "contradiction": 2.39481,
            "irrelevancy": 1.17921,
            "logical_agreement": 96.42597,
            "grammar_ref": 5.0449,
            "grammar_hyp": 4.83568,
            "nubia_score": 0.91542
        },
        "meteor": 0.521063518793893,
        "bertscore": {
            "precision": 0.9677,
            "recall": 0.96237,
            "f1": 0.96484
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_372": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 51,
        "mean_pred_length": 17.0,
        "std_pred_length": 2.449489742783178,
        "median_pred_length": 17.0,
        "min_pred_length": 14,
        "max_pred_length": 20,
        "distinct-1": 0.7843137254901961,
        "vocab_size-1": 40,
        "unique-1": 32,
        "entropy-1": 5.196647645765804,
        "distinct-2": 1.0,
        "vocab_size-2": 48,
        "unique-2": 48,
        "entropy-2": 5.5849625007211605,
        "cond_entropy-2": 0.3189908046731385,
        "distinct-3": 1.0,
        "vocab_size-3": 45,
        "unique-3": 45,
        "entropy-3": 5.491853096329673,
        "cond_entropy-3": -0.09310940439148176,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 2.0548046676563256,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8409090909090909,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.124093266315398,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.357552004618081,
        "cond_entropy-2-nopunct": 0.23360544700916355,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.10962449117449787,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.87222,
            "recall": 0.8462,
            "fmeasure": 0.85424
        },
        "rouge2": {
            "precision": 0.73782,
            "recall": 0.69626,
            "fmeasure": 0.71253
        },
        "rougeL": {
            "precision": 0.81667,
            "recall": 0.77953,
            "fmeasure": 0.79363
        },
        "rougeLsum": {
            "precision": 0.81667,
            "recall": 0.77953,
            "fmeasure": 0.79363
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.8461538461538461,
            "3": 0.8518518518518519
        },
        "nist": 4.84516414824908,
        "bleu": 69.37679,
        "bleurt": 0.43141,
        "nubia": {
            "semantic_relation": 4.61861,
            "contradiction": 8.58088,
            "irrelevancy": 17.29671,
            "logical_agreement": 74.12241,
            "grammar_ref": 4.97796,
            "grammar_hyp": 4.95481,
            "nubia_score": 0.80825
        },
        "meteor": 0.4927176396084974,
        "bertscore": {
            "precision": 0.94506,
            "recall": 0.94421,
            "f1": 0.94441
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_490": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 76,
        "mean_pred_length": 15.2,
        "std_pred_length": 4.166533331199932,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.75,
        "vocab_size-1": 57,
        "unique-1": 48,
        "entropy-1": 5.59113610606341,
        "distinct-2": 0.9859154929577465,
        "vocab_size-2": 70,
        "unique-2": 69,
        "entropy-2": 6.121578105420169,
        "cond_entropy-2": 0.3789938645203301,
        "distinct-3": 1.0,
        "vocab_size-3": 66,
        "unique-3": 66,
        "entropy-3": 6.044394119358462,
        "cond_entropy-3": -0.07504996984319821,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 12.8,
        "std_pred_length-nopunct": 3.3105890714493698,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 52,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.558364648336088,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 59,
        "unique-2-nopunct": 59,
        "entropy-2-nopunct": 5.882643049361836,
        "cond_entropy-2-nopunct": 0.34475597320066187,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 54,
        "unique-3-nopunct": 54,
        "entropy-3-nopunct": 5.7548875021634665,
        "cond_entropy-3-nopunct": -0.12775554719837257,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78725,
            "recall": 0.76256,
            "fmeasure": 0.76842
        },
        "rouge2": {
            "precision": 0.59741,
            "recall": 0.57987,
            "fmeasure": 0.5827
        },
        "rougeL": {
            "precision": 0.72843,
            "recall": 0.68953,
            "fmeasure": 0.70259
        },
        "rougeLsum": {
            "precision": 0.72843,
            "recall": 0.68953,
            "fmeasure": 0.70259
        },
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.125,
            "3": 0.75
        },
        "nist": 4.614481310079597,
        "bleu": 40.77186,
        "bleurt": 0.26868,
        "nubia": {
            "semantic_relation": 4.34861,
            "contradiction": 2.94586,
            "irrelevancy": 22.05321,
            "logical_agreement": 75.00093,
            "grammar_ref": 4.31899,
            "grammar_hyp": 4.31439,
            "nubia_score": 0.80824
        },
        "meteor": 0.3958027912750074,
        "bertscore": {
            "precision": 0.94422,
            "recall": 0.93569,
            "f1": 0.93918
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_424": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 52,
        "mean_pred_length": 13.0,
        "std_pred_length": 6.442049363362563,
        "median_pred_length": 11.5,
        "min_pred_length": 6,
        "max_pred_length": 23,
        "distinct-1": 0.7307692307692307,
        "vocab_size-1": 38,
        "unique-1": 30,
        "entropy-1": 5.056020968057883,
        "distinct-2": 1.0,
        "vocab_size-2": 48,
        "unique-2": 48,
        "entropy-2": 5.5849625007211605,
        "cond_entropy-2": 0.41597642850354233,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": -0.12553088208385924,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 6.020797289396148,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.782608695652174,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.012479890745556,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.3923174227787625,
        "cond_entropy-2-nopunct": 0.4047024906342935,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.14438990933517482,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.58512,
            "recall": 0.60698,
            "fmeasure": 0.58108
        },
        "rouge2": {
            "precision": 0.36234,
            "recall": 0.37877,
            "fmeasure": 0.3586
        },
        "rougeL": {
            "precision": 0.4879,
            "recall": 0.50407,
            "fmeasure": 0.48172
        },
        "rougeLsum": {
            "precision": 0.4879,
            "recall": 0.50407,
            "fmeasure": 0.48172
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0,
            "3": 0.65
        },
        "nist": 4.056931303813524,
        "bleu": 31.85318,
        "bleurt": 0.0987,
        "nubia": {
            "semantic_relation": 3.93614,
            "contradiction": 22.97862,
            "irrelevancy": 11.6093,
            "logical_agreement": 65.41208,
            "grammar_ref": 4.90076,
            "grammar_hyp": 4.8636,
            "nubia_score": 0.65703
        },
        "meteor": 0.35724581515629794,
        "bertscore": {
            "precision": 0.90598,
            "recall": 0.89657,
            "f1": 0.90034
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_462": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 91,
        "mean_pred_length": 22.75,
        "std_pred_length": 8.437268515343103,
        "median_pred_length": 22.0,
        "min_pred_length": 12,
        "max_pred_length": 35,
        "distinct-1": 0.7912087912087912,
        "vocab_size-1": 72,
        "unique-1": 61,
        "entropy-1": 5.958344090748148,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 84,
        "unique-2": 81,
        "entropy-2": 6.373977978607345,
        "cond_entropy-2": 0.34894195909830805,
        "distinct-3": 0.9879518072289156,
        "vocab_size-3": 82,
        "unique-3": 81,
        "entropy-3": 6.350943045804763,
        "cond_entropy-3": -0.01971129341746646,
        "total_length-nopunct": 76,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 6.708203932499369,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.881578947368421,
        "vocab_size-1-nopunct": 67,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 6.011085408180434,
        "distinct-2-nopunct": 0.9722222222222222,
        "vocab_size-2-nopunct": 70,
        "unique-2-nopunct": 68,
        "entropy-2-nopunct": 6.11436944588676,
        "cond_entropy-2-nopunct": 0.11644193244317119,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 68,
        "unique-3-nopunct": 68,
        "entropy-3-nopunct": 6.087462841250345,
        "cond_entropy-3-nopunct": -0.023638630780208267,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80766,
            "recall": 0.72454,
            "fmeasure": 0.76142
        },
        "rouge2": {
            "precision": 0.60307,
            "recall": 0.54271,
            "fmeasure": 0.56923
        },
        "rougeL": {
            "precision": 0.62423,
            "recall": 0.56414,
            "fmeasure": 0.59089
        },
        "rougeLsum": {
            "precision": 0.62423,
            "recall": 0.56414,
            "fmeasure": 0.59089
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.75
        },
        "nist": 4.385336083600233,
        "bleu": 38.23462,
        "bleurt": 0.33379,
        "nubia": {
            "semantic_relation": 3.89677,
            "contradiction": 45.84472,
            "irrelevancy": 22.58274,
            "logical_agreement": 31.57254,
            "grammar_ref": 4.59177,
            "grammar_hyp": 4.25458,
            "nubia_score": 0.66177
        },
        "meteor": 0.3578240701817171,
        "bertscore": {
            "precision": 0.93612,
            "recall": 0.90686,
            "f1": 0.92115
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_375": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.75,
        "msttr-100_nopunct": NaN,
        "total_length": 103,
        "mean_pred_length": 12.875,
        "std_pred_length": 3.6206870894900596,
        "median_pred_length": 11.5,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.7475728155339806,
        "vocab_size-1": 77,
        "unique-1": 62,
        "entropy-1": 6.038394823278733,
        "distinct-2": 0.9263157894736842,
        "vocab_size-2": 88,
        "unique-2": 81,
        "entropy-2": 6.422487187278317,
        "cond_entropy-2": 0.18603810748629235,
        "distinct-3": 0.9540229885057471,
        "vocab_size-3": 83,
        "unique-3": 79,
        "entropy-3": 6.350989472860217,
        "cond_entropy-3": -0.05794659524084036,
        "total_length-nopunct": 89,
        "mean_pred_length-nopunct": 11.125,
        "std_pred_length-nopunct": 3.550968177835448,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8202247191011236,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 6.085229077009514,
        "distinct-2-nopunct": 0.9382716049382716,
        "vocab_size-2-nopunct": 76,
        "unique-2-nopunct": 71,
        "entropy-2-nopunct": 6.216393212761157,
        "cond_entropy-2-nopunct": 0.1697324670066648,
        "distinct-3-nopunct": 0.958904109589041,
        "vocab_size-3-nopunct": 70,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 6.107632778058109,
        "cond_entropy-3-nopunct": -0.09523092345666229,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.89685,
            "recall": 0.7984,
            "fmeasure": 0.83587
        },
        "rouge2": {
            "precision": 0.62771,
            "recall": 0.57151,
            "fmeasure": 0.59164
        },
        "rougeL": {
            "precision": 0.73023,
            "recall": 0.65483,
            "fmeasure": 0.68325
        },
        "rougeLsum": {
            "precision": 0.73023,
            "recall": 0.65483,
            "fmeasure": 0.68325
        },
        "local_recall": {
            "1": 0.13513513513513514,
            "2": 0.7,
            "3": 0.8833333333333333
        },
        "nist": 5.190610555770061,
        "bleu": 46.58172,
        "bleurt": 0.38929,
        "nubia": {
            "semantic_relation": 4.40797,
            "contradiction": 2.08935,
            "irrelevancy": 18.06127,
            "logical_agreement": 79.84938,
            "grammar_ref": 5.34109,
            "grammar_hyp": 5.47407,
            "nubia_score": 0.75474
        },
        "meteor": 0.4097149848724323,
        "bertscore": {
            "precision": 0.9525,
            "recall": 0.93446,
            "f1": 0.93964
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_challenge_test_turk_backtranslation",
        "N": 359,
        "msttr-100": 0.71662,
        "msttr-100_nopunct": 0.75917,
        "total_length": 6850,
        "mean_pred_length": 19.080779944289695,
        "std_pred_length": 9.22462753460174,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.35956204379562046,
        "vocab_size-1": 2463,
        "unique-1": 1814,
        "entropy-1": 8.995410193403645,
        "distinct-2": 0.8288399322138346,
        "vocab_size-2": 5380,
        "unique-2": 4952,
        "entropy-2": 12.055305736558978,
        "cond_entropy-2": 2.790841040745259,
        "distinct-3": 0.9603718199608611,
        "vocab_size-3": 5889,
        "unique-3": 5770,
        "entropy-3": 12.451370850221815,
        "cond_entropy-3": 0.41281581503597586,
        "total_length-nopunct": 6094,
        "mean_pred_length-nopunct": 16.974930362116993,
        "std_pred_length-nopunct": 8.226727007225776,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.4023629799803085,
        "vocab_size-1-nopunct": 2452,
        "unique-1-nopunct": 1810,
        "entropy-1-nopunct": 9.334550935675878,
        "distinct-2-nopunct": 0.8482999128160419,
        "vocab_size-2-nopunct": 4865,
        "unique-2-nopunct": 4514,
        "entropy-2-nopunct": 11.954316312004455,
        "cond_entropy-2-nopunct": 2.7628966353580395,
        "distinct-3-nopunct": 0.9747023809523809,
        "vocab_size-3-nopunct": 5240,
        "unique-3-nopunct": 5146,
        "entropy-3-nopunct": 12.331459576059313,
        "cond_entropy-3-nopunct": 0.4021285140611452,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_backtranslation.json",
        "rouge1": {
            "precision": 0.69655,
            "recall": 0.62448,
            "fmeasure": 0.64457
        },
        "rouge2": {
            "precision": 0.46243,
            "recall": 0.41804,
            "fmeasure": 0.42728
        },
        "rougeL": {
            "precision": 0.64414,
            "recall": 0.57943,
            "fmeasure": 0.59635
        },
        "rougeLsum": {
            "precision": 0.64414,
            "recall": 0.57943,
            "fmeasure": 0.59635
        },
        "local_recall": {
            "1": 0.0636672325976231,
            "2": 0.1673052362707535,
            "3": 0.2975929978118162,
            "4": 0.3074484944532488,
            "5": 0.4174454828660436,
            "6": 0.5549516908212561,
            "7": 0.7071401298205422
        },
        "nist": 8.12708073877138,
        "bleu": 40.17479,
        "sari": 45.17477,
        "bleurt": -0.10033,
        "nubia": {
            "semantic_relation": 3.61217,
            "contradiction": 12.10817,
            "irrelevancy": 25.20108,
            "logical_agreement": 62.69075,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.05181,
            "nubia_score": 0.52702
        },
        "meteor": 0.33346014396451656,
        "bertscore": {
            "precision": 0.9106,
            "recall": 0.89548,
            "f1": 0.90011
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_464": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8,
        "vocab_size-1": 12,
        "unique-1": 10,
        "entropy-1": 3.4565647621309536,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.38295629088933336,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3248629576173574,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.41269152701913925,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.63333,
            "recall": 0.7033,
            "fmeasure": 0.66626
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.5609,
            "fmeasure": 0.52849
        },
        "rougeL": {
            "precision": 0.63333,
            "recall": 0.7033,
            "fmeasure": 0.66626
        },
        "rougeLsum": {
            "precision": 0.63333,
            "recall": 0.7033,
            "fmeasure": 0.66626
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.75
        },
        "nist": 2.2741769249602286,
        "bleu": 43.74811,
        "bleurt": 0.33714,
        "nubia": {
            "semantic_relation": 2.87235,
            "contradiction": 51.9024,
            "irrelevancy": 46.80327,
            "logical_agreement": 1.29433,
            "grammar_ref": 3.57757,
            "grammar_hyp": 3.66021,
            "nubia_score": 0.37476
        },
        "meteor": 0.35872168717912056,
        "bertscore": {
            "precision": 0.91504,
            "recall": 0.92908,
            "f1": 0.92201
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_340": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.78,
        "total_length": 150,
        "mean_pred_length": 18.75,
        "std_pred_length": 5.84700778176325,
        "median_pred_length": 19.5,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 100,
        "unique-1": 81,
        "entropy-1": 6.281630690265098,
        "distinct-2": 0.9366197183098591,
        "vocab_size-2": 133,
        "unique-2": 126,
        "entropy-2": 7.008902049082153,
        "cond_entropy-2": 0.6116199785483478,
        "distinct-3": 0.9776119402985075,
        "vocab_size-3": 131,
        "unique-3": 128,
        "entropy-3": 7.021313071054795,
        "cond_entropy-3": 0.020819682893389056,
        "total_length-nopunct": 126,
        "mean_pred_length-nopunct": 15.75,
        "std_pred_length-nopunct": 4.815340071064556,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.753968253968254,
        "vocab_size-1-nopunct": 95,
        "unique-1-nopunct": 80,
        "entropy-1-nopunct": 6.342048970981608,
        "distinct-2-nopunct": 0.940677966101695,
        "vocab_size-2-nopunct": 111,
        "unique-2-nopunct": 106,
        "entropy-2-nopunct": 6.747049829022849,
        "cond_entropy-2-nopunct": 0.43463547769740485,
        "distinct-3-nopunct": 0.990909090909091,
        "vocab_size-3-nopunct": 109,
        "unique-3-nopunct": 108,
        "entropy-3-nopunct": 6.76317789534285,
        "cond_entropy-3-nopunct": 0.02598939143554569,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82694,
            "recall": 0.83178,
            "fmeasure": 0.82011
        },
        "rouge2": {
            "precision": 0.6381,
            "recall": 0.62658,
            "fmeasure": 0.62584
        },
        "rougeL": {
            "precision": 0.7289,
            "recall": 0.76233,
            "fmeasure": 0.73422
        },
        "rougeLsum": {
            "precision": 0.7289,
            "recall": 0.76233,
            "fmeasure": 0.73422
        },
        "local_recall": {
            "1": 0.0625,
            "2": 0.4,
            "3": 0.8514851485148515
        },
        "nist": 5.4303693868125595,
        "bleu": 49.43738,
        "bleurt": 0.42754,
        "nubia": {
            "semantic_relation": 4.49885,
            "contradiction": 5.72638,
            "irrelevancy": 26.72539,
            "logical_agreement": 67.54823,
            "grammar_ref": 4.58534,
            "grammar_hyp": 4.65939,
            "nubia_score": 0.81063
        },
        "meteor": 0.4437935528923675,
        "bertscore": {
            "precision": 0.93265,
            "recall": 0.94486,
            "f1": 0.93724
        }
    },
    "web_nlg_en_validation": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_validation",
        "N": 1667,
        "msttr-100": 0.56191,
        "msttr-100_nopunct": 0.58771,
        "total_length": 37121,
        "mean_pred_length": 22.268146370725855,
        "std_pred_length": 11.380087076424235,
        "median_pred_length": 21.0,
        "min_pred_length": 4,
        "max_pred_length": 65,
        "distinct-1": 0.09924301608254088,
        "vocab_size-1": 3684,
        "unique-1": 1251,
        "entropy-1": 8.742926778708133,
        "distinct-2": 0.3433463078919163,
        "vocab_size-2": 12173,
        "unique-2": 6936,
        "entropy-2": 12.346813016055295,
        "cond_entropy-2": 3.3777910608055737,
        "distinct-3": 0.5685026785450025,
        "vocab_size-3": 19208,
        "unique-3": 13759,
        "entropy-3": 13.626727443715902,
        "cond_entropy-3": 1.3232499067649128,
        "total_length-nopunct": 32741,
        "mean_pred_length-nopunct": 19.640671865626874,
        "std_pred_length-nopunct": 10.169639775030163,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 58,
        "distinct-1-nopunct": 0.11218350080938273,
        "vocab_size-1-nopunct": 3673,
        "unique-1-nopunct": 1250,
        "entropy-1-nopunct": 9.124707018531318,
        "distinct-2-nopunct": 0.3608161163673811,
        "vocab_size-2-nopunct": 11212,
        "unique-2-nopunct": 6638,
        "entropy-2-nopunct": 12.248841882036317,
        "cond_entropy-2-nopunct": 3.266426426513139,
        "distinct-3-nopunct": 0.5817662461318733,
        "vocab_size-3-nopunct": 17108,
        "unique-3-nopunct": 12535,
        "entropy-3-nopunct": 13.462937677706382,
        "cond_entropy-3-nopunct": 1.2608914261538375,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_validation.json",
        "rouge1": {
            "precision": 0.81679,
            "recall": 0.81381,
            "fmeasure": 0.81015
        },
        "rouge2": {
            "precision": 0.59904,
            "recall": 0.59768,
            "fmeasure": 0.59426
        },
        "rougeL": {
            "precision": 0.68177,
            "recall": 0.68177,
            "fmeasure": 0.67724
        },
        "rougeLsum": {
            "precision": 0.68177,
            "recall": 0.68177,
            "fmeasure": 0.67724
        },
        "local_recall": {
            "1": 0.3221189869623857,
            "2": 0.7229885057471265,
            "3": 0.931515812431843,
            "4": 0.9716312056737588,
            "5": 0.9714285714285714,
            "6": 0.75,
            "7": 1.0,
            "8": 1.0
        },
        "nist": 11.0104970150669,
        "bleu": 59.08771,
        "bleurt": 0.40076,
        "nubia": {
            "semantic_relation": 4.72856,
            "contradiction": 2.92655,
            "irrelevancy": 3.94364,
            "logical_agreement": 93.12981,
            "grammar_ref": 4.59465,
            "grammar_hyp": 4.59133,
            "nubia_score": 0.879
        },
        "meteor": 0.44751176703945506,
        "bertscore": {
            "precision": 0.94889,
            "recall": 0.94989,
            "f1": 0.94855
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_425": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.12336199461765363,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.03740119765411,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.14421971022094893,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.6,
            "recall": 0.7094,
            "fmeasure": 0.64753
        },
        "rouge2": {
            "precision": 0.54386,
            "recall": 0.64869,
            "fmeasure": 0.58901
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.48718,
            "fmeasure": 0.437
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.48718,
            "fmeasure": 0.437
        },
        "local_recall": {
            "1": 0.6153846153846154,
            "2": 1.0,
            "3": 0.5714285714285714
        },
        "nist": 3.8010816427204808,
        "bleu": 62.5534,
        "bleurt": -0.39908,
        "nubia": {
            "semantic_relation": 1.99106,
            "contradiction": 96.77068,
            "irrelevancy": 2.79997,
            "logical_agreement": 0.42935,
            "grammar_ref": 4.13721,
            "grammar_hyp": 3.48658,
            "nubia_score": 0.25539
        },
        "meteor": 0.44352263709088907,
        "bertscore": {
            "precision": 0.92586,
            "recall": 0.92629,
            "f1": 0.92608
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_342": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 55,
        "mean_pred_length": 11.0,
        "std_pred_length": 3.63318042491699,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 17,
        "distinct-1": 0.8,
        "vocab_size-1": 44,
        "unique-1": 37,
        "entropy-1": 5.302004659404652,
        "distinct-2": 1.0,
        "vocab_size-2": 50,
        "unique-2": 50,
        "entropy-2": 5.643856189774728,
        "cond_entropy-2": 0.15759422629333436,
        "distinct-3": 1.0,
        "vocab_size-3": 45,
        "unique-3": 45,
        "entropy-3": 5.491853096329673,
        "cond_entropy-3": -0.15200309344505006,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 9.6,
        "std_pred_length-nopunct": 3.2619012860600183,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.319235677759421,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.426264754702098,
        "cond_entropy-2-nopunct": 0.13792754472892937,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.17833724125851255,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7497,
            "recall": 0.76328,
            "fmeasure": 0.75384
        },
        "rouge2": {
            "precision": 0.43934,
            "recall": 0.41721,
            "fmeasure": 0.42659
        },
        "rougeL": {
            "precision": 0.69152,
            "recall": 0.71963,
            "fmeasure": 0.70003
        },
        "rougeLsum": {
            "precision": 0.69152,
            "recall": 0.71963,
            "fmeasure": 0.70003
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.625,
            "3": 0.7368421052631579
        },
        "nist": 3.9261214672686755,
        "bleu": 28.412,
        "bleurt": 0.28761,
        "nubia": {
            "semantic_relation": 4.22109,
            "contradiction": 0.50001,
            "irrelevancy": 46.80191,
            "logical_agreement": 52.69809,
            "grammar_ref": 5.90284,
            "grammar_hyp": 5.17454,
            "nubia_score": 0.80168
        },
        "meteor": 0.4006960667306487,
        "bertscore": {
            "precision": 0.92132,
            "recall": 0.92526,
            "f1": 0.9232
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_426": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 67,
        "mean_pred_length": 22.333333333333332,
        "std_pred_length": 3.39934634239519,
        "median_pred_length": 21.0,
        "min_pred_length": 19,
        "max_pred_length": 27,
        "distinct-1": 0.7164179104477612,
        "vocab_size-1": 48,
        "unique-1": 33,
        "entropy-1": 5.453857100776369,
        "distinct-2": 0.859375,
        "vocab_size-2": 55,
        "unique-2": 46,
        "entropy-2": 5.71875,
        "cond_entropy-2": 0.21929616120614032,
        "distinct-3": 0.9016393442622951,
        "vocab_size-3": 55,
        "unique-3": 49,
        "entropy-3": 5.734016026087474,
        "cond_entropy-3": 0.029097993300591138,
        "total_length-nopunct": 59,
        "mean_pred_length-nopunct": 19.666666666666668,
        "std_pred_length-nopunct": 3.0912061651652345,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7627118644067796,
        "vocab_size-1-nopunct": 45,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.382477371322398,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.521640636343323,
        "cond_entropy-2-nopunct": 0.14810071205874376,
        "distinct-3-nopunct": 0.9056603773584906,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.539241209280176,
        "cond_entropy-3-nopunct": 0.01490515514710453,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66397,
            "recall": 0.63696,
            "fmeasure": 0.63145
        },
        "rouge2": {
            "precision": 0.48086,
            "recall": 0.48191,
            "fmeasure": 0.47021
        },
        "rougeL": {
            "precision": 0.62303,
            "recall": 0.61199,
            "fmeasure": 0.6007
        },
        "rougeLsum": {
            "precision": 0.62303,
            "recall": 0.61199,
            "fmeasure": 0.6007
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.41935483870967744,
            "3": 0.8
        },
        "nist": 3.838874985627037,
        "bleu": 39.09036,
        "bleurt": 0.06549,
        "nubia": {
            "semantic_relation": 3.96133,
            "contradiction": 2.68825,
            "irrelevancy": 57.75812,
            "logical_agreement": 39.55363,
            "grammar_ref": 3.62435,
            "grammar_hyp": 3.53325,
            "nubia_score": 0.67525
        },
        "meteor": 0.3214520227613503,
        "bertscore": {
            "precision": 0.9076,
            "recall": 0.8918,
            "f1": 0.89751
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_343": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.77,
        "msttr-100_nopunct": NaN,
        "total_length": 110,
        "mean_pred_length": 18.333333333333332,
        "std_pred_length": 4.853406592853679,
        "median_pred_length": 16.5,
        "min_pred_length": 12,
        "max_pred_length": 27,
        "distinct-1": 0.7454545454545455,
        "vocab_size-1": 82,
        "unique-1": 69,
        "entropy-1": 6.0925011906990525,
        "distinct-2": 0.9807692307692307,
        "vocab_size-2": 102,
        "unique-2": 100,
        "entropy-2": 6.661978179679561,
        "cond_entropy-2": 0.4600863748711484,
        "distinct-3": 1.0,
        "vocab_size-3": 98,
        "unique-3": 98,
        "entropy-3": 6.614709844115218,
        "cond_entropy-3": -0.04491354749527156,
        "total_length-nopunct": 96,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 3.7859388972001824,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 78,
        "unique-1-nopunct": 69,
        "entropy-1-nopunct": 6.082205599611886,
        "distinct-2-nopunct": 0.9777777777777777,
        "vocab_size-2-nopunct": 88,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.447408651885218,
        "cond_entropy-2-nopunct": 0.39872017901396767,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 84,
        "entropy-3-nopunct": 6.39231742277876,
        "cond_entropy-3-nopunct": -0.051916625931866675,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.60283,
            "recall": 0.7276,
            "fmeasure": 0.63106
        },
        "rouge2": {
            "precision": 0.42411,
            "recall": 0.51824,
            "fmeasure": 0.43999
        },
        "rougeL": {
            "precision": 0.56179,
            "recall": 0.68374,
            "fmeasure": 0.58979
        },
        "rougeLsum": {
            "precision": 0.56179,
            "recall": 0.68374,
            "fmeasure": 0.58979
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.5833333333333334,
            "3": 0.7291666666666666
        },
        "nist": 3.960219239214182,
        "bleu": 35.91424,
        "bleurt": -0.0214,
        "nubia": {
            "semantic_relation": 3.77185,
            "contradiction": 16.55809,
            "irrelevancy": 57.87695,
            "logical_agreement": 25.56497,
            "grammar_ref": 4.25456,
            "grammar_hyp": 4.25505,
            "nubia_score": 0.59184
        },
        "meteor": 0.38966830896816507,
        "bertscore": {
            "precision": 0.87309,
            "recall": 0.90093,
            "f1": 0.8845
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_492": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 13.0,
        "std_pred_length": 3.559026084010437,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 16,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 30,
        "unique-1": 25,
        "entropy-1": 4.746439398127533,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.33631896331590855,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 3.2998316455372216,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.664578373902382,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.3789876863828586,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.14201900487242786,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.67647,
            "recall": 0.5966,
            "fmeasure": 0.61545
        },
        "rouge2": {
            "precision": 0.3312,
            "recall": 0.30193,
            "fmeasure": 0.30785
        },
        "rougeL": {
            "precision": 0.53011,
            "recall": 0.46987,
            "fmeasure": 0.48402
        },
        "rougeLsum": {
            "precision": 0.53011,
            "recall": 0.46987,
            "fmeasure": 0.48402
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.8571428571428571,
            "3": 0.45454545454545453
        },
        "nist": 3.403134775942037,
        "bleu": 29.08181,
        "bleurt": 0.20098,
        "nubia": {
            "semantic_relation": 4.09043,
            "contradiction": 0.31331,
            "irrelevancy": 33.69956,
            "logical_agreement": 65.98714,
            "grammar_ref": 3.54742,
            "grammar_hyp": 3.83812,
            "nubia_score": 0.78762
        },
        "meteor": 0.3134272084914655,
        "bertscore": {
            "precision": 0.90151,
            "recall": 0.87334,
            "f1": 0.88585
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_495": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 80,
        "mean_pred_length": 20.0,
        "std_pred_length": 4.743416490252569,
        "median_pred_length": 20.5,
        "min_pred_length": 13,
        "max_pred_length": 26,
        "distinct-1": 0.75,
        "vocab_size-1": 60,
        "unique-1": 47,
        "entropy-1": 5.7268075889568975,
        "distinct-2": 1.0,
        "vocab_size-2": 76,
        "unique-2": 76,
        "entropy-2": 6.247927513443591,
        "cond_entropy-2": 0.44717889848302445,
        "distinct-3": 1.0,
        "vocab_size-3": 72,
        "unique-3": 72,
        "entropy-3": 6.1699250014423175,
        "cond_entropy-3": -0.0780025120012733,
        "total_length-nopunct": 73,
        "mean_pred_length-nopunct": 18.25,
        "std_pred_length-nopunct": 4.602988159880492,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7671232876712328,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 44,
        "entropy-1-nopunct": 5.647226744161712,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 69,
        "unique-2-nopunct": 69,
        "entropy-2-nopunct": 6.108524456778164,
        "cond_entropy-2-nopunct": 0.4782599047740478,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 65,
        "unique-3-nopunct": 65,
        "entropy-3-nopunct": 6.022367813028458,
        "cond_entropy-3-nopunct": -0.08615664374971463,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72756,
            "recall": 0.689,
            "fmeasure": 0.70313
        },
        "rouge2": {
            "precision": 0.49683,
            "recall": 0.46154,
            "fmeasure": 0.47748
        },
        "rougeL": {
            "precision": 0.60524,
            "recall": 0.61054,
            "fmeasure": 0.59663
        },
        "rougeLsum": {
            "precision": 0.60524,
            "recall": 0.61054,
            "fmeasure": 0.59663
        },
        "local_recall": {
            "1": 0.16,
            "2": 0.7,
            "3": 0.7666666666666667
        },
        "nist": 4.6500039382979805,
        "bleu": 42.99176,
        "bleurt": 0.19807,
        "nubia": {
            "semantic_relation": 4.05679,
            "contradiction": 3.56253,
            "irrelevancy": 31.22366,
            "logical_agreement": 65.21381,
            "grammar_ref": 4.35502,
            "grammar_hyp": 4.48749,
            "nubia_score": 0.64314
        },
        "meteor": 0.4089732099211167,
        "bertscore": {
            "precision": 0.92059,
            "recall": 0.91407,
            "f1": 0.91191
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_427": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 50,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 3.8586123009300755,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.76,
        "vocab_size-1": 38,
        "unique-1": 31,
        "entropy-1": 5.0614678801994515,
        "distinct-2": 0.9148936170212766,
        "vocab_size-2": 43,
        "unique-2": 40,
        "entropy-2": 5.368314649503949,
        "cond_entropy-2": 0.24285267199731297,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": 0.10381748291792028,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 3.39934634239519,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.782608695652174,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.993898304391787,
        "distinct-2-nopunct": 0.9069767441860465,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.2226627197680635,
        "cond_entropy-2-nopunct": 0.2657176933994294,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": 0.11453552773935091,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72193,
            "recall": 0.72289,
            "fmeasure": 0.71458
        },
        "rouge2": {
            "precision": 0.41997,
            "recall": 0.43557,
            "fmeasure": 0.42559
        },
        "rougeL": {
            "precision": 0.60703,
            "recall": 0.62628,
            "fmeasure": 0.61044
        },
        "rougeLsum": {
            "precision": 0.60703,
            "recall": 0.62628,
            "fmeasure": 0.61044
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.6923076923076923,
            "3": 0.7333333333333333
        },
        "nist": 4.897678219994522,
        "bleu": 48.47054,
        "bleurt": 0.28538,
        "nubia": {
            "semantic_relation": 4.03652,
            "contradiction": 0.67404,
            "irrelevancy": 70.90991,
            "logical_agreement": 28.41604,
            "grammar_ref": 4.38609,
            "grammar_hyp": 4.06215,
            "nubia_score": 0.7131
        },
        "meteor": 0.3628943990960308,
        "bertscore": {
            "precision": 0.91489,
            "recall": 0.92357,
            "f1": 0.9188
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_465": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 2.0,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 12,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.16992500144231232,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.16992500144231232,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.19264507794239588,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.89177,
            "recall": 0.68465,
            "fmeasure": 0.76997
        },
        "rouge2": {
            "precision": 0.52778,
            "recall": 0.43632,
            "fmeasure": 0.47398
        },
        "rougeL": {
            "precision": 0.69913,
            "recall": 0.59182,
            "fmeasure": 0.63698
        },
        "rougeLsum": {
            "precision": 0.69913,
            "recall": 0.59182,
            "fmeasure": 0.63698
        },
        "local_recall": {
            "1": 0.8,
            "2": 0.25,
            "3": 0.75
        },
        "nist": 2.9497072618370157,
        "bleu": 28.0105,
        "bleurt": 0.32473,
        "nubia": {
            "semantic_relation": 4.28166,
            "contradiction": 16.38295,
            "irrelevancy": 3.38632,
            "logical_agreement": 80.23073,
            "grammar_ref": 5.19402,
            "grammar_hyp": 6.42644,
            "nubia_score": 0.55027
        },
        "meteor": 0.36640040192228845,
        "bertscore": {
            "precision": 0.92336,
            "recall": 0.91525,
            "f1": 0.91817
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_496": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 61,
        "mean_pred_length": 20.333333333333332,
        "std_pred_length": 0.9428090415820634,
        "median_pred_length": 21.0,
        "min_pred_length": 19,
        "max_pred_length": 21,
        "distinct-1": 0.7868852459016393,
        "vocab_size-1": 48,
        "unique-1": 41,
        "entropy-1": 5.422220124306263,
        "distinct-2": 1.0,
        "vocab_size-2": 58,
        "unique-2": 58,
        "entropy-2": 5.85798099512757,
        "cond_entropy-2": 0.3800826662972787,
        "distinct-3": 1.0,
        "vocab_size-3": 55,
        "unique-3": 55,
        "entropy-3": 5.7813597135246555,
        "cond_entropy-3": -0.0766212816029123,
        "total_length-nopunct": 53,
        "mean_pred_length-nopunct": 17.666666666666668,
        "std_pred_length-nopunct": 1.699673171197595,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8301886792452831,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.3220756431608,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.643856189774728,
        "cond_entropy-2-nopunct": 0.34613123529806417,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.55458885167764,
        "cond_entropy-3-nopunct": -0.08926733809708727,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78208,
            "recall": 0.79883,
            "fmeasure": 0.77799
        },
        "rouge2": {
            "precision": 0.54524,
            "recall": 0.59304,
            "fmeasure": 0.56165
        },
        "rougeL": {
            "precision": 0.65708,
            "recall": 0.71153,
            "fmeasure": 0.67528
        },
        "rougeLsum": {
            "precision": 0.65708,
            "recall": 0.71153,
            "fmeasure": 0.67528
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8571428571428571
        },
        "nist": 5.155107922695902,
        "bleu": 60.74791,
        "bleurt": 0.46489,
        "nubia": {
            "semantic_relation": 4.66403,
            "contradiction": 0.60925,
            "irrelevancy": 34.45712,
            "logical_agreement": 64.93363,
            "grammar_ref": 4.0888,
            "grammar_hyp": 4.04202,
            "nubia_score": 0.86504
        },
        "meteor": 0.449061353522361,
        "bertscore": {
            "precision": 0.9409,
            "recall": 0.94815,
            "f1": 0.94405
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_498": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.13652573434569687,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.03740119765411,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.14421971022094904,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.68421,
            "recall": 0.59885,
            "fmeasure": 0.63862
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.38571,
            "fmeasure": 0.41296
        },
        "rougeL": {
            "precision": 0.68421,
            "recall": 0.59885,
            "fmeasure": 0.63862
        },
        "rougeLsum": {
            "precision": 0.68421,
            "recall": 0.59885,
            "fmeasure": 0.63862
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.25,
            "3": 0.6428571428571429
        },
        "nist": 2.530450380057439,
        "bleu": 20.59493,
        "bleurt": -0.09464,
        "nubia": {
            "semantic_relation": 4.03154,
            "contradiction": 3.72972,
            "irrelevancy": 62.78613,
            "logical_agreement": 33.48415,
            "grammar_ref": 4.70322,
            "grammar_hyp": 5.30126,
            "nubia_score": 0.55397
        },
        "meteor": 0.3042404250366658,
        "bertscore": {
            "precision": 0.89571,
            "recall": 0.87941,
            "f1": 0.88748
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_468": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 97,
        "mean_pred_length": 16.166666666666668,
        "std_pred_length": 7.22072634081149,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.6288659793814433,
        "vocab_size-1": 61,
        "unique-1": 47,
        "entropy-1": 5.521096317299566,
        "distinct-2": 0.9010989010989011,
        "vocab_size-2": 82,
        "unique-2": 75,
        "entropy-2": 6.293401508283021,
        "cond_entropy-2": 0.6729988629065168,
        "distinct-3": 0.9647058823529412,
        "vocab_size-3": 82,
        "unique-3": 80,
        "entropy-3": 6.329921671406372,
        "cond_entropy-3": 0.05165379596445813,
        "total_length-nopunct": 89,
        "mean_pred_length-nopunct": 14.833333333333334,
        "std_pred_length-nopunct": 7.080881928749334,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6629213483146067,
        "vocab_size-1-nopunct": 59,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.496683679171268,
        "distinct-2-nopunct": 0.891566265060241,
        "vocab_size-2-nopunct": 74,
        "unique-2-nopunct": 67,
        "entropy-2-nopunct": 6.139981901174317,
        "cond_entropy-2-nopunct": 0.7020247100846276,
        "distinct-3-nopunct": 0.961038961038961,
        "vocab_size-3-nopunct": 74,
        "unique-3-nopunct": 72,
        "entropy-3-nopunct": 6.179060728978496,
        "cond_entropy-3-nopunct": 0.0444079859994501,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8571,
            "recall": 0.83583,
            "fmeasure": 0.84292
        },
        "rouge2": {
            "precision": 0.70291,
            "recall": 0.68647,
            "fmeasure": 0.69154
        },
        "rougeL": {
            "precision": 0.82479,
            "recall": 0.80701,
            "fmeasure": 0.8126
        },
        "rougeLsum": {
            "precision": 0.82479,
            "recall": 0.80701,
            "fmeasure": 0.8126
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.6666666666666666,
            "3": 0.8115942028985508
        },
        "nist": 5.706165518226549,
        "bleu": 62.07348,
        "bleurt": 0.60186,
        "nubia": {
            "semantic_relation": 4.58162,
            "contradiction": 17.77473,
            "irrelevancy": 13.46441,
            "logical_agreement": 68.76086,
            "grammar_ref": 4.9652,
            "grammar_hyp": 4.81379,
            "nubia_score": 0.85592
        },
        "meteor": 0.4485191030605614,
        "bertscore": {
            "precision": 0.96797,
            "recall": 0.95097,
            "f1": 0.95921
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_376": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.82,
        "total_length": 139,
        "mean_pred_length": 17.375,
        "std_pred_length": 4.998437255783052,
        "median_pred_length": 18.0,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.7338129496402878,
        "vocab_size-1": 102,
        "unique-1": 90,
        "entropy-1": 6.292065554956991,
        "distinct-2": 0.9770992366412213,
        "vocab_size-2": 128,
        "unique-2": 125,
        "entropy-2": 6.9876214748198935,
        "cond_entropy-2": 0.5524689284934013,
        "distinct-3": 0.991869918699187,
        "vocab_size-3": 122,
        "unique-3": 121,
        "entropy-3": 6.926254342737602,
        "cond_entropy-3": -0.05838817099495869,
        "total_length-nopunct": 121,
        "mean_pred_length-nopunct": 15.125,
        "std_pred_length-nopunct": 4.284784125250653,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8099173553719008,
        "vocab_size-1-nopunct": 98,
        "unique-1-nopunct": 88,
        "entropy-1-nopunct": 6.367169952132754,
        "distinct-2-nopunct": 0.9734513274336283,
        "vocab_size-2-nopunct": 110,
        "unique-2-nopunct": 107,
        "entropy-2-nopunct": 6.767081617282463,
        "cond_entropy-2-nopunct": 0.4389695968411553,
        "distinct-3-nopunct": 0.9904761904761905,
        "vocab_size-3-nopunct": 104,
        "unique-3-nopunct": 103,
        "entropy-3-nopunct": 6.695197898618494,
        "cond_entropy-3-nopunct": -0.06783820665382725,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66131,
            "recall": 0.69888,
            "fmeasure": 0.66219
        },
        "rouge2": {
            "precision": 0.41625,
            "recall": 0.45555,
            "fmeasure": 0.42462
        },
        "rougeL": {
            "precision": 0.48823,
            "recall": 0.56102,
            "fmeasure": 0.51301
        },
        "rougeLsum": {
            "precision": 0.48823,
            "recall": 0.56102,
            "fmeasure": 0.51301
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.5666666666666667,
            "3": 0.6986301369863014
        },
        "nist": 4.480463463124859,
        "bleu": 33.48578,
        "bleurt": -0.04243,
        "nubia": {
            "semantic_relation": 3.89307,
            "contradiction": 3.46273,
            "irrelevancy": 52.14432,
            "logical_agreement": 44.39295,
            "grammar_ref": 4.8199,
            "grammar_hyp": 4.68996,
            "nubia_score": 0.65861
        },
        "meteor": 0.3632155430301818,
        "bertscore": {
            "precision": 0.88302,
            "recall": 0.90469,
            "f1": 0.89211
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_500": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 22.5,
        "std_pred_length": 3.5,
        "median_pred_length": 22.5,
        "min_pred_length": 19,
        "max_pred_length": 26,
        "distinct-1": 0.8444444444444444,
        "vocab_size-1": 38,
        "unique-1": 32,
        "entropy-1": 5.163966707392707,
        "distinct-2": 1.0,
        "vocab_size-2": 43,
        "unique-2": 43,
        "entropy-2": 5.426264754702098,
        "cond_entropy-2": 0.23103694912041112,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.06871275008401433,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.017535737070864,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.1699250014423095,
        "cond_entropy-2-nopunct": 0.1651888075032675,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8373,
            "recall": 0.85652,
            "fmeasure": 0.8419
        },
        "rouge2": {
            "precision": 0.5848,
            "recall": 0.57004,
            "fmeasure": 0.57344
        },
        "rougeL": {
            "precision": 0.75397,
            "recall": 0.75139,
            "fmeasure": 0.7479
        },
        "rougeLsum": {
            "precision": 0.75397,
            "recall": 0.75139,
            "fmeasure": 0.7479
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.8709677419354839
        },
        "nist": 4.922018568136947,
        "bleu": 59.79747,
        "bleurt": 0.15102,
        "nubia": {
            "semantic_relation": 3.67512,
            "contradiction": 26.43375,
            "irrelevancy": 21.40782,
            "logical_agreement": 52.15843,
            "grammar_ref": 5.38335,
            "grammar_hyp": 5.37904,
            "nubia_score": 0.57826
        },
        "meteor": 0.4407063539256618,
        "bertscore": {
            "precision": 0.93445,
            "recall": 0.9506,
            "f1": 0.93993
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_378": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.74,
        "total_length": 127,
        "mean_pred_length": 18.142857142857142,
        "std_pred_length": 5.514359733033937,
        "median_pred_length": 17.0,
        "min_pred_length": 13,
        "max_pred_length": 28,
        "distinct-1": 0.6535433070866141,
        "vocab_size-1": 83,
        "unique-1": 65,
        "entropy-1": 5.988883135694555,
        "distinct-2": 0.9083333333333333,
        "vocab_size-2": 109,
        "unique-2": 98,
        "entropy-2": 6.723557262275199,
        "cond_entropy-2": 0.629233513273452,
        "distinct-3": 0.9380530973451328,
        "vocab_size-3": 106,
        "unique-3": 99,
        "entropy-3": 6.696285157105471,
        "cond_entropy-3": -0.015915173016339754,
        "total_length-nopunct": 113,
        "mean_pred_length-nopunct": 16.142857142857142,
        "std_pred_length-nopunct": 4.823412290324037,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6902654867256637,
        "vocab_size-1-nopunct": 78,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 5.941211594871376,
        "distinct-2-nopunct": 0.8962264150943396,
        "vocab_size-2-nopunct": 95,
        "unique-2-nopunct": 84,
        "entropy-2-nopunct": 6.520373284751865,
        "cond_entropy-2-nopunct": 0.6277727424541625,
        "distinct-3-nopunct": 0.9292929292929293,
        "vocab_size-3-nopunct": 92,
        "unique-3-nopunct": 85,
        "entropy-3-nopunct": 6.487942478665477,
        "cond_entropy-3-nopunct": -0.017755753675509085,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77024,
            "recall": 0.74854,
            "fmeasure": 0.74928
        },
        "rouge2": {
            "precision": 0.5911,
            "recall": 0.56391,
            "fmeasure": 0.57149
        },
        "rougeL": {
            "precision": 0.63469,
            "recall": 0.63288,
            "fmeasure": 0.62995
        },
        "rougeLsum": {
            "precision": 0.63469,
            "recall": 0.63288,
            "fmeasure": 0.62995
        },
        "local_recall": {
            "1": 0.11538461538461539,
            "2": 0.38095238095238093,
            "3": 0.7666666666666667
        },
        "nist": 5.351442172181742,
        "bleu": 48.5572,
        "bleurt": 0.13746,
        "nubia": {
            "semantic_relation": 4.11022,
            "contradiction": 14.61491,
            "irrelevancy": 37.05542,
            "logical_agreement": 48.32968,
            "grammar_ref": 4.76973,
            "grammar_hyp": 4.63345,
            "nubia_score": 0.70072
        },
        "meteor": 0.4048010244997736,
        "bertscore": {
            "precision": 0.93617,
            "recall": 0.92346,
            "f1": 0.92892
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_469": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 5.312459150169743,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 36,
        "unique-1": 33,
        "entropy-1": 5.103055907333276,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": -0.004366621150304511,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.12199052437861026,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 5.436502143433364,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9428571428571428,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.014997302659249,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": -0.004283016944966456,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.14201900487242786,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.68392,
            "recall": 0.74669,
            "fmeasure": 0.69383
        },
        "rouge2": {
            "precision": 0.53086,
            "recall": 0.5323,
            "fmeasure": 0.51719
        },
        "rougeL": {
            "precision": 0.61374,
            "recall": 0.67526,
            "fmeasure": 0.6222
        },
        "rougeLsum": {
            "precision": 0.61374,
            "recall": 0.67526,
            "fmeasure": 0.6222
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.47058823529411764,
            "3": 0.875
        },
        "nist": 3.8475524937796415,
        "bleu": 43.97226,
        "bleurt": 0.32252,
        "nubia": {
            "semantic_relation": 4.13884,
            "contradiction": 1.85289,
            "irrelevancy": 43.89695,
            "logical_agreement": 54.25016,
            "grammar_ref": 6.27104,
            "grammar_hyp": 5.35683,
            "nubia_score": 0.75644
        },
        "meteor": 0.36583046865298324,
        "bertscore": {
            "precision": 0.92754,
            "recall": 0.94588,
            "f1": 0.93312
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_428": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.41667,
            "recall": 0.5625,
            "fmeasure": 0.47727
        },
        "rouge2": {
            "precision": 0.09091,
            "recall": 0.12698,
            "fmeasure": 0.10556
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.3375,
            "fmeasure": 0.28636
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.3375,
            "fmeasure": 0.28636
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.625
        },
        "nist": 1.5759665446662703,
        "bleu": 9.66927,
        "bleurt": 0.16223,
        "nubia": {
            "semantic_relation": 4.12708,
            "contradiction": 0.10818,
            "irrelevancy": 0.60786,
            "logical_agreement": 99.28396,
            "grammar_ref": 6.57359,
            "grammar_hyp": 5.678,
            "nubia_score": 0.7087
        },
        "meteor": 0.27920953319435216,
        "bertscore": {
            "precision": 0.86653,
            "recall": 0.90721,
            "f1": 0.88641
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_504": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.63,
        "msttr-100_nopunct": NaN,
        "total_length": 106,
        "mean_pred_length": 21.2,
        "std_pred_length": 7.626270385975047,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 33,
        "distinct-1": 0.6037735849056604,
        "vocab_size-1": 64,
        "unique-1": 44,
        "entropy-1": 5.631762781993118,
        "distinct-2": 0.8514851485148515,
        "vocab_size-2": 86,
        "unique-2": 72,
        "entropy-2": 6.353707646096701,
        "cond_entropy-2": 0.6612631600284733,
        "distinct-3": 0.90625,
        "vocab_size-3": 87,
        "unique-3": 78,
        "entropy-3": 6.397462500721161,
        "cond_entropy-3": 0.0596144294502311,
        "total_length-nopunct": 98,
        "mean_pred_length-nopunct": 19.6,
        "std_pred_length-nopunct": 6.740919818541086,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6326530612244898,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 44,
        "entropy-1-nopunct": 5.596054891912889,
        "distinct-2-nopunct": 0.8387096774193549,
        "vocab_size-2-nopunct": 78,
        "unique-2-nopunct": 64,
        "entropy-2-nopunct": 6.208461096031006,
        "cond_entropy-2-nopunct": 0.6456672230537274,
        "distinct-3-nopunct": 0.8977272727272727,
        "vocab_size-3-nopunct": 79,
        "unique-3-nopunct": 70,
        "entropy-3-nopunct": 6.254886164091848,
        "cond_entropy-3-nopunct": 0.05385107459930555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74674,
            "recall": 0.77343,
            "fmeasure": 0.75285
        },
        "rouge2": {
            "precision": 0.58688,
            "recall": 0.57886,
            "fmeasure": 0.57653
        },
        "rougeL": {
            "precision": 0.64824,
            "recall": 0.65038,
            "fmeasure": 0.64371
        },
        "rougeLsum": {
            "precision": 0.64824,
            "recall": 0.65038,
            "fmeasure": 0.64371
        },
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.0,
            "3": 0.8285714285714286
        },
        "nist": 4.675429941701889,
        "bleu": 45.34593,
        "bleurt": 0.35703,
        "nubia": {
            "semantic_relation": 4.82397,
            "contradiction": 6.33323,
            "irrelevancy": 22.78718,
            "logical_agreement": 70.87959,
            "grammar_ref": 4.46418,
            "grammar_hyp": 4.01627,
            "nubia_score": 0.89635
        },
        "meteor": 0.41928045928581886,
        "bertscore": {
            "precision": 0.92397,
            "recall": 0.93,
            "f1": 0.92312
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_575": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 37.0,
        "std_pred_length": 0.0,
        "median_pred_length": 37.0,
        "min_pred_length": 37,
        "max_pred_length": 37,
        "distinct-1": 0.7567567567567568,
        "vocab_size-1": 28,
        "unique-1": 21,
        "entropy-1": 4.682162149295792,
        "distinct-2": 0.9722222222222222,
        "vocab_size-2": 35,
        "unique-2": 34,
        "entropy-2": 5.114369445886754,
        "cond_entropy-2": 0.4190764970446667,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": 0.016500872645511065,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 33.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 33.0,
        "min_pred_length-nopunct": 33,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.7878787878787878,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.574400937409154,
        "distinct-2-nopunct": 0.96875,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.9375,
        "cond_entropy-2-nopunct": 0.37778634952676327,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": 0.018712439419133295,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.67677,
            "recall": 0.60604,
            "fmeasure": 0.63858
        },
        "rouge2": {
            "precision": 0.27083,
            "recall": 0.2549,
            "fmeasure": 0.26263
        },
        "rougeL": {
            "precision": 0.46465,
            "recall": 0.4158,
            "fmeasure": 0.43826
        },
        "rougeLsum": {
            "precision": 0.46465,
            "recall": 0.4158,
            "fmeasure": 0.43826
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5,
            "3": 0.8260869565217391
        },
        "nist": 3.475249256293997,
        "bleu": 12.93698,
        "bleurt": 0.27594,
        "nubia": {
            "semantic_relation": 3.92082,
            "contradiction": 81.10306,
            "irrelevancy": 17.75066,
            "logical_agreement": 1.14627,
            "grammar_ref": 5.19058,
            "grammar_hyp": 4.50501,
            "nubia_score": 0.66797
        },
        "meteor": 0.3498835157372468,
        "bertscore": {
            "precision": 0.91976,
            "recall": 0.92189,
            "f1": 0.91897
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_472": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.186704345910024,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.2186000898557489,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966059,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.92157,
            "recall": 0.85552,
            "fmeasure": 0.88671
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.75,
            "fmeasure": 0.75
        },
        "rougeL": {
            "precision": 0.92157,
            "recall": 0.85552,
            "fmeasure": 0.88671
        },
        "rougeLsum": {
            "precision": 0.92157,
            "recall": 0.85552,
            "fmeasure": 0.88671
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.781490055580646,
        "bleu": 87.25129,
        "bleurt": 0.60599,
        "nubia": {
            "semantic_relation": 4.84131,
            "contradiction": 0.58627,
            "irrelevancy": 3.95162,
            "logical_agreement": 95.46212,
            "grammar_ref": 5.82691,
            "grammar_hyp": 5.33292,
            "nubia_score": 0.96383
        },
        "meteor": 0.5347033086663171,
        "bertscore": {
            "precision": 0.9645,
            "recall": 0.97236,
            "f1": 0.96842
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_576": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 65,
        "mean_pred_length": 21.666666666666668,
        "std_pred_length": 5.734883511361751,
        "median_pred_length": 21.0,
        "min_pred_length": 15,
        "max_pred_length": 29,
        "distinct-1": 0.7846153846153846,
        "vocab_size-1": 51,
        "unique-1": 44,
        "entropy-1": 5.471991851323574,
        "distinct-2": 0.9838709677419355,
        "vocab_size-2": 61,
        "unique-2": 60,
        "entropy-2": 5.921938245870744,
        "cond_entropy-2": 0.39988575556251527,
        "distinct-3": 1.0,
        "vocab_size-3": 59,
        "unique-3": 59,
        "entropy-3": 5.882643049361836,
        "cond_entropy-3": -0.03765495594028832,
        "total_length-nopunct": 58,
        "mean_pred_length-nopunct": 19.333333333333332,
        "std_pred_length-nopunct": 4.109609335312651,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8275862068965517,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 44,
        "entropy-1-nopunct": 5.392126684633539,
        "distinct-2-nopunct": 0.9818181818181818,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 53,
        "entropy-2-nopunct": 5.744996077161019,
        "cond_entropy-2-nopunct": 0.3782796276453395,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 52,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 5.700439718141095,
        "cond_entropy-3-nopunct": -0.042458456922029035,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77365,
            "recall": 0.84161,
            "fmeasure": 0.80398
        },
        "rouge2": {
            "precision": 0.56959,
            "recall": 0.62887,
            "fmeasure": 0.59748
        },
        "rougeL": {
            "precision": 0.71175,
            "recall": 0.7662,
            "fmeasure": 0.73617
        },
        "rougeLsum": {
            "precision": 0.71175,
            "recall": 0.7662,
            "fmeasure": 0.73617
        },
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 0.75,
            "3": 0.9285714285714286
        },
        "nist": 4.819671062012766,
        "bleu": 49.43467,
        "bleurt": 0.45325,
        "nubia": {
            "semantic_relation": 4.00627,
            "contradiction": 16.37579,
            "irrelevancy": 38.97209,
            "logical_agreement": 44.65212,
            "grammar_ref": 4.44265,
            "grammar_hyp": 4.24053,
            "nubia_score": 0.70861
        },
        "meteor": 0.42740584542845234,
        "bertscore": {
            "precision": 0.94467,
            "recall": 0.96074,
            "f1": 0.94993
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_473": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 1.0,
        "vocab_size-1": 20,
        "unique-1": 20,
        "entropy-1": 4.321928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.07400058144377676,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70588,
            "recall": 0.59497,
            "fmeasure": 0.64444
        },
        "rouge2": {
            "precision": 0.29167,
            "recall": 0.24579,
            "fmeasure": 0.26625
        },
        "rougeL": {
            "precision": 0.52941,
            "recall": 0.44622,
            "fmeasure": 0.48333
        },
        "rougeLsum": {
            "precision": 0.52941,
            "recall": 0.44622,
            "fmeasure": 0.48333
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7058823529411765
        },
        "nist": 2.758297653074456,
        "bleu": 20.46592,
        "bleurt": -0.05222,
        "nubia": {
            "semantic_relation": 4.11924,
            "contradiction": 0.77595,
            "irrelevancy": 62.44154,
            "logical_agreement": 36.7825,
            "grammar_ref": 4.86737,
            "grammar_hyp": 6.30719,
            "nubia_score": 0.50495
        },
        "meteor": 0.310054999067031,
        "bertscore": {
            "precision": 0.87925,
            "recall": 0.86379,
            "f1": 0.87129
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_474": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 2.0,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 20,
        "unique-1": 13,
        "entropy-1": 4.208966082694623,
        "distinct-2": 0.8846153846153846,
        "vocab_size-2": 23,
        "unique-2": 20,
        "entropy-2": 4.46967048737186,
        "cond_entropy-2": 0.22981123847439044,
        "distinct-3": 0.9166666666666666,
        "vocab_size-3": 22,
        "unique-3": 20,
        "entropy-3": 4.418295834054489,
        "cond_entropy-3": -0.03214388408660256,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.72,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.053660689688185,
        "distinct-2-nopunct": 0.8695652173913043,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.2626923908396215,
        "cond_entropy-2-nopunct": 0.26035304898504774,
        "distinct-3-nopunct": 0.9047619047619048,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.201841232302569,
        "cond_entropy-3-nopunct": -0.03600643804015718,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.84199,
            "recall": 0.91667,
            "fmeasure": 0.87668
        },
        "rouge2": {
            "precision": 0.65897,
            "recall": 0.70875,
            "fmeasure": 0.68202
        },
        "rougeL": {
            "precision": 0.84199,
            "recall": 0.91667,
            "fmeasure": 0.87668
        },
        "rougeLsum": {
            "precision": 0.84199,
            "recall": 0.91667,
            "fmeasure": 0.87668
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.8947368421052632
        },
        "nist": 4.268076867048142,
        "bleu": 60.21797,
        "bleurt": 0.80094,
        "nubia": {
            "semantic_relation": 4.91639,
            "contradiction": 0.14562,
            "irrelevancy": 0.58735,
            "logical_agreement": 99.26703,
            "grammar_ref": 4.16906,
            "grammar_hyp": 4.30925,
            "nubia_score": 0.92784
        },
        "meteor": 0.5253201445401519,
        "bertscore": {
            "precision": 0.95992,
            "recall": 0.97013,
            "f1": 0.96497
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_505": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 66,
        "mean_pred_length": 13.2,
        "std_pred_length": 5.3814496188294845,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.6515151515151515,
        "vocab_size-1": 43,
        "unique-1": 32,
        "entropy-1": 5.1675107408595595,
        "distinct-2": 0.8032786885245902,
        "vocab_size-2": 49,
        "unique-2": 41,
        "entropy-2": 5.479757419459163,
        "cond_entropy-2": 0.1938003903710469,
        "distinct-3": 0.8928571428571429,
        "vocab_size-3": 50,
        "unique-3": 45,
        "entropy-3": 5.57958907380469,
        "cond_entropy-3": 0.1400977184619228,
        "total_length-nopunct": 59,
        "mean_pred_length-nopunct": 11.8,
        "std_pred_length-nopunct": 4.664761515876241,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6949152542372882,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.132394532302679,
        "distinct-2-nopunct": 0.7777777777777778,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.245447224305561,
        "cond_entropy-2-nopunct": 0.14548311024909893,
        "distinct-3-nopunct": 0.8775510204081632,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.354406017540444,
        "cond_entropy-3-nopunct": 0.1405343317918106,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88597,
            "recall": 0.84538,
            "fmeasure": 0.85855
        },
        "rouge2": {
            "precision": 0.7686,
            "recall": 0.74919,
            "fmeasure": 0.75435
        },
        "rougeL": {
            "precision": 0.8496,
            "recall": 0.82316,
            "fmeasure": 0.83096
        },
        "rougeLsum": {
            "precision": 0.8496,
            "recall": 0.82316,
            "fmeasure": 0.83096
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.8305084745762712
        },
        "nist": 4.7777293557345555,
        "bleu": 62.12428,
        "bleurt": 0.79374,
        "nubia": {
            "semantic_relation": 4.72522,
            "contradiction": 0.48003,
            "irrelevancy": 0.60981,
            "logical_agreement": 98.91016,
            "grammar_ref": 4.79762,
            "grammar_hyp": 4.72445,
            "nubia_score": 0.93101
        },
        "meteor": 0.47203761553514795,
        "bertscore": {
            "precision": 0.98098,
            "recall": 0.96844,
            "f1": 0.97449
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_475": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.66,
        "msttr-100_nopunct": NaN,
        "total_length": 102,
        "mean_pred_length": 14.571428571428571,
        "std_pred_length": 3.697765458727081,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 20,
        "distinct-1": 0.6568627450980392,
        "vocab_size-1": 67,
        "unique-1": 48,
        "entropy-1": 5.762496480078034,
        "distinct-2": 0.9263157894736842,
        "vocab_size-2": 88,
        "unique-2": 81,
        "entropy-2": 6.422487187278316,
        "cond_entropy-2": 0.5201803659250334,
        "distinct-3": 0.9772727272727273,
        "vocab_size-3": 86,
        "unique-3": 84,
        "entropy-3": 6.41397707318276,
        "cond_entropy-3": 0.0032123739427129816,
        "total_length-nopunct": 92,
        "mean_pred_length-nopunct": 13.142857142857142,
        "std_pred_length-nopunct": 3.8332593899996397,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6956521739130435,
        "vocab_size-1-nopunct": 64,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.7500700054186495,
        "distinct-2-nopunct": 0.9294117647058824,
        "vocab_size-2-nopunct": 79,
        "unique-2-nopunct": 73,
        "entropy-2-nopunct": 6.268214465549471,
        "cond_entropy-2-nopunct": 0.5700790913598675,
        "distinct-3-nopunct": 0.9871794871794872,
        "vocab_size-3-nopunct": 77,
        "unique-3-nopunct": 76,
        "entropy-3-nopunct": 6.259761193221231,
        "cond_entropy-3-nopunct": -0.008604101890837873,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.61366,
            "recall": 0.70602,
            "fmeasure": 0.64671
        },
        "rouge2": {
            "precision": 0.3336,
            "recall": 0.38795,
            "fmeasure": 0.35206
        },
        "rougeL": {
            "precision": 0.47143,
            "recall": 0.57283,
            "fmeasure": 0.51072
        },
        "rougeLsum": {
            "precision": 0.47143,
            "recall": 0.57283,
            "fmeasure": 0.51072
        },
        "local_recall": {
            "1": 0.2692307692307692,
            "2": 0.6666666666666666,
            "3": 0.8043478260869565
        },
        "nist": 4.480866030931795,
        "bleu": 32.50586,
        "bleurt": 0.18643,
        "nubia": {
            "semantic_relation": 4.12296,
            "contradiction": 2.75417,
            "irrelevancy": 52.89327,
            "logical_agreement": 44.35257,
            "grammar_ref": 5.09695,
            "grammar_hyp": 4.56645,
            "nubia_score": 0.70563
        },
        "meteor": 0.35625280796662473,
        "bertscore": {
            "precision": 0.90764,
            "recall": 0.91589,
            "f1": 0.91074
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_476": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 3.5,
        "median_pred_length": 15.5,
        "min_pred_length": 12,
        "max_pred_length": 19,
        "distinct-1": 0.9032258064516129,
        "vocab_size-1": 28,
        "unique-1": 25,
        "entropy-1": 4.760647923290102,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.04171571922345566,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9629629629629629,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.6808134280893965,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": -0.03103131238874395,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.96667,
            "recall": 0.91176,
            "fmeasure": 0.9375
        },
        "rouge2": {
            "precision": 0.89286,
            "recall": 0.84375,
            "fmeasure": 0.86667
        },
        "rougeL": {
            "precision": 0.96667,
            "recall": 0.91176,
            "fmeasure": 0.9375
        },
        "rougeLsum": {
            "precision": 0.96667,
            "recall": 0.91176,
            "fmeasure": 0.9375
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9259259259259259
        },
        "nist": 4.883480009604316,
        "bleu": 88.14311,
        "bleurt": 0.78349,
        "nubia": {
            "semantic_relation": 4.88145,
            "contradiction": 0.35546,
            "irrelevancy": 0.56175,
            "logical_agreement": 99.08279,
            "grammar_ref": 5.04945,
            "grammar_hyp": 4.9279,
            "nubia_score": 0.95961
        },
        "meteor": 0.5649323575562583,
        "bertscore": {
            "precision": 0.99185,
            "recall": 0.98409,
            "f1": 0.98794
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_429": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 10.0,
        "std_pred_length": 2.943920288775949,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 13,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 26,
        "unique-1": 23,
        "entropy-1": 4.6150610122030695,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": -0.0038549452969019156,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 8.666666666666666,
        "std_pred_length-nopunct": 2.6246692913372702,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.546593564294937,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": -0.0029647186058182947,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.2016338611696506,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.93519,
            "recall": 0.78596,
            "fmeasure": 0.85135
        },
        "rouge2": {
            "precision": 0.73359,
            "recall": 0.58333,
            "fmeasure": 0.64632
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.61673,
            "fmeasure": 0.6745
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.61673,
            "fmeasure": 0.6745
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.5,
            "3": 0.8636363636363636
        },
        "nist": 4.251541399401237,
        "bleu": 50.37383,
        "bleurt": 0.13387,
        "nubia": {
            "semantic_relation": 4.45719,
            "contradiction": 0.32986,
            "irrelevancy": 11.35616,
            "logical_agreement": 88.31398,
            "grammar_ref": 5.1114,
            "grammar_hyp": 5.30096,
            "nubia_score": 0.76965
        },
        "meteor": 0.4061555384608179,
        "bertscore": {
            "precision": 0.95389,
            "recall": 0.93617,
            "f1": 0.94473
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_580": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 81,
        "mean_pred_length": 16.2,
        "std_pred_length": 7.6000000000000005,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.7654320987654321,
        "vocab_size-1": 62,
        "unique-1": 50,
        "entropy-1": 5.772267676328604,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 72,
        "unique-2": 68,
        "entropy-2": 6.142664355548853,
        "cond_entropy-2": 0.2549791944615961,
        "distinct-3": 0.9577464788732394,
        "vocab_size-3": 68,
        "unique-3": 65,
        "entropy-3": 6.065240077251155,
        "cond_entropy-3": -0.07001137985439645,
        "total_length-nopunct": 72,
        "mean_pred_length-nopunct": 14.4,
        "std_pred_length-nopunct": 6.681317235396026,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8055555555555556,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.720417668433979,
        "distinct-2-nopunct": 0.9402985074626866,
        "vocab_size-2-nopunct": 63,
        "unique-2-nopunct": 59,
        "entropy-2-nopunct": 5.946686205383141,
        "cond_entropy-2-nopunct": 0.24488848717367312,
        "distinct-3-nopunct": 0.9516129032258065,
        "vocab_size-3-nopunct": 59,
        "unique-3-nopunct": 56,
        "entropy-3-nopunct": 5.857422116838485,
        "cond_entropy-3-nopunct": -0.09576384781283255,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76318,
            "recall": 0.82964,
            "fmeasure": 0.78694
        },
        "rouge2": {
            "precision": 0.57904,
            "recall": 0.62131,
            "fmeasure": 0.5929
        },
        "rougeL": {
            "precision": 0.67414,
            "recall": 0.73231,
            "fmeasure": 0.69471
        },
        "rougeLsum": {
            "precision": 0.67414,
            "recall": 0.73231,
            "fmeasure": 0.69471
        },
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 1.0,
            "3": 0.8222222222222222
        },
        "nist": 3.720487647440348,
        "bleu": 35.3122,
        "bleurt": 0.29588,
        "nubia": {
            "semantic_relation": 4.00645,
            "contradiction": 38.91204,
            "irrelevancy": 33.86088,
            "logical_agreement": 27.22708,
            "grammar_ref": 5.55931,
            "grammar_hyp": 5.34779,
            "nubia_score": 0.61059
        },
        "meteor": 0.39819576394242334,
        "bertscore": {
            "precision": 0.92348,
            "recall": 0.9483,
            "f1": 0.93319
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_531": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.037537158749660605,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.043321469306228516,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.6738,
            "fmeasure": 0.66346
        },
        "rouge2": {
            "precision": 0.30952,
            "recall": 0.30833,
            "fmeasure": 0.30556
        },
        "rougeL": {
            "precision": 0.48889,
            "recall": 0.58111,
            "fmeasure": 0.52564
        },
        "rougeLsum": {
            "precision": 0.48889,
            "recall": 0.58111,
            "fmeasure": 0.52564
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "nist": 3.4120370565751066,
        "bleu": 19.25161,
        "bleurt": 0.22101,
        "nubia": {
            "semantic_relation": 4.5344,
            "contradiction": 1.62252,
            "irrelevancy": 48.56193,
            "logical_agreement": 49.81555,
            "grammar_ref": 5.72031,
            "grammar_hyp": 5.21814,
            "nubia_score": 0.79865
        },
        "meteor": 0.335787584193912,
        "bertscore": {
            "precision": 0.91738,
            "recall": 0.90538,
            "f1": 0.91134
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_532": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 55,
        "mean_pred_length": 18.333333333333332,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 19,
        "distinct-1": 0.8545454545454545,
        "vocab_size-1": 47,
        "unique-1": 42,
        "entropy-1": 5.449274940679377,
        "distinct-2": 1.0,
        "vocab_size-2": 52,
        "unique-2": 52,
        "entropy-2": 5.700439718141095,
        "cond_entropy-2": 0.17888337008425823,
        "distinct-3": 1.0,
        "vocab_size-3": 49,
        "unique-3": 49,
        "entropy-3": 5.614709844115208,
        "cond_entropy-3": -0.08572987402588379,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 0.9428090415820634,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9183673469387755,
        "vocab_size-1-nopunct": 45,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.436038670601668,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.5235619560570095,
        "cond_entropy-2-nopunct": 0.09917575329318433,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.426264754702098,
        "cond_entropy-3-nopunct": -0.09729720135491506,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88799,
            "recall": 0.79952,
            "fmeasure": 0.82815
        },
        "rouge2": {
            "precision": 0.73181,
            "recall": 0.70439,
            "fmeasure": 0.70493
        },
        "rougeL": {
            "precision": 0.72542,
            "recall": 0.69238,
            "fmeasure": 0.70059
        },
        "rougeLsum": {
            "precision": 0.72542,
            "recall": 0.69238,
            "fmeasure": 0.70059
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.5,
            "3": 0.7547169811320755
        },
        "nist": 4.7184910745912285,
        "bleu": 54.39116,
        "bleurt": 0.4449,
        "nubia": {
            "semantic_relation": 4.19768,
            "contradiction": 0.30798,
            "irrelevancy": 66.46742,
            "logical_agreement": 33.2246,
            "grammar_ref": 4.33326,
            "grammar_hyp": 4.52446,
            "nubia_score": 0.69398
        },
        "meteor": 0.4031251857450008,
        "bertscore": {
            "precision": 0.96223,
            "recall": 0.94563,
            "f1": 0.95283
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_430": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.76,
        "total_length": 123,
        "mean_pred_length": 15.375,
        "std_pred_length": 6.613197033205649,
        "median_pred_length": 13.5,
        "min_pred_length": 8,
        "max_pred_length": 32,
        "distinct-1": 0.6910569105691057,
        "vocab_size-1": 85,
        "unique-1": 67,
        "entropy-1": 6.116101981016105,
        "distinct-2": 0.9391304347826087,
        "vocab_size-2": 108,
        "unique-2": 101,
        "entropy-2": 6.723750920509606,
        "cond_entropy-2": 0.44462198456344937,
        "distinct-3": 0.9719626168224299,
        "vocab_size-3": 104,
        "unique-3": 101,
        "entropy-3": 6.685392220045998,
        "cond_entropy-3": -0.02925670940304139,
        "total_length-nopunct": 108,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 5.787918451395113,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.7592592592592593,
        "vocab_size-1-nopunct": 82,
        "unique-1-nopunct": 66,
        "entropy-1-nopunct": 6.185352548419693,
        "distinct-2-nopunct": 0.93,
        "vocab_size-2-nopunct": 93,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.503856189774739,
        "cond_entropy-2-nopunct": 0.36406643765452584,
        "distinct-3-nopunct": 0.967391304347826,
        "vocab_size-3-nopunct": 89,
        "unique-3-nopunct": 86,
        "entropy-3-nopunct": 6.458344564752679,
        "cond_entropy-3-nopunct": -0.03333771197858132,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.91449,
            "recall": 0.86627,
            "fmeasure": 0.88683
        },
        "rouge2": {
            "precision": 0.83274,
            "recall": 0.79715,
            "fmeasure": 0.81178
        },
        "rougeL": {
            "precision": 0.88027,
            "recall": 0.83715,
            "fmeasure": 0.85537
        },
        "rougeLsum": {
            "precision": 0.88027,
            "recall": 0.83715,
            "fmeasure": 0.85537
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 0.8867924528301887
        },
        "nist": 6.193243396713395,
        "bleu": 71.26012,
        "bleurt": 0.57111,
        "nubia": {
            "semantic_relation": 4.38705,
            "contradiction": 12.66105,
            "irrelevancy": 16.74186,
            "logical_agreement": 70.59709,
            "grammar_ref": 5.14689,
            "grammar_hyp": 5.25957,
            "nubia_score": 0.7627
        },
        "meteor": 0.5036976052330323,
        "bertscore": {
            "precision": 0.96578,
            "recall": 0.95352,
            "f1": 0.95924
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_581": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.58182,
            "fmeasure": 0.69281
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.32222,
            "fmeasure": 0.39167
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.58182,
            "fmeasure": 0.69281
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.58182,
            "fmeasure": 0.69281
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nist": 1.577349665494077,
        "bleu": 17.46171,
        "bleurt": 0.51995,
        "nubia": {
            "semantic_relation": 4.71231,
            "contradiction": 0.57424,
            "irrelevancy": 0.56789,
            "logical_agreement": 98.85787,
            "grammar_ref": 4.19474,
            "grammar_hyp": 4.7893,
            "nubia_score": 0.93145
        },
        "meteor": 0.32522079578586516,
        "bertscore": {
            "precision": 0.96748,
            "recall": 0.93753,
            "f1": 0.95227
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_534": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 60,
        "mean_pred_length": 20.0,
        "std_pred_length": 7.2571803523590805,
        "median_pred_length": 17.0,
        "min_pred_length": 13,
        "max_pred_length": 30,
        "distinct-1": 0.8,
        "vocab_size-1": 48,
        "unique-1": 42,
        "entropy-1": 5.408985545926397,
        "distinct-2": 1.0,
        "vocab_size-2": 57,
        "unique-2": 57,
        "entropy-2": 5.832890014164737,
        "cond_entropy-2": 0.3666909181836576,
        "distinct-3": 1.0,
        "vocab_size-3": 54,
        "unique-3": 54,
        "entropy-3": 5.7548875021634665,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 53,
        "mean_pred_length-nopunct": 17.666666666666668,
        "std_pred_length-nopunct": 6.018490028422596,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8490566037735849,
        "vocab_size-1-nopunct": 45,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.343684077646209,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.643856189774728,
        "cond_entropy-2-nopunct": 0.32322629474353093,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.55458885167764,
        "cond_entropy-3-nopunct": -0.08926733809708727,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.62531,
            "recall": 0.50863,
            "fmeasure": 0.55593
        },
        "rouge2": {
            "precision": 0.332,
            "recall": 0.26246,
            "fmeasure": 0.29056
        },
        "rougeL": {
            "precision": 0.46605,
            "recall": 0.38237,
            "fmeasure": 0.41612
        },
        "rougeLsum": {
            "precision": 0.46605,
            "recall": 0.38237,
            "fmeasure": 0.41612
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.6,
            "3": 0.6363636363636364
        },
        "nist": 2.9522491253705296,
        "bleu": 11.2691,
        "bleurt": -0.03778,
        "nubia": {
            "semantic_relation": 3.37829,
            "contradiction": 43.51747,
            "irrelevancy": 17.06379,
            "logical_agreement": 39.41874,
            "grammar_ref": 3.79025,
            "grammar_hyp": 4.19855,
            "nubia_score": 0.51374
        },
        "meteor": 0.26647362993881696,
        "bertscore": {
            "precision": 0.88727,
            "recall": 0.88233,
            "f1": 0.88221
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_582": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 56,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.123105625617661,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.7321428571428571,
        "vocab_size-1": 41,
        "unique-1": 30,
        "entropy-1": 5.208966082694627,
        "distinct-2": 0.8653846153846154,
        "vocab_size-2": 45,
        "unique-2": 39,
        "entropy-2": 5.416691881561027,
        "cond_entropy-2": 0.09990955574047759,
        "distinct-3": 0.9375,
        "vocab_size-3": 45,
        "unique-3": 42,
        "entropy-3": 5.4599625007211605,
        "cond_entropy-3": 0.06691627220846971,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.9154759474226504,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7708333333333334,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 5.095175521464346,
        "distinct-2-nopunct": 0.8181818181818182,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 5.078638720860853,
        "cond_entropy-2-nopunct": 0.027989288419856123,
        "distinct-3-nopunct": 0.875,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 5.071928094887363,
        "cond_entropy-3-nopunct": 0.0313686638041517,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.975,
            "recall": 0.92643,
            "fmeasure": 0.94807
        },
        "rouge2": {
            "precision": 0.89425,
            "recall": 0.86591,
            "fmeasure": 0.87912
        },
        "rougeL": {
            "precision": 0.94167,
            "recall": 0.88839,
            "fmeasure": 0.91141
        },
        "rougeLsum": {
            "precision": 0.94167,
            "recall": 0.88839,
            "fmeasure": 0.91141
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9024390243902439
        },
        "nist": 5.271620622208107,
        "bleu": 70.96483,
        "bleurt": 0.71633,
        "nubia": {
            "semantic_relation": 4.80959,
            "contradiction": 0.25912,
            "irrelevancy": 8.75868,
            "logical_agreement": 90.9822,
            "grammar_ref": 5.18336,
            "grammar_hyp": 4.99435,
            "nubia_score": 0.94277
        },
        "meteor": 0.5355474160669821,
        "bertscore": {
            "precision": 0.97958,
            "recall": 0.98068,
            "f1": 0.97816
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_432": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 98,
        "mean_pred_length": 19.6,
        "std_pred_length": 12.435433245367852,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 42,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 70,
        "unique-1": 61,
        "entropy-1": 5.794927227506671,
        "distinct-2": 0.967741935483871,
        "vocab_size-2": 90,
        "unique-2": 87,
        "entropy-2": 6.474642682075778,
        "cond_entropy-2": 0.5989549449842262,
        "distinct-3": 1.0,
        "vocab_size-3": 88,
        "unique-3": 88,
        "entropy-3": 6.459431618637305,
        "cond_entropy-3": -0.011545374288915732,
        "total_length-nopunct": 78,
        "mean_pred_length-nopunct": 15.6,
        "std_pred_length-nopunct": 9.046546302318914,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.8205128205128205,
        "vocab_size-1-nopunct": 64,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 5.762903661142209,
        "distinct-2-nopunct": 0.9726027397260274,
        "vocab_size-2-nopunct": 71,
        "unique-2-nopunct": 69,
        "entropy-2-nopunct": 6.135030038332083,
        "cond_entropy-2-nopunct": 0.40791394963644595,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 68,
        "unique-3-nopunct": 68,
        "entropy-3-nopunct": 6.087462841250345,
        "cond_entropy-3-nopunct": -0.04353818821791301,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.90903,
            "recall": 0.78445,
            "fmeasure": 0.83889
        },
        "rouge2": {
            "precision": 0.77321,
            "recall": 0.6668,
            "fmeasure": 0.7132
        },
        "rougeL": {
            "precision": 0.76624,
            "recall": 0.65949,
            "fmeasure": 0.70606
        },
        "rougeLsum": {
            "precision": 0.76624,
            "recall": 0.65949,
            "fmeasure": 0.70606
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.125,
            "3": 0.8701298701298701
        },
        "nist": 5.67814500929698,
        "bleu": 68.16446,
        "bleurt": 0.52159,
        "nubia": {
            "semantic_relation": 4.67448,
            "contradiction": 0.29481,
            "irrelevancy": 0.58868,
            "logical_agreement": 99.1165,
            "grammar_ref": 4.65184,
            "grammar_hyp": 4.8966,
            "nubia_score": 0.89281
        },
        "meteor": 0.4821947339616016,
        "bertscore": {
            "precision": 0.96852,
            "recall": 0.94906,
            "f1": 0.95865
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_477": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 6.0,
        "median_pred_length": 20.0,
        "min_pred_length": 14,
        "max_pred_length": 26,
        "distinct-1": 0.775,
        "vocab_size-1": 31,
        "unique-1": 26,
        "entropy-1": 4.734183719779189,
        "distinct-2": 0.9210526315789473,
        "vocab_size-2": 35,
        "unique-2": 32,
        "entropy-2": 5.090032776601483,
        "cond_entropy-2": 0.3341513923543005,
        "distinct-3": 0.9722222222222222,
        "vocab_size-3": 35,
        "unique-3": 34,
        "entropy-3": 5.114369445886754,
        "cond_entropy-3": 0.03310859910983796,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.572431251322118,
        "distinct-2-nopunct": 0.9117647058823529,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.910992253015044,
        "cond_entropy-2-nopunct": 0.3737076928764665,
        "distinct-3-nopunct": 0.96875,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.9375,
        "cond_entropy-3-nopunct": 0.037537158749660605,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82234,
            "recall": 0.90909,
            "fmeasure": 0.8628
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.76459,
            "fmeasure": 0.73031
        },
        "rougeL": {
            "precision": 0.82234,
            "recall": 0.90909,
            "fmeasure": 0.8628
        },
        "rougeLsum": {
            "precision": 0.82234,
            "recall": 0.90909,
            "fmeasure": 0.8628
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.9615384615384616
        },
        "nist": 5.030602460886151,
        "bleu": 77.42868,
        "bleurt": 0.77245,
        "nubia": {
            "semantic_relation": 4.99278,
            "contradiction": 0.28914,
            "irrelevancy": 1.4734,
            "logical_agreement": 98.23746,
            "grammar_ref": 3.8433,
            "grammar_hyp": 3.57305,
            "nubia_score": 0.99594
        },
        "meteor": 0.5593662882094376,
        "bertscore": {
            "precision": 0.96775,
            "recall": 0.97732,
            "f1": 0.9725
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_584": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.95833,
            "recall": 0.88426,
            "fmeasure": 0.91912
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.60714,
            "fmeasure": 0.63492
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.76852,
            "fmeasure": 0.79902
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.76852,
            "fmeasure": 0.79902
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8571428571428571
        },
        "nist": 3.5786529413771158,
        "bleu": 65.00593,
        "bleurt": 0.60894,
        "nubia": {
            "semantic_relation": 4.95991,
            "contradiction": 0.71544,
            "irrelevancy": 0.62403,
            "logical_agreement": 98.66053,
            "grammar_ref": 5.94246,
            "grammar_hyp": 6.5727,
            "nubia_score": 0.90996
        },
        "meteor": 0.4688551030349617,
        "bertscore": {
            "precision": 0.98848,
            "recall": 0.9735,
            "f1": 0.98093
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_480": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.73,
        "total_length": 187,
        "mean_pred_length": 18.7,
        "std_pred_length": 4.960846701924985,
        "median_pred_length": 18.5,
        "min_pred_length": 13,
        "max_pred_length": 29,
        "distinct-1": 0.6096256684491979,
        "vocab_size-1": 114,
        "unique-1": 89,
        "entropy-1": 6.347737880700924,
        "distinct-2": 0.8926553672316384,
        "vocab_size-2": 158,
        "unique-2": 142,
        "entropy-2": 7.237351948375871,
        "cond_entropy-2": 0.7696834735675401,
        "distinct-3": 0.9281437125748503,
        "vocab_size-3": 155,
        "unique-3": 143,
        "entropy-3": 7.239991717623729,
        "cond_entropy-3": 0.016427410068680353,
        "total_length-nopunct": 166,
        "mean_pred_length-nopunct": 16.6,
        "std_pred_length-nopunct": 4.565084884205331,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6626506024096386,
        "vocab_size-1-nopunct": 110,
        "unique-1-nopunct": 89,
        "entropy-1-nopunct": 6.366777293367178,
        "distinct-2-nopunct": 0.8846153846153846,
        "vocab_size-2-nopunct": 138,
        "unique-2-nopunct": 123,
        "entropy-2-nopunct": 7.036973452822753,
        "cond_entropy-2-nopunct": 0.7097841773029159,
        "distinct-3-nopunct": 0.9246575342465754,
        "vocab_size-3-nopunct": 135,
        "unique-3-nopunct": 124,
        "entropy-3-nopunct": 7.039139627373171,
        "cond_entropy-3-nopunct": 0.019181843457244625,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81232,
            "recall": 0.76521,
            "fmeasure": 0.78143
        },
        "rouge2": {
            "precision": 0.59223,
            "recall": 0.56967,
            "fmeasure": 0.5755
        },
        "rougeL": {
            "precision": 0.69573,
            "recall": 0.66174,
            "fmeasure": 0.6725
        },
        "rougeLsum": {
            "precision": 0.69573,
            "recall": 0.66174,
            "fmeasure": 0.6725
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.5555555555555556,
            "3": 0.8034188034188035
        },
        "nist": 5.50177426726973,
        "bleu": 45.62345,
        "bleurt": 0.37071,
        "nubia": {
            "semantic_relation": 4.31666,
            "contradiction": 25.41881,
            "irrelevancy": 14.62755,
            "logical_agreement": 59.95364,
            "grammar_ref": 4.07874,
            "grammar_hyp": 4.50076,
            "nubia_score": 0.7399
        },
        "meteor": 0.40808175661481294,
        "bertscore": {
            "precision": 0.93815,
            "recall": 0.93534,
            "f1": 0.93657
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_483": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 12.333333333333334,
        "std_pred_length": 2.8674417556808756,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.8378378378378378,
        "vocab_size-1": 31,
        "unique-1": 27,
        "entropy-1": 4.844324311457953,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": 0.13550616686149178,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.13326653086346418,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.943920288775949,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8787878787878788,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.779094498080774,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": 0.12099272632218087,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.15200309344505,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.68376,
            "recall": 0.78058,
            "fmeasure": 0.71528
        },
        "rouge2": {
            "precision": 0.53175,
            "recall": 0.57837,
            "fmeasure": 0.5455
        },
        "rougeL": {
            "precision": 0.68376,
            "recall": 0.78058,
            "fmeasure": 0.71528
        },
        "rougeLsum": {
            "precision": 0.68376,
            "recall": 0.78058,
            "fmeasure": 0.71528
        },
        "local_recall": {
            "1": 0.0625,
            "2": 0.7692307692307693,
            "3": 0.9166666666666666
        },
        "nist": 3.628280534606305,
        "bleu": 35.50501,
        "bleurt": 0.50432,
        "nubia": {
            "semantic_relation": 4.58907,
            "contradiction": 0.38175,
            "irrelevancy": 33.58185,
            "logical_agreement": 66.0364,
            "grammar_ref": 5.27099,
            "grammar_hyp": 5.01829,
            "nubia_score": 0.90658
        },
        "meteor": 0.4704259657217445,
        "bertscore": {
            "precision": 0.91181,
            "recall": 0.95488,
            "f1": 0.93093
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_535": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5,
            "recall": 0.33333,
            "fmeasure": 0.4
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.125,
            "fmeasure": 0.15385
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.33333,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.33333,
            "fmeasure": 0.4
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.3333333333333333
        },
        "nist": 1.1102226191048412,
        "bleu": 10.17528,
        "bleurt": 0.14193,
        "nubia": {
            "semantic_relation": 3.58171,
            "contradiction": 0.16384,
            "irrelevancy": 1.38184,
            "logical_agreement": 98.45431,
            "grammar_ref": 6.68645,
            "grammar_hyp": 6.28924,
            "nubia_score": 0.69878
        },
        "meteor": 0.21851367216868106,
        "bertscore": {
            "precision": 0.84409,
            "recall": 0.79178,
            "f1": 0.8171
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_434": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 3.0,
        "median_pred_length": 20.0,
        "min_pred_length": 17,
        "max_pred_length": 23,
        "distinct-1": 0.75,
        "vocab_size-1": 30,
        "unique-1": 22,
        "entropy-1": 4.784183719779189,
        "distinct-2": 0.9736842105263158,
        "vocab_size-2": 37,
        "unique-2": 36,
        "entropy-2": 5.19529593449622,
        "cond_entropy-2": 0.3867829713016689,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.022446956445717595,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7878787878787878,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.597276316262592,
        "distinct-2-nopunct": 0.967741935483871,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.889680181354619,
        "cond_entropy-2-nopunct": 0.3212501749691789,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.02724979801792366,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.52528,
            "recall": 0.74893,
            "fmeasure": 0.61703
        },
        "rouge2": {
            "precision": 0.30556,
            "recall": 0.45862,
            "fmeasure": 0.36376
        },
        "rougeL": {
            "precision": 0.46182,
            "recall": 0.65629,
            "fmeasure": 0.54118
        },
        "rougeLsum": {
            "precision": 0.46182,
            "recall": 0.65629,
            "fmeasure": 0.54118
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.75
        },
        "nist": 2.4205779877993043,
        "bleu": 20.13836,
        "bleurt": -0.30388,
        "nubia": {
            "semantic_relation": 3.21456,
            "contradiction": 45.4141,
            "irrelevancy": 27.5872,
            "logical_agreement": 26.99871,
            "grammar_ref": 4.76014,
            "grammar_hyp": 3.76644,
            "nubia_score": 0.56227
        },
        "meteor": 0.35698455135702944,
        "bertscore": {
            "precision": 0.83108,
            "recall": 0.90675,
            "f1": 0.86725
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_536": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 50,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 0.9428090415820634,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 18,
        "distinct-1": 0.72,
        "vocab_size-1": 36,
        "unique-1": 30,
        "entropy-1": 4.909275070710716,
        "distinct-2": 0.9148936170212766,
        "vocab_size-2": 43,
        "unique-2": 40,
        "entropy-2": 5.368314649503949,
        "cond_entropy-2": 0.4047599161342664,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": 0.058362937463374884,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 0.9428090415820634,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7446808510638298,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.874287395272594,
        "distinct-2-nopunct": 0.9318181818181818,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.305911448133581,
        "cond_entropy-2-nopunct": 0.43255369761587836,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": 0.06287373969209045,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7805,
            "recall": 0.67225,
            "fmeasure": 0.71982
        },
        "rouge2": {
            "precision": 0.41786,
            "recall": 0.35902,
            "fmeasure": 0.38421
        },
        "rougeL": {
            "precision": 0.57655,
            "recall": 0.52901,
            "fmeasure": 0.54746
        },
        "rougeLsum": {
            "precision": 0.57655,
            "recall": 0.52901,
            "fmeasure": 0.54746
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.25,
            "3": 0.75
        },
        "nist": 4.296147761796787,
        "bleu": 37.71383,
        "bleurt": 0.06661,
        "nubia": {
            "semantic_relation": 4.34968,
            "contradiction": 0.88568,
            "irrelevancy": 24.4081,
            "logical_agreement": 74.70622,
            "grammar_ref": 4.10939,
            "grammar_hyp": 4.40587,
            "nubia_score": 0.75993
        },
        "meteor": 0.3481325007699591,
        "bertscore": {
            "precision": 0.92203,
            "recall": 0.91099,
            "f1": 0.91107
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_485": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7735572622751845,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.04332146930622849,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.80828,
            "fmeasure": 0.86616
        },
        "rouge2": {
            "precision": 0.64286,
            "recall": 0.55147,
            "fmeasure": 0.59355
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.46187,
            "fmeasure": 0.49495
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.46187,
            "fmeasure": 0.49495
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "nist": 2.7910011142063147,
        "bleu": 26.84166,
        "bleurt": 0.46031,
        "nubia": {
            "semantic_relation": 4.96522,
            "contradiction": 0.1617,
            "irrelevancy": 0.45961,
            "logical_agreement": 99.37869,
            "grammar_ref": 3.15249,
            "grammar_hyp": 3.46064,
            "nubia_score": 0.98056
        },
        "meteor": 0.4123716786243268,
        "bertscore": {
            "precision": 0.95567,
            "recall": 0.92415,
            "f1": 0.93965
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_435": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 67,
        "mean_pred_length": 16.75,
        "std_pred_length": 4.968651728587948,
        "median_pred_length": 17.5,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.7910447761194029,
        "vocab_size-1": 53,
        "unique-1": 45,
        "entropy-1": 5.5659432948708,
        "distinct-2": 1.0,
        "vocab_size-2": 63,
        "unique-2": 63,
        "entropy-2": 5.97727992349992,
        "cond_entropy-2": 0.31610779660288935,
        "distinct-3": 1.0,
        "vocab_size-3": 59,
        "unique-3": 59,
        "entropy-3": 5.882643049361836,
        "cond_entropy-3": -0.0946368741380753,
        "total_length-nopunct": 58,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 4.6097722286464435,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8448275862068966,
        "vocab_size-1-nopunct": 49,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.500138107159235,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 54,
        "entropy-2-nopunct": 5.7548875021634665,
        "cond_entropy-2-nopunct": 0.2812562755944794,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.643856189774728,
        "cond_entropy-3-nopunct": -0.11103131238874385,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81518,
            "recall": 0.68211,
            "fmeasure": 0.74111
        },
        "rouge2": {
            "precision": 0.46557,
            "recall": 0.38513,
            "fmeasure": 0.42047
        },
        "rougeL": {
            "precision": 0.63476,
            "recall": 0.53226,
            "fmeasure": 0.57776
        },
        "rougeLsum": {
            "precision": 0.63476,
            "recall": 0.53226,
            "fmeasure": 0.57776
        },
        "local_recall": {
            "1": 0.07142857142857142,
            "2": 0.6,
            "3": 0.6909090909090909
        },
        "nist": 4.084160810946082,
        "bleu": 25.26661,
        "bleurt": 0.0747,
        "nubia": {
            "semantic_relation": 4.15989,
            "contradiction": 16.83051,
            "irrelevancy": 30.48522,
            "logical_agreement": 52.68428,
            "grammar_ref": 4.16687,
            "grammar_hyp": 4.87818,
            "nubia_score": 0.66628
        },
        "meteor": 0.3380563907211483,
        "bertscore": {
            "precision": 0.90971,
            "recall": 0.89393,
            "f1": 0.90143
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_486": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 64,
        "mean_pred_length": 16.0,
        "std_pred_length": 10.27131929208707,
        "median_pred_length": 13.5,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.765625,
        "vocab_size-1": 49,
        "unique-1": 40,
        "entropy-1": 5.413909765557392,
        "distinct-2": 0.9833333333333333,
        "vocab_size-2": 59,
        "unique-2": 58,
        "entropy-2": 5.873557262275184,
        "cond_entropy-2": 0.36538684568063423,
        "distinct-3": 1.0,
        "vocab_size-3": 56,
        "unique-3": 56,
        "entropy-3": 5.807354922057609,
        "cond_entropy-3": -0.09953567355091447,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 12.25,
        "std_pred_length-nopunct": 7.628073151196179,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8979591836734694,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.410628211462147,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.491853096329673,
        "cond_entropy-2-nopunct": 0.05492102999224406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.13430109171159124,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.51571,
            "recall": 0.44167,
            "fmeasure": 0.45238
        },
        "rouge2": {
            "precision": 0.25718,
            "recall": 0.26252,
            "fmeasure": 0.25138
        },
        "rougeL": {
            "precision": 0.50929,
            "recall": 0.43473,
            "fmeasure": 0.44571
        },
        "rougeLsum": {
            "precision": 0.50929,
            "recall": 0.43473,
            "fmeasure": 0.44571
        },
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.2894736842105263,
            "3": 0.8
        },
        "nist": 3.8283812162565014,
        "bleu": 44.90217,
        "bleurt": -0.48388,
        "nubia": {
            "semantic_relation": 3.30915,
            "contradiction": 25.05191,
            "irrelevancy": 54.42718,
            "logical_agreement": 20.5209,
            "grammar_ref": 4.83501,
            "grammar_hyp": 5.03537,
            "nubia_score": 0.40822
        },
        "meteor": 0.3369280266875983,
        "bertscore": {
            "precision": 0.81987,
            "recall": 0.82299,
            "f1": 0.81417
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_436": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.86667,
            "fmeasure": 0.86667
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.01117167855772,
        "bleu": 100.0,
        "bleurt": 0.77386,
        "nubia": {
            "semantic_relation": 4.66362,
            "contradiction": 2.49017,
            "irrelevancy": 1.24853,
            "logical_agreement": 96.2613,
            "grammar_ref": 6.06085,
            "grammar_hyp": 5.70692,
            "nubia_score": 0.90186
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_539": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966058,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.36842,
            "recall": 0.58333,
            "fmeasure": 0.45161
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.27273,
            "fmeasure": 0.2069
        },
        "rougeL": {
            "precision": 0.26316,
            "recall": 0.41667,
            "fmeasure": 0.32258
        },
        "rougeLsum": {
            "precision": 0.26316,
            "recall": 0.41667,
            "fmeasure": 0.32258
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "nist": 1.1949875002403856,
        "bleu": 8.35518,
        "bleurt": 0.00317,
        "nubia": {
            "semantic_relation": 3.96194,
            "contradiction": 0.32696,
            "irrelevancy": 98.49315,
            "logical_agreement": 1.17989,
            "grammar_ref": 5.68739,
            "grammar_hyp": 4.01718,
            "nubia_score": 0.66819
        },
        "meteor": 0.2918525653325891,
        "bertscore": {
            "precision": 0.78447,
            "recall": 0.80853,
            "f1": 0.79632
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_510": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 4.5,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 18,
        "distinct-1": 0.8148148148148148,
        "vocab_size-1": 22,
        "unique-1": 17,
        "entropy-1": 4.3845171317931,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.20896868761125617,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.186704345910023,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.162496476250065,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7381,
            "recall": 0.61219,
            "fmeasure": 0.66918
        },
        "rouge2": {
            "precision": 0.45673,
            "recall": 0.37222,
            "fmeasure": 0.4101
        },
        "rougeL": {
            "precision": 0.60714,
            "recall": 0.50475,
            "fmeasure": 0.55102
        },
        "rougeLsum": {
            "precision": 0.60714,
            "recall": 0.50475,
            "fmeasure": 0.55102
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.2,
            "3": 0.7
        },
        "nist": 3.7501189518400757,
        "bleu": 34.32937,
        "bleurt": 0.29753,
        "nubia": {
            "semantic_relation": 4.45158,
            "contradiction": 0.23813,
            "irrelevancy": 32.22576,
            "logical_agreement": 67.53612,
            "grammar_ref": 5.35082,
            "grammar_hyp": 5.03948,
            "nubia_score": 0.93127
        },
        "meteor": 0.37090647529186954,
        "bertscore": {
            "precision": 0.93728,
            "recall": 0.9124,
            "f1": 0.92465
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_488": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96078,
            "fmeasure": 0.97917
        },
        "rouge2": {
            "precision": 0.80952,
            "recall": 0.7381,
            "fmeasure": 0.77143
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.81569,
            "fmeasure": 0.85
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.81569,
            "fmeasure": 0.85
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "nist": 4.997400644669717,
        "bleu": 78.67012,
        "bleurt": 0.63445,
        "nubia": {
            "semantic_relation": 4.74121,
            "contradiction": 0.21038,
            "irrelevancy": 0.47513,
            "logical_agreement": 99.31449,
            "grammar_ref": 4.24096,
            "grammar_hyp": 4.22897,
            "nubia_score": 0.92017
        },
        "meteor": 0.5302622459418969,
        "bertscore": {
            "precision": 0.96928,
            "recall": 0.96681,
            "f1": 0.96805
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_585": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 71,
        "mean_pred_length": 11.833333333333334,
        "std_pred_length": 3.0776975521032313,
        "median_pred_length": 10.5,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.5211267605633803,
        "vocab_size-1": 37,
        "unique-1": 26,
        "entropy-1": 4.793356098042735,
        "distinct-2": 0.7384615384615385,
        "vocab_size-2": 48,
        "unique-2": 38,
        "entropy-2": 5.417995312795469,
        "cond_entropy-2": 0.511232616667264,
        "distinct-3": 0.7796610169491526,
        "vocab_size-3": 46,
        "unique-3": 39,
        "entropy-3": 5.365196862701146,
        "cond_entropy-3": -0.0719281534971216,
        "total_length-nopunct": 63,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 2.6299556396765835,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.5396825396825397,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.694835677159103,
        "distinct-2-nopunct": 0.7368421052631579,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.227112382358057,
        "cond_entropy-2-nopunct": 0.5838517574074028,
        "distinct-3-nopunct": 0.7843137254901961,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.167044214308413,
        "cond_entropy-3-nopunct": -0.08203329964422641,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.91664,
            "recall": 0.88342,
            "fmeasure": 0.89454
        },
        "rouge2": {
            "precision": 0.76129,
            "recall": 0.74377,
            "fmeasure": 0.74813
        },
        "rougeL": {
            "precision": 0.88331,
            "recall": 0.8597,
            "fmeasure": 0.86673
        },
        "rougeLsum": {
            "precision": 0.88331,
            "recall": 0.8597,
            "fmeasure": 0.86673
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.7692307692307693,
            "3": 0.8809523809523809
        },
        "nist": 6.1122666866110205,
        "bleu": 77.5169,
        "bleurt": 0.64552,
        "nubia": {
            "semantic_relation": 4.22787,
            "contradiction": 16.9614,
            "irrelevancy": 22.50901,
            "logical_agreement": 60.52959,
            "grammar_ref": 4.0718,
            "grammar_hyp": 4.02433,
            "nubia_score": 0.79421
        },
        "meteor": 0.4954632634763069,
        "bertscore": {
            "precision": 0.98354,
            "recall": 0.97884,
            "f1": 0.98111
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_588": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 10,
        "unique-1": 6,
        "entropy-1": 3.2359263506290334,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 12,
        "unique-2": 11,
        "entropy-2": 3.5465935642949384,
        "cond_entropy-2": 0.35462325762194935,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": 0.05118944924673077,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 2.918295834054489,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.277613436819116,
        "cond_entropy-2-nopunct": 0.3290145724615955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": 0.06249647625006499,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73077,
            "recall": 0.75962,
            "fmeasure": 0.74462
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.69697,
            "fmeasure": 0.68116
        },
        "rougeL": {
            "precision": 0.73077,
            "recall": 0.75962,
            "fmeasure": 0.74462
        },
        "rougeLsum": {
            "precision": 0.73077,
            "recall": 0.75962,
            "fmeasure": 0.74462
        },
        "local_recall": {
            "1": 0,
            "2": 0.7
        },
        "nist": 3.16333702950726,
        "bleu": 61.15381,
        "bleurt": 0.61792,
        "nubia": {
            "semantic_relation": 3.13439,
            "contradiction": 98.90522,
            "irrelevancy": 0.47835,
            "logical_agreement": 0.61642,
            "grammar_ref": 3.96979,
            "grammar_hyp": 3.46395,
            "nubia_score": 0.46717
        },
        "meteor": 0.451369116507126,
        "bertscore": {
            "precision": 0.97184,
            "recall": 0.94737,
            "f1": 0.95944
        }
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 1322,
        "msttr-100": 0.53024,
        "msttr-100_nopunct": 0.54737,
        "total_length": 29466,
        "mean_pred_length": 22.28895612708018,
        "std_pred_length": 11.430829228574833,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 65,
        "distinct-1": 0.06543134460055658,
        "vocab_size-1": 1928,
        "unique-1": 683,
        "entropy-1": 7.959052473369674,
        "distinct-2": 0.23301591813530415,
        "vocab_size-2": 6558,
        "unique-2": 3349,
        "entropy-2": 11.351342559169295,
        "cond_entropy-2": 3.2031814104151963,
        "distinct-3": 0.41234807247781674,
        "vocab_size-3": 11060,
        "unique-3": 6974,
        "entropy-3": 12.605910161105982,
        "cond_entropy-3": 1.3123748723798592,
        "total_length-nopunct": 25941,
        "mean_pred_length-nopunct": 19.62254160363086,
        "std_pred_length-nopunct": 10.29785784240436,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 58,
        "distinct-1-nopunct": 0.07393701090937127,
        "vocab_size-1-nopunct": 1918,
        "unique-1-nopunct": 682,
        "entropy-1-nopunct": 8.259608904868262,
        "distinct-2-nopunct": 0.2489946789065356,
        "vocab_size-2-nopunct": 6130,
        "unique-2-nopunct": 3273,
        "entropy-2-nopunct": 11.276231596209806,
        "cond_entropy-2-nopunct": 3.1771175797427,
        "distinct-3-nopunct": 0.432072799072842,
        "vocab_size-3-nopunct": 10066,
        "unique-3-nopunct": 6607,
        "entropy-3-nopunct": 12.471933161081285,
        "cond_entropy-3-nopunct": 1.2547103917658058,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.67653,
            "recall": 0.67809,
            "fmeasure": 0.67031
        },
        "rouge2": {
            "precision": 0.39995,
            "recall": 0.40103,
            "fmeasure": 0.39596
        },
        "rougeL": {
            "precision": 0.53309,
            "recall": 0.53633,
            "fmeasure": 0.52863
        },
        "rougeLsum": {
            "precision": 0.53309,
            "recall": 0.53633,
            "fmeasure": 0.52863
        },
        "local_recall": {
            "1": 0.21891136883094894,
            "2": 0.5146872803935348,
            "3": 0.7560335781741868,
            "4": 0.9607843137254902,
            "5": 0.6190476190476191
        },
        "nist": 7.529264426533547,
        "bleu": 36.92577,
        "bleurt": -0.00947,
        "nubia": {
            "semantic_relation": 3.97379,
            "contradiction": 24.78128,
            "irrelevancy": 10.907,
            "logical_agreement": 64.31172,
            "grammar_ref": 4.6229,
            "grammar_hyp": 4.7123,
            "nubia_score": 0.64624
        },
        "meteor": 0.3323347588934393,
        "bertscore": {
            "precision": 0.89375,
            "recall": 0.89597,
            "f1": 0.89352
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_540": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 59,
        "mean_pred_length": 11.8,
        "std_pred_length": 4.261455150532504,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 19,
        "distinct-1": 0.7627118644067796,
        "vocab_size-1": 45,
        "unique-1": 38,
        "entropy-1": 5.2873987192133,
        "distinct-2": 0.9814814814814815,
        "vocab_size-2": 53,
        "unique-2": 52,
        "entropy-2": 5.717850465126429,
        "cond_entropy-2": 0.2705736195484224,
        "distinct-3": 1.0,
        "vocab_size-3": 49,
        "unique-3": 49,
        "entropy-3": 5.614709844115208,
        "cond_entropy-3": -0.09936133151764785,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 10.4,
        "std_pred_length-nopunct": 4.17612260356422,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8269230769230769,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.286790198827115,
        "distinct-2-nopunct": 0.9787234042553191,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.512035660188278,
        "cond_entropy-2-nopunct": 0.2692507293732888,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.3923174227787625,
        "cond_entropy-3-nopunct": -0.11465238127982942,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82231,
            "recall": 0.65352,
            "fmeasure": 0.69463
        },
        "rouge2": {
            "precision": 0.4178,
            "recall": 0.3735,
            "fmeasure": 0.38197
        },
        "rougeL": {
            "precision": 0.70376,
            "recall": 0.5801,
            "fmeasure": 0.61043
        },
        "rougeLsum": {
            "precision": 0.70376,
            "recall": 0.5801,
            "fmeasure": 0.61043
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.8125,
            "3": 0.6190476190476191
        },
        "nist": 4.170480884115523,
        "bleu": 44.25076,
        "bleurt": 0.17918,
        "nubia": {
            "semantic_relation": 3.76842,
            "contradiction": 20.31967,
            "irrelevancy": 28.97606,
            "logical_agreement": 50.70427,
            "grammar_ref": 4.71659,
            "grammar_hyp": 4.9851,
            "nubia_score": 0.59617
        },
        "meteor": 0.3555903300587152,
        "bertscore": {
            "precision": 0.93548,
            "recall": 0.89885,
            "f1": 0.91564
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_512": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9047619047619048,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.201841232302569,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.129610672108602,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.1219280948873624,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.1365257343456969,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7619,
            "recall": 0.3761,
            "fmeasure": 0.50329
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.1537,
            "fmeasure": 0.21026
        },
        "rougeL": {
            "precision": 0.50794,
            "recall": 0.24072,
            "fmeasure": 0.32643
        },
        "rougeLsum": {
            "precision": 0.50794,
            "recall": 0.24072,
            "fmeasure": 0.32643
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.16666666666666666,
            "3": 0.38461538461538464
        },
        "nist": 0.3232435971523351,
        "bleu": 6.50008,
        "bleurt": -0.52111,
        "nubia": {
            "semantic_relation": 3.40174,
            "contradiction": 1.44451,
            "irrelevancy": 95.77319,
            "logical_agreement": 2.78231,
            "grammar_ref": 4.78179,
            "grammar_hyp": 4.29854,
            "nubia_score": 0.33431
        },
        "meteor": 0.18876841833989988,
        "bertscore": {
            "precision": 0.87455,
            "recall": 0.81824,
            "f1": 0.84508
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_590": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.816496580927726,
        "median_pred_length": 18.0,
        "min_pred_length": 17,
        "max_pred_length": 19,
        "distinct-1": 0.7222222222222222,
        "vocab_size-1": 39,
        "unique-1": 29,
        "entropy-1": 5.120356715006238,
        "distinct-2": 0.9803921568627451,
        "vocab_size-2": 50,
        "unique-2": 49,
        "entropy-2": 5.63320965569699,
        "cond_entropy-2": 0.45694519283404517,
        "distinct-3": 1.0,
        "vocab_size-3": 48,
        "unique-3": 48,
        "entropy-3": 5.5849625007211605,
        "cond_entropy-3": -0.0457961745836727,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 2.160246899469287,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.9694136517890755,
        "distinct-2-nopunct": 0.9761904761904762,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.344698375159715,
        "cond_entropy-2-nopunct": 0.34117325512353647,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": -0.08127417827548626,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5436,
            "recall": 0.75013,
            "fmeasure": 0.62612
        },
        "rouge2": {
            "precision": 0.28592,
            "recall": 0.45505,
            "fmeasure": 0.34803
        },
        "rougeL": {
            "precision": 0.46489,
            "recall": 0.66911,
            "fmeasure": 0.5444
        },
        "rougeLsum": {
            "precision": 0.46489,
            "recall": 0.66911,
            "fmeasure": 0.5444
        },
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.6,
            "3": 0.8461538461538461
        },
        "nist": 3.2802693649983814,
        "bleu": 27.60826,
        "bleurt": 0.27756,
        "nubia": {
            "semantic_relation": 3.80294,
            "contradiction": 14.0423,
            "irrelevancy": 42.08968,
            "logical_agreement": 43.86802,
            "grammar_ref": 4.63208,
            "grammar_hyp": 3.57105,
            "nubia_score": 0.70387
        },
        "meteor": 0.3688191907556474,
        "bertscore": {
            "precision": 0.88545,
            "recall": 0.90952,
            "f1": 0.8932
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_513": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.54167,
            "recall": 0.60317,
            "fmeasure": 0.5641
        },
        "rouge2": {
            "precision": 0.13636,
            "recall": 0.16346,
            "fmeasure": 0.14693
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.45635,
            "fmeasure": 0.4304
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.45635,
            "fmeasure": 0.4304
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.8571428571428571
        },
        "nist": 2.0066104177484014,
        "bleu": 8.22596,
        "bleurt": 0.32398,
        "nubia": {
            "semantic_relation": 3.30585,
            "contradiction": 5.68813,
            "irrelevancy": 77.61956,
            "logical_agreement": 16.69231,
            "grammar_ref": 5.58883,
            "grammar_hyp": 4.18861,
            "nubia_score": 0.49566
        },
        "meteor": 0.3531556244060064,
        "bertscore": {
            "precision": 0.85061,
            "recall": 0.93238,
            "f1": 0.88962
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_543": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.6,
            "fmeasure": 0.54545
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8333333333333334
        },
        "nist": 2.1055161915432032,
        "bleu": 41.11336,
        "bleurt": 0.18287,
        "nubia": {
            "semantic_relation": 4.01521,
            "contradiction": 10.23484,
            "irrelevancy": 37.69891,
            "logical_agreement": 52.06625,
            "grammar_ref": 7.84225,
            "grammar_hyp": 7.31486,
            "nubia_score": 0.66591
        },
        "meteor": 0.4231469901582543,
        "bertscore": {
            "precision": 0.93887,
            "recall": 0.95113,
            "f1": 0.94496
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_544": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.875,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 3.0286497677077553,
        "bleu": 70.16879,
        "bleurt": 0.76221,
        "nubia": {
            "semantic_relation": 4.89761,
            "contradiction": 0.83309,
            "irrelevancy": 31.2673,
            "logical_agreement": 67.89961,
            "grammar_ref": 5.45224,
            "grammar_hyp": 4.86831,
            "nubia_score": 0.98957
        },
        "meteor": 0.5613051214200641,
        "bertscore": {
            "precision": 0.98524,
            "recall": 0.9921,
            "f1": 0.98866
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_515": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 43,
        "mean_pred_length": 14.333333333333334,
        "std_pred_length": 1.699673171197595,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.813953488372093,
        "vocab_size-1": 35,
        "unique-1": 28,
        "entropy-1": 5.036616208140156,
        "distinct-2": 0.975,
        "vocab_size-2": 39,
        "unique-2": 38,
        "entropy-2": 5.271928094887364,
        "cond_entropy-2": 0.14566334018526417,
        "distinct-3": 1.0,
        "vocab_size-3": 37,
        "unique-3": 37,
        "entropy-3": 5.209453365628954,
        "cond_entropy-3": -0.05842067520435854,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 1.632993161855452,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.97770991116994,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.058813890331199,
        "cond_entropy-2-nopunct": 0.10674500480228634,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.004318760871737871,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88661,
            "recall": 0.95185,
            "fmeasure": 0.91149
        },
        "rouge2": {
            "precision": 0.83466,
            "recall": 0.92107,
            "fmeasure": 0.86619
        },
        "rougeL": {
            "precision": 0.85356,
            "recall": 0.96068,
            "fmeasure": 0.89735
        },
        "rougeLsum": {
            "precision": 0.85356,
            "recall": 0.96068,
            "fmeasure": 0.89735
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 1.0
        },
        "nist": 5.263053586708178,
        "bleu": 80.21298,
        "bleurt": 0.64515,
        "nubia": {
            "semantic_relation": 4.58576,
            "contradiction": 0.43884,
            "irrelevancy": 43.25261,
            "logical_agreement": 56.30855,
            "grammar_ref": 4.92539,
            "grammar_hyp": 4.86663,
            "nubia_score": 0.87126
        },
        "meteor": 0.5965846477944291,
        "bertscore": {
            "precision": 0.97153,
            "recall": 0.98561,
            "f1": 0.97798
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_438": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185189,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.54762,
            "recall": 0.71818,
            "fmeasure": 0.62111
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.42963,
            "fmeasure": 0.35837
        },
        "rougeL": {
            "precision": 0.28571,
            "recall": 0.32576,
            "fmeasure": 0.30222
        },
        "rougeLsum": {
            "precision": 0.28571,
            "recall": 0.32576,
            "fmeasure": 0.30222
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.7777777777777778
        },
        "nist": 2.4934887525257237,
        "bleu": 12.90922,
        "bleurt": -0.15789,
        "nubia": {
            "semantic_relation": 3.24617,
            "contradiction": 98.33355,
            "irrelevancy": 0.40116,
            "logical_agreement": 1.26529,
            "grammar_ref": 5.84412,
            "grammar_hyp": 5.94298,
            "nubia_score": 0.3818
        },
        "meteor": 0.349708238419007,
        "bertscore": {
            "precision": 0.90698,
            "recall": 0.9399,
            "f1": 0.9226
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_545": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 0.5,
        "median_pred_length": 13.5,
        "min_pred_length": 13,
        "max_pred_length": 14,
        "distinct-1": 0.9259259259259259,
        "vocab_size-1": 25,
        "unique-1": 23,
        "entropy-1": 4.606739354015322,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": -0.031031312388743945,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9583333333333334,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.501629167387823,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": -0.034621791174768206,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.87762,
            "recall": 0.92803,
            "fmeasure": 0.90018
        },
        "rouge2": {
            "precision": 0.675,
            "recall": 0.72273,
            "fmeasure": 0.6969
        },
        "rougeL": {
            "precision": 0.83916,
            "recall": 0.88384,
            "fmeasure": 0.85907
        },
        "rougeLsum": {
            "precision": 0.83916,
            "recall": 0.88384,
            "fmeasure": 0.85907
        },
        "local_recall": {
            "1": 0.2,
            "2": 1.0,
            "3": 0.9473684210526315
        },
        "nist": 5.26672597061002,
        "bleu": 72.06633,
        "bleurt": 0.78803,
        "nubia": {
            "semantic_relation": 4.99125,
            "contradiction": 0.44315,
            "irrelevancy": 1.51381,
            "logical_agreement": 98.04304,
            "grammar_ref": 5.62679,
            "grammar_hyp": 5.36072,
            "nubia_score": 0.98569
        },
        "meteor": 0.5112047156689505,
        "bertscore": {
            "precision": 0.98189,
            "recall": 0.99076,
            "f1": 0.98479
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_549": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 1.0,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 15,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 24,
        "unique-1": 20,
        "entropy-1": 4.521640636343319,
        "distinct-2": 0.9615384615384616,
        "vocab_size-2": 25,
        "unique-2": 24,
        "entropy-2": 4.623516641218013,
        "cond_entropy-2": 0.04693094992964166,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.03214388408660255,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.88,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.403856189774723,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.436605434317882,
        "cond_entropy-2-nopunct": 0.05361880976054911,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.03600643804015718,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.60256,
            "recall": 0.51282,
            "fmeasure": 0.55162
        },
        "rouge2": {
            "precision": 0.34848,
            "recall": 0.29573,
            "fmeasure": 0.31829
        },
        "rougeL": {
            "precision": 0.60256,
            "recall": 0.51282,
            "fmeasure": 0.55162
        },
        "rougeLsum": {
            "precision": 0.60256,
            "recall": 0.51282,
            "fmeasure": 0.55162
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.8,
            "3": 0.43478260869565216
        },
        "nist": 3.037295363838494,
        "bleu": 14.05033,
        "bleurt": -0.04068,
        "nubia": {
            "semantic_relation": 3.70437,
            "contradiction": 0.27638,
            "irrelevancy": 73.09387,
            "logical_agreement": 26.62976,
            "grammar_ref": 4.72797,
            "grammar_hyp": 4.82982,
            "nubia_score": 0.53033
        },
        "meteor": 0.3048391841179664,
        "bertscore": {
            "precision": 0.92299,
            "recall": 0.89654,
            "f1": 0.909
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_592": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.95833,
            "recall": 1.0,
            "fmeasure": 0.97778
        },
        "rouge2": {
            "precision": 0.90476,
            "recall": 0.94444,
            "fmeasure": 0.92308
        },
        "rougeL": {
            "precision": 0.95833,
            "recall": 1.0,
            "fmeasure": 0.97778
        },
        "rougeLsum": {
            "precision": 0.95833,
            "recall": 1.0,
            "fmeasure": 0.97778
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 3.944797625754069,
        "bleu": 100.0,
        "bleurt": 0.56963,
        "nubia": {
            "semantic_relation": 4.73925,
            "contradiction": 0.27952,
            "irrelevancy": 59.63412,
            "logical_agreement": 40.08636,
            "grammar_ref": 5.97194,
            "grammar_hyp": 6.19529,
            "nubia_score": 0.89159
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_594": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 4.0,
        "median_pred_length": 18.0,
        "min_pred_length": 14,
        "max_pred_length": 22,
        "distinct-1": 0.7222222222222222,
        "vocab_size-1": 26,
        "unique-1": 21,
        "entropy-1": 4.401828211042221,
        "distinct-2": 0.9411764705882353,
        "vocab_size-2": 32,
        "unique-2": 30,
        "entropy-2": 4.969815782426808,
        "cond_entropy-2": 0.5543462061140044,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": 0.0375371587496606,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7352941176470589,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.333007416120831,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.875,
        "cond_entropy-2-nopunct": 0.5891460479497616,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": 0.040223928941851894,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.83651,
            "fmeasure": 0.7677
        },
        "rouge2": {
            "precision": 0.56827,
            "recall": 0.66946,
            "fmeasure": 0.61175
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.83651,
            "fmeasure": 0.7677
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.83651,
            "fmeasure": 0.7677
        },
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.8666666666666667,
            "3": 0.75
        },
        "nist": 4.647296101575556,
        "bleu": 59.33626,
        "bleurt": 0.50136,
        "nubia": {
            "semantic_relation": 3.62925,
            "contradiction": 49.8826,
            "irrelevancy": 0.64569,
            "logical_agreement": 49.47171,
            "grammar_ref": 4.13759,
            "grammar_hyp": 3.99814,
            "nubia_score": 0.62342
        },
        "meteor": 0.4530244829780845,
        "bertscore": {
            "precision": 0.94592,
            "recall": 0.94534,
            "f1": 0.94563
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_595": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.84375,
        "vocab_size-1": 27,
        "unique-1": 24,
        "entropy-1": 4.625,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.2402239289418518,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.450212064914748,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.2777001806988724,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86012,
            "recall": 0.89326,
            "fmeasure": 0.87176
        },
        "rouge2": {
            "precision": 0.56325,
            "recall": 0.59553,
            "fmeasure": 0.57488
        },
        "rougeL": {
            "precision": 0.70982,
            "recall": 0.73474,
            "fmeasure": 0.71761
        },
        "rougeLsum": {
            "precision": 0.70982,
            "recall": 0.73474,
            "fmeasure": 0.71761
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666,
            "3": 0.9
        },
        "nist": 4.19524391689188,
        "bleu": 36.88488,
        "bleurt": 0.43945,
        "nubia": {
            "semantic_relation": 4.89019,
            "contradiction": 0.51775,
            "irrelevancy": 14.83846,
            "logical_agreement": 84.64379,
            "grammar_ref": 4.12394,
            "grammar_hyp": 3.35519,
            "nubia_score": 0.97875
        },
        "meteor": 0.45624404159136256,
        "bertscore": {
            "precision": 0.94077,
            "recall": 0.95017,
            "f1": 0.94444
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_615": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 63,
        "mean_pred_length": 21.0,
        "std_pred_length": 4.96655480858378,
        "median_pred_length": 24.0,
        "min_pred_length": 14,
        "max_pred_length": 25,
        "distinct-1": 0.746031746031746,
        "vocab_size-1": 47,
        "unique-1": 36,
        "entropy-1": 5.388082852408431,
        "distinct-2": 0.9666666666666667,
        "vocab_size-2": 58,
        "unique-2": 56,
        "entropy-2": 5.8402239289418505,
        "cond_entropy-2": 0.40235280505193993,
        "distinct-3": 0.9824561403508771,
        "vocab_size-3": 56,
        "unique-3": 55,
        "entropy-3": 5.797802294866491,
        "cond_entropy-3": -0.038912862145531156,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 4.320493798938574,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7962962962962963,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.266655502596795,
        "distinct-2-nopunct": 0.9803921568627451,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.63320965569699,
        "cond_entropy-2-nopunct": 0.3952736824864638,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.5849625007211605,
        "cond_entropy-3-nopunct": -0.04579617458367275,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76688,
            "recall": 0.72216,
            "fmeasure": 0.74065
        },
        "rouge2": {
            "precision": 0.49043,
            "recall": 0.47029,
            "fmeasure": 0.47737
        },
        "rougeL": {
            "precision": 0.61264,
            "recall": 0.59342,
            "fmeasure": 0.59944
        },
        "rougeLsum": {
            "precision": 0.61264,
            "recall": 0.59342,
            "fmeasure": 0.59944
        },
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.11764705882352941,
            "3": 0.7222222222222222
        },
        "nist": 4.038539502265539,
        "bleu": 29.79743,
        "bleurt": -0.07658,
        "nubia": {
            "semantic_relation": 4.2652,
            "contradiction": 0.60162,
            "irrelevancy": 17.21673,
            "logical_agreement": 82.18165,
            "grammar_ref": 4.60968,
            "grammar_hyp": 4.62791,
            "nubia_score": 0.60758
        },
        "meteor": 0.3211215693807884,
        "bertscore": {
            "precision": 0.879,
            "recall": 0.86743,
            "f1": 0.87309
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_600": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.8205128205128205,
        "vocab_size-1": 32,
        "unique-1": 28,
        "entropy-1": 4.855789718806774,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.2178561159133975,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 11.333333333333334,
        "std_pred_length-nopunct": 0.4714045207910317,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.793345194191515,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.18931411429782616,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.14684138832927116,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81566,
            "recall": 0.76481,
            "fmeasure": 0.77352
        },
        "rouge2": {
            "precision": 0.52121,
            "recall": 0.57829,
            "fmeasure": 0.53084
        },
        "rougeL": {
            "precision": 0.64899,
            "recall": 0.69213,
            "fmeasure": 0.65038
        },
        "rougeLsum": {
            "precision": 0.64899,
            "recall": 0.69213,
            "fmeasure": 0.65038
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.3333333333333333,
            "3": 0.78125
        },
        "nist": 3.880444790545157,
        "bleu": 34.80151,
        "bleurt": 0.07679,
        "nubia": {
            "semantic_relation": 3.86291,
            "contradiction": 2.64404,
            "irrelevancy": 78.33233,
            "logical_agreement": 19.02364,
            "grammar_ref": 4.26152,
            "grammar_hyp": 4.45245,
            "nubia_score": 0.61506
        },
        "meteor": 0.39704743049134095,
        "bertscore": {
            "precision": 0.91124,
            "recall": 0.92661,
            "f1": 0.91433
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_550": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 41,
        "mean_pred_length": 20.5,
        "std_pred_length": 8.5,
        "median_pred_length": 20.5,
        "min_pred_length": 12,
        "max_pred_length": 29,
        "distinct-1": 0.9024390243902439,
        "vocab_size-1": 37,
        "unique-1": 33,
        "entropy-1": 5.16243005339857,
        "distinct-2": 1.0,
        "vocab_size-2": 39,
        "unique-2": 39,
        "entropy-2": 5.285402218862247,
        "cond_entropy-2": 0.08169636809031879,
        "distinct-3": 1.0,
        "vocab_size-3": 37,
        "unique-3": 37,
        "entropy-3": 5.209453365628954,
        "cond_entropy-3": -0.07594885323329875,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.9428571428571428,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.01499730265925,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.03632322362560796,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.09019780897157811,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72667,
            "recall": 0.74986,
            "fmeasure": 0.72973
        },
        "rouge2": {
            "precision": 0.36944,
            "recall": 0.39112,
            "fmeasure": 0.37849
        },
        "rougeL": {
            "precision": 0.44364,
            "recall": 0.45618,
            "fmeasure": 0.44469
        },
        "rougeLsum": {
            "precision": 0.44364,
            "recall": 0.45618,
            "fmeasure": 0.44469
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.08333333333333333,
            "3": 0.8571428571428571
        },
        "nist": 4.08774256381359,
        "bleu": 34.73338,
        "bleurt": 0.29824,
        "nubia": {
            "semantic_relation": 4.2826,
            "contradiction": 0.31161,
            "irrelevancy": 17.07238,
            "logical_agreement": 82.61602,
            "grammar_ref": 4.42501,
            "grammar_hyp": 4.20396,
            "nubia_score": 0.76098
        },
        "meteor": 0.4143729850584737,
        "bertscore": {
            "precision": 0.93405,
            "recall": 0.93099,
            "f1": 0.92717
        }
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 457,
        "msttr-100": 0.50785,
        "msttr-100_nopunct": 0.51299,
        "total_length": 14413,
        "mean_pred_length": 31.538293216630198,
        "std_pred_length": 12.645960068671897,
        "median_pred_length": 29.0,
        "min_pred_length": 8,
        "max_pred_length": 80,
        "distinct-1": 0.0961631860126275,
        "vocab_size-1": 1386,
        "unique-1": 573,
        "entropy-1": 7.827218570749708,
        "distinct-2": 0.29492691315563196,
        "vocab_size-2": 4116,
        "unique-2": 2384,
        "entropy-2": 10.807658294286872,
        "cond_entropy-2": 2.85802444423957,
        "distinct-3": 0.4661086006370842,
        "vocab_size-3": 6292,
        "unique-3": 4373,
        "entropy-3": 11.835077867792316,
        "cond_entropy-3": 1.069390004985263,
        "total_length-nopunct": 12738,
        "mean_pred_length-nopunct": 27.87308533916849,
        "std_pred_length-nopunct": 11.298093306506203,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 71,
        "distinct-1-nopunct": 0.10810174281676872,
        "vocab_size-1-nopunct": 1377,
        "unique-1-nopunct": 572,
        "entropy-1-nopunct": 8.07548310062219,
        "distinct-2-nopunct": 0.3081996580083055,
        "vocab_size-2-nopunct": 3785,
        "unique-2-nopunct": 2269,
        "entropy-2-nopunct": 10.71477424410136,
        "cond_entropy-2-nopunct": 2.7360550633552188,
        "distinct-3-nopunct": 0.47919485791610283,
        "vocab_size-3-nopunct": 5666,
        "unique-3-nopunct": 4012,
        "entropy-3-nopunct": 11.69101866498557,
        "cond_entropy-3-nopunct": 1.0058833813686157,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.68922,
            "recall": 0.67411,
            "fmeasure": 0.67437
        },
        "rouge2": {
            "precision": 0.40407,
            "recall": 0.39538,
            "fmeasure": 0.39528
        },
        "rougeL": {
            "precision": 0.49966,
            "recall": 0.48949,
            "fmeasure": 0.48903
        },
        "rougeLsum": {
            "precision": 0.49966,
            "recall": 0.48949,
            "fmeasure": 0.48903
        },
        "local_recall": {
            "1": 0.22845441595441596,
            "2": 0.5521684475172848,
            "3": 0.8121143228320883,
            "4": 0.25,
            "5": 0.875
        },
        "nist": 7.759878856038498,
        "bleu": 40.90524,
        "bleurt": -0.06094,
        "nubia": {
            "semantic_relation": 4.04995,
            "contradiction": 15.1663,
            "irrelevancy": 10.78054,
            "logical_agreement": 74.05316,
            "grammar_ref": 4.37649,
            "grammar_hyp": 4.39343,
            "nubia_score": 0.68386
        },
        "meteor": 0.3460865738849042,
        "bertscore": {
            "precision": 0.89697,
            "recall": 0.8945,
            "f1": 0.89441
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_516": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 92,
        "mean_pred_length": 23.0,
        "std_pred_length": 8.514693182963201,
        "median_pred_length": 21.0,
        "min_pred_length": 14,
        "max_pred_length": 36,
        "distinct-1": 0.7282608695652174,
        "vocab_size-1": 67,
        "unique-1": 56,
        "entropy-1": 5.8253137934752015,
        "distinct-2": 0.9772727272727273,
        "vocab_size-2": 86,
        "unique-2": 84,
        "entropy-2": 6.41397707318276,
        "cond_entropy-2": 0.529492741643096,
        "distinct-3": 1.0,
        "vocab_size-3": 84,
        "unique-3": 84,
        "entropy-3": 6.39231742277876,
        "cond_entropy-3": -0.01949514823948912,
        "total_length-nopunct": 77,
        "mean_pred_length-nopunct": 19.25,
        "std_pred_length-nopunct": 5.402545696243577,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 63,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.810690235775894,
        "distinct-2-nopunct": 0.9863013698630136,
        "vocab_size-2-nopunct": 72,
        "unique-2-nopunct": 71,
        "entropy-2-nopunct": 6.162427298606055,
        "cond_entropy-2-nopunct": 0.37672864118188,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 69,
        "unique-3-nopunct": 69,
        "entropy-3-nopunct": 6.108524456778164,
        "cond_entropy-3-nopunct": -0.05231459485547146,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.809,
            "recall": 0.78184,
            "fmeasure": 0.77462
        },
        "rouge2": {
            "precision": 0.47958,
            "recall": 0.44284,
            "fmeasure": 0.44674
        },
        "rougeL": {
            "precision": 0.65203,
            "recall": 0.64221,
            "fmeasure": 0.63077
        },
        "rougeLsum": {
            "precision": 0.65203,
            "recall": 0.64221,
            "fmeasure": 0.63077
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.6,
            "3": 0.7761194029850746
        },
        "nist": 5.06087370748274,
        "bleu": 37.50521,
        "bleurt": 0.12966,
        "nubia": {
            "semantic_relation": 4.37911,
            "contradiction": 1.8744,
            "irrelevancy": 23.9223,
            "logical_agreement": 74.2033,
            "grammar_ref": 4.38942,
            "grammar_hyp": 4.48734,
            "nubia_score": 0.73532
        },
        "meteor": 0.3957756776925945,
        "bertscore": {
            "precision": 0.92921,
            "recall": 0.91499,
            "f1": 0.91817
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_519": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.69841,
            "fmeasure": 0.82222
        },
        "rouge2": {
            "precision": 0.74074,
            "recall": 0.50183,
            "fmeasure": 0.59816
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 0.62857,
            "fmeasure": 0.74
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 0.62857,
            "fmeasure": 0.74
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9090909090909091
        },
        "nist": 2.6330370023236713,
        "bleu": 42.95749,
        "bleurt": 0.45492,
        "nubia": {
            "semantic_relation": 4.97277,
            "contradiction": 0.35627,
            "irrelevancy": 0.48729,
            "logical_agreement": 99.15644,
            "grammar_ref": 5.37123,
            "grammar_hyp": 6.85358,
            "nubia_score": 0.74277
        },
        "meteor": 0.42350497485471644,
        "bertscore": {
            "precision": 0.98201,
            "recall": 0.93212,
            "f1": 0.95641
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_552": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 60,
        "mean_pred_length": 20.0,
        "std_pred_length": 5.0990195135927845,
        "median_pred_length": 18.0,
        "min_pred_length": 15,
        "max_pred_length": 27,
        "distinct-1": 0.7166666666666667,
        "vocab_size-1": 43,
        "unique-1": 36,
        "entropy-1": 5.167481795998513,
        "distinct-2": 1.0,
        "vocab_size-2": 57,
        "unique-2": 57,
        "entropy-2": 5.832890014164737,
        "cond_entropy-2": 0.5990613128825437,
        "distinct-3": 1.0,
        "vocab_size-3": 54,
        "unique-3": 54,
        "entropy-3": 5.7548875021634665,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 17.333333333333332,
        "std_pred_length-nopunct": 4.189935029992178,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7884615384615384,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.154968026283396,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.614709844115208,
        "cond_entropy-2-nopunct": 0.4931380438639181,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.5235619560570095,
        "cond_entropy-3-nopunct": -0.09114788805819536,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.40226,
            "recall": 0.57506,
            "fmeasure": 0.4653
        },
        "rouge2": {
            "precision": 0.13194,
            "recall": 0.23675,
            "fmeasure": 0.16889
        },
        "rougeL": {
            "precision": 0.30016,
            "recall": 0.44076,
            "fmeasure": 0.35176
        },
        "rougeLsum": {
            "precision": 0.30016,
            "recall": 0.44076,
            "fmeasure": 0.35176
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.6206896551724138
        },
        "nist": 2.2675017180093877,
        "bleu": 15.63028,
        "bleurt": -0.2243,
        "nubia": {
            "semantic_relation": 3.433,
            "contradiction": 2.68725,
            "irrelevancy": 64.17821,
            "logical_agreement": 33.13454,
            "grammar_ref": 4.76688,
            "grammar_hyp": 4.36835,
            "nubia_score": 0.5289
        },
        "meteor": 0.2978157150229278,
        "bertscore": {
            "precision": 0.81746,
            "recall": 0.89571,
            "f1": 0.85197
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_603": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.8076923076923077,
        "vocab_size-1": 21,
        "unique-1": 18,
        "entropy-1": 4.238901256602629,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.42341647163363244,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7916666666666666,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.084962500721157,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.4603385857706395,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.06413033741971555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.84722,
            "recall": 0.66883,
            "fmeasure": 0.74163
        },
        "rouge2": {
            "precision": 0.71014,
            "recall": 0.55556,
            "fmeasure": 0.61817
        },
        "rougeL": {
            "precision": 0.80556,
            "recall": 0.63174,
            "fmeasure": 0.70186
        },
        "rougeLsum": {
            "precision": 0.80556,
            "recall": 0.63174,
            "fmeasure": 0.70186
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8095238095238095
        },
        "nist": 1.873534918451332,
        "bleu": 51.7928,
        "bleurt": 0.06217,
        "nubia": {
            "semantic_relation": 2.48766,
            "contradiction": 99.68673,
            "irrelevancy": 0.14927,
            "logical_agreement": 0.164,
            "grammar_ref": 3.4256,
            "grammar_hyp": 3.31478,
            "nubia_score": 0.24162
        },
        "meteor": 0.39846682060596106,
        "bertscore": {
            "precision": 0.9511,
            "recall": 0.89951,
            "f1": 0.92459
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-large (Baseline)/e2e_nlg_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 87,
        "mean_pred_length": 17.4,
        "std_pred_length": 6.468384651518491,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.45977011494252873,
        "vocab_size-1": 40,
        "unique-1": 16,
        "entropy-1": 4.998521048460822,
        "distinct-2": 0.6463414634146342,
        "vocab_size-2": 53,
        "unique-2": 27,
        "entropy-2": 5.606214925661532,
        "cond_entropy-2": 0.5245882385013462,
        "distinct-3": 0.6753246753246753,
        "vocab_size-3": 52,
        "unique-3": 27,
        "entropy-3": 5.617435891344253,
        "cond_entropy-3": 0.03403506171885395,
        "total_length-nopunct": 78,
        "mean_pred_length-nopunct": 15.6,
        "std_pred_length-nopunct": 6.248199740725323,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.48717948717948717,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.951898776960389,
        "distinct-2-nopunct": 0.6301369863013698,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 5.400651401695949,
        "cond_entropy-2-nopunct": 0.49097940156827363,
        "distinct-3-nopunct": 0.6617647058823529,
        "vocab_size-3-nopunct": 45,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 5.410992253015043,
        "cond_entropy-3-nopunct": 0.0389565246414519,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.36632,
            "recall": 0.5083,
            "fmeasure": 0.41641
        },
        "rouge2": {
            "precision": 0.13408,
            "recall": 0.19318,
            "fmeasure": 0.15392
        },
        "rougeL": {
            "precision": 0.31608,
            "recall": 0.45271,
            "fmeasure": 0.36412
        },
        "rougeLsum": {
            "precision": 0.31608,
            "recall": 0.45271,
            "fmeasure": 0.36412
        },
        "local_recall": {
            "1": 0.4642857142857143
        },
        "nist": 1.7664093606069138,
        "bleu": 6.78861,
        "bleurt": -0.62953,
        "nubia": {
            "semantic_relation": 3.02299,
            "contradiction": 0.39609,
            "irrelevancy": 97.46942,
            "logical_agreement": 2.13449,
            "grammar_ref": 5.06674,
            "grammar_hyp": 5.12535,
            "nubia_score": 0.44456
        },
        "meteor": 0.20055776152809543,
        "bertscore": {
            "precision": 0.82998,
            "recall": 0.84818,
            "f1": 0.83875
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_520": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.78,
        "msttr-100_nopunct": NaN,
        "total_length": 103,
        "mean_pred_length": 14.714285714285714,
        "std_pred_length": 3.4522988495984492,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 20,
        "distinct-1": 0.7766990291262136,
        "vocab_size-1": 80,
        "unique-1": 70,
        "entropy-1": 6.073690668166107,
        "distinct-2": 1.0,
        "vocab_size-2": 96,
        "unique-2": 96,
        "entropy-2": 6.5849625007211605,
        "cond_entropy-2": 0.33720588477505997,
        "distinct-3": 1.0,
        "vocab_size-3": 89,
        "unique-3": 89,
        "entropy-3": 6.47573343096641,
        "cond_entropy-3": -0.10922906975475832,
        "total_length-nopunct": 89,
        "mean_pred_length-nopunct": 12.714285714285714,
        "std_pred_length-nopunct": 2.762725657973388,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8651685393258427,
        "vocab_size-1-nopunct": 77,
        "unique-1-nopunct": 69,
        "entropy-1-nopunct": 6.1666348354121725,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 82,
        "unique-2-nopunct": 82,
        "entropy-2-nopunct": 6.357552004618087,
        "cond_entropy-2-nopunct": 0.21730363468006322,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 75,
        "unique-3-nopunct": 75,
        "entropy-3-nopunct": 6.228818690495891,
        "cond_entropy-3-nopunct": -0.12873331412220293,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72104,
            "recall": 0.68167,
            "fmeasure": 0.68657
        },
        "rouge2": {
            "precision": 0.5085,
            "recall": 0.49668,
            "fmeasure": 0.49382
        },
        "rougeL": {
            "precision": 0.66212,
            "recall": 0.63092,
            "fmeasure": 0.6346
        },
        "rougeLsum": {
            "precision": 0.66212,
            "recall": 0.63092,
            "fmeasure": 0.6346
        },
        "local_recall": {
            "1": 0.05263157894736842,
            "2": 0.35714285714285715,
            "3": 0.7391304347826086
        },
        "nist": 4.2622929333760595,
        "bleu": 41.74047,
        "bleurt": 0.28739,
        "nubia": {
            "semantic_relation": 3.89116,
            "contradiction": 7.38111,
            "irrelevancy": 65.3729,
            "logical_agreement": 27.246,
            "grammar_ref": 4.63553,
            "grammar_hyp": 4.6717,
            "nubia_score": 0.64462
        },
        "meteor": 0.3623799697661229,
        "bertscore": {
            "precision": 0.91501,
            "recall": 0.91299,
            "f1": 0.90939
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_604": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432272,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.96296,
            "fmeasure": 0.91228
        },
        "rouge2": {
            "precision": 0.7037,
            "recall": 0.79167,
            "fmeasure": 0.7451
        },
        "rougeL": {
            "precision": 0.76667,
            "recall": 0.85185,
            "fmeasure": 0.80702
        },
        "rougeLsum": {
            "precision": 0.76667,
            "recall": 0.85185,
            "fmeasure": 0.80702
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.5020969067098413,
        "bleu": 47.90438,
        "bleurt": 0.58148,
        "nubia": {
            "semantic_relation": 4.97032,
            "contradiction": 0.3094,
            "irrelevancy": 0.50799,
            "logical_agreement": 99.18261,
            "grammar_ref": 6.26263,
            "grammar_hyp": 6.06017,
            "nubia_score": 0.98655
        },
        "meteor": 0.45394045114632486,
        "bertscore": {
            "precision": 0.96523,
            "recall": 0.9443,
            "f1": 0.95465
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_553": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 57,
        "mean_pred_length": 19.0,
        "std_pred_length": 9.797958971132712,
        "median_pred_length": 19.0,
        "min_pred_length": 7,
        "max_pred_length": 31,
        "distinct-1": 0.7894736842105263,
        "vocab_size-1": 45,
        "unique-1": 38,
        "entropy-1": 5.322023075940812,
        "distinct-2": 0.9814814814814815,
        "vocab_size-2": 53,
        "unique-2": 52,
        "entropy-2": 5.717850465126429,
        "cond_entropy-2": 0.3361554134913245,
        "distinct-3": 1.0,
        "vocab_size-3": 51,
        "unique-3": 51,
        "entropy-3": 5.6724253419715005,
        "cond_entropy-3": -0.04324647391746317,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 6.018490028422596,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9302325581395349,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.26917434767504,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.3219280948873635,
        "cond_entropy-2-nopunct": 0.06453552773935088,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.11247472925841272,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.58571,
            "recall": 0.57261,
            "fmeasure": 0.57751
        },
        "rouge2": {
            "precision": 0.29142,
            "recall": 0.27046,
            "fmeasure": 0.27963
        },
        "rougeL": {
            "precision": 0.4873,
            "recall": 0.47271,
            "fmeasure": 0.4786
        },
        "rougeLsum": {
            "precision": 0.4873,
            "recall": 0.47271,
            "fmeasure": 0.4786
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.5652173913043478,
            "3": 0.47058823529411764
        },
        "nist": 3.084723694142217,
        "bleu": 13.53517,
        "bleurt": -0.15597,
        "nubia": {
            "semantic_relation": 3.94652,
            "contradiction": 0.79758,
            "irrelevancy": 56.63616,
            "logical_agreement": 42.56626,
            "grammar_ref": 4.61531,
            "grammar_hyp": 5.34991,
            "nubia_score": 0.60626
        },
        "meteor": 0.2588666670982242,
        "bertscore": {
            "precision": 0.87664,
            "recall": 0.90225,
            "f1": 0.88897
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_555": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.3764992953429935,
        "bleu": 100.0,
        "bleurt": 0.91462,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.23486,
            "irrelevancy": 0.53273,
            "logical_agreement": 99.23241,
            "grammar_ref": 4.18747,
            "grammar_hyp": 4.4235,
            "nubia_score": 0.98266
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_560": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 7.788880963698615,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.8125,
        "vocab_size-1": 39,
        "unique-1": 31,
        "entropy-1": 5.194235677759421,
        "distinct-2": 0.9555555555555556,
        "vocab_size-2": 43,
        "unique-2": 41,
        "entropy-2": 5.402964207440784,
        "cond_entropy-2": 0.1291128178307405,
        "distinct-3": 0.9761904761904762,
        "vocab_size-3": 41,
        "unique-3": 40,
        "entropy-3": 5.344698375159715,
        "cond_entropy-3": -0.051916625931866786,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 6.018490028422597,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.0719280948873635,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.209453365628954,
        "cond_entropy-2-nopunct": 0.13076851398483053,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.12199052437861026,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65709,
            "recall": 0.56465,
            "fmeasure": 0.60407
        },
        "rouge2": {
            "precision": 0.32346,
            "recall": 0.2963,
            "fmeasure": 0.30876
        },
        "rougeL": {
            "precision": 0.52039,
            "recall": 0.44881,
            "fmeasure": 0.47867
        },
        "rougeLsum": {
            "precision": 0.52039,
            "recall": 0.44881,
            "fmeasure": 0.47867
        },
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.0,
            "3": 0.75
        },
        "nist": 3.8669590923733117,
        "bleu": 31.56091,
        "bleurt": 0.13862,
        "nubia": {
            "semantic_relation": 4.02604,
            "contradiction": 9.56486,
            "irrelevancy": 12.37084,
            "logical_agreement": 78.0643,
            "grammar_ref": 4.73268,
            "grammar_hyp": 5.05355,
            "nubia_score": 0.64476
        },
        "meteor": 0.36991688130773337,
        "bertscore": {
            "precision": 0.9121,
            "recall": 0.88569,
            "f1": 0.89848
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_522": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.7727272727272727,
        "vocab_size-1": 17,
        "unique-1": 13,
        "entropy-1": 3.970573095811684,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.4450233042444856,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.7841837197791883,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.4394145502490373,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5873,
            "recall": 0.88622,
            "fmeasure": 0.70482
        },
        "rouge2": {
            "precision": 0.38333,
            "recall": 0.6,
            "fmeasure": 0.46667
        },
        "rougeL": {
            "precision": 0.52381,
            "recall": 0.79327,
            "fmeasure": 0.62957
        },
        "rougeLsum": {
            "precision": 0.52381,
            "recall": 0.79327,
            "fmeasure": 0.62957
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9166666666666666
        },
        "nist": 2.3606435552583798,
        "bleu": 30.18385,
        "bleurt": 0.62715,
        "nubia": {
            "semantic_relation": 4.76561,
            "contradiction": 0.11845,
            "irrelevancy": 27.05406,
            "logical_agreement": 72.82749,
            "grammar_ref": 4.55634,
            "grammar_hyp": 3.47814,
            "nubia_score": 0.96793
        },
        "meteor": 0.44299825550590827,
        "bertscore": {
            "precision": 0.87719,
            "recall": 0.96356,
            "f1": 0.91835
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_616": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 11.0,
        "std_pred_length": 2.9154759474226504,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 15,
        "distinct-1": 0.7727272727272727,
        "vocab_size-1": 34,
        "unique-1": 28,
        "entropy-1": 4.913977073182751,
        "distinct-2": 1.0,
        "vocab_size-2": 40,
        "unique-2": 40,
        "entropy-2": 5.3219280948873635,
        "cond_entropy-2": 0.2624964762500649,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 2.692582403567252,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.879506460812008,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.087462841250338,
        "cond_entropy-2-nopunct": 0.25130003368910686,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.18057224564182076,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82234,
            "recall": 0.71701,
            "fmeasure": 0.74765
        },
        "rouge2": {
            "precision": 0.66319,
            "recall": 0.61539,
            "fmeasure": 0.62586
        },
        "rougeL": {
            "precision": 0.77701,
            "recall": 0.7092,
            "fmeasure": 0.73008
        },
        "rougeLsum": {
            "precision": 0.77701,
            "recall": 0.7092,
            "fmeasure": 0.73008
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "nist": 4.408292501641833,
        "bleu": 54.54618,
        "bleurt": 0.36101,
        "nubia": {
            "semantic_relation": 4.09325,
            "contradiction": 20.38043,
            "irrelevancy": 13.57623,
            "logical_agreement": 66.04333,
            "grammar_ref": 4.6519,
            "grammar_hyp": 5.08443,
            "nubia_score": 0.68291
        },
        "meteor": 0.40416366725083297,
        "bertscore": {
            "precision": 0.93527,
            "recall": 0.91997,
            "f1": 0.92497
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_605": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.94872,
            "recall": 0.725,
            "fmeasure": 0.81992
        },
        "rouge2": {
            "precision": 0.91667,
            "recall": 0.69123,
            "fmeasure": 0.78614
        },
        "rougeL": {
            "precision": 0.94872,
            "recall": 0.725,
            "fmeasure": 0.81992
        },
        "rougeLsum": {
            "precision": 0.94872,
            "recall": 0.725,
            "fmeasure": 0.81992
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.75
        },
        "nist": 2.4090636926463773,
        "bleu": 71.92017,
        "bleurt": 0.39244,
        "nubia": {
            "semantic_relation": 3.76609,
            "contradiction": 0.20429,
            "irrelevancy": 1.0493,
            "logical_agreement": 98.74641,
            "grammar_ref": 3.95052,
            "grammar_hyp": 4.64234,
            "nubia_score": 0.5936
        },
        "meteor": 0.46533854723503365,
        "bertscore": {
            "precision": 0.98531,
            "recall": 0.92036,
            "f1": 0.95173
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_606": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 10.0,
        "std_pred_length": 1.5811388300841898,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 12,
        "distinct-1": 0.775,
        "vocab_size-1": 31,
        "unique-1": 27,
        "entropy-1": 4.731687083026443,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.2815980308448616,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.16992500144231223,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 8.75,
        "std_pred_length-nopunct": 1.299038105676658,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.8285714285714286,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.683293289103912,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.3284500829398703,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.19930880822340663,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71875,
            "recall": 0.69008,
            "fmeasure": 0.69614
        },
        "rouge2": {
            "precision": 0.52116,
            "recall": 0.44922,
            "fmeasure": 0.48076
        },
        "rougeL": {
            "precision": 0.70208,
            "recall": 0.66786,
            "fmeasure": 0.67684
        },
        "rougeLsum": {
            "precision": 0.70208,
            "recall": 0.66786,
            "fmeasure": 0.67684
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.5,
            "3": 0.72
        },
        "nist": 4.397976761954545,
        "bleu": 47.82859,
        "bleurt": 0.32817,
        "nubia": {
            "semantic_relation": 3.99158,
            "contradiction": 11.46308,
            "irrelevancy": 24.49972,
            "logical_agreement": 64.0372,
            "grammar_ref": 4.98306,
            "grammar_hyp": 4.42373,
            "nubia_score": 0.66878
        },
        "meteor": 0.4090380110481072,
        "bertscore": {
            "precision": 0.92199,
            "recall": 0.92506,
            "f1": 0.92241
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_618": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 49,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 2.494438257849294,
        "median_pred_length": 17.0,
        "min_pred_length": 13,
        "max_pred_length": 19,
        "distinct-1": 0.8163265306122449,
        "vocab_size-1": 40,
        "unique-1": 34,
        "entropy-1": 5.201145303166425,
        "distinct-2": 0.9782608695652174,
        "vocab_size-2": 45,
        "unique-2": 44,
        "entropy-2": 5.480083695187444,
        "cond_entropy-2": 0.20254287290543355,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.0507855734479384,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 2.449489742783178,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8444444444444444,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.1471914295668535,
        "distinct-2-nopunct": 0.9761904761904762,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.344698375159714,
        "cond_entropy-2-nopunct": 0.2221256360759175,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": -0.05563315263446055,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.697,
            "recall": 0.70138,
            "fmeasure": 0.68353
        },
        "rouge2": {
            "precision": 0.51582,
            "recall": 0.45793,
            "fmeasure": 0.48086
        },
        "rougeL": {
            "precision": 0.62025,
            "recall": 0.58891,
            "fmeasure": 0.59095
        },
        "rougeLsum": {
            "precision": 0.62025,
            "recall": 0.58891,
            "fmeasure": 0.59095
        },
        "local_recall": {
            "1": 0.1875,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "nist": 3.861226844070754,
        "bleu": 39.83744,
        "bleurt": 0.09789,
        "nubia": {
            "semantic_relation": 3.93079,
            "contradiction": 0.25983,
            "irrelevancy": 66.45812,
            "logical_agreement": 33.28205,
            "grammar_ref": 4.66623,
            "grammar_hyp": 4.0283,
            "nubia_score": 0.73315
        },
        "meteor": 0.3693821911176916,
        "bertscore": {
            "precision": 0.90457,
            "recall": 0.90689,
            "f1": 0.89962
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_608": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 2.5,
        "median_pred_length": 14.5,
        "min_pred_length": 12,
        "max_pred_length": 17,
        "distinct-1": 0.7586206896551724,
        "vocab_size-1": 22,
        "unique-1": 15,
        "entropy-1": 4.375222374437917,
        "distinct-2": 0.8518518518518519,
        "vocab_size-2": 23,
        "unique-2": 19,
        "entropy-2": 4.458591205867174,
        "cond_entropy-2": 0.04505465518404472,
        "distinct-3": 0.92,
        "vocab_size-3": 23,
        "unique-3": 21,
        "entropy-3": 4.4838561897747224,
        "cond_entropy-3": 0.04896868761125604,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.310443057719025,
        "distinct-2-nopunct": 0.84,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.323856189774723,
        "cond_entropy-2-nopunct": 0.008968687611256035,
        "distinct-3-nopunct": 0.9130434782608695,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.349648912578752,
        "cond_entropy-3-nopunct": 0.010140548890983897,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.69034,
            "recall": 0.78791,
            "fmeasure": 0.73547
        },
        "rouge2": {
            "precision": 0.47222,
            "recall": 0.52259,
            "fmeasure": 0.49609
        },
        "rougeL": {
            "precision": 0.67992,
            "recall": 0.74524,
            "fmeasure": 0.71101
        },
        "rougeLsum": {
            "precision": 0.67992,
            "recall": 0.74524,
            "fmeasure": 0.71101
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.8095238095238095
        },
        "nist": 3.318902481423803,
        "bleu": 42.5608,
        "bleurt": 0.51152,
        "nubia": {
            "semantic_relation": 4.79617,
            "contradiction": 0.25196,
            "irrelevancy": 17.25534,
            "logical_agreement": 82.4927,
            "grammar_ref": 4.34398,
            "grammar_hyp": 4.54089,
            "nubia_score": 0.88356
        },
        "meteor": 0.4228755295950793,
        "bertscore": {
            "precision": 0.92053,
            "recall": 0.92962,
            "f1": 0.92505
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_620": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 29.0,
        "std_pred_length": 0.0,
        "median_pred_length": 29.0,
        "min_pred_length": 29,
        "max_pred_length": 29,
        "distinct-1": 0.6551724137931034,
        "vocab_size-1": 19,
        "unique-1": 11,
        "entropy-1": 4.0993603054724,
        "distinct-2": 0.8928571428571429,
        "vocab_size-2": 25,
        "unique-2": 22,
        "entropy-2": 4.593069207771891,
        "cond_entropy-2": 0.5208024983586034,
        "distinct-3": 0.9259259259259259,
        "vocab_size-3": 25,
        "unique-3": 23,
        "entropy-3": 4.606739354015322,
        "cond_entropy-3": 0.02160665417993861,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.64,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.843856189774723,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.418295834054489,
        "cond_entropy-2-nopunct": 0.6077729776130986,
        "distinct-3-nopunct": 0.9565217391304348,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.436605434317882,
        "cond_entropy-3-nopunct": 0.02555597707498716,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.68452,
            "fmeasure": 0.44778
        },
        "rouge2": {
            "precision": 0.17308,
            "recall": 0.36713,
            "fmeasure": 0.23493
        },
        "rougeL": {
            "precision": 0.2037,
            "recall": 0.41667,
            "fmeasure": 0.2733
        },
        "rougeLsum": {
            "precision": 0.2037,
            "recall": 0.41667,
            "fmeasure": 0.2733
        },
        "local_recall": {
            "1": 0.45454545454545453,
            "2": 0.8571428571428571
        },
        "nist": 2.0190232508494965,
        "bleu": 19.61887,
        "bleurt": -0.02285,
        "nubia": {
            "semantic_relation": 4.02814,
            "contradiction": 0.29518,
            "irrelevancy": 96.93468,
            "logical_agreement": 2.77015,
            "grammar_ref": 5.74657,
            "grammar_hyp": 3.59453,
            "nubia_score": 0.59411
        },
        "meteor": 0.3122951727931994,
        "bertscore": {
            "precision": 0.79355,
            "recall": 0.89136,
            "f1": 0.83609
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_440": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.79,
        "msttr-100_nopunct": 0.83,
        "total_length": 136,
        "mean_pred_length": 17.0,
        "std_pred_length": 4.58257569495584,
        "median_pred_length": 16.5,
        "min_pred_length": 12,
        "max_pred_length": 25,
        "distinct-1": 0.7573529411764706,
        "vocab_size-1": 103,
        "unique-1": 91,
        "entropy-1": 6.373349492141775,
        "distinct-2": 0.9921875,
        "vocab_size-2": 127,
        "unique-2": 126,
        "entropy-2": 6.984375,
        "cond_entropy-2": 0.4681575921775015,
        "distinct-3": 1.0,
        "vocab_size-3": 120,
        "unique-3": 120,
        "entropy-3": 6.906890595608536,
        "cond_entropy-3": -0.07644273772481483,
        "total_length-nopunct": 120,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 4.444097208657794,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.825,
        "vocab_size-1-nopunct": 99,
        "unique-1-nopunct": 89,
        "entropy-1-nopunct": 6.426810258321558,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 112,
        "unique-2-nopunct": 112,
        "entropy-2-nopunct": 6.807354922057591,
        "cond_entropy-2-nopunct": 0.4148361163994147,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 104,
        "unique-3-nopunct": 104,
        "entropy-3-nopunct": 6.7004397181411,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72452,
            "recall": 0.7371,
            "fmeasure": 0.72337
        },
        "rouge2": {
            "precision": 0.46518,
            "recall": 0.47949,
            "fmeasure": 0.46348
        },
        "rougeL": {
            "precision": 0.56661,
            "recall": 0.57589,
            "fmeasure": 0.56021
        },
        "rougeLsum": {
            "precision": 0.56661,
            "recall": 0.57589,
            "fmeasure": 0.56021
        },
        "local_recall": {
            "1": 0.2682926829268293,
            "2": 0.52,
            "3": 0.8695652173913043
        },
        "nist": 5.22868582845406,
        "bleu": 35.01208,
        "bleurt": 0.03197,
        "nubia": {
            "semantic_relation": 3.66953,
            "contradiction": 12.90611,
            "irrelevancy": 45.11313,
            "logical_agreement": 41.98075,
            "grammar_ref": 4.83092,
            "grammar_hyp": 4.61031,
            "nubia_score": 0.58413
        },
        "meteor": 0.38732258757167964,
        "bertscore": {
            "precision": 0.89682,
            "recall": 0.91064,
            "f1": 0.90065
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_441": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 2.0548046676563256,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 18,
        "distinct-1": 0.8085106382978723,
        "vocab_size-1": 38,
        "unique-1": 31,
        "entropy-1": 5.139487255840896,
        "distinct-2": 1.0,
        "vocab_size-2": 44,
        "unique-2": 44,
        "entropy-2": 5.4594316186372955,
        "cond_entropy-2": 0.2401811192815566,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.10187961401921372,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 2.494438257849294,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 5.003055907333277,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.209453365628954,
        "cond_entropy-2-nopunct": 0.23225195998924852,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.12199052437861026,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.57524,
            "recall": 0.61106,
            "fmeasure": 0.56596
        },
        "rouge2": {
            "precision": 0.36595,
            "recall": 0.39293,
            "fmeasure": 0.35879
        },
        "rougeL": {
            "precision": 0.57524,
            "recall": 0.61106,
            "fmeasure": 0.56596
        },
        "rougeLsum": {
            "precision": 0.57524,
            "recall": 0.61106,
            "fmeasure": 0.56596
        },
        "local_recall": {
            "1": 0.24242424242424243,
            "2": 0.75
        },
        "nist": 3.595153178733854,
        "bleu": 38.39213,
        "bleurt": -0.10112,
        "nubia": {
            "semantic_relation": 3.36841,
            "contradiction": 13.51354,
            "irrelevancy": 75.46341,
            "logical_agreement": 11.02305,
            "grammar_ref": 5.06451,
            "grammar_hyp": 4.5419,
            "nubia_score": 0.53108
        },
        "meteor": 0.35786350221344576,
        "bertscore": {
            "precision": 0.89418,
            "recall": 0.91533,
            "f1": 0.90294
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_561": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.7735572622751845,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.043321469306228516,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.046930949929641655,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rouge2": {
            "precision": 0.81818,
            "recall": 0.81818,
            "fmeasure": 0.81818
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "nist": 2.6017006625380596,
        "bleu": 45.46697,
        "bleurt": -0.11575,
        "nubia": {
            "semantic_relation": 4.27352,
            "contradiction": 6.06656,
            "irrelevancy": 34.69403,
            "logical_agreement": 59.23942,
            "grammar_ref": 4.85143,
            "grammar_hyp": 5.53057,
            "nubia_score": 0.55699
        },
        "meteor": 0.4486121983053691,
        "bertscore": {
            "precision": 0.89081,
            "recall": 0.92678,
            "f1": 0.90844
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_442": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.42857,
            "recall": 0.27381,
            "fmeasure": 0.33036
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.14286,
            "recall": 0.09127,
            "fmeasure": 0.11012
        },
        "rougeLsum": {
            "precision": 0.14286,
            "recall": 0.09127,
            "fmeasure": 0.11012
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.25
        },
        "nist": 0.44391983539812346,
        "bleu": 4.99514,
        "bleurt": -0.07426,
        "nubia": {
            "semantic_relation": 3.34702,
            "contradiction": 3.14683,
            "irrelevancy": 35.94674,
            "logical_agreement": 60.90643,
            "grammar_ref": 5.77141,
            "grammar_hyp": 6.54327,
            "nubia_score": 0.32866
        },
        "meteor": 0.11691022964509397,
        "bertscore": {
            "precision": 0.89164,
            "recall": 0.868,
            "f1": 0.87966
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_609": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 24,
        "unique-1": 22,
        "entropy-1": 4.546593564294937,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.10341647163363243,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.277613436819113,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.12336199461765365,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75758,
            "recall": 0.82038,
            "fmeasure": 0.78729
        },
        "rouge2": {
            "precision": 0.61905,
            "recall": 0.63968,
            "fmeasure": 0.62911
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.46898,
            "fmeasure": 0.46159
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.46898,
            "fmeasure": 0.46159
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8333333333333334
        },
        "nist": 3.6947408441787104,
        "bleu": 61.31107,
        "bleurt": 0.30616,
        "nubia": {
            "semantic_relation": 4.69085,
            "contradiction": 0.20547,
            "irrelevancy": 3.98994,
            "logical_agreement": 95.80459,
            "grammar_ref": 5.09304,
            "grammar_hyp": 4.12332,
            "nubia_score": 0.98405
        },
        "meteor": 0.45613196429777075,
        "bertscore": {
            "precision": 0.94665,
            "recall": 0.95642,
            "f1": 0.95151
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_524": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.81818,
            "fmeasure": 0.9
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.7,
            "fmeasure": 0.77778
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.81818,
            "fmeasure": 0.9
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.81818,
            "fmeasure": 0.9
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.875
        },
        "nist": 3.4656555564613205,
        "bleu": 73.98067,
        "bleurt": 0.65906,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.24845,
            "irrelevancy": 0.45905,
            "logical_agreement": 99.29249,
            "grammar_ref": 4.055,
            "grammar_hyp": 4.62386,
            "nubia_score": 0.98742
        },
        "meteor": 0.45030454326165953,
        "bertscore": {
            "precision": 0.98612,
            "recall": 0.93682,
            "f1": 0.96084
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_610": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966062,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rouge2": {
            "precision": 0.9375,
            "recall": 0.9375,
            "fmeasure": 0.9375
        },
        "rougeL": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rougeLsum": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9375
        },
        "nist": 4.514053391810574,
        "bleu": 90.3602,
        "bleurt": 0.72398,
        "nubia": {
            "semantic_relation": 3.74862,
            "contradiction": 97.6993,
            "irrelevancy": 1.77644,
            "logical_agreement": 0.52426,
            "grammar_ref": 5.25838,
            "grammar_hyp": 5.18253,
            "nubia_score": 0.52622
        },
        "meteor": 0.572472684946071,
        "bertscore": {
            "precision": 0.98423,
            "recall": 0.98839,
            "f1": 0.98631
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_621": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 0.95238,
            "recall": 0.91667,
            "fmeasure": 0.93333
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "nist": 4.251192788981044,
        "bleu": 100.0,
        "bleurt": 0.64779,
        "nubia": {
            "semantic_relation": 4.42679,
            "contradiction": 6.87785,
            "irrelevancy": 1.70123,
            "logical_agreement": 91.42092,
            "grammar_ref": 7.10682,
            "grammar_hyp": 7.20763,
            "nubia_score": 0.72464
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_623": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.90476,
            "fmeasure": 0.92308
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 2.9143184224283365,
        "bleu": 100.0,
        "bleurt": 0.61495,
        "nubia": {
            "semantic_relation": 4.47646,
            "contradiction": 0.85873,
            "irrelevancy": 0.61324,
            "logical_agreement": 98.52803,
            "grammar_ref": 5.29735,
            "grammar_hyp": 5.49873,
            "nubia_score": 0.81214
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_612": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 18.0,
        "std_pred_length": 6.683312551921141,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 42,
        "unique-1": 35,
        "entropy-1": 5.215639067371547,
        "distinct-2": 0.9803921568627451,
        "vocab_size-2": 50,
        "unique-2": 49,
        "entropy-2": 5.63320965569699,
        "cond_entropy-2": 0.3560579962119538,
        "distinct-3": 1.0,
        "vocab_size-3": 48,
        "unique-3": 48,
        "entropy-3": 5.5849625007211605,
        "cond_entropy-3": -0.04579617458367275,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 5.436502143433363,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8085106382978723,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.07874783089891,
        "distinct-2-nopunct": 0.9772727272727273,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.413977073182751,
        "cond_entropy-2-nopunct": 0.36767294824602953,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.05309912621433558,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.49537,
            "recall": 0.52051,
            "fmeasure": 0.49609
        },
        "rouge2": {
            "precision": 0.21268,
            "recall": 0.23855,
            "fmeasure": 0.21825
        },
        "rougeL": {
            "precision": 0.37778,
            "recall": 0.39076,
            "fmeasure": 0.37565
        },
        "rougeLsum": {
            "precision": 0.37778,
            "recall": 0.39076,
            "fmeasure": 0.37565
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.46153846153846156,
            "3": 0.48
        },
        "nist": 2.490602423911669,
        "bleu": 10.59646,
        "bleurt": 0.04265,
        "nubia": {
            "semantic_relation": 3.68402,
            "contradiction": 0.21048,
            "irrelevancy": 65.5196,
            "logical_agreement": 34.26992,
            "grammar_ref": 4.28129,
            "grammar_hyp": 3.83522,
            "nubia_score": 0.69087
        },
        "meteor": 0.2650074664834574,
        "bertscore": {
            "precision": 0.84073,
            "recall": 0.86162,
            "f1": 0.84873
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_525": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.46667,
            "recall": 0.53472,
            "fmeasure": 0.49622
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.26667,
            "recall": 0.30556,
            "fmeasure": 0.28355
        },
        "rougeLsum": {
            "precision": 0.26667,
            "recall": 0.30556,
            "fmeasure": 0.28355
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5454545454545454
        },
        "nist": 1.8856536478323354,
        "bleu": 3.84619,
        "bleurt": -0.11363,
        "nubia": {
            "semantic_relation": 3.99567,
            "contradiction": 0.41016,
            "irrelevancy": 20.18466,
            "logical_agreement": 79.40518,
            "grammar_ref": 5.53377,
            "grammar_hyp": 5.2208,
            "nubia_score": 0.66911
        },
        "meteor": 0.21805792163543442,
        "bertscore": {
            "precision": 0.82795,
            "recall": 0.81979,
            "f1": 0.8211
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_654": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.92,
        "vocab_size-1": 23,
        "unique-1": 22,
        "entropy-1": 4.453660689688184,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.13922662353657622,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.061400544664143256,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.39231742277876,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": -0.07038932789139804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7193,
            "recall": 0.69474,
            "fmeasure": 0.7067
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.47368,
            "fmeasure": 0.45787
        },
        "rougeL": {
            "precision": 0.57895,
            "recall": 0.5693,
            "fmeasure": 0.574
        },
        "rougeLsum": {
            "precision": 0.57895,
            "recall": 0.5693,
            "fmeasure": 0.574
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.3333333333333333,
            "3": 0.7777777777777778
        },
        "nist": 4.262384164840717,
        "bleu": 55.92599,
        "bleurt": 0.33178,
        "nubia": {
            "semantic_relation": 4.44056,
            "contradiction": 0.12322,
            "irrelevancy": 0.93378,
            "logical_agreement": 98.94301,
            "grammar_ref": 3.79365,
            "grammar_hyp": 3.80128,
            "nubia_score": 0.87638
        },
        "meteor": 0.398009250841363,
        "bertscore": {
            "precision": 0.90597,
            "recall": 0.91478,
            "f1": 0.91035
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_564": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 2.0,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 12,
        "distinct-1": 0.75,
        "vocab_size-1": 15,
        "unique-1": 10,
        "entropy-1": 3.821928094887362,
        "distinct-2": 0.8333333333333334,
        "vocab_size-2": 15,
        "unique-2": 12,
        "entropy-2": 3.8365916681089787,
        "cond_entropy-2": -0.04089198233393865,
        "distinct-3": 0.875,
        "vocab_size-3": 14,
        "unique-3": 12,
        "entropy-3": 3.75,
        "cond_entropy-3": -0.04492500144231237,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.7254805569978675,
        "distinct-2-nopunct": 0.8125,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.625,
        "cond_entropy-2-nopunct": -0.04492500144231237,
        "distinct-3-nopunct": 0.8571428571428571,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.521640636343319,
        "cond_entropy-3-nopunct": -0.04978793508525296,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.92857,
            "fmeasure": 0.96154
        },
        "rouge2": {
            "precision": 0.93939,
            "recall": 0.87179,
            "fmeasure": 0.90278
        },
        "rougeL": {
            "precision": 0.93056,
            "recall": 0.86905,
            "fmeasure": 0.89744
        },
        "rougeLsum": {
            "precision": 0.93056,
            "recall": 0.86905,
            "fmeasure": 0.89744
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.3333333333333333,
            "3": 0.9375
        },
        "nist": 4.397844835611353,
        "bleu": 73.211,
        "bleurt": 0.7228,
        "nubia": {
            "semantic_relation": 4.74767,
            "contradiction": 1.91921,
            "irrelevancy": 22.8732,
            "logical_agreement": 75.20758,
            "grammar_ref": 4.81259,
            "grammar_hyp": 4.83769,
            "nubia_score": 0.89738
        },
        "meteor": 0.5782089453357577,
        "bertscore": {
            "precision": 0.99485,
            "recall": 0.9876,
            "f1": 0.9912
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_624": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 86,
        "mean_pred_length": 21.5,
        "std_pred_length": 9.340770846134703,
        "median_pred_length": 20.0,
        "min_pred_length": 12,
        "max_pred_length": 34,
        "distinct-1": 0.7441860465116279,
        "vocab_size-1": 64,
        "unique-1": 52,
        "entropy-1": 5.770376708695509,
        "distinct-2": 0.9878048780487805,
        "vocab_size-2": 81,
        "unique-2": 80,
        "entropy-2": 6.333161760715648,
        "cond_entropy-2": 0.4972186152399702,
        "distinct-3": 1.0,
        "vocab_size-3": 78,
        "unique-3": 78,
        "entropy-3": 6.285402218862257,
        "cond_entropy-3": -0.04650876011480939,
        "total_length-nopunct": 78,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 8.645808232895291,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.7948717948717948,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 5.767371809162681,
        "distinct-2-nopunct": 0.9864864864864865,
        "vocab_size-2-nopunct": 73,
        "unique-2-nopunct": 72,
        "entropy-2-nopunct": 6.182426338601928,
        "cond_entropy-2-nopunct": 0.4160291461797651,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 70,
        "unique-3-nopunct": 70,
        "entropy-3-nopunct": 6.129283016944973,
        "cond_entropy-3-nopunct": -0.05159892011255472,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65728,
            "recall": 0.67755,
            "fmeasure": 0.65652
        },
        "rouge2": {
            "precision": 0.44676,
            "recall": 0.38732,
            "fmeasure": 0.40101
        },
        "rougeL": {
            "precision": 0.58201,
            "recall": 0.54883,
            "fmeasure": 0.5476
        },
        "rougeLsum": {
            "precision": 0.58201,
            "recall": 0.54883,
            "fmeasure": 0.5476
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.3684210526315789,
            "3": 0.8333333333333334
        },
        "nist": 4.770652742094201,
        "bleu": 42.25228,
        "bleurt": -0.01113,
        "nubia": {
            "semantic_relation": 3.43625,
            "contradiction": 25.09583,
            "irrelevancy": 60.89055,
            "logical_agreement": 14.01361,
            "grammar_ref": 4.54253,
            "grammar_hyp": 3.95852,
            "nubia_score": 0.50589
        },
        "meteor": 0.3775151807075636,
        "bertscore": {
            "precision": 0.89881,
            "recall": 0.873,
            "f1": 0.88005
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_567": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 43,
        "mean_pred_length": 21.5,
        "std_pred_length": 1.5,
        "median_pred_length": 21.5,
        "min_pred_length": 20,
        "max_pred_length": 23,
        "distinct-1": 0.8372093023255814,
        "vocab_size-1": 36,
        "unique-1": 31,
        "entropy-1": 5.054171731446283,
        "distinct-2": 1.0,
        "vocab_size-2": 41,
        "unique-2": 41,
        "entropy-2": 5.357552004618081,
        "cond_entropy-2": 0.27275066455013214,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.07214978575583503,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 18.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8918918918918919,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 4.939183095358683,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.129283016944964,
        "cond_entropy-2-nopunct": 0.20554393703030216,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.08488889758651327,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75784,
            "recall": 0.83449,
            "fmeasure": 0.79373
        },
        "rouge2": {
            "precision": 0.64309,
            "recall": 0.72157,
            "fmeasure": 0.67916
        },
        "rougeL": {
            "precision": 0.75784,
            "recall": 0.83449,
            "fmeasure": 0.79373
        },
        "rougeLsum": {
            "precision": 0.75784,
            "recall": 0.83449,
            "fmeasure": 0.79373
        },
        "local_recall": {
            "1": 0,
            "2": 0.875,
            "3": 0.8571428571428571
        },
        "nist": 3.682982249696402,
        "bleu": 52.32356,
        "bleurt": 0.34633,
        "nubia": {
            "semantic_relation": 3.55182,
            "contradiction": 47.06525,
            "irrelevancy": 46.63353,
            "logical_agreement": 6.30122,
            "grammar_ref": 3.41143,
            "grammar_hyp": 3.0937,
            "nubia_score": 0.66254
        },
        "meteor": 0.5029730739495106,
        "bertscore": {
            "precision": 0.92401,
            "recall": 0.94965,
            "f1": 0.93361
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_656": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.64103,
            "recall": 0.63194,
            "fmeasure": 0.63356
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.22626,
            "fmeasure": 0.2233
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.45833,
            "fmeasure": 0.45793
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.45833,
            "fmeasure": 0.45793
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.2,
            "3": 0.6363636363636364
        },
        "nist": 2.3751391454228368,
        "bleu": 18.92862,
        "bleurt": 0.27668,
        "nubia": {
            "semantic_relation": 4.01941,
            "contradiction": 0.49586,
            "irrelevancy": 32.25624,
            "logical_agreement": 67.24791,
            "grammar_ref": 4.67419,
            "grammar_hyp": 4.63809,
            "nubia_score": 0.64238
        },
        "meteor": 0.3059528646080519,
        "bertscore": {
            "precision": 0.86028,
            "recall": 0.84751,
            "f1": 0.85152
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_528": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 8.0,
        "median_pred_length": 20.0,
        "min_pred_length": 12,
        "max_pred_length": 28,
        "distinct-1": 0.875,
        "vocab_size-1": 35,
        "unique-1": 30,
        "entropy-1": 5.0719280948873635,
        "distinct-2": 0.9736842105263158,
        "vocab_size-2": 37,
        "unique-2": 36,
        "entropy-2": 5.19529593449622,
        "cond_entropy-2": 0.08389415539832844,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.0224469564457176,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 8.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8857142857142857,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.900711588373535,
        "distinct-2-nopunct": 0.9696969696969697,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.9837880587523955,
        "cond_entropy-2-nopunct": 0.09692928423166854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.025681679939320107,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.9,
            "recall": 0.94796,
            "fmeasure": 0.92258
        },
        "rouge2": {
            "precision": 0.8125,
            "recall": 0.85173,
            "fmeasure": 0.83092
        },
        "rougeL": {
            "precision": 0.74667,
            "recall": 0.77174,
            "fmeasure": 0.75857
        },
        "rougeLsum": {
            "precision": 0.74667,
            "recall": 0.77174,
            "fmeasure": 0.75857
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.9615384615384616
        },
        "nist": 4.281879313308934,
        "bleu": 61.68006,
        "bleurt": 0.27373,
        "nubia": {
            "semantic_relation": 4.61065,
            "contradiction": 1.0152,
            "irrelevancy": 6.311,
            "logical_agreement": 92.6738,
            "grammar_ref": 4.36539,
            "grammar_hyp": 4.5148,
            "nubia_score": 0.82637
        },
        "meteor": 0.4837492764929925,
        "bertscore": {
            "precision": 0.93944,
            "recall": 0.94441,
            "f1": 0.94035
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_529": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717246,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": 0.0930692077718899,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70833,
            "recall": 0.60833,
            "fmeasure": 0.65278
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.13228,
            "fmeasure": 0.1369
        },
        "rougeL": {
            "precision": 0.70833,
            "recall": 0.60833,
            "fmeasure": 0.65278
        },
        "rougeLsum": {
            "precision": 0.70833,
            "recall": 0.60833,
            "fmeasure": 0.65278
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.625
        },
        "nist": 2.4861483323793028,
        "bleu": 22.08959,
        "bleurt": 0.40889,
        "nubia": {
            "semantic_relation": 4.27958,
            "contradiction": 0.306,
            "irrelevancy": 1.25703,
            "logical_agreement": 98.43697,
            "grammar_ref": 5.68329,
            "grammar_hyp": 5.92681,
            "nubia_score": 0.75601
        },
        "meteor": 0.3204139794506069,
        "bertscore": {
            "precision": 0.93095,
            "recall": 0.92046,
            "f1": 0.92372
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_530": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 90,
        "mean_pred_length": 18.0,
        "std_pred_length": 4.516635916254486,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 22,
        "distinct-1": 0.5888888888888889,
        "vocab_size-1": 53,
        "unique-1": 34,
        "entropy-1": 5.397369835618359,
        "distinct-2": 0.8,
        "vocab_size-2": 68,
        "unique-2": 54,
        "entropy-2": 5.982747847826054,
        "cond_entropy-2": 0.5131753749032116,
        "distinct-3": 0.8875,
        "vocab_size-3": 71,
        "unique-3": 62,
        "entropy-3": 6.096928094887358,
        "cond_entropy-3": 0.1408454400807907,
        "total_length-nopunct": 79,
        "mean_pred_length-nopunct": 15.8,
        "std_pred_length-nopunct": 3.9698866482558417,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6329113924050633,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.330440836916583,
        "distinct-2-nopunct": 0.7972972972972973,
        "vocab_size-2-nopunct": 59,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.773444412838544,
        "cond_entropy-2-nopunct": 0.4952562726287481,
        "distinct-3-nopunct": 0.8985507246376812,
        "vocab_size-3-nopunct": 62,
        "unique-3-nopunct": 55,
        "entropy-3-nopunct": 5.905625906053528,
        "cond_entropy-3-nopunct": 0.14928359124328336,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88338,
            "recall": 0.87249,
            "fmeasure": 0.87712
        },
        "rouge2": {
            "precision": 0.73722,
            "recall": 0.73296,
            "fmeasure": 0.73444
        },
        "rougeL": {
            "precision": 0.78422,
            "recall": 0.77213,
            "fmeasure": 0.77753
        },
        "rougeLsum": {
            "precision": 0.78422,
            "recall": 0.77213,
            "fmeasure": 0.77753
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.2857142857142857,
            "3": 0.890625
        },
        "nist": 5.854646183950661,
        "bleu": 70.83413,
        "bleurt": 0.62969,
        "nubia": {
            "semantic_relation": 4.64941,
            "contradiction": 0.14573,
            "irrelevancy": 22.14657,
            "logical_agreement": 77.70771,
            "grammar_ref": 3.93665,
            "grammar_hyp": 3.81264,
            "nubia_score": 0.89122
        },
        "meteor": 0.516227200681168,
        "bertscore": {
            "precision": 0.96488,
            "recall": 0.97017,
            "f1": 0.96685
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_707": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rouge2": {
            "precision": 0.78788,
            "recall": 0.8963,
            "fmeasure": 0.8381
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.090634124990776,
        "bleu": 76.11606,
        "bleurt": 0.48581,
        "nubia": {
            "semantic_relation": 4.3761,
            "contradiction": 0.09394,
            "irrelevancy": 99.63689,
            "logical_agreement": 0.26917,
            "grammar_ref": 5.85321,
            "grammar_hyp": 5.83654,
            "nubia_score": 0.79202
        },
        "meteor": 0.5715186082473627,
        "bertscore": {
            "precision": 0.98299,
            "recall": 0.99732,
            "f1": 0.9901
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_445": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8,
        "vocab_size-1": 24,
        "unique-1": 19,
        "entropy-1": 4.481727678869736,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": 0.2845674515263523,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.88,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.403856189774723,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.14057533149967955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88141,
            "recall": 0.77536,
            "fmeasure": 0.82112
        },
        "rouge2": {
            "precision": 0.66288,
            "recall": 0.58494,
            "fmeasure": 0.61728
        },
        "rougeL": {
            "precision": 0.78419,
            "recall": 0.70151,
            "fmeasure": 0.73725
        },
        "rougeLsum": {
            "precision": 0.78419,
            "recall": 0.70151,
            "fmeasure": 0.73725
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.8571428571428571
        },
        "nist": 4.7568887799427655,
        "bleu": 59.44999,
        "bleurt": 0.45323,
        "nubia": {
            "semantic_relation": 4.66299,
            "contradiction": 1.44082,
            "irrelevancy": 49.00493,
            "logical_agreement": 49.55425,
            "grammar_ref": 5.26806,
            "grammar_hyp": 4.77602,
            "nubia_score": 0.87868
        },
        "meteor": 0.4205870261608557,
        "bertscore": {
            "precision": 0.96566,
            "recall": 0.94641,
            "f1": 0.9559
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_708": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 12.333333333333334,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 13,
        "distinct-1": 0.6756756756756757,
        "vocab_size-1": 25,
        "unique-1": 16,
        "entropy-1": 4.499597622210293,
        "distinct-2": 0.8235294117647058,
        "vocab_size-2": 28,
        "unique-2": 23,
        "entropy-2": 4.712319091186707,
        "cond_entropy-2": 0.13550616686149178,
        "distinct-3": 0.9032258064516129,
        "vocab_size-3": 28,
        "unique-3": 25,
        "entropy-3": 4.760647923290102,
        "cond_entropy-3": 0.08463306598051874,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 10.666666666666666,
        "std_pred_length-nopunct": 0.4714045207910317,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.71875,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.390319531114783,
        "distinct-2-nopunct": 0.7586206896551724,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.349191770915039,
        "cond_entropy-2-nopunct": 0.021942633133208985,
        "distinct-3-nopunct": 0.8076923076923077,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.315824333525707,
        "cond_entropy-3-nopunct": 0.025339011558268773,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.84848,
            "recall": 0.86667,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.7037,
            "fmeasure": 0.70175
        },
        "rougeL": {
            "precision": 0.75758,
            "recall": 0.76667,
            "fmeasure": 0.7619
        },
        "rougeLsum": {
            "precision": 0.75758,
            "recall": 0.76667,
            "fmeasure": 0.7619
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6,
            "3": 1.0
        },
        "nist": 3.97877353894781,
        "bleu": 61.3747,
        "bleurt": 0.67464,
        "nubia": {
            "semantic_relation": 4.79156,
            "contradiction": 0.37103,
            "irrelevancy": 2.18554,
            "logical_agreement": 97.44344,
            "grammar_ref": 5.72052,
            "grammar_hyp": 5.72696,
            "nubia_score": 0.90683
        },
        "meteor": 0.4710153881260911,
        "bertscore": {
            "precision": 0.9494,
            "recall": 0.96188,
            "f1": 0.95557
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_657": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 50,
        "mean_pred_length": 25.0,
        "std_pred_length": 10.0,
        "median_pred_length": 25.0,
        "min_pred_length": 15,
        "max_pred_length": 35,
        "distinct-1": 0.66,
        "vocab_size-1": 33,
        "unique-1": 21,
        "entropy-1": 4.878562939644918,
        "distinct-2": 0.8125,
        "vocab_size-2": 39,
        "unique-2": 31,
        "entropy-2": 5.194235677759421,
        "cond_entropy-2": 0.3058932902032429,
        "distinct-3": 0.8913043478260869,
        "vocab_size-3": 41,
        "unique-3": 36,
        "entropy-3": 5.306170651709185,
        "cond_entropy-3": 0.12892309668723645,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 23.5,
        "std_pred_length-nopunct": 9.5,
        "median_pred_length-nopunct": 23.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.6595744680851063,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.783000287709758,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 5.075077818503818,
        "cond_entropy-2-nopunct": 0.291148966954388,
        "distinct-3-nopunct": 0.8837209302325582,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.193706615167214,
        "cond_entropy-3-nopunct": 0.10115410026643075,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77742,
            "recall": 0.74411,
            "fmeasure": 0.75358
        },
        "rouge2": {
            "precision": 0.54888,
            "recall": 0.51212,
            "fmeasure": 0.52474
        },
        "rougeL": {
            "precision": 0.69156,
            "recall": 0.65335,
            "fmeasure": 0.66613
        },
        "rougeLsum": {
            "precision": 0.69156,
            "recall": 0.65335,
            "fmeasure": 0.66613
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.2,
            "3": 0.8787878787878788
        },
        "nist": 4.267293443984682,
        "bleu": 30.96599,
        "bleurt": 0.09824,
        "nubia": {
            "semantic_relation": 4.00357,
            "contradiction": 26.38447,
            "irrelevancy": 2.29171,
            "logical_agreement": 71.32382,
            "grammar_ref": 3.5955,
            "grammar_hyp": 3.88596,
            "nubia_score": 0.69026
        },
        "meteor": 0.39252672520351956,
        "bertscore": {
            "precision": 0.94113,
            "recall": 0.90239,
            "f1": 0.9208
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_625": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.16253715874966057,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.17355726227518525,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75,
            "recall": 0.59903,
            "fmeasure": 0.6595
        },
        "rouge2": {
            "precision": 0.35556,
            "recall": 0.26768,
            "fmeasure": 0.30163
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.33445,
            "fmeasure": 0.36546
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.33445,
            "fmeasure": 0.36546
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "nist": 3.55640580371446,
        "bleu": 39.84681,
        "bleurt": -0.44029,
        "nubia": {
            "semantic_relation": 3.09413,
            "contradiction": 2.64481,
            "irrelevancy": 64.71694,
            "logical_agreement": 32.63825,
            "grammar_ref": 4.61776,
            "grammar_hyp": 3.5821,
            "nubia_score": 0.49502
        },
        "meteor": 0.2774384877363323,
        "bertscore": {
            "precision": 0.86562,
            "recall": 0.84284,
            "f1": 0.85408
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_627": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9565217391304348,
        "vocab_size-1": 22,
        "unique-1": 21,
        "entropy-1": 4.436605434317882,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.02677875348937534,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.02961067210860201,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.34921,
            "recall": 0.44928,
            "fmeasure": 0.38788
        },
        "rouge2": {
            "precision": 0.15,
            "recall": 0.1993,
            "fmeasure": 0.16883
        },
        "rougeL": {
            "precision": 0.28571,
            "recall": 0.37267,
            "fmeasure": 0.31948
        },
        "rougeLsum": {
            "precision": 0.28571,
            "recall": 0.37267,
            "fmeasure": 0.31948
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.5
        },
        "nist": 2.0098945034716293,
        "bleu": 11.21457,
        "bleurt": -0.12554,
        "nubia": {
            "semantic_relation": 4.01696,
            "contradiction": 0.09874,
            "irrelevancy": 92.87711,
            "logical_agreement": 7.02414,
            "grammar_ref": 4.57081,
            "grammar_hyp": 3.6562,
            "nubia_score": 0.77781
        },
        "meteor": 0.2886908013811681,
        "bertscore": {
            "precision": 0.83699,
            "recall": 0.8599,
            "f1": 0.84829
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_720": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 75,
        "mean_pred_length": 18.75,
        "std_pred_length": 5.931905258852336,
        "median_pred_length": 19.5,
        "min_pred_length": 11,
        "max_pred_length": 25,
        "distinct-1": 0.7333333333333333,
        "vocab_size-1": 55,
        "unique-1": 43,
        "entropy-1": 5.595355023771527,
        "distinct-2": 0.971830985915493,
        "vocab_size-2": 69,
        "unique-2": 67,
        "entropy-2": 6.093409091335663,
        "cond_entropy-2": 0.42106610512608217,
        "distinct-3": 0.9850746268656716,
        "vocab_size-3": 66,
        "unique-3": 65,
        "entropy-3": 6.0362384441891095,
        "cond_entropy-3": -0.05380718277825281,
        "total_length-nopunct": 68,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 5.196152422706632,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7794117647058824,
        "vocab_size-1-nopunct": 53,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.576361554453821,
        "distinct-2-nopunct": 0.96875,
        "vocab_size-2-nopunct": 62,
        "unique-2-nopunct": 60,
        "entropy-2-nopunct": 5.9375,
        "cond_entropy-2-nopunct": 0.3930822759709649,
        "distinct-3-nopunct": 0.9833333333333333,
        "vocab_size-3-nopunct": 59,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.873557262275184,
        "cond_entropy-3-nopunct": -0.059776071058148084,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71169,
            "recall": 0.8143,
            "fmeasure": 0.7554
        },
        "rouge2": {
            "precision": 0.51542,
            "recall": 0.57832,
            "fmeasure": 0.54289
        },
        "rougeL": {
            "precision": 0.55639,
            "recall": 0.66213,
            "fmeasure": 0.60125
        },
        "rougeLsum": {
            "precision": 0.55639,
            "recall": 0.66213,
            "fmeasure": 0.60125
        },
        "local_recall": {
            "1": 0.3125,
            "2": 0.5,
            "3": 0.9210526315789473
        },
        "nist": 4.609424845128201,
        "bleu": 54.61521,
        "bleurt": 0.52814,
        "nubia": {
            "semantic_relation": 4.63485,
            "contradiction": 6.04617,
            "irrelevancy": 42.15413,
            "logical_agreement": 51.7997,
            "grammar_ref": 4.54108,
            "grammar_hyp": 4.11173,
            "nubia_score": 0.83382
        },
        "meteor": 0.4620709473609869,
        "bertscore": {
            "precision": 0.92294,
            "recall": 0.94254,
            "f1": 0.93251
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_570": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.0433214693062285,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.87179,
            "recall": 0.80952,
            "fmeasure": 0.83951
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.61538,
            "fmeasure": 0.64
        },
        "rougeL": {
            "precision": 0.74359,
            "recall": 0.69048,
            "fmeasure": 0.71605
        },
        "rougeLsum": {
            "precision": 0.74359,
            "recall": 0.69048,
            "fmeasure": 0.71605
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.25,
            "3": 0.8888888888888888
        },
        "nist": 4.777806403564686,
        "bleu": 73.11104,
        "bleurt": 0.51047,
        "nubia": {
            "semantic_relation": 4.80674,
            "contradiction": 0.22764,
            "irrelevancy": 0.4644,
            "logical_agreement": 99.30796,
            "grammar_ref": 5.70189,
            "grammar_hyp": 5.01094,
            "nubia_score": 0.97119
        },
        "meteor": 0.4718059540396743,
        "bertscore": {
            "precision": 0.97601,
            "recall": 0.96838,
            "f1": 0.97218
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_448": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 13.25,
        "std_pred_length": 0.4330127018922193,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 14,
        "distinct-1": 0.8301886792452831,
        "vocab_size-1": 44,
        "unique-1": 37,
        "entropy-1": 5.350561963997159,
        "distinct-2": 0.9387755102040817,
        "vocab_size-2": 46,
        "unique-2": 43,
        "entropy-2": 5.492260864523372,
        "cond_entropy-2": 0.009238369143845945,
        "distinct-3": 0.9555555555555556,
        "vocab_size-3": 43,
        "unique-3": 41,
        "entropy-3": 5.402964207440784,
        "cond_entropy-3": -0.07841230334108928,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.7071067811865476,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.334962500721158,
        "distinct-2-nopunct": 0.9318181818181818,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.323067982273659,
        "cond_entropy-2-nopunct": 0.010832754279777283,
        "distinct-3-nopunct": 0.95,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.221928094887364,
        "cond_entropy-3-nopunct": -0.08750352374993503,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86948,
            "recall": 0.7883,
            "fmeasure": 0.82566
        },
        "rouge2": {
            "precision": 0.66035,
            "recall": 0.60468,
            "fmeasure": 0.63039
        },
        "rougeL": {
            "precision": 0.80467,
            "recall": 0.73716,
            "fmeasure": 0.76852
        },
        "rougeLsum": {
            "precision": 0.80467,
            "recall": 0.73716,
            "fmeasure": 0.76852
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.2222222222222222,
            "3": 0.8478260869565217
        },
        "nist": 5.0177953419721915,
        "bleu": 66.56905,
        "bleurt": 0.52163,
        "nubia": {
            "semantic_relation": 4.75945,
            "contradiction": 2.5804,
            "irrelevancy": 1.77394,
            "logical_agreement": 95.64567,
            "grammar_ref": 4.9146,
            "grammar_hyp": 4.90395,
            "nubia_score": 0.88231
        },
        "meteor": 0.47224720638821577,
        "bertscore": {
            "precision": 0.97256,
            "recall": 0.95929,
            "f1": 0.96367
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_721": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 1.0,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.9545454545454546,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.368522527728205,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.95455,
            "recall": 0.81843,
            "fmeasure": 0.8799
        },
        "rouge2": {
            "precision": 0.725,
            "recall": 0.60934,
            "fmeasure": 0.66095
        },
        "rougeL": {
            "precision": 0.88131,
            "recall": 0.75455,
            "fmeasure": 0.81178
        },
        "rougeLsum": {
            "precision": 0.88131,
            "recall": 0.75455,
            "fmeasure": 0.81178
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.7692307692307693,
            "3": 0.8888888888888888
        },
        "nist": 3.45193483039471,
        "bleu": 63.82745,
        "bleurt": 0.52275,
        "nubia": {
            "semantic_relation": 4.44566,
            "contradiction": 1.89347,
            "irrelevancy": 2.26282,
            "logical_agreement": 95.84371,
            "grammar_ref": 4.61516,
            "grammar_hyp": 4.67834,
            "nubia_score": 0.80478
        },
        "meteor": 0.4376641492357371,
        "bertscore": {
            "precision": 0.98978,
            "recall": 0.95077,
            "f1": 0.96988
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_630": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 62,
        "mean_pred_length": 15.5,
        "std_pred_length": 4.092676385936225,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 19,
        "distinct-1": 0.4838709677419355,
        "vocab_size-1": 30,
        "unique-1": 15,
        "entropy-1": 4.5096233618491794,
        "distinct-2": 0.7241379310344828,
        "vocab_size-2": 42,
        "unique-2": 28,
        "entropy-2": 5.271774098575846,
        "cond_entropy-2": 0.7238454228327176,
        "distinct-3": 0.8333333333333334,
        "vocab_size-3": 45,
        "unique-3": 36,
        "entropy-3": 5.421554168830134,
        "cond_entropy-3": 0.15616576629515588,
        "total_length-nopunct": 58,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 4.092676385936225,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.5,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.451713360483827,
        "distinct-2-nopunct": 0.7222222222222222,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 5.1622949095708766,
        "cond_entropy-2-nopunct": 0.7777124849865859,
        "distinct-3-nopunct": 0.82,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.283856189774726,
        "cond_entropy-3-nopunct": 0.16896868761125602,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.89881,
            "recall": 0.82601,
            "fmeasure": 0.85928
        },
        "rouge2": {
            "precision": 0.77036,
            "recall": 0.71305,
            "fmeasure": 0.73915
        },
        "rougeL": {
            "precision": 0.87103,
            "recall": 0.80274,
            "fmeasure": 0.83396
        },
        "rougeLsum": {
            "precision": 0.87103,
            "recall": 0.80274,
            "fmeasure": 0.83396
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.803921568627451
        },
        "nist": 4.422958637500809,
        "bleu": 58.77041,
        "bleurt": 0.62569,
        "nubia": {
            "semantic_relation": 4.31649,
            "contradiction": 46.30327,
            "irrelevancy": 2.80212,
            "logical_agreement": 50.89461,
            "grammar_ref": 3.98368,
            "grammar_hyp": 4.11218,
            "nubia_score": 0.78645
        },
        "meteor": 0.42964002826720865,
        "bertscore": {
            "precision": 0.97319,
            "recall": 0.95889,
            "f1": 0.96592
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2221,
        "msttr-100": 0.73754,
        "msttr-100_nopunct": 0.79276,
        "total_length": 33804,
        "mean_pred_length": 15.220171094101756,
        "std_pred_length": 4.638063469677267,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 54,
        "distinct-1": 0.2523961661341853,
        "vocab_size-1": 8532,
        "unique-1": 6119,
        "entropy-1": 9.709948623912362,
        "distinct-2": 0.6629515878795554,
        "vocab_size-2": 20938,
        "unique-2": 18198,
        "entropy-2": 13.555075653961337,
        "cond_entropy-2": 3.4379799415435155,
        "distinct-3": 0.8659151283972482,
        "vocab_size-3": 25425,
        "unique-3": 23786,
        "entropy-3": 14.42254571058623,
        "cond_entropy-3": 0.8554132100833214,
        "total_length-nopunct": 29410,
        "mean_pred_length-nopunct": 13.241782980639352,
        "std_pred_length-nopunct": 4.155745632819588,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.2895273716422985,
        "vocab_size-1-nopunct": 8515,
        "unique-1-nopunct": 6118,
        "entropy-1-nopunct": 10.238465190109679,
        "distinct-2-nopunct": 0.7020486226047299,
        "vocab_size-2-nopunct": 19088,
        "unique-2-nopunct": 16926,
        "entropy-2-nopunct": 13.478094205724322,
        "cond_entropy-2-nopunct": 3.415089977670604,
        "distinct-3-nopunct": 0.8914210189041973,
        "vocab_size-3-nopunct": 22257,
        "unique-3-nopunct": 21017,
        "entropy-3-nopunct": 14.285836820191589,
        "cond_entropy-3-nopunct": 0.864907586954073,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78522,
            "recall": 0.75646,
            "fmeasure": 0.75975
        },
        "rouge2": {
            "precision": 0.55391,
            "recall": 0.53419,
            "fmeasure": 0.53585
        },
        "rougeL": {
            "precision": 0.67653,
            "recall": 0.65485,
            "fmeasure": 0.6559
        },
        "rougeLsum": {
            "precision": 0.67653,
            "recall": 0.65485,
            "fmeasure": 0.6559
        },
        "local_recall": {
            "1": 0.21622757847533633,
            "2": 0.45268854748603354,
            "3": 0.793001079525009
        },
        "nist": 10.249967855585565,
        "bleu": 48.22266,
        "bleurt": 0.30986,
        "nubia": {
            "semantic_relation": 4.33116,
            "contradiction": 5.94161,
            "irrelevancy": 26.792,
            "logical_agreement": 67.26639,
            "grammar_ref": 4.79644,
            "grammar_hyp": 4.81145,
            "nubia_score": 0.75782
        },
        "meteor": 0.40527652670120046,
        "bertscore": {
            "precision": 0.9334,
            "recall": 0.93025,
            "f1": 0.93021
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_450": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 51,
        "mean_pred_length": 12.75,
        "std_pred_length": 2.384848003542364,
        "median_pred_length": 12.5,
        "min_pred_length": 10,
        "max_pred_length": 16,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 42,
        "unique-1": 38,
        "entropy-1": 5.226251077223196,
        "distinct-2": 1.0,
        "vocab_size-2": 47,
        "unique-2": 47,
        "entropy-2": 5.55458885167764,
        "cond_entropy-2": 0.19609728634791793,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.1283240969755395,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.1213203435596424,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.232158891364569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.3219280948873635,
        "cond_entropy-2-nopunct": 0.112496476250065,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.81199,
            "fmeasure": 0.75665
        },
        "rouge2": {
            "precision": 0.50116,
            "recall": 0.57322,
            "fmeasure": 0.52806
        },
        "rougeL": {
            "precision": 0.6562,
            "recall": 0.73655,
            "fmeasure": 0.68628
        },
        "rougeLsum": {
            "precision": 0.6562,
            "recall": 0.73655,
            "fmeasure": 0.68628
        },
        "local_recall": {
            "1": 0.24,
            "2": 0.625,
            "3": 0.8095238095238095
        },
        "nist": 4.532252917851803,
        "bleu": 40.885,
        "bleurt": 0.23862,
        "nubia": {
            "semantic_relation": 4.19261,
            "contradiction": 1.59166,
            "irrelevancy": 29.47256,
            "logical_agreement": 68.93577,
            "grammar_ref": 4.75156,
            "grammar_hyp": 5.30898,
            "nubia_score": 0.6605
        },
        "meteor": 0.3887089999308095,
        "bertscore": {
            "precision": 0.91454,
            "recall": 0.93439,
            "f1": 0.92038
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_785": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 0.5,
        "median_pred_length": 11.5,
        "min_pred_length": 11,
        "max_pred_length": 12,
        "distinct-1": 0.5652173913043478,
        "vocab_size-1": 13,
        "unique-1": 5,
        "entropy-1": 3.567040216926579,
        "distinct-2": 0.7619047619047619,
        "vocab_size-2": 16,
        "unique-2": 11,
        "entropy-2": 3.9161269465882835,
        "cond_entropy-2": 0.34494594291222375,
        "distinct-3": 0.8421052631578947,
        "vocab_size-3": 16,
        "unique-3": 13,
        "entropy-3": 3.932138039759373,
        "cond_entropy-3": 0.06613640645429875,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.5714285714285714,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 3.4399364703978077,
        "distinct-2-nopunct": 0.7368421052631579,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.7216117239699,
        "cond_entropy-2-nopunct": 0.3819258801385093,
        "distinct-3-nopunct": 0.8235294117647058,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.734521664779752,
        "cond_entropy-3-nopunct": 0.07482944545381269,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85455,
            "recall": 0.74606,
            "fmeasure": 0.79199
        },
        "rouge2": {
            "precision": 0.64444,
            "recall": 0.56528,
            "fmeasure": 0.59839
        },
        "rougeL": {
            "precision": 0.82424,
            "recall": 0.72645,
            "fmeasure": 0.76818
        },
        "rougeLsum": {
            "precision": 0.82424,
            "recall": 0.72645,
            "fmeasure": 0.76818
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "nist": 3.6865641759601018,
        "bleu": 56.48663,
        "bleurt": 0.51247,
        "nubia": {
            "semantic_relation": 4.87205,
            "contradiction": 0.32107,
            "irrelevancy": 0.58636,
            "logical_agreement": 99.09256,
            "grammar_ref": 4.6711,
            "grammar_hyp": 4.52472,
            "nubia_score": 0.97946
        },
        "meteor": 0.5378808253330242,
        "bertscore": {
            "precision": 0.97899,
            "recall": 0.97159,
            "f1": 0.97526
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_574": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.702819531114783,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.22388309575274976,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75,
            "recall": 0.73077,
            "fmeasure": 0.74
        },
        "rouge2": {
            "precision": 0.51515,
            "recall": 0.50253,
            "fmeasure": 0.50856
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.73077,
            "fmeasure": 0.74
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.73077,
            "fmeasure": 0.74
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "nist": 3.576518763314491,
        "bleu": 56.76722,
        "bleurt": 0.55427,
        "nubia": {
            "semantic_relation": 4.95276,
            "contradiction": 0.2167,
            "irrelevancy": 8.37854,
            "logical_agreement": 91.40476,
            "grammar_ref": 5.03839,
            "grammar_hyp": 4.78988,
            "nubia_score": 0.95461
        },
        "meteor": 0.461847453043217,
        "bertscore": {
            "precision": 0.95273,
            "recall": 0.94431,
            "f1": 0.9485
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_791": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 35.0,
        "std_pred_length": 0.0,
        "median_pred_length": 35.0,
        "min_pred_length": 35,
        "max_pred_length": 35,
        "distinct-1": 0.7714285714285715,
        "vocab_size-1": 27,
        "unique-1": 22,
        "entropy-1": 4.593429088311722,
        "distinct-2": 0.8823529411764706,
        "vocab_size-2": 30,
        "unique-2": 26,
        "entropy-2": 4.852168723603279,
        "cond_entropy-2": 0.27450004495723934,
        "distinct-3": 0.9090909090909091,
        "vocab_size-3": 30,
        "unique-3": 27,
        "entropy-3": 4.8625759375402735,
        "cond_entropy-3": 0.017537338714174698,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 34.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 34.0,
        "min_pred_length-nopunct": 34,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.7647058823529411,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.535848502951413,
        "distinct-2-nopunct": 0.8787878787878788,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.801969876934213,
        "cond_entropy-2-nopunct": 0.28283695999185565,
        "distinct-3-nopunct": 0.90625,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.8125,
        "cond_entropy-3-nopunct": 0.01810588064154658,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.7702,
            "fmeasure": 0.63838
        },
        "rouge2": {
            "precision": 0.36458,
            "recall": 0.51967,
            "fmeasure": 0.42836
        },
        "rougeL": {
            "precision": 0.51515,
            "recall": 0.72727,
            "fmeasure": 0.60287
        },
        "rougeLsum": {
            "precision": 0.51515,
            "recall": 0.72727,
            "fmeasure": 0.60287
        },
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.7368421052631579
        },
        "nist": 2.6982390516437436,
        "bleu": 27.25088,
        "bleurt": -0.13101,
        "nubia": {
            "semantic_relation": 4.2503,
            "contradiction": 2.7956,
            "irrelevancy": 64.23834,
            "logical_agreement": 32.96606,
            "grammar_ref": 4.34096,
            "grammar_hyp": 4.3475,
            "nubia_score": 0.59553
        },
        "meteor": 0.3500870176063953,
        "bertscore": {
            "precision": 0.86129,
            "recall": 0.89619,
            "f1": 0.87839
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_726": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 1.8856180831641267,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.925,
        "vocab_size-1": 37,
        "unique-1": 35,
        "entropy-1": 5.153055907333277,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": -0.05842067520435854,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.12199052437861026,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.160246899469287,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9722222222222222,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.114369445886754,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": -0.06492482147779848,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.13750352374993471,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.82164,
            "fmeasure": 0.87126
        },
        "rouge2": {
            "precision": 0.74603,
            "recall": 0.66361,
            "fmeasure": 0.69986
        },
        "rougeL": {
            "precision": 0.75556,
            "recall": 0.67622,
            "fmeasure": 0.71143
        },
        "rougeLsum": {
            "precision": 0.75556,
            "recall": 0.67622,
            "fmeasure": 0.71143
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6875,
            "3": 0.9130434782608695
        },
        "nist": 4.671852119565929,
        "bleu": 58.91835,
        "bleurt": 0.66291,
        "nubia": {
            "semantic_relation": 4.65275,
            "contradiction": 3.96401,
            "irrelevancy": 29.31024,
            "logical_agreement": 66.72575,
            "grammar_ref": 4.8308,
            "grammar_hyp": 5.15314,
            "nubia_score": 0.81077
        },
        "meteor": 0.4834268364575855,
        "bertscore": {
            "precision": 0.97093,
            "recall": 0.95548,
            "f1": 0.96266
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_660": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 10.0,
        "std_pred_length": 2.160246899469287,
        "median_pred_length": 9.0,
        "min_pred_length": 8,
        "max_pred_length": 13,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 26,
        "unique-1": 24,
        "entropy-1": 4.589898095464288,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.024103851079522856,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 2.160246899469287,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9259259259259259,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.578780557638898,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.02819531114783215,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.19264507794239577,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73479,
            "recall": 0.51073,
            "fmeasure": 0.59898
        },
        "rouge2": {
            "precision": 0.45046,
            "recall": 0.2962,
            "fmeasure": 0.35345
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.43087,
            "fmeasure": 0.50201
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.43087,
            "fmeasure": 0.50201
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.5,
            "3": 0.5416666666666666
        },
        "nist": 2.4313092152644145,
        "bleu": 26.42891,
        "bleurt": 0.06682,
        "nubia": {
            "semantic_relation": 3.72565,
            "contradiction": 10.39888,
            "irrelevancy": 1.51675,
            "logical_agreement": 88.08437,
            "grammar_ref": 4.31237,
            "grammar_hyp": 5.13786,
            "nubia_score": 0.56803
        },
        "meteor": 0.2985657277023026,
        "bertscore": {
            "precision": 0.90424,
            "recall": 0.85301,
            "f1": 0.8776
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_792": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 8.0,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 28,
        "unique-1": 22,
        "entropy-1": 4.683542362433229,
        "distinct-2": 0.9705882352941176,
        "vocab_size-2": 33,
        "unique-2": 32,
        "entropy-2": 5.028639311838573,
        "cond_entropy-2": 0.3148841634647017,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.024962841250339415,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 7.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.78125,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.515319531114783,
        "distinct-2-nopunct": 0.9666666666666667,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.840223928941852,
        "cond_entropy-2-nopunct": 0.30438434572871126,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.028107102122342926,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78655,
            "recall": 0.82361,
            "fmeasure": 0.80317
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.61184,
            "fmeasure": 0.61824
        },
        "rougeL": {
            "precision": 0.78655,
            "recall": 0.76944,
            "fmeasure": 0.77778
        },
        "rougeLsum": {
            "precision": 0.78655,
            "recall": 0.76944,
            "fmeasure": 0.77778
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.42857142857142855,
            "3": 0.8571428571428571
        },
        "nist": 4.989198974032595,
        "bleu": 68.78921,
        "bleurt": 0.59916,
        "nubia": {
            "semantic_relation": 4.59903,
            "contradiction": 0.14802,
            "irrelevancy": 1.85193,
            "logical_agreement": 98.00005,
            "grammar_ref": 4.56769,
            "grammar_hyp": 4.17229,
            "nubia_score": 0.91527
        },
        "meteor": 0.4856443805986503,
        "bertscore": {
            "precision": 0.95865,
            "recall": 0.96254,
            "f1": 0.95588
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_854": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 2.449489742783178,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 19,
        "distinct-1": 0.6041666666666666,
        "vocab_size-1": 29,
        "unique-1": 17,
        "entropy-1": 4.662782031835942,
        "distinct-2": 0.8222222222222222,
        "vocab_size-2": 37,
        "unique-2": 31,
        "entropy-2": 5.091853096329674,
        "cond_entropy-2": 0.3848855957046725,
        "distinct-3": 0.8809523809523809,
        "vocab_size-3": 37,
        "unique-3": 32,
        "entropy-3": 5.154222184683524,
        "cond_entropy-3": 0.04332146930622843,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 3.0912061651652345,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6341463414634146,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.491459931341817,
        "distinct-2-nopunct": 0.8157894736842105,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.82687488186464,
        "cond_entropy-2-nopunct": 0.3511590615709476,
        "distinct-3-nopunct": 0.8571428571428571,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.843568731230678,
        "cond_entropy-3-nopunct": 0.0527840749299525,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.68519,
            "recall": 0.60133,
            "fmeasure": 0.62774
        },
        "rouge2": {
            "precision": 0.44742,
            "recall": 0.41288,
            "fmeasure": 0.41703
        },
        "rougeL": {
            "precision": 0.5463,
            "recall": 0.49691,
            "fmeasure": 0.50871
        },
        "rougeLsum": {
            "precision": 0.5463,
            "recall": 0.49691,
            "fmeasure": 0.50871
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.55,
            "3": 0.631578947368421
        },
        "nist": 2.8775094816508204,
        "bleu": 16.44498,
        "bleurt": -0.23,
        "nubia": {
            "semantic_relation": 3.15835,
            "contradiction": 3.69052,
            "irrelevancy": 61.76117,
            "logical_agreement": 34.54831,
            "grammar_ref": 3.73262,
            "grammar_hyp": 4.5597,
            "nubia_score": 0.4012
        },
        "meteor": 0.31688458523438634,
        "bertscore": {
            "precision": 0.87886,
            "recall": 0.86412,
            "f1": 0.87081
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_855": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 18,
        "unique-1": 15,
        "entropy-1": 4.061482186720775,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.3497852090063903,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.892407118592875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.29726901589669724,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.87719,
            "recall": 0.79365,
            "fmeasure": 0.83333
        },
        "rouge2": {
            "precision": 0.59259,
            "recall": 0.71282,
            "fmeasure": 0.64063
        },
        "rougeL": {
            "precision": 0.63158,
            "recall": 0.57143,
            "fmeasure": 0.6
        },
        "rougeLsum": {
            "precision": 0.63158,
            "recall": 0.57143,
            "fmeasure": 0.6
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.5,
            "3": 0.9090909090909091
        },
        "nist": 5.220984270746222,
        "bleu": 66.47043,
        "bleurt": 0.33751,
        "nubia": {
            "semantic_relation": 4.62505,
            "contradiction": 0.14217,
            "irrelevancy": 33.54517,
            "logical_agreement": 66.31266,
            "grammar_ref": 3.68983,
            "grammar_hyp": 3.82655,
            "nubia_score": 0.90306
        },
        "meteor": 0.5020084403606202,
        "bertscore": {
            "precision": 0.96065,
            "recall": 0.95836,
            "f1": 0.94641
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_663": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 11.333333333333334,
        "std_pred_length": 6.182412330330469,
        "median_pred_length": 8.0,
        "min_pred_length": 6,
        "max_pred_length": 20,
        "distinct-1": 0.7647058823529411,
        "vocab_size-1": 26,
        "unique-1": 20,
        "entropy-1": 4.572469458770135,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": 0.27818145307729286,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.14684138832927116,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 9.333333333333334,
        "std_pred_length-nopunct": 4.784233364802441,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.351823225551767,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.3466967678036592,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1844245711374276,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81849,
            "recall": 0.69846,
            "fmeasure": 0.72165
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.52083,
            "fmeasure": 0.51634
        },
        "rougeL": {
            "precision": 0.75182,
            "recall": 0.67172,
            "fmeasure": 0.68377
        },
        "rougeLsum": {
            "precision": 0.75182,
            "recall": 0.67172,
            "fmeasure": 0.68377
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "nist": 3.4222255732869944,
        "bleu": 59.25075,
        "bleurt": 0.44786,
        "nubia": {
            "semantic_relation": 3.70515,
            "contradiction": 35.83894,
            "irrelevancy": 11.15585,
            "logical_agreement": 53.00522,
            "grammar_ref": 4.11451,
            "grammar_hyp": 4.48869,
            "nubia_score": 0.58321
        },
        "meteor": 0.4453080237374264,
        "bertscore": {
            "precision": 0.95437,
            "recall": 0.92468,
            "f1": 0.93845
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_632": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 11,
        "unique-1": 9,
        "entropy-1": 3.3927474104487847,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.21785611591339743,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.2516291673878226,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.2381054815525046,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75,
            "recall": 0.38384,
            "fmeasure": 0.50679
        },
        "rouge2": {
            "precision": 0.63636,
            "recall": 0.31197,
            "fmeasure": 0.41779
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.34119,
            "fmeasure": 0.45048
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.34119,
            "fmeasure": 0.45048
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "nist": 0.3411038620047611,
        "bleu": 20.4264,
        "bleurt": -0.25713,
        "nubia": {
            "semantic_relation": 3.2368,
            "contradiction": 7.90976,
            "irrelevancy": 1.56267,
            "logical_agreement": 90.52756,
            "grammar_ref": 5.07625,
            "grammar_hyp": 5.20401,
            "nubia_score": 0.34231
        },
        "meteor": 0.2559610186768102,
        "bertscore": {
            "precision": 0.88093,
            "recall": 0.83265,
            "f1": 0.85611
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_856": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.8695652173913043,
        "vocab_size-1": 20,
        "unique-1": 17,
        "entropy-1": 4.262692390839622,
        "distinct-2": 0.9545454545454546,
        "vocab_size-2": 21,
        "unique-2": 20,
        "entropy-2": 4.368522527728205,
        "cond_entropy-2": 0.11768784439846627,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": 0.02812389937955851,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.106603137064474,
        "distinct-2-nopunct": 0.95,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.221928094887362,
        "cond_entropy-2-nopunct": 0.129610672108602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": 0.03126257645096009,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.6,
            "recall": 0.68452,
            "fmeasure": 0.63886
        },
        "rouge2": {
            "precision": 0.40278,
            "recall": 0.48333,
            "fmeasure": 0.43939
        },
        "rougeL": {
            "precision": 0.32,
            "recall": 0.36508,
            "fmeasure": 0.34073
        },
        "rougeLsum": {
            "precision": 0.32,
            "recall": 0.36508,
            "fmeasure": 0.34073
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6666666666666666
        },
        "nist": 2.838484330930212,
        "bleu": 25.18966,
        "bleurt": -0.12768,
        "nubia": {
            "semantic_relation": 4.10152,
            "contradiction": 1.84356,
            "irrelevancy": 68.03676,
            "logical_agreement": 30.11968,
            "grammar_ref": 6.02354,
            "grammar_hyp": 5.65027,
            "nubia_score": 0.701
        },
        "meteor": 0.3900483694683282,
        "bertscore": {
            "precision": 0.87915,
            "recall": 0.88058,
            "f1": 0.87693
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-large (Baseline)/e2e_nlg_test",
        "N": 120,
        "msttr-100": 0.31857,
        "msttr-100_nopunct": 0.33053,
        "total_length": 2154,
        "mean_pred_length": 17.95,
        "std_pred_length": 7.079136011312868,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 32,
        "distinct-1": 0.06824512534818941,
        "vocab_size-1": 147,
        "unique-1": 14,
        "entropy-1": 5.814116924701179,
        "distinct-2": 0.1455260570304818,
        "vocab_size-2": 296,
        "unique-2": 59,
        "entropy-2": 7.1455304604256265,
        "cond_entropy-2": 1.2223781029702474,
        "distinct-3": 0.19644723092998956,
        "vocab_size-3": 376,
        "unique-3": 91,
        "entropy-3": 7.671652494748652,
        "cond_entropy-3": 0.5928056887687227,
        "total_length-nopunct": 1985,
        "mean_pred_length-nopunct": 16.541666666666668,
        "std_pred_length-nopunct": 6.636886611121881,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.07355163727959697,
        "vocab_size-1-nopunct": 146,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 5.8786209349168805,
        "distinct-2-nopunct": 0.14584450402144772,
        "vocab_size-2-nopunct": 272,
        "unique-2-nopunct": 54,
        "entropy-2-nopunct": 7.008620535003977,
        "cond_entropy-2-nopunct": 1.2500014531347738,
        "distinct-3-nopunct": 0.20114613180515759,
        "vocab_size-3-nopunct": 351,
        "unique-3-nopunct": 85,
        "entropy-3-nopunct": 7.577050235321696,
        "cond_entropy-3-nopunct": 0.630163945158501,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.54318,
            "recall": 0.64564,
            "fmeasure": 0.55232
        },
        "rouge2": {
            "precision": 0.32466,
            "recall": 0.39086,
            "fmeasure": 0.32929
        },
        "rougeL": {
            "precision": 0.4438,
            "recall": 0.52112,
            "fmeasure": 0.44735
        },
        "rougeLsum": {
            "precision": 0.4438,
            "recall": 0.52112,
            "fmeasure": 0.44735
        },
        "local_recall": {
            "1": 0.6142571618920719
        },
        "nist": 3.241902646123368,
        "bleu": 19.43044,
        "bleurt": -0.32565,
        "nubia": {
            "semantic_relation": 3.61179,
            "contradiction": 6.19966,
            "irrelevancy": 58.88203,
            "logical_agreement": 34.91832,
            "grammar_ref": 5.42765,
            "grammar_hyp": 4.9233,
            "nubia_score": 0.52864
        },
        "meteor": 0.2981064453577275,
        "bertscore": {
            "precision": 0.87183,
            "recall": 0.88263,
            "f1": 0.87595
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_728": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 0.5,
        "median_pred_length": 12.5,
        "min_pred_length": 12,
        "max_pred_length": 13,
        "distinct-1": 0.6,
        "vocab_size-1": 15,
        "unique-1": 7,
        "entropy-1": 3.7638561897747236,
        "distinct-2": 0.6956521739130435,
        "vocab_size-2": 16,
        "unique-2": 9,
        "entropy-2": 3.9148663038831004,
        "cond_entropy-2": 0.14057533149967955,
        "distinct-3": 0.7142857142857143,
        "vocab_size-3": 15,
        "unique-3": 9,
        "entropy-3": 3.820888851350188,
        "cond_entropy-3": -0.03600643804015718,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.6086956521739131,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.6539967386657093,
        "distinct-2-nopunct": 0.6666666666666666,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 3.7256507561120933,
        "cond_entropy-2-nopunct": 0.15446975243603325,
        "distinct-3-nopunct": 0.6842105263157895,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 3.6163485660751635,
        "cond_entropy-3-nopunct": -0.039126751440438104,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65404,
            "recall": 0.77991,
            "fmeasure": 0.69418
        },
        "rouge2": {
            "precision": 0.43333,
            "recall": 0.51313,
            "fmeasure": 0.45613
        },
        "rougeL": {
            "precision": 0.50126,
            "recall": 0.63568,
            "fmeasure": 0.54585
        },
        "rougeLsum": {
            "precision": 0.50126,
            "recall": 0.63568,
            "fmeasure": 0.54585
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.3333333333333333,
            "3": 0.8666666666666667
        },
        "nist": 3.3144704999849504,
        "bleu": 29.76171,
        "bleurt": -0.01983,
        "nubia": {
            "semantic_relation": 3.96258,
            "contradiction": 0.18928,
            "irrelevancy": 66.18077,
            "logical_agreement": 33.62995,
            "grammar_ref": 5.09196,
            "grammar_hyp": 4.66472,
            "nubia_score": 0.71925
        },
        "meteor": 0.44985942709171706,
        "bertscore": {
            "precision": 0.90492,
            "recall": 0.9509,
            "f1": 0.92628
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_858": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.08389415539832848,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.96429,
            "fmeasure": 0.8256
        },
        "rouge2": {
            "precision": 0.52941,
            "recall": 0.72115,
            "fmeasure": 0.61034
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.81593,
            "fmeasure": 0.69859
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.81593,
            "fmeasure": 0.69859
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.9
        },
        "nist": 2.6515965012503964,
        "bleu": 31.2767,
        "bleurt": -0.12747,
        "nubia": {
            "semantic_relation": 4.66563,
            "contradiction": 0.07803,
            "irrelevancy": 98.03883,
            "logical_agreement": 1.88313,
            "grammar_ref": 4.1674,
            "grammar_hyp": 5.58186,
            "nubia_score": 0.63743
        },
        "meteor": 0.35853083267771274,
        "bertscore": {
            "precision": 0.87916,
            "recall": 0.91975,
            "f1": 0.8982
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_795": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.55556,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.125,
            "fmeasure": 0.15385
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.22222,
            "fmeasure": 0.26667
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.22222,
            "fmeasure": 0.26667
        },
        "local_recall": {
            "1": 0,
            "2": 0.45454545454545453
        },
        "nist": 0.6304149766941763,
        "bleu": 7.33573,
        "bleurt": 0.00942,
        "nubia": {
            "semantic_relation": 4.02683,
            "contradiction": 3.15839,
            "irrelevancy": 22.2673,
            "logical_agreement": 74.57432,
            "grammar_ref": 4.80739,
            "grammar_hyp": 4.13608,
            "nubia_score": 0.7704
        },
        "meteor": 0.23200981519179284,
        "bertscore": {
            "precision": 0.78067,
            "recall": 0.76674,
            "f1": 0.77364
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_735": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 22,
        "unique-1": 18,
        "entropy-1": 4.392747410448783,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.26341647163363247,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.095795255000932,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.3138381850938442,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.49275,
            "recall": 0.69281,
            "fmeasure": 0.57544
        },
        "rouge2": {
            "precision": 0.25758,
            "recall": 0.40152,
            "fmeasure": 0.31154
        },
        "rougeL": {
            "precision": 0.28986,
            "recall": 0.40784,
            "fmeasure": 0.3386
        },
        "rougeLsum": {
            "precision": 0.28986,
            "recall": 0.40784,
            "fmeasure": 0.3386
        },
        "local_recall": {
            "1": 0,
            "2": 0.8333333333333334,
            "3": 0.6
        },
        "nist": 2.223663226187963,
        "bleu": 15.98052,
        "bleurt": -0.59892,
        "nubia": {
            "semantic_relation": 3.18066,
            "contradiction": 89.88814,
            "irrelevancy": 7.05611,
            "logical_agreement": 3.05575,
            "grammar_ref": 4.69116,
            "grammar_hyp": 3.8079,
            "nubia_score": 0.51203
        },
        "meteor": 0.335190136593001,
        "bertscore": {
            "precision": 0.83795,
            "recall": 0.8884,
            "f1": 0.85543
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_860": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.277613436819116,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.037503523749935014,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.41667,
            "fmeasure": 0.47619
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.18182,
            "fmeasure": 0.21053
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.33333,
            "fmeasure": 0.38095
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.33333,
            "fmeasure": 0.38095
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "nist": 1.8940012323125859,
        "bleu": 15.14869,
        "bleurt": -0.25643,
        "nubia": {
            "semantic_relation": 3.94731,
            "contradiction": 1.61948,
            "irrelevancy": 95.75607,
            "logical_agreement": 2.62444,
            "grammar_ref": 5.64121,
            "grammar_hyp": 6.31455,
            "nubia_score": 0.49156
        },
        "meteor": 0.2861714160399236,
        "bertscore": {
            "precision": 0.88439,
            "recall": 0.85522,
            "f1": 0.86956
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_635": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 4.482634504257068,
        "bleu": 100.0,
        "bleurt": 0.76845,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2983,
            "irrelevancy": 0.53829,
            "logical_agreement": 99.16341,
            "grammar_ref": 5.3705,
            "grammar_hyp": 5.33734,
            "nubia_score": 0.99191
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_736": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 14,
        "unique-1": 10,
        "entropy-1": 3.7254805569978675,
        "distinct-2": 0.9375,
        "vocab_size-2": 15,
        "unique-2": 14,
        "entropy-2": 3.875,
        "cond_entropy-2": 0.08007499855768763,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.04978793508525297,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.625,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.6644977792004623,
        "cond_entropy-2-nopunct": 0.0930692077718899,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.055725754669781344,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75,
            "recall": 0.71481,
            "fmeasure": 0.73094
        },
        "rouge2": {
            "precision": 0.54762,
            "recall": 0.53042,
            "fmeasure": 0.53829
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.58981,
            "fmeasure": 0.60594
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.58981,
            "fmeasure": 0.60594
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7058823529411765
        },
        "nist": 3.035692374520041,
        "bleu": 36.53166,
        "bleurt": 0.60675,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.15914,
            "irrelevancy": 0.47736,
            "logical_agreement": 99.36349,
            "grammar_ref": 4.99735,
            "grammar_hyp": 5.24758,
            "nubia_score": 0.99469
        },
        "meteor": 0.3986578936848289,
        "bertscore": {
            "precision": 0.95474,
            "recall": 0.93062,
            "f1": 0.94251
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_798": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 58,
        "mean_pred_length": 19.333333333333332,
        "std_pred_length": 3.39934634239519,
        "median_pred_length": 18.0,
        "min_pred_length": 16,
        "max_pred_length": 24,
        "distinct-1": 0.5,
        "vocab_size-1": 29,
        "unique-1": 17,
        "entropy-1": 4.553692365959561,
        "distinct-2": 0.6545454545454545,
        "vocab_size-2": 36,
        "unique-2": 23,
        "entropy-2": 5.00809925874319,
        "cond_entropy-2": 0.4390974088807289,
        "distinct-3": 0.6923076923076923,
        "vocab_size-3": 36,
        "unique-3": 24,
        "entropy-3": 5.026986833359288,
        "cond_entropy-3": 0.025037216238104384,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 2.943920288775949,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.5,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.442038372726781,
        "distinct-2-nopunct": 0.6470588235294118,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.877732694658147,
        "cond_entropy-2-nopunct": 0.41154966285034006,
        "distinct-3-nopunct": 0.6875,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.897055208874201,
        "cond_entropy-3-nopunct": 0.0029507004764236207,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77522,
            "recall": 0.78061,
            "fmeasure": 0.76983
        },
        "rouge2": {
            "precision": 0.54464,
            "recall": 0.54626,
            "fmeasure": 0.53849
        },
        "rougeL": {
            "precision": 0.69123,
            "recall": 0.69007,
            "fmeasure": 0.68392
        },
        "rougeLsum": {
            "precision": 0.69123,
            "recall": 0.69007,
            "fmeasure": 0.68392
        },
        "local_recall": {
            "1": 0.7,
            "2": 0.3333333333333333,
            "3": 0.8157894736842105
        },
        "nist": 4.642339485199481,
        "bleu": 47.30792,
        "bleurt": -0.00534,
        "nubia": {
            "semantic_relation": 4.35858,
            "contradiction": 0.77886,
            "irrelevancy": 45.30371,
            "logical_agreement": 53.91743,
            "grammar_ref": 5.76985,
            "grammar_hyp": 5.51441,
            "nubia_score": 0.75739
        },
        "meteor": 0.4341521473257983,
        "bertscore": {
            "precision": 0.93443,
            "recall": 0.92467,
            "f1": 0.92938
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_864": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 8,
        "unique-1": 7,
        "entropy-1": 2.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": 0.08007499855768763,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": 0.0930692077718899,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 2.4156844010247407,
        "bleu": 100.0,
        "bleurt": 0.6432,
        "nubia": {
            "semantic_relation": 4.64096,
            "contradiction": 0.21793,
            "irrelevancy": 0.49368,
            "logical_agreement": 99.2884,
            "grammar_ref": 5.14316,
            "grammar_hyp": 5.3673,
            "nubia_score": 0.85584
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_740": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.88889,
            "fmeasure": 0.92063
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.81818,
            "fmeasure": 0.84211
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.88889,
            "fmeasure": 0.92063
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.88889,
            "fmeasure": 0.92063
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.7224676484285957,
        "bleu": 100.0,
        "bleurt": 0.68577,
        "nubia": {
            "semantic_relation": 4.40157,
            "contradiction": 5.65972,
            "irrelevancy": 2.65283,
            "logical_agreement": 91.68745,
            "grammar_ref": 4.01628,
            "grammar_hyp": 3.81914,
            "nubia_score": 0.8297
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_665": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.81667,
            "fmeasure": 0.82857
        },
        "rouge2": {
            "precision": 0.70833,
            "recall": 0.68506,
            "fmeasure": 0.69398
        },
        "rougeL": {
            "precision": 0.84615,
            "recall": 0.81667,
            "fmeasure": 0.82857
        },
        "rougeLsum": {
            "precision": 0.84615,
            "recall": 0.81667,
            "fmeasure": 0.82857
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 1.0
        },
        "nist": 4.09251370597287,
        "bleu": 67.29865,
        "bleurt": 0.67946,
        "nubia": {
            "semantic_relation": 4.67622,
            "contradiction": 0.49994,
            "irrelevancy": 0.68259,
            "logical_agreement": 98.81746,
            "grammar_ref": 5.25223,
            "grammar_hyp": 5.20882,
            "nubia_score": 0.8468
        },
        "meteor": 0.5934341018717497,
        "bertscore": {
            "precision": 0.9565,
            "recall": 0.9669,
            "f1": 0.96167
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_868": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 0.5,
        "median_pred_length": 16.5,
        "min_pred_length": 16,
        "max_pred_length": 17,
        "distinct-1": 0.5151515151515151,
        "vocab_size-1": 17,
        "unique-1": 5,
        "entropy-1": 3.9683403313485464,
        "distinct-2": 0.6451612903225806,
        "vocab_size-2": 20,
        "unique-2": 9,
        "entropy-2": 4.244518891032037,
        "cond_entropy-2": 0.2810852556841295,
        "distinct-3": 0.6551724137931034,
        "vocab_size-3": 19,
        "unique-3": 9,
        "entropy-3": 4.168325822713779,
        "cond_entropy-3": -0.02724979801792366,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.5161290322580645,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 3.8732358263763285,
        "distinct-2-nopunct": 0.6206896551724138,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 4.0993603054724,
        "cond_entropy-2-nopunct": 0.24601959865813772,
        "distinct-3-nopunct": 0.6296296296296297,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 4.014146761422729,
        "cond_entropy-3-nopunct": -0.02901941889002934,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.60076,
            "recall": 0.67407,
            "fmeasure": 0.62559
        },
        "rouge2": {
            "precision": 0.4663,
            "recall": 0.53885,
            "fmeasure": 0.49184
        },
        "rougeL": {
            "precision": 0.47876,
            "recall": 0.65705,
            "fmeasure": 0.55305
        },
        "rougeLsum": {
            "precision": 0.47876,
            "recall": 0.65705,
            "fmeasure": 0.55305
        },
        "local_recall": {
            "1": 0.4117647058823529,
            "2": 0.2857142857142857,
            "3": 0.6875
        },
        "nist": 4.110620727442172,
        "bleu": 55.53974,
        "bleurt": -0.00795,
        "nubia": {
            "semantic_relation": 3.85389,
            "contradiction": 22.72442,
            "irrelevancy": 52.99691,
            "logical_agreement": 24.27867,
            "grammar_ref": 3.56015,
            "grammar_hyp": 3.03878,
            "nubia_score": 0.76412
        },
        "meteor": 0.40993894646373746,
        "bertscore": {
            "precision": 0.89395,
            "recall": 0.91809,
            "f1": 0.90151
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_800": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 11.0,
        "std_pred_length": 2.449489742783178,
        "median_pred_length": 11.0,
        "min_pred_length": 8,
        "max_pred_length": 14,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 27,
        "unique-1": 22,
        "entropy-1": 4.6578823768686535,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 28,
        "unique-2": 26,
        "entropy-2": 4.773557262275185,
        "cond_entropy-2": -0.0041701904166014095,
        "distinct-3": 0.9629629629629629,
        "vocab_size-3": 26,
        "unique-3": 25,
        "entropy-3": 4.6808134280893965,
        "cond_entropy-3": -0.07792901937097599,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 9.666666666666666,
        "std_pred_length-nopunct": 2.0548046676563256,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8620689655172413,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.582118926162054,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.546593564294937,
        "cond_entropy-2-nopunct": -0.04215666160186466,
        "distinct-3-nopunct": 0.9565217391304348,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.436605434317882,
        "cond_entropy-3-nopunct": -0.08992124034494872,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.60714,
            "recall": 0.56848,
            "fmeasure": 0.58229
        },
        "rouge2": {
            "precision": 0.19024,
            "recall": 0.17363,
            "fmeasure": 0.17926
        },
        "rougeL": {
            "precision": 0.47619,
            "recall": 0.4418,
            "fmeasure": 0.45389
        },
        "rougeLsum": {
            "precision": 0.47619,
            "recall": 0.4418,
            "fmeasure": 0.45389
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 0.5862068965517241
        },
        "nist": 2.5020734585791202,
        "bleu": 10.67853,
        "bleurt": -0.06617,
        "nubia": {
            "semantic_relation": 3.73713,
            "contradiction": 55.90271,
            "irrelevancy": 20.61182,
            "logical_agreement": 23.48548,
            "grammar_ref": 5.969,
            "grammar_hyp": 6.0547,
            "nubia_score": 0.46452
        },
        "meteor": 0.26912802632039445,
        "bertscore": {
            "precision": 0.90456,
            "recall": 0.88861,
            "f1": 0.89644
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_805": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.46154,
            "recall": 0.66667,
            "fmeasure": 0.54095
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.18182,
            "fmeasure": 0.17391
        },
        "rougeL": {
            "precision": 0.30769,
            "recall": 0.44444,
            "fmeasure": 0.36063
        },
        "rougeLsum": {
            "precision": 0.30769,
            "recall": 0.44444,
            "fmeasure": 0.36063
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "nist": 1.8334882352877773,
        "bleu": 15.13322,
        "bleurt": -0.18634,
        "nubia": {
            "semantic_relation": 3.25459,
            "contradiction": 0.08136,
            "irrelevancy": 99.74084,
            "logical_agreement": 0.1778,
            "grammar_ref": 5.08958,
            "grammar_hyp": 3.93988,
            "nubia_score": 0.56992
        },
        "meteor": 0.2056021939504506,
        "bertscore": {
            "precision": 0.76793,
            "recall": 0.87287,
            "f1": 0.81704
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_667": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.42857,
            "recall": 0.31053,
            "fmeasure": 0.36007
        },
        "rouge2": {
            "precision": 0.07692,
            "recall": 0.05458,
            "fmeasure": 0.06384
        },
        "rougeL": {
            "precision": 0.21429,
            "recall": 0.15526,
            "fmeasure": 0.18004
        },
        "rougeLsum": {
            "precision": 0.21429,
            "recall": 0.15526,
            "fmeasure": 0.18004
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.3125
        },
        "nist": 1.0524416978019213,
        "bleu": 5.60061,
        "bleurt": -0.3402,
        "nubia": {
            "semantic_relation": 3.31408,
            "contradiction": 0.10117,
            "irrelevancy": 99.27464,
            "logical_agreement": 0.62419,
            "grammar_ref": 4.46991,
            "grammar_hyp": 4.6028,
            "nubia_score": 0.41578
        },
        "meteor": 0.20028017791631325,
        "bertscore": {
            "precision": 0.80308,
            "recall": 0.7855,
            "f1": 0.79419
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_742": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.8,
            "fmeasure": 0.72727
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 2.456435556800404,
        "bleu": 50.0,
        "bleurt": 0.93658,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.14589,
            "irrelevancy": 0.6446,
            "logical_agreement": 98.20952,
            "grammar_ref": 4.87815,
            "grammar_hyp": 4.39193,
            "nubia_score": 1.0
        },
        "meteor": 0.5277006683854432,
        "bertscore": {
            "precision": 0.986,
            "recall": 0.99497,
            "f1": 0.99047
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_873": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.7857142857142857,
        "vocab_size-1": 11,
        "unique-1": 9,
        "entropy-1": 3.3248629576173574,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.41269152701913925,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7692307692307693,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.180832987205441,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.44743007442701976,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80769,
            "recall": 0.52328,
            "fmeasure": 0.63063
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.21196,
            "fmeasure": 0.25714
        },
        "rougeL": {
            "precision": 0.61538,
            "recall": 0.40196,
            "fmeasure": 0.48288
        },
        "rougeLsum": {
            "precision": 0.61538,
            "recall": 0.40196,
            "fmeasure": 0.48288
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5714285714285714
        },
        "nist": 1.3330872431410694,
        "bleu": 12.43902,
        "bleurt": 0.1598,
        "nubia": {
            "semantic_relation": 4.08361,
            "contradiction": 0.86186,
            "irrelevancy": 1.20541,
            "logical_agreement": 97.93274,
            "grammar_ref": 4.95035,
            "grammar_hyp": 5.72147,
            "nubia_score": 0.56726
        },
        "meteor": 0.2854882302944084,
        "bertscore": {
            "precision": 0.93611,
            "recall": 0.88697,
            "f1": 0.91088
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_876": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.85714,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.5,
            "fmeasure": 0.375
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.85714,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.85714,
            "fmeasure": 0.66667
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7142857142857143
        },
        "nist": 1.5,
        "bleu": 10.60031,
        "bleurt": 0.68944,
        "nubia": {
            "semantic_relation": 4.7181,
            "contradiction": 0.18101,
            "irrelevancy": 42.50259,
            "logical_agreement": 57.31642,
            "grammar_ref": 5.74517,
            "grammar_hyp": 3.91475,
            "nubia_score": 1.0
        },
        "meteor": 0.44519131687853003,
        "bertscore": {
            "precision": 0.88921,
            "recall": 0.94805,
            "f1": 0.91769
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_748": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 4.5,
        "median_pred_length": 17.5,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.6857142857142857,
        "vocab_size-1": 24,
        "unique-1": 13,
        "entropy-1": 4.5007115883735365,
        "distinct-2": 0.7272727272727273,
        "vocab_size-2": 24,
        "unique-2": 15,
        "entropy-2": 4.498939573903909,
        "cond_entropy-2": -0.024282836980452638,
        "distinct-3": 0.7419354838709677,
        "vocab_size-3": 23,
        "unique-3": 15,
        "entropy-3": 4.438067278128811,
        "cond_entropy-3": -0.09019780897157816,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7096774193548387,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.373551149096553,
        "distinct-2-nopunct": 0.7241379310344828,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 4.306256857196537,
        "cond_entropy-2-nopunct": -0.09621531525930296,
        "distinct-3-nopunct": 0.7407407407407407,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 4.23636898364495,
        "cond_entropy-3-nopunct": -0.10309349296410339,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.62719,
            "recall": 0.65626,
            "fmeasure": 0.64114
        },
        "rouge2": {
            "precision": 0.35859,
            "recall": 0.40758,
            "fmeasure": 0.37849
        },
        "rougeL": {
            "precision": 0.46053,
            "recall": 0.56512,
            "fmeasure": 0.50309
        },
        "rougeLsum": {
            "precision": 0.46053,
            "recall": 0.56512,
            "fmeasure": 0.50309
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6363636363636364,
            "3": 0.7777777777777778
        },
        "nist": 3.348512195452516,
        "bleu": 20.9912,
        "bleurt": -0.18108,
        "nubia": {
            "semantic_relation": 4.62597,
            "contradiction": 0.53444,
            "irrelevancy": 23.70685,
            "logical_agreement": 75.7587,
            "grammar_ref": 3.87403,
            "grammar_hyp": 4.05841,
            "nubia_score": 0.86202
        },
        "meteor": 0.3929947574023172,
        "bertscore": {
            "precision": 0.90778,
            "recall": 0.90936,
            "f1": 0.90743
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_636": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.033108599109837954,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.037537158749660585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.89474,
            "recall": 0.76153,
            "fmeasure": 0.82269
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.55267,
            "fmeasure": 0.60427
        },
        "rougeL": {
            "precision": 0.82456,
            "recall": 0.69104,
            "fmeasure": 0.75184
        },
        "rougeLsum": {
            "precision": 0.82456,
            "recall": 0.69104,
            "fmeasure": 0.75184
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.7647058823529411
        },
        "nist": 3.0398761319201837,
        "bleu": 46.0002,
        "bleurt": 0.43261,
        "nubia": {
            "semantic_relation": 4.34275,
            "contradiction": 0.11339,
            "irrelevancy": 1.47731,
            "logical_agreement": 98.40931,
            "grammar_ref": 3.0511,
            "grammar_hyp": 2.85893,
            "nubia_score": 0.92287
        },
        "meteor": 0.41086177530149887,
        "bertscore": {
            "precision": 0.95573,
            "recall": 0.93158,
            "f1": 0.9435
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_749": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322706,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.277613436819116,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.61538,
            "fmeasure": 0.64
        },
        "rouge2": {
            "precision": 0.45455,
            "recall": 0.41667,
            "fmeasure": 0.43478
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.61538,
            "fmeasure": 0.64
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.61538,
            "fmeasure": 0.64
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.4166666666666667
        },
        "nist": 2.2525263171991474,
        "bleu": 21.18855,
        "bleurt": 0.45429,
        "nubia": {
            "semantic_relation": 4.21144,
            "contradiction": 67.13493,
            "irrelevancy": 14.6111,
            "logical_agreement": 18.25397,
            "grammar_ref": 4.23153,
            "grammar_hyp": 3.7876,
            "nubia_score": 0.75693
        },
        "meteor": 0.4077294945384672,
        "bertscore": {
            "precision": 0.90148,
            "recall": 0.89659,
            "f1": 0.89879
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_882": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 4.0,
        "median_pred_length": 17.0,
        "min_pred_length": 13,
        "max_pred_length": 21,
        "distinct-1": 0.8529411764705882,
        "vocab_size-1": 29,
        "unique-1": 25,
        "entropy-1": 4.7711426205984715,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.18612739319226904,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.09310940439148141,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.6150610122030695,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.2131388800977809,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.92982,
            "recall": 0.88,
            "fmeasure": 0.90229
        },
        "rouge2": {
            "precision": 0.75926,
            "recall": 0.73604,
            "fmeasure": 0.74685
        },
        "rougeL": {
            "precision": 0.84211,
            "recall": 0.80333,
            "fmeasure": 0.82071
        },
        "rougeLsum": {
            "precision": 0.84211,
            "recall": 0.80333,
            "fmeasure": 0.82071
        },
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.0,
            "3": 0.92
        },
        "nist": 4.86238945770601,
        "bleu": 65.17322,
        "bleurt": 0.52515,
        "nubia": {
            "semantic_relation": 4.56326,
            "contradiction": 0.45524,
            "irrelevancy": 27.12173,
            "logical_agreement": 72.42303,
            "grammar_ref": 4.2058,
            "grammar_hyp": 4.39177,
            "nubia_score": 0.8756
        },
        "meteor": 0.4769039634695639,
        "bertscore": {
            "precision": 0.9526,
            "recall": 0.95339,
            "f1": 0.94966
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_808": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.16253715874966052,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.640223928941851,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.18617861216337128,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.58937,
            "fmeasure": 0.56664
        },
        "rouge2": {
            "precision": 0.45098,
            "recall": 0.49206,
            "fmeasure": 0.46689
        },
        "rougeL": {
            "precision": 0.53704,
            "recall": 0.58081,
            "fmeasure": 0.55404
        },
        "rougeLsum": {
            "precision": 0.53704,
            "recall": 0.58081,
            "fmeasure": 0.55404
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5384615384615384
        },
        "nist": 2.196191450552471,
        "bleu": 39.56717,
        "bleurt": -0.15471,
        "nubia": {
            "semantic_relation": 2.62648,
            "contradiction": 14.18686,
            "irrelevancy": 85.42587,
            "logical_agreement": 0.38727,
            "grammar_ref": 4.44297,
            "grammar_hyp": 4.73333,
            "nubia_score": 0.2039
        },
        "meteor": 0.33490412258321683,
        "bertscore": {
            "precision": 0.83705,
            "recall": 0.92153,
            "f1": 0.87726
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_637": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518523,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.546593564294939,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74359,
            "recall": 0.67521,
            "fmeasure": 0.70696
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.2381,
            "fmeasure": 0.24359
        },
        "rougeL": {
            "precision": 0.41026,
            "recall": 0.45584,
            "fmeasure": 0.4289
        },
        "rougeLsum": {
            "precision": 0.41026,
            "recall": 0.45584,
            "fmeasure": 0.4289
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.42857142857142855,
            "3": 0.8333333333333334
        },
        "nist": 3.427774972009144,
        "bleu": 16.18861,
        "bleurt": -0.26938,
        "nubia": {
            "semantic_relation": 3.78932,
            "contradiction": 28.59134,
            "irrelevancy": 69.7015,
            "logical_agreement": 1.70717,
            "grammar_ref": 5.94843,
            "grammar_hyp": 5.44817,
            "nubia_score": 0.58584
        },
        "meteor": 0.3205716388201548,
        "bertscore": {
            "precision": 0.88163,
            "recall": 0.89297,
            "f1": 0.88727
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_810": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 3.0,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 19,
        "distinct-1": 0.75,
        "vocab_size-1": 24,
        "unique-1": 19,
        "entropy-1": 4.413909765557392,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.46538684568063415,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7666666666666667,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.348394345536403,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.4988531658120666,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70833,
            "recall": 0.84565,
            "fmeasure": 0.7621
        },
        "rouge2": {
            "precision": 0.4697,
            "recall": 0.54067,
            "fmeasure": 0.49625
        },
        "rougeL": {
            "precision": 0.68981,
            "recall": 0.82811,
            "fmeasure": 0.74408
        },
        "rougeLsum": {
            "precision": 0.68981,
            "recall": 0.82811,
            "fmeasure": 0.74408
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.7619047619047619
        },
        "nist": 3.3909163715645323,
        "bleu": 44.08596,
        "bleurt": 0.17456,
        "nubia": {
            "semantic_relation": 4.12545,
            "contradiction": 30.66209,
            "irrelevancy": 65.17532,
            "logical_agreement": 4.16259,
            "grammar_ref": 5.29605,
            "grammar_hyp": 5.03335,
            "nubia_score": 0.68688
        },
        "meteor": 0.41725175345326315,
        "bertscore": {
            "precision": 0.92632,
            "recall": 0.94071,
            "f1": 0.93311
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_752": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.14421971022094904,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.8521687236032816,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.1625371587496606,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.55882,
            "recall": 0.76389,
            "fmeasure": 0.63287
        },
        "rouge2": {
            "precision": 0.46875,
            "recall": 0.64583,
            "fmeasure": 0.53091
        },
        "rougeL": {
            "precision": 0.55882,
            "recall": 0.76389,
            "fmeasure": 0.63287
        },
        "rougeLsum": {
            "precision": 0.55882,
            "recall": 0.76389,
            "fmeasure": 0.63287
        },
        "local_recall": {
            "1": 0.45454545454545453,
            "2": 1.0
        },
        "nist": 3.167284242023824,
        "bleu": 61.65255,
        "bleurt": -0.26358,
        "nubia": {
            "semantic_relation": 3.15117,
            "contradiction": 1.82096,
            "irrelevancy": 96.96439,
            "logical_agreement": 1.21466,
            "grammar_ref": 4.24724,
            "grammar_hyp": 3.9378,
            "nubia_score": 0.47237
        },
        "meteor": 0.46301699762786325,
        "bertscore": {
            "precision": 0.92203,
            "recall": 0.93692,
            "f1": 0.92942
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_670": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76667,
            "recall": 0.63068,
            "fmeasure": 0.68742
        },
        "rouge2": {
            "precision": 0.59259,
            "recall": 0.48889,
            "fmeasure": 0.53216
        },
        "rougeL": {
            "precision": 0.76667,
            "recall": 0.63068,
            "fmeasure": 0.68742
        },
        "rougeLsum": {
            "precision": 0.76667,
            "recall": 0.63068,
            "fmeasure": 0.68742
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.6666666666666666
        },
        "nist": 2.648529168376138,
        "bleu": 53.90595,
        "bleurt": 0.4735,
        "nubia": {
            "semantic_relation": 4.42268,
            "contradiction": 0.48172,
            "irrelevancy": 0.47937,
            "logical_agreement": 99.03891,
            "grammar_ref": 4.84054,
            "grammar_hyp": 4.44059,
            "nubia_score": 0.83222
        },
        "meteor": 0.4508446043207896,
        "bertscore": {
            "precision": 0.95217,
            "recall": 0.93968,
            "f1": 0.94588
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_640": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 65,
        "mean_pred_length": 16.25,
        "std_pred_length": 10.425329730996522,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.8,
        "vocab_size-1": 52,
        "unique-1": 43,
        "entropy-1": 5.560829351489995,
        "distinct-2": 0.9836065573770492,
        "vocab_size-2": 60,
        "unique-2": 59,
        "entropy-2": 5.897950452316981,
        "cond_entropy-2": 0.23623837699344796,
        "distinct-3": 1.0,
        "vocab_size-3": 57,
        "unique-3": 57,
        "entropy-3": 5.832890014164737,
        "cond_entropy-3": -0.06275960409989875,
        "total_length-nopunct": 58,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 9.313968005098578,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.8448275862068966,
        "vocab_size-1-nopunct": 49,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.513153408920674,
        "distinct-2-nopunct": 0.9814814814814815,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 52,
        "entropy-2-nopunct": 5.717850465126429,
        "cond_entropy-2-nopunct": 0.21172132185071163,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.643856189774728,
        "cond_entropy-3-nopunct": -0.07103131238874391,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75083,
            "recall": 0.7234,
            "fmeasure": 0.72887
        },
        "rouge2": {
            "precision": 0.42879,
            "recall": 0.43251,
            "fmeasure": 0.42668
        },
        "rougeL": {
            "precision": 0.68833,
            "recall": 0.64731,
            "fmeasure": 0.66025
        },
        "rougeLsum": {
            "precision": 0.68833,
            "recall": 0.64731,
            "fmeasure": 0.66025
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.4,
            "3": 0.7777777777777778
        },
        "nist": 4.257635970214246,
        "bleu": 46.67478,
        "bleurt": 0.08009,
        "nubia": {
            "semantic_relation": 4.01231,
            "contradiction": 6.28915,
            "irrelevancy": 14.90387,
            "logical_agreement": 78.80698,
            "grammar_ref": 4.34153,
            "grammar_hyp": 5.20853,
            "nubia_score": 0.6237
        },
        "meteor": 0.3824282494984143,
        "bertscore": {
            "precision": 0.92165,
            "recall": 0.87904,
            "f1": 0.89912
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_642": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 50,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 1.699673171197595,
        "median_pred_length": 16.0,
        "min_pred_length": 15,
        "max_pred_length": 19,
        "distinct-1": 0.78,
        "vocab_size-1": 39,
        "unique-1": 31,
        "entropy-1": 5.158562939644918,
        "distinct-2": 1.0,
        "vocab_size-2": 47,
        "unique-2": 47,
        "entropy-2": 5.55458885167764,
        "cond_entropy-2": 0.325834257739656,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": -0.09515723304034036,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 1.4142135623730951,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8222222222222222,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.102746985122408,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.3923174227787625,
        "cond_entropy-2-nopunct": 0.3173637313140124,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": -0.10691520391651191,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.89735,
            "recall": 0.82689,
            "fmeasure": 0.85655
        },
        "rouge2": {
            "precision": 0.65499,
            "recall": 0.59766,
            "fmeasure": 0.6209
        },
        "rougeL": {
            "precision": 0.75431,
            "recall": 0.69554,
            "fmeasure": 0.71953
        },
        "rougeLsum": {
            "precision": 0.75431,
            "recall": 0.69554,
            "fmeasure": 0.71953
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.42857142857142855,
            "3": 0.8648648648648649
        },
        "nist": 5.060798748900897,
        "bleu": 52.65742,
        "bleurt": 0.33543,
        "nubia": {
            "semantic_relation": 4.32278,
            "contradiction": 0.65606,
            "irrelevancy": 12.56791,
            "logical_agreement": 86.77602,
            "grammar_ref": 4.591,
            "grammar_hyp": 4.63393,
            "nubia_score": 0.76835
        },
        "meteor": 0.4221054149613054,
        "bertscore": {
            "precision": 0.94688,
            "recall": 0.92785,
            "f1": 0.93574
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_812": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "nist": 3.0945894140476606,
        "bleu": 62.62845,
        "bleurt": 0.79405,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.37071,
            "irrelevancy": 0.70467,
            "logical_agreement": 98.92462,
            "grammar_ref": 4.58246,
            "grammar_hyp": 4.34125,
            "nubia_score": 0.98178
        },
        "meteor": 0.512675617900284,
        "bertscore": {
            "precision": 0.96634,
            "recall": 0.98092,
            "f1": 0.97358
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_815": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 0.5,
        "median_pred_length": 13.5,
        "min_pred_length": 13,
        "max_pred_length": 14,
        "distinct-1": 0.8518518518518519,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.430632409490749,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.1591641876977948,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.303508854797679,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.18150945892357132,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.87821,
            "recall": 0.88828,
            "fmeasure": 0.88306
        },
        "rouge2": {
            "precision": 0.66987,
            "recall": 0.67735,
            "fmeasure": 0.67346
        },
        "rougeL": {
            "precision": 0.84249,
            "recall": 0.85165,
            "fmeasure": 0.8469
        },
        "rougeLsum": {
            "precision": 0.84249,
            "recall": 0.85165,
            "fmeasure": 0.8469
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.5,
            "3": 0.7894736842105263
        },
        "nist": 3.9257619883095596,
        "bleu": 45.51393,
        "bleurt": 0.3955,
        "nubia": {
            "semantic_relation": 4.11144,
            "contradiction": 0.99935,
            "irrelevancy": 96.58105,
            "logical_agreement": 2.4196,
            "grammar_ref": 4.97173,
            "grammar_hyp": 4.81402,
            "nubia_score": 0.67822
        },
        "meteor": 0.4435328496586512,
        "bertscore": {
            "precision": 0.94525,
            "recall": 0.95746,
            "f1": 0.94793
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_672": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 7.0,
        "median_pred_length": 20.0,
        "min_pred_length": 13,
        "max_pred_length": 27,
        "distinct-1": 0.875,
        "vocab_size-1": 35,
        "unique-1": 31,
        "entropy-1": 5.053055907333276,
        "distinct-2": 1.0,
        "vocab_size-2": 38,
        "unique-2": 38,
        "entropy-2": 5.247927513443589,
        "cond_entropy-2": 0.15639119492894601,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.0780025120012732,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 18.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8918918918918919,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.9728347844893985,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.129283016944964,
        "cond_entropy-2-nopunct": 0.14139786566354437,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.08488889758651327,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.64881,
            "recall": 0.60691,
            "fmeasure": 0.62195
        },
        "rouge2": {
            "precision": 0.39848,
            "recall": 0.3963,
            "fmeasure": 0.39529
        },
        "rougeL": {
            "precision": 0.48214,
            "recall": 0.42928,
            "fmeasure": 0.45
        },
        "rougeLsum": {
            "precision": 0.48214,
            "recall": 0.42928,
            "fmeasure": 0.45
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6333333333333333
        },
        "nist": 3.386633572692504,
        "bleu": 37.52288,
        "bleurt": -0.12799,
        "nubia": {
            "semantic_relation": 3.49562,
            "contradiction": 6.34462,
            "irrelevancy": 56.28163,
            "logical_agreement": 37.37376,
            "grammar_ref": 4.36031,
            "grammar_hyp": 4.7168,
            "nubia_score": 0.49278
        },
        "meteor": 0.35027197977592267,
        "bertscore": {
            "precision": 0.87355,
            "recall": 0.84774,
            "f1": 0.85831
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_675": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.76923,
            "fmeasure": 0.76923
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.63333,
            "fmeasure": 0.59091
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.75058,
            "fmeasure": 0.70513
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.75058,
            "fmeasure": 0.70513
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.27630381192071,
        "bleu": 64.00572,
        "bleurt": 0.21352,
        "nubia": {
            "semantic_relation": 4.80973,
            "contradiction": 0.62133,
            "irrelevancy": 38.0045,
            "logical_agreement": 61.37417,
            "grammar_ref": 4.43463,
            "grammar_hyp": 4.76683,
            "nubia_score": 0.85605
        },
        "meteor": 0.5205559484776897,
        "bertscore": {
            "precision": 0.928,
            "recall": 0.96387,
            "f1": 0.94559
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_755": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 2.0,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 12,
        "distinct-1": 0.6,
        "vocab_size-1": 12,
        "unique-1": 4,
        "entropy-1": 3.521928094887362,
        "distinct-2": 0.7222222222222222,
        "vocab_size-2": 13,
        "unique-2": 8,
        "entropy-2": 3.6143694458867563,
        "cond_entropy-2": 0.07021912877717248,
        "distinct-3": 0.75,
        "vocab_size-3": 12,
        "unique-3": 8,
        "entropy-3": 3.5,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.6111111111111112,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 3.392147223664534,
        "distinct-2-nopunct": 0.75,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.5,
        "cond_entropy-2-nopunct": 0.08007499855768765,
        "distinct-3-nopunct": 0.7857142857142857,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.378783493486176,
        "cond_entropy-3-nopunct": -0.19264507794239585,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.94444,
            "fmeasure": 0.97059
        },
        "rouge2": {
            "precision": 0.92857,
            "recall": 0.875,
            "fmeasure": 0.9
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.94444,
            "fmeasure": 0.97059
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.94444,
            "fmeasure": 0.97059
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8333333333333334
        },
        "nist": 3.919830122786615,
        "bleu": 88.33845,
        "bleurt": 0.54569,
        "nubia": {
            "semantic_relation": 4.91259,
            "contradiction": 1.68311,
            "irrelevancy": 1.04477,
            "logical_agreement": 97.27212,
            "grammar_ref": 5.78027,
            "grammar_hyp": 6.03171,
            "nubia_score": 0.91696
        },
        "meteor": 0.5406320475162033,
        "bertscore": {
            "precision": 0.9865,
            "recall": 0.97376,
            "f1": 0.98005
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_644": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 1.0,
        "median_pred_length": 15.0,
        "min_pred_length": 14,
        "max_pred_length": 16,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 28,
        "unique-1": 26,
        "entropy-1": 4.773557262275186,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": -0.028107102122342922,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9642857142857143,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.735926350629034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": -0.029992126993435272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88259,
            "recall": 0.85519,
            "fmeasure": 0.86838
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.75307,
            "fmeasure": 0.76494
        },
        "rougeL": {
            "precision": 0.88259,
            "recall": 0.85519,
            "fmeasure": 0.86838
        },
        "rougeLsum": {
            "precision": 0.88259,
            "recall": 0.85519,
            "fmeasure": 0.86838
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.92
        },
        "nist": 4.343452825284802,
        "bleu": 66.14566,
        "bleurt": 0.55603,
        "nubia": {
            "semantic_relation": 4.68308,
            "contradiction": 1.15161,
            "irrelevancy": 2.39387,
            "logical_agreement": 96.45452,
            "grammar_ref": 4.65278,
            "grammar_hyp": 4.67846,
            "nubia_score": 0.88145
        },
        "meteor": 0.48425296272997537,
        "bertscore": {
            "precision": 0.97618,
            "recall": 0.97039,
            "f1": 0.97327
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_645": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 29.0,
        "std_pred_length": 0.0,
        "median_pred_length": 29.0,
        "min_pred_length": 29,
        "max_pred_length": 29,
        "distinct-1": 0.9310344827586207,
        "vocab_size-1": 27,
        "unique-1": 25,
        "entropy-1": 4.720049960644813,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": 0.09223106978717509,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.05246741989413545,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": -0.061400544664143256,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.06413033741971555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79167,
            "recall": 0.98333,
            "fmeasure": 0.87703
        },
        "rouge2": {
            "precision": 0.65217,
            "recall": 0.81871,
            "fmeasure": 0.7259
        },
        "rougeL": {
            "precision": 0.79167,
            "recall": 0.98333,
            "fmeasure": 0.87703
        },
        "rougeLsum": {
            "precision": 0.79167,
            "recall": 0.98333,
            "fmeasure": 0.87703
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 3.6592821637891744,
        "bleu": 59.46599,
        "bleurt": 0.33566,
        "nubia": {
            "semantic_relation": 4.00401,
            "contradiction": 6.41816,
            "irrelevancy": 89.10992,
            "logical_agreement": 4.47192,
            "grammar_ref": 3.98302,
            "grammar_hyp": 3.86258,
            "nubia_score": 0.66972
        },
        "meteor": 0.5212210545306645,
        "bertscore": {
            "precision": 0.94911,
            "recall": 0.98571,
            "f1": 0.96706
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_816": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.71,
        "total_length": 124,
        "mean_pred_length": 24.8,
        "std_pred_length": 15.929846201391902,
        "median_pred_length": 18.0,
        "min_pred_length": 12,
        "max_pred_length": 56,
        "distinct-1": 0.6774193548387096,
        "vocab_size-1": 84,
        "unique-1": 68,
        "entropy-1": 6.028027488981108,
        "distinct-2": 0.9327731092436975,
        "vocab_size-2": 111,
        "unique-2": 103,
        "entropy-2": 6.760363981795337,
        "cond_entropy-2": 0.6736911451889438,
        "distinct-3": 0.956140350877193,
        "vocab_size-3": 109,
        "unique-3": 104,
        "entropy-3": 6.74517071591914,
        "cond_entropy-3": -0.009296170195833323,
        "total_length-nopunct": 106,
        "mean_pred_length-nopunct": 21.2,
        "std_pred_length-nopunct": 13.059862173851606,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.7264150943396226,
        "vocab_size-1-nopunct": 77,
        "unique-1-nopunct": 64,
        "entropy-1-nopunct": 5.958261879794566,
        "distinct-2-nopunct": 0.9207920792079208,
        "vocab_size-2-nopunct": 93,
        "unique-2-nopunct": 85,
        "entropy-2-nopunct": 6.499795641167621,
        "cond_entropy-2-nopunct": 0.5598336908170504,
        "distinct-3-nopunct": 0.9479166666666666,
        "vocab_size-3-nopunct": 91,
        "unique-3-nopunct": 86,
        "entropy-3-nopunct": 6.4807958340544936,
        "cond_entropy-3-nopunct": -0.021165648697305122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66304,
            "recall": 0.75486,
            "fmeasure": 0.68964
        },
        "rouge2": {
            "precision": 0.47494,
            "recall": 0.55205,
            "fmeasure": 0.49953
        },
        "rougeL": {
            "precision": 0.59542,
            "recall": 0.68019,
            "fmeasure": 0.62231
        },
        "rougeLsum": {
            "precision": 0.59542,
            "recall": 0.68019,
            "fmeasure": 0.62231
        },
        "local_recall": {
            "1": 0.19047619047619047,
            "2": 0.803921568627451,
            "3": 0.7714285714285715
        },
        "nist": 4.830925436700738,
        "bleu": 38.54222,
        "bleurt": 0.16808,
        "nubia": {
            "semantic_relation": 4.08641,
            "contradiction": 12.26489,
            "irrelevancy": 34.488,
            "logical_agreement": 53.24711,
            "grammar_ref": 4.74118,
            "grammar_hyp": 4.66926,
            "nubia_score": 0.70782
        },
        "meteor": 0.42596274747449725,
        "bertscore": {
            "precision": 0.9108,
            "recall": 0.92165,
            "f1": 0.91116
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_678": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673073,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432275,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.9,
            "fmeasure": 0.92105
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.8888888888888888
        },
        "nist": 2.733880981892677,
        "bleu": 57.60844,
        "bleurt": -0.0324,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.39232,
            "irrelevancy": 0.99354,
            "logical_agreement": 97.61415,
            "grammar_ref": 5.30755,
            "grammar_hyp": 5.79546,
            "nubia_score": 0.75076
        },
        "meteor": 0.45231505213245843,
        "bertscore": {
            "precision": 0.90565,
            "recall": 0.94307,
            "f1": 0.92398
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_888": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 61,
        "mean_pred_length": 15.25,
        "std_pred_length": 2.680951323690902,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 18,
        "distinct-1": 0.6557377049180327,
        "vocab_size-1": 40,
        "unique-1": 30,
        "entropy-1": 5.008365821063043,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 54,
        "unique-2": 51,
        "entropy-2": 5.7276268562700015,
        "cond_entropy-2": 0.6436379837332662,
        "distinct-3": 1.0,
        "vocab_size-3": 53,
        "unique-3": 53,
        "entropy-3": 5.727920454563195,
        "cond_entropy-3": 0.008237987568268861,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 2.48746859276655,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.6727272727272727,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.903820395224831,
        "distinct-2-nopunct": 0.9411764705882353,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.554778283147969,
        "cond_entropy-2-nopunct": 0.7001766579858639,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.55458885167764,
        "cond_entropy-3-nopunct": -0.011453511570453816,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66066,
            "recall": 0.58374,
            "fmeasure": 0.61536
        },
        "rouge2": {
            "precision": 0.42969,
            "recall": 0.40168,
            "fmeasure": 0.41394
        },
        "rougeL": {
            "precision": 0.57654,
            "recall": 0.51019,
            "fmeasure": 0.53738
        },
        "rougeLsum": {
            "precision": 0.57654,
            "recall": 0.51019,
            "fmeasure": 0.53738
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.5454545454545454,
            "3": 0.4864864864864865
        },
        "nist": 3.294427621867995,
        "bleu": 25.77042,
        "bleurt": 0.20196,
        "nubia": {
            "semantic_relation": 3.39341,
            "contradiction": 49.09992,
            "irrelevancy": 5.16297,
            "logical_agreement": 45.7371,
            "grammar_ref": 4.12218,
            "grammar_hyp": 3.91848,
            "nubia_score": 0.51738
        },
        "meteor": 0.2809956846687372,
        "bertscore": {
            "precision": 0.88863,
            "recall": 0.87273,
            "f1": 0.88036
        }
    },
    "web_nlg_en_test": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 1779,
        "msttr-100": 0.63975,
        "msttr-100_nopunct": 0.68433,
        "total_length": 43879,
        "mean_pred_length": 24.66498032602586,
        "std_pred_length": 12.430228623322094,
        "median_pred_length": 23.0,
        "min_pred_length": 5,
        "max_pred_length": 80,
        "distinct-1": 0.05232571389502951,
        "vocab_size-1": 2296,
        "unique-1": 701,
        "entropy-1": 8.088019127315306,
        "distinct-2": 0.20232779097387174,
        "vocab_size-2": 8518,
        "unique-2": 4162,
        "entropy-2": 11.566757042590318,
        "cond_entropy-2": 3.3052508514080143,
        "distinct-3": 0.3744946801914635,
        "vocab_size-3": 15100,
        "unique-3": 9344,
        "entropy-3": 12.916885370258726,
        "cond_entropy-3": 1.4075843304500504,
        "total_length-nopunct": 38679,
        "mean_pred_length-nopunct": 21.741989881956155,
        "std_pred_length-nopunct": 11.161962967518834,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 71,
        "distinct-1-nopunct": 0.059075984384291215,
        "vocab_size-1-nopunct": 2285,
        "unique-1-nopunct": 700,
        "entropy-1-nopunct": 8.39320556265177,
        "distinct-2-nopunct": 0.21878048780487805,
        "vocab_size-2-nopunct": 8073,
        "unique-2-nopunct": 4176,
        "entropy-2-nopunct": 11.503779643223481,
        "cond_entropy-2-nopunct": 3.257369034507904,
        "distinct-3-nopunct": 0.39517667492383474,
        "vocab_size-3-nopunct": 13879,
        "unique-3-nopunct": 8967,
        "entropy-3-nopunct": 12.793969867845766,
        "cond_entropy-3-nopunct": 1.3446331406319867,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.67979,
            "recall": 0.67707,
            "fmeasure": 0.67136
        },
        "rouge2": {
            "precision": 0.40101,
            "recall": 0.39957,
            "fmeasure": 0.39578
        },
        "rougeL": {
            "precision": 0.52451,
            "recall": 0.5243,
            "fmeasure": 0.51845
        },
        "rougeLsum": {
            "precision": 0.52451,
            "recall": 0.5243,
            "fmeasure": 0.51845
        },
        "local_recall": {
            "1": 0.22198634459808364,
            "2": 0.5262697873166942,
            "3": 0.7737435897435897,
            "4": 0.9090909090909091,
            "5": 0.6896551724137931
        },
        "nist": 7.852147119410051,
        "bleu": 38.44314,
        "bleurt": -0.02269,
        "nubia": {
            "semantic_relation": 3.99336,
            "contradiction": 22.31133,
            "irrelevancy": 10.87452,
            "logical_agreement": 66.81416,
            "grammar_ref": 4.5596,
            "grammar_hyp": 4.63039,
            "nubia_score": 0.6559
        },
        "meteor": 0.3369220590826048,
        "bertscore": {
            "precision": 0.89457,
            "recall": 0.89559,
            "f1": 0.89375
        }
    },
    "web_nlg_en_challenge_train_sample": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_challenge_train_sample",
        "N": 502
    },
    "web_nlg_en_challenge_validation_sample": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_challenge_validation_sample",
        "N": 499
    },
    "totto_test_contrast_challenge_table_size-table_size_822": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.04089198233393865,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.16992500144231232,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.04723891230848748,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.2064508774674265,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75694,
            "recall": 0.51891,
            "fmeasure": 0.61223
        },
        "rouge2": {
            "precision": 0.4256,
            "recall": 0.24466,
            "fmeasure": 0.30853
        },
        "rougeL": {
            "precision": 0.67593,
            "recall": 0.4402,
            "fmeasure": 0.5288
        },
        "rougeLsum": {
            "precision": 0.67593,
            "recall": 0.4402,
            "fmeasure": 0.5288
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.3333333333333333,
            "3": 0.5882352941176471
        },
        "nist": 2.877268190691991,
        "bleu": 37.25177,
        "bleurt": 0.36431,
        "nubia": {
            "semantic_relation": 4.39832,
            "contradiction": 0.43277,
            "irrelevancy": 1.02096,
            "logical_agreement": 98.54628,
            "grammar_ref": 4.56502,
            "grammar_hyp": 5.4012,
            "nubia_score": 0.73723
        },
        "meteor": 0.3347602959254823,
        "bertscore": {
            "precision": 0.94108,
            "recall": 0.87275,
            "f1": 0.90363
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_648": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.5898980954642865,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.24009914803219057,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.4677201004745006,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2588453731729854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5,
            "recall": 0.41176,
            "fmeasure": 0.45161
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.25,
            "fmeasure": 0.27586
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.35294,
            "fmeasure": 0.3871
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.35294,
            "fmeasure": 0.3871
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.4
        },
        "nist": 1.794479582553992,
        "bleu": 17.79529,
        "bleurt": -0.09914,
        "nubia": {
            "semantic_relation": 3.25178,
            "contradiction": 84.27364,
            "irrelevancy": 14.0497,
            "logical_agreement": 1.67666,
            "grammar_ref": 3.58521,
            "grammar_hyp": 3.64677,
            "nubia_score": 0.45574
        },
        "meteor": 0.2145137910036873,
        "bertscore": {
            "precision": 0.90417,
            "recall": 0.8498,
            "f1": 0.87614
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_756": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.61905,
            "recall": 0.68116,
            "fmeasure": 0.64141
        },
        "rouge2": {
            "precision": 0.475,
            "recall": 0.50974,
            "fmeasure": 0.48599
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.61449,
            "fmeasure": 0.58586
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.61449,
            "fmeasure": 0.58586
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.6666666666666666
        },
        "nist": 4.24061153009675,
        "bleu": 55.59164,
        "bleurt": -0.19668,
        "nubia": {
            "semantic_relation": 3.62541,
            "contradiction": 4.5466,
            "irrelevancy": 89.20096,
            "logical_agreement": 6.25244,
            "grammar_ref": 5.51157,
            "grammar_hyp": 5.53765,
            "nubia_score": 0.50659
        },
        "meteor": 0.41166546244615554,
        "bertscore": {
            "precision": 0.93821,
            "recall": 0.9392,
            "f1": 0.9387
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_889": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 11,
        "unique-1": 9,
        "entropy-1": 3.3927474104487847,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.21785611591339743,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.2516291673878226,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.23810548155250458,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.53846,
            "recall": 0.57143,
            "fmeasure": 0.53448
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.16667,
            "fmeasure": 0.11111
        },
        "rougeL": {
            "precision": 0.23077,
            "recall": 0.42857,
            "fmeasure": 0.3
        },
        "rougeLsum": {
            "precision": 0.23077,
            "recall": 0.42857,
            "fmeasure": 0.3
        },
        "local_recall": {
            "1": 0.375,
            "2": 0,
            "3": 0.6666666666666666
        },
        "nist": 1.900669663990067,
        "bleu": 4.12777,
        "bleurt": 0.04181,
        "nubia": {
            "semantic_relation": 3.77465,
            "contradiction": 0.09813,
            "irrelevancy": 95.61225,
            "logical_agreement": 4.28961,
            "grammar_ref": 4.92688,
            "grammar_hyp": 3.5121,
            "nubia_score": 0.78687
        },
        "meteor": 0.31662120743575817,
        "bertscore": {
            "precision": 0.77391,
            "recall": 0.80369,
            "f1": 0.75685
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_680": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 3.5,
        "median_pred_length": 13.5,
        "min_pred_length": 10,
        "max_pred_length": 17,
        "distinct-1": 0.8518518518518519,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.43063240949075,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.1591641876977948,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.88,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.373660689688184,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.17339652724591728,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80208,
            "recall": 0.68978,
            "fmeasure": 0.70813
        },
        "rouge2": {
            "precision": 0.63889,
            "recall": 0.53219,
            "fmeasure": 0.55113
        },
        "rougeL": {
            "precision": 0.77083,
            "recall": 0.67213,
            "fmeasure": 0.68557
        },
        "rougeLsum": {
            "precision": 0.77083,
            "recall": 0.67213,
            "fmeasure": 0.68557
        },
        "local_recall": {
            "1": 0.375,
            "2": 0.5,
            "3": 0.68
        },
        "nist": 3.012402709899105,
        "bleu": 38.15769,
        "bleurt": 0.17815,
        "nubia": {
            "semantic_relation": 4.25376,
            "contradiction": 0.51588,
            "irrelevancy": 39.99765,
            "logical_agreement": 59.48646,
            "grammar_ref": 5.14413,
            "grammar_hyp": 4.77449,
            "nubia_score": 0.75784
        },
        "meteor": 0.3651199551214698,
        "bertscore": {
            "precision": 0.95616,
            "recall": 0.91871,
            "f1": 0.93646
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_890": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.47222,
            "fmeasure": 0.55238
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.26786,
            "fmeasure": 0.32051
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.23611,
            "fmeasure": 0.27619
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.23611,
            "fmeasure": 0.27619
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.2857142857142857
        },
        "nist": 0.9256182547129214,
        "bleu": 12.87263,
        "bleurt": 0.00375,
        "nubia": {
            "semantic_relation": 3.60008,
            "contradiction": 15.21661,
            "irrelevancy": 10.65032,
            "logical_agreement": 74.13307,
            "grammar_ref": 4.73918,
            "grammar_hyp": 5.76757,
            "nubia_score": 0.44048
        },
        "meteor": 0.2570974710736757,
        "bertscore": {
            "precision": 0.86524,
            "recall": 0.84242,
            "f1": 0.85367
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_895": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 0.5,
        "median_pred_length": 11.5,
        "min_pred_length": 11,
        "max_pred_length": 12,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": -0.036006438040157185,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.14438990933517493,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.09175833038780652,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70833,
            "recall": 0.62963,
            "fmeasure": 0.64551
        },
        "rouge2": {
            "precision": 0.48333,
            "recall": 0.43382,
            "fmeasure": 0.44035
        },
        "rougeL": {
            "precision": 0.70833,
            "recall": 0.62963,
            "fmeasure": 0.64551
        },
        "rougeLsum": {
            "precision": 0.70833,
            "recall": 0.62963,
            "fmeasure": 0.64551
        },
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.5333333333333333,
            "3": 1.0
        },
        "nist": 3.5897416827230053,
        "bleu": 39.33458,
        "bleurt": 0.16933,
        "nubia": {
            "semantic_relation": 3.42125,
            "contradiction": 19.18354,
            "irrelevancy": 34.4145,
            "logical_agreement": 46.40196,
            "grammar_ref": 4.46901,
            "grammar_hyp": 3.99827,
            "nubia_score": 0.52268
        },
        "meteor": 0.37117659698027455,
        "bertscore": {
            "precision": 0.93349,
            "recall": 0.91372,
            "f1": 0.92259
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_760": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 58,
        "mean_pred_length": 14.5,
        "std_pred_length": 5.852349955359813,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.7068965517241379,
        "vocab_size-1": 41,
        "unique-1": 35,
        "entropy-1": 5.017379486469581,
        "distinct-2": 0.9814814814814815,
        "vocab_size-2": 53,
        "unique-2": 52,
        "entropy-2": 5.717850465126429,
        "cond_entropy-2": 0.6145896089278124,
        "distinct-3": 1.0,
        "vocab_size-3": 50,
        "unique-3": 50,
        "entropy-3": 5.643856189774728,
        "cond_entropy-3": -0.07103131238874397,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 2.8722813232690143,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8478260869565217,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.15932527122737,
        "distinct-2-nopunct": 0.9761904761904762,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.344698375159715,
        "cond_entropy-2-nopunct": 0.22006231201135398,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.09175833038780648,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70113,
            "recall": 0.67491,
            "fmeasure": 0.66999
        },
        "rouge2": {
            "precision": 0.29022,
            "recall": 0.31121,
            "fmeasure": 0.29436
        },
        "rougeL": {
            "precision": 0.5918,
            "recall": 0.58407,
            "fmeasure": 0.57183
        },
        "rougeLsum": {
            "precision": 0.5918,
            "recall": 0.58407,
            "fmeasure": 0.57183
        },
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.6111111111111112,
            "3": 0.782608695652174
        },
        "nist": 4.501375195384811,
        "bleu": 31.1748,
        "bleurt": 0.21352,
        "nubia": {
            "semantic_relation": 3.72858,
            "contradiction": 17.65828,
            "irrelevancy": 31.0332,
            "logical_agreement": 51.30852,
            "grammar_ref": 4.9362,
            "grammar_hyp": 4.10825,
            "nubia_score": 0.6375
        },
        "meteor": 0.36563812109587623,
        "bertscore": {
            "precision": 0.91875,
            "recall": 0.93496,
            "f1": 0.92205
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_682": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.75556,
            "fmeasure": 0.75569
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.56614,
            "fmeasure": 0.56899
        },
        "rougeL": {
            "precision": 0.76923,
            "recall": 0.75556,
            "fmeasure": 0.75569
        },
        "rougeLsum": {
            "precision": 0.76923,
            "recall": 0.75556,
            "fmeasure": 0.75569
        },
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "nist": 4.474416099899872,
        "bleu": 51.47302,
        "bleurt": 0.33863,
        "nubia": {
            "semantic_relation": 4.58246,
            "contradiction": 0.86231,
            "irrelevancy": 56.25508,
            "logical_agreement": 42.88262,
            "grammar_ref": 4.75278,
            "grammar_hyp": 5.26027,
            "nubia_score": 0.74168
        },
        "meteor": 0.4748101853768951,
        "bertscore": {
            "precision": 0.96933,
            "recall": 0.95282,
            "f1": 0.95899
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_828": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 55,
        "mean_pred_length": 27.5,
        "std_pred_length": 3.5,
        "median_pred_length": 27.5,
        "min_pred_length": 24,
        "max_pred_length": 31,
        "distinct-1": 0.7818181818181819,
        "vocab_size-1": 43,
        "unique-1": 38,
        "entropy-1": 5.179188523001679,
        "distinct-2": 1.0,
        "vocab_size-2": 53,
        "unique-2": 53,
        "entropy-2": 5.727920454563195,
        "cond_entropy-2": 0.5337195236567233,
        "distinct-3": 1.0,
        "vocab_size-3": 51,
        "unique-3": 51,
        "entropy-3": 5.6724253419715005,
        "cond_entropy-3": -0.055495112591703706,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.8541666666666666,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.178508854797682,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.5235619560570095,
        "cond_entropy-2-nopunct": 0.3627249989081813,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.4594316186372955,
        "cond_entropy-3-nopunct": -0.06413033741971554,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72619,
            "recall": 0.6743,
            "fmeasure": 0.69072
        },
        "rouge2": {
            "precision": 0.49058,
            "recall": 0.45274,
            "fmeasure": 0.46456
        },
        "rougeL": {
            "precision": 0.54881,
            "recall": 0.52525,
            "fmeasure": 0.52354
        },
        "rougeLsum": {
            "precision": 0.54881,
            "recall": 0.52525,
            "fmeasure": 0.52354
        },
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0,
            "3": 0.717948717948718
        },
        "nist": 4.674221923738289,
        "bleu": 44.45993,
        "bleurt": 0.22754,
        "nubia": {
            "semantic_relation": 3.36783,
            "contradiction": 50.26287,
            "irrelevancy": 3.53185,
            "logical_agreement": 46.20528,
            "grammar_ref": 3.79147,
            "grammar_hyp": 3.67705,
            "nubia_score": 0.54293
        },
        "meteor": 0.3624309753520029,
        "bertscore": {
            "precision": 0.91494,
            "recall": 0.89052,
            "f1": 0.89893
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_684": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 86,
        "mean_pred_length": 14.333333333333334,
        "std_pred_length": 4.14996653266291,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.7325581395348837,
        "vocab_size-1": 63,
        "unique-1": 48,
        "entropy-1": 5.786502545299147,
        "distinct-2": 0.95,
        "vocab_size-2": 76,
        "unique-2": 72,
        "entropy-2": 6.221928094887357,
        "cond_entropy-2": 0.28953552773935076,
        "distinct-3": 0.972972972972973,
        "vocab_size-3": 72,
        "unique-3": 70,
        "entropy-3": 6.155399311574901,
        "cond_entropy-3": -0.05842067520435862,
        "total_length-nopunct": 72,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.8284271247461903,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8194444444444444,
        "vocab_size-1-nopunct": 59,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.787844793048887,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 63,
        "unique-2-nopunct": 60,
        "entropy-2-nopunct": 5.9534850284493706,
        "cond_entropy-2-nopunct": 0.18522328464836688,
        "distinct-3-nopunct": 0.9666666666666667,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 56,
        "entropy-3-nopunct": 5.84022392894185,
        "cond_entropy-3-nopunct": -0.10417019041660147,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8185,
            "recall": 0.72928,
            "fmeasure": 0.75671
        },
        "rouge2": {
            "precision": 0.60699,
            "recall": 0.53747,
            "fmeasure": 0.5605
        },
        "rougeL": {
            "precision": 0.71625,
            "recall": 0.64283,
            "fmeasure": 0.66634
        },
        "rougeLsum": {
            "precision": 0.71625,
            "recall": 0.64283,
            "fmeasure": 0.66634
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.45,
            "3": 0.7096774193548387
        },
        "nist": 4.584543160349586,
        "bleu": 47.69014,
        "bleurt": 0.27739,
        "nubia": {
            "semantic_relation": 4.43946,
            "contradiction": 4.07347,
            "irrelevancy": 12.54676,
            "logical_agreement": 83.37977,
            "grammar_ref": 4.51194,
            "grammar_hyp": 4.64569,
            "nubia_score": 0.77543
        },
        "meteor": 0.42190359190645665,
        "bertscore": {
            "precision": 0.93066,
            "recall": 0.91846,
            "f1": 0.92346
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_764": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.78947,
            "fmeasure": 0.81081
        },
        "rouge2": {
            "precision": 0.70588,
            "recall": 0.66667,
            "fmeasure": 0.68571
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.78947,
            "fmeasure": 0.81081
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.78947,
            "fmeasure": 0.81081
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8125
        },
        "nist": 3.5143401442053412,
        "bleu": 63.20957,
        "bleurt": 0.48678,
        "nubia": {
            "semantic_relation": 4.76268,
            "contradiction": 0.56011,
            "irrelevancy": 3.14231,
            "logical_agreement": 96.29758,
            "grammar_ref": 4.21408,
            "grammar_hyp": 4.82375,
            "nubia_score": 0.81281
        },
        "meteor": 0.4193552855930098,
        "bertscore": {
            "precision": 0.94967,
            "recall": 0.93712,
            "f1": 0.94335
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_650": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": 0.0930692077718899,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.5216406363433186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": 0.11094091199688534,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 3.50789957099271,
        "bleu": 100.0,
        "bleurt": 0.89367,
        "nubia": {
            "semantic_relation": 4.97499,
            "contradiction": 0.89945,
            "irrelevancy": 0.58957,
            "logical_agreement": 98.51098,
            "grammar_ref": 4.12966,
            "grammar_hyp": 4.39551,
            "nubia_score": 0.98513
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "schema_guided_dialog_challenge_test_scramble_parent": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.70746,
        "total_length": 6710,
        "mean_pred_length": 13.42,
        "std_pred_length": 7.650594748122527,
        "median_pred_length": 12.0,
        "min_pred_length": 2,
        "max_pred_length": 46,
        "distinct-1": 0.15081967213114755,
        "vocab_size-1": 1012,
        "unique-1": 566,
        "entropy-1": 7.785244122236181,
        "distinct-2": 0.46602254428341383,
        "vocab_size-2": 2894,
        "unique-2": 2000,
        "entropy-2": 10.66123488379287,
        "cond_entropy-2": 2.644753705016189,
        "distinct-3": 0.6807355516637478,
        "vocab_size-3": 3887,
        "unique-3": 3152,
        "entropy-3": 11.510423433150391,
        "cond_entropy-3": 0.8875042066244381,
        "total_length-nopunct": 5902,
        "mean_pred_length-nopunct": 11.804,
        "std_pred_length-nopunct": 6.982376672738302,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.1696035242290749,
        "vocab_size-1-nopunct": 1001,
        "unique-1-nopunct": 564,
        "entropy-1-nopunct": 7.96490950874351,
        "distinct-2-nopunct": 0.48185857089966677,
        "vocab_size-2-nopunct": 2603,
        "unique-2-nopunct": 1854,
        "entropy-2-nopunct": 10.4910777051817,
        "cond_entropy-2-nopunct": 2.666031382382303,
        "distinct-3-nopunct": 0.6944727717723842,
        "vocab_size-3-nopunct": 3405,
        "unique-3-nopunct": 2814,
        "entropy-3-nopunct": 11.31513638199856,
        "cond_entropy-3-nopunct": 0.8725722829341401,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.56387,
            "recall": 0.54271,
            "fmeasure": 0.54163
        },
        "rouge2": {
            "precision": 0.34039,
            "recall": 0.32671,
            "fmeasure": 0.32594
        },
        "rougeL": {
            "precision": 0.50651,
            "recall": 0.48724,
            "fmeasure": 0.48653
        },
        "rougeLsum": {
            "precision": 0.50651,
            "recall": 0.48724,
            "fmeasure": 0.48653
        },
        "local_recall": {
            "1": 0.5594562037515057
        },
        "nist": 5.964422565571172,
        "bleu": 30.89829,
        "bleurt": -0.10916,
        "nubia": {
            "semantic_relation": 3.5368,
            "contradiction": 8.56502,
            "irrelevancy": 24.76269,
            "logical_agreement": 66.67229,
            "grammar_ref": 4.7801,
            "grammar_hyp": 4.59909,
            "nubia_score": 0.62148
        },
        "meteor": 0.3080324956431604,
        "bertscore": {
            "precision": 0.86927,
            "recall": 0.86211,
            "f1": 0.86523
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_686": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.92593,
            "recall": 0.7641,
            "fmeasure": 0.83413
        },
        "rouge2": {
            "precision": 0.79167,
            "recall": 0.57407,
            "fmeasure": 0.66275
        },
        "rougeL": {
            "precision": 0.92593,
            "recall": 0.7641,
            "fmeasure": 0.83413
        },
        "rougeLsum": {
            "precision": 0.92593,
            "recall": 0.7641,
            "fmeasure": 0.83413
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 0.875
        },
        "nist": 1.9701201394757433,
        "bleu": 71.89393,
        "bleurt": 0.43409,
        "nubia": {
            "semantic_relation": 4.36339,
            "contradiction": 0.32693,
            "irrelevancy": 0.51164,
            "logical_agreement": 99.16143,
            "grammar_ref": 4.05789,
            "grammar_hyp": 4.04889,
            "nubia_score": 0.86891
        },
        "meteor": 0.48117686361121714,
        "bertscore": {
            "precision": 0.97666,
            "recall": 0.96558,
            "f1": 0.97109
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_896": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.63,
        "msttr-100_nopunct": 0.65,
        "total_length": 143,
        "mean_pred_length": 17.875,
        "std_pred_length": 6.450532923720334,
        "median_pred_length": 16.5,
        "min_pred_length": 9,
        "max_pred_length": 32,
        "distinct-1": 0.5734265734265734,
        "vocab_size-1": 82,
        "unique-1": 59,
        "entropy-1": 5.811821820579793,
        "distinct-2": 0.9111111111111111,
        "vocab_size-2": 123,
        "unique-2": 113,
        "entropy-2": 6.887854300722507,
        "cond_entropy-2": 0.9781391181396483,
        "distinct-3": 0.9763779527559056,
        "vocab_size-3": 124,
        "unique-3": 121,
        "entropy-3": 6.941440592283959,
        "cond_entropy-3": 0.06548936534595659,
        "total_length-nopunct": 127,
        "mean_pred_length-nopunct": 15.875,
        "std_pred_length-nopunct": 5.967359131140006,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6141732283464567,
        "vocab_size-1-nopunct": 78,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.78190275124402,
        "distinct-2-nopunct": 0.8991596638655462,
        "vocab_size-2-nopunct": 107,
        "unique-2-nopunct": 97,
        "entropy-2-nopunct": 6.680449906128724,
        "cond_entropy-2-nopunct": 0.9495496169309469,
        "distinct-3-nopunct": 0.972972972972973,
        "vocab_size-3-nopunct": 108,
        "unique-3-nopunct": 105,
        "entropy-3-nopunct": 6.740361812296067,
        "cond_entropy-3-nopunct": 0.0520738913629353,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.675,
            "recall": 0.63659,
            "fmeasure": 0.63829
        },
        "rouge2": {
            "precision": 0.48016,
            "recall": 0.45084,
            "fmeasure": 0.45462
        },
        "rougeL": {
            "precision": 0.59856,
            "recall": 0.56753,
            "fmeasure": 0.56851
        },
        "rougeLsum": {
            "precision": 0.59856,
            "recall": 0.56753,
            "fmeasure": 0.56851
        },
        "local_recall": {
            "1": 0.3076923076923077,
            "2": 0.6216216216216216,
            "3": 0.6301369863013698
        },
        "nist": 4.441952814081906,
        "bleu": 40.3411,
        "bleurt": -0.04831,
        "nubia": {
            "semantic_relation": 3.3071,
            "contradiction": 19.90502,
            "irrelevancy": 47.90227,
            "logical_agreement": 32.19271,
            "grammar_ref": 4.28101,
            "grammar_hyp": 4.01042,
            "nubia_score": 0.53294
        },
        "meteor": 0.32478181193226907,
        "bertscore": {
            "precision": 0.87427,
            "recall": 0.87234,
            "f1": 0.87166
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_900": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 2.5,
        "median_pred_length": 12.5,
        "min_pred_length": 10,
        "max_pred_length": 15,
        "distinct-1": 0.84,
        "vocab_size-1": 21,
        "unique-1": 17,
        "entropy-1": 4.323856189774723,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.14057533149967955,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8695652173913043,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.262692390839622,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.15446975243603323,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.14438990933517493,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.89762,
            "recall": 1.0,
            "fmeasure": 0.94542
        },
        "rouge2": {
            "precision": 0.75499,
            "recall": 0.85119,
            "fmeasure": 0.79951
        },
        "rougeL": {
            "precision": 0.82619,
            "recall": 0.92308,
            "fmeasure": 0.87135
        },
        "rougeLsum": {
            "precision": 0.82619,
            "recall": 0.92308,
            "fmeasure": 0.87135
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0,
            "3": 0.9473684210526315
        },
        "nist": 4.622576582020486,
        "bleu": 67.78543,
        "bleurt": 0.59063,
        "nubia": {
            "semantic_relation": 4.61445,
            "contradiction": 0.36347,
            "irrelevancy": 33.62997,
            "logical_agreement": 66.00656,
            "grammar_ref": 5.10267,
            "grammar_hyp": 5.2336,
            "nubia_score": 0.8531
        },
        "meteor": 0.5328811160404424,
        "bertscore": {
            "precision": 0.96656,
            "recall": 0.97202,
            "f1": 0.96923
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_903": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.6402239289418516,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.11475004073479991,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.423065265165703,
        "bleu": 100.0,
        "bleurt": 0.94038,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.31517,
            "irrelevancy": 0.55477,
            "logical_agreement": 99.13006,
            "grammar_ref": 5.42428,
            "grammar_hyp": 5.51742,
            "nubia_score": 0.98965
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_765": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.768492245572466,
        "bleu": 100.0,
        "bleurt": 0.97268,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.373,
            "irrelevancy": 0.51156,
            "logical_agreement": 99.11544,
            "grammar_ref": 5.07856,
            "grammar_hyp": 5.22425,
            "nubia_score": 0.9763
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_830": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.6416041678685933,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.4769363694743175,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.4677201004745006,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2588453731729854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.9375,
            "recall": 1.0,
            "fmeasure": 0.96774
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.71429,
            "fmeasure": 0.68966
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.6,
            "fmeasure": 0.58065
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.6,
            "fmeasure": 0.58065
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.89145926838456,
        "bleu": 56.49269,
        "bleurt": 0.65892,
        "nubia": {
            "semantic_relation": 4.92199,
            "contradiction": 0.648,
            "irrelevancy": 14.49103,
            "logical_agreement": 84.86097,
            "grammar_ref": 4.08392,
            "grammar_hyp": 3.84603,
            "nubia_score": 0.96737
        },
        "meteor": 0.5178515092602387,
        "bertscore": {
            "precision": 0.96781,
            "recall": 0.97397,
            "f1": 0.97088
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_770": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.12336199461765371,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.129610672108602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.7,
            "fmeasure": 0.68293
        },
        "rouge2": {
            "precision": 0.28333,
            "recall": 0.29825,
            "fmeasure": 0.2906
        },
        "rougeL": {
            "precision": 0.52381,
            "recall": 0.5693,
            "fmeasure": 0.54553
        },
        "rougeLsum": {
            "precision": 0.52381,
            "recall": 0.5693,
            "fmeasure": 0.54553
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.75,
            "3": 0.8333333333333334
        },
        "nist": 3.5065810251442824,
        "bleu": 20.91599,
        "bleurt": -0.03696,
        "nubia": {
            "semantic_relation": 4.03904,
            "contradiction": 0.34785,
            "irrelevancy": 58.18105,
            "logical_agreement": 41.47109,
            "grammar_ref": 5.26752,
            "grammar_hyp": 4.81354,
            "nubia_score": 0.67824
        },
        "meteor": 0.35757585731433006,
        "bertscore": {
            "precision": 0.88293,
            "recall": 0.89402,
            "f1": 0.88844
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_833": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185189,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.96078,
            "recall": 0.75591,
            "fmeasure": 0.84444
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.67677,
            "fmeasure": 0.76161
        },
        "rougeL": {
            "precision": 0.96078,
            "recall": 0.75591,
            "fmeasure": 0.84444
        },
        "rougeLsum": {
            "precision": 0.96078,
            "recall": 0.75591,
            "fmeasure": 0.84444
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 1.0,
            "3": 0.8571428571428571
        },
        "nist": 5.074202687561549,
        "bleu": 79.93249,
        "bleurt": 0.52498,
        "nubia": {
            "semantic_relation": 4.64656,
            "contradiction": 0.65741,
            "irrelevancy": 0.75432,
            "logical_agreement": 98.58827,
            "grammar_ref": 4.95426,
            "grammar_hyp": 5.01119,
            "nubia_score": 0.85081
        },
        "meteor": 0.5293855573293579,
        "bertscore": {
            "precision": 0.97669,
            "recall": 0.96698,
            "f1": 0.97081
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_909": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.816496580927726,
        "median_pred_length": 15.0,
        "min_pred_length": 14,
        "max_pred_length": 16,
        "distinct-1": 0.7111111111111111,
        "vocab_size-1": 32,
        "unique-1": 23,
        "entropy-1": 4.836080318455743,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 36,
        "unique-2": 30,
        "entropy-2": 5.106603137064475,
        "cond_entropy-2": 0.2041521241196444,
        "distinct-3": 0.9230769230769231,
        "vocab_size-3": 36,
        "unique-3": 33,
        "entropy-3": 5.131556065016094,
        "cond_entropy-3": -0.004351101352409298,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 1.247219128924647,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7567567567567568,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.648510460165075,
        "distinct-2-nopunct": 0.9117647058823529,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.910992253015045,
        "cond_entropy-2-nopunct": 0.19432969627325647,
        "distinct-3-nopunct": 0.967741935483871,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.889680181354619,
        "cond_entropy-3-nopunct": -0.06875040183120609,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77946,
            "recall": 0.8468,
            "fmeasure": 0.80824
        },
        "rouge2": {
            "precision": 0.53752,
            "recall": 0.58182,
            "fmeasure": 0.55614
        },
        "rougeL": {
            "precision": 0.75724,
            "recall": 0.81818,
            "fmeasure": 0.78323
        },
        "rougeLsum": {
            "precision": 0.75724,
            "recall": 0.81818,
            "fmeasure": 0.78323
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8387096774193549
        },
        "nist": 3.6443432588014653,
        "bleu": 39.70558,
        "bleurt": 0.50599,
        "nubia": {
            "semantic_relation": 4.80603,
            "contradiction": 0.99443,
            "irrelevancy": 11.94553,
            "logical_agreement": 87.06004,
            "grammar_ref": 3.77014,
            "grammar_hyp": 3.29009,
            "nubia_score": 0.9129
        },
        "meteor": 0.45400183213453393,
        "bertscore": {
            "precision": 0.92887,
            "recall": 0.9651,
            "f1": 0.94456
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_834": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.82353,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.66667,
            "fmeasure": 0.70238
        },
        "rougeL": {
            "precision": 0.65385,
            "recall": 0.58145,
            "fmeasure": 0.61282
        },
        "rougeLsum": {
            "precision": 0.65385,
            "recall": 0.58145,
            "fmeasure": 0.61282
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "nist": 4.306797170061882,
        "bleu": 69.04427,
        "bleurt": 0.47554,
        "nubia": {
            "semantic_relation": 4.27928,
            "contradiction": 0.25448,
            "irrelevancy": 0.49291,
            "logical_agreement": 99.25261,
            "grammar_ref": 4.29821,
            "grammar_hyp": 4.38971,
            "nubia_score": 0.78008
        },
        "meteor": 0.5500501807094148,
        "bertscore": {
            "precision": 0.97265,
            "recall": 0.97025,
            "f1": 0.97145
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_910": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 3.0,
        "median_pred_length": 17.0,
        "min_pred_length": 14,
        "max_pred_length": 20,
        "distinct-1": 0.7647058823529411,
        "vocab_size-1": 26,
        "unique-1": 18,
        "entropy-1": 4.616874605956221,
        "distinct-2": 0.9375,
        "vocab_size-2": 30,
        "unique-2": 28,
        "entropy-2": 4.875,
        "cond_entropy-2": 0.22503715874966068,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": 0.04022392894185191,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.506890595608518,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.664497779200462,
        "cond_entropy-2-nopunct": 0.18617861216337128,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": 0.04693094992964164,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.52976,
            "recall": 0.73843,
            "fmeasure": 0.61565
        },
        "rouge2": {
            "precision": 0.27727,
            "recall": 0.4212,
            "fmeasure": 0.33389
        },
        "rougeL": {
            "precision": 0.45833,
            "recall": 0.64815,
            "fmeasure": 0.53596
        },
        "rougeLsum": {
            "precision": 0.45833,
            "recall": 0.64815,
            "fmeasure": 0.53596
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.875,
            "3": 0.5
        },
        "nist": 2.255078159910192,
        "bleu": 13.52706,
        "bleurt": 0.15878,
        "nubia": {
            "semantic_relation": 4.12108,
            "contradiction": 6.07621,
            "irrelevancy": 65.90872,
            "logical_agreement": 28.01507,
            "grammar_ref": 4.27476,
            "grammar_hyp": 3.89865,
            "nubia_score": 0.69983
        },
        "meteor": 0.32528135497322036,
        "bertscore": {
            "precision": 0.88288,
            "recall": 0.90818,
            "f1": 0.89366
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_651": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.625,
            "recall": 0.9375,
            "fmeasure": 0.75
        },
        "rouge2": {
            "precision": 0.54545,
            "recall": 0.85714,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.9375,
            "fmeasure": 0.75
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.9375,
            "fmeasure": 0.75
        },
        "local_recall": {
            "1": 0.5,
            "2": 1.0
        },
        "nist": 2.4457289637024866,
        "bleu": 57.60844,
        "bleurt": -0.90817,
        "nubia": {
            "semantic_relation": 3.78386,
            "contradiction": 0.35437,
            "irrelevancy": 99.34266,
            "logical_agreement": 0.30297,
            "grammar_ref": 5.1072,
            "grammar_hyp": 5.23779,
            "nubia_score": 0.49785
        },
        "meteor": 0.5108007395276796,
        "bertscore": {
            "precision": 0.86546,
            "recall": 0.96651,
            "f1": 0.9132
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_840": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 77,
        "mean_pred_length": 15.4,
        "std_pred_length": 5.885575587824865,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.7012987012987013,
        "vocab_size-1": 54,
        "unique-1": 41,
        "entropy-1": 5.515172216267276,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 64,
        "unique-2": 57,
        "entropy-2": 5.937218230578931,
        "cond_entropy-2": 0.3129964469186186,
        "distinct-3": 0.9104477611940298,
        "vocab_size-3": 61,
        "unique-3": 55,
        "entropy-3": 5.886984712845829,
        "cond_entropy-3": -0.032867340802995644,
        "total_length-nopunct": 67,
        "mean_pred_length-nopunct": 13.4,
        "std_pred_length-nopunct": 5.351635264103861,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7611940298507462,
        "vocab_size-1-nopunct": 51,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.4949748246892565,
        "distinct-2-nopunct": 0.8870967741935484,
        "vocab_size-2-nopunct": 55,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.71621425390037,
        "cond_entropy-2-nopunct": 0.2672970393537309,
        "distinct-3-nopunct": 0.9122807017543859,
        "vocab_size-3-nopunct": 52,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.657451417673512,
        "cond_entropy-3-nopunct": -0.03788721723680953,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86275,
            "recall": 0.8663,
            "fmeasure": 0.86235
        },
        "rouge2": {
            "precision": 0.7921,
            "recall": 0.78431,
            "fmeasure": 0.78629
        },
        "rougeL": {
            "precision": 0.80784,
            "recall": 0.85678,
            "fmeasure": 0.81718
        },
        "rougeLsum": {
            "precision": 0.80784,
            "recall": 0.85678,
            "fmeasure": 0.81718
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714,
            "3": 0.9347826086956522
        },
        "nist": 5.374854920826042,
        "bleu": 73.37464,
        "bleurt": 0.41841,
        "nubia": {
            "semantic_relation": 3.96381,
            "contradiction": 20.09985,
            "irrelevancy": 6.5252,
            "logical_agreement": 73.37495,
            "grammar_ref": 5.02868,
            "grammar_hyp": 4.62902,
            "nubia_score": 0.75043
        },
        "meteor": 0.6082749339199544,
        "bertscore": {
            "precision": 0.93323,
            "recall": 0.95228,
            "f1": 0.94249
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_912": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 52,
        "mean_pred_length": 13.0,
        "std_pred_length": 4.847679857416329,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 18,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 40,
        "unique-1": 33,
        "entropy-1": 5.131023555171156,
        "distinct-2": 0.9791666666666666,
        "vocab_size-2": 47,
        "unique-2": 46,
        "entropy-2": 5.543295834054494,
        "cond_entropy-2": 0.2662296178902177,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": -0.08007633662931371,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 10.75,
        "std_pred_length-nopunct": 3.766629793329841,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8372093023255814,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.054171731446283,
        "distinct-2-nopunct": 0.9743589743589743,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.234120167580196,
        "cond_entropy-2-nopunct": 0.21811182313450905,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.09897634477442473,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.84479,
            "recall": 0.64796,
            "fmeasure": 0.71912
        },
        "rouge2": {
            "precision": 0.65556,
            "recall": 0.46835,
            "fmeasure": 0.52927
        },
        "rougeL": {
            "precision": 0.73368,
            "recall": 0.58129,
            "fmeasure": 0.63341
        },
        "rougeLsum": {
            "precision": 0.73368,
            "recall": 0.58129,
            "fmeasure": 0.63341
        },
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.55,
            "3": 0.6666666666666666
        },
        "nist": 4.073367023223617,
        "bleu": 49.69178,
        "bleurt": 0.10147,
        "nubia": {
            "semantic_relation": 3.54949,
            "contradiction": 25.41018,
            "irrelevancy": 46.2446,
            "logical_agreement": 28.34522,
            "grammar_ref": 4.43752,
            "grammar_hyp": 4.88385,
            "nubia_score": 0.53945
        },
        "meteor": 0.4103886127528086,
        "bertscore": {
            "precision": 0.9424,
            "recall": 0.92024,
            "f1": 0.93098
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_693": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673076,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.71429,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.56667,
            "recall": 0.4359,
            "fmeasure": 0.49275
        },
        "rougeL": {
            "precision": 0.84848,
            "recall": 0.66667,
            "fmeasure": 0.74667
        },
        "rougeLsum": {
            "precision": 0.84848,
            "recall": 0.66667,
            "fmeasure": 0.74667
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8
        },
        "nist": 3.4595216280661427,
        "bleu": 38.14156,
        "bleurt": 0.44858,
        "nubia": {
            "semantic_relation": 4.61109,
            "contradiction": 3.09482,
            "irrelevancy": 8.3594,
            "logical_agreement": 88.54578,
            "grammar_ref": 4.18993,
            "grammar_hyp": 4.96442,
            "nubia_score": 0.74324
        },
        "meteor": 0.3918734238227112,
        "bertscore": {
            "precision": 0.96123,
            "recall": 0.92567,
            "f1": 0.94312
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_845": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 10,
        "unique-1": 8,
        "entropy-1": 3.2516291673878226,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.23810548155250455,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.0957952550009344,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.262496476250065,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.60317,
            "fmeasure": 0.72115
        },
        "rouge2": {
            "precision": 0.9,
            "recall": 0.57857,
            "fmeasure": 0.7
        },
        "rougeL": {
            "precision": 0.90909,
            "recall": 0.60317,
            "fmeasure": 0.72115
        },
        "rougeLsum": {
            "precision": 0.90909,
            "recall": 0.60317,
            "fmeasure": 0.72115
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nist": 1.12356491777363,
        "bleu": 59.22252,
        "bleurt": 0.24584,
        "nubia": {
            "semantic_relation": 4.1524,
            "contradiction": 0.3849,
            "irrelevancy": 0.53944,
            "logical_agreement": 99.07566,
            "grammar_ref": 2.70093,
            "grammar_hyp": 2.95932,
            "nubia_score": 0.8747
        },
        "meteor": 0.4466946348571188,
        "bertscore": {
            "precision": 0.98789,
            "recall": 0.8933,
            "f1": 0.93822
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_774": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.0,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 15,
        "distinct-1": 0.8846153846153846,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.46967048737186,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.05118944924673078,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9130434782608695,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.349648912578752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.059231657197938034,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.14438990933517493,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79048,
            "recall": 0.67542,
            "fmeasure": 0.71813
        },
        "rouge2": {
            "precision": 0.39174,
            "recall": 0.37401,
            "fmeasure": 0.37908
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.53502,
            "fmeasure": 0.55673
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.53502,
            "fmeasure": 0.55673
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6,
            "3": 0.52
        },
        "nist": 2.620124822457884,
        "bleu": 27.92438,
        "bleurt": 0.06464,
        "nubia": {
            "semantic_relation": 3.95249,
            "contradiction": 0.29104,
            "irrelevancy": 49.92743,
            "logical_agreement": 49.78153,
            "grammar_ref": 4.18803,
            "grammar_hyp": 3.6861,
            "nubia_score": 0.68856
        },
        "meteor": 0.3009423222305082,
        "bertscore": {
            "precision": 0.88311,
            "recall": 0.89426,
            "f1": 0.8856
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_915": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 52,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 9.672412085697939,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.8076923076923077,
        "vocab_size-1": 42,
        "unique-1": 34,
        "entropy-1": 5.286790198827115,
        "distinct-2": 1.0,
        "vocab_size-2": 49,
        "unique-2": 49,
        "entropy-2": 5.614709844115208,
        "cond_entropy-2": 0.25620660561010555,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": -0.09114788805819536,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 7.788880963698615,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.2084111518371525,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.3923174227787625,
        "cond_entropy-2-nopunct": 0.18034260031012067,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": -0.10691520391651191,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70808,
            "recall": 0.86998,
            "fmeasure": 0.78016
        },
        "rouge2": {
            "precision": 0.3567,
            "recall": 0.45877,
            "fmeasure": 0.40116
        },
        "rougeL": {
            "precision": 0.58215,
            "recall": 0.71236,
            "fmeasure": 0.64026
        },
        "rougeLsum": {
            "precision": 0.58215,
            "recall": 0.71236,
            "fmeasure": 0.64026
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6,
            "3": 0.9354838709677419
        },
        "nist": 4.161825696736714,
        "bleu": 44.58671,
        "bleurt": 0.10632,
        "nubia": {
            "semantic_relation": 4.50454,
            "contradiction": 1.93069,
            "irrelevancy": 63.61337,
            "logical_agreement": 34.45594,
            "grammar_ref": 5.15251,
            "grammar_hyp": 4.86604,
            "nubia_score": 0.79641
        },
        "meteor": 0.47257922880697883,
        "bertscore": {
            "precision": 0.90867,
            "recall": 0.93224,
            "f1": 0.92025
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_695": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.0,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.75,
        "vocab_size-1": 18,
        "unique-1": 12,
        "entropy-1": 4.084962500721156,
        "distinct-2": 0.8181818181818182,
        "vocab_size-2": 18,
        "unique-2": 14,
        "entropy-2": 4.095795255000932,
        "cond_entropy-2": -0.034621791174768185,
        "distinct-3": 0.85,
        "vocab_size-3": 17,
        "unique-3": 14,
        "entropy-3": 4.021928094887363,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7727272727272727,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.004886164091841,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.9219280948873623,
        "cond_entropy-2-nopunct": -0.08750352374993502,
        "distinct-3-nopunct": 0.8333333333333334,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.8365916681089787,
        "cond_entropy-3-nopunct": -0.09644753788949419,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.6530437207411035,
        "bleu": 100.0,
        "bleurt": 0.9828,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.34259,
            "irrelevancy": 0.55688,
            "logical_agreement": 99.10053,
            "grammar_ref": 6.12532,
            "grammar_hyp": 6.14583,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_849": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.1523912776298655,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.25454711376829503,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.984183719779189,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.28151981340693205,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.57576,
            "recall": 0.52778,
            "fmeasure": 0.55072
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.31125,
            "fmeasure": 0.32179
        },
        "rougeL": {
            "precision": 0.51515,
            "recall": 0.48485,
            "fmeasure": 0.49934
        },
        "rougeLsum": {
            "precision": 0.51515,
            "recall": 0.48485,
            "fmeasure": 0.49934
        },
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 0.5294117647058824
        },
        "nist": 3.1748889009768035,
        "bleu": 25.85072,
        "bleurt": 0.08561,
        "nubia": {
            "semantic_relation": 3.81495,
            "contradiction": 0.07559,
            "irrelevancy": 98.01125,
            "logical_agreement": 1.91316,
            "grammar_ref": 3.8277,
            "grammar_hyp": 3.67353,
            "nubia_score": 0.70806
        },
        "meteor": 0.27754812291992803,
        "bertscore": {
            "precision": 0.85058,
            "recall": 0.83901,
            "f1": 0.84475
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_780": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.1699250014423126,
        "bleu": 100.0,
        "bleurt": 0.99428,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.22767,
            "irrelevancy": 0.5448,
            "logical_agreement": 99.22753,
            "grammar_ref": 5.18772,
            "grammar_hyp": 5.18772,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1015": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 1.5,
        "median_pred_length": 18.5,
        "min_pred_length": 17,
        "max_pred_length": 20,
        "distinct-1": 0.7837837837837838,
        "vocab_size-1": 29,
        "unique-1": 24,
        "entropy-1": 4.702564514219128,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.36511429419376407,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.08488889758651327,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.706890595608519,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.11475004073479983,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.60754,
            "recall": 0.51148,
            "fmeasure": 0.53826
        },
        "rouge2": {
            "precision": 0.26042,
            "recall": 0.20509,
            "fmeasure": 0.22164
        },
        "rougeL": {
            "precision": 0.40993,
            "recall": 0.34576,
            "fmeasure": 0.36276
        },
        "rougeLsum": {
            "precision": 0.40993,
            "recall": 0.34576,
            "fmeasure": 0.36276
        },
        "local_recall": {
            "1": 0.25925925925925924,
            "2": 0.5714285714285714
        },
        "nist": 3.0615298188454694,
        "bleu": 13.09335,
        "bleurt": -0.07703,
        "nubia": {
            "semantic_relation": 3.62497,
            "contradiction": 4.6843,
            "irrelevancy": 66.6803,
            "logical_agreement": 28.6354,
            "grammar_ref": 4.87596,
            "grammar_hyp": 4.1068,
            "nubia_score": 0.58695
        },
        "meteor": 0.21790399677777286,
        "bertscore": {
            "precision": 0.90081,
            "recall": 0.88954,
            "f1": 0.88358
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1164": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 1.0,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 15,
        "distinct-1": 0.7857142857142857,
        "vocab_size-1": 22,
        "unique-1": 18,
        "entropy-1": 4.307354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.3546232576219493,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8076923076923077,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.23890125660263,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.384522782580064,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.63553,
            "recall": 0.65101,
            "fmeasure": 0.62678
        },
        "rouge2": {
            "precision": 0.36859,
            "recall": 0.35664,
            "fmeasure": 0.35041
        },
        "rougeL": {
            "precision": 0.56319,
            "recall": 0.52117,
            "fmeasure": 0.53417
        },
        "rougeLsum": {
            "precision": 0.56319,
            "recall": 0.52117,
            "fmeasure": 0.53417
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.2222222222222222,
            "3": 0.6470588235294118
        },
        "nist": 3.141319604784403,
        "bleu": 28.77508,
        "bleurt": 0.13676,
        "nubia": {
            "semantic_relation": 3.66552,
            "contradiction": 48.7526,
            "irrelevancy": 50.38259,
            "logical_agreement": 0.86481,
            "grammar_ref": 4.30067,
            "grammar_hyp": 4.1858,
            "nubia_score": 0.57896
        },
        "meteor": 0.33125148541857224,
        "bertscore": {
            "precision": 0.89699,
            "recall": 0.92345,
            "f1": 0.90885
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1020": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 3.0,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 15,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 20,
        "unique-1": 16,
        "entropy-1": 4.251629167387823,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.14719639064341358,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.932138039759373,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.19247650427734211,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.18057224564182078,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80114,
            "recall": 0.567,
            "fmeasure": 0.64296
        },
        "rouge2": {
            "precision": 0.50714,
            "recall": 0.3881,
            "fmeasure": 0.42407
        },
        "rougeL": {
            "precision": 0.61932,
            "recall": 0.49741,
            "fmeasure": 0.53657
        },
        "rougeLsum": {
            "precision": 0.61932,
            "recall": 0.49741,
            "fmeasure": 0.53657
        },
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.5454545454545454,
            "3": 0.7272727272727273
        },
        "nist": 3.192901772844706,
        "bleu": 42.38185,
        "bleurt": -0.09843,
        "nubia": {
            "semantic_relation": 4.0125,
            "contradiction": 4.65067,
            "irrelevancy": 31.83452,
            "logical_agreement": 63.51482,
            "grammar_ref": 4.3679,
            "grammar_hyp": 5.56157,
            "nubia_score": 0.52718
        },
        "meteor": 0.3506355805484461,
        "bertscore": {
            "precision": 0.93613,
            "recall": 0.90568,
            "f1": 0.91638
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_696": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 59,
        "mean_pred_length": 19.666666666666668,
        "std_pred_length": 8.73053390247253,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 32,
        "distinct-1": 0.8305084745762712,
        "vocab_size-1": 49,
        "unique-1": 43,
        "entropy-1": 5.4841722865766345,
        "distinct-2": 1.0,
        "vocab_size-2": 56,
        "unique-2": 56,
        "entropy-2": 5.807354922057609,
        "cond_entropy-2": 0.2596205780915389,
        "distinct-3": 1.0,
        "vocab_size-3": 53,
        "unique-3": 53,
        "entropy-3": 5.727920454563195,
        "cond_entropy-3": -0.07943446749440497,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 7.788880963698615,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.8703703703703703,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.444611807678959,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 5.6724253419715005,
        "cond_entropy-2-nopunct": 0.2460650457328007,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.5849625007211605,
        "cond_entropy-3-nopunct": -0.08746284125033933,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7277,
            "recall": 0.68995,
            "fmeasure": 0.69917
        },
        "rouge2": {
            "precision": 0.54554,
            "recall": 0.51768,
            "fmeasure": 0.52419
        },
        "rougeL": {
            "precision": 0.5977,
            "recall": 0.58736,
            "fmeasure": 0.58638
        },
        "rougeLsum": {
            "precision": 0.5977,
            "recall": 0.58736,
            "fmeasure": 0.58638
        },
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.07692307692307693,
            "3": 0.8536585365853658
        },
        "nist": 4.078114591372769,
        "bleu": 42.6975,
        "bleurt": 0.08151,
        "nubia": {
            "semantic_relation": 4.04337,
            "contradiction": 3.26843,
            "irrelevancy": 25.70769,
            "logical_agreement": 71.02388,
            "grammar_ref": 4.54005,
            "grammar_hyp": 4.27314,
            "nubia_score": 0.70291
        },
        "meteor": 0.4004400408792208,
        "bertscore": {
            "precision": 0.92465,
            "recall": 0.92027,
            "f1": 0.92153
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_852": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.65278,
            "fmeasure": 0.5381
        },
        "rougeL": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rougeLsum": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "nist": 2.7109047337507373,
        "bleu": 53.10725,
        "bleurt": 0.22576,
        "nubia": {
            "semantic_relation": 4.03158,
            "contradiction": 0.1933,
            "irrelevancy": 99.65987,
            "logical_agreement": 0.14683,
            "grammar_ref": 5.68221,
            "grammar_hyp": 4.97464,
            "nubia_score": 0.75981
        },
        "meteor": 0.5033950705050299,
        "bertscore": {
            "precision": 0.91794,
            "recall": 0.99099,
            "f1": 0.95307
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_700": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 10.5,
        "std_pred_length": 1.5,
        "median_pred_length": 10.5,
        "min_pred_length": 9,
        "max_pred_length": 12,
        "distinct-1": 0.9047619047619048,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.20184123230257,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.03912675144043812,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.1604646721932461,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.04492500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.19264507794239588,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.92037,
            "fmeasure": 0.80184
        },
        "rouge2": {
            "precision": 0.5641,
            "recall": 0.725,
            "fmeasure": 0.62338
        },
        "rougeL": {
            "precision": 0.69048,
            "recall": 0.83704,
            "fmeasure": 0.74735
        },
        "rougeLsum": {
            "precision": 0.69048,
            "recall": 0.83704,
            "fmeasure": 0.74735
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.5,
            "3": 0.9090909090909091
        },
        "nist": 4.073508785260441,
        "bleu": 62.44452,
        "bleurt": 0.16539,
        "nubia": {
            "semantic_relation": 4.59069,
            "contradiction": 6.87232,
            "irrelevancy": 37.95642,
            "logical_agreement": 55.17127,
            "grammar_ref": 5.35128,
            "grammar_hyp": 4.96975,
            "nubia_score": 0.85212
        },
        "meteor": 0.4656875850790296,
        "bertscore": {
            "precision": 0.92875,
            "recall": 0.94343,
            "f1": 0.93579
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_702": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76667,
            "recall": 0.74411,
            "fmeasure": 0.75355
        },
        "rouge2": {
            "precision": 0.40741,
            "recall": 0.39167,
            "fmeasure": 0.39835
        },
        "rougeL": {
            "precision": 0.56667,
            "recall": 0.54882,
            "fmeasure": 0.55639
        },
        "rougeLsum": {
            "precision": 0.56667,
            "recall": 0.54882,
            "fmeasure": 0.55639
        },
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.75
        },
        "nist": 2.681266793851506,
        "bleu": 13.9508,
        "bleurt": -0.5809,
        "nubia": {
            "semantic_relation": 3.95271,
            "contradiction": 11.63042,
            "irrelevancy": 75.42703,
            "logical_agreement": 12.94254,
            "grammar_ref": 6.0554,
            "grammar_hyp": 6.8021,
            "nubia_score": 0.41238
        },
        "meteor": 0.35297909215051454,
        "bertscore": {
            "precision": 0.86613,
            "recall": 0.89674,
            "f1": 0.88117
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_705": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7,
            "recall": 0.52564,
            "fmeasure": 0.60024
        },
        "rouge2": {
            "precision": 0.51852,
            "recall": 0.38889,
            "fmeasure": 0.44444
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.51282,
            "fmeasure": 0.57971
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.51282,
            "fmeasure": 0.57971
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6
        },
        "nist": 2.15060165196274,
        "bleu": 28.14501,
        "bleurt": -0.17401,
        "nubia": {
            "semantic_relation": 3.32037,
            "contradiction": 2.96236,
            "irrelevancy": 91.25153,
            "logical_agreement": 5.78611,
            "grammar_ref": 5.35534,
            "grammar_hyp": 5.07251,
            "nubia_score": 0.41485
        },
        "meteor": 0.31408417730700317,
        "bertscore": {
            "precision": 0.92381,
            "recall": 0.87638,
            "f1": 0.89947
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1685": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.39572,
            "fmeasure": 0.4787
        },
        "rouge2": {
            "precision": 0.42424,
            "recall": 0.24206,
            "fmeasure": 0.3071
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.35294,
            "fmeasure": 0.41379
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.35294,
            "fmeasure": 0.41379
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.5
        },
        "nist": 1.431947632530936,
        "bleu": 27.78567,
        "bleurt": 0.19679,
        "nubia": {
            "semantic_relation": 3.93128,
            "contradiction": 3.70092,
            "irrelevancy": 17.66046,
            "logical_agreement": 78.63862,
            "grammar_ref": 3.28677,
            "grammar_hyp": 4.28178,
            "nubia_score": 0.6088
        },
        "meteor": 0.22171691183608866,
        "bertscore": {
            "precision": 0.91949,
            "recall": 0.89037,
            "f1": 0.8986
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1165": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.26984,
            "fmeasure": 0.32727
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.5
        },
        "nist": 1.8094988549899862,
        "bleu": 24.59813,
        "bleurt": 0.30353,
        "nubia": {
            "semantic_relation": 4.18837,
            "contradiction": 0.38664,
            "irrelevancy": 0.58445,
            "logical_agreement": 99.02891,
            "grammar_ref": 4.24352,
            "grammar_hyp": 4.86986,
            "nubia_score": 0.75842
        },
        "meteor": 0.3010544205973617,
        "bertscore": {
            "precision": 0.97738,
            "recall": 0.94093,
            "f1": 0.95881
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1688": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.4,
            "recall": 0.35294,
            "fmeasure": 0.375
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.25,
            "fmeasure": 0.26667
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.29412,
            "fmeasure": 0.3125
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.29412,
            "fmeasure": 0.3125
        },
        "local_recall": {
            "1": 0,
            "2": 0.4
        },
        "nist": 1.66578250153649,
        "bleu": 20.70317,
        "bleurt": -0.39103,
        "nubia": {
            "semantic_relation": 2.11493,
            "contradiction": 96.53339,
            "irrelevancy": 2.28837,
            "logical_agreement": 1.17823,
            "grammar_ref": 4.28272,
            "grammar_hyp": 4.79082,
            "nubia_score": 0.15088
        },
        "meteor": 0.21512735963051483,
        "bertscore": {
            "precision": 0.76222,
            "recall": 0.78934,
            "f1": 0.77554
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1320": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.94872,
            "fmeasure": 0.90667
        },
        "rouge2": {
            "precision": 0.69697,
            "recall": 0.7381,
            "fmeasure": 0.70692
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.76282,
            "fmeasure": 0.73333
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.76282,
            "fmeasure": 0.73333
        },
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 3.9024801311398734,
        "bleu": 58.51655,
        "bleurt": -0.00284,
        "nubia": {
            "semantic_relation": 4.16958,
            "contradiction": 0.28804,
            "irrelevancy": 50.15351,
            "logical_agreement": 49.55844,
            "grammar_ref": 4.62626,
            "grammar_hyp": 4.37029,
            "nubia_score": 0.72136
        },
        "meteor": 0.5319853951676884,
        "bertscore": {
            "precision": 0.98044,
            "recall": 0.97622,
            "f1": 0.97833
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1022": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.55556,
            "fmeasure": 0.625
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.375,
            "fmeasure": 0.42857
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.55556,
            "fmeasure": 0.625
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.55556,
            "fmeasure": 0.625
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.5
        },
        "nist": 1.0913650456308712,
        "bleu": 32.8183,
        "bleurt": 0.3617,
        "nubia": {
            "semantic_relation": 2.76346,
            "contradiction": 63.75985,
            "irrelevancy": 10.38447,
            "logical_agreement": 25.85568,
            "grammar_ref": 5.49813,
            "grammar_hyp": 5.04312,
            "nubia_score": 0.2528
        },
        "meteor": 0.2538881940949526,
        "bertscore": {
            "precision": 0.9298,
            "recall": 0.89599,
            "f1": 0.91258
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1168": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.702819531114783,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.22388309575274978,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.4677201004745006,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2588453731729854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.42857,
            "recall": 0.22222,
            "fmeasure": 0.29268
        },
        "rouge2": {
            "precision": 0.07692,
            "recall": 0.03846,
            "fmeasure": 0.05128
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.22222,
            "fmeasure": 0.29268
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.22222,
            "fmeasure": 0.29268
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.2222222222222222
        },
        "nist": 0.20393861298303398,
        "bleu": 1.40808,
        "bleurt": -0.57589,
        "nubia": {
            "semantic_relation": 2.11219,
            "contradiction": 16.19162,
            "irrelevancy": 24.63795,
            "logical_agreement": 59.17043,
            "grammar_ref": 4.95946,
            "grammar_hyp": 6.19032,
            "nubia_score": 0.11552
        },
        "meteor": 0.0916389403043304,
        "bertscore": {
            "precision": 0.83379,
            "recall": 0.78494,
            "f1": 0.80859
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1692": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 3.0,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 17,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 24,
        "unique-1": 21,
        "entropy-1": 4.494680368408909,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.15288816155131352,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8846153846153846,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.440636352673264,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.16597642850354202,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65833,
            "recall": 0.64242,
            "fmeasure": 0.65
        },
        "rouge2": {
            "precision": 0.40196,
            "recall": 0.39363,
            "fmeasure": 0.39757
        },
        "rougeL": {
            "precision": 0.60556,
            "recall": 0.59192,
            "fmeasure": 0.59841
        },
        "rougeLsum": {
            "precision": 0.60556,
            "recall": 0.59192,
            "fmeasure": 0.59841
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.47368421052631576,
            "3": 0.8333333333333334
        },
        "nist": 3.0258361524358275,
        "bleu": 25.89373,
        "bleurt": 0.03402,
        "nubia": {
            "semantic_relation": 3.87781,
            "contradiction": 19.34983,
            "irrelevancy": 64.0465,
            "logical_agreement": 16.60367,
            "grammar_ref": 5.11675,
            "grammar_hyp": 4.54613,
            "nubia_score": 0.58595
        },
        "meteor": 0.29933976607816437,
        "bertscore": {
            "precision": 0.89554,
            "recall": 0.88271,
            "f1": 0.88828
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1032": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7735572622751845,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.04332146930622849,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.46667,
            "recall": 0.63636,
            "fmeasure": 0.53846
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.4,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.35556,
            "recall": 0.38788,
            "fmeasure": 0.36923
        },
        "rougeLsum": {
            "precision": 0.35556,
            "recall": 0.38788,
            "fmeasure": 0.36923
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.7
        },
        "nist": 3.0633392639199912,
        "bleu": 29.11892,
        "bleurt": -0.98858,
        "nubia": {
            "semantic_relation": 2.23126,
            "contradiction": 97.64087,
            "irrelevancy": 1.43992,
            "logical_agreement": 0.91922,
            "grammar_ref": 4.59968,
            "grammar_hyp": 4.64449,
            "nubia_score": 0.21785
        },
        "meteor": 0.28790588178896986,
        "bertscore": {
            "precision": 0.80698,
            "recall": 0.82421,
            "f1": 0.81029
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1170": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.5641,
            "fmeasure": 0.675
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.41667,
            "fmeasure": 0.50794
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.5641,
            "fmeasure": 0.675
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.5641,
            "fmeasure": 0.675
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.625
        },
        "nist": 1.353289509199005,
        "bleu": 42.13953,
        "bleurt": 0.02674,
        "nubia": {
            "semantic_relation": 3.58413,
            "contradiction": 0.90915,
            "irrelevancy": 0.77982,
            "logical_agreement": 98.31103,
            "grammar_ref": 4.45494,
            "grammar_hyp": 5.04864,
            "nubia_score": 0.50694
        },
        "meteor": 0.2969362339094229,
        "bertscore": {
            "precision": 0.95405,
            "recall": 0.92629,
            "f1": 0.93996
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1700": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.8,
            "fmeasure": 0.84211
        },
        "rouge2": {
            "precision": 0.70833,
            "recall": 0.62963,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.8,
            "fmeasure": 0.84211
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.8,
            "fmeasure": 0.84211
        },
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.147228454144942,
        "bleu": 71.08668,
        "bleurt": 0.16582,
        "nubia": {
            "semantic_relation": 4.71044,
            "contradiction": 5.5692,
            "irrelevancy": 5.51737,
            "logical_agreement": 88.91343,
            "grammar_ref": 5.6957,
            "grammar_hyp": 5.81375,
            "nubia_score": 0.71935
        },
        "meteor": 0.5012258995950178,
        "bertscore": {
            "precision": 0.99477,
            "recall": 0.98191,
            "f1": 0.9883
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1330": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 5.5,
        "median_pred_length": 13.5,
        "min_pred_length": 8,
        "max_pred_length": 19,
        "distinct-1": 0.8148148148148148,
        "vocab_size-1": 22,
        "unique-1": 17,
        "entropy-1": 4.3845171317931,
        "distinct-2": 0.92,
        "vocab_size-2": 23,
        "unique-2": 21,
        "entropy-2": 4.4838561897747224,
        "cond_entropy-2": 0.04896868761125603,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": 0.05361880976054911,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.251629167387823,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.277613436819113,
        "cond_entropy-2-nopunct": 0.05628729973432271,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": 0.06249647625006499,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80672,
            "recall": 0.71801,
            "fmeasure": 0.75604
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.49216,
            "fmeasure": 0.51881
        },
        "rougeL": {
            "precision": 0.60084,
            "recall": 0.55377,
            "fmeasure": 0.57335
        },
        "rougeLsum": {
            "precision": 0.60084,
            "recall": 0.55377,
            "fmeasure": 0.57335
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.5,
            "3": 0.7894736842105263
        },
        "nist": 4.340355720796141,
        "bleu": 25.7797,
        "bleurt": -0.16941,
        "nubia": {
            "semantic_relation": 4.47538,
            "contradiction": 0.17478,
            "irrelevancy": 1.92829,
            "logical_agreement": 97.89693,
            "grammar_ref": 6.00658,
            "grammar_hyp": 6.10281,
            "nubia_score": 0.80838
        },
        "meteor": 0.36543034253074086,
        "bertscore": {
            "precision": 0.92049,
            "recall": 0.87589,
            "f1": 0.89758
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_918": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 49,
        "mean_pred_length": 49.0,
        "std_pred_length": 0.0,
        "median_pred_length": 49.0,
        "min_pred_length": 49,
        "max_pred_length": 49,
        "distinct-1": 0.6938775510204082,
        "vocab_size-1": 34,
        "unique-1": 21,
        "entropy-1": 4.971653211373842,
        "distinct-2": 0.875,
        "vocab_size-2": 42,
        "unique-2": 36,
        "entropy-2": 5.3349625007211605,
        "cond_entropy-2": 0.37670630252942583,
        "distinct-3": 0.9361702127659575,
        "vocab_size-3": 44,
        "unique-3": 41,
        "entropy-3": 5.426929277209555,
        "cond_entropy-3": 0.09728592542456599,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 45.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 45.0,
        "min_pred_length-nopunct": 45,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.7111111111111111,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.89730004072604,
        "distinct-2-nopunct": 0.8636363636363636,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.186704345910023,
        "cond_entropy-2-nopunct": 0.2801896019022469,
        "distinct-3-nopunct": 0.9302325581395349,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.286729870981167,
        "cond_entropy-3-nopunct": 0.08311220583224255,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.3913,
            "recall": 0.68376,
            "fmeasure": 0.49772
        },
        "rouge2": {
            "precision": 0.16296,
            "recall": 0.49556,
            "fmeasure": 0.23993
        },
        "rougeL": {
            "precision": 0.30435,
            "recall": 0.53181,
            "fmeasure": 0.38711
        },
        "rougeLsum": {
            "precision": 0.30435,
            "recall": 0.53181,
            "fmeasure": 0.38711
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.9
        },
        "nist": 2.1308886718928144,
        "bleu": 20.57906,
        "bleurt": -0.26709,
        "nubia": {
            "semantic_relation": 3.56266,
            "contradiction": 28.05959,
            "irrelevancy": 66.18609,
            "logical_agreement": 5.75433,
            "grammar_ref": 4.65446,
            "grammar_hyp": 3.98461,
            "nubia_score": 0.11791
        },
        "meteor": 0.30034912427768334,
        "bertscore": {
            "precision": 0.87193,
            "recall": 0.90733,
            "f1": 0.88611
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1036": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 5.0,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 18,
        "distinct-1": 0.8846153846153846,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.46967048737186,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.05118944924673082,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.05628729973432274,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72269,
            "recall": 0.58754,
            "fmeasure": 0.6369
        },
        "rouge2": {
            "precision": 0.34375,
            "recall": 0.25084,
            "fmeasure": 0.28447
        },
        "rougeL": {
            "precision": 0.52101,
            "recall": 0.43367,
            "fmeasure": 0.46508
        },
        "rougeLsum": {
            "precision": 0.52101,
            "recall": 0.43367,
            "fmeasure": 0.46508
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855,
            "3": 0.631578947368421
        },
        "nist": 2.8336012716494854,
        "bleu": 6.26183,
        "bleurt": 0.15835,
        "nubia": {
            "semantic_relation": 4.15069,
            "contradiction": 21.14638,
            "irrelevancy": 19.99131,
            "logical_agreement": 58.86231,
            "grammar_ref": 4.70186,
            "grammar_hyp": 5.73889,
            "nubia_score": 0.57812
        },
        "meteor": 0.3094876078993271,
        "bertscore": {
            "precision": 0.90423,
            "recall": 0.8647,
            "f1": 0.87992
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1172": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.72222,
            "fmeasure": 0.76389
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.21481,
            "fmeasure": 0.25714
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.57778,
            "fmeasure": 0.61111
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.57778,
            "fmeasure": 0.61111
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "nist": 1.8984662032591466,
        "bleu": 45.49941,
        "bleurt": -0.25784,
        "nubia": {
            "semantic_relation": 4.1669,
            "contradiction": 24.05626,
            "irrelevancy": 6.20733,
            "logical_agreement": 69.73641,
            "grammar_ref": 7.45181,
            "grammar_hyp": 7.92309,
            "nubia_score": 0.5873
        },
        "meteor": 0.41695290290356585,
        "bertscore": {
            "precision": 0.92658,
            "recall": 0.92658,
            "f1": 0.92658
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1730": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 58,
        "mean_pred_length": 19.333333333333332,
        "std_pred_length": 4.189935029992178,
        "median_pred_length": 18.0,
        "min_pred_length": 15,
        "max_pred_length": 25,
        "distinct-1": 0.5172413793103449,
        "vocab_size-1": 30,
        "unique-1": 14,
        "entropy-1": 4.719375822415368,
        "distinct-2": 0.8181818181818182,
        "vocab_size-2": 45,
        "unique-2": 37,
        "entropy-2": 5.390272895264166,
        "cond_entropy-2": 0.6465503095028577,
        "distinct-3": 0.9230769230769231,
        "vocab_size-3": 48,
        "unique-3": 44,
        "entropy-3": 5.546593564294942,
        "cond_entropy-3": 0.14042183162271976,
        "total_length-nopunct": 51,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 2.943920288775949,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.5490196078431373,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.627636861282394,
        "distinct-2-nopunct": 0.8125,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.178508854797682,
        "cond_entropy-2-nopunct": 0.5745046068916887,
        "distinct-3-nopunct": 0.9333333333333333,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.35851976299634,
        "cond_entropy-3-nopunct": 0.16266337348245008,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77679,
            "recall": 0.73823,
            "fmeasure": 0.75491
        },
        "rouge2": {
            "precision": 0.50655,
            "recall": 0.49084,
            "fmeasure": 0.49715
        },
        "rougeL": {
            "precision": 0.55225,
            "recall": 0.51541,
            "fmeasure": 0.53149
        },
        "rougeLsum": {
            "precision": 0.55225,
            "recall": 0.51541,
            "fmeasure": 0.53149
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.7555555555555555
        },
        "nist": 4.233730635779358,
        "bleu": 40.63454,
        "bleurt": 0.02756,
        "nubia": {
            "semantic_relation": 3.65183,
            "contradiction": 61.55945,
            "irrelevancy": 22.28703,
            "logical_agreement": 16.15351,
            "grammar_ref": 4.73012,
            "grammar_hyp": 5.08286,
            "nubia_score": 0.49541
        },
        "meteor": 0.36409913930151533,
        "bertscore": {
            "precision": 0.92344,
            "recall": 0.90374,
            "f1": 0.91131
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1359": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65385,
            "recall": 0.5881,
            "fmeasure": 0.61905
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.33516,
            "fmeasure": 0.35385
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.45,
            "fmeasure": 0.47354
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.45,
            "fmeasure": 0.47354
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.7272727272727273
        },
        "nist": 2.6831146301678572,
        "bleu": 25.93783,
        "bleurt": 0.27418,
        "nubia": {
            "semantic_relation": 4.46136,
            "contradiction": 0.24776,
            "irrelevancy": 0.71991,
            "logical_agreement": 99.03233,
            "grammar_ref": 5.03823,
            "grammar_hyp": 4.49648,
            "nubia_score": 0.90359
        },
        "meteor": 0.32097379405732984,
        "bertscore": {
            "precision": 0.90853,
            "recall": 0.87084,
            "f1": 0.88928
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1043": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.35897,
            "recall": 0.34343,
            "fmeasure": 0.34921
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.29091,
            "fmeasure": 0.26877
        },
        "rougeL": {
            "precision": 0.35897,
            "recall": 0.34343,
            "fmeasure": 0.34921
        },
        "rougeLsum": {
            "precision": 0.35897,
            "recall": 0.34343,
            "fmeasure": 0.34921
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.4
        },
        "nist": 2.0127982274959493,
        "bleu": 25.8843,
        "bleurt": -0.60612,
        "nubia": {
            "semantic_relation": 2.44868,
            "contradiction": 91.82511,
            "irrelevancy": 6.79175,
            "logical_agreement": 1.38313,
            "grammar_ref": 5.20931,
            "grammar_hyp": 5.65124,
            "nubia_score": 0.17677
        },
        "meteor": 0.20489851454040772,
        "bertscore": {
            "precision": 0.7797,
            "recall": 0.80286,
            "f1": 0.78555
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1050": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90909
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.78571,
            "fmeasure": 0.84211
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90909
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90909
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 3.273915542852983,
        "bleu": 100.0,
        "bleurt": 0.56444,
        "nubia": {
            "semantic_relation": 4.30531,
            "contradiction": 0.13077,
            "irrelevancy": 33.52146,
            "logical_agreement": 66.34777,
            "grammar_ref": 5.27628,
            "grammar_hyp": 5.33569,
            "nubia_score": 0.8039
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1379": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.8518518518518519,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.43063240949075,
        "distinct-2": 0.9615384615384616,
        "vocab_size-2": 25,
        "unique-2": 24,
        "entropy-2": 4.623516641218013,
        "cond_entropy-2": 0.20535558144544927,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": 0.023416471633632502,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 26.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 26,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.363713275750188,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.5638561897747225,
        "cond_entropy-2-nopunct": 0.21361197172017118,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": 0.024439644279765044,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82051,
            "recall": 0.79012,
            "fmeasure": 0.80503
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.70513,
            "fmeasure": 0.71895
        },
        "rougeL": {
            "precision": 0.82051,
            "recall": 0.79012,
            "fmeasure": 0.80503
        },
        "rougeLsum": {
            "precision": 0.82051,
            "recall": 0.79012,
            "fmeasure": 0.80503
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.8095238095238095
        },
        "nist": 4.234948156768185,
        "bleu": 60.20018,
        "bleurt": 0.17762,
        "nubia": {
            "semantic_relation": 4.17437,
            "contradiction": 5.4856,
            "irrelevancy": 10.84421,
            "logical_agreement": 83.67019,
            "grammar_ref": 4.19464,
            "grammar_hyp": 4.08455,
            "nubia_score": 0.69971
        },
        "meteor": 0.4551467595156829,
        "bertscore": {
            "precision": 0.96422,
            "recall": 0.95302,
            "f1": 0.95859
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1174": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 10.5,
        "std_pred_length": 3.5,
        "median_pred_length": 10.5,
        "min_pred_length": 7,
        "max_pred_length": 14,
        "distinct-1": 0.7619047619047619,
        "vocab_size-1": 16,
        "unique-1": 11,
        "entropy-1": 3.916126946588283,
        "distinct-2": 0.8421052631578947,
        "vocab_size-2": 16,
        "unique-2": 13,
        "entropy-2": 3.932138039759373,
        "cond_entropy-2": -0.03912675144043809,
        "distinct-3": 0.8823529411764706,
        "vocab_size-3": 15,
        "unique-3": 13,
        "entropy-3": 3.8521687236032816,
        "cond_entropy-3": -0.04281761336971672,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7894736842105263,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.826874881864636,
        "distinct-2-nopunct": 0.8235294117647058,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.734521664779752,
        "cond_entropy-2-nopunct": -0.10164114278148138,
        "distinct-3-nopunct": 0.8666666666666667,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.640223928941851,
        "cond_entropy-3-nopunct": -0.11390557897515413,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82143,
            "recall": 0.85119,
            "fmeasure": 0.83333
        },
        "rouge2": {
            "precision": 0.69744,
            "recall": 0.71717,
            "fmeasure": 0.70455
        },
        "rougeL": {
            "precision": 0.78571,
            "recall": 0.80952,
            "fmeasure": 0.79487
        },
        "rougeLsum": {
            "precision": 0.78571,
            "recall": 0.80952,
            "fmeasure": 0.79487
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8125
        },
        "nist": 3.41607145067997,
        "bleu": 56.92343,
        "bleurt": 0.52098,
        "nubia": {
            "semantic_relation": 4.39164,
            "contradiction": 0.533,
            "irrelevancy": 50.16471,
            "logical_agreement": 49.30228,
            "grammar_ref": 4.94813,
            "grammar_hyp": 5.34807,
            "nubia_score": 0.74683
        },
        "meteor": 0.4559027799946566,
        "bertscore": {
            "precision": 0.95982,
            "recall": 0.97108,
            "f1": 0.96539
        }
    },
    "xsum_validation": {
        "predictions_file": "T5-large (Baseline)/xsum_validation",
        "N": 1117,
        "msttr-100": 0.73655,
        "msttr-100_nopunct": 0.75747,
        "total_length": 23827,
        "mean_pred_length": 21.331244404655326,
        "std_pred_length": 4.579687311719243,
        "median_pred_length": 21.0,
        "min_pred_length": 8,
        "max_pred_length": 39,
        "distinct-1": 0.19817853695387586,
        "vocab_size-1": 4722,
        "unique-1": 2759,
        "entropy-1": 9.253667116404918,
        "distinct-2": 0.6494936151475121,
        "vocab_size-2": 14750,
        "unique-2": 12268,
        "entropy-2": 13.134472274788681,
        "cond_entropy-2": 3.64419668187365,
        "distinct-3": 0.880702079377576,
        "vocab_size-3": 19017,
        "unique-3": 17676,
        "entropy-3": 14.061915532096831,
        "cond_entropy-3": 0.9292263699986203,
        "total_length-nopunct": 22182,
        "mean_pred_length-nopunct": 19.858549686660698,
        "std_pred_length-nopunct": 4.385992480186329,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.21233432512848255,
        "vocab_size-1-nopunct": 4710,
        "unique-1-nopunct": 2757,
        "entropy-1-nopunct": 9.448370205217893,
        "distinct-2-nopunct": 0.6600522193211488,
        "vocab_size-2-nopunct": 13904,
        "unique-2-nopunct": 11619,
        "entropy-2-nopunct": 13.068952073259046,
        "cond_entropy-2-nopunct": 3.74278657273576,
        "distinct-3-nopunct": 0.8908662522558652,
        "vocab_size-3-nopunct": 17771,
        "unique-3-nopunct": 16575,
        "entropy-3-nopunct": 13.990104752392796,
        "cond_entropy-3-nopunct": 0.9367032255077798,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_validation.json",
        "rouge1": {
            "precision": 0.41856,
            "recall": 0.39188,
            "fmeasure": 0.39704
        },
        "rouge2": {
            "precision": 0.16958,
            "recall": 0.15856,
            "fmeasure": 0.16074
        },
        "rougeL": {
            "precision": 0.32814,
            "recall": 0.30775,
            "fmeasure": 0.3115
        },
        "rougeLsum": {
            "precision": 0.32814,
            "recall": 0.30775,
            "fmeasure": 0.3115
        },
        "local_recall": {
            "1": 0.36677809902421393
        },
        "nist": 4.042115918414019,
        "bleu": 11.05431,
        "bleurt": -0.28861,
        "nubia": {
            "semantic_relation": 3.0186,
            "contradiction": 15.84502,
            "irrelevancy": 66.97362,
            "logical_agreement": 17.18136,
            "grammar_ref": 3.8151,
            "grammar_hyp": 3.6159,
            "nubia_score": 0.46532
        },
        "meteor": 0.1796568731243612,
        "bertscore": {
            "precision": 0.83785,
            "recall": 0.82771,
            "f1": 0.83244
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1770": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.11251249881411757,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.1219280948873624,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.1365257343456969,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.38095,
            "recall": 0.69697,
            "fmeasure": 0.49242
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.38182,
            "fmeasure": 0.26237
        },
        "rougeL": {
            "precision": 0.38095,
            "recall": 0.69697,
            "fmeasure": 0.49242
        },
        "rougeLsum": {
            "precision": 0.38095,
            "recall": 0.69697,
            "fmeasure": 0.49242
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.75
        },
        "nist": 1.3265909987017535,
        "bleu": 12.06294,
        "bleurt": -0.15996,
        "nubia": {
            "semantic_relation": 4.29663,
            "contradiction": 0.17312,
            "irrelevancy": 88.30698,
            "logical_agreement": 11.5199,
            "grammar_ref": 5.10481,
            "grammar_hyp": 3.86244,
            "nubia_score": 0.55362
        },
        "meteor": 0.29782350207397557,
        "bertscore": {
            "precision": 0.82128,
            "recall": 0.89961,
            "f1": 0.85866
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_920": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 52,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 2.8674417556808756,
        "median_pred_length": 17.0,
        "min_pred_length": 14,
        "max_pred_length": 21,
        "distinct-1": 0.8269230769230769,
        "vocab_size-1": 43,
        "unique-1": 35,
        "entropy-1": 5.339768804637951,
        "distinct-2": 0.9795918367346939,
        "vocab_size-2": 48,
        "unique-2": 47,
        "entropy-2": 5.5738935175845965,
        "cond_entropy-2": 0.1591680851577899,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": -0.04766962718863019,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 4.109609335312651,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8478260869565217,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.219214129970054,
        "distinct-2-nopunct": 0.9767441860465116,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.379753126795121,
        "cond_entropy-2-nopunct": 0.18177256608694536,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.05433665981473579,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.69237,
            "recall": 0.71481,
            "fmeasure": 0.70092
        },
        "rouge2": {
            "precision": 0.49781,
            "recall": 0.52342,
            "fmeasure": 0.50831
        },
        "rougeL": {
            "precision": 0.64237,
            "recall": 0.66111,
            "fmeasure": 0.64917
        },
        "rougeLsum": {
            "precision": 0.64237,
            "recall": 0.66111,
            "fmeasure": 0.64917
        },
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.3,
            "3": 0.7222222222222222
        },
        "nist": 3.9202124791641384,
        "bleu": 35.83574,
        "bleurt": 0.12754,
        "nubia": {
            "semantic_relation": 3.76964,
            "contradiction": 25.43958,
            "irrelevancy": 44.47882,
            "logical_agreement": 30.0816,
            "grammar_ref": 4.46773,
            "grammar_hyp": 4.60301,
            "nubia_score": 0.54954
        },
        "meteor": 0.3163989469573574,
        "bertscore": {
            "precision": 0.92425,
            "recall": 0.90964,
            "f1": 0.91093
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1176": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 9.0,
        "std_pred_length": 2.0,
        "median_pred_length": 9.0,
        "min_pred_length": 7,
        "max_pred_length": 11,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 14,
        "unique-1": 10,
        "entropy-1": 3.7254805569978675,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.20507499855768763,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.19264507794239588,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.625,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.23592635062903272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644807,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65,
            "recall": 0.65,
            "fmeasure": 0.65
        },
        "rouge2": {
            "precision": 0.46296,
            "recall": 0.46296,
            "fmeasure": 0.46296
        },
        "rougeL": {
            "precision": 0.56667,
            "recall": 0.56667,
            "fmeasure": 0.56667
        },
        "rougeLsum": {
            "precision": 0.56667,
            "recall": 0.56667,
            "fmeasure": 0.56667
        },
        "local_recall": {
            "1": 0.1,
            "2": 0,
            "3": 0.7333333333333333
        },
        "nist": 3.170026063909986,
        "bleu": 67.56001,
        "bleurt": 0.26595,
        "nubia": {
            "semantic_relation": 3.73168,
            "contradiction": 0.53487,
            "irrelevancy": 1.02184,
            "logical_agreement": 98.44329,
            "grammar_ref": 5.47595,
            "grammar_hyp": 4.85552,
            "nubia_score": 0.70245
        },
        "meteor": 0.41523929854207936,
        "bertscore": {
            "precision": 0.89736,
            "recall": 0.87977,
            "f1": 0.88836
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_924": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.043321469306228516,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82222,
            "recall": 0.72807,
            "fmeasure": 0.77103
        },
        "rouge2": {
            "precision": 0.64286,
            "recall": 0.56667,
            "fmeasure": 0.60129
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.53289,
            "fmeasure": 0.56357
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.53289,
            "fmeasure": 0.56357
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.75
        },
        "nist": 2.3014758164921103,
        "bleu": 38.16857,
        "bleurt": -0.15235,
        "nubia": {
            "semantic_relation": 4.2286,
            "contradiction": 0.082,
            "irrelevancy": 5.78961,
            "logical_agreement": 94.12839,
            "grammar_ref": 4.542,
            "grammar_hyp": 4.17812,
            "nubia_score": 0.8155
        },
        "meteor": 0.36603378617919835,
        "bertscore": {
            "precision": 0.88809,
            "recall": 0.81119,
            "f1": 0.8479
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_925": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.7735572622751845,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.04332146930622849,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.7619,
            "fmeasure": 0.79524
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.30769,
            "fmeasure": 0.30769
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.35714,
            "fmeasure": 0.35714
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.35714,
            "fmeasure": 0.35714
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8461538461538461
        },
        "nist": 3.095584266552612,
        "bleu": 10.82598,
        "bleurt": 0.38009,
        "nubia": {
            "semantic_relation": 4.39047,
            "contradiction": 0.44822,
            "irrelevancy": 0.84469,
            "logical_agreement": 98.70709,
            "grammar_ref": 5.0526,
            "grammar_hyp": 5.14987,
            "nubia_score": 0.73463
        },
        "meteor": 0.3796259133692255,
        "bertscore": {
            "precision": 0.9124,
            "recall": 0.91194,
            "f1": 0.91217
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1180": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 4.5,
        "median_pred_length": 12.5,
        "min_pred_length": 8,
        "max_pred_length": 17,
        "distinct-1": 0.8,
        "vocab_size-1": 20,
        "unique-1": 15,
        "entropy-1": 4.243856189774724,
        "distinct-2": 0.8695652173913043,
        "vocab_size-2": 20,
        "unique-2": 17,
        "entropy-2": 4.262692390839622,
        "cond_entropy-2": -0.03333771197858132,
        "distinct-3": 0.9523809523809523,
        "vocab_size-3": 20,
        "unique-3": 19,
        "entropy-3": 4.297079327540665,
        "cond_entropy-3": -0.03600643804015718,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.095795255000933,
        "distinct-2-nopunct": 0.9,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.1219280948873624,
        "cond_entropy-2-nopunct": -0.037503523749935014,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.040891982333938634,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.51429,
            "recall": 0.50458,
            "fmeasure": 0.50523
        },
        "rouge2": {
            "precision": 0.2619,
            "recall": 0.26549,
            "fmeasure": 0.26136
        },
        "rougeL": {
            "precision": 0.48095,
            "recall": 0.46703,
            "fmeasure": 0.46993
        },
        "rougeLsum": {
            "precision": 0.48095,
            "recall": 0.46703,
            "fmeasure": 0.46993
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "nist": 2.3562793865187746,
        "bleu": 18.20497,
        "bleurt": 0.21303,
        "nubia": {
            "semantic_relation": 3.26043,
            "contradiction": 47.52693,
            "irrelevancy": 52.0334,
            "logical_agreement": 0.43967,
            "grammar_ref": 5.01983,
            "grammar_hyp": 4.84199,
            "nubia_score": 0.45489
        },
        "meteor": 0.2974913745378087,
        "bertscore": {
            "precision": 0.90022,
            "recall": 0.91184,
            "f1": 0.90576
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1055": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 2.8483609718589222,
        "bleu": 100.0,
        "bleurt": 0.96931,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.21732,
            "irrelevancy": 0.45505,
            "logical_agreement": 99.32763,
            "grammar_ref": 5.4078,
            "grammar_hyp": 5.46881,
            "nubia_score": 0.9943
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1056": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 12,
        "unique-1": 10,
        "entropy-1": 3.521640636343319,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 12,
        "unique-2": 11,
        "entropy-2": 3.5465935642949384,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": 0.05118944924673077,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.418295834054489,
        "cond_entropy-2-nopunct": 0.05118944924673078,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": 0.056287299734322706,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.53846,
            "recall": 0.62092,
            "fmeasure": 0.56364
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.46875,
            "fmeasure": 0.40714
        },
        "rougeL": {
            "precision": 0.53846,
            "recall": 0.62092,
            "fmeasure": 0.56364
        },
        "rougeLsum": {
            "precision": 0.53846,
            "recall": 0.62092,
            "fmeasure": 0.56364
        },
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.7142857142857143
        },
        "nist": 2.333361941695811,
        "bleu": 31.61488,
        "bleurt": 0.18823,
        "nubia": {
            "semantic_relation": 4.21805,
            "contradiction": 0.26553,
            "irrelevancy": 84.0294,
            "logical_agreement": 15.70508,
            "grammar_ref": 5.6106,
            "grammar_hyp": 4.19382,
            "nubia_score": 0.77504
        },
        "meteor": 0.4361381544346885,
        "bertscore": {
            "precision": 0.87901,
            "recall": 0.91528,
            "f1": 0.89678
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1182": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.0433214693062285,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.47222,
            "fmeasure": 0.39012
        },
        "rouge2": {
            "precision": 0.07143,
            "recall": 0.10438,
            "fmeasure": 0.08464
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.47222,
            "fmeasure": 0.39012
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.47222,
            "fmeasure": 0.39012
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "nist": 1.1675001135097276,
        "bleu": 3.92972,
        "bleurt": -0.71442,
        "nubia": {
            "semantic_relation": 3.32904,
            "contradiction": 0.13323,
            "irrelevancy": 99.73638,
            "logical_agreement": 0.13039,
            "grammar_ref": 4.40566,
            "grammar_hyp": 4.20608,
            "nubia_score": 0.4781
        },
        "meteor": 0.22293221207876535,
        "bertscore": {
            "precision": 0.79293,
            "recall": 0.82266,
            "f1": 0.80752
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1384": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.29167,
            "recall": 0.43651,
            "fmeasure": 0.34837
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.36508,
            "fmeasure": 0.29574
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.36508,
            "fmeasure": 0.29574
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5
        },
        "nist": 1.3553885422075338,
        "bleu": 5.064,
        "bleurt": 0.45014,
        "nubia": {
            "semantic_relation": 2.98275,
            "contradiction": 0.09943,
            "irrelevancy": 98.36294,
            "logical_agreement": 1.53762,
            "grammar_ref": 4.8549,
            "grammar_hyp": 3.55452,
            "nubia_score": 0.54983
        },
        "meteor": 0.3123490177111846,
        "bertscore": {
            "precision": 0.84989,
            "recall": 0.88386,
            "f1": 0.86654
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_931": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.033108599109837954,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.47222,
            "recall": 0.73462,
            "fmeasure": 0.57258
        },
        "rouge2": {
            "precision": 0.17647,
            "recall": 0.27778,
            "fmeasure": 0.21485
        },
        "rougeL": {
            "precision": 0.22222,
            "recall": 0.34231,
            "fmeasure": 0.26843
        },
        "rougeLsum": {
            "precision": 0.22222,
            "recall": 0.34231,
            "fmeasure": 0.26843
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.875
        },
        "nist": 2.339335344821895,
        "bleu": 14.74736,
        "bleurt": -0.57664,
        "nubia": {
            "semantic_relation": 3.17737,
            "contradiction": 10.97769,
            "irrelevancy": 88.80212,
            "logical_agreement": 0.22019,
            "grammar_ref": 4.19915,
            "grammar_hyp": 5.02646,
            "nubia_score": 0.35784
        },
        "meteor": 0.32218849077047446,
        "bertscore": {
            "precision": 0.8399,
            "recall": 0.8741,
            "f1": 0.85666
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1072": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 4.5,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 18,
        "distinct-1": 0.8148148148148148,
        "vocab_size-1": 22,
        "unique-1": 19,
        "entropy-1": 4.310443057719026,
        "distinct-2": 0.96,
        "vocab_size-2": 24,
        "unique-2": 23,
        "entropy-2": 4.5638561897747225,
        "cond_entropy-2": 0.20896868761125612,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.03333771197858132,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.16829583405449,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.368522527728204,
        "cond_entropy-2-nopunct": 0.23810548155250447,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.037503523749935014,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74074,
            "recall": 0.59615,
            "fmeasure": 0.62401
        },
        "rouge2": {
            "precision": 0.55392,
            "recall": 0.39744,
            "fmeasure": 0.43382
        },
        "rougeL": {
            "precision": 0.71296,
            "recall": 0.55769,
            "fmeasure": 0.59176
        },
        "rougeLsum": {
            "precision": 0.71296,
            "recall": 0.55769,
            "fmeasure": 0.59176
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.5714285714285714
        },
        "nist": 2.7687370364598585,
        "bleu": 25.97362,
        "bleurt": -0.20216,
        "nubia": {
            "semantic_relation": 3.38478,
            "contradiction": 49.97219,
            "irrelevancy": 0.41616,
            "logical_agreement": 49.61166,
            "grammar_ref": 4.47266,
            "grammar_hyp": 3.96256,
            "nubia_score": 0.5771
        },
        "meteor": 0.3512379988716303,
        "bertscore": {
            "precision": 0.88457,
            "recall": 0.86404,
            "f1": 0.87284
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_936": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 3.0,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 19,
        "distinct-1": 0.96875,
        "vocab_size-1": 31,
        "unique-1": 30,
        "entropy-1": 4.9375,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": -0.09310940439148141,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.754887502163471,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": -0.11103131238874399,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.95833,
            "recall": 0.83333,
            "fmeasure": 0.88384
        },
        "rouge2": {
            "precision": 0.81111,
            "recall": 0.71166,
            "fmeasure": 0.74893
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.77143,
            "fmeasure": 0.81313
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.77143,
            "fmeasure": 0.81313
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.8076923076923077
        },
        "nist": 3.5978070978103753,
        "bleu": 49.26988,
        "bleurt": 0.26762,
        "nubia": {
            "semantic_relation": 4.21958,
            "contradiction": 48.90468,
            "irrelevancy": 1.41799,
            "logical_agreement": 49.67734,
            "grammar_ref": 4.54027,
            "grammar_hyp": 5.39557,
            "nubia_score": 0.52407
        },
        "meteor": 0.4389267115461241,
        "bertscore": {
            "precision": 0.94944,
            "recall": 0.94974,
            "f1": 0.94921
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1080": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.84314,
            "recall": 0.675,
            "fmeasure": 0.74841
        },
        "rouge2": {
            "precision": 0.29167,
            "recall": 0.26433,
            "fmeasure": 0.2765
        },
        "rougeL": {
            "precision": 0.5098,
            "recall": 0.50833,
            "fmeasure": 0.50778
        },
        "rougeLsum": {
            "precision": 0.5098,
            "recall": 0.50833,
            "fmeasure": 0.50778
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.75,
            "3": 0.7142857142857143
        },
        "nist": 3.3313738028972995,
        "bleu": 14.16965,
        "bleurt": -0.31481,
        "nubia": {
            "semantic_relation": 3.72041,
            "contradiction": 1.72728,
            "irrelevancy": 33.56156,
            "logical_agreement": 64.71116,
            "grammar_ref": 4.75667,
            "grammar_hyp": 4.44503,
            "nubia_score": 0.60969
        },
        "meteor": 0.33008547765183394,
        "bertscore": {
            "precision": 0.8716,
            "recall": 0.85431,
            "f1": 0.86197
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_938": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 32.0,
        "std_pred_length": 0.0,
        "median_pred_length": 32.0,
        "min_pred_length": 32,
        "max_pred_length": 32,
        "distinct-1": 0.84375,
        "vocab_size-1": 27,
        "unique-1": 23,
        "entropy-1": 4.663909765557392,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": 0.26887010077924517,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.04730571477835684,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 27.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 27,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.9259259259259259,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.606739354015323,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.09939836982377728,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.05658352836636749,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.96296,
            "recall": 1.0,
            "fmeasure": 0.98113
        },
        "rouge2": {
            "precision": 0.92308,
            "recall": 0.96,
            "fmeasure": 0.94118
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 1.0,
            "fmeasure": 0.98113
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 1.0,
            "fmeasure": 0.98113
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 5.106103203587009,
        "bleu": 91.57104,
        "bleurt": 0.82638,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.15379,
            "irrelevancy": 0.41963,
            "logical_agreement": 99.42659,
            "grammar_ref": 4.59074,
            "grammar_hyp": 4.45543,
            "nubia_score": 1.0
        },
        "meteor": 0.6495217122678133,
        "bertscore": {
            "precision": 0.99404,
            "recall": 0.99774,
            "f1": 0.99589
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_challenge_test_turk_bfp02",
        "N": 359,
        "msttr-100": 0.73493,
        "msttr-100_nopunct": 0.78226,
        "total_length": 6989,
        "mean_pred_length": 19.467966573816156,
        "std_pred_length": 9.467049087643522,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.38646444412648445,
        "vocab_size-1": 2701,
        "unique-1": 2089,
        "entropy-1": 9.204645106725538,
        "distinct-2": 0.8470588235294118,
        "vocab_size-2": 5616,
        "unique-2": 5256,
        "entropy-2": 12.142576459483575,
        "cond_entropy-2": 2.6632107035770116,
        "distinct-3": 0.9665125179397225,
        "vocab_size-3": 6061,
        "unique-3": 5976,
        "entropy-3": 12.492748704564912,
        "cond_entropy-3": 0.36721919563068334,
        "total_length-nopunct": 6203,
        "mean_pred_length-nopunct": 17.278551532033426,
        "std_pred_length-nopunct": 8.33326469091822,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.4334999193938417,
        "vocab_size-1-nopunct": 2689,
        "unique-1-nopunct": 2085,
        "entropy-1-nopunct": 9.571757390579991,
        "distinct-2-nopunct": 0.8685831622176592,
        "vocab_size-2-nopunct": 5076,
        "unique-2-nopunct": 4784,
        "entropy-2-nopunct": 12.05063593238278,
        "cond_entropy-2-nopunct": 2.617840274711773,
        "distinct-3-nopunct": 0.9808568824065633,
        "vocab_size-3-nopunct": 5380,
        "unique-3-nopunct": 5313,
        "entropy-3-nopunct": 12.374120640923003,
        "cond_entropy-3-nopunct": 0.34843183791407084,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp02.json",
        "rouge1": {
            "precision": 0.77834,
            "recall": 0.71106,
            "fmeasure": 0.73019
        },
        "rouge2": {
            "precision": 0.60385,
            "recall": 0.54578,
            "fmeasure": 0.56203
        },
        "rougeL": {
            "precision": 0.75598,
            "recall": 0.68678,
            "fmeasure": 0.70699
        },
        "rougeLsum": {
            "precision": 0.75598,
            "recall": 0.68678,
            "fmeasure": 0.70699
        },
        "local_recall": {
            "1": 0.04690152801358234,
            "2": 0.1558109833971903,
            "3": 0.33260393873085337,
            "4": 0.44849445324881143,
            "5": 0.5752855659397715,
            "6": 0.6714975845410628,
            "7": 0.7869415807560137
        },
        "nist": 9.715243446439407,
        "bleu": 54.41266,
        "sari": 48.27817,
        "bleurt": -0.24923,
        "nubia": {
            "semantic_relation": 4.02649,
            "contradiction": 6.251,
            "irrelevancy": 17.25101,
            "logical_agreement": 76.49799,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.58088,
            "nubia_score": 0.56522
        },
        "meteor": 0.3875313224471269,
        "bertscore": {
            "precision": 0.91585,
            "recall": 0.91896,
            "f1": 0.91454
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_940": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.6901165175936654,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.3347176276348775,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.4565647621309536,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.38295629088933336,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.67402,
            "fmeasure": 0.70228
        },
        "rouge2": {
            "precision": 0.45238,
            "recall": 0.41528,
            "fmeasure": 0.43295
        },
        "rougeL": {
            "precision": 0.51111,
            "recall": 0.47059,
            "fmeasure": 0.48992
        },
        "rougeLsum": {
            "precision": 0.51111,
            "recall": 0.47059,
            "fmeasure": 0.48992
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.14285714285714285,
            "3": 0.7777777777777778
        },
        "nist": 3.8857829082886455,
        "bleu": 48.25893,
        "bleurt": 0.12459,
        "nubia": {
            "semantic_relation": 3.2133,
            "contradiction": 0.07007,
            "irrelevancy": 35.34268,
            "logical_agreement": 64.58725,
            "grammar_ref": 3.5564,
            "grammar_hyp": 3.3071,
            "nubia_score": 0.57929
        },
        "meteor": 0.35976830387915265,
        "bertscore": {
            "precision": 0.92092,
            "recall": 0.89276,
            "f1": 0.90662
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1400": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322706,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.277613436819116,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.95833
        },
        "rouge2": {
            "precision": 0.95,
            "recall": 0.875,
            "fmeasure": 0.90909
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.95833
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.95833
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0
        },
        "nist": 3.926459146568544,
        "bleu": 84.15565,
        "bleurt": 0.84989,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.18557,
            "irrelevancy": 0.52009,
            "logical_agreement": 99.29434,
            "grammar_ref": 4.75081,
            "grammar_hyp": 4.86853,
            "nubia_score": 0.98938
        },
        "meteor": 0.5623201842518945,
        "bertscore": {
            "precision": 0.99834,
            "recall": 0.98391,
            "f1": 0.99107
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1408": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.614369445886757,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.5057731339256742,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7647058823529411,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.4992275471326932,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.5375371587496608,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.23529,
            "recall": 0.28356,
            "fmeasure": 0.25621
        },
        "rouge2": {
            "precision": 0.0625,
            "recall": 0.07639,
            "fmeasure": 0.06845
        },
        "rougeL": {
            "precision": 0.21569,
            "recall": 0.23379,
            "fmeasure": 0.22353
        },
        "rougeLsum": {
            "precision": 0.21569,
            "recall": 0.23379,
            "fmeasure": 0.22353
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "nist": 1.1076685432222044,
        "bleu": 5.10928,
        "bleurt": -0.51387,
        "nubia": {
            "semantic_relation": 1.19713,
            "contradiction": 31.22915,
            "irrelevancy": 67.58457,
            "logical_agreement": 1.18628,
            "grammar_ref": 4.12033,
            "grammar_hyp": 3.57394,
            "nubia_score": 0.11702
        },
        "meteor": 0.12010865911715858,
        "bertscore": {
            "precision": 0.67961,
            "recall": 0.68091,
            "f1": 0.68018
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_945": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 3.5,
        "median_pred_length": 14.5,
        "min_pred_length": 11,
        "max_pred_length": 18,
        "distinct-1": 0.8275862068965517,
        "vocab_size-1": 24,
        "unique-1": 20,
        "entropy-1": 4.487122805397797,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.22116159970861762,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.88,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.373660689688184,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.17339652724591728,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78333,
            "recall": 0.84551,
            "fmeasure": 0.80486
        },
        "rouge2": {
            "precision": 0.63492,
            "recall": 0.69292,
            "fmeasure": 0.65465
        },
        "rougeL": {
            "precision": 0.65,
            "recall": 0.71997,
            "fmeasure": 0.67687
        },
        "rougeLsum": {
            "precision": 0.65,
            "recall": 0.71997,
            "fmeasure": 0.67687
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.125,
            "3": 0.9473684210526315
        },
        "nist": 4.266462805416016,
        "bleu": 58.12095,
        "bleurt": 0.39374,
        "nubia": {
            "semantic_relation": 3.89386,
            "contradiction": 0.42501,
            "irrelevancy": 1.517,
            "logical_agreement": 98.05799,
            "grammar_ref": 4.25678,
            "grammar_hyp": 3.70558,
            "nubia_score": 0.73821
        },
        "meteor": 0.4747333312051358,
        "bertscore": {
            "precision": 0.95991,
            "recall": 0.96271,
            "f1": 0.95914
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1188": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.2776134368191165,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.37857,
            "fmeasure": 0.46739
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.18407,
            "fmeasure": 0.2316
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.30952,
            "fmeasure": 0.38225
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.30952,
            "fmeasure": 0.38225
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.45454545454545453
        },
        "nist": 1.5661433161303462,
        "bleu": 19.0308,
        "bleurt": 0.08751,
        "nubia": {
            "semantic_relation": 3.83936,
            "contradiction": 84.66886,
            "irrelevancy": 11.39227,
            "logical_agreement": 3.93887,
            "grammar_ref": 4.95834,
            "grammar_hyp": 4.81091,
            "nubia_score": 0.52869
        },
        "meteor": 0.23020224675774723,
        "bertscore": {
            "precision": 0.91653,
            "recall": 0.87243,
            "f1": 0.89393
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1428": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5,
            "recall": 0.35714,
            "fmeasure": 0.41667
        },
        "rouge2": {
            "precision": 0.18519,
            "recall": 0.12821,
            "fmeasure": 0.15152
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.28571,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.28571,
            "fmeasure": 0.33333
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.2,
            "3": 0.5714285714285714
        },
        "nist": 2.110628108142053,
        "bleu": 8.6162,
        "bleurt": -0.18107,
        "nubia": {
            "semantic_relation": 3.11994,
            "contradiction": 0.26653,
            "irrelevancy": 99.39549,
            "logical_agreement": 0.33798,
            "grammar_ref": 3.90604,
            "grammar_hyp": 4.6,
            "nubia_score": 0.34857
        },
        "meteor": 0.24896456715295223,
        "bertscore": {
            "precision": 0.77945,
            "recall": 0.78365,
            "f1": 0.78155
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_952": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5,
            "recall": 0.38462,
            "fmeasure": 0.43478
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.2037,
            "fmeasure": 0.21164
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.38462,
            "fmeasure": 0.43478
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.38462,
            "fmeasure": 0.43478
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.42857142857142855
        },
        "nist": 1.3958920781800714,
        "bleu": 8.60612,
        "bleurt": -0.19069,
        "nubia": {
            "semantic_relation": 3.48593,
            "contradiction": 5.45948,
            "irrelevancy": 89.32513,
            "logical_agreement": 5.2154,
            "grammar_ref": 5.35395,
            "grammar_hyp": 4.57908,
            "nubia_score": 0.48361
        },
        "meteor": 0.23484797711253358,
        "bertscore": {
            "precision": 0.89235,
            "recall": 0.85571,
            "f1": 0.87365
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1098": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.875,
            "recall": 0.84259,
            "fmeasure": 0.85784
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.68452,
            "fmeasure": 0.69841
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.84259,
            "fmeasure": 0.85784
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.84259,
            "fmeasure": 0.85784
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.218725846082821,
        "bleu": 65.8037,
        "bleurt": 0.58344,
        "nubia": {
            "semantic_relation": 4.68121,
            "contradiction": 0.23407,
            "irrelevancy": 0.60193,
            "logical_agreement": 99.164,
            "grammar_ref": 5.1757,
            "grammar_hyp": 5.22369,
            "nubia_score": 0.89839
        },
        "meteor": 0.5312513743477362,
        "bertscore": {
            "precision": 0.98124,
            "recall": 0.97997,
            "f1": 0.97952
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1773": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.18182,
            "recall": 0.29167,
            "fmeasure": 0.22291
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.09091,
            "recall": 0.14583,
            "fmeasure": 0.11146
        },
        "rougeLsum": {
            "precision": 0.09091,
            "recall": 0.14583,
            "fmeasure": 0.11146
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.4
        },
        "nist": 0.637486607400413,
        "bleu": 3.73744,
        "bleurt": -0.84965,
        "nubia": {
            "semantic_relation": 2.18165,
            "contradiction": 16.02046,
            "irrelevancy": 83.55685,
            "logical_agreement": 0.42269,
            "grammar_ref": 7.18676,
            "grammar_hyp": 6.29309,
            "nubia_score": 0.15519
        },
        "meteor": 0.21689421138886908,
        "bertscore": {
            "precision": 0.66976,
            "recall": 0.77662,
            "f1": 0.71298
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1100": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.0,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 20,
        "distinct-1": 0.75,
        "vocab_size-1": 24,
        "unique-1": 19,
        "entropy-1": 4.413909765557392,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.4653868456806342,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.208966082694624,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.4765434499851152,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.57435,
            "recall": 0.52523,
            "fmeasure": 0.49087
        },
        "rouge2": {
            "precision": 0.32955,
            "recall": 0.48193,
            "fmeasure": 0.34922
        },
        "rougeL": {
            "precision": 0.40605,
            "recall": 0.51421,
            "fmeasure": 0.40125
        },
        "rougeLsum": {
            "precision": 0.40605,
            "recall": 0.51421,
            "fmeasure": 0.40125
        },
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.4,
            "3": 0.43478260869565216
        },
        "nist": 2.1733829996292884,
        "bleu": 29.02964,
        "bleurt": -0.01397,
        "nubia": {
            "semantic_relation": 3.47474,
            "contradiction": 17.35623,
            "irrelevancy": 82.2401,
            "logical_agreement": 0.40367,
            "grammar_ref": 4.39403,
            "grammar_hyp": 3.96549,
            "nubia_score": 0.49408
        },
        "meteor": 0.2274509735312662,
        "bertscore": {
            "precision": 0.85995,
            "recall": 0.82613,
            "f1": 0.83655
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1113": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 46,
        "mean_pred_length": 46.0,
        "std_pred_length": 0.0,
        "median_pred_length": 46.0,
        "min_pred_length": 46,
        "max_pred_length": 46,
        "distinct-1": 0.7608695652173914,
        "vocab_size-1": 35,
        "unique-1": 30,
        "entropy-1": 4.827909782143968,
        "distinct-2": 0.9777777777777777,
        "vocab_size-2": 44,
        "unique-2": 43,
        "entropy-2": 5.447408651885229,
        "cond_entropy-2": 0.6349578069393279,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": 0.013033067762168043,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 37.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 37.0,
        "min_pred_length-nopunct": 37,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.8918918918918919,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.993237149412737,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.1699250014423095,
        "cond_entropy-2-nopunct": 0.18269385803558488,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.04064198449734609,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77477,
            "recall": 0.88693,
            "fmeasure": 0.82689
        },
        "rouge2": {
            "precision": 0.71296,
            "recall": 0.81048,
            "fmeasure": 0.75856
        },
        "rougeL": {
            "precision": 0.77477,
            "recall": 0.87753,
            "fmeasure": 0.82291
        },
        "rougeLsum": {
            "precision": 0.77477,
            "recall": 0.87753,
            "fmeasure": 0.82291
        },
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.8888888888888888
        },
        "nist": 4.332861683639986,
        "bleu": 69.09679,
        "bleurt": 0.26391,
        "nubia": {
            "semantic_relation": 3.70901,
            "contradiction": 0.17757,
            "irrelevancy": 76.77281,
            "logical_agreement": 23.04962,
            "grammar_ref": 3.7645,
            "grammar_hyp": 3.18307,
            "nubia_score": 0.66879
        },
        "meteor": 0.5328769659485082,
        "bertscore": {
            "precision": 0.92906,
            "recall": 0.9644,
            "f1": 0.9464
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1122": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8,
            "recall": 0.51515,
            "fmeasure": 0.61364
        },
        "rouge2": {
            "precision": 0.27778,
            "recall": 0.18398,
            "fmeasure": 0.21667
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.32197,
            "fmeasure": 0.38352
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.32197,
            "fmeasure": 0.38352
        },
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.75
        },
        "nist": 1.9224678068947696,
        "bleu": 26.20062,
        "bleurt": 0.0375,
        "nubia": {
            "semantic_relation": 3.78235,
            "contradiction": 0.6822,
            "irrelevancy": 49.08349,
            "logical_agreement": 50.23431,
            "grammar_ref": 4.87259,
            "grammar_hyp": 5.74026,
            "nubia_score": 0.45191
        },
        "meteor": 0.3899344179774085,
        "bertscore": {
            "precision": 0.92821,
            "recall": 0.93037,
            "f1": 0.92929
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1782": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 3.9976702764876113,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.18615790478558616,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.9057645846554525,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.19723710464117222,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.525,
            "recall": 0.55749,
            "fmeasure": 0.53861
        },
        "rouge2": {
            "precision": 0.42105,
            "recall": 0.45536,
            "fmeasure": 0.43571
        },
        "rougeL": {
            "precision": 0.425,
            "recall": 0.46658,
            "fmeasure": 0.44337
        },
        "rougeLsum": {
            "precision": 0.425,
            "recall": 0.46658,
            "fmeasure": 0.44337
        },
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.8
        },
        "nist": 2.937883306955821,
        "bleu": 34.11488,
        "bleurt": -0.25645,
        "nubia": {
            "semantic_relation": 3.55937,
            "contradiction": 0.20054,
            "irrelevancy": 88.32634,
            "logical_agreement": 11.47311,
            "grammar_ref": 3.66593,
            "grammar_hyp": 3.09595,
            "nubia_score": 0.66121
        },
        "meteor": 0.4658104754303333,
        "bertscore": {
            "precision": 0.89272,
            "recall": 0.89785,
            "f1": 0.89528
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1369,
        "msttr-100": 0.72411,
        "msttr-100_nopunct": 0.77882,
        "total_length": 25352,
        "mean_pred_length": 18.51862673484295,
        "std_pred_length": 5.482276045059248,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 52,
        "distinct-1": 0.25181445250867784,
        "vocab_size-1": 6384,
        "unique-1": 4510,
        "entropy-1": 9.543020836689688,
        "distinct-2": 0.6589667681274236,
        "vocab_size-2": 15804,
        "unique-2": 13550,
        "entropy-2": 13.219121654236123,
        "cond_entropy-2": 3.3698296574875806,
        "distinct-3": 0.857345007517467,
        "vocab_size-3": 19388,
        "unique-3": 18041,
        "entropy-3": 14.020329466108404,
        "cond_entropy-3": 0.7984082000309671,
        "total_length-nopunct": 22098,
        "mean_pred_length-nopunct": 16.141709276844413,
        "std_pred_length-nopunct": 4.671729970855901,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.28821612815639425,
        "vocab_size-1-nopunct": 6369,
        "unique-1-nopunct": 4509,
        "entropy-1-nopunct": 10.020671764976434,
        "distinct-2-nopunct": 0.6993101452071977,
        "vocab_size-2-nopunct": 14496,
        "unique-2-nopunct": 12725,
        "entropy-2-nopunct": 13.145264159690441,
        "cond_entropy-2-nopunct": 3.258125314976645,
        "distinct-3-nopunct": 0.8791838842975207,
        "vocab_size-3-nopunct": 17021,
        "unique-3-nopunct": 16006,
        "entropy-3-nopunct": 13.870034421700893,
        "cond_entropy-3-nopunct": 0.7699038705852003,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7683,
            "recall": 0.74045,
            "fmeasure": 0.74356
        },
        "rouge2": {
            "precision": 0.52808,
            "recall": 0.51264,
            "fmeasure": 0.51282
        },
        "rougeL": {
            "precision": 0.64871,
            "recall": 0.62881,
            "fmeasure": 0.62947
        },
        "rougeLsum": {
            "precision": 0.64871,
            "recall": 0.62881,
            "fmeasure": 0.62947
        },
        "local_recall": {
            "1": 0.2267379679144385,
            "2": 0.4383093085756169,
            "3": 0.7798707963533177
        },
        "nist": 9.872018133032643,
        "bleu": 47.53137,
        "bleurt": 0.26503,
        "nubia": {
            "semantic_relation": 4.22811,
            "contradiction": 7.70981,
            "irrelevancy": 30.55602,
            "logical_agreement": 61.73417,
            "grammar_ref": 4.49662,
            "grammar_hyp": 4.45523,
            "nubia_score": 0.7405
        },
        "meteor": 0.4010682972260088,
        "bertscore": {
            "precision": 0.92926,
            "recall": 0.92589,
            "f1": 0.9259
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1441": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 50,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 4.642796092394706,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.64,
        "vocab_size-1": 32,
        "unique-1": 19,
        "entropy-1": 4.821467880199451,
        "distinct-2": 0.8297872340425532,
        "vocab_size-2": 39,
        "unique-2": 31,
        "entropy-2": 5.214163319762746,
        "cond_entropy-2": 0.3440204911922804,
        "distinct-3": 0.9090909090909091,
        "vocab_size-3": 40,
        "unique-3": 36,
        "entropy-3": 5.277613436819113,
        "cond_entropy-3": 0.08666094877784146,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 5.0990195135927845,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6444444444444445,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.683752474627444,
        "distinct-2-nopunct": 0.8095238095238095,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 5.01136504182638,
        "cond_entropy-2-nopunct": 0.3300500379184407,
        "distinct-3-nopunct": 0.8974358974358975,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 5.0802740137340425,
        "cond_entropy-3-nopunct": 0.07257197557066761,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73399,
            "recall": 0.72326,
            "fmeasure": 0.71051
        },
        "rouge2": {
            "precision": 0.57323,
            "recall": 0.5206,
            "fmeasure": 0.53406
        },
        "rougeL": {
            "precision": 0.5955,
            "recall": 0.55791,
            "fmeasure": 0.56327
        },
        "rougeLsum": {
            "precision": 0.5955,
            "recall": 0.55791,
            "fmeasure": 0.56327
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.5555555555555556,
            "3": 0.8888888888888888
        },
        "nist": 3.9606480404747626,
        "bleu": 42.86287,
        "bleurt": -0.1113,
        "nubia": {
            "semantic_relation": 3.99228,
            "contradiction": 0.93065,
            "irrelevancy": 59.68123,
            "logical_agreement": 39.38812,
            "grammar_ref": 4.27064,
            "grammar_hyp": 4.26311,
            "nubia_score": 0.67137
        },
        "meteor": 0.4089907829268962,
        "bertscore": {
            "precision": 0.92388,
            "recall": 0.91519,
            "f1": 0.9192
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1446": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.589898095464287,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.24009914803219046,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.4677201004745006,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2588453731729854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.62222,
            "recall": 1.0,
            "fmeasure": 0.76522
        },
        "rouge2": {
            "precision": 0.54762,
            "recall": 0.92593,
            "fmeasure": 0.68599
        },
        "rougeL": {
            "precision": 0.62222,
            "recall": 1.0,
            "fmeasure": 0.76522
        },
        "rougeLsum": {
            "precision": 0.62222,
            "recall": 1.0,
            "fmeasure": 0.76522
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7142857142857143
        },
        "nist": 1.989975000480771,
        "bleu": 18.39938,
        "bleurt": 0.38412,
        "nubia": {
            "semantic_relation": 4.35339,
            "contradiction": 0.0667,
            "irrelevancy": 43.24676,
            "logical_agreement": 56.68654,
            "grammar_ref": 3.90726,
            "grammar_hyp": 2.57984,
            "nubia_score": 0.86478
        },
        "meteor": 0.5153774504778692,
        "bertscore": {
            "precision": 0.89936,
            "recall": 0.95607,
            "f1": 0.9112
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1194": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.69697,
            "recall": 0.76667,
            "fmeasure": 0.73016
        },
        "rouge2": {
            "precision": 0.53333,
            "recall": 0.59259,
            "fmeasure": 0.5614
        },
        "rougeL": {
            "precision": 0.60606,
            "recall": 0.66667,
            "fmeasure": 0.63492
        },
        "rougeLsum": {
            "precision": 0.60606,
            "recall": 0.66667,
            "fmeasure": 0.63492
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.7142857142857143
        },
        "nist": 2.814253915463221,
        "bleu": 40.89601,
        "bleurt": 0.66299,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.24956,
            "irrelevancy": 0.43222,
            "logical_agreement": 99.31822,
            "grammar_ref": 4.16465,
            "grammar_hyp": 4.30116,
            "nubia_score": 0.9604
        },
        "meteor": 0.43541821690673427,
        "bertscore": {
            "precision": 0.93236,
            "recall": 0.95703,
            "f1": 0.94454
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 483,
        "msttr-100": 0.72846,
        "msttr-100_nopunct": 0.77846,
        "total_length": 10422,
        "mean_pred_length": 21.577639751552795,
        "std_pred_length": 5.673270754554736,
        "median_pred_length": 21.0,
        "min_pred_length": 10,
        "max_pred_length": 49,
        "distinct-1": 0.3167338322778737,
        "vocab_size-1": 3301,
        "unique-1": 2460,
        "entropy-1": 9.217919048814448,
        "distinct-2": 0.734782171244592,
        "vocab_size-2": 7303,
        "unique-2": 6395,
        "entropy-2": 12.359503145228084,
        "cond_entropy-2": 2.908301020284168,
        "distinct-3": 0.9128595600676819,
        "vocab_size-3": 8632,
        "unique-3": 8162,
        "entropy-3": 12.98327991786304,
        "cond_entropy-3": 0.6189534312874349,
        "total_length-nopunct": 9140,
        "mean_pred_length-nopunct": 18.923395445134574,
        "std_pred_length-nopunct": 5.082785796422942,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.3599562363238512,
        "vocab_size-1-nopunct": 3290,
        "unique-1-nopunct": 2459,
        "entropy-1-nopunct": 9.612264383218845,
        "distinct-2-nopunct": 0.7642370336144161,
        "vocab_size-2-nopunct": 6616,
        "unique-2-nopunct": 5918,
        "entropy-2-nopunct": 12.241676390975254,
        "cond_entropy-2-nopunct": 2.7284607677015624,
        "distinct-3-nopunct": 0.9229263518473207,
        "vocab_size-3-nopunct": 7544,
        "unique-3-nopunct": 7186,
        "entropy-3-nopunct": 12.797059481673456,
        "cond_entropy-3-nopunct": 0.5800012971789611,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75588,
            "recall": 0.73726,
            "fmeasure": 0.73654
        },
        "rouge2": {
            "precision": 0.50755,
            "recall": 0.49792,
            "fmeasure": 0.49602
        },
        "rougeL": {
            "precision": 0.61483,
            "recall": 0.60165,
            "fmeasure": 0.59988
        },
        "rougeLsum": {
            "precision": 0.61483,
            "recall": 0.60165,
            "fmeasure": 0.59988
        },
        "local_recall": {
            "1": 0.2309482257126236,
            "2": 0.40064516129032257,
            "3": 0.777729130180969
        },
        "nist": 8.879248431877807,
        "bleu": 43.2284,
        "bleurt": 0.2019,
        "nubia": {
            "semantic_relation": 4.16573,
            "contradiction": 8.58892,
            "irrelevancy": 35.1186,
            "logical_agreement": 56.29248,
            "grammar_ref": 4.32701,
            "grammar_hyp": 4.25042,
            "nubia_score": 0.72991
        },
        "meteor": 0.39084531924454874,
        "bertscore": {
            "precision": 0.92316,
            "recall": 0.92191,
            "f1": 0.92085
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1788": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966059,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76471,
            "recall": 0.76471,
            "fmeasure": 0.76471
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.375,
            "fmeasure": 0.375
        },
        "rougeL": {
            "precision": 0.64706,
            "recall": 0.64706,
            "fmeasure": 0.64706
        },
        "rougeLsum": {
            "precision": 0.64706,
            "recall": 0.64706,
            "fmeasure": 0.64706
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8
        },
        "nist": 3.2014976016543804,
        "bleu": 17.39639,
        "bleurt": 0.38272,
        "nubia": {
            "semantic_relation": 4.05715,
            "contradiction": 0.50886,
            "irrelevancy": 4.92633,
            "logical_agreement": 94.56481,
            "grammar_ref": 4.8802,
            "grammar_hyp": 5.04676,
            "nubia_score": 0.63346
        },
        "meteor": 0.3965217323441567,
        "bertscore": {
            "precision": 0.9519,
            "recall": 0.93318,
            "f1": 0.94245
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1470": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 55,
        "mean_pred_length": 13.75,
        "std_pred_length": 5.80409338312195,
        "median_pred_length": 15.5,
        "min_pred_length": 5,
        "max_pred_length": 19,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 45,
        "unique-1": 39,
        "entropy-1": 5.338368295768287,
        "distinct-2": 0.9803921568627451,
        "vocab_size-2": 50,
        "unique-2": 49,
        "entropy-2": 5.63320965569699,
        "cond_entropy-2": 0.1474737774086171,
        "distinct-3": 1.0,
        "vocab_size-3": 47,
        "unique-3": 47,
        "entropy-3": 5.55458885167764,
        "cond_entropy-3": -0.07528329880449633,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 5.244044240850758,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.319235677759422,
        "distinct-2-nopunct": 0.9772727272727273,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.41397707318275,
        "cond_entropy-2-nopunct": 0.11889837932894691,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.08750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.64924,
            "recall": 0.43237,
            "fmeasure": 0.48027
        },
        "rouge2": {
            "precision": 0.34249,
            "recall": 0.23961,
            "fmeasure": 0.26493
        },
        "rougeL": {
            "precision": 0.45152,
            "recall": 0.32626,
            "fmeasure": 0.36956
        },
        "rougeLsum": {
            "precision": 0.45152,
            "recall": 0.32626,
            "fmeasure": 0.36956
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.2962962962962963,
            "3": 0.5172413793103449
        },
        "nist": 2.1823131902562616,
        "bleu": 26.13003,
        "bleurt": -0.2566,
        "nubia": {
            "semantic_relation": 3.90748,
            "contradiction": 0.70201,
            "irrelevancy": 46.49357,
            "logical_agreement": 52.80443,
            "grammar_ref": 5.44243,
            "grammar_hyp": 5.99672,
            "nubia_score": 0.57357
        },
        "meteor": 0.21465105661874376,
        "bertscore": {
            "precision": 0.87731,
            "recall": 0.83858,
            "f1": 0.84875
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1792": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 1.0,
        "vocab_size-1": 20,
        "unique-1": 20,
        "entropy-1": 4.321928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.07400058144377676,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.72727,
            "fmeasure": 0.84211
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.55556,
            "fmeasure": 0.64815
        },
        "rougeL": {
            "precision": 0.8125,
            "recall": 0.59091,
            "fmeasure": 0.68421
        },
        "rougeLsum": {
            "precision": 0.8125,
            "recall": 0.59091,
            "fmeasure": 0.68421
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.75,
            "3": 0.8125
        },
        "nist": 4.15959450361753,
        "bleu": 53.53,
        "bleurt": -0.07153,
        "nubia": {
            "semantic_relation": 4.27554,
            "contradiction": 0.23421,
            "irrelevancy": 33.32769,
            "logical_agreement": 66.4381,
            "grammar_ref": 3.23206,
            "grammar_hyp": 3.37894,
            "nubia_score": 0.84017
        },
        "meteor": 0.3930022827856047,
        "bertscore": {
            "precision": 0.95416,
            "recall": 0.91645,
            "f1": 0.93492
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1128": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.40741,
            "recall": 0.29048,
            "fmeasure": 0.33715
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.08625,
            "fmeasure": 0.10192
        },
        "rougeL": {
            "precision": 0.40741,
            "recall": 0.29048,
            "fmeasure": 0.33715
        },
        "rougeLsum": {
            "precision": 0.40741,
            "recall": 0.29048,
            "fmeasure": 0.33715
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.2727272727272727,
            "3": 0.3333333333333333
        },
        "nist": 0.9346258422306595,
        "bleu": 7.68785,
        "bleurt": -0.05072,
        "nubia": {
            "semantic_relation": 2.72293,
            "contradiction": 68.91756,
            "irrelevancy": 23.34568,
            "logical_agreement": 7.73677,
            "grammar_ref": 4.72922,
            "grammar_hyp": 4.56459,
            "nubia_score": 0.25198
        },
        "meteor": 0.20497750744036802,
        "bertscore": {
            "precision": 0.85888,
            "recall": 0.83759,
            "f1": 0.84579
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1503": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.7647058823529411,
        "vocab_size-1": 13,
        "unique-1": 9,
        "entropy-1": 3.6168746059562227,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.4125371587496606,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.5,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.37355726227518526,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.60417,
            "recall": 0.54684,
            "fmeasure": 0.57398
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.18382,
            "fmeasure": 0.19153
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.37691,
            "fmeasure": 0.39572
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.37691,
            "fmeasure": 0.39572
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.5
        },
        "nist": 2.339402779945882,
        "bleu": 12.12709,
        "bleurt": -0.16825,
        "nubia": {
            "semantic_relation": 4.11881,
            "contradiction": 48.59402,
            "irrelevancy": 9.13844,
            "logical_agreement": 42.26754,
            "grammar_ref": 4.86284,
            "grammar_hyp": 4.69743,
            "nubia_score": 0.62795
        },
        "meteor": 0.2217638446950238,
        "bertscore": {
            "precision": 0.81548,
            "recall": 0.80507,
            "f1": 0.80869
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1800": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.85,
        "vocab_size-1": 17,
        "unique-1": 14,
        "entropy-1": 4.021928094887363,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 17,
        "unique-2": 16,
        "entropy-2": 4.058813890331201,
        "cond_entropy-2": -0.04089198233393866,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.04492500144231237,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.6644977792004623,
        "cond_entropy-2-nopunct": -0.04978793508525297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.055725754669781344,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80952,
            "recall": 0.40224,
            "fmeasure": 0.51989
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.19704,
            "fmeasure": 0.28687
        },
        "rougeL": {
            "precision": 0.63492,
            "recall": 0.29551,
            "fmeasure": 0.39066
        },
        "rougeLsum": {
            "precision": 0.63492,
            "recall": 0.29551,
            "fmeasure": 0.39066
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.46153846153846156
        },
        "nist": 0.7831015228554052,
        "bleu": 19.88772,
        "bleurt": -0.36344,
        "nubia": {
            "semantic_relation": 2.83515,
            "contradiction": 2.65013,
            "irrelevancy": 47.63545,
            "logical_agreement": 49.71442,
            "grammar_ref": 4.38763,
            "grammar_hyp": 4.67193,
            "nubia_score": 0.31509
        },
        "meteor": 0.22216489443841908,
        "bertscore": {
            "precision": 0.92144,
            "recall": 0.8458,
            "f1": 0.88086
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_960": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 50,
        "mean_pred_length": 12.5,
        "std_pred_length": 2.0615528128088303,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 14,
        "distinct-1": 0.68,
        "vocab_size-1": 34,
        "unique-1": 24,
        "entropy-1": 4.87656563024272,
        "distinct-2": 0.8913043478260869,
        "vocab_size-2": 41,
        "unique-2": 36,
        "entropy-2": 5.306170651709185,
        "cond_entropy-2": 0.3224128962083812,
        "distinct-3": 0.9285714285714286,
        "vocab_size-3": 39,
        "unique-3": 36,
        "entropy-3": 5.249460279921619,
        "cond_entropy-3": -0.03600643804015717,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 1.7320508075688772,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.7272727272727273,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.814783255532744,
        "distinct-2-nopunct": 0.9,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.121928094887363,
        "cond_entropy-2-nopunct": 0.34660967566507184,
        "distinct-3-nopunct": 0.9444444444444444,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.058813890331199,
        "cond_entropy-3-nopunct": -0.0686697601117164,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.775,
            "recall": 0.79078,
            "fmeasure": 0.77478
        },
        "rouge2": {
            "precision": 0.68855,
            "recall": 0.7125,
            "fmeasure": 0.67909
        },
        "rougeL": {
            "precision": 0.775,
            "recall": 0.79078,
            "fmeasure": 0.77478
        },
        "rougeLsum": {
            "precision": 0.775,
            "recall": 0.79078,
            "fmeasure": 0.77478
        },
        "local_recall": {
            "1": 0.3,
            "2": 0.16666666666666666,
            "3": 0.8055555555555556
        },
        "nist": 4.490058645344504,
        "bleu": 62.54126,
        "bleurt": 0.38956,
        "nubia": {
            "semantic_relation": 4.45791,
            "contradiction": 2.69328,
            "irrelevancy": 52.25345,
            "logical_agreement": 45.05327,
            "grammar_ref": 4.5734,
            "grammar_hyp": 4.45293,
            "nubia_score": 0.78471
        },
        "meteor": 0.48376019174453083,
        "bertscore": {
            "precision": 0.94653,
            "recall": 0.96587,
            "f1": 0.95445
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1135": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.64912,
            "recall": 0.78611,
            "fmeasure": 0.71092
        },
        "rouge2": {
            "precision": 0.40741,
            "recall": 0.46667,
            "fmeasure": 0.43434
        },
        "rougeL": {
            "precision": 0.54386,
            "recall": 0.65833,
            "fmeasure": 0.59552
        },
        "rougeLsum": {
            "precision": 0.54386,
            "recall": 0.65833,
            "fmeasure": 0.59552
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 1.0,
            "3": 0.8181818181818182
        },
        "nist": 3.640381355301299,
        "bleu": 31.32768,
        "bleurt": 0.16418,
        "nubia": {
            "semantic_relation": 3.99398,
            "contradiction": 5.79899,
            "irrelevancy": 24.6286,
            "logical_agreement": 69.5724,
            "grammar_ref": 5.46955,
            "grammar_hyp": 4.00886,
            "nubia_score": 0.77025
        },
        "meteor": 0.37085879405872496,
        "bertscore": {
            "precision": 0.90449,
            "recall": 0.91572,
            "f1": 0.91007
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1140": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.96154,
            "recall": 0.92857,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.84295,
            "fmeasure": 0.85833
        },
        "rougeL": {
            "precision": 0.80769,
            "recall": 0.78022,
            "fmeasure": 0.79345
        },
        "rougeLsum": {
            "precision": 0.80769,
            "recall": 0.78022,
            "fmeasure": 0.79345
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "nist": 3.8535769082186824,
        "bleu": 76.74162,
        "bleurt": 0.39021,
        "nubia": {
            "semantic_relation": 3.73103,
            "contradiction": 47.93643,
            "irrelevancy": 1.84919,
            "logical_agreement": 50.21438,
            "grammar_ref": 2.33019,
            "grammar_hyp": 2.4164,
            "nubia_score": 0.6985
        },
        "meteor": 0.5426177315437225,
        "bertscore": {
            "precision": 0.9822,
            "recall": 0.97494,
            "f1": 0.97856
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1552": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74359,
            "recall": 0.85606,
            "fmeasure": 0.79556
        },
        "rouge2": {
            "precision": 0.61111,
            "recall": 0.71515,
            "fmeasure": 0.65876
        },
        "rougeL": {
            "precision": 0.74359,
            "recall": 0.85606,
            "fmeasure": 0.79556
        },
        "rougeLsum": {
            "precision": 0.74359,
            "recall": 0.85606,
            "fmeasure": 0.79556
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.875
        },
        "nist": 3.668906062536221,
        "bleu": 56.3756,
        "bleurt": 0.49448,
        "nubia": {
            "semantic_relation": 4.78062,
            "contradiction": 0.18549,
            "irrelevancy": 2.52911,
            "logical_agreement": 97.28539,
            "grammar_ref": 6.27756,
            "grammar_hyp": 6.12631,
            "nubia_score": 0.87631
        },
        "meteor": 0.4816573593726147,
        "bertscore": {
            "precision": 0.95874,
            "recall": 0.98132,
            "f1": 0.9699
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1206": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 19.5,
        "std_pred_length": 0.5,
        "median_pred_length": 19.5,
        "min_pred_length": 19,
        "max_pred_length": 20,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 30,
        "unique-1": 23,
        "entropy-1": 4.785151577725659,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.3972883090458075,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": -0.08017034868398329,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7575757575757576,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.513794876803093,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.4423755782647747,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.09621531525930291,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85539,
            "recall": 0.68148,
            "fmeasure": 0.74093
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.46016,
            "fmeasure": 0.48737
        },
        "rougeL": {
            "precision": 0.73223,
            "recall": 0.60185,
            "fmeasure": 0.64625
        },
        "rougeLsum": {
            "precision": 0.73223,
            "recall": 0.60185,
            "fmeasure": 0.64625
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855,
            "3": 0.7
        },
        "nist": 3.7894224672514945,
        "bleu": 39.99598,
        "bleurt": 0.05884,
        "nubia": {
            "semantic_relation": 4.2504,
            "contradiction": 2.0712,
            "irrelevancy": 52.24194,
            "logical_agreement": 45.68686,
            "grammar_ref": 4.16263,
            "grammar_hyp": 4.21577,
            "nubia_score": 0.71005
        },
        "meteor": 0.31136088872423945,
        "bertscore": {
            "precision": 0.92489,
            "recall": 0.88851,
            "f1": 0.90309
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_966": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.92857,
            "recall": 0.92857,
            "fmeasure": 0.92857
        },
        "rouge2": {
            "precision": 0.84615,
            "recall": 0.84615,
            "fmeasure": 0.84615
        },
        "rougeL": {
            "precision": 0.92857,
            "recall": 0.92857,
            "fmeasure": 0.92857
        },
        "rougeLsum": {
            "precision": 0.92857,
            "recall": 0.92857,
            "fmeasure": 0.92857
        },
        "local_recall": {
            "1": 0,
            "2": 0.8,
            "3": 1.0
        },
        "nist": 3.4160855200757196,
        "bleu": 74.4782,
        "bleurt": 0.6574,
        "nubia": {
            "semantic_relation": 4.56461,
            "contradiction": 0.29772,
            "irrelevancy": 34.06963,
            "logical_agreement": 65.63266,
            "grammar_ref": 6.35753,
            "grammar_hyp": 6.2037,
            "nubia_score": 0.84079
        },
        "meteor": 0.5370438479273406,
        "bertscore": {
            "precision": 0.96662,
            "recall": 0.99259,
            "f1": 0.97906
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1809": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.640223928941851,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.18617861216337128,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.52778,
            "recall": 0.5,
            "fmeasure": 0.49864
        },
        "rouge2": {
            "precision": 0.17647,
            "recall": 0.17094,
            "fmeasure": 0.16818
        },
        "rougeL": {
            "precision": 0.52778,
            "recall": 0.5,
            "fmeasure": 0.49864
        },
        "rougeLsum": {
            "precision": 0.52778,
            "recall": 0.5,
            "fmeasure": 0.49864
        },
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.5555555555555556
        },
        "nist": 1.7818352863740805,
        "bleu": 11.30608,
        "bleurt": -0.08881,
        "nubia": {
            "semantic_relation": 2.89307,
            "contradiction": 22.12057,
            "irrelevancy": 50.66423,
            "logical_agreement": 27.2152,
            "grammar_ref": 3.10421,
            "grammar_hyp": 2.7021,
            "nubia_score": 0.41723
        },
        "meteor": 0.3080780458159505,
        "bertscore": {
            "precision": 0.84714,
            "recall": 0.89642,
            "f1": 0.86839
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1141": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.62963,
            "recall": 0.48485,
            "fmeasure": 0.54762
        },
        "rouge2": {
            "precision": 0.29167,
            "recall": 0.21515,
            "fmeasure": 0.24756
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.38889,
            "fmeasure": 0.45635
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.38889,
            "fmeasure": 0.45635
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.5
        },
        "nist": 2.038944894698677,
        "bleu": 22.35234,
        "bleurt": 0.05805,
        "nubia": {
            "semantic_relation": 3.91397,
            "contradiction": 0.94826,
            "irrelevancy": 45.28218,
            "logical_agreement": 53.76955,
            "grammar_ref": 4.53537,
            "grammar_hyp": 4.57978,
            "nubia_score": 0.61473
        },
        "meteor": 0.24545494528992856,
        "bertscore": {
            "precision": 0.8988,
            "recall": 0.87691,
            "f1": 0.88772
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1210": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.029610672108601997,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.76912,
            "fmeasure": 0.79985
        },
        "rouge2": {
            "precision": 0.68421,
            "recall": 0.63968,
            "fmeasure": 0.66111
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.6555,
            "fmeasure": 0.67643
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.6555,
            "fmeasure": 0.67643
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.6666666666666666,
            "3": 0.7857142857142857
        },
        "nist": 4.588629133630698,
        "bleu": 67.12403,
        "bleurt": 0.59402,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.18639,
            "irrelevancy": 0.97385,
            "logical_agreement": 98.83976,
            "grammar_ref": 3.4928,
            "grammar_hyp": 3.55096,
            "nubia_score": 0.9949
        },
        "meteor": 0.5414471790768619,
        "bertscore": {
            "precision": 0.97283,
            "recall": 0.96134,
            "f1": 0.96705
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_968": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.037537158749660585,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185189,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70833,
            "recall": 0.60529,
            "fmeasure": 0.64957
        },
        "rouge2": {
            "precision": 0.42222,
            "recall": 0.35606,
            "fmeasure": 0.38419
        },
        "rougeL": {
            "precision": 0.6875,
            "recall": 0.47826,
            "fmeasure": 0.5641
        },
        "rougeLsum": {
            "precision": 0.6875,
            "recall": 0.47826,
            "fmeasure": 0.5641
        },
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333,
            "3": 0.6875
        },
        "nist": 2.6343507046521233,
        "bleu": 32.75571,
        "bleurt": 0.23196,
        "nubia": {
            "semantic_relation": 3.62043,
            "contradiction": 16.13259,
            "irrelevancy": 34.92942,
            "logical_agreement": 48.93798,
            "grammar_ref": 4.20692,
            "grammar_hyp": 4.45193,
            "nubia_score": 0.49465
        },
        "meteor": 0.39484629594925474,
        "bertscore": {
            "precision": 0.93547,
            "recall": 0.92543,
            "f1": 0.9278
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1560": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 4.0,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 19,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 20,
        "unique-1": 12,
        "entropy-1": 4.1898980954642875,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": 0.5972420051750476,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6923076923076923,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.026986833359286,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.5724300744270198,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75,
            "recall": 0.80439,
            "fmeasure": 0.73741
        },
        "rouge2": {
            "precision": 0.52632,
            "recall": 0.5923,
            "fmeasure": 0.52359
        },
        "rougeL": {
            "precision": 0.65,
            "recall": 0.76681,
            "fmeasure": 0.65275
        },
        "rougeLsum": {
            "precision": 0.65,
            "recall": 0.76681,
            "fmeasure": 0.65275
        },
        "local_recall": {
            "1": 0.75,
            "2": 0.25,
            "3": 0.9333333333333333
        },
        "nist": 3.275350245151707,
        "bleu": 32.06933,
        "bleurt": 0.13554,
        "nubia": {
            "semantic_relation": 3.76883,
            "contradiction": 32.54342,
            "irrelevancy": 17.74578,
            "logical_agreement": 49.7108,
            "grammar_ref": 4.07172,
            "grammar_hyp": 4.63596,
            "nubia_score": 0.55248
        },
        "meteor": 0.44928793943118667,
        "bertscore": {
            "precision": 0.89126,
            "recall": 0.96208,
            "f1": 0.91577
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1820": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5,
            "recall": 0.42222,
            "fmeasure": 0.44928
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.2381,
            "fmeasure": 0.25397
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.42222,
            "fmeasure": 0.44928
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.42222,
            "fmeasure": 0.44928
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "nist": 1.2423647907303101,
        "bleu": 11.20847,
        "bleurt": -0.86993,
        "nubia": {
            "semantic_relation": 3.2947,
            "contradiction": 0.28776,
            "irrelevancy": 95.16334,
            "logical_agreement": 4.5489,
            "grammar_ref": 4.70243,
            "grammar_hyp": 5.65085,
            "nubia_score": 0.34871
        },
        "meteor": 0.23666615119469175,
        "bertscore": {
            "precision": 0.82872,
            "recall": 0.77681,
            "f1": 0.7872
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1216": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518525,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.46551,
            "fmeasure": 0.60039
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.13258,
            "fmeasure": 0.1732
        },
        "rougeL": {
            "precision": 0.38462,
            "recall": 0.21159,
            "fmeasure": 0.2729
        },
        "rougeLsum": {
            "precision": 0.38462,
            "recall": 0.21159,
            "fmeasure": 0.2729
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.6363636363636364,
            "3": 0.2222222222222222
        },
        "nist": 2.181137292231572,
        "bleu": 12.39211,
        "bleurt": -0.78594,
        "nubia": {
            "semantic_relation": 2.61876,
            "contradiction": 25.00003,
            "irrelevancy": 32.08231,
            "logical_agreement": 42.91766,
            "grammar_ref": 3.96534,
            "grammar_hyp": 4.65853,
            "nubia_score": 0.22875
        },
        "meteor": 0.26138328227636665,
        "bertscore": {
            "precision": 0.91389,
            "recall": 0.84161,
            "f1": 0.87626
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1260": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 2.5,
        "median_pred_length": 16.5,
        "min_pred_length": 14,
        "max_pred_length": 19,
        "distinct-1": 0.7575757575757576,
        "vocab_size-1": 25,
        "unique-1": 19,
        "entropy-1": 4.513794876803093,
        "distinct-2": 0.967741935483871,
        "vocab_size-2": 30,
        "unique-2": 29,
        "entropy-2": 4.889680181354619,
        "cond_entropy-2": 0.3456013847163876,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.02724979801792366,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7741935483870968,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.453880987666651,
        "distinct-2-nopunct": 0.9655172413793104,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.789015477886192,
        "cond_entropy-2-nopunct": 0.3696389952347294,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.029019418890029347,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88526,
            "recall": 0.65858,
            "fmeasure": 0.74706
        },
        "rouge2": {
            "precision": 0.60307,
            "recall": 0.46833,
            "fmeasure": 0.52439
        },
        "rougeL": {
            "precision": 0.66923,
            "recall": 0.50948,
            "fmeasure": 0.57346
        },
        "rougeLsum": {
            "precision": 0.66923,
            "recall": 0.50948,
            "fmeasure": 0.57346
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.23529411764705882,
            "3": 0.7857142857142857
        },
        "nist": 2.6893095937734355,
        "bleu": 40.64558,
        "bleurt": 0.3213,
        "nubia": {
            "semantic_relation": 4.09855,
            "contradiction": 0.11434,
            "irrelevancy": 0.98852,
            "logical_agreement": 98.89714,
            "grammar_ref": 3.63495,
            "grammar_hyp": 4.1114,
            "nubia_score": 0.70383
        },
        "meteor": 0.3820901599241051,
        "bertscore": {
            "precision": 0.94537,
            "recall": 0.91541,
            "f1": 0.92982
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1272": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.8125,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.577819531114783,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 14,
        "unique-2": 13,
        "entropy-2": 3.773557262275185,
        "cond_entropy-2": 0.2238830957527498,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": 0.043321469306228495,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3248629576173574,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.5465935642949384,
        "cond_entropy-2-nopunct": 0.2588453731729854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": 0.05118944924673077,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.46667,
            "recall": 0.46875,
            "fmeasure": 0.46719
        },
        "rouge2": {
            "precision": 0.21429,
            "recall": 0.21538,
            "fmeasure": 0.21456
        },
        "rougeL": {
            "precision": 0.46667,
            "recall": 0.46875,
            "fmeasure": 0.46719
        },
        "rougeLsum": {
            "precision": 0.46667,
            "recall": 0.46875,
            "fmeasure": 0.46719
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.375
        },
        "nist": 2.0367354245926177,
        "bleu": 14.24779,
        "bleurt": 0.46436,
        "nubia": {
            "semantic_relation": 3.42731,
            "contradiction": 81.98752,
            "irrelevancy": 8.31471,
            "logical_agreement": 9.69776,
            "grammar_ref": 3.06207,
            "grammar_hyp": 2.84247,
            "nubia_score": 0.63889
        },
        "meteor": 0.3220235645695511,
        "bertscore": {
            "precision": 0.90588,
            "recall": 0.91471,
            "f1": 0.91027
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_972": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.03126257645096008,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75,
            "recall": 0.76441,
            "fmeasure": 0.75672
        },
        "rouge2": {
            "precision": 0.40351,
            "recall": 0.45185,
            "fmeasure": 0.42554
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.6817,
            "fmeasure": 0.67375
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.6817,
            "fmeasure": 0.67375
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7857142857142857
        },
        "nist": 3.7353277958458637,
        "bleu": 36.3349,
        "bleurt": 0.38284,
        "nubia": {
            "semantic_relation": 4.20369,
            "contradiction": 0.15483,
            "irrelevancy": 33.56026,
            "logical_agreement": 66.28492,
            "grammar_ref": 4.42639,
            "grammar_hyp": 4.05232,
            "nubia_score": 0.81135
        },
        "meteor": 0.3954855875922128,
        "bertscore": {
            "precision": 0.93986,
            "recall": 0.94396,
            "f1": 0.94191
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1824": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 29.0,
        "std_pred_length": 0.0,
        "median_pred_length": 29.0,
        "min_pred_length": 29,
        "max_pred_length": 29,
        "distinct-1": 0.7241379310344828,
        "vocab_size-1": 21,
        "unique-1": 16,
        "entropy-1": 4.21126073643228,
        "distinct-2": 0.9285714285714286,
        "vocab_size-2": 26,
        "unique-2": 24,
        "entropy-2": 4.664497779200463,
        "cond_entropy-2": 0.4049056234358702,
        "distinct-3": 0.9629629629629629,
        "vocab_size-3": 26,
        "unique-3": 25,
        "entropy-3": 4.6808134280893965,
        "cond_entropy-3": 0.02160665417993861,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 3.9976702764876113,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.1861579047855862,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.47368,
            "recall": 0.46053,
            "fmeasure": 0.46694
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.24269,
            "fmeasure": 0.24625
        },
        "rougeL": {
            "precision": 0.39474,
            "recall": 0.38421,
            "fmeasure": 0.38934
        },
        "rougeLsum": {
            "precision": 0.39474,
            "recall": 0.38421,
            "fmeasure": 0.38934
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.5
        },
        "nist": 2.672501786010112,
        "bleu": 30.95827,
        "bleurt": -0.43983,
        "nubia": {
            "semantic_relation": 3.29852,
            "contradiction": 0.64357,
            "irrelevancy": 98.97469,
            "logical_agreement": 0.38174,
            "grammar_ref": 4.38153,
            "grammar_hyp": 4.23398,
            "nubia_score": 0.48289
        },
        "meteor": 0.31727015014979887,
        "bertscore": {
            "precision": 0.89262,
            "recall": 0.85568,
            "f1": 0.87376
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1296": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966059,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.64583,
            "recall": 0.71652,
            "fmeasure": 0.67546
        },
        "rouge2": {
            "precision": 0.35556,
            "recall": 0.34641,
            "fmeasure": 0.34877
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.64672,
            "fmeasure": 0.60987
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.64672,
            "fmeasure": 0.60987
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.6666666666666666,
            "3": 0.7777777777777778
        },
        "nist": 3.1078173715833577,
        "bleu": 25.77229,
        "bleurt": 0.10519,
        "nubia": {
            "semantic_relation": 3.53238,
            "contradiction": 25.21487,
            "irrelevancy": 50.71032,
            "logical_agreement": 24.07482,
            "grammar_ref": 5.3293,
            "grammar_hyp": 5.06308,
            "nubia_score": 0.48726
        },
        "meteor": 0.3491455946868221,
        "bertscore": {
            "precision": 0.9449,
            "recall": 0.9579,
            "f1": 0.94892
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1152": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.375,
            "recall": 0.33333,
            "fmeasure": 0.35294
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.125,
            "fmeasure": 0.13333
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.33333,
            "fmeasure": 0.35294
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.33333,
            "fmeasure": 0.35294
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.3333333333333333
        },
        "nist": 1.3464372969835736,
        "bleu": 10.2292,
        "bleurt": 0.38618,
        "nubia": {
            "semantic_relation": 4.57579,
            "contradiction": 0.1875,
            "irrelevancy": 0.53519,
            "logical_agreement": 99.2773,
            "grammar_ref": 3.99081,
            "grammar_hyp": 4.08566,
            "nubia_score": 0.95189
        },
        "meteor": 0.21640749237103607,
        "bertscore": {
            "precision": 0.87326,
            "recall": 0.84855,
            "f1": 0.86073
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1836": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 24,
        "unique-1": 22,
        "entropy-1": 4.546593564294937,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.10341647163363246,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.9565217391304348,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.436605434317882,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.026778753489375362,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.59722,
            "recall": 0.59697,
            "fmeasure": 0.59657
        },
        "rouge2": {
            "precision": 0.2029,
            "recall": 0.20238,
            "fmeasure": 0.20245
        },
        "rougeL": {
            "precision": 0.20833,
            "recall": 0.21818,
            "fmeasure": 0.21295
        },
        "rougeLsum": {
            "precision": 0.20833,
            "recall": 0.21818,
            "fmeasure": 0.21295
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.5789473684210527
        },
        "nist": 3.115359922401174,
        "bleu": 6.71333,
        "bleurt": -0.13244,
        "nubia": {
            "semantic_relation": 3.63993,
            "contradiction": 0.31796,
            "irrelevancy": 90.15308,
            "logical_agreement": 9.52895,
            "grammar_ref": 4.82125,
            "grammar_hyp": 4.11758,
            "nubia_score": 0.62029
        },
        "meteor": 0.25171228879348617,
        "bertscore": {
            "precision": 0.86332,
            "recall": 0.83624,
            "f1": 0.84957
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1573": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.42803,
            "fmeasure": 0.37302
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.14286,
            "fmeasure": 0.10526
        },
        "rougeL": {
            "precision": 0.28205,
            "recall": 0.36742,
            "fmeasure": 0.31746
        },
        "rougeLsum": {
            "precision": 0.28205,
            "recall": 0.36742,
            "fmeasure": 0.31746
        },
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.14285714285714285
        },
        "nist": 0.8250533418130888,
        "bleu": 3.73744,
        "bleurt": -1.15373,
        "nubia": {
            "semantic_relation": 1.96443,
            "contradiction": 0.42721,
            "irrelevancy": 98.62987,
            "logical_agreement": 0.94293,
            "grammar_ref": 5.51883,
            "grammar_hyp": 5.27726,
            "nubia_score": 0.1558
        },
        "meteor": 0.11700182815356491,
        "bertscore": {
            "precision": 0.74491,
            "recall": 0.74448,
            "f1": 0.74469
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_976": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78571,
            "recall": 0.60039,
            "fmeasure": 0.68056
        },
        "rouge2": {
            "precision": 0.53846,
            "recall": 0.40414,
            "fmeasure": 0.46165
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.54581,
            "fmeasure": 0.61869
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.54581,
            "fmeasure": 0.61869
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6
        },
        "nist": 2.23788198421141,
        "bleu": 26.83805,
        "bleurt": 0.5007,
        "nubia": {
            "semantic_relation": 3.52698,
            "contradiction": 2.09315,
            "irrelevancy": 4.01221,
            "logical_agreement": 93.89464,
            "grammar_ref": 3.47563,
            "grammar_hyp": 4.39002,
            "nubia_score": 0.48343
        },
        "meteor": 0.34719988275275565,
        "bertscore": {
            "precision": 0.91022,
            "recall": 0.90002,
            "f1": 0.90509
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1155": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.8125,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.577819531114783,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 14,
        "unique-2": 13,
        "entropy-2": 3.7735572622751845,
        "cond_entropy-2": 0.22388309575274978,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": 0.04332146930622849,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3248629576173574,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.5465935642949384,
        "cond_entropy-2-nopunct": 0.2588453731729854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": 0.05118944924673077,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.90196,
            "recall": 0.93856,
            "fmeasure": 0.91912
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.86905,
            "fmeasure": 0.85
        },
        "rougeL": {
            "precision": 0.90196,
            "recall": 0.93856,
            "fmeasure": 0.91912
        },
        "rougeLsum": {
            "precision": 0.90196,
            "recall": 0.93856,
            "fmeasure": 0.91912
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.7
        },
        "nist": 3.7823328563833676,
        "bleu": 61.28081,
        "bleurt": 0.79797,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.1702,
            "irrelevancy": 1.29006,
            "logical_agreement": 98.53974,
            "grammar_ref": 3.50326,
            "grammar_hyp": 3.19652,
            "nubia_score": 1.0
        },
        "meteor": 0.9804878048780489,
        "bertscore": {
            "precision": 0.98668,
            "recall": 0.99313,
            "f1": 0.9899
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_980": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.11251249881411757,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.02961067210860197,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71212,
            "recall": 0.61758,
            "fmeasure": 0.65828
        },
        "rouge2": {
            "precision": 0.39683,
            "recall": 0.34242,
            "fmeasure": 0.36571
        },
        "rougeL": {
            "precision": 0.56061,
            "recall": 0.40179,
            "fmeasure": 0.46807
        },
        "rougeLsum": {
            "precision": 0.56061,
            "recall": 0.40179,
            "fmeasure": 0.46807
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.4444444444444444,
            "3": 0.6111111111111112
        },
        "nist": 3.0384206242129017,
        "bleu": 38.03824,
        "bleurt": 0.01435,
        "nubia": {
            "semantic_relation": 4.47193,
            "contradiction": 0.9327,
            "irrelevancy": 25.89617,
            "logical_agreement": 73.17113,
            "grammar_ref": 3.59602,
            "grammar_hyp": 4.16138,
            "nubia_score": 0.75965
        },
        "meteor": 0.34075531102854,
        "bertscore": {
            "precision": 0.92184,
            "recall": 0.89557,
            "f1": 0.90669
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1582": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 4.0,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 24,
        "unique-1": 22,
        "entropy-1": 4.546593564294937,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": -0.03214388408660256,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9545454545454546,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.368522527728204,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": -0.037503523749935014,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.8303,
            "fmeasure": 0.90381
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.61429,
            "fmeasure": 0.65795
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.73939,
            "fmeasure": 0.79855
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.73939,
            "fmeasure": 0.79855
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8461538461538461
        },
        "nist": 4.233710489746673,
        "bleu": 64.38619,
        "bleurt": 0.59043,
        "nubia": {
            "semantic_relation": 4.753,
            "contradiction": 0.20074,
            "irrelevancy": 0.45592,
            "logical_agreement": 99.34334,
            "grammar_ref": 3.76682,
            "grammar_hyp": 4.75947,
            "nubia_score": 0.84541
        },
        "meteor": 0.4737742843457279,
        "bertscore": {
            "precision": 0.97297,
            "recall": 0.94453,
            "f1": 0.95847
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1302": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.16253715874966052,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.17355726227518528,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8125,
            "recall": 0.5216,
            "fmeasure": 0.63488
        },
        "rouge2": {
            "precision": 0.53333,
            "recall": 0.33445,
            "fmeasure": 0.41078
        },
        "rougeL": {
            "precision": 0.6875,
            "recall": 0.48611,
            "fmeasure": 0.5693
        },
        "rougeLsum": {
            "precision": 0.6875,
            "recall": 0.48611,
            "fmeasure": 0.5693
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.4444444444444444
        },
        "nist": 1.7512922410496652,
        "bleu": 20.06086,
        "bleurt": -0.36542,
        "nubia": {
            "semantic_relation": 3.98875,
            "contradiction": 0.931,
            "irrelevancy": 43.71435,
            "logical_agreement": 55.35464,
            "grammar_ref": 3.86337,
            "grammar_hyp": 4.29992,
            "nubia_score": 0.60938
        },
        "meteor": 0.2938308140290156,
        "bertscore": {
            "precision": 0.90549,
            "recall": 0.88355,
            "f1": 0.89358
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1840": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.0,
        "bleu": 100.0,
        "bleurt": 1.00232,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.55079,
            "irrelevancy": 0.53693,
            "logical_agreement": 98.91228,
            "grammar_ref": 4.38626,
            "grammar_hyp": 4.38626,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1638": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432272,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78788,
            "recall": 0.8963,
            "fmeasure": 0.8381
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.75,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.88889,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.88889,
            "fmeasure": 0.8
        },
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "nist": 2.659005565642719,
        "bleu": 32.64971,
        "bleurt": 0.74939,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.4082,
            "irrelevancy": 0.76883,
            "logical_agreement": 98.82297,
            "grammar_ref": 4.6206,
            "grammar_hyp": 4.37368,
            "nubia_score": 0.96322
        },
        "meteor": 0.9051319272478866,
        "bertscore": {
            "precision": 0.94619,
            "recall": 0.97387,
            "f1": 0.95983
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1304": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.75,
        "vocab_size-1": 18,
        "unique-1": 12,
        "entropy-1": 4.084962500721156,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 22,
        "unique-2": 21,
        "entropy-2": 4.436605434317882,
        "cond_entropy-2": 0.373382064031509,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": 0.026778753489375355,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7894736842105263,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.8268748818646365,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.36644193244317125,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.87619,
            "fmeasure": 0.71567
        },
        "rouge2": {
            "precision": 0.49275,
            "recall": 0.7381,
            "fmeasure": 0.58747
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.84444,
            "fmeasure": 0.68604
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.84444,
            "fmeasure": 0.68604
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.2,
            "3": 0.8
        },
        "nist": 2.19090554471602,
        "bleu": 15.41506,
        "bleurt": -0.11646,
        "nubia": {
            "semantic_relation": 3.61949,
            "contradiction": 0.757,
            "irrelevancy": 19.78819,
            "logical_agreement": 79.45481,
            "grammar_ref": 3.44293,
            "grammar_hyp": 3.24728,
            "nubia_score": 0.68183
        },
        "meteor": 0.39368905951794103,
        "bertscore": {
            "precision": 0.81838,
            "recall": 0.9622,
            "f1": 0.88119
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1928": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.96078,
            "recall": 0.93651,
            "fmeasure": 0.94471
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.81111,
            "fmeasure": 0.8184
        },
        "rougeL": {
            "precision": 0.72549,
            "recall": 0.70635,
            "fmeasure": 0.71292
        },
        "rougeLsum": {
            "precision": 0.72549,
            "recall": 0.70635,
            "fmeasure": 0.71292
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.6666666666666666,
            "3": 0.8888888888888888
        },
        "nist": 3.610049812198351,
        "bleu": 51.18285,
        "bleurt": -0.25179,
        "nubia": {
            "semantic_relation": 4.15871,
            "contradiction": 1.55874,
            "irrelevancy": 55.14643,
            "logical_agreement": 43.29483,
            "grammar_ref": 3.89472,
            "grammar_hyp": 5.30972,
            "nubia_score": 0.56051
        },
        "meteor": 0.4725225802439666,
        "bertscore": {
            "precision": 0.91093,
            "recall": 0.94,
            "f1": 0.92364
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1936": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 9.5,
        "std_pred_length": 0.5,
        "median_pred_length": 9.5,
        "min_pred_length": 9,
        "max_pred_length": 10,
        "distinct-1": 0.6842105263157895,
        "vocab_size-1": 13,
        "unique-1": 7,
        "entropy-1": 3.6163485660751635,
        "distinct-2": 0.9411764705882353,
        "vocab_size-2": 16,
        "unique-2": 15,
        "entropy-2": 3.969815782426811,
        "cond_entropy-2": 0.3101235631008714,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.0472389123084875,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.7058823529411765,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.4992275471326932,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.773557262275185,
        "cond_entropy-2-nopunct": 0.28609442102484584,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.05260472362127269,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78889,
            "recall": 0.54398,
            "fmeasure": 0.63672
        },
        "rouge2": {
            "precision": 0.46528,
            "recall": 0.32335,
            "fmeasure": 0.37696
        },
        "rougeL": {
            "precision": 0.78889,
            "recall": 0.54398,
            "fmeasure": 0.63672
        },
        "rougeLsum": {
            "precision": 0.78889,
            "recall": 0.54398,
            "fmeasure": 0.63672
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.45454545454545453
        },
        "nist": 1.3504960403922237,
        "bleu": 10.78671,
        "bleurt": 0.46295,
        "nubia": {
            "semantic_relation": 4.18597,
            "contradiction": 0.44745,
            "irrelevancy": 1.44862,
            "logical_agreement": 98.10393,
            "grammar_ref": 3.22845,
            "grammar_hyp": 3.48039,
            "nubia_score": 0.75376
        },
        "meteor": 0.3326885244666272,
        "bertscore": {
            "precision": 0.92895,
            "recall": 0.87605,
            "f1": 0.90115
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1878": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.0,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 15,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 24,
        "unique-1": 22,
        "entropy-1": 4.546593564294937,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": -0.03214388408660255,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9583333333333334,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.501629167387823,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": -0.03462179117476821,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70556,
            "recall": 0.45677,
            "fmeasure": 0.55174
        },
        "rouge2": {
            "precision": 0.36905,
            "recall": 0.23453,
            "fmeasure": 0.28512
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.37865,
            "fmeasure": 0.45588
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.37865,
            "fmeasure": 0.45588
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.5
        },
        "nist": 1.531855420465482,
        "bleu": 10.91545,
        "bleurt": 0.2849,
        "nubia": {
            "semantic_relation": 4.14563,
            "contradiction": 0.42863,
            "irrelevancy": 0.67485,
            "logical_agreement": 98.89653,
            "grammar_ref": 4.13564,
            "grammar_hyp": 5.26048,
            "nubia_score": 0.62833
        },
        "meteor": 0.28615927985758616,
        "bertscore": {
            "precision": 0.91799,
            "recall": 0.85881,
            "f1": 0.88661
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_990": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 1.0,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.5454545454545454,
        "vocab_size-1": 12,
        "unique-1": 3,
        "entropy-1": 3.516027641266231,
        "distinct-2": 0.6,
        "vocab_size-2": 12,
        "unique-2": 4,
        "entropy-2": 3.5219280948873624,
        "cond_entropy-2": 0.00024085135823841142,
        "distinct-3": 0.6111111111111112,
        "vocab_size-3": 11,
        "unique-3": 4,
        "entropy-3": 3.392147223664534,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.55,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 3,
        "entropy-1-nopunct": 3.3841837197791884,
        "distinct-2-nopunct": 0.6111111111111112,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 3.392147223664534,
        "cond_entropy-2-nopunct": 0.0010462122306984685,
        "distinct-3-nopunct": 0.625,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 3.25,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81481,
            "recall": 0.78314,
            "fmeasure": 0.76217
        },
        "rouge2": {
            "precision": 0.69167,
            "recall": 0.5,
            "fmeasure": 0.57926
        },
        "rougeL": {
            "precision": 0.82492,
            "recall": 0.61553,
            "fmeasure": 0.7037
        },
        "rougeLsum": {
            "precision": 0.82492,
            "recall": 0.61553,
            "fmeasure": 0.7037
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855,
            "3": 0.631578947368421
        },
        "nist": 2.522383722603699,
        "bleu": 41.20044,
        "bleurt": 0.26976,
        "nubia": {
            "semantic_relation": 3.99998,
            "contradiction": 0.21264,
            "irrelevancy": 16.70052,
            "logical_agreement": 83.08684,
            "grammar_ref": 4.70595,
            "grammar_hyp": 6.32903,
            "nubia_score": 0.50649
        },
        "meteor": 0.3319159940420885,
        "bertscore": {
            "precision": 0.94682,
            "recall": 0.86477,
            "f1": 0.90391
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1890": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7735572622751845,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.64706,
            "fmeasure": 0.6875
        },
        "rouge2": {
            "precision": 0.21429,
            "recall": 0.1875,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.35294,
            "fmeasure": 0.375
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.35294,
            "fmeasure": 0.375
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "nist": 2.5369422424050088,
        "bleu": 11.81183,
        "bleurt": -0.02123,
        "nubia": {
            "semantic_relation": 3.53315,
            "contradiction": 62.28468,
            "irrelevancy": 23.48923,
            "logical_agreement": 14.22609,
            "grammar_ref": 4.71038,
            "grammar_hyp": 4.72063,
            "nubia_score": 0.45614
        },
        "meteor": 0.2667984573680362,
        "bertscore": {
            "precision": 0.90063,
            "recall": 0.88632,
            "f1": 0.89341
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 379,
        "msttr-100": 0.70241,
        "msttr-100_nopunct": 0.75039,
        "total_length": 8789,
        "mean_pred_length": 23.189973614775724,
        "std_pred_length": 6.138747970749438,
        "median_pred_length": 22.0,
        "min_pred_length": 8,
        "max_pred_length": 59,
        "distinct-1": 0.33473660257139604,
        "vocab_size-1": 2942,
        "unique-1": 2133,
        "entropy-1": 9.173648416016718,
        "distinct-2": 0.7644470868014269,
        "vocab_size-2": 6429,
        "unique-2": 5616,
        "entropy-2": 12.250663141935267,
        "cond_entropy-2": 2.866465672199084,
        "distinct-3": 0.9348773502677126,
        "vocab_size-3": 7508,
        "unique-3": 7137,
        "entropy-3": 12.819626673622635,
        "cond_entropy-3": 0.5529146214404476,
        "total_length-nopunct": 7637,
        "mean_pred_length-nopunct": 20.150395778364118,
        "std_pred_length-nopunct": 5.410443200119894,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 53,
        "distinct-1-nopunct": 0.3833966217100956,
        "vocab_size-1-nopunct": 2928,
        "unique-1-nopunct": 2133,
        "entropy-1-nopunct": 9.580166715528312,
        "distinct-2-nopunct": 0.8013226784238082,
        "vocab_size-2-nopunct": 5816,
        "unique-2-nopunct": 5194,
        "entropy-2-nopunct": 12.166680754227636,
        "cond_entropy-2-nopunct": 2.675347274864537,
        "distinct-3-nopunct": 0.9479575519697631,
        "vocab_size-3-nopunct": 6521,
        "unique-3-nopunct": 6258,
        "entropy-3-nopunct": 12.627582409481198,
        "cond_entropy-3-nopunct": 0.47999320710782295,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74935,
            "recall": 0.7179,
            "fmeasure": 0.72364
        },
        "rouge2": {
            "precision": 0.49016,
            "recall": 0.47138,
            "fmeasure": 0.47396
        },
        "rougeL": {
            "precision": 0.59873,
            "recall": 0.57821,
            "fmeasure": 0.57992
        },
        "rougeLsum": {
            "precision": 0.59873,
            "recall": 0.57821,
            "fmeasure": 0.57992
        },
        "local_recall": {
            "1": 0.23139880952380953,
            "2": 0.4172510518934081,
            "3": 0.7657380607814761
        },
        "nist": 8.616938813145113,
        "bleu": 39.88513,
        "bleurt": 0.19052,
        "nubia": {
            "semantic_relation": 4.05548,
            "contradiction": 10.39578,
            "irrelevancy": 30.26885,
            "logical_agreement": 59.33537,
            "grammar_ref": 4.27824,
            "grammar_hyp": 4.21954,
            "nubia_score": 0.699
        },
        "meteor": 0.37387760925402347,
        "bertscore": {
            "precision": 0.92284,
            "recall": 0.91524,
            "f1": 0.91725
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1310": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.2776134368191165,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "rouge2": {
            "precision": 0.88889,
            "recall": 0.8,
            "fmeasure": 0.84211
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.548645758111165,
        "bleu": 100.0,
        "bleurt": 0.7198,
        "nubia": {
            "semantic_relation": 4.65439,
            "contradiction": 0.55881,
            "irrelevancy": 1.76619,
            "logical_agreement": 97.675,
            "grammar_ref": 4.67316,
            "grammar_hyp": 4.54703,
            "nubia_score": 0.85279
        },
        "meteor": 0.5161210442123606,
        "bertscore": {
            "precision": 0.98951,
            "recall": 0.9715,
            "f1": 0.98042
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1000": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964164,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322734,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.64286,
            "recall": 0.81818,
            "fmeasure": 0.72
        },
        "rouge2": {
            "precision": 0.46154,
            "recall": 0.6,
            "fmeasure": 0.52174
        },
        "rougeL": {
            "precision": 0.64286,
            "recall": 0.81818,
            "fmeasure": 0.72
        },
        "rougeLsum": {
            "precision": 0.64286,
            "recall": 0.81818,
            "fmeasure": 0.72
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.875
        },
        "nist": 2.999613157008355,
        "bleu": 16.9862,
        "bleurt": 0.35457,
        "nubia": {
            "semantic_relation": 4.96761,
            "contradiction": 0.66724,
            "irrelevancy": 69.4922,
            "logical_agreement": 29.84057,
            "grammar_ref": 3.90557,
            "grammar_hyp": 3.86789,
            "nubia_score": 0.96498
        },
        "meteor": 0.35594327848477014,
        "bertscore": {
            "precision": 0.92905,
            "recall": 0.93073,
            "f1": 0.91777
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 124,
        "msttr-100": 0.70323,
        "msttr-100_nopunct": 0.74593,
        "total_length": 3129,
        "mean_pred_length": 25.233870967741936,
        "std_pred_length": 7.057493010712366,
        "median_pred_length": 24.0,
        "min_pred_length": 12,
        "max_pred_length": 56,
        "distinct-1": 0.4170661553211889,
        "vocab_size-1": 1305,
        "unique-1": 1012,
        "entropy-1": 8.589592755704563,
        "distinct-2": 0.8322795341098169,
        "vocab_size-2": 2501,
        "unique-2": 2267,
        "entropy-2": 11.034174500389323,
        "cond_entropy-2": 2.2818388175485564,
        "distinct-3": 0.9590419993057966,
        "vocab_size-3": 2763,
        "unique-3": 2660,
        "entropy-3": 11.4057004427332,
        "cond_entropy-3": 0.3721470285349681,
        "total_length-nopunct": 2737,
        "mean_pred_length-nopunct": 22.072580645161292,
        "std_pred_length-nopunct": 6.313290368401759,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.47278041651443187,
        "vocab_size-1-nopunct": 1294,
        "unique-1-nopunct": 1010,
        "entropy-1-nopunct": 8.884693875148834,
        "distinct-2-nopunct": 0.8538078836586299,
        "vocab_size-2-nopunct": 2231,
        "unique-2-nopunct": 2053,
        "entropy-2-nopunct": 10.895389967055966,
        "cond_entropy-2-nopunct": 2.087699531382397,
        "distinct-3-nopunct": 0.963439132181599,
        "vocab_size-3-nopunct": 2398,
        "unique-3-nopunct": 2320,
        "entropy-3-nopunct": 11.203351734150221,
        "cond_entropy-3-nopunct": 0.32040516457960105,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73848,
            "recall": 0.71079,
            "fmeasure": 0.71379
        },
        "rouge2": {
            "precision": 0.4741,
            "recall": 0.46824,
            "fmeasure": 0.46269
        },
        "rougeL": {
            "precision": 0.5964,
            "recall": 0.58367,
            "fmeasure": 0.58061
        },
        "rougeLsum": {
            "precision": 0.5964,
            "recall": 0.58367,
            "fmeasure": 0.58061
        },
        "local_recall": {
            "1": 0.2153209109730849,
            "2": 0.4604966139954853,
            "3": 0.7459514170040485
        },
        "nist": 7.714825977769766,
        "bleu": 38.49839,
        "bleurt": 0.14422,
        "nubia": {
            "semantic_relation": 3.94967,
            "contradiction": 11.90945,
            "irrelevancy": 33.85336,
            "logical_agreement": 54.2372,
            "grammar_ref": 4.3248,
            "grammar_hyp": 4.19301,
            "nubia_score": 0.66509
        },
        "meteor": 0.361558391509991,
        "bertscore": {
            "precision": 0.91725,
            "recall": 0.91392,
            "f1": 0.91362
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1315": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.52381,
            "recall": 0.56944,
            "fmeasure": 0.54359
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.13333,
            "fmeasure": 0.12121
        },
        "rougeL": {
            "precision": 0.47619,
            "recall": 0.52778,
            "fmeasure": 0.49915
        },
        "rougeLsum": {
            "precision": 0.47619,
            "recall": 0.52778,
            "fmeasure": 0.49915
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.75
        },
        "nist": 2.0949385676221532,
        "bleu": 16.51582,
        "bleurt": -0.04532,
        "nubia": {
            "semantic_relation": 3.99869,
            "contradiction": 2.61879,
            "irrelevancy": 55.46774,
            "logical_agreement": 41.91347,
            "grammar_ref": 5.75818,
            "grammar_hyp": 5.95108,
            "nubia_score": 0.5996
        },
        "meteor": 0.3262776065014196,
        "bertscore": {
            "precision": 0.83661,
            "recall": 0.87925,
            "f1": 0.8574
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1908": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.6402239289418516,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337128,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.21785611591339746,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.46154,
            "recall": 0.54971,
            "fmeasure": 0.48864
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.10185,
            "fmeasure": 0.08889
        },
        "rougeL": {
            "precision": 0.38462,
            "recall": 0.45809,
            "fmeasure": 0.4072
        },
        "rougeLsum": {
            "precision": 0.38462,
            "recall": 0.45809,
            "fmeasure": 0.4072
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nist": 2.1006299471246863,
        "bleu": 8.83937,
        "bleurt": 0.44134,
        "nubia": {
            "semantic_relation": 4.37485,
            "contradiction": 0.08383,
            "irrelevancy": 9.15998,
            "logical_agreement": 90.75619,
            "grammar_ref": 3.44041,
            "grammar_hyp": 3.85213,
            "nubia_score": 0.80888
        },
        "meteor": 0.3738039722945387,
        "bertscore": {
            "precision": 0.9055,
            "recall": 0.92924,
            "f1": 0.91721
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1005": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.2776134368191165,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.79167,
            "recall": 0.63333,
            "fmeasure": 0.7037
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "local_recall": {
            "1": 0.25,
            "2": 0,
            "3": 0.7777777777777778
        },
        "nist": 3.8998572512287097,
        "bleu": 70.97039,
        "bleurt": 0.49536,
        "nubia": {
            "semantic_relation": 4.54342,
            "contradiction": 0.48545,
            "irrelevancy": 0.54019,
            "logical_agreement": 98.97436,
            "grammar_ref": 4.98843,
            "grammar_hyp": 5.36395,
            "nubia_score": 0.7985
        },
        "meteor": 0.5047034859011716,
        "bertscore": {
            "precision": 0.98271,
            "recall": 0.9644,
            "f1": 0.97347
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 128,
        "msttr-100": 0.66632,
        "msttr-100_nopunct": 0.70969,
        "total_length": 3833,
        "mean_pred_length": 29.9453125,
        "std_pred_length": 10.0041464792027,
        "median_pred_length": 29.0,
        "min_pred_length": 5,
        "max_pred_length": 54,
        "distinct-1": 0.36785807461518394,
        "vocab_size-1": 1410,
        "unique-1": 1095,
        "entropy-1": 8.372914645742382,
        "distinct-2": 0.7225371120107962,
        "vocab_size-2": 2677,
        "unique-2": 2404,
        "entropy-2": 10.785873923156148,
        "cond_entropy-2": 2.291214563189576,
        "distinct-3": 0.8521107072966173,
        "vocab_size-3": 3048,
        "unique-3": 2901,
        "entropy-3": 11.271477817856734,
        "cond_entropy-3": 0.48793876042722445,
        "total_length-nopunct": 3286,
        "mean_pred_length-nopunct": 25.671875,
        "std_pred_length-nopunct": 8.62781600315949,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.42574558734023127,
        "vocab_size-1-nopunct": 1399,
        "unique-1-nopunct": 1091,
        "entropy-1-nopunct": 8.706386917494864,
        "distinct-2-nopunct": 0.7558581380620646,
        "vocab_size-2-nopunct": 2387,
        "unique-2-nopunct": 2167,
        "entropy-2-nopunct": 10.708976474996375,
        "cond_entropy-2-nopunct": 2.0578429057784593,
        "distinct-3-nopunct": 0.8726072607260726,
        "vocab_size-3-nopunct": 2644,
        "unique-3-nopunct": 2537,
        "entropy-3-nopunct": 11.104055487211662,
        "cond_entropy-3-nopunct": 0.40519867793243913,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75712,
            "recall": 0.74603,
            "fmeasure": 0.74153
        },
        "rouge2": {
            "precision": 0.51079,
            "recall": 0.50501,
            "fmeasure": 0.5017
        },
        "rougeL": {
            "precision": 0.61258,
            "recall": 0.60973,
            "fmeasure": 0.60287
        },
        "rougeLsum": {
            "precision": 0.61258,
            "recall": 0.60973,
            "fmeasure": 0.60287
        },
        "local_recall": {
            "1": 0.2199546485260771,
            "2": 0.44573643410852715,
            "3": 0.7945578231292517
        },
        "nist": 8.164750378744829,
        "bleu": 49.68539,
        "bleurt": 0.15151,
        "nubia": {
            "semantic_relation": 3.91705,
            "contradiction": 15.4823,
            "irrelevancy": 27.22766,
            "logical_agreement": 57.29004,
            "grammar_ref": 4.11595,
            "grammar_hyp": 3.98953,
            "nubia_score": 0.66236
        },
        "meteor": 0.4012017043516428,
        "bertscore": {
            "precision": 0.92187,
            "recall": 0.91878,
            "f1": 0.91877
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3204": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.640223928941851,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337134,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.21785611591339743,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.925938214656137,
        "bleu": 100.0,
        "bleurt": 0.92236,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.67194,
            "irrelevancy": 0.62656,
            "logical_agreement": 98.70151,
            "grammar_ref": 3.94537,
            "grammar_hyp": 3.94537,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1914": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.5037,
            "fmeasure": 0.64198
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.26891,
            "fmeasure": 0.34909
        },
        "rougeL": {
            "precision": 0.7037,
            "recall": 0.4037,
            "fmeasure": 0.51235
        },
        "rougeLsum": {
            "precision": 0.7037,
            "recall": 0.4037,
            "fmeasure": 0.51235
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.5384615384615384
        },
        "nist": 0.7514117701566305,
        "bleu": 28.41088,
        "bleurt": 0.03781,
        "nubia": {
            "semantic_relation": 3.90649,
            "contradiction": 0.57624,
            "irrelevancy": 0.5262,
            "logical_agreement": 98.89756,
            "grammar_ref": 4.4151,
            "grammar_hyp": 6.06828,
            "nubia_score": 0.46595
        },
        "meteor": 0.2841762990914195,
        "bertscore": {
            "precision": 0.94668,
            "recall": 0.88134,
            "f1": 0.91284
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1969": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.81481,
            "fmeasure": 0.8642
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.76471,
            "fmeasure": 0.8
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.81481,
            "fmeasure": 0.8642
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.81481,
            "fmeasure": 0.8642
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 0.9782567700931432,
        "bleu": 100.0,
        "bleurt": 0.384,
        "nubia": {
            "semantic_relation": 4.42127,
            "contradiction": 0.1348,
            "irrelevancy": 0.45863,
            "logical_agreement": 99.40657,
            "grammar_ref": 4.62828,
            "grammar_hyp": 6.42175,
            "nubia_score": 0.6405
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3222": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.188721875540867,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.3067316181128199,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.027169118440619,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.3379852264664119,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.72751,
            "fmeasure": 0.83954
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.51584,
            "fmeasure": 0.60333
        },
        "rougeL": {
            "precision": 0.93939,
            "recall": 0.51704,
            "fmeasure": 0.66347
        },
        "rougeLsum": {
            "precision": 0.93939,
            "recall": 0.51704,
            "fmeasure": 0.66347
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "nist": 1.9105250180801645,
        "bleu": 62.207,
        "bleurt": -0.14434,
        "nubia": {
            "semantic_relation": 3.27646,
            "contradiction": 93.29798,
            "irrelevancy": 1.81369,
            "logical_agreement": 4.88833,
            "grammar_ref": 3.09217,
            "grammar_hyp": 2.87496,
            "nubia_score": 0.56072
        },
        "meteor": 0.3977613383709655,
        "bertscore": {
            "precision": 0.96167,
            "recall": 0.90351,
            "f1": 0.93168
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1974": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 9.5,
        "std_pred_length": 0.5,
        "median_pred_length": 9.5,
        "min_pred_length": 9,
        "max_pred_length": 10,
        "distinct-1": 0.47368421052631576,
        "vocab_size-1": 9,
        "unique-1": 3,
        "entropy-1": 2.9847696187067436,
        "distinct-2": 0.5294117647058824,
        "vocab_size-2": 9,
        "unique-2": 3,
        "entropy-2": 3.0286393118385755,
        "cond_entropy-2": 0.0748294454538127,
        "distinct-3": 0.6,
        "vocab_size-3": 9,
        "unique-3": 3,
        "entropy-3": 3.106890595608519,
        "cond_entropy-3": 0.08609442102484582,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.47058823529411764,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 3,
        "entropy-1-nopunct": 2.793345194191516,
        "distinct-2-nopunct": 0.5333333333333333,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 3,
        "entropy-2-nopunct": 2.8402239289418523,
        "cond_entropy-2-nopunct": -0.0472389123084875,
        "distinct-3-nopunct": 0.6153846153846154,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 2.931208948910323,
        "cond_entropy-3-nopunct": -0.05260472362127268,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "rouge2": {
            "precision": 0.79464,
            "recall": 0.72685,
            "fmeasure": 0.75776
        },
        "rougeL": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "rougeLsum": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "nist": 4.451815875634701,
        "bleu": 69.05636,
        "bleurt": 0.78257,
        "nubia": {
            "semantic_relation": 4.99611,
            "contradiction": 0.40178,
            "irrelevancy": 0.5141,
            "logical_agreement": 99.08412,
            "grammar_ref": 4.85767,
            "grammar_hyp": 5.20195,
            "nubia_score": 0.97201
        },
        "meteor": 0.9489775258149422,
        "bertscore": {
            "precision": 0.98549,
            "recall": 0.97733,
            "f1": 0.98137
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1980": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.93333,
            "recall": 1.0,
            "fmeasure": 0.96296
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.81905,
            "fmeasure": 0.76863
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.81905,
            "fmeasure": 0.76863
        },
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.875
        },
        "nist": 2.8043533630124777,
        "bleu": 38.82727,
        "bleurt": 0.39135,
        "nubia": {
            "semantic_relation": 4.8136,
            "contradiction": 0.69691,
            "irrelevancy": 56.12808,
            "logical_agreement": 43.17501,
            "grammar_ref": 6.57473,
            "grammar_hyp": 4.94905,
            "nubia_score": 0.99874
        },
        "meteor": 0.45626915779345323,
        "bertscore": {
            "precision": 0.95635,
            "recall": 0.92424,
            "f1": 0.94002
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3432": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5,
            "recall": 0.7,
            "fmeasure": 0.58182
        },
        "rouge2": {
            "precision": 0.29412,
            "recall": 0.42208,
            "fmeasure": 0.34562
        },
        "rougeL": {
            "precision": 0.37037,
            "recall": 0.52222,
            "fmeasure": 0.43232
        },
        "rougeLsum": {
            "precision": 0.37037,
            "recall": 0.52222,
            "fmeasure": 0.43232
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nist": 1.5266657517158808,
        "bleu": 10.07904,
        "bleurt": -0.36187,
        "nubia": {
            "semantic_relation": 3.81047,
            "contradiction": 0.13087,
            "irrelevancy": 94.05295,
            "logical_agreement": 5.81618,
            "grammar_ref": 4.47457,
            "grammar_hyp": 4.62068,
            "nubia_score": 0.59795
        },
        "meteor": 0.3634826364233921,
        "bertscore": {
            "precision": 0.78924,
            "recall": 0.87548,
            "f1": 0.82431
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3479": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.625,
            "recall": 0.51754,
            "fmeasure": 0.56614
        },
        "rouge2": {
            "precision": 0.31111,
            "recall": 0.25536,
            "fmeasure": 0.28045
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.46579,
            "fmeasure": 0.50952
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.46579,
            "fmeasure": 0.50952
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5555555555555556
        },
        "nist": 2.439493811153617,
        "bleu": 19.17707,
        "bleurt": -0.0799,
        "nubia": {
            "semantic_relation": 3.9356,
            "contradiction": 0.09034,
            "irrelevancy": 99.3676,
            "logical_agreement": 0.54206,
            "grammar_ref": 4.62058,
            "grammar_hyp": 5.27916,
            "nubia_score": 0.54587
        },
        "meteor": 0.2984890068558078,
        "bertscore": {
            "precision": 0.84371,
            "recall": 0.78649,
            "f1": 0.8141
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2040": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 2.5,
        "median_pred_length": 15.5,
        "min_pred_length": 13,
        "max_pred_length": 18,
        "distinct-1": 0.6451612903225806,
        "vocab_size-1": 20,
        "unique-1": 11,
        "entropy-1": 4.180002761999779,
        "distinct-2": 0.7586206896551724,
        "vocab_size-2": 22,
        "unique-2": 15,
        "entropy-2": 4.375222374437916,
        "cond_entropy-2": 0.17964675370621427,
        "distinct-3": 0.8148148148148148,
        "vocab_size-3": 22,
        "unique-3": 17,
        "entropy-3": 4.3845171317931,
        "cond_entropy-3": 0.04505465518404472,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6551724137931034,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 4.0993603054724,
        "distinct-2-nopunct": 0.7407407407407407,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 4.236368983644952,
        "cond_entropy-2-nopunct": 0.15616576629515583,
        "distinct-3-nopunct": 0.8,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 4.243856189774723,
        "cond_entropy-3-nopunct": 0.008968687611256052,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.98611,
            "recall": 0.93106,
            "fmeasure": 0.95763
        },
        "rouge2": {
            "precision": 0.95152,
            "recall": 0.89457,
            "fmeasure": 0.92197
        },
        "rougeL": {
            "precision": 0.98611,
            "recall": 0.93106,
            "fmeasure": 0.95763
        },
        "rougeLsum": {
            "precision": 0.98611,
            "recall": 0.93106,
            "fmeasure": 0.95763
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.75,
            "3": 0.9130434782608695
        },
        "nist": 5.272756365722568,
        "bleu": 90.56555,
        "bleurt": 0.46054,
        "nubia": {
            "semantic_relation": 4.50569,
            "contradiction": 0.26099,
            "irrelevancy": 32.86289,
            "logical_agreement": 66.87613,
            "grammar_ref": 4.08754,
            "grammar_hyp": 4.19033,
            "nubia_score": 0.83387
        },
        "meteor": 0.5718366351108638,
        "bertscore": {
            "precision": 0.99021,
            "recall": 0.97274,
            "f1": 0.98132
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3492": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.63636,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8181818181818182
        },
        "nist": 3.0088906840841796,
        "bleu": 58.33511,
        "bleurt": 0.7528,
        "nubia": {
            "semantic_relation": 4.98921,
            "contradiction": 0.42473,
            "irrelevancy": 22.33974,
            "logical_agreement": 77.23553,
            "grammar_ref": 4.14586,
            "grammar_hyp": 3.79251,
            "nubia_score": 1.0
        },
        "meteor": 0.4630505936482093,
        "bertscore": {
            "precision": 0.97213,
            "recall": 0.96481,
            "f1": 0.96846
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1640": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.625,
            "fmeasure": 0.71429
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.31579,
            "fmeasure": 0.36364
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.375,
            "fmeasure": 0.42857
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.375,
            "fmeasure": 0.42857
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.625
        },
        "nist": 2.505570096670576,
        "bleu": 14.79258,
        "bleurt": 0.23809,
        "nubia": {
            "semantic_relation": 4.81472,
            "contradiction": 1.20324,
            "irrelevancy": 0.93736,
            "logical_agreement": 97.85941,
            "grammar_ref": 4.55046,
            "grammar_hyp": 5.48032,
            "nubia_score": 0.75973
        },
        "meteor": 0.3533446814959668,
        "bertscore": {
            "precision": 0.92993,
            "recall": 0.89008,
            "f1": 0.90957
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3540": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.82143,
            "fmeasure": 0.9011
        },
        "rouge2": {
            "precision": 0.93333,
            "recall": 0.74603,
            "fmeasure": 0.82828
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.82143,
            "fmeasure": 0.9011
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.82143,
            "fmeasure": 0.9011
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "nist": 2.1126567718249225,
        "bleu": 84.64817,
        "bleurt": -0.15862,
        "nubia": {
            "semantic_relation": 3.69006,
            "contradiction": 0.31517,
            "irrelevancy": 0.57051,
            "logical_agreement": 99.11432,
            "grammar_ref": 6.37596,
            "grammar_hyp": 5.64518,
            "nubia_score": 0.75233
        },
        "meteor": 0.507208078598044,
        "bertscore": {
            "precision": 0.97931,
            "recall": 0.9326,
            "f1": 0.95538
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1656": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.277613436819116,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.84615,
            "fmeasure": 0.91667
        },
        "rouge2": {
            "precision": 0.9,
            "recall": 0.75,
            "fmeasure": 0.81818
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.84615,
            "fmeasure": 0.91667
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.84615,
            "fmeasure": 0.91667
        },
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666
        },
        "nist": 2.644529512411263,
        "bleu": 53.41953,
        "bleurt": 0.67363,
        "nubia": {
            "semantic_relation": 4.26135,
            "contradiction": 0.23391,
            "irrelevancy": 0.45277,
            "logical_agreement": 99.31332,
            "grammar_ref": 3.76485,
            "grammar_hyp": 3.02431,
            "nubia_score": 0.96731
        },
        "meteor": 0.4854757860824232,
        "bertscore": {
            "precision": 0.9821,
            "recall": 0.96544,
            "f1": 0.9737
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1926": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 12,
        "unique-1": 10,
        "entropy-1": 3.521640636343319,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.2007771037757955,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.21785611591339743,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.89744,
            "recall": 0.80855,
            "fmeasure": 0.84982
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.5873,
            "fmeasure": 0.62393
        },
        "rougeL": {
            "precision": 0.79487,
            "recall": 0.71282,
            "fmeasure": 0.75092
        },
        "rougeLsum": {
            "precision": 0.79487,
            "recall": 0.71282,
            "fmeasure": 0.75092
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "nist": 4.183277077700489,
        "bleu": 67.71111,
        "bleurt": 0.39888,
        "nubia": {
            "semantic_relation": 4.82767,
            "contradiction": 0.3341,
            "irrelevancy": 0.51166,
            "logical_agreement": 99.15423,
            "grammar_ref": 4.20051,
            "grammar_hyp": 4.47185,
            "nubia_score": 0.91922
        },
        "meteor": 0.43144177927531935,
        "bertscore": {
            "precision": 0.97561,
            "recall": 0.91553,
            "f1": 0.94456
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3546": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.875,
            "fmeasure": 0.90323
        },
        "rouge2": {
            "precision": 0.47619,
            "recall": 0.49231,
            "fmeasure": 0.48361
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.34226,
            "fmeasure": 0.33741
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.34226,
            "fmeasure": 0.33741
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7272727272727273
        },
        "nist": 3.4052088690524895,
        "bleu": 17.31747,
        "bleurt": -0.22161,
        "nubia": {
            "semantic_relation": 4.40134,
            "contradiction": 0.28662,
            "irrelevancy": 33.62168,
            "logical_agreement": 66.09171,
            "grammar_ref": 4.41465,
            "grammar_hyp": 5.63693,
            "nubia_score": 0.63015
        },
        "meteor": 0.37239613830825974,
        "bertscore": {
            "precision": 0.89853,
            "recall": 0.89961,
            "f1": 0.89907
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5418": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8421052631578947,
        "vocab_size-1": 16,
        "unique-1": 13,
        "entropy-1": 3.932138039759373,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 17,
        "unique-2": 16,
        "entropy-2": 4.058813890331201,
        "cond_entropy-2": 0.14421971022094904,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": 0.03518489863155644,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.8365916681089787,
        "distinct-2-nopunct": 0.9411764705882353,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.969815782426811,
        "cond_entropy-2-nopunct": 0.15283195745508585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": 0.037537158749660585,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.52778,
            "recall": 0.36232,
            "fmeasure": 0.42785
        },
        "rouge2": {
            "precision": 0.35294,
            "recall": 0.23433,
            "fmeasure": 0.28038
        },
        "rougeL": {
            "precision": 0.52778,
            "recall": 0.36232,
            "fmeasure": 0.42785
        },
        "rougeLsum": {
            "precision": 0.52778,
            "recall": 0.36232,
            "fmeasure": 0.42785
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.42105263157894735
        },
        "nist": 1.6269347822761986,
        "bleu": 18.43745,
        "bleurt": -0.66644,
        "nubia": {
            "semantic_relation": 2.33588,
            "contradiction": 78.54837,
            "irrelevancy": 20.93221,
            "logical_agreement": 0.51942,
            "grammar_ref": 4.294,
            "grammar_hyp": 4.11508,
            "nubia_score": 0.15952
        },
        "meteor": 0.22977706774980416,
        "bertscore": {
            "precision": 0.85825,
            "recall": 0.81704,
            "f1": 0.83703
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1680": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78788,
            "recall": 0.86667,
            "fmeasure": 0.8254
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.51852,
            "fmeasure": 0.49123
        },
        "rougeL": {
            "precision": 0.51515,
            "recall": 0.56667,
            "fmeasure": 0.53968
        },
        "rougeLsum": {
            "precision": 0.51515,
            "recall": 0.56667,
            "fmeasure": 0.53968
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8
        },
        "nist": 3.1227989408526344,
        "bleu": 23.23342,
        "bleurt": 0.52526,
        "nubia": {
            "semantic_relation": 4.92746,
            "contradiction": 0.20361,
            "irrelevancy": 1.11157,
            "logical_agreement": 98.68482,
            "grammar_ref": 4.2439,
            "grammar_hyp": 4.26278,
            "nubia_score": 0.96929
        },
        "meteor": 0.44212044811612455,
        "bertscore": {
            "precision": 0.9415,
            "recall": 0.96357,
            "f1": 0.9524
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2304": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 10.5,
        "std_pred_length": 0.5,
        "median_pred_length": 10.5,
        "min_pred_length": 10,
        "max_pred_length": 11,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 18,
        "unique-1": 15,
        "entropy-1": 4.106603137064474,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.06613640645429873,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.1604646721932461,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.03740119765411,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.07482944545381268,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.18057224564182078,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85,
            "recall": 0.68745,
            "fmeasure": 0.74841
        },
        "rouge2": {
            "precision": 0.61111,
            "recall": 0.49011,
            "fmeasure": 0.53456
        },
        "rougeL": {
            "precision": 0.85,
            "recall": 0.68745,
            "fmeasure": 0.74841
        },
        "rougeLsum": {
            "precision": 0.85,
            "recall": 0.68745,
            "fmeasure": 0.74841
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.7058823529411765
        },
        "nist": 2.0397017623591114,
        "bleu": 37.82097,
        "bleurt": 0.30774,
        "nubia": {
            "semantic_relation": 4.01271,
            "contradiction": 51.97721,
            "irrelevancy": 21.31821,
            "logical_agreement": 26.70458,
            "grammar_ref": 3.80999,
            "grammar_hyp": 4.24157,
            "nubia_score": 0.60216
        },
        "meteor": 0.3787766403842524,
        "bertscore": {
            "precision": 0.95773,
            "recall": 0.9163,
            "f1": 0.93626
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1010": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 15,
        "unique-1": 12,
        "entropy-1": 3.8365916681089787,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.27047901627861526,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.734521664779752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.2875371587496605,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.52941,
            "recall": 0.75,
            "fmeasure": 0.62069
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.36364,
            "fmeasure": 0.2963
        },
        "rougeL": {
            "precision": 0.29412,
            "recall": 0.50926,
            "fmeasure": 0.37135
        },
        "rougeLsum": {
            "precision": 0.29412,
            "recall": 0.50926,
            "fmeasure": 0.37135
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.45454545454545453
        },
        "nist": 2.0347283090782633,
        "bleu": 12.51224,
        "bleurt": 0.43084,
        "nubia": {
            "semantic_relation": 4.48383,
            "contradiction": 0.09197,
            "irrelevancy": 33.7478,
            "logical_agreement": 66.16023,
            "grammar_ref": 4.00353,
            "grammar_hyp": 3.74782,
            "nubia_score": 0.81511
        },
        "meteor": 0.2744389872474588,
        "bertscore": {
            "precision": 0.87226,
            "recall": 0.87127,
            "f1": 0.87177
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3591": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 3.8465578035643277,
        "bleu": 100.0,
        "bleurt": 0.87565,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.69325,
            "irrelevancy": 0.54497,
            "logical_agreement": 98.76179,
            "grammar_ref": 7.00423,
            "grammar_hyp": 7.45225,
            "nubia_score": 0.93405
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5455": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.81818,
            "fmeasure": 0.78261
        },
        "rougeL": {
            "precision": 0.76923,
            "recall": 0.83333,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.76923,
            "recall": 0.83333,
            "fmeasure": 0.8
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.470039480297192,
        "bleu": 58.47065,
        "bleurt": 0.67552,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.23447,
            "irrelevancy": 8.96049,
            "logical_agreement": 90.80504,
            "grammar_ref": 4.72684,
            "grammar_hyp": 4.64113,
            "nubia_score": 0.97366
        },
        "meteor": 0.5173810893899051,
        "bertscore": {
            "precision": 0.97295,
            "recall": 0.96361,
            "f1": 0.96825
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3612": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9545454545454546,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.368522527728205,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.02812389937955851,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.47368,
            "recall": 0.43413,
            "fmeasure": 0.45299
        },
        "rouge2": {
            "precision": 0.2037,
            "recall": 0.18596,
            "fmeasure": 0.1944
        },
        "rougeL": {
            "precision": 0.26316,
            "recall": 0.24603,
            "fmeasure": 0.25427
        },
        "rougeLsum": {
            "precision": 0.26316,
            "recall": 0.24603,
            "fmeasure": 0.25427
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.6
        },
        "nist": 3.252684062673951,
        "bleu": 14.78984,
        "bleurt": -0.11004,
        "nubia": {
            "semantic_relation": 3.35653,
            "contradiction": 46.19145,
            "irrelevancy": 49.79751,
            "logical_agreement": 4.01104,
            "grammar_ref": 5.50536,
            "grammar_hyp": 4.60253,
            "nubia_score": 0.50514
        },
        "meteor": 0.27505656366352604,
        "bertscore": {
            "precision": 0.85434,
            "recall": 0.86316,
            "f1": 0.85836
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2313": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 1.5,
        "median_pred_length": 15.5,
        "min_pred_length": 14,
        "max_pred_length": 17,
        "distinct-1": 0.8064516129032258,
        "vocab_size-1": 25,
        "unique-1": 20,
        "entropy-1": 4.542748326446119,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 28,
        "unique-2": 27,
        "entropy-2": 4.789015477886192,
        "cond_entropy-2": 0.20567735722909256,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.029019418890029347,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8148148148148148,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.3565583354166755,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.5638561897747225,
        "cond_entropy-2-nopunct": 0.19916418769779487,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.03333771197858132,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.51453,
            "recall": 0.26055,
            "fmeasure": 0.33981
        },
        "rouge2": {
            "precision": 0.20833,
            "recall": 0.08275,
            "fmeasure": 0.11596
        },
        "rougeL": {
            "precision": 0.33162,
            "recall": 0.1765,
            "fmeasure": 0.22636
        },
        "rougeLsum": {
            "precision": 0.33162,
            "recall": 0.1765,
            "fmeasure": 0.22636
        },
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.0,
            "3": 0.3235294117647059
        },
        "nist": 0.176141613203818,
        "bleu": 3.16029,
        "bleurt": -0.57634,
        "nubia": {
            "semantic_relation": 2.29166,
            "contradiction": 44.15326,
            "irrelevancy": 8.207,
            "logical_agreement": 47.63974,
            "grammar_ref": 3.44707,
            "grammar_hyp": 4.08967,
            "nubia_score": 0.15331
        },
        "meteor": 0.12126504038652597,
        "bertscore": {
            "precision": 0.84482,
            "recall": 0.77207,
            "f1": 0.80017
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5538": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.47222,
            "fmeasure": 0.55238
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5555555555555556
        },
        "nist": 2.32249814589546,
        "bleu": 41.10546,
        "bleurt": 0.65075,
        "nubia": {
            "semantic_relation": 4.62868,
            "contradiction": 0.5038,
            "irrelevancy": 0.54324,
            "logical_agreement": 98.95296,
            "grammar_ref": 4.24503,
            "grammar_hyp": 4.03961,
            "nubia_score": 0.96227
        },
        "meteor": 0.8569614896318238,
        "bertscore": {
            "precision": 0.96587,
            "recall": 0.9307,
            "f1": 0.94796
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2080": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 47.0,
        "std_pred_length": 0.0,
        "median_pred_length": 47.0,
        "min_pred_length": 47,
        "max_pred_length": 47,
        "distinct-1": 0.6808510638297872,
        "vocab_size-1": 32,
        "unique-1": 23,
        "entropy-1": 4.799061723926002,
        "distinct-2": 0.8478260869565217,
        "vocab_size-2": 39,
        "unique-2": 33,
        "entropy-2": 5.202803532096936,
        "cond_entropy-2": 0.4201663109481466,
        "distinct-3": 0.9333333333333333,
        "vocab_size-3": 42,
        "unique-3": 39,
        "entropy-3": 5.358519762996339,
        "cond_entropy-3": 0.16284419587629428,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 42.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 42.0,
        "min_pred_length-nopunct": 42,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.7142857142857143,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.737322779818596,
        "distinct-2-nopunct": 0.8536585365853658,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 5.046457187492144,
        "cond_entropy-2-nopunct": 0.3251098867701396,
        "distinct-3-nopunct": 0.925,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.171928094887363,
        "cond_entropy-3-nopunct": 0.13324827782336543,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.42029,
            "recall": 0.62197,
            "fmeasure": 0.50038
        },
        "rouge2": {
            "precision": 0.17778,
            "recall": 0.26667,
            "fmeasure": 0.21279
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.49298,
            "fmeasure": 0.39675
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.49298,
            "fmeasure": 0.39675
        },
        "local_recall": {
            "1": 0.3,
            "2": 0.8,
            "3": 0.45
        },
        "nist": 1.9564816645741576,
        "bleu": 5.46943,
        "bleurt": -0.2266,
        "nubia": {
            "semantic_relation": 3.63333,
            "contradiction": 5.94635,
            "irrelevancy": 39.33127,
            "logical_agreement": 54.72238,
            "grammar_ref": 5.53052,
            "grammar_hyp": 3.90814,
            "nubia_score": 0.70548
        },
        "meteor": 0.27433728039610095,
        "bertscore": {
            "precision": 0.82635,
            "recall": 0.85231,
            "f1": 0.83741
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2385": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.031262576450960096,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.90476,
            "recall": 0.95,
            "fmeasure": 0.92683
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.73684,
            "fmeasure": 0.71795
        },
        "rougeL": {
            "precision": 0.87302,
            "recall": 0.94815,
            "fmeasure": 0.90848
        },
        "rougeLsum": {
            "precision": 0.87302,
            "recall": 0.94815,
            "fmeasure": 0.90848
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.6666666666666666,
            "3": 1.0
        },
        "nist": 5.164572862262538,
        "bleu": 78.9014,
        "bleurt": 0.56137,
        "nubia": {
            "semantic_relation": 4.6569,
            "contradiction": 0.60114,
            "irrelevancy": 98.14851,
            "logical_agreement": 1.25035,
            "grammar_ref": 4.59116,
            "grammar_hyp": 4.50818,
            "nubia_score": 0.86332
        },
        "meteor": 0.544420550418756,
        "bertscore": {
            "precision": 0.97774,
            "recall": 0.98904,
            "f1": 0.98336
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3720": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 1.0,
        "median_pred_length": 16.0,
        "min_pred_length": 15,
        "max_pred_length": 17,
        "distinct-1": 0.59375,
        "vocab_size-1": 19,
        "unique-1": 8,
        "entropy-1": 4.125,
        "distinct-2": 0.7333333333333333,
        "vocab_size-2": 22,
        "unique-2": 14,
        "entropy-2": 4.3735572622751855,
        "cond_entropy-2": 0.24022392894185185,
        "distinct-3": 0.8214285714285714,
        "vocab_size-3": 23,
        "unique-3": 18,
        "entropy-3": 4.450212064914748,
        "cond_entropy-3": 0.04332146930622849,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.625,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.8349625007211565,
        "distinct-2-nopunct": 0.7272727272727273,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.913977073182751,
        "cond_entropy-2-nopunct": 0.05628729973432271,
        "distinct-3-nopunct": 0.8,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.9219280948873623,
        "cond_entropy-3-nopunct": -0.037503523749935014,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9130434782608695
        },
        "nist": 4.282514138572009,
        "bleu": 79.81519,
        "bleurt": 0.4515,
        "nubia": {
            "semantic_relation": 4.32726,
            "contradiction": 43.9504,
            "irrelevancy": 13.81033,
            "logical_agreement": 42.23927,
            "grammar_ref": 4.1188,
            "grammar_hyp": 4.60786,
            "nubia_score": 0.66303
        },
        "meteor": 0.4570160089905608,
        "bertscore": {
            "precision": 0.98345,
            "recall": 0.93834,
            "f1": 0.95858
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1683": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.8695652173913043,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.229871195093384,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.170866253554935,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77083,
            "recall": 0.64141,
            "fmeasure": 0.69866
        },
        "rouge2": {
            "precision": 0.37778,
            "recall": 0.31466,
            "fmeasure": 0.34259
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.4697,
            "fmeasure": 0.51084
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.4697,
            "fmeasure": 0.51084
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.625
        },
        "nist": 3.1217766955183293,
        "bleu": 33.21618,
        "bleurt": -0.06719,
        "nubia": {
            "semantic_relation": 3.31541,
            "contradiction": 95.41116,
            "irrelevancy": 1.92184,
            "logical_agreement": 2.667,
            "grammar_ref": 4.78465,
            "grammar_hyp": 5.74343,
            "nubia_score": 0.3279
        },
        "meteor": 0.30020362864262484,
        "bertscore": {
            "precision": 0.94147,
            "recall": 0.92401,
            "f1": 0.93234
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2104": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.39167,
            "fmeasure": 0.53755
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.20952,
            "fmeasure": 0.29524
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.38431,
            "fmeasure": 0.5303
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.38431,
            "fmeasure": 0.5303
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "nist": 0.2841455313229504,
        "bleu": 7.56238,
        "bleurt": -0.36155,
        "nubia": {
            "semantic_relation": 3.65233,
            "contradiction": 0.32311,
            "irrelevancy": 1.26008,
            "logical_agreement": 98.41681,
            "grammar_ref": 4.68072,
            "grammar_hyp": 5.64189,
            "nubia_score": 0.52633
        },
        "meteor": 0.18866647190206598,
        "bertscore": {
            "precision": 0.89426,
            "recall": 0.7758,
            "f1": 0.83082
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5550": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.96296,
            "fmeasure": 0.91228
        },
        "rouge2": {
            "precision": 0.7037,
            "recall": 0.79167,
            "fmeasure": 0.7451
        },
        "rougeL": {
            "precision": 0.86667,
            "recall": 0.96296,
            "fmeasure": 0.91228
        },
        "rougeLsum": {
            "precision": 0.86667,
            "recall": 0.96296,
            "fmeasure": 0.91228
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.9682591176000703,
        "bleu": 76.11606,
        "bleurt": 0.77776,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.17539,
            "irrelevancy": 5.81074,
            "logical_agreement": 94.01388,
            "grammar_ref": 4.6877,
            "grammar_hyp": 4.63407,
            "nubia_score": 0.9946
        },
        "meteor": 0.544209755399708,
        "bertscore": {
            "precision": 0.98018,
            "recall": 0.99668,
            "f1": 0.98836
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2112": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.5873,
            "fmeasure": 0.65152
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "nist": 3.0881978509745025,
        "bleu": 68.94026,
        "bleurt": 0.64449,
        "nubia": {
            "semantic_relation": 4.6318,
            "contradiction": 0.66466,
            "irrelevancy": 0.56229,
            "logical_agreement": 98.77305,
            "grammar_ref": 5.07671,
            "grammar_hyp": 5.29413,
            "nubia_score": 0.85198
        },
        "meteor": 0.81809314801268,
        "bertscore": {
            "precision": 0.98644,
            "recall": 0.96366,
            "f1": 0.97492
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5656": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 4.5,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 18,
        "distinct-1": 0.8148148148148148,
        "vocab_size-1": 22,
        "unique-1": 17,
        "entropy-1": 4.3845171317931,
        "distinct-2": 0.92,
        "vocab_size-2": 23,
        "unique-2": 21,
        "entropy-2": 4.4838561897747224,
        "cond_entropy-2": 0.048968687611256057,
        "distinct-3": 0.9565217391304348,
        "vocab_size-3": 22,
        "unique-3": 21,
        "entropy-3": 4.436605434317882,
        "cond_entropy-3": -0.03333771197858132,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.095795255000932,
        "distinct-2-nopunct": 0.9,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.1219280948873624,
        "cond_entropy-2-nopunct": 0.012496476250064989,
        "distinct-3-nopunct": 0.9444444444444444,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.058813890331201,
        "cond_entropy-3-nopunct": -0.09644753788949419,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70536,
            "recall": 0.75463,
            "fmeasure": 0.72303
        },
        "rouge2": {
            "precision": 0.45055,
            "recall": 0.50825,
            "fmeasure": 0.47355
        },
        "rougeL": {
            "precision": 0.64286,
            "recall": 0.70093,
            "fmeasure": 0.6653
        },
        "rougeLsum": {
            "precision": 0.64286,
            "recall": 0.70093,
            "fmeasure": 0.6653
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7894736842105263
        },
        "nist": 3.5165067988781327,
        "bleu": 47.71625,
        "bleurt": 0.26382,
        "nubia": {
            "semantic_relation": 4.45358,
            "contradiction": 6.64989,
            "irrelevancy": 26.39842,
            "logical_agreement": 66.95168,
            "grammar_ref": 6.17452,
            "grammar_hyp": 5.96806,
            "nubia_score": 0.73568
        },
        "meteor": 0.39607356968056495,
        "bertscore": {
            "precision": 0.91684,
            "recall": 0.91118,
            "f1": 0.90897
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2123": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.62465,
            "fmeasure": 0.69142
        },
        "rouge2": {
            "precision": 0.69697,
            "recall": 0.51282,
            "fmeasure": 0.58951
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.62465,
            "fmeasure": 0.69142
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.62465,
            "fmeasure": 0.69142
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6923076923076923
        },
        "nist": 3.179158422000987,
        "bleu": 50.78432,
        "bleurt": 0.05546,
        "nubia": {
            "semantic_relation": 3.83539,
            "contradiction": 27.20618,
            "irrelevancy": 67.00664,
            "logical_agreement": 5.78718,
            "grammar_ref": 4.48877,
            "grammar_hyp": 4.52277,
            "nubia_score": 0.58167
        },
        "meteor": 0.3876669651197313,
        "bertscore": {
            "precision": 0.96075,
            "recall": 0.91274,
            "f1": 0.92047
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1014": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 2.584962500721156,
        "bleu": 100.0,
        "bleurt": 0.99531,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.15788,
            "irrelevancy": 0.43071,
            "logical_agreement": 99.41142,
            "grammar_ref": 6.34893,
            "grammar_hyp": 6.34893,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 46,
        "msttr-100": 0.57462,
        "msttr-100_nopunct": 0.58167,
        "total_length": 1375,
        "mean_pred_length": 29.891304347826086,
        "std_pred_length": 7.352101920301625,
        "median_pred_length": 29.0,
        "min_pred_length": 19,
        "max_pred_length": 47,
        "distinct-1": 0.1469090909090909,
        "vocab_size-1": 202,
        "unique-1": 72,
        "entropy-1": 6.499525274973465,
        "distinct-2": 0.42663656884875845,
        "vocab_size-2": 567,
        "unique-2": 316,
        "entropy-2": 8.566917366164985,
        "cond_entropy-2": 2.0156905250913644,
        "distinct-3": 0.6640685892439595,
        "vocab_size-3": 852,
        "unique-3": 634,
        "entropy-3": 9.457133147760116,
        "cond_entropy-3": 0.8920198157662977,
        "total_length-nopunct": 1272,
        "mean_pred_length-nopunct": 27.652173913043477,
        "std_pred_length-nopunct": 6.627404867223828,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.15566037735849056,
        "vocab_size-1-nopunct": 198,
        "unique-1-nopunct": 72,
        "entropy-1-nopunct": 6.480540087224155,
        "distinct-2-nopunct": 0.4363784665579119,
        "vocab_size-2-nopunct": 535,
        "unique-2-nopunct": 310,
        "entropy-2-nopunct": 8.47280808513458,
        "cond_entropy-2-nopunct": 2.004886761807785,
        "distinct-3-nopunct": 0.6661016949152543,
        "vocab_size-3-nopunct": 786,
        "unique-3-nopunct": 594,
        "entropy-3-nopunct": 9.331366799462506,
        "cond_entropy-3-nopunct": 0.8803416879855667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.64764,
            "recall": 0.63948,
            "fmeasure": 0.6339
        },
        "rouge2": {
            "precision": 0.40435,
            "recall": 0.40867,
            "fmeasure": 0.40057
        },
        "rougeL": {
            "precision": 0.51357,
            "recall": 0.51511,
            "fmeasure": 0.50704
        },
        "rougeLsum": {
            "precision": 0.51357,
            "recall": 0.51511,
            "fmeasure": 0.50704
        },
        "local_recall": {
            "1": 0.6251032204789431
        },
        "nist": 5.341249431355817,
        "bleu": 34.4562,
        "bleurt": -0.1648,
        "nubia": {
            "semantic_relation": 3.73396,
            "contradiction": 52.17105,
            "irrelevancy": 26.12744,
            "logical_agreement": 21.70151,
            "grammar_ref": 4.5797,
            "grammar_hyp": 4.49547,
            "nubia_score": 0.54999
        },
        "meteor": 0.31954162967926225,
        "bertscore": {
            "precision": 0.89225,
            "recall": 0.89264,
            "f1": 0.89219
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3908": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.027169118440619,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.3379852264664118,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.8464393446710154,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.20021079560409605,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85,
            "recall": 0.7906,
            "fmeasure": 0.81236
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.625,
            "fmeasure": 0.63866
        },
        "rougeL": {
            "precision": 0.85,
            "recall": 0.7906,
            "fmeasure": 0.81236
        },
        "rougeLsum": {
            "precision": 0.85,
            "recall": 0.7906,
            "fmeasure": 0.81236
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "nist": 3.992017761727649,
        "bleu": 66.87403,
        "bleurt": 0.59777,
        "nubia": {
            "semantic_relation": 4.51861,
            "contradiction": 0.43234,
            "irrelevancy": 0.73303,
            "logical_agreement": 98.83463,
            "grammar_ref": 4.60771,
            "grammar_hyp": 3.81886,
            "nubia_score": 0.89671
        },
        "meteor": 0.47681970506965704,
        "bertscore": {
            "precision": 0.98091,
            "recall": 0.9804,
            "f1": 0.98065
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3944": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.277613436819116,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5,
            "recall": 0.47727,
            "fmeasure": 0.4881
        },
        "rouge2": {
            "precision": 0.27778,
            "recall": 0.26667,
            "fmeasure": 0.27193
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.47727,
            "fmeasure": 0.4881
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.47727,
            "fmeasure": 0.4881
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5555555555555556
        },
        "nist": 2.0051680775472014,
        "bleu": 18.36028,
        "bleurt": 0.3274,
        "nubia": {
            "semantic_relation": 3.83498,
            "contradiction": 0.58579,
            "irrelevancy": 46.47985,
            "logical_agreement": 52.93436,
            "grammar_ref": 4.7527,
            "grammar_hyp": 4.57693,
            "nubia_score": 0.58744
        },
        "meteor": 0.3064082180560334,
        "bertscore": {
            "precision": 0.90816,
            "recall": 0.89984,
            "f1": 0.90398
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4050": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.12336199461765365,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.03310859910983796,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.52632,
            "recall": 0.61275,
            "fmeasure": 0.56614
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.26111,
            "fmeasure": 0.24005
        },
        "rougeL": {
            "precision": 0.35088,
            "recall": 0.40931,
            "fmeasure": 0.37778
        },
        "rougeLsum": {
            "precision": 0.35088,
            "recall": 0.40931,
            "fmeasure": 0.37778
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6923076923076923
        },
        "nist": 2.7229529717626044,
        "bleu": 14.51835,
        "bleurt": 0.23873,
        "nubia": {
            "semantic_relation": 3.81963,
            "contradiction": 0.0765,
            "irrelevancy": 2.0213,
            "logical_agreement": 97.9022,
            "grammar_ref": 5.85115,
            "grammar_hyp": 4.08589,
            "nubia_score": 0.84929
        },
        "meteor": 0.33169926589897514,
        "bertscore": {
            "precision": 0.88978,
            "recall": 0.87746,
            "f1": 0.88358
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4060": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 0.5,
        "median_pred_length": 18.5,
        "min_pred_length": 18,
        "max_pred_length": 19,
        "distinct-1": 0.7567567567567568,
        "vocab_size-1": 28,
        "unique-1": 22,
        "entropy-1": 4.625409028482011,
        "distinct-2": 0.9714285714285714,
        "vocab_size-2": 34,
        "unique-2": 33,
        "entropy-2": 5.072140159802107,
        "cond_entropy-2": 0.4229622362999259,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.02428283698045265,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8518518518518519,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.458591205867174,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.5638561897747225,
        "cond_entropy-2-nopunct": 0.12896868761125602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.03333771197858132,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80403,
            "recall": 0.92094,
            "fmeasure": 0.85814
        },
        "rouge2": {
            "precision": 0.64744,
            "recall": 0.77273,
            "fmeasure": 0.70455
        },
        "rougeL": {
            "precision": 0.70879,
            "recall": 0.83333,
            "fmeasure": 0.76603
        },
        "rougeLsum": {
            "precision": 0.70879,
            "recall": 0.83333,
            "fmeasure": 0.76603
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.9090909090909091
        },
        "nist": 3.2878081840755398,
        "bleu": 34.14144,
        "bleurt": -0.12049,
        "nubia": {
            "semantic_relation": 4.21278,
            "contradiction": 35.26995,
            "irrelevancy": 46.83404,
            "logical_agreement": 17.89601,
            "grammar_ref": 6.50157,
            "grammar_hyp": 6.39826,
            "nubia_score": 0.63049
        },
        "meteor": 0.43618777227608474,
        "bertscore": {
            "precision": 0.88047,
            "recall": 0.96419,
            "f1": 0.91893
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4320": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 26.5,
        "std_pred_length": 8.5,
        "median_pred_length": 26.5,
        "min_pred_length": 18,
        "max_pred_length": 35,
        "distinct-1": 0.5849056603773585,
        "vocab_size-1": 31,
        "unique-1": 16,
        "entropy-1": 4.779530595950171,
        "distinct-2": 0.7450980392156863,
        "vocab_size-2": 38,
        "unique-2": 26,
        "entropy-2": 5.147819704674177,
        "cond_entropy-2": 0.3662651816107855,
        "distinct-3": 0.7755102040816326,
        "vocab_size-3": 38,
        "unique-3": 27,
        "entropy-3": 5.165730252278474,
        "cond_entropy-3": 0.039323022596028503,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 7.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.5833333333333334,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.621115365169275,
        "distinct-2-nopunct": 0.717391304347826,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.941933966879545,
        "cond_entropy-2-nopunct": 0.3627249989081814,
        "distinct-3-nopunct": 0.75,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.9594316186372955,
        "cond_entropy-3-nopunct": 0.04393528762945417,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.94086,
            "recall": 0.91895,
            "fmeasure": 0.92926
        },
        "rouge2": {
            "precision": 0.81667,
            "recall": 0.79972,
            "fmeasure": 0.80769
        },
        "rougeL": {
            "precision": 0.77957,
            "recall": 0.76536,
            "fmeasure": 0.77205
        },
        "rougeLsum": {
            "precision": 0.77957,
            "recall": 0.76536,
            "fmeasure": 0.77205
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6,
            "3": 0.9714285714285714
        },
        "nist": 4.776359329158802,
        "bleu": 70.24315,
        "bleurt": 0.48566,
        "nubia": {
            "semantic_relation": 4.7347,
            "contradiction": 0.85546,
            "irrelevancy": 26.65186,
            "logical_agreement": 72.49268,
            "grammar_ref": 4.56621,
            "grammar_hyp": 4.40092,
            "nubia_score": 0.87228
        },
        "meteor": 0.48649131641062154,
        "bertscore": {
            "precision": 0.96423,
            "recall": 0.96329,
            "f1": 0.96176
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2148": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.084183719779189,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.17625665551219516,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.9057645846554525,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.19723710464117222,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85965,
            "recall": 0.68172,
            "fmeasure": 0.75979
        },
        "rouge2": {
            "precision": 0.53704,
            "recall": 0.42303,
            "fmeasure": 0.47287
        },
        "rougeL": {
            "precision": 0.59649,
            "recall": 0.45262,
            "fmeasure": 0.51429
        },
        "rougeLsum": {
            "precision": 0.59649,
            "recall": 0.45262,
            "fmeasure": 0.51429
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nist": 3.193440356062036,
        "bleu": 33.30287,
        "bleurt": 0.4853,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.37789,
            "irrelevancy": 0.52368,
            "logical_agreement": 99.09842,
            "grammar_ref": 3.26294,
            "grammar_hyp": 3.68712,
            "nubia_score": 0.96374
        },
        "meteor": 0.37656615956732437,
        "bertscore": {
            "precision": 0.92444,
            "recall": 0.88297,
            "f1": 0.90289
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2392": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 46,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 1.8856180831641267,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 18,
        "distinct-1": 0.391304347826087,
        "vocab_size-1": 18,
        "unique-1": 6,
        "entropy-1": 3.9353304337534993,
        "distinct-2": 0.5813953488372093,
        "vocab_size-2": 25,
        "unique-2": 17,
        "entropy-2": 4.355588010113545,
        "cond_entropy-2": 0.42048564763323387,
        "distinct-3": 0.725,
        "vocab_size-3": 29,
        "unique-3": 23,
        "entropy-3": 4.67756715711693,
        "cond_entropy-3": 0.3522799028475245,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 1.4142135623730951,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.3888888888888889,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 3.536758681457,
        "distinct-2-nopunct": 0.6060606060606061,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.998050937146914,
        "cond_entropy-2-nopunct": 0.513703587766083,
        "distinct-3-nopunct": 0.7333333333333333,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.272905595320056,
        "cond_entropy-3-nopunct": 0.2738248096795526,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.92208,
            "recall": 0.8303,
            "fmeasure": 0.8673
        },
        "rouge2": {
            "precision": 0.75385,
            "recall": 0.70192,
            "fmeasure": 0.72255
        },
        "rougeL": {
            "precision": 0.87446,
            "recall": 0.79798,
            "fmeasure": 0.82881
        },
        "rougeLsum": {
            "precision": 0.87446,
            "recall": 0.79798,
            "fmeasure": 0.82881
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6428571428571429,
            "3": 0.8888888888888888
        },
        "nist": 4.67498132340788,
        "bleu": 70.37577,
        "bleurt": 0.66863,
        "nubia": {
            "semantic_relation": 4.83482,
            "contradiction": 32.3902,
            "irrelevancy": 1.67838,
            "logical_agreement": 65.93141,
            "grammar_ref": 4.141,
            "grammar_hyp": 4.26502,
            "nubia_score": 0.90468
        },
        "meteor": 0.47430057109689056,
        "bertscore": {
            "precision": 0.97036,
            "recall": 0.9601,
            "f1": 0.96498
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2400": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.63636,
            "fmeasure": 0.6087
        },
        "rouge2": {
            "precision": 0.27273,
            "recall": 0.3,
            "fmeasure": 0.28571
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.45455,
            "fmeasure": 0.43478
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.45455,
            "fmeasure": 0.43478
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.6
        },
        "nist": 2.299874760174743,
        "bleu": 11.49876,
        "bleurt": 0.17948,
        "nubia": {
            "semantic_relation": 4.39702,
            "contradiction": 0.80279,
            "irrelevancy": 98.15424,
            "logical_agreement": 1.04297,
            "grammar_ref": 5.42176,
            "grammar_hyp": 4.74385,
            "nubia_score": 0.75667
        },
        "meteor": 0.30407419704668404,
        "bertscore": {
            "precision": 0.88212,
            "recall": 0.91801,
            "f1": 0.89971
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4340": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.76263,
            "fmeasure": 0.79444
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.3375,
            "fmeasure": 0.35417
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.51515,
            "fmeasure": 0.53333
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.51515,
            "fmeasure": 0.53333
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 1.0
        },
        "nist": 3.434696101844569,
        "bleu": 36.55552,
        "bleurt": 0.49672,
        "nubia": {
            "semantic_relation": 4.94226,
            "contradiction": 0.10502,
            "irrelevancy": 2.09987,
            "logical_agreement": 97.79511,
            "grammar_ref": 5.60099,
            "grammar_hyp": 5.83881,
            "nubia_score": 0.9529
        },
        "meteor": 0.3911506824473873,
        "bertscore": {
            "precision": 0.90723,
            "recall": 0.92449,
            "f1": 0.91577
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2422": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322734,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86111,
            "recall": 0.66214,
            "fmeasure": 0.74575
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.5,
            "fmeasure": 0.56897
        },
        "rougeL": {
            "precision": 0.86111,
            "recall": 0.66214,
            "fmeasure": 0.74575
        },
        "rougeLsum": {
            "precision": 0.86111,
            "recall": 0.66214,
            "fmeasure": 0.74575
        },
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.7
        },
        "nist": 2.460877066081187,
        "bleu": 31.60942,
        "bleurt": 0.09037,
        "nubia": {
            "semantic_relation": 4.13175,
            "contradiction": 5.11621,
            "irrelevancy": 58.80018,
            "logical_agreement": 36.08361,
            "grammar_ref": 5.01319,
            "grammar_hyp": 4.77291,
            "nubia_score": 0.64306
        },
        "meteor": 0.34961682015412276,
        "bertscore": {
            "precision": 0.96082,
            "recall": 0.91957,
            "f1": 0.93535
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2490": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8095238095238095,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 3.9161269465882835,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.42961067210860193,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185188,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.25,
            "recall": 0.12903,
            "fmeasure": 0.17021
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.1875,
            "recall": 0.09677,
            "fmeasure": 0.12766
        },
        "rougeLsum": {
            "precision": 0.1875,
            "recall": 0.09677,
            "fmeasure": 0.12766
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.21428571428571427,
            "3": 0.1111111111111111
        },
        "nist": 1.3559472423157046,
        "bleu": 5.13666,
        "bleurt": -0.73286,
        "nubia": {
            "semantic_relation": 1.56415,
            "contradiction": 54.49542,
            "irrelevancy": 44.2061,
            "logical_agreement": 1.29847,
            "grammar_ref": 4.34568,
            "grammar_hyp": 3.44184,
            "nubia_score": 0.11438
        },
        "meteor": 0.08442784526435636,
        "bertscore": {
            "precision": 0.8153,
            "recall": 0.78345,
            "f1": 0.78295
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4352": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.0433214693062285,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.75,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.90909,
            "recall": 0.66667,
            "fmeasure": 0.76923
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.75,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.75,
            "fmeasure": 0.85714
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.7692307692307693
        },
        "nist": 3.8409079073408483,
        "bleu": 81.96501,
        "bleurt": 0.60851,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29298,
            "irrelevancy": 4.9324,
            "logical_agreement": 94.77463,
            "grammar_ref": 4.10709,
            "grammar_hyp": 4.57073,
            "nubia_score": 0.97421
        },
        "meteor": 0.4966624063624693,
        "bertscore": {
            "precision": 0.98659,
            "recall": 0.94382,
            "f1": 0.96473
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5082": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.8963,
            "fmeasure": 0.79942
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.4213,
            "fmeasure": 0.37193
        },
        "rougeL": {
            "precision": 0.63889,
            "recall": 0.79259,
            "fmeasure": 0.70707
        },
        "rougeLsum": {
            "precision": 0.63889,
            "recall": 0.79259,
            "fmeasure": 0.70707
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.875
        },
        "nist": 3.038485661251777,
        "bleu": 27.62935,
        "bleurt": 0.22323,
        "nubia": {
            "semantic_relation": 4.34536,
            "contradiction": 0.38822,
            "irrelevancy": 93.49285,
            "logical_agreement": 6.11894,
            "grammar_ref": 4.96639,
            "grammar_hyp": 5.77914,
            "nubia_score": 0.56712
        },
        "meteor": 0.42856343508545097,
        "bertscore": {
            "precision": 0.90112,
            "recall": 0.91088,
            "f1": 0.90597
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2640": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.72727,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.4,
            "fmeasure": 0.44444
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6363636363636364
        },
        "nist": 2.4929182263680483,
        "bleu": 19.43406,
        "bleurt": 0.5593,
        "nubia": {
            "semantic_relation": 4.25211,
            "contradiction": 0.57776,
            "irrelevancy": 0.52541,
            "logical_agreement": 98.89683,
            "grammar_ref": 5.20642,
            "grammar_hyp": 4.57554,
            "nubia_score": 0.83281
        },
        "meteor": 0.38388402914845343,
        "bertscore": {
            "precision": 0.96843,
            "recall": 0.92985,
            "f1": 0.94875
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5094": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.5291,
            "fmeasure": 0.45408
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.81667,
            "fmeasure": 0.71345
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.81667,
            "fmeasure": 0.71345
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.875
        },
        "nist": 2.4503518615750686,
        "bleu": 35.0844,
        "bleurt": 0.65602,
        "nubia": {
            "semantic_relation": 4.80212,
            "contradiction": 0.31869,
            "irrelevancy": 34.70753,
            "logical_agreement": 64.97379,
            "grammar_ref": 4.01433,
            "grammar_hyp": 3.8335,
            "nubia_score": 0.94237
        },
        "meteor": 0.48443287216470526,
        "bertscore": {
            "precision": 0.91568,
            "recall": 0.95615,
            "f1": 0.93548
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2667": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 8.5,
        "std_pred_length": 0.5,
        "median_pred_length": 8.5,
        "min_pred_length": 8,
        "max_pred_length": 9,
        "distinct-1": 0.7058823529411765,
        "vocab_size-1": 12,
        "unique-1": 7,
        "entropy-1": 3.4992275471326932,
        "distinct-2": 0.8,
        "vocab_size-2": 12,
        "unique-2": 9,
        "entropy-2": 3.506890595608518,
        "cond_entropy-2": -0.047238912308487514,
        "distinct-3": 0.8461538461538461,
        "vocab_size-3": 11,
        "unique-3": 9,
        "entropy-3": 3.3927474104487847,
        "cond_entropy-3": -0.05260472362127269,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 7.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 7.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.7333333333333333,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.3735572622751846,
        "distinct-2-nopunct": 0.7692307692307693,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 3.238901256602631,
        "cond_entropy-2-nopunct": -0.05260472362127269,
        "distinct-3-nopunct": 0.8181818181818182,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 3.0957952550009344,
        "cond_entropy-3-nopunct": -0.05918991768561316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.78384,
            "fmeasure": 0.87473
        },
        "rouge2": {
            "precision": 0.84524,
            "recall": 0.64352,
            "fmeasure": 0.72639
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.78384,
            "fmeasure": 0.87473
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.78384,
            "fmeasure": 0.87473
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.8235294117647058
        },
        "nist": 3.3475106969243034,
        "bleu": 60.57479,
        "bleurt": 0.76635,
        "nubia": {
            "semantic_relation": 4.83788,
            "contradiction": 0.59678,
            "irrelevancy": 0.53861,
            "logical_agreement": 98.86461,
            "grammar_ref": 4.57714,
            "grammar_hyp": 4.90481,
            "nubia_score": 0.9704
        },
        "meteor": 0.4684327774899376,
        "bertscore": {
            "precision": 0.99164,
            "recall": 0.9597,
            "f1": 0.97395
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5166": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.4,
            "recall": 0.35354,
            "fmeasure": 0.37518
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.19394,
            "fmeasure": 0.20702
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.35354,
            "fmeasure": 0.37518
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.35354,
            "fmeasure": 0.37518
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.2222222222222222
        },
        "nist": 0.9313738634396848,
        "bleu": 8.29519,
        "bleurt": -0.53575,
        "nubia": {
            "semantic_relation": 2.78899,
            "contradiction": 0.29727,
            "irrelevancy": 97.22608,
            "logical_agreement": 2.47665,
            "grammar_ref": 4.79209,
            "grammar_hyp": 3.90146,
            "nubia_score": 0.40056
        },
        "meteor": 0.2331715255855191,
        "bertscore": {
            "precision": 0.79602,
            "recall": 0.78154,
            "f1": 0.78871
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6225": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 1.0,
        "vocab_size-1": 20,
        "unique-1": 20,
        "entropy-1": 4.321928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.07400058144377676,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.40351,
            "recall": 0.36508,
            "fmeasure": 0.38333
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.15,
            "fmeasure": 0.15789
        },
        "rougeL": {
            "precision": 0.36842,
            "recall": 0.33333,
            "fmeasure": 0.35
        },
        "rougeLsum": {
            "precision": 0.36842,
            "recall": 0.33333,
            "fmeasure": 0.35
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.0,
            "3": 0.5454545454545454
        },
        "nist": 1.88835474061159,
        "bleu": 6.98196,
        "bleurt": 0.27193,
        "nubia": {
            "semantic_relation": 3.29705,
            "contradiction": 91.5301,
            "irrelevancy": 8.24065,
            "logical_agreement": 0.22924,
            "grammar_ref": 3.9898,
            "grammar_hyp": 4.40587,
            "nubia_score": 0.37295
        },
        "meteor": 0.24583434156987158,
        "bertscore": {
            "precision": 0.89747,
            "recall": 0.85813,
            "f1": 0.8737
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2681": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.4182958340544896,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432272,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.1219280948873624,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7,
            "recall": 0.40414,
            "fmeasure": 0.51235
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.12255,
            "fmeasure": 0.15795
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.34641,
            "fmeasure": 0.43915
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.34641,
            "fmeasure": 0.43915
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.35294117647058826
        },
        "nist": 0.6424118222294133,
        "bleu": 7.39488,
        "bleurt": 0.08363,
        "nubia": {
            "semantic_relation": 3.71509,
            "contradiction": 0.30494,
            "irrelevancy": 1.03727,
            "logical_agreement": 98.65779,
            "grammar_ref": 4.84215,
            "grammar_hyp": 5.71535,
            "nubia_score": 0.45137
        },
        "meteor": 0.20330360684439092,
        "bertscore": {
            "precision": 0.90575,
            "recall": 0.86147,
            "f1": 0.88305
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5360": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81481,
            "recall": 0.61481,
            "fmeasure": 0.68876
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.37473,
            "fmeasure": 0.42039
        },
        "rougeL": {
            "precision": 0.7037,
            "recall": 0.52963,
            "fmeasure": 0.59389
        },
        "rougeLsum": {
            "precision": 0.7037,
            "recall": 0.52963,
            "fmeasure": 0.59389
        },
        "local_recall": {
            "1": 0,
            "2": 0.14285714285714285,
            "3": 0.7
        },
        "nist": 1.140204368901255,
        "bleu": 37.25177,
        "bleurt": 0.33005,
        "nubia": {
            "semantic_relation": 3.90425,
            "contradiction": 0.23632,
            "irrelevancy": 2.91639,
            "logical_agreement": 96.84729,
            "grammar_ref": 3.74426,
            "grammar_hyp": 3.79136,
            "nubia_score": 0.72975
        },
        "meteor": 0.32661173471612,
        "bertscore": {
            "precision": 0.95956,
            "recall": 0.90472,
            "f1": 0.93133
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-large (Baseline)/e2e_nlg_test",
        "N": 389,
        "msttr-100": 0.30054,
        "msttr-100_nopunct": 0.29896,
        "total_length": 7475,
        "mean_pred_length": 19.215938303341904,
        "std_pred_length": 5.941415180825971,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 40,
        "distinct-1": 0.03036789297658863,
        "vocab_size-1": 227,
        "unique-1": 34,
        "entropy-1": 6.147883396223749,
        "distinct-2": 0.09342365227208581,
        "vocab_size-2": 662,
        "unique-2": 164,
        "entropy-2": 7.949069042799572,
        "cond_entropy-2": 1.668525367055366,
        "distinct-3": 0.14857398835299387,
        "vocab_size-3": 995,
        "unique-3": 312,
        "entropy-3": 8.803406295343828,
        "cond_entropy-3": 0.8575792385243942,
        "total_length-nopunct": 6740,
        "mean_pred_length-nopunct": 17.326478149100257,
        "std_pred_length-nopunct": 5.334935370880913,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.03323442136498516,
        "vocab_size-1-nopunct": 224,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 6.238732357806546,
        "distinct-2-nopunct": 0.09699259959061565,
        "vocab_size-2-nopunct": 616,
        "unique-2-nopunct": 149,
        "entropy-2-nopunct": 7.881079123866344,
        "cond_entropy-2-nopunct": 1.7052811745428107,
        "distinct-3-nopunct": 0.15431063401543108,
        "vocab_size-3-nopunct": 920,
        "unique-3-nopunct": 282,
        "entropy-3-nopunct": 8.767926490277855,
        "cond_entropy-3-nopunct": 0.8821657553125276,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.66145,
            "recall": 0.66529,
            "fmeasure": 0.64351
        },
        "rouge2": {
            "precision": 0.39335,
            "recall": 0.3955,
            "fmeasure": 0.38154
        },
        "rougeL": {
            "precision": 0.51026,
            "recall": 0.51062,
            "fmeasure": 0.49494
        },
        "rougeLsum": {
            "precision": 0.51026,
            "recall": 0.51062,
            "fmeasure": 0.49494
        },
        "local_recall": {
            "1": 0.6446576679134819
        },
        "nist": 4.275053849384718,
        "bleu": 26.39924,
        "bleurt": 0.04059,
        "nubia": {
            "semantic_relation": 3.97908,
            "contradiction": 4.6364,
            "irrelevancy": 39.13192,
            "logical_agreement": 56.23167,
            "grammar_ref": 5.31197,
            "grammar_hyp": 4.74498,
            "nubia_score": 0.69437
        },
        "meteor": 0.3305657650187123,
        "bertscore": {
            "precision": 0.89995,
            "recall": 0.89674,
            "f1": 0.89777
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2682": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.11768784439846629,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.40741,
            "recall": 0.49841,
            "fmeasure": 0.44823
        },
        "rouge2": {
            "precision": 0.07843,
            "recall": 0.09524,
            "fmeasure": 0.08602
        },
        "rougeL": {
            "precision": 0.35185,
            "recall": 0.43932,
            "fmeasure": 0.39036
        },
        "rougeLsum": {
            "precision": 0.35185,
            "recall": 0.43932,
            "fmeasure": 0.39036
        },
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.0,
            "3": 0.5
        },
        "nist": 2.864545766267946,
        "bleu": 11.63901,
        "bleurt": -0.03301,
        "nubia": {
            "semantic_relation": 3.47333,
            "contradiction": 0.25109,
            "irrelevancy": 56.33228,
            "logical_agreement": 43.41663,
            "grammar_ref": 4.11472,
            "grammar_hyp": 3.23787,
            "nubia_score": 0.6727
        },
        "meteor": 0.3191110055054909,
        "bertscore": {
            "precision": 0.84228,
            "recall": 0.86755,
            "f1": 0.85473
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2718": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.3219280948873626,
        "bleu": 100.0,
        "bleurt": 0.97683,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29478,
            "irrelevancy": 0.49577,
            "logical_agreement": 99.20945,
            "grammar_ref": 4.98947,
            "grammar_hyp": 4.98947,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2205": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8,
            "recall": 0.66667,
            "fmeasure": 0.72727
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.2,
            "fmeasure": 0.22222
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.66667,
            "fmeasure": 0.72727
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.66667,
            "fmeasure": 0.72727
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "nist": 2.0213518032398983,
        "bleu": 20.548,
        "bleurt": 0.50917,
        "nubia": {
            "semantic_relation": 3.97787,
            "contradiction": 13.04341,
            "irrelevancy": 1.72989,
            "logical_agreement": 85.22669,
            "grammar_ref": 6.21263,
            "grammar_hyp": 7.71397,
            "nubia_score": 0.47877
        },
        "meteor": 0.39900870824544665,
        "bertscore": {
            "precision": 0.96529,
            "recall": 0.93699,
            "f1": 0.95093
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2884": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.30769,
            "recall": 0.26667,
            "fmeasure": 0.28571
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.07143,
            "fmeasure": 0.07692
        },
        "rougeL": {
            "precision": 0.23077,
            "recall": 0.2,
            "fmeasure": 0.21429
        },
        "rougeLsum": {
            "precision": 0.23077,
            "recall": 0.2,
            "fmeasure": 0.21429
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333
        },
        "nist": 1.3251132139617805,
        "bleu": 6.19108,
        "bleurt": -0.36261,
        "nubia": {
            "semantic_relation": 2.1379,
            "contradiction": 2.33324,
            "irrelevancy": 97.29278,
            "logical_agreement": 0.37398,
            "grammar_ref": 5.48676,
            "grammar_hyp": 4.98434,
            "nubia_score": 0.16718
        },
        "meteor": 0.14931313041983682,
        "bertscore": {
            "precision": 0.80397,
            "recall": 0.79024,
            "f1": 0.79647
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6643": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 5,
        "mean_pred_length": 5.0,
        "std_pred_length": 0.0,
        "median_pred_length": 5.0,
        "min_pred_length": 5,
        "max_pred_length": 5,
        "distinct-1": 1.0,
        "vocab_size-1": 5,
        "unique-1": 5,
        "entropy-1": 2.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 4,
        "unique-2": 4,
        "entropy-2": 2.0,
        "cond_entropy-2": -0.32192809488736235,
        "distinct-3": 1.0,
        "vocab_size-3": 3,
        "unique-3": 3,
        "entropy-3": 1.584962500721156,
        "cond_entropy-3": -0.4150374992788437,
        "total_length-nopunct": 4,
        "mean_pred_length-nopunct": 4.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 4.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 4,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 4,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 2.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 3,
        "unique-2-nopunct": 3,
        "entropy-2-nopunct": 1.584962500721156,
        "cond_entropy-2-nopunct": -0.4150374992788437,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 2,
        "unique-3-nopunct": 2,
        "entropy-3-nopunct": 1.0,
        "cond_entropy-3-nopunct": -0.5849625007211562,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.2,
            "fmeasure": 0.25
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "nist": 1.3934338964335204,
        "bleu": 28.6419,
        "bleurt": 0.82527,
        "nubia": {
            "semantic_relation": 4.93787,
            "contradiction": 0.30154,
            "irrelevancy": 0.49604,
            "logical_agreement": 99.20242,
            "grammar_ref": 5.72796,
            "grammar_hyp": 7.07513,
            "nubia_score": 0.79132
        },
        "meteor": 0.4307001776843669,
        "bertscore": {
            "precision": 0.97397,
            "recall": 0.93815,
            "f1": 0.95573
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-10": {
        "predictions_file": "T5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.74048,
        "msttr-100_nopunct": 0.75895,
        "total_length": 2133,
        "mean_pred_length": 20.12264150943396,
        "std_pred_length": 4.863617005986232,
        "median_pred_length": 19.0,
        "min_pred_length": 11,
        "max_pred_length": 38,
        "distinct-1": 0.4411626816690108,
        "vocab_size-1": 941,
        "unique-1": 747,
        "entropy-1": 8.34636438100027,
        "distinct-2": 0.8618648248643315,
        "vocab_size-2": 1747,
        "unique-2": 1623,
        "entropy-2": 10.573940141489155,
        "cond_entropy-2": 2.021610506811182,
        "distinct-3": 0.9703279541905258,
        "vocab_size-3": 1864,
        "unique-3": 1827,
        "entropy-3": 10.837399379422704,
        "cond_entropy-3": 0.27073488817613417,
        "total_length-nopunct": 1987,
        "mean_pred_length-nopunct": 18.745283018867923,
        "std_pred_length-nopunct": 4.58681728919178,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.4695520885757423,
        "vocab_size-1-nopunct": 933,
        "unique-1-nopunct": 743,
        "entropy-1-nopunct": 8.47853673848307,
        "distinct-2-nopunct": 0.860180754917597,
        "vocab_size-2-nopunct": 1618,
        "unique-2-nopunct": 1503,
        "entropy-2-nopunct": 10.456700363059456,
        "cond_entropy-2-nopunct": 2.076762849207763,
        "distinct-3-nopunct": 0.9701408450704225,
        "vocab_size-3-nopunct": 1722,
        "unique-3-nopunct": 1687,
        "entropy-3-nopunct": 10.723217001127304,
        "cond_entropy-3-nopunct": 0.2840321459963742,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.3696,
            "recall": 0.33084,
            "fmeasure": 0.34107
        },
        "rouge2": {
            "precision": 0.13625,
            "recall": 0.1179,
            "fmeasure": 0.12411
        },
        "rougeL": {
            "precision": 0.30564,
            "recall": 0.27203,
            "fmeasure": 0.28116
        },
        "rougeLsum": {
            "precision": 0.30564,
            "recall": 0.27203,
            "fmeasure": 0.28116
        },
        "local_recall": {
            "1": 0.3030155642023346
        },
        "nist": 2.830582142027058,
        "bleu": 8.29496,
        "bleurt": -0.44216,
        "nubia": {
            "semantic_relation": 2.6322,
            "contradiction": 21.55427,
            "irrelevancy": 66.84995,
            "logical_agreement": 11.59578,
            "grammar_ref": 3.93729,
            "grammar_hyp": 3.69643,
            "nubia_score": 0.36651
        },
        "meteor": 0.1433595093393415,
        "bertscore": {
            "precision": 0.82464,
            "recall": 0.80972,
            "f1": 0.81685
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8082": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.61538,
            "recall": 0.66667,
            "fmeasure": 0.64
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.36364,
            "fmeasure": 0.34783
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.5,
            "fmeasure": 0.48
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.5,
            "fmeasure": 0.48
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "nist": 2.1020431467184912,
        "bleu": 26.51812,
        "bleurt": 0.28729,
        "nubia": {
            "semantic_relation": 4.50565,
            "contradiction": 0.49696,
            "irrelevancy": 21.17486,
            "logical_agreement": 78.32819,
            "grammar_ref": 4.44512,
            "grammar_hyp": 3.63039,
            "nubia_score": 0.91644
        },
        "meteor": 0.3723909204837073,
        "bertscore": {
            "precision": 0.87796,
            "recall": 0.91968,
            "f1": 0.89834
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2232": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.06903423794455239,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.07400058144377676,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.4127,
            "recall": 0.42088,
            "fmeasure": 0.41582
        },
        "rouge2": {
            "precision": 0.23333,
            "recall": 0.24206,
            "fmeasure": 0.23668
        },
        "rougeL": {
            "precision": 0.28571,
            "recall": 0.3262,
            "fmeasure": 0.30355
        },
        "rougeLsum": {
            "precision": 0.28571,
            "recall": 0.3262,
            "fmeasure": 0.30355
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.3333333333333333,
            "3": 0.4444444444444444
        },
        "nist": 2.4637029965361172,
        "bleu": 19.04255,
        "bleurt": -0.77064,
        "nubia": {
            "semantic_relation": 2.93848,
            "contradiction": 76.63954,
            "irrelevancy": 21.87157,
            "logical_agreement": 1.48888,
            "grammar_ref": 5.24053,
            "grammar_hyp": 5.42886,
            "nubia_score": 0.33985
        },
        "meteor": 0.19799318630345542,
        "bertscore": {
            "precision": 0.82687,
            "recall": 0.8714,
            "f1": 0.84323
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2233": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "rouge2": {
            "precision": 0.85,
            "recall": 0.81818,
            "fmeasure": 0.83333
        },
        "rougeL": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "rougeLsum": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "nist": 3.354990287206174,
        "bleu": 69.97522,
        "bleurt": 0.72733,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.37452,
            "irrelevancy": 0.52123,
            "logical_agreement": 99.10425,
            "grammar_ref": 4.19853,
            "grammar_hyp": 3.27977,
            "nubia_score": 1.0
        },
        "meteor": 0.5740797318313066,
        "bertscore": {
            "precision": 0.95106,
            "recall": 0.98284,
            "f1": 0.96669
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8822": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 3.0,
        "median_pred_length": 11.0,
        "min_pred_length": 8,
        "max_pred_length": 14,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 18,
        "unique-1": 14,
        "entropy-1": 4.095795255000932,
        "distinct-2": 0.95,
        "vocab_size-2": 19,
        "unique-2": 18,
        "entropy-2": 4.221928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.04089198233393864,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.021928094887363,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.058813890331201,
        "cond_entropy-2-nopunct": 0.014663573221616898,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.10742500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.63095,
            "recall": 0.67593,
            "fmeasure": 0.62745
        },
        "rouge2": {
            "precision": 0.26923,
            "recall": 0.21528,
            "fmeasure": 0.23404
        },
        "rougeL": {
            "precision": 0.5119,
            "recall": 0.55185,
            "fmeasure": 0.51066
        },
        "rougeLsum": {
            "precision": 0.5119,
            "recall": 0.55185,
            "fmeasure": 0.51066
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.75,
            "3": 0.6
        },
        "nist": 2.8793425284587184,
        "bleu": 12.65068,
        "bleurt": 0.15058,
        "nubia": {
            "semantic_relation": 3.76129,
            "contradiction": 2.20628,
            "irrelevancy": 86.45199,
            "logical_agreement": 11.34173,
            "grammar_ref": 5.12311,
            "grammar_hyp": 5.01767,
            "nubia_score": 0.52382
        },
        "meteor": 0.324532178816341,
        "bertscore": {
            "precision": 0.88065,
            "recall": 0.87912,
            "f1": 0.87849
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2940": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.5769230769230769,
        "vocab_size-1": 15,
        "unique-1": 4,
        "entropy-1": 3.854285871987246,
        "distinct-2": 0.5833333333333334,
        "vocab_size-2": 14,
        "unique-2": 4,
        "entropy-2": 3.751629167387823,
        "cond_entropy-2": -0.11547721741993588,
        "distinct-3": 0.5909090909090909,
        "vocab_size-3": 13,
        "unique-3": 4,
        "entropy-3": 3.6412498004554794,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.5909090909090909,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 3.6412498004554794,
        "distinct-2-nopunct": 0.6,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 3.521928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 0.6111111111111112,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 3.392147223664534,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.854285871987245,
        "bleu": 100.0,
        "bleurt": 0.94692,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.32615,
            "irrelevancy": 0.47325,
            "logical_agreement": 99.2006,
            "grammar_ref": 5.00662,
            "grammar_hyp": 5.00662,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2247": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 10.333333333333334,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 11,
        "distinct-1": 0.5806451612903226,
        "vocab_size-1": 18,
        "unique-1": 10,
        "entropy-1": 3.9937305842314763,
        "distinct-2": 0.7142857142857143,
        "vocab_size-2": 20,
        "unique-2": 14,
        "entropy-2": 4.182005814760214,
        "cond_entropy-2": 0.12136486182526234,
        "distinct-3": 0.84,
        "vocab_size-3": 21,
        "unique-3": 17,
        "entropy-3": 4.323856189774722,
        "cond_entropy-3": 0.02669676780365919,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 8.666666666666666,
        "std_pred_length-nopunct": 0.4714045207910317,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.6153846153846154,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.8150724101159423,
        "distinct-2-nopunct": 0.782608695652174,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 4.0559581516151235,
        "cond_entropy-2-nopunct": 0.1496341946257877,
        "distinct-3-nopunct": 0.9,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.1219280948873624,
        "cond_entropy-3-nopunct": 0.03611051393852278,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85859,
            "recall": 0.74151,
            "fmeasure": 0.78513
        },
        "rouge2": {
            "precision": 0.69877,
            "recall": 0.61049,
            "fmeasure": 0.64259
        },
        "rougeL": {
            "precision": 0.85859,
            "recall": 0.74151,
            "fmeasure": 0.78513
        },
        "rougeLsum": {
            "precision": 0.85859,
            "recall": 0.74151,
            "fmeasure": 0.78513
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.6666666666666666
        },
        "nist": 3.1018362371662342,
        "bleu": 47.4867,
        "bleurt": 0.22034,
        "nubia": {
            "semantic_relation": 3.8152,
            "contradiction": 83.53638,
            "irrelevancy": 12.2136,
            "logical_agreement": 4.25002,
            "grammar_ref": 4.42296,
            "grammar_hyp": 4.61484,
            "nubia_score": 0.52393
        },
        "meteor": 0.43106084479327345,
        "bertscore": {
            "precision": 0.95331,
            "recall": 0.91586,
            "f1": 0.93263
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2960": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7,
            "recall": 0.79545,
            "fmeasure": 0.74074
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.60119,
            "fmeasure": 0.53431
        },
        "rougeL": {
            "precision": 0.63333,
            "recall": 0.76852,
            "fmeasure": 0.69396
        },
        "rougeLsum": {
            "precision": 0.63333,
            "recall": 0.76852,
            "fmeasure": 0.69396
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8
        },
        "nist": 2.573335161354208,
        "bleu": 28.99784,
        "bleurt": -0.40575,
        "nubia": {
            "semantic_relation": 2.49111,
            "contradiction": 23.11552,
            "irrelevancy": 74.93293,
            "logical_agreement": 1.95155,
            "grammar_ref": 3.66596,
            "grammar_hyp": 4.48074,
            "nubia_score": 0.23506
        },
        "meteor": 0.35544347173293367,
        "bertscore": {
            "precision": 0.83406,
            "recall": 0.89226,
            "f1": 0.86218
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2248": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.4182958340544896,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432272,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.277613436819116,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.83333,
            "fmeasure": 0.86957
        },
        "rouge2": {
            "precision": 0.8,
            "recall": 0.72727,
            "fmeasure": 0.7619
        },
        "rougeL": {
            "precision": 0.90909,
            "recall": 0.83333,
            "fmeasure": 0.86957
        },
        "rougeLsum": {
            "precision": 0.90909,
            "recall": 0.83333,
            "fmeasure": 0.86957
        },
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.7777777777777778
        },
        "nist": 2.9254129356891743,
        "bleu": 46.17366,
        "bleurt": -0.22476,
        "nubia": {
            "semantic_relation": 3.84684,
            "contradiction": 21.47097,
            "irrelevancy": 73.42104,
            "logical_agreement": 5.10799,
            "grammar_ref": 4.85772,
            "grammar_hyp": 5.36114,
            "nubia_score": 0.44411
        },
        "meteor": 0.46025929695794054,
        "bertscore": {
            "precision": 0.9376,
            "recall": 0.89313,
            "f1": 0.91483
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8946": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.88889,
            "fmeasure": 0.94118
        },
        "rouge2": {
            "precision": 0.85714,
            "recall": 0.75,
            "fmeasure": 0.8
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.88889,
            "fmeasure": 0.94118
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.88889,
            "fmeasure": 0.94118
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8888888888888888
        },
        "nist": 3.4723355925730734,
        "bleu": 74.26141,
        "bleurt": 0.70747,
        "nubia": {
            "semantic_relation": 4.86369,
            "contradiction": 1.31576,
            "irrelevancy": 0.75386,
            "logical_agreement": 97.93038,
            "grammar_ref": 5.69157,
            "grammar_hyp": 5.49013,
            "nubia_score": 0.91027
        },
        "meteor": 0.5112614165460022,
        "bertscore": {
            "precision": 0.97734,
            "recall": 0.95629,
            "f1": 0.9667
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2976": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.702819531114783,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.22388309575274976,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.589898095464287,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.24009914803219054,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.39583,
            "recall": 0.62698,
            "fmeasure": 0.47826
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.42424,
            "fmeasure": 0.2674
        },
        "rougeL": {
            "precision": 0.29167,
            "recall": 0.46825,
            "fmeasure": 0.35404
        },
        "rougeLsum": {
            "precision": 0.29167,
            "recall": 0.46825,
            "fmeasure": 0.35404
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.75
        },
        "nist": 1.6650834702511912,
        "bleu": 8.80464,
        "bleurt": -1.06326,
        "nubia": {
            "semantic_relation": 3.29298,
            "contradiction": 6.23352,
            "irrelevancy": 72.44704,
            "logical_agreement": 21.31945,
            "grammar_ref": 6.44614,
            "grammar_hyp": 5.04521,
            "nubia_score": 0.3723
        },
        "meteor": 0.2618695595037368,
        "bertscore": {
            "precision": 0.8356,
            "recall": 0.90076,
            "f1": 0.84647
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_10500": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.2776134368191165,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.5216406363433186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.055725754669781344,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.77381,
            "fmeasure": 0.74176
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.45,
            "fmeasure": 0.43182
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.61905,
            "fmeasure": 0.59341
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.61905,
            "fmeasure": 0.59341
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.8
        },
        "nist": 1.8343917425288474,
        "bleu": 10.25229,
        "bleurt": 0.37844,
        "nubia": {
            "semantic_relation": 4.92175,
            "contradiction": 0.37641,
            "irrelevancy": 24.61773,
            "logical_agreement": 75.00586,
            "grammar_ref": 7.77345,
            "grammar_hyp": 5.70476,
            "nubia_score": 1.0
        },
        "meteor": 0.3948771435487059,
        "bertscore": {
            "precision": 0.88359,
            "recall": 0.91095,
            "f1": 0.89706
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3000": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518525,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.2178561159133974,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5,
            "recall": 0.43333,
            "fmeasure": 0.46429
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.07143,
            "fmeasure": 0.07692
        },
        "rougeL": {
            "precision": 0.23077,
            "recall": 0.2,
            "fmeasure": 0.21429
        },
        "rougeLsum": {
            "precision": 0.23077,
            "recall": 0.2,
            "fmeasure": 0.21429
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.4444444444444444
        },
        "nist": 1.5865806347427995,
        "bleu": 3.97795,
        "bleurt": -0.42423,
        "nubia": {
            "semantic_relation": 3.43037,
            "contradiction": 1.99908,
            "irrelevancy": 57.02246,
            "logical_agreement": 40.97846,
            "grammar_ref": 5.62728,
            "grammar_hyp": 4.7571,
            "nubia_score": 0.52428
        },
        "meteor": 0.23063844302841777,
        "bertscore": {
            "precision": 0.85821,
            "recall": 0.87266,
            "f1": 0.86538
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_13590": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 4.0,
        "median_pred_length": 12.0,
        "min_pred_length": 8,
        "max_pred_length": 16,
        "distinct-1": 0.75,
        "vocab_size-1": 18,
        "unique-1": 13,
        "entropy-1": 4.053508854797679,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.3101492315852843,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.7894736842105263,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.8268748818646365,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.2513000336891068,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.18057224564182078,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.69524,
            "recall": 0.79861,
            "fmeasure": 0.71815
        },
        "rouge2": {
            "precision": 0.34524,
            "recall": 0.44778,
            "fmeasure": 0.37375
        },
        "rougeL": {
            "precision": 0.60159,
            "recall": 0.71938,
            "fmeasure": 0.63172
        },
        "rougeLsum": {
            "precision": 0.60159,
            "recall": 0.71938,
            "fmeasure": 0.63172
        },
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.6428571428571429,
            "3": 1.0
        },
        "nist": 2.776031893386586,
        "bleu": 25.12873,
        "bleurt": 0.18339,
        "nubia": {
            "semantic_relation": 4.08626,
            "contradiction": 16.81626,
            "irrelevancy": 24.44824,
            "logical_agreement": 58.7355,
            "grammar_ref": 5.40028,
            "grammar_hyp": 5.14271,
            "nubia_score": 0.68921
        },
        "meteor": 0.4074907069384767,
        "bertscore": {
            "precision": 0.84468,
            "recall": 0.89938,
            "f1": 0.86698
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3008": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.92857,
            "recall": 0.87395,
            "fmeasure": 0.89862
        },
        "rouge2": {
            "precision": 0.82051,
            "recall": 0.77244,
            "fmeasure": 0.79399
        },
        "rougeL": {
            "precision": 0.92857,
            "recall": 0.87395,
            "fmeasure": 0.89862
        },
        "rougeLsum": {
            "precision": 0.92857,
            "recall": 0.87395,
            "fmeasure": 0.89862
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9285714285714286
        },
        "nist": 4.049748410536706,
        "bleu": 80.03203,
        "bleurt": 0.68335,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.30843,
            "irrelevancy": 0.40659,
            "logical_agreement": 99.28498,
            "grammar_ref": 5.90677,
            "grammar_hyp": 6.88493,
            "nubia_score": 0.82108
        },
        "meteor": 0.5453172261251402,
        "bertscore": {
            "precision": 0.99654,
            "recall": 0.99654,
            "f1": 0.99654
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_14710": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.8,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85714
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 1.0,
            "3": 0.8333333333333334
        },
        "nist": 3.8847261486639773,
        "bleu": 62.38986,
        "bleurt": 0.38009,
        "nubia": {
            "semantic_relation": 4.50225,
            "contradiction": 21.81559,
            "irrelevancy": 19.52177,
            "logical_agreement": 58.66264,
            "grammar_ref": 5.78237,
            "grammar_hyp": 6.70668,
            "nubia_score": 0.59673
        },
        "meteor": 0.47681970506965704,
        "bertscore": {
            "precision": 0.95679,
            "recall": 0.96954,
            "f1": 0.96312
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3016": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.8,
        "vocab_size-1": 8,
        "unique-1": 6,
        "entropy-1": 2.9219280948873623,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 8,
        "unique-2": 7,
        "entropy-2": 2.94770277922009,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": 0.08007499855768763,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.725480556997868,
        "distinct-2-nopunct": 0.875,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.75,
        "cond_entropy-2-nopunct": -0.04492500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.04978793508525296,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.47872969366552,
        "bleu": 100.0,
        "bleurt": 0.9148,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.20451,
            "irrelevancy": 0.76191,
            "logical_agreement": 98.03358,
            "grammar_ref": 4.07249,
            "grammar_hyp": 4.01604,
            "nubia_score": 0.98068
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15144": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.875,
            "fmeasure": 0.93333
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.71429,
            "fmeasure": 0.76923
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.875,
            "fmeasure": 0.93333
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.875,
            "fmeasure": 0.93333
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.875
        },
        "nist": 2.9898332363522426,
        "bleu": 61.0195,
        "bleurt": 0.84839,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.51812,
            "irrelevancy": 0.46692,
            "logical_agreement": 99.01496,
            "grammar_ref": 5.85687,
            "grammar_hyp": 6.57356,
            "nubia_score": 0.90444
        },
        "meteor": 0.5230551846972475,
        "bertscore": {
            "precision": 0.99164,
            "recall": 0.97723,
            "f1": 0.98438
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3047": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 0.5,
        "median_pred_length": 12.5,
        "min_pred_length": 12,
        "max_pred_length": 13,
        "distinct-1": 0.6,
        "vocab_size-1": 15,
        "unique-1": 5,
        "entropy-1": 3.843856189774724,
        "distinct-2": 0.6521739130434783,
        "vocab_size-2": 15,
        "unique-2": 7,
        "entropy-2": 3.8279097821439705,
        "cond_entropy-2": -0.03333771197858132,
        "distinct-3": 0.7142857142857143,
        "vocab_size-3": 15,
        "unique-3": 9,
        "entropy-3": 3.8208888513501886,
        "cond_entropy-3": -0.03600643804015718,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.6086956521739131,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 3.7409532604048397,
        "distinct-2-nopunct": 0.6666666666666666,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 3.7256507561120933,
        "cond_entropy-2-nopunct": -0.03600643804015718,
        "distinct-3-nopunct": 0.7368421052631579,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.7216117239699003,
        "cond_entropy-3-nopunct": -0.03912675144043809,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.91288,
            "recall": 0.95455,
            "fmeasure": 0.93281
        },
        "rouge2": {
            "precision": 0.75909,
            "recall": 0.8,
            "fmeasure": 0.77857
        },
        "rougeL": {
            "precision": 0.91288,
            "recall": 0.95455,
            "fmeasure": 0.93281
        },
        "rougeLsum": {
            "precision": 0.91288,
            "recall": 0.95455,
            "fmeasure": 0.93281
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9545454545454546
        },
        "nist": 3.2455679996253584,
        "bleu": 72.74167,
        "bleurt": 0.31586,
        "nubia": {
            "semantic_relation": 4.13586,
            "contradiction": 0.46914,
            "irrelevancy": 94.41189,
            "logical_agreement": 5.11897,
            "grammar_ref": 3.76088,
            "grammar_hyp": 3.7973,
            "nubia_score": 0.77142
        },
        "meteor": 0.5145240815578183,
        "bertscore": {
            "precision": 0.93855,
            "recall": 0.96771,
            "f1": 0.95283
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2260": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.6875,
            "fmeasure": 0.64706
        },
        "rouge2": {
            "precision": 0.4375,
            "recall": 0.5,
            "fmeasure": 0.46667
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.6875,
            "fmeasure": 0.64706
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.6875,
            "fmeasure": 0.64706
        },
        "local_recall": {
            "1": 0.5,
            "2": 1.0
        },
        "nist": 3.614827668236417,
        "bleu": 65.8037,
        "bleurt": 0.39208,
        "nubia": {
            "semantic_relation": 4.41248,
            "contradiction": 0.2876,
            "irrelevancy": 88.92729,
            "logical_agreement": 10.78511,
            "grammar_ref": 5.57872,
            "grammar_hyp": 5.23829,
            "nubia_score": 0.81711
        },
        "meteor": 0.5430106152849822,
        "bertscore": {
            "precision": 0.9655,
            "recall": 0.98722,
            "f1": 0.97624
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15834": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.41071,
            "fmeasure": 0.45055
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "nist": 2.8610927314735184,
        "bleu": 33.12203,
        "bleurt": 0.35902,
        "nubia": {
            "semantic_relation": 4.56442,
            "contradiction": 2.44907,
            "irrelevancy": 2.37459,
            "logical_agreement": 95.17634,
            "grammar_ref": 5.6187,
            "grammar_hyp": 6.50772,
            "nubia_score": 0.67533
        },
        "meteor": 0.3707878006073302,
        "bertscore": {
            "precision": 0.95923,
            "recall": 0.93678,
            "f1": 0.94787
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3141": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.625,
            "recall": 0.68182,
            "fmeasure": 0.65217
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.4,
            "fmeasure": 0.38095
        },
        "rougeL": {
            "precision": 0.54167,
            "recall": 0.59091,
            "fmeasure": 0.56522
        },
        "rougeLsum": {
            "precision": 0.54167,
            "recall": 0.59091,
            "fmeasure": 0.56522
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.5714285714285714
        },
        "nist": 2.9997292837160456,
        "bleu": 50.08718,
        "bleurt": -0.17979,
        "nubia": {
            "semantic_relation": 3.22419,
            "contradiction": 0.08178,
            "irrelevancy": 99.56479,
            "logical_agreement": 0.35343,
            "grammar_ref": 4.25346,
            "grammar_hyp": 3.90368,
            "nubia_score": 0.53738
        },
        "meteor": 0.32475256955519033,
        "bertscore": {
            "precision": 0.88097,
            "recall": 0.89407,
            "f1": 0.88747
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2262": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966059,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.41176,
            "recall": 0.7,
            "fmeasure": 0.51852
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.55556,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.41176,
            "recall": 0.7,
            "fmeasure": 0.51852
        },
        "rougeLsum": {
            "precision": 0.41176,
            "recall": 0.7,
            "fmeasure": 0.51852
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.75
        },
        "nist": 1.345334518358949,
        "bleu": 27.49978,
        "bleurt": 0.22187,
        "nubia": {
            "semantic_relation": 4.16536,
            "contradiction": 0.23778,
            "irrelevancy": 89.65712,
            "logical_agreement": 10.1051,
            "grammar_ref": 5.64952,
            "grammar_hyp": 3.7802,
            "nubia_score": 0.72504
        },
        "meteor": 0.32182504834592524,
        "bertscore": {
            "precision": 0.83875,
            "recall": 0.9109,
            "f1": 0.87158
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2280": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.051189449246730745,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322734,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.867976246918685,
        "bleu": 100.0,
        "bleurt": 0.73788,
        "nubia": {
            "semantic_relation": 4.77875,
            "contradiction": 0.20639,
            "irrelevancy": 0.55532,
            "logical_agreement": 99.23829,
            "grammar_ref": 4.35803,
            "grammar_hyp": 4.93905,
            "nubia_score": 0.9019
        },
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2282": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.64706,
            "recall": 0.64706,
            "fmeasure": 0.64706
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.375,
            "fmeasure": 0.375
        },
        "rougeL": {
            "precision": 0.52941,
            "recall": 0.52941,
            "fmeasure": 0.52941
        },
        "rougeLsum": {
            "precision": 0.52941,
            "recall": 0.52941,
            "fmeasure": 0.52941
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6428571428571429
        },
        "nist": 2.442788563925935,
        "bleu": 17.27939,
        "bleurt": 0.03897,
        "nubia": {
            "semantic_relation": 2.62854,
            "contradiction": 98.83101,
            "irrelevancy": 0.93979,
            "logical_agreement": 0.2292,
            "grammar_ref": 3.64996,
            "grammar_hyp": 4.28983,
            "nubia_score": 0.27435
        },
        "meteor": 0.2971916435328238,
        "bertscore": {
            "precision": 0.91405,
            "recall": 0.89687,
            "f1": 0.90538
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2290": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.6875,
        "vocab_size-1": 11,
        "unique-1": 6,
        "entropy-1": 3.375,
        "distinct-2": 0.8,
        "vocab_size-2": 12,
        "unique-2": 9,
        "entropy-2": 3.506890595608518,
        "cond_entropy-2": 0.17355726227518525,
        "distinct-3": 0.8571428571428571,
        "vocab_size-3": 12,
        "unique-3": 10,
        "entropy-3": 3.521640636343319,
        "cond_entropy-3": 0.04332146930622849,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 3.2402239289418517,
        "distinct-2-nopunct": 0.7857142857142857,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.3787834934861767,
        "cond_entropy-2-nopunct": 0.11475004073479991,
        "distinct-3-nopunct": 0.8461538461538461,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.3927474104487847,
        "cond_entropy-3-nopunct": 0.04693094992964167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.87302,
            "recall": 0.8083,
            "fmeasure": 0.83932
        },
        "rouge2": {
            "precision": 0.8,
            "recall": 0.68998,
            "fmeasure": 0.73982
        },
        "rougeL": {
            "precision": 0.49206,
            "recall": 0.4552,
            "fmeasure": 0.47287
        },
        "rougeLsum": {
            "precision": 0.49206,
            "recall": 0.4552,
            "fmeasure": 0.47287
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.7777777777777778
        },
        "nist": 3.7077046298335246,
        "bleu": 64.61595,
        "bleurt": 0.29116,
        "nubia": {
            "semantic_relation": 4.45503,
            "contradiction": 1.47234,
            "irrelevancy": 0.7119,
            "logical_agreement": 97.81576,
            "grammar_ref": 3.13705,
            "grammar_hyp": 3.02007,
            "nubia_score": 0.91968
        },
        "meteor": 0.43777846617797245,
        "bertscore": {
            "precision": 0.95588,
            "recall": 0.9449,
            "f1": 0.95036
        }
    },
    "web_nlg_en_challenge_test_scramble": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.53344,
        "msttr-100_nopunct": 0.55112,
        "total_length": 12205,
        "mean_pred_length": 24.41,
        "std_pred_length": 12.239685453474692,
        "median_pred_length": 22.5,
        "min_pred_length": 7,
        "max_pred_length": 66,
        "distinct-1": 0.12265464973371569,
        "vocab_size-1": 1497,
        "unique-1": 595,
        "entropy-1": 7.968803440990323,
        "distinct-2": 0.37530969671080733,
        "vocab_size-2": 4393,
        "unique-2": 2606,
        "entropy-2": 11.179469024068418,
        "cond_entropy-2": 3.0406331800752358,
        "distinct-3": 0.5877733154841589,
        "vocab_size-3": 6586,
        "unique-3": 4788,
        "entropy-3": 12.219248616913431,
        "cond_entropy-3": 1.0893457610313315,
        "total_length-nopunct": 10777,
        "mean_pred_length-nopunct": 21.554,
        "std_pred_length-nopunct": 10.98576733778756,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 57,
        "distinct-1-nopunct": 0.13788623921313908,
        "vocab_size-1-nopunct": 1486,
        "unique-1-nopunct": 592,
        "entropy-1-nopunct": 8.240152959450915,
        "distinct-2-nopunct": 0.3901916901819597,
        "vocab_size-2-nopunct": 4010,
        "unique-2-nopunct": 2468,
        "entropy-2-nopunct": 11.073391407075807,
        "cond_entropy-2-nopunct": 2.975427446025085,
        "distinct-3-nopunct": 0.5980362074255907,
        "vocab_size-3-nopunct": 5847,
        "unique-3-nopunct": 4328,
        "entropy-3-nopunct": 12.051496221969304,
        "cond_entropy-3-nopunct": 1.0251512722313947,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_scramble.json",
        "rouge1": {
            "precision": 0.66934,
            "recall": 0.66888,
            "fmeasure": 0.66136
        },
        "rouge2": {
            "precision": 0.38862,
            "recall": 0.38707,
            "fmeasure": 0.3829
        },
        "rougeL": {
            "precision": 0.51913,
            "recall": 0.51885,
            "fmeasure": 0.5124
        },
        "rougeLsum": {
            "precision": 0.51913,
            "recall": 0.51885,
            "fmeasure": 0.5124
        },
        "local_recall": {
            "1": 0.2117019173749753,
            "2": 0.5242619613165932,
            "3": 0.7668287210172027,
            "4": 0.4,
            "5": 0.8333333333333334
        },
        "nist": 7.643396044067681,
        "bleu": 37.82526,
        "bleurt": -0.03049,
        "nubia": {
            "semantic_relation": 3.96073,
            "contradiction": 22.89126,
            "irrelevancy": 10.34016,
            "logical_agreement": 66.76858,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.6602,
            "nubia_score": 0.6454
        },
        "meteor": 0.33233614376835746,
        "bertscore": {
            "precision": 0.89192,
            "recall": 0.89369,
            "f1": 0.8916
        }
    },
    "xsum_challenge_test_backtranslation_parent": {
        "predictions_file": "T5-large (Baseline)/xsum_test",
        "N": 500,
        "msttr-100": 0.738,
        "msttr-100_nopunct": 0.76062,
        "total_length": 10534,
        "mean_pred_length": 21.068,
        "std_pred_length": 4.452794178939781,
        "median_pred_length": 21.0,
        "min_pred_length": 8,
        "max_pred_length": 36,
        "distinct-1": 0.2736852097968483,
        "vocab_size-1": 2883,
        "unique-1": 1838,
        "entropy-1": 9.052449020411924,
        "distinct-2": 0.7410803268885788,
        "vocab_size-2": 7436,
        "unique-2": 6466,
        "entropy-2": 12.390197569256236,
        "cond_entropy-2": 3.105763918543444,
        "distinct-3": 0.9234319278372142,
        "vocab_size-3": 8804,
        "unique-3": 8370,
        "entropy-3": 13.018756989244837,
        "cond_entropy-3": 0.6388410374043733,
        "total_length-nopunct": 9797,
        "mean_pred_length-nopunct": 19.594,
        "std_pred_length-nopunct": 4.290590169195841,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.2932530366438706,
        "vocab_size-1-nopunct": 2873,
        "unique-1-nopunct": 1837,
        "entropy-1-nopunct": 9.241817658304766,
        "distinct-2-nopunct": 0.7470151661826395,
        "vocab_size-2-nopunct": 6945,
        "unique-2-nopunct": 6071,
        "entropy-2-nopunct": 12.295207888703228,
        "cond_entropy-2-nopunct": 3.1745894833206,
        "distinct-3-nopunct": 0.9288393770603615,
        "vocab_size-3-nopunct": 8171,
        "unique-3-nopunct": 7784,
        "entropy-3-nopunct": 12.9245226267993,
        "cond_entropy-3-nopunct": 0.6467404315815284,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.42711,
            "recall": 0.39627,
            "fmeasure": 0.40308
        },
        "rouge2": {
            "precision": 0.17476,
            "recall": 0.16177,
            "fmeasure": 0.16427
        },
        "rougeL": {
            "precision": 0.33892,
            "recall": 0.31334,
            "fmeasure": 0.31904
        },
        "rougeLsum": {
            "precision": 0.33892,
            "recall": 0.31334,
            "fmeasure": 0.31904
        },
        "local_recall": {
            "1": 0.36985747498231075
        },
        "nist": 3.9272201837814045,
        "bleu": 11.58681,
        "bleurt": -0.2782,
        "nubia": {
            "semantic_relation": 3.05314,
            "contradiction": 18.46331,
            "irrelevancy": 65.39339,
            "logical_agreement": 16.14331,
            "grammar_ref": 3.78538,
            "grammar_hyp": 3.59165,
            "nubia_score": 0.46792
        },
        "meteor": 0.17992891811093234,
        "bertscore": {
            "precision": 0.83913,
            "recall": 0.82901,
            "f1": 0.83371
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_challenge_test_turk_bfp05",
        "N": 359,
        "msttr-100": 0.74406,
        "msttr-100_nopunct": 0.79823,
        "total_length": 6996,
        "mean_pred_length": 19.487465181058496,
        "std_pred_length": 9.45355065766765,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 54,
        "distinct-1": 0.4219554030874786,
        "vocab_size-1": 2952,
        "unique-1": 2405,
        "entropy-1": 9.363133347295847,
        "distinct-2": 0.859725779719753,
        "vocab_size-2": 5706,
        "unique-2": 5374,
        "entropy-2": 12.195035363901699,
        "cond_entropy-2": 2.556821874237998,
        "distinct-3": 0.969576298184135,
        "vocab_size-3": 6087,
        "unique-3": 6004,
        "entropy-3": 12.510443950882276,
        "cond_entropy-3": 0.3337645790505446,
        "total_length-nopunct": 6202,
        "mean_pred_length-nopunct": 17.275766016713092,
        "std_pred_length-nopunct": 8.383512663576605,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4737181554337311,
        "vocab_size-1-nopunct": 2938,
        "unique-1-nopunct": 2402,
        "entropy-1-nopunct": 9.747016338330239,
        "distinct-2-nopunct": 0.8793428033544413,
        "vocab_size-2-nopunct": 5138,
        "unique-2-nopunct": 4882,
        "entropy-2-nopunct": 12.082911429459664,
        "cond_entropy-2-nopunct": 2.4736141482249714,
        "distinct-3-nopunct": 0.9819474835886215,
        "vocab_size-3-nopunct": 5385,
        "unique-3-nopunct": 5320,
        "entropy-3-nopunct": 12.3770426362415,
        "cond_entropy-3-nopunct": 0.31817937232907934,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp05.json",
        "rouge1": {
            "precision": 0.72674,
            "recall": 0.6563,
            "fmeasure": 0.67612
        },
        "rouge2": {
            "precision": 0.52376,
            "recall": 0.46945,
            "fmeasure": 0.48283
        },
        "rougeL": {
            "precision": 0.69924,
            "recall": 0.63216,
            "fmeasure": 0.65043
        },
        "rougeLsum": {
            "precision": 0.69924,
            "recall": 0.63216,
            "fmeasure": 0.65043
        },
        "local_recall": {
            "1": 0.044142614601018676,
            "2": 0.13665389527458494,
            "3": 0.31072210065645517,
            "4": 0.41679873217115687,
            "5": 0.509865005192108,
            "6": 0.6286231884057971,
            "7": 0.7285223367697594
        },
        "nist": 8.76064952884697,
        "bleu": 45.07721,
        "sari": 48.81074,
        "bleurt": -0.56599,
        "nubia": {
            "semantic_relation": 3.84978,
            "contradiction": 8.50606,
            "irrelevancy": 19.02035,
            "logical_agreement": 72.47358,
            "grammar_ref": 4.55265,
            "grammar_hyp": 6.089,
            "nubia_score": 0.48611
        },
        "meteor": 0.33886332429764315,
        "bertscore": {
            "precision": 0.88514,
            "recall": 0.90075,
            "f1": 0.88996
        }
    },
    "xsum_challenge_test_bfp_02_parent": {
        "predictions_file": "T5-large (Baseline)/xsum_test",
        "N": 500,
        "msttr-100": 0.74123,
        "msttr-100_nopunct": 0.76465,
        "total_length": 10637,
        "mean_pred_length": 21.274,
        "std_pred_length": 4.565843186093889,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 37,
        "distinct-1": 0.2752655824010529,
        "vocab_size-1": 2928,
        "unique-1": 1903,
        "entropy-1": 9.075601369473308,
        "distinct-2": 0.7418368353556279,
        "vocab_size-2": 7520,
        "unique-2": 6572,
        "entropy-2": 12.400768434616694,
        "cond_entropy-2": 3.0963961931530286,
        "distinct-3": 0.9255992528795268,
        "vocab_size-3": 8920,
        "unique-3": 8523,
        "entropy-3": 13.033880372028754,
        "cond_entropy-3": 0.6415907434628653,
        "total_length-nopunct": 9912,
        "mean_pred_length-nopunct": 19.824,
        "std_pred_length-nopunct": 4.409651233374359,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.29418886198547217,
        "vocab_size-1-nopunct": 2916,
        "unique-1-nopunct": 1899,
        "entropy-1-nopunct": 9.256839752956797,
        "distinct-2-nopunct": 0.7473438164045899,
        "vocab_size-2-nopunct": 7034,
        "unique-2-nopunct": 6178,
        "entropy-2-nopunct": 12.304522033346727,
        "cond_entropy-2-nopunct": 3.1641416566781535,
        "distinct-3-nopunct": 0.930991921005386,
        "vocab_size-3-nopunct": 8297,
        "unique-3-nopunct": 7947,
        "entropy-3-nopunct": 12.939657504683234,
        "cond_entropy-3-nopunct": 0.6492225340767075,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.42748,
            "recall": 0.3959,
            "fmeasure": 0.40326
        },
        "rouge2": {
            "precision": 0.17872,
            "recall": 0.16597,
            "fmeasure": 0.16865
        },
        "rougeL": {
            "precision": 0.33587,
            "recall": 0.31158,
            "fmeasure": 0.31721
        },
        "rougeLsum": {
            "precision": 0.33587,
            "recall": 0.31158,
            "fmeasure": 0.31721
        },
        "local_recall": {
            "1": 0.36747226624405704
        },
        "nist": 3.907623676289503,
        "bleu": 11.22085,
        "bleurt": -0.28967,
        "nubia": {
            "semantic_relation": 3.05735,
            "contradiction": 18.73323,
            "irrelevancy": 63.31281,
            "logical_agreement": 17.95396,
            "grammar_ref": 3.74155,
            "grammar_hyp": 3.59487,
            "nubia_score": 0.46673
        },
        "meteor": 0.18003866709327623,
        "bertscore": {
            "precision": 0.84015,
            "recall": 0.82787,
            "f1": 0.83363
        }
    },
    "xsum_challenge_test_bfp_05_parent": {
        "predictions_file": "T5-large (Baseline)/xsum_test",
        "N": 500,
        "msttr-100": 0.73689,
        "msttr-100_nopunct": 0.75898,
        "total_length": 10613,
        "mean_pred_length": 21.226,
        "std_pred_length": 4.3898660571821555,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 36,
        "distinct-1": 0.2735324601903326,
        "vocab_size-1": 2903,
        "unique-1": 1887,
        "entropy-1": 9.035146002953507,
        "distinct-2": 0.7336102046870365,
        "vocab_size-2": 7419,
        "unique-2": 6488,
        "entropy-2": 12.359489265715318,
        "cond_entropy-2": 3.095854764016279,
        "distinct-3": 0.9178196192655779,
        "vocab_size-3": 8823,
        "unique-3": 8392,
        "entropy-3": 13.010667210697973,
        "cond_entropy-3": 0.66108194422335,
        "total_length-nopunct": 9895,
        "mean_pred_length-nopunct": 19.79,
        "std_pred_length-nopunct": 4.2301182016581995,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.2923698837796867,
        "vocab_size-1-nopunct": 2893,
        "unique-1-nopunct": 1886,
        "entropy-1-nopunct": 9.211666689832608,
        "distinct-2-nopunct": 0.7377328366152208,
        "vocab_size-2-nopunct": 6931,
        "unique-2-nopunct": 6078,
        "entropy-2-nopunct": 12.262851098632183,
        "cond_entropy-2-nopunct": 3.167491921550231,
        "distinct-3-nopunct": 0.9219786396852164,
        "vocab_size-3-nopunct": 8201,
        "unique-3-nopunct": 7807,
        "entropy-3-nopunct": 12.915253073331563,
        "cond_entropy-3-nopunct": 0.6706885310142325,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.42332,
            "recall": 0.39155,
            "fmeasure": 0.39924
        },
        "rouge2": {
            "precision": 0.1721,
            "recall": 0.15853,
            "fmeasure": 0.16165
        },
        "rougeL": {
            "precision": 0.33328,
            "recall": 0.30786,
            "fmeasure": 0.31398
        },
        "rougeLsum": {
            "precision": 0.33328,
            "recall": 0.30786,
            "fmeasure": 0.31398
        },
        "local_recall": {
            "1": 0.36678614097968937
        },
        "nist": 3.878569907194372,
        "bleu": 10.94367,
        "bleurt": -0.29007,
        "nubia": {
            "semantic_relation": 3.01417,
            "contradiction": 18.59798,
            "irrelevancy": 64.95088,
            "logical_agreement": 16.45115,
            "grammar_ref": 3.79385,
            "grammar_hyp": 3.59853,
            "nubia_score": 0.45446
        },
        "meteor": 0.17822328143126856,
        "bertscore": {
            "precision": 0.83993,
            "recall": 0.82738,
            "f1": 0.8333
        }
    },
    "xsum_challenge_test_nopunc_parent": {
        "predictions_file": "T5-large (Baseline)/xsum_test",
        "N": 500,
        "msttr-100": 0.74152,
        "msttr-100_nopunct": 0.76153,
        "total_length": 10540,
        "mean_pred_length": 21.08,
        "std_pred_length": 4.6969777517037485,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 37,
        "distinct-1": 0.2814990512333966,
        "vocab_size-1": 2967,
        "unique-1": 1915,
        "entropy-1": 9.098175844947926,
        "distinct-2": 0.7470119521912351,
        "vocab_size-2": 7500,
        "unique-2": 6557,
        "entropy-2": 12.409653125590332,
        "cond_entropy-2": 3.078707725420315,
        "distinct-3": 0.9275681341719078,
        "vocab_size-3": 8849,
        "unique-3": 8446,
        "entropy-3": 13.030898319513836,
        "cond_entropy-3": 0.6314462510616494,
        "total_length-nopunct": 9818,
        "mean_pred_length-nopunct": 19.636,
        "std_pred_length-nopunct": 4.481908522047276,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.30107964962314115,
        "vocab_size-1-nopunct": 2956,
        "unique-1-nopunct": 1913,
        "entropy-1-nopunct": 9.279381453997685,
        "distinct-2-nopunct": 0.7513414895900408,
        "vocab_size-2-nopunct": 7001,
        "unique-2-nopunct": 6146,
        "entropy-2-nopunct": 12.310238343327919,
        "cond_entropy-2-nopunct": 3.1507252596023756,
        "distinct-3-nopunct": 0.9320707643456566,
        "vocab_size-3-nopunct": 8219,
        "unique-3-nopunct": 7858,
        "entropy-3-nopunct": 12.934765890899222,
        "cond_entropy-3-nopunct": 0.6427889384030108,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.42459,
            "recall": 0.39326,
            "fmeasure": 0.40054
        },
        "rouge2": {
            "precision": 0.17981,
            "recall": 0.16497,
            "fmeasure": 0.16851
        },
        "rougeL": {
            "precision": 0.34073,
            "recall": 0.31378,
            "fmeasure": 0.32063
        },
        "rougeLsum": {
            "precision": 0.34073,
            "recall": 0.31378,
            "fmeasure": 0.32063
        },
        "local_recall": {
            "1": 0.3655082362394536
        },
        "nist": 3.9365724711813606,
        "bleu": 11.51224,
        "bleurt": -0.28579,
        "nubia": {
            "semantic_relation": 3.01791,
            "contradiction": 18.56696,
            "irrelevancy": 64.47456,
            "logical_agreement": 16.95848,
            "grammar_ref": 3.78318,
            "grammar_hyp": 3.64462,
            "nubia_score": 0.45191
        },
        "meteor": 0.1801843416298632,
        "bertscore": {
            "precision": 0.8408,
            "recall": 0.82835,
            "f1": 0.83422
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 214,
        "msttr-100": 0.45389,
        "msttr-100_nopunct": 0.45207,
        "total_length": 12688,
        "mean_pred_length": 59.28971962616822,
        "std_pred_length": 11.718273409384654,
        "median_pred_length": 60.0,
        "min_pred_length": 30,
        "max_pred_length": 84,
        "distinct-1": 0.1116015132408575,
        "vocab_size-1": 1416,
        "unique-1": 688,
        "entropy-1": 5.85758143211301,
        "distinct-2": 0.2780984447651114,
        "vocab_size-2": 3469,
        "unique-2": 1970,
        "entropy-2": 10.043314046436391,
        "cond_entropy-2": 4.191256914055963,
        "distinct-3": 0.4747960848287113,
        "vocab_size-3": 5821,
        "unique-3": 3847,
        "entropy-3": 11.65318996165136,
        "cond_entropy-3": 1.6315152141964606,
        "total_length-nopunct": 11691,
        "mean_pred_length-nopunct": 54.63084112149533,
        "std_pred_length-nopunct": 11.448347317489125,
        "median_pred_length-nopunct": 55.0,
        "min_pred_length-nopunct": 29,
        "max_pred_length-nopunct": 80,
        "distinct-1-nopunct": 0.12034898639979472,
        "vocab_size-1-nopunct": 1407,
        "unique-1-nopunct": 686,
        "entropy-1-nopunct": 5.75881161756672,
        "distinct-2-nopunct": 0.2828265226104383,
        "vocab_size-2-nopunct": 3246,
        "unique-2-nopunct": 1866,
        "entropy-2-nopunct": 9.939564128513332,
        "cond_entropy-2-nopunct": 4.23858277236639,
        "distinct-3-nopunct": 0.47429636864068186,
        "vocab_size-3-nopunct": 5342,
        "unique-3-nopunct": 3580,
        "entropy-3-nopunct": 11.490316395044667,
        "cond_entropy-3-nopunct": 1.5754517494106737,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.4361,
            "recall": 0.40737,
            "fmeasure": 0.41369
        },
        "rouge2": {
            "precision": 0.2178,
            "recall": 0.20136,
            "fmeasure": 0.20498
        },
        "rougeL": {
            "precision": 0.39681,
            "recall": 0.37009,
            "fmeasure": 0.37566
        },
        "rougeLsum": {
            "precision": 0.39681,
            "recall": 0.37009,
            "fmeasure": 0.37566
        },
        "local_recall": {
            "1": 0.09280089988751405,
            "2": 0.19192477876106195,
            "3": 0.25860805860805863
        },
        "nist": 1.114641007575831,
        "bleu": 1.91718,
        "bleurt": -0.53303,
        "nubia": {
            "semantic_relation": 3.37503,
            "contradiction": 32.2217,
            "irrelevancy": 17.45567,
            "logical_agreement": 50.32262,
            "grammar_ref": 2.5317,
            "grammar_hyp": 2.4347,
            "nubia_score": 0.13029
        },
        "meteor": 0.1227733301941358,
        "bertscore": {
            "precision": 0.85647,
            "recall": 0.8691,
            "f1": 0.86229
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 214,
        "msttr-100": 0.46333,
        "msttr-100_nopunct": 0.46021,
        "total_length": 10204,
        "mean_pred_length": 47.6822429906542,
        "std_pred_length": 12.543828307731763,
        "median_pred_length": 46.0,
        "min_pred_length": 12,
        "max_pred_length": 79,
        "distinct-1": 0.12152097216777734,
        "vocab_size-1": 1240,
        "unique-1": 618,
        "entropy-1": 5.846388941773089,
        "distinct-2": 0.305005005005005,
        "vocab_size-2": 3047,
        "unique-2": 1826,
        "entropy-2": 9.96977073814327,
        "cond_entropy-2": 4.116372298341103,
        "distinct-3": 0.5146276595744681,
        "vocab_size-3": 5031,
        "unique-3": 3499,
        "entropy-3": 11.496444888694361,
        "cond_entropy-3": 1.5508559509726036,
        "total_length-nopunct": 9431,
        "mean_pred_length-nopunct": 44.070093457943926,
        "std_pred_length-nopunct": 12.30225809341005,
        "median_pred_length-nopunct": 42.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 73,
        "distinct-1-nopunct": 0.13084508535680203,
        "vocab_size-1-nopunct": 1234,
        "unique-1-nopunct": 618,
        "entropy-1-nopunct": 5.7501332299181716,
        "distinct-2-nopunct": 0.3082347835521319,
        "vocab_size-2-nopunct": 2841,
        "unique-2-nopunct": 1694,
        "entropy-2-nopunct": 9.848572325957166,
        "cond_entropy-2-nopunct": 4.164469966710496,
        "distinct-3-nopunct": 0.5106075752526935,
        "vocab_size-3-nopunct": 4597,
        "unique-3-nopunct": 3197,
        "entropy-3-nopunct": 11.341842561166173,
        "cond_entropy-3-nopunct": 1.5266633878534834,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.44694,
            "recall": 0.44461,
            "fmeasure": 0.44207
        },
        "rouge2": {
            "precision": 0.20269,
            "recall": 0.20335,
            "fmeasure": 0.20156
        },
        "rougeL": {
            "precision": 0.42128,
            "recall": 0.42034,
            "fmeasure": 0.41714
        },
        "rougeLsum": {
            "precision": 0.42128,
            "recall": 0.42034,
            "fmeasure": 0.41714
        },
        "local_recall": {
            "1": 0.09309198374584411,
            "2": 0.21076573161485973,
            "3": 0.2826855123674912,
            "4": 0.18181818181818182
        },
        "nist": 1.0525308682207144,
        "bleu": 2.08983,
        "bleurt": -0.52002,
        "nubia": {
            "semantic_relation": 3.26939,
            "contradiction": 32.38507,
            "irrelevancy": 17.0722,
            "logical_agreement": 50.54273,
            "grammar_ref": 2.61878,
            "grammar_hyp": 2.55056,
            "nubia_score": 0.1398
        },
        "meteor": 0.12809864725696615,
        "bertscore": {
            "precision": 0.85767,
            "recall": 0.87261,
            "f1": 0.86456
        }
    },
    "web_nlg_en_challenge_test_numbers": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_challenge_test_numbers",
        "N": 500,
        "msttr-100": 0.64276,
        "msttr-100_nopunct": 0.6867,
        "total_length": 12337,
        "mean_pred_length": 24.674,
        "std_pred_length": 12.331087705470267,
        "median_pred_length": 23.0,
        "min_pred_length": 5,
        "max_pred_length": 69,
        "distinct-1": 0.12725946340277214,
        "vocab_size-1": 1570,
        "unique-1": 697,
        "entropy-1": 8.002010087348909,
        "distinct-2": 0.3697727464729239,
        "vocab_size-2": 4377,
        "unique-2": 2611,
        "entropy-2": 11.159586933777115,
        "cond_entropy-2": 2.9886934350855516,
        "distinct-3": 0.5710505424715533,
        "vocab_size-3": 6474,
        "unique-3": 4668,
        "entropy-3": 12.152169568200984,
        "cond_entropy-3": 1.0438607864306328,
        "total_length-nopunct": 10903,
        "mean_pred_length-nopunct": 21.806,
        "std_pred_length-nopunct": 11.081171598707423,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.14307988626983398,
        "vocab_size-1-nopunct": 1560,
        "unique-1-nopunct": 696,
        "entropy-1-nopunct": 8.288223327556429,
        "distinct-2-nopunct": 0.38431221762952994,
        "vocab_size-2-nopunct": 3998,
        "unique-2-nopunct": 2474,
        "entropy-2-nopunct": 11.05428957499612,
        "cond_entropy-2-nopunct": 2.9023376971736727,
        "distinct-3-nopunct": 0.5843683732202363,
        "vocab_size-3-nopunct": 5787,
        "unique-3-nopunct": 4278,
        "entropy-3-nopunct": 11.991620859024968,
        "cond_entropy-3-nopunct": 0.9832396290696451,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_numbers.json",
        "rouge1": {
            "precision": 0.67833,
            "recall": 0.66929,
            "fmeasure": 0.66632
        },
        "rouge2": {
            "precision": 0.4023,
            "recall": 0.39863,
            "fmeasure": 0.39559
        },
        "rougeL": {
            "precision": 0.52595,
            "recall": 0.52135,
            "fmeasure": 0.51731
        },
        "rougeLsum": {
            "precision": 0.52595,
            "recall": 0.52135,
            "fmeasure": 0.51731
        },
        "local_recall": {
            "1": 0.20761028643111018,
            "2": 0.5311317509459924,
            "3": 0.771822907331063,
            "4": 0.6666666666666666,
            "5": 0.8181818181818182
        },
        "nist": 7.655158282175429,
        "bleu": 39.07044,
        "bleurt": -0.0303,
        "nubia": {
            "semantic_relation": 3.82737,
            "contradiction": 32.14712,
            "irrelevancy": 10.2429,
            "logical_agreement": 57.60998,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.61131,
            "nubia_score": 0.60864
        },
        "meteor": 0.3353091310264315,
        "bertscore": {
            "precision": 0.89554,
            "recall": 0.89507,
            "f1": 0.89385
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 200,
        "msttr-100": 0.46771,
        "msttr-100_nopunct": 0.46359,
        "total_length": 7028,
        "mean_pred_length": 35.14,
        "std_pred_length": 11.236565311517573,
        "median_pred_length": 33.0,
        "min_pred_length": 11,
        "max_pred_length": 76,
        "distinct-1": 0.142145702902675,
        "vocab_size-1": 999,
        "unique-1": 552,
        "entropy-1": 5.760485825579663,
        "distinct-2": 0.34915055653192734,
        "vocab_size-2": 2384,
        "unique-2": 1524,
        "entropy-2": 9.790350998667643,
        "cond_entropy-2": 4.012717776443532,
        "distinct-3": 0.5555220277610139,
        "vocab_size-3": 3682,
        "unique-3": 2706,
        "entropy-3": 11.112033338910708,
        "cond_entropy-3": 1.3694226202902775,
        "total_length-nopunct": 6433,
        "mean_pred_length-nopunct": 32.165,
        "std_pred_length-nopunct": 10.864979291282612,
        "median_pred_length-nopunct": 30.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 70,
        "distinct-1-nopunct": 0.15404943261308876,
        "vocab_size-1-nopunct": 991,
        "unique-1-nopunct": 549,
        "entropy-1-nopunct": 5.646662431905561,
        "distinct-2-nopunct": 0.34638215947376866,
        "vocab_size-2-nopunct": 2159,
        "unique-2-nopunct": 1375,
        "entropy-2-nopunct": 9.605238059102664,
        "cond_entropy-2-nopunct": 4.07747876448039,
        "distinct-3-nopunct": 0.5478203215647274,
        "vocab_size-3-nopunct": 3305,
        "unique-3-nopunct": 2442,
        "entropy-3-nopunct": 10.91808281928843,
        "cond_entropy-3-nopunct": 1.3631221686334112,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.37719,
            "recall": 0.38505,
            "fmeasure": 0.37689
        },
        "rouge2": {
            "precision": 0.17954,
            "recall": 0.18115,
            "fmeasure": 0.17719
        },
        "rougeL": {
            "precision": 0.35429,
            "recall": 0.36338,
            "fmeasure": 0.35445
        },
        "rougeLsum": {
            "precision": 0.35429,
            "recall": 0.36338,
            "fmeasure": 0.35445
        },
        "local_recall": {
            "1": 0.10263929618768329,
            "2": 0.1875,
            "3": 0.25487646293888166,
            "4": 0.15,
            "5": 0.2692307692307692,
            "6": 0.0,
            "7": 0.16666666666666666
        },
        "nist": 1.1349469850954468,
        "bleu": 2.05702,
        "bleurt": -0.47152,
        "nubia": {
            "semantic_relation": 3.25315,
            "contradiction": 33.11172,
            "irrelevancy": 16.98198,
            "logical_agreement": 49.9063,
            "grammar_ref": 2.7039,
            "grammar_hyp": 2.72391,
            "nubia_score": 0.16695
        },
        "meteor": 0.13803288366963976,
        "bertscore": {
            "precision": 0.86238,
            "recall": 0.87434,
            "f1": 0.86754
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-2": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 1397,
        "msttr-100": 0.62196,
        "msttr-100_nopunct": 0.62458,
        "total_length": 28097,
        "mean_pred_length": 20.112383679312813,
        "std_pred_length": 6.6696974848921755,
        "median_pred_length": 19.0,
        "min_pred_length": 6,
        "max_pred_length": 56,
        "distinct-1": 0.061892728761077695,
        "vocab_size-1": 1739,
        "unique-1": 825,
        "entropy-1": 7.425674223065679,
        "distinct-2": 0.20273408239700375,
        "vocab_size-2": 5413,
        "unique-2": 3256,
        "entropy-2": 10.220794597455534,
        "cond_entropy-2": 2.6862121830888026,
        "distinct-3": 0.3731573331225546,
        "vocab_size-3": 9442,
        "unique-3": 6644,
        "entropy-3": 11.73929560993548,
        "cond_entropy-3": 1.5449223101338954,
        "total_length-nopunct": 25381,
        "mean_pred_length-nopunct": 18.16821760916249,
        "std_pred_length-nopunct": 6.295142988139472,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 50,
        "distinct-1-nopunct": 0.06796422520783263,
        "vocab_size-1-nopunct": 1725,
        "unique-1-nopunct": 822,
        "entropy-1-nopunct": 7.4902175291350375,
        "distinct-2-nopunct": 0.2174366244162775,
        "vocab_size-2-nopunct": 5215,
        "unique-2-nopunct": 3215,
        "entropy-2-nopunct": 10.16044652485698,
        "cond_entropy-2-nopunct": 2.749347775641206,
        "distinct-3-nopunct": 0.3923938548722717,
        "vocab_size-3-nopunct": 8863,
        "unique-3-nopunct": 6345,
        "entropy-3-nopunct": 11.671379329585791,
        "cond_entropy-3-nopunct": 1.55404489736248,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.66032,
            "recall": 0.64404,
            "fmeasure": 0.63974
        },
        "rouge2": {
            "precision": 0.44461,
            "recall": 0.43375,
            "fmeasure": 0.43065
        },
        "rougeL": {
            "precision": 0.57155,
            "recall": 0.55838,
            "fmeasure": 0.55435
        },
        "rougeLsum": {
            "precision": 0.57155,
            "recall": 0.55838,
            "fmeasure": 0.55435
        },
        "local_recall": {
            "1": 0.6352175681171208
        },
        "nist": 6.69762150893707,
        "bleu": 35.77843,
        "bleurt": -0.06005,
        "nubia": {
            "semantic_relation": 4.07519,
            "contradiction": 9.41975,
            "irrelevancy": 21.47157,
            "logical_agreement": 69.10868,
            "grammar_ref": 4.97201,
            "grammar_hyp": 4.87928,
            "nubia_score": 0.6832
        },
        "meteor": 0.34170541894502404,
        "bertscore": {
            "precision": 0.88416,
            "recall": 0.87984,
            "f1": 0.88157
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 32,
        "msttr-100": 0.45667,
        "msttr-100_nopunct": 0.456,
        "total_length": 2170,
        "mean_pred_length": 67.8125,
        "std_pred_length": 6.97064155942622,
        "median_pred_length": 69.0,
        "min_pred_length": 43,
        "max_pred_length": 79,
        "distinct-1": 0.1737327188940092,
        "vocab_size-1": 377,
        "unique-1": 198,
        "entropy-1": 5.32042906946371,
        "distinct-2": 0.3938260056127222,
        "vocab_size-2": 842,
        "unique-2": 510,
        "entropy-2": 8.816528700522644,
        "cond_entropy-2": 3.502066567494012,
        "distinct-3": 0.5721747388414055,
        "vocab_size-3": 1205,
        "unique-3": 830,
        "entropy-3": 9.777437565669771,
        "cond_entropy-3": 0.9714979368502097,
        "total_length-nopunct": 2033,
        "mean_pred_length-nopunct": 63.53125,
        "std_pred_length-nopunct": 6.642591620557447,
        "median_pred_length-nopunct": 64.5,
        "min_pred_length-nopunct": 40,
        "max_pred_length-nopunct": 75,
        "distinct-1-nopunct": 0.18199704869650762,
        "vocab_size-1-nopunct": 370,
        "unique-1-nopunct": 198,
        "entropy-1-nopunct": 5.188741610620295,
        "distinct-2-nopunct": 0.39980009995002497,
        "vocab_size-2-nopunct": 800,
        "unique-2-nopunct": 481,
        "entropy-2-nopunct": 8.756862938248686,
        "cond_entropy-2-nopunct": 3.5833242566887633,
        "distinct-3-nopunct": 0.5764347384459116,
        "vocab_size-3-nopunct": 1135,
        "unique-3-nopunct": 784,
        "entropy-3-nopunct": 9.707036004135027,
        "cond_entropy-3-nopunct": 0.9649529452092093,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.74583,
            "recall": 0.73295,
            "fmeasure": 0.72467
        },
        "rouge2": {
            "precision": 0.35156,
            "recall": 0.38008,
            "fmeasure": 0.35423
        },
        "rougeL": {
            "precision": 0.6901,
            "recall": 0.68364,
            "fmeasure": 0.67158
        },
        "rougeLsum": {
            "precision": 0.6901,
            "recall": 0.68364,
            "fmeasure": 0.67158
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.174496644295302,
            "3": 0.23961661341853036
        },
        "nist": 1.1287444983944743,
        "bleu": 1.03388,
        "bleurt": -0.51045,
        "nubia": {
            "semantic_relation": 3.24205,
            "contradiction": 33.76925,
            "irrelevancy": 21.2792,
            "logical_agreement": 44.95155,
            "grammar_ref": 2.45871,
            "grammar_hyp": 2.43302,
            "nubia_score": 0.14084
        },
        "meteor": 0.10691214046149387,
        "bertscore": {
            "precision": 0.86079,
            "recall": 0.86382,
            "f1": 0.862
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-large (Baseline)/e2e_nlg_test",
        "N": 737,
        "msttr-100": 0.2922,
        "msttr-100_nopunct": 0.28779,
        "total_length": 15954,
        "mean_pred_length": 21.647218453188604,
        "std_pred_length": 4.667837469924336,
        "median_pred_length": 22.0,
        "min_pred_length": 12,
        "max_pred_length": 41,
        "distinct-1": 0.016171493042497178,
        "vocab_size-1": 258,
        "unique-1": 45,
        "entropy-1": 5.97396015791841,
        "distinct-2": 0.06032726555825721,
        "vocab_size-2": 918,
        "unique-2": 245,
        "entropy-2": 7.892785919713252,
        "cond_entropy-2": 1.8145572230028029,
        "distinct-3": 0.1095303867403315,
        "vocab_size-3": 1586,
        "unique-3": 531,
        "entropy-3": 8.909674854354098,
        "cond_entropy-3": 1.0377573760157182,
        "total_length-nopunct": 14557,
        "mean_pred_length-nopunct": 19.7516960651289,
        "std_pred_length-nopunct": 4.231682591777856,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.017586041079892836,
        "vocab_size-1-nopunct": 256,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 6.033680848009593,
        "distinct-2-nopunct": 0.06324167872648336,
        "vocab_size-2-nopunct": 874,
        "unique-2-nopunct": 236,
        "entropy-2-nopunct": 7.832164826027695,
        "cond_entropy-2-nopunct": 1.8617447778861815,
        "distinct-3-nopunct": 0.11449973247726057,
        "vocab_size-3-nopunct": 1498,
        "unique-3-nopunct": 495,
        "entropy-3-nopunct": 8.893063218446864,
        "cond_entropy-3-nopunct": 1.0592111941907054,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.68375,
            "recall": 0.68842,
            "fmeasure": 0.67355
        },
        "rouge2": {
            "precision": 0.40136,
            "recall": 0.40361,
            "fmeasure": 0.39476
        },
        "rougeL": {
            "precision": 0.51785,
            "recall": 0.52117,
            "fmeasure": 0.51012
        },
        "rougeLsum": {
            "precision": 0.51785,
            "recall": 0.52117,
            "fmeasure": 0.51012
        },
        "local_recall": {
            "1": 0.6733611216369837
        },
        "nist": 4.618700621308964,
        "bleu": 28.41136,
        "bleurt": 0.14313,
        "nubia": {
            "semantic_relation": 4.08853,
            "contradiction": 5.18699,
            "irrelevancy": 32.64113,
            "logical_agreement": 62.17189,
            "grammar_ref": 4.94689,
            "grammar_hyp": 4.53397,
            "nubia_score": 0.72297
        },
        "meteor": 0.343018186237415,
        "bertscore": {
            "precision": 0.90717,
            "recall": 0.90133,
            "f1": 0.9038
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_challenge_test_turk_nopunc",
        "N": 359,
        "msttr-100": 0.72243,
        "msttr-100_nopunct": 0.76694,
        "total_length": 7058,
        "mean_pred_length": 19.66016713091922,
        "std_pred_length": 9.398118164914992,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.3543496741286483,
        "vocab_size-1": 2501,
        "unique-1": 1827,
        "entropy-1": 9.068781604156358,
        "distinct-2": 0.8254963427377221,
        "vocab_size-2": 5530,
        "unique-2": 5090,
        "entropy-2": 12.081900464284606,
        "cond_entropy-2": 2.748623484687526,
        "distinct-3": 0.955993690851735,
        "vocab_size-3": 6061,
        "unique-3": 5937,
        "entropy-3": 12.47100098705081,
        "cond_entropy-3": 0.40846421726614196,
        "total_length-nopunct": 6273,
        "mean_pred_length-nopunct": 17.473537604456826,
        "std_pred_length-nopunct": 8.28084654602299,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.39693926351028214,
        "vocab_size-1-nopunct": 2490,
        "unique-1-nopunct": 1825,
        "entropy-1-nopunct": 9.409440166707876,
        "distinct-2-nopunct": 0.8468041934392966,
        "vocab_size-2-nopunct": 5008,
        "unique-2-nopunct": 4643,
        "entropy-2-nopunct": 11.996549714626974,
        "cond_entropy-2-nopunct": 2.7294829023271086,
        "distinct-3-nopunct": 0.9728172817281728,
        "vocab_size-3-nopunct": 5404,
        "unique-3-nopunct": 5303,
        "entropy-3-nopunct": 12.371752563457706,
        "cond_entropy-3-nopunct": 0.4030316170132766,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_nopunc.json",
        "rouge1": {
            "precision": 0.84113,
            "recall": 0.76658,
            "fmeasure": 0.78774
        },
        "rouge2": {
            "precision": 0.69508,
            "recall": 0.63541,
            "fmeasure": 0.64978
        },
        "rougeL": {
            "precision": 0.81221,
            "recall": 0.74244,
            "fmeasure": 0.7612
        },
        "rougeLsum": {
            "precision": 0.81221,
            "recall": 0.74244,
            "fmeasure": 0.7612
        },
        "local_recall": {
            "1": 0.04647707979626486,
            "2": 0.16475095785440613,
            "3": 0.37199124726477023,
            "4": 0.5103011093502378,
            "5": 0.6105919003115264,
            "6": 0.7373188405797102,
            "7": 0.8549064528445972
        },
        "nist": 10.830913808832701,
        "bleu": 65.19261,
        "sari": 48.33985,
        "bleurt": 0.15522,
        "nubia": {
            "semantic_relation": 4.19151,
            "contradiction": 4.24863,
            "irrelevancy": 18.47877,
            "logical_agreement": 77.2726,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.9262,
            "nubia_score": 0.66593
        },
        "meteor": 0.4444723998100211,
        "bertscore": {
            "precision": 0.95081,
            "recall": 0.9368,
            "f1": 0.94102
        }
    },
    "xsum_test": {
        "predictions_file": "T5-large (Baseline)/xsum_test",
        "N": 1166,
        "msttr-100": 0.73773,
        "msttr-100_nopunct": 0.75904,
        "total_length": 24705,
        "mean_pred_length": 21.187821612349914,
        "std_pred_length": 4.51525592607494,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 38,
        "distinct-1": 0.20068811981380288,
        "vocab_size-1": 4958,
        "unique-1": 2872,
        "entropy-1": 9.312076582682604,
        "distinct-2": 0.6565699477462934,
        "vocab_size-2": 15455,
        "unique-2": 12941,
        "entropy-2": 13.19296968798421,
        "cond_entropy-2": 3.6385571927624007,
        "distinct-3": 0.8808832074375363,
        "vocab_size-3": 19708,
        "unique-3": 18405,
        "entropy-3": 14.103063303499138,
        "cond_entropy-3": 0.9152622193257293,
        "total_length-nopunct": 23026,
        "mean_pred_length-nopunct": 19.747855917667238,
        "std_pred_length-nopunct": 4.336991317450968,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.21480066012333884,
        "vocab_size-1-nopunct": 4946,
        "unique-1-nopunct": 2869,
        "entropy-1-nopunct": 9.510269405650789,
        "distinct-2-nopunct": 0.6653705397987191,
        "vocab_size-2-nopunct": 14545,
        "unique-2-nopunct": 12279,
        "entropy-2-nopunct": 13.113849825210828,
        "cond_entropy-2-nopunct": 3.728079588145234,
        "distinct-3-nopunct": 0.8878902097226249,
        "vocab_size-3-nopunct": 18374,
        "unique-3-nopunct": 17208,
        "entropy-3-nopunct": 14.019473784933375,
        "cond_entropy-3-nopunct": 0.9254421451331474,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.42458,
            "recall": 0.39191,
            "fmeasure": 0.39993
        },
        "rouge2": {
            "precision": 0.17631,
            "recall": 0.16287,
            "fmeasure": 0.1659
        },
        "rougeL": {
            "precision": 0.33566,
            "recall": 0.30963,
            "fmeasure": 0.31607
        },
        "rougeLsum": {
            "precision": 0.33566,
            "recall": 0.30963,
            "fmeasure": 0.31607
        },
        "local_recall": {
            "1": 0.36539036154864046
        },
        "nist": 4.072359797620752,
        "bleu": 11.26708,
        "bleurt": -0.29157,
        "nubia": {
            "semantic_relation": 3.03045,
            "contradiction": 18.25758,
            "irrelevancy": 64.74767,
            "logical_agreement": 16.99474,
            "grammar_ref": 3.76542,
            "grammar_hyp": 3.60773,
            "nubia_score": 0.45974
        },
        "meteor": 0.17881081843268773,
        "bertscore": {
            "precision": 0.83949,
            "recall": 0.82766,
            "f1": 0.83323
        }
    },
    "xsum_challenge_train_sample": {
        "predictions_file": "T5-large (Baseline)/xsum_challenge_train_sample",
        "N": 500
    },
    "xsum_challenge_validation_sample": {
        "predictions_file": "T5-large (Baseline)/xsum_challenge_validation_sample",
        "N": 500
    },
    "schema_guided_dialog_test_contrast_challenge_acts-3": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 983,
        "msttr-100": 0.22642,
        "msttr-100_nopunct": 0.21738,
        "total_length": 5325,
        "mean_pred_length": 5.417090539165819,
        "std_pred_length": 1.5841897136300072,
        "median_pred_length": 5.0,
        "min_pred_length": 2,
        "max_pred_length": 16,
        "distinct-1": 0.01652582159624413,
        "vocab_size-1": 88,
        "unique-1": 21,
        "entropy-1": 3.9653614234008887,
        "distinct-2": 0.0426070935052971,
        "vocab_size-2": 185,
        "unique-2": 75,
        "entropy-2": 4.803238814614255,
        "cond_entropy-2": 0.7283403106176505,
        "distinct-3": 0.06728192914557904,
        "vocab_size-3": 226,
        "unique-3": 105,
        "entropy-3": 5.582994632559917,
        "cond_entropy-3": 0.6538841510445386,
        "total_length-nopunct": 4295,
        "mean_pred_length-nopunct": 4.369277721261445,
        "std_pred_length-nopunct": 1.2912382518236636,
        "median_pred_length-nopunct": 4.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.01979045401629802,
        "vocab_size-1-nopunct": 85,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 3.734057949963514,
        "distinct-2-nopunct": 0.043478260869565216,
        "vocab_size-2-nopunct": 144,
        "unique-2-nopunct": 59,
        "entropy-2-nopunct": 4.462905067042496,
        "cond_entropy-2-nopunct": 0.5834578341325074,
        "distinct-3-nopunct": 0.06437768240343347,
        "vocab_size-3-nopunct": 150,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 4.835877476136082,
        "cond_entropy-3-nopunct": 0.5716269852194596,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.54301,
            "recall": 0.51696,
            "fmeasure": 0.52174
        },
        "rouge2": {
            "precision": 0.36774,
            "recall": 0.34991,
            "fmeasure": 0.35281
        },
        "rougeL": {
            "precision": 0.54224,
            "recall": 0.51635,
            "fmeasure": 0.52106
        },
        "rougeLsum": {
            "precision": 0.54224,
            "recall": 0.51635,
            "fmeasure": 0.52106
        },
        "local_recall": {
            "1": 0.4960393919931492
        },
        "nist": 2.915222775819561,
        "bleu": 30.43025,
        "bleurt": 0.16685,
        "nubia": {
            "semantic_relation": 3.1656,
            "contradiction": 3.15379,
            "irrelevancy": 22.82766,
            "logical_agreement": 74.01855,
            "grammar_ref": 4.77701,
            "grammar_hyp": 4.59567,
            "nubia_score": 0.60403
        },
        "meteor": 0.28387211530960776,
        "bertscore": {
            "precision": 0.86241,
            "recall": 0.85691,
            "f1": 0.85921
        }
    },
    "xsum_challenge_test_backtranslation": {
        "predictions_file": "T5-large (Baseline)/xsum_challenge_test_backtranslation",
        "N": 500,
        "msttr-100": 0.72413,
        "msttr-100_nopunct": 0.74376,
        "total_length": 10917,
        "mean_pred_length": 21.834,
        "std_pred_length": 5.047221413807799,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 41,
        "distinct-1": 0.26765594943665844,
        "vocab_size-1": 2922,
        "unique-1": 1859,
        "entropy-1": 8.98325944823455,
        "distinct-2": 0.7291926658346933,
        "vocab_size-2": 7596,
        "unique-2": 6588,
        "entropy-2": 12.38072483717945,
        "cond_entropy-2": 3.182800416255653,
        "distinct-3": 0.9215488555006555,
        "vocab_size-3": 9139,
        "unique-3": 8665,
        "entropy-3": 13.073388744753444,
        "cond_entropy-3": 0.7122713595887591,
        "total_length-nopunct": 10145,
        "mean_pred_length-nopunct": 20.29,
        "std_pred_length-nopunct": 4.8358970212360815,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.28684080827994085,
        "vocab_size-1-nopunct": 2910,
        "unique-1-nopunct": 1856,
        "entropy-1-nopunct": 9.152983566349192,
        "distinct-2-nopunct": 0.7334370139968895,
        "vocab_size-2-nopunct": 7074,
        "unique-2-nopunct": 6161,
        "entropy-2-nopunct": 12.274592159812663,
        "cond_entropy-2-nopunct": 3.251302425083369,
        "distinct-3-nopunct": 0.9257517769272827,
        "vocab_size-3-nopunct": 8466,
        "unique-3-nopunct": 8041,
        "entropy-3-nopunct": 12.973770353839093,
        "cond_entropy-3-nopunct": 0.7265471440954447,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_backtranslation.json",
        "rouge1": {
            "precision": 0.36993,
            "recall": 0.35309,
            "fmeasure": 0.3534
        },
        "rouge2": {
            "precision": 0.12303,
            "recall": 0.11629,
            "fmeasure": 0.11685
        },
        "rougeL": {
            "precision": 0.28436,
            "recall": 0.27044,
            "fmeasure": 0.27089
        },
        "rougeLsum": {
            "precision": 0.28436,
            "recall": 0.27044,
            "fmeasure": 0.27089
        },
        "local_recall": {
            "1": 0.3253815829374305
        },
        "nist": 3.2232242010083634,
        "bleu": 7.56497,
        "bleurt": -0.38729,
        "nubia": {
            "semantic_relation": 2.66616,
            "contradiction": 21.2845,
            "irrelevancy": 67.59975,
            "logical_agreement": 11.11575,
            "grammar_ref": 3.78538,
            "grammar_hyp": 3.63803,
            "nubia_score": 0.38443
        },
        "meteor": 0.15453249800733063,
        "bertscore": {
            "precision": 0.81938,
            "recall": 0.81245,
            "f1": 0.8156
        }
    },
    "cs_restaurants_validation": {
        "predictions_file": "T5-large (Baseline)/cs_restaurants_validation",
        "N": 781,
        "msttr-100": 0.54022,
        "msttr-100_nopunct": 0.54866,
        "total_length": 13833,
        "mean_pred_length": 17.71190781049936,
        "std_pred_length": 7.032590973238727,
        "median_pred_length": 18.0,
        "min_pred_length": 4,
        "max_pred_length": 48,
        "distinct-1": 0.03549483120075182,
        "vocab_size-1": 491,
        "unique-1": 137,
        "entropy-1": 6.250409940091213,
        "distinct-2": 0.12128409439166411,
        "vocab_size-2": 1583,
        "unique-2": 617,
        "entropy-2": 9.131642969620138,
        "cond_entropy-2": 2.801373082530917,
        "distinct-3": 0.21033330616901638,
        "vocab_size-3": 2581,
        "unique-3": 1229,
        "entropy-3": 10.053942831917524,
        "cond_entropy-3": 0.9153926931125926,
        "total_length-nopunct": 12710,
        "mean_pred_length-nopunct": 16.274007682458386,
        "std_pred_length-nopunct": 6.77490306907276,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.03831628638867034,
        "vocab_size-1-nopunct": 487,
        "unique-1-nopunct": 137,
        "entropy-1-nopunct": 6.231444959796677,
        "distinct-2-nopunct": 0.12306144689412356,
        "vocab_size-2-nopunct": 1468,
        "unique-2-nopunct": 585,
        "entropy-2-nopunct": 9.01548277317537,
        "cond_entropy-2-nopunct": 2.8503518075882512,
        "distinct-3-nopunct": 0.2163616792249731,
        "vocab_size-3-nopunct": 2412,
        "unique-3-nopunct": 1166,
        "entropy-3-nopunct": 9.964305636917695,
        "cond_entropy-3-nopunct": 0.9072305659831015,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_validation.json",
        "rouge1": {
            "precision": 0.39851,
            "recall": 0.44717,
            "fmeasure": 0.40387
        },
        "rouge2": {
            "precision": 0.22465,
            "recall": 0.25794,
            "fmeasure": 0.22897
        },
        "rougeL": {
            "precision": 0.35925,
            "recall": 0.40666,
            "fmeasure": 0.3655
        },
        "rougeLsum": {
            "precision": 0.35925,
            "recall": 0.40666,
            "fmeasure": 0.3655
        },
        "local_recall": {
            "1": 0.26849112426035504
        },
        "nist": 1.3062700952348338,
        "bleu": 2.74749,
        "bleurt": -0.79453,
        "nubia": {
            "semantic_relation": 2.60937,
            "contradiction": 32.04947,
            "irrelevancy": 26.97545,
            "logical_agreement": 40.97508,
            "grammar_ref": 6.54085,
            "grammar_hyp": 5.96937,
            "nubia_score": 0.25373
        },
        "meteor": 0.12395903134841066,
        "bertscore": {
            "precision": 0.80513,
            "recall": 0.83988,
            "f1": 0.8218
        }
    },
    "cs_restaurants_test": {
        "predictions_file": "T5-large (Baseline)/cs_restaurants_test",
        "N": 842,
        "msttr-100": 0.52897,
        "msttr-100_nopunct": 0.53964,
        "total_length": 15562,
        "mean_pred_length": 18.482185273159146,
        "std_pred_length": 6.002199990484228,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 55,
        "distinct-1": 0.04684487855031487,
        "vocab_size-1": 729,
        "unique-1": 252,
        "entropy-1": 6.305514557824851,
        "distinct-2": 0.14619565217391303,
        "vocab_size-2": 2152,
        "unique-2": 1040,
        "entropy-2": 9.005456878807681,
        "cond_entropy-2": 2.6321439691716235,
        "distinct-3": 0.24729788153912668,
        "vocab_size-3": 3432,
        "unique-3": 2096,
        "entropy-3": 9.774387036182896,
        "cond_entropy-3": 0.8342982294277889,
        "total_length-nopunct": 14039,
        "mean_pred_length-nopunct": 16.673396674584325,
        "std_pred_length-nopunct": 5.715668351963107,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 53,
        "distinct-1-nopunct": 0.05164185483296531,
        "vocab_size-1-nopunct": 725,
        "unique-1-nopunct": 252,
        "entropy-1-nopunct": 6.311458119101683,
        "distinct-2-nopunct": 0.1482912783208305,
        "vocab_size-2-nopunct": 1957,
        "unique-2-nopunct": 985,
        "entropy-2-nopunct": 8.858130256638132,
        "cond_entropy-2-nopunct": 2.7075075782602793,
        "distinct-3-nopunct": 0.25341966815054634,
        "vocab_size-3-nopunct": 3131,
        "unique-3-nopunct": 1946,
        "entropy-3-nopunct": 9.6554559443623,
        "cond_entropy-3-nopunct": 0.8699571057610788,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.39784,
            "recall": 0.45319,
            "fmeasure": 0.40561
        },
        "rouge2": {
            "precision": 0.21472,
            "recall": 0.24523,
            "fmeasure": 0.2182
        },
        "rougeL": {
            "precision": 0.3557,
            "recall": 0.40481,
            "fmeasure": 0.36254
        },
        "rougeLsum": {
            "precision": 0.3557,
            "recall": 0.40481,
            "fmeasure": 0.36254
        },
        "local_recall": {
            "1": 0.29246328622887224
        },
        "nist": 1.4717228809347807,
        "bleu": 3.55667,
        "bleurt": -0.75035,
        "nubia": {
            "semantic_relation": 2.7,
            "contradiction": 33.57688,
            "irrelevancy": 28.40835,
            "logical_agreement": 38.01477,
            "grammar_ref": 6.8707,
            "grammar_hyp": 5.89872,
            "nubia_score": 0.29059
        },
        "meteor": 0.1348718532882381,
        "bertscore": {
            "precision": 0.81493,
            "recall": 0.85296,
            "f1": 0.83319
        }
    },
    "cs_restaurants_challenge_train_sample": {
        "predictions_file": "T5-large (Baseline)/cs_restaurants_challenge_train_sample",
        "N": 500
    },
    "cs_restaurants_challenge_validation_sample": {
        "predictions_file": "T5-large (Baseline)/cs_restaurants_challenge_validation_sample",
        "N": 500
    },
    "schema_guided_dialog_test_contrast_challenge_acts-4": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 1027,
        "msttr-100": 0.62402,
        "msttr-100_nopunct": 0.66533,
        "total_length": 10749,
        "mean_pred_length": 10.466407010710808,
        "std_pred_length": 4.422830809327356,
        "median_pred_length": 9.0,
        "min_pred_length": 2,
        "max_pred_length": 24,
        "distinct-1": 0.10810307935621918,
        "vocab_size-1": 1162,
        "unique-1": 617,
        "entropy-1": 7.366213906695968,
        "distinct-2": 0.3167043818144415,
        "vocab_size-2": 3079,
        "unique-2": 1947,
        "entropy-2": 10.25933978185743,
        "cond_entropy-2": 2.536176365026809,
        "distinct-3": 0.5105232892466935,
        "vocab_size-3": 4439,
        "unique-3": 3199,
        "entropy-3": 11.360612522825615,
        "cond_entropy-3": 1.1520107833681106,
        "total_length-nopunct": 9270,
        "mean_pred_length-nopunct": 9.026290165530671,
        "std_pred_length-nopunct": 4.148683836002773,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.12427184466019417,
        "vocab_size-1-nopunct": 1152,
        "unique-1-nopunct": 616,
        "entropy-1-nopunct": 7.649493825882615,
        "distinct-2-nopunct": 0.33058352541550406,
        "vocab_size-2-nopunct": 2725,
        "unique-2-nopunct": 1735,
        "entropy-2-nopunct": 10.122729345251003,
        "cond_entropy-2-nopunct": 2.7167094420220863,
        "distinct-3-nopunct": 0.53289929353096,
        "vocab_size-3-nopunct": 3847,
        "unique-3-nopunct": 2847,
        "entropy-3-nopunct": 11.174261547609005,
        "cond_entropy-3-nopunct": 1.1869259821874383,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.67291,
            "recall": 0.66055,
            "fmeasure": 0.65486
        },
        "rouge2": {
            "precision": 0.46595,
            "recall": 0.4595,
            "fmeasure": 0.45304
        },
        "rougeL": {
            "precision": 0.61391,
            "recall": 0.60016,
            "fmeasure": 0.59598
        },
        "rougeLsum": {
            "precision": 0.61391,
            "recall": 0.60016,
            "fmeasure": 0.59598
        },
        "local_recall": {
            "1": 0.6307658353564335
        },
        "nist": 7.25053475067898,
        "bleu": 44.55779,
        "bleurt": 0.19884,
        "nubia": {
            "semantic_relation": 4.07497,
            "contradiction": 6.29984,
            "irrelevancy": 16.47159,
            "logical_agreement": 77.22857,
            "grammar_ref": 4.86642,
            "grammar_hyp": 4.7524,
            "nubia_score": 0.7483
        },
        "meteor": 0.3747669332010925,
        "bertscore": {
            "precision": 0.90333,
            "recall": 0.89941,
            "f1": 0.90096
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "T5-large (Baseline)/e2e_nlg_test",
        "N": 1187,
        "msttr-100": 0.29151,
        "msttr-100_nopunct": 0.28635,
        "total_length": 28415,
        "mean_pred_length": 23.938500421229993,
        "std_pred_length": 4.572592477311249,
        "median_pred_length": 24.0,
        "min_pred_length": 14,
        "max_pred_length": 39,
        "distinct-1": 0.009537216259018124,
        "vocab_size-1": 271,
        "unique-1": 47,
        "entropy-1": 5.908944884041417,
        "distinct-2": 0.04095049214044366,
        "vocab_size-2": 1115,
        "unique-2": 316,
        "entropy-2": 7.90173601726388,
        "cond_entropy-2": 1.903003500569318,
        "distinct-3": 0.08083406935217542,
        "vocab_size-3": 2105,
        "unique-3": 693,
        "entropy-3": 9.033619310378677,
        "cond_entropy-3": 1.1418072271930313,
        "total_length-nopunct": 26026,
        "mean_pred_length-nopunct": 21.92586352148273,
        "std_pred_length-nopunct": 4.2120975520051545,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.01033581802812572,
        "vocab_size-1-nopunct": 269,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.946059458364711,
        "distinct-2-nopunct": 0.043278714924111276,
        "vocab_size-2-nopunct": 1075,
        "unique-2-nopunct": 316,
        "entropy-2-nopunct": 7.849400362738874,
        "cond_entropy-2-nopunct": 1.946609097633981,
        "distinct-3-nopunct": 0.08443260612210383,
        "vocab_size-3-nopunct": 1997,
        "unique-3-nopunct": 662,
        "entropy-3-nopunct": 9.03058078851131,
        "cond_entropy-3-nopunct": 1.1728568364052463,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.71403,
            "recall": 0.71406,
            "fmeasure": 0.70209
        },
        "rouge2": {
            "precision": 0.40375,
            "recall": 0.40268,
            "fmeasure": 0.39613
        },
        "rougeL": {
            "precision": 0.49997,
            "recall": 0.49885,
            "fmeasure": 0.49096
        },
        "rougeLsum": {
            "precision": 0.49997,
            "recall": 0.49885,
            "fmeasure": 0.49096
        },
        "local_recall": {
            "1": 0.6997094369815134
        },
        "nist": 4.767625228247511,
        "bleu": 28.78841,
        "bleurt": 0.13821,
        "nubia": {
            "semantic_relation": 4.15405,
            "contradiction": 2.8241,
            "irrelevancy": 36.71384,
            "logical_agreement": 60.46206,
            "grammar_ref": 4.92209,
            "grammar_hyp": 4.54878,
            "nubia_score": 0.74383
        },
        "meteor": 0.35601809642862536,
        "bertscore": {
            "precision": 0.90787,
            "recall": 0.90549,
            "f1": 0.90627
        }
    },
    "xsum_challenge_test_bfp_02": {
        "predictions_file": "T5-large (Baseline)/xsum_challenge_test_bfp_02",
        "N": 500,
        "msttr-100": 0.73302,
        "msttr-100_nopunct": 0.75364,
        "total_length": 10653,
        "mean_pred_length": 21.306,
        "std_pred_length": 4.625187996179182,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 37,
        "distinct-1": 0.27278700835445413,
        "vocab_size-1": 2906,
        "unique-1": 1903,
        "entropy-1": 8.999847015993799,
        "distinct-2": 0.7306214911848715,
        "vocab_size-2": 7418,
        "unique-2": 6440,
        "entropy-2": 12.356105036040377,
        "cond_entropy-2": 3.1326941672383466,
        "distinct-3": 0.9196104837874236,
        "vocab_size-3": 8877,
        "unique-3": 8445,
        "entropy-3": 13.018908358058633,
        "cond_entropy-3": 0.676122985022999,
        "total_length-nopunct": 9929,
        "mean_pred_length-nopunct": 19.858,
        "std_pred_length-nopunct": 4.504424047533713,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.29157014805116327,
        "vocab_size-1-nopunct": 2895,
        "unique-1-nopunct": 1899,
        "entropy-1-nopunct": 9.175216402160864,
        "distinct-2-nopunct": 0.7359210944957048,
        "vocab_size-2-nopunct": 6939,
        "unique-2-nopunct": 6057,
        "entropy-2-nopunct": 12.261533444440257,
        "cond_entropy-2-nopunct": 3.2093508586548025,
        "distinct-3-nopunct": 0.9249636017471161,
        "vocab_size-3-nopunct": 8259,
        "unique-3-nopunct": 7881,
        "entropy-3-nopunct": 12.926916776507447,
        "cond_entropy-3-nopunct": 0.6852827740202727,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_02.json",
        "rouge1": {
            "precision": 0.41638,
            "recall": 0.38505,
            "fmeasure": 0.39287
        },
        "rouge2": {
            "precision": 0.16776,
            "recall": 0.15518,
            "fmeasure": 0.15818
        },
        "rougeL": {
            "precision": 0.3245,
            "recall": 0.29998,
            "fmeasure": 0.30609
        },
        "rougeLsum": {
            "precision": 0.3245,
            "recall": 0.29998,
            "fmeasure": 0.30609
        },
        "local_recall": {
            "1": 0.3595483359746434
        },
        "nist": 3.78489685886052,
        "bleu": 10.70793,
        "bleurt": -0.3337,
        "nubia": {
            "semantic_relation": 2.97543,
            "contradiction": 18.9337,
            "irrelevancy": 65.34416,
            "logical_agreement": 15.72214,
            "grammar_ref": 3.74155,
            "grammar_hyp": 3.63915,
            "nubia_score": 0.44208
        },
        "meteor": 0.17311759057632647,
        "bertscore": {
            "precision": 0.83369,
            "recall": 0.8246,
            "f1": 0.82881
        }
    },
    "cs_restaurants_challenge_test_scramble": {
        "predictions_file": "T5-large (Baseline)/cs_restaurants_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.53966,
        "msttr-100_nopunct": 0.55506,
        "total_length": 8782,
        "mean_pred_length": 17.564,
        "std_pred_length": 6.047636232446525,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 39,
        "distinct-1": 0.06706900478250968,
        "vocab_size-1": 589,
        "unique-1": 231,
        "entropy-1": 6.31715449448947,
        "distinct-2": 0.20200434677614104,
        "vocab_size-2": 1673,
        "unique-2": 924,
        "entropy-2": 8.965892986770127,
        "cond_entropy-2": 2.568057896389064,
        "distinct-3": 0.31804163454124906,
        "vocab_size-3": 2475,
        "unique-3": 1642,
        "entropy-3": 9.664786460845148,
        "cond_entropy-3": 0.7617447850602992,
        "total_length-nopunct": 7901,
        "mean_pred_length-nopunct": 15.802,
        "std_pred_length-nopunct": 5.709185230836359,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.07404126059992407,
        "vocab_size-1-nopunct": 585,
        "unique-1-nopunct": 231,
        "entropy-1-nopunct": 6.327437648233969,
        "distinct-2-nopunct": 0.20132414538575868,
        "vocab_size-2-nopunct": 1490,
        "unique-2-nopunct": 820,
        "entropy-2-nopunct": 8.808960362612908,
        "cond_entropy-2-nopunct": 2.6424948751790938,
        "distinct-3-nopunct": 0.32154760179684105,
        "vocab_size-3-nopunct": 2219,
        "unique-3-nopunct": 1475,
        "entropy-3-nopunct": 9.526561308823437,
        "cond_entropy-3-nopunct": 0.7851497900698606,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_challenge_test_scramble.json",
        "rouge1": {
            "precision": 0.41144,
            "recall": 0.44193,
            "fmeasure": 0.41039
        },
        "rouge2": {
            "precision": 0.22263,
            "recall": 0.23951,
            "fmeasure": 0.2215
        },
        "rougeL": {
            "precision": 0.36263,
            "recall": 0.3928,
            "fmeasure": 0.36322
        },
        "rougeLsum": {
            "precision": 0.36263,
            "recall": 0.3928,
            "fmeasure": 0.36322
        },
        "local_recall": {
            "1": 0.2862799906825064
        },
        "nist": 1.4997617480324548,
        "bleu": 3.62869,
        "bleurt": -0.72274,
        "nubia": {
            "semantic_relation": 2.71076,
            "contradiction": 33.1118,
            "irrelevancy": 28.01498,
            "logical_agreement": 38.87322,
            "grammar_ref": 6.87434,
            "grammar_hyp": 6.03863,
            "nubia_score": 0.32032
        },
        "meteor": 0.13262417951417838,
        "bertscore": {
            "precision": 0.81923,
            "recall": 0.85248,
            "f1": 0.83521
        }
    },
    "xsum_challenge_test_bfp_05": {
        "predictions_file": "T5-large (Baseline)/xsum_challenge_test_bfp_05",
        "N": 500,
        "msttr-100": 0.73274,
        "msttr-100_nopunct": 0.75232,
        "total_length": 10688,
        "mean_pred_length": 21.376,
        "std_pred_length": 4.671040997465126,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 42,
        "distinct-1": 0.2794723053892216,
        "vocab_size-1": 2987,
        "unique-1": 2031,
        "entropy-1": 8.992975057635956,
        "distinct-2": 0.7276207302709069,
        "vocab_size-2": 7413,
        "unique-2": 6457,
        "entropy-2": 12.325773603111939,
        "cond_entropy-2": 3.1117577511525107,
        "distinct-3": 0.9176300578034682,
        "vocab_size-3": 8890,
        "unique-3": 8455,
        "entropy-3": 13.015823001072707,
        "cond_entropy-3": 0.6976379496791284,
        "total_length-nopunct": 9959,
        "mean_pred_length-nopunct": 19.918,
        "std_pred_length-nopunct": 4.471160475760181,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.29872477156341,
        "vocab_size-1-nopunct": 2975,
        "unique-1-nopunct": 2028,
        "entropy-1-nopunct": 9.159649886617409,
        "distinct-2-nopunct": 0.7345385347288297,
        "vocab_size-2-nopunct": 6948,
        "unique-2-nopunct": 6090,
        "entropy-2-nopunct": 12.238642696371015,
        "cond_entropy-2-nopunct": 3.1944550458983834,
        "distinct-3-nopunct": 0.9237638129255498,
        "vocab_size-3-nopunct": 8276,
        "unique-3-nopunct": 7890,
        "entropy-3-nopunct": 12.92573167720852,
        "cond_entropy-3-nopunct": 0.7056600841664769,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_05.json",
        "rouge1": {
            "precision": 0.39533,
            "recall": 0.36973,
            "fmeasure": 0.37463
        },
        "rouge2": {
            "precision": 0.14777,
            "recall": 0.13681,
            "fmeasure": 0.13908
        },
        "rougeL": {
            "precision": 0.30714,
            "recall": 0.28768,
            "fmeasure": 0.29128
        },
        "rougeLsum": {
            "precision": 0.30714,
            "recall": 0.28768,
            "fmeasure": 0.29128
        },
        "local_recall": {
            "1": 0.34169653524492233
        },
        "nist": 3.543723130924506,
        "bleu": 9.13168,
        "bleurt": -0.43679,
        "nubia": {
            "semantic_relation": 2.79467,
            "contradiction": 21.11822,
            "irrelevancy": 65.05504,
            "logical_agreement": 13.82674,
            "grammar_ref": 3.79385,
            "grammar_hyp": 3.87377,
            "nubia_score": 0.38691
        },
        "meteor": 0.1640577177495218,
        "bertscore": {
            "precision": 0.82415,
            "recall": 0.81858,
            "f1": 0.82105
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-5": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 958,
        "msttr-100": 0.66826,
        "msttr-100_nopunct": 0.69301,
        "total_length": 20785,
        "mean_pred_length": 21.69624217118998,
        "std_pred_length": 5.989605337584188,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 45,
        "distinct-1": 0.08222275679576618,
        "vocab_size-1": 1709,
        "unique-1": 809,
        "entropy-1": 7.725577181739995,
        "distinct-2": 0.26468956473495736,
        "vocab_size-2": 5248,
        "unique-2": 3171,
        "entropy-2": 10.656504384568139,
        "cond_entropy-2": 2.7930796735136814,
        "distinct-3": 0.45137527160951824,
        "vocab_size-3": 8517,
        "unique-3": 5970,
        "entropy-3": 12.045152645952749,
        "cond_entropy-3": 1.4598709046928058,
        "total_length-nopunct": 18307,
        "mean_pred_length-nopunct": 19.109603340292274,
        "std_pred_length-nopunct": 5.481177856867169,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.0925875348227454,
        "vocab_size-1-nopunct": 1695,
        "unique-1-nopunct": 806,
        "entropy-1-nopunct": 7.941345982436947,
        "distinct-2-nopunct": 0.2830134301688858,
        "vocab_size-2-nopunct": 4910,
        "unique-2-nopunct": 3054,
        "entropy-2-nopunct": 10.634319947242952,
        "cond_entropy-2-nopunct": 2.836894258971792,
        "distinct-3-nopunct": 0.48014154108962237,
        "vocab_size-3-nopunct": 7870,
        "unique-3-nopunct": 5596,
        "entropy-3-nopunct": 12.058300730848531,
        "cond_entropy-3-nopunct": 1.5093839908755404,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.62837,
            "recall": 0.61392,
            "fmeasure": 0.61092
        },
        "rouge2": {
            "precision": 0.3928,
            "recall": 0.38382,
            "fmeasure": 0.38153
        },
        "rougeL": {
            "precision": 0.54712,
            "recall": 0.53496,
            "fmeasure": 0.53222
        },
        "rougeLsum": {
            "precision": 0.54712,
            "recall": 0.53496,
            "fmeasure": 0.53222
        },
        "local_recall": {
            "1": 0.6006234060640409
        },
        "nist": 6.429572908397594,
        "bleu": 31.21394,
        "bleurt": -0.06686,
        "nubia": {
            "semantic_relation": 4.28023,
            "contradiction": 5.6033,
            "irrelevancy": 20.31063,
            "logical_agreement": 74.08607,
            "grammar_ref": 4.83769,
            "grammar_hyp": 4.75462,
            "nubia_score": 0.73679
        },
        "meteor": 0.33250809613242965,
        "bertscore": {
            "precision": 0.88184,
            "recall": 0.87858,
            "f1": 0.87981
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-9": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 72,
        "msttr-100": 0.65636,
        "msttr-100_nopunct": 0.67053,
        "total_length": 2240,
        "mean_pred_length": 31.11111111111111,
        "std_pred_length": 9.417117327793687,
        "median_pred_length": 31.0,
        "min_pred_length": 9,
        "max_pred_length": 58,
        "distinct-1": 0.190625,
        "vocab_size-1": 427,
        "unique-1": 226,
        "entropy-1": 7.152504929592067,
        "distinct-2": 0.47001845018450183,
        "vocab_size-2": 1019,
        "unique-2": 678,
        "entropy-2": 9.282617567372819,
        "cond_entropy-2": 2.0674238781958794,
        "distinct-3": 0.6631679389312977,
        "vocab_size-3": 1390,
        "unique-3": 1093,
        "entropy-3": 10.045231009149605,
        "cond_entropy-3": 0.7529445215646984,
        "total_length-nopunct": 1998,
        "mean_pred_length-nopunct": 27.75,
        "std_pred_length-nopunct": 8.714212528966687,
        "median_pred_length-nopunct": 28.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 50,
        "distinct-1-nopunct": 0.2097097097097097,
        "vocab_size-1-nopunct": 419,
        "unique-1-nopunct": 224,
        "entropy-1-nopunct": 7.232998245587248,
        "distinct-2-nopunct": 0.49584631360332293,
        "vocab_size-2-nopunct": 955,
        "unique-2-nopunct": 647,
        "entropy-2-nopunct": 9.2323495139473,
        "cond_entropy-2-nopunct": 2.004511003207988,
        "distinct-3-nopunct": 0.6882416396979504,
        "vocab_size-3-nopunct": 1276,
        "unique-3-nopunct": 1029,
        "entropy-3-nopunct": 9.94664198948058,
        "cond_entropy-3-nopunct": 0.7298786344668585,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.66434,
            "recall": 0.58783,
            "fmeasure": 0.61551
        },
        "rouge2": {
            "precision": 0.42363,
            "recall": 0.37069,
            "fmeasure": 0.38944
        },
        "rougeL": {
            "precision": 0.52368,
            "recall": 0.46074,
            "fmeasure": 0.48328
        },
        "rougeLsum": {
            "precision": 0.52368,
            "recall": 0.46074,
            "fmeasure": 0.48328
        },
        "local_recall": {
            "1": 0.609258337481334
        },
        "nist": 5.728911075384467,
        "bleu": 32.69628,
        "bleurt": -0.09428,
        "nubia": {
            "semantic_relation": 4.00478,
            "contradiction": 3.09795,
            "irrelevancy": 15.05603,
            "logical_agreement": 81.84602,
            "grammar_ref": 4.20036,
            "grammar_hyp": 4.28199,
            "nubia_score": 0.66187
        },
        "meteor": 0.33525569601386784,
        "bertscore": {
            "precision": 0.89701,
            "recall": 0.87669,
            "f1": 0.88637
        }
    },
    "xsum_challenge_test_nopunc": {
        "predictions_file": "T5-large (Baseline)/xsum_challenge_test_nopunc",
        "N": 500,
        "msttr-100": 0.73849,
        "msttr-100_nopunct": 0.76333,
        "total_length": 10634,
        "mean_pred_length": 21.268,
        "std_pred_length": 4.668637488604143,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 37,
        "distinct-1": 0.27863456836561973,
        "vocab_size-1": 2963,
        "unique-1": 1927,
        "entropy-1": 9.090578770029511,
        "distinct-2": 0.745608841523584,
        "vocab_size-2": 7556,
        "unique-2": 6614,
        "entropy-2": 12.419676805154245,
        "cond_entropy-2": 3.100513196341691,
        "distinct-3": 0.9281710608262403,
        "vocab_size-3": 8942,
        "unique-3": 8555,
        "entropy-3": 13.044476341738124,
        "cond_entropy-3": 0.6323814668066012,
        "total_length-nopunct": 9904,
        "mean_pred_length-nopunct": 19.808,
        "std_pred_length-nopunct": 4.485881853103133,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.29796042003231016,
        "vocab_size-1-nopunct": 2951,
        "unique-1-nopunct": 1924,
        "entropy-1-nopunct": 9.270885540521478,
        "distinct-2-nopunct": 0.7514887282007656,
        "vocab_size-2-nopunct": 7067,
        "unique-2-nopunct": 6215,
        "entropy-2-nopunct": 12.325740229731075,
        "cond_entropy-2-nopunct": 3.1701314603872444,
        "distinct-3-nopunct": 0.9328391734052112,
        "vocab_size-3-nopunct": 8306,
        "unique-3-nopunct": 7961,
        "entropy-3-nopunct": 12.948464308245969,
        "cond_entropy-3-nopunct": 0.6396646221012652,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_nopunc.json",
        "rouge1": {
            "precision": 0.42391,
            "recall": 0.39535,
            "fmeasure": 0.40128
        },
        "rouge2": {
            "precision": 0.17966,
            "recall": 0.16488,
            "fmeasure": 0.16848
        },
        "rougeL": {
            "precision": 0.33881,
            "recall": 0.31346,
            "fmeasure": 0.31959
        },
        "rougeLsum": {
            "precision": 0.33881,
            "recall": 0.31346,
            "fmeasure": 0.31959
        },
        "local_recall": {
            "1": 0.36721574929690637
        },
        "nist": 3.9446799144786144,
        "bleu": 11.56911,
        "bleurt": -0.27591,
        "nubia": {
            "semantic_relation": 3.03052,
            "contradiction": 18.27646,
            "irrelevancy": 64.60071,
            "logical_agreement": 17.12283,
            "grammar_ref": 3.78318,
            "grammar_hyp": 3.64065,
            "nubia_score": 0.45771
        },
        "meteor": 0.18040840915190948,
        "bertscore": {
            "precision": 0.84022,
            "recall": 0.82856,
            "f1": 0.83405
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-10": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 1024,
        "msttr-100": 0.50798,
        "msttr-100_nopunct": 0.53321,
        "total_length": 9972,
        "mean_pred_length": 9.73828125,
        "std_pred_length": 5.910948806739781,
        "median_pred_length": 6.0,
        "min_pred_length": 3,
        "max_pred_length": 34,
        "distinct-1": 0.07862013638186924,
        "vocab_size-1": 784,
        "unique-1": 434,
        "entropy-1": 6.436749519977446,
        "distinct-2": 0.2341305319624497,
        "vocab_size-2": 2095,
        "unique-2": 1267,
        "entropy-2": 9.100734376333312,
        "cond_entropy-2": 2.344089155728538,
        "distinct-3": 0.39979808177688037,
        "vocab_size-3": 3168,
        "unique-3": 2208,
        "entropy-3": 10.261962976836399,
        "cond_entropy-3": 1.1206350616947784,
        "total_length-nopunct": 8491,
        "mean_pred_length-nopunct": 8.2919921875,
        "std_pred_length-nopunct": 5.249041424387786,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.09115534094924037,
        "vocab_size-1-nopunct": 774,
        "unique-1-nopunct": 432,
        "entropy-1-nopunct": 6.663330383323309,
        "distinct-2-nopunct": 0.25873844917637606,
        "vocab_size-2-nopunct": 1932,
        "unique-2-nopunct": 1221,
        "entropy-2-nopunct": 9.01080761302841,
        "cond_entropy-2-nopunct": 2.504360249948079,
        "distinct-3-nopunct": 0.44234052460034146,
        "vocab_size-3-nopunct": 2850,
        "unique-3-nopunct": 2062,
        "entropy-3-nopunct": 10.218395835668925,
        "cond_entropy-3-nopunct": 1.150353328604917,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.40827,
            "recall": 0.37817,
            "fmeasure": 0.3817
        },
        "rouge2": {
            "precision": 0.18972,
            "recall": 0.1811,
            "fmeasure": 0.18099
        },
        "rougeL": {
            "precision": 0.36415,
            "recall": 0.3357,
            "fmeasure": 0.33935
        },
        "rougeLsum": {
            "precision": 0.36415,
            "recall": 0.3357,
            "fmeasure": 0.33935
        },
        "local_recall": {
            "1": 0.40587654862405437
        },
        "nist": 4.258620980029771,
        "bleu": 22.72444,
        "bleurt": -0.55948,
        "nubia": {
            "semantic_relation": 2.46348,
            "contradiction": 11.7806,
            "irrelevancy": 31.12786,
            "logical_agreement": 57.09154,
            "grammar_ref": 5.2128,
            "grammar_hyp": 5.11661,
            "nubia_score": 0.40176
        },
        "meteor": 0.23688133958622945,
        "bertscore": {
            "precision": 0.8464,
            "recall": 0.83563,
            "f1": 0.84057
        }
    },
    "xsum_challenge_test_covid": {
        "predictions_file": "T5-large (Baseline)/xsum_challenge_test_covid",
        "N": 401,
        "msttr-100": 0.69409,
        "msttr-100_nopunct": 0.71218,
        "total_length": 9399,
        "mean_pred_length": 23.438902743142144,
        "std_pred_length": 4.963897872418203,
        "median_pred_length": 23.0,
        "min_pred_length": 5,
        "max_pred_length": 38,
        "distinct-1": 0.19831897010320246,
        "vocab_size-1": 1864,
        "unique-1": 1120,
        "entropy-1": 8.268492425479216,
        "distinct-2": 0.5777950655701267,
        "vocab_size-2": 5199,
        "unique-2": 4177,
        "entropy-2": 11.51967209470855,
        "cond_entropy-2": 3.0866216535671587,
        "distinct-3": 0.7995812492730022,
        "vocab_size-3": 6874,
        "unique-3": 6161,
        "entropy-3": 12.44534240113344,
        "cond_entropy-3": 0.9199837756349895,
        "total_length-nopunct": 8708,
        "mean_pred_length-nopunct": 21.71571072319202,
        "std_pred_length-nopunct": 4.7510573760620005,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.21290767110702802,
        "vocab_size-1-nopunct": 1854,
        "unique-1-nopunct": 1117,
        "entropy-1-nopunct": 8.396795370548256,
        "distinct-2-nopunct": 0.5935957626098471,
        "vocab_size-2-nopunct": 4931,
        "unique-2-nopunct": 4011,
        "entropy-2-nopunct": 11.453534511791469,
        "cond_entropy-2-nopunct": 3.1244259847799767,
        "distinct-3-nopunct": 0.8130533771818872,
        "vocab_size-3-nopunct": 6428,
        "unique-3-nopunct": 5809,
        "entropy-3-nopunct": 12.364365620324037,
        "cond_entropy-3-nopunct": 0.9084241505296454,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_covid.json",
        "rouge1": {
            "precision": 0.32051,
            "recall": 0.31351,
            "fmeasure": 0.30925
        },
        "rouge2": {
            "precision": 0.09943,
            "recall": 0.09939,
            "fmeasure": 0.09707
        },
        "rougeL": {
            "precision": 0.24136,
            "recall": 0.23796,
            "fmeasure": 0.23356
        },
        "rougeLsum": {
            "precision": 0.24136,
            "recall": 0.23796,
            "fmeasure": 0.23356
        },
        "local_recall": {
            "1": 0.28952426717924074
        },
        "nist": 2.6507812021528037,
        "bleu": 6.77172,
        "bleurt": -0.48945,
        "nubia": {
            "semantic_relation": 2.41179,
            "contradiction": 18.61634,
            "irrelevancy": 70.17477,
            "logical_agreement": 11.20889,
            "grammar_ref": 4.04957,
            "grammar_hyp": 3.66825,
            "nubia_score": 0.33711
        },
        "meteor": 0.13500078037447907,
        "bertscore": {
            "precision": 0.79928,
            "recall": 0.79167,
            "f1": 0.79514
        }
    },
    "web_nlg_ru_challenge_test_scramble_parent": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_test",
        "N": 500,
        "msttr-100": 0.44215,
        "msttr-100_nopunct": 0.43767,
        "total_length": 22324,
        "mean_pred_length": 44.648,
        "std_pred_length": 20.14368625649238,
        "median_pred_length": 44.0,
        "min_pred_length": 9,
        "max_pred_length": 85,
        "distinct-1": 0.0811234545780326,
        "vocab_size-1": 1811,
        "unique-1": 757,
        "entropy-1": 5.916861708552101,
        "distinct-2": 0.22264479472140764,
        "vocab_size-2": 4859,
        "unique-2": 2589,
        "entropy-2": 10.235800112650784,
        "cond_entropy-2": 4.315042876898193,
        "distinct-3": 0.4012380416432189,
        "vocab_size-3": 8556,
        "unique-3": 5414,
        "entropy-3": 11.944959430708446,
        "cond_entropy-3": 1.7475485683639118,
        "total_length-nopunct": 20619,
        "mean_pred_length-nopunct": 41.238,
        "std_pred_length-nopunct": 19.016975469301105,
        "median_pred_length-nopunct": 41.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 80,
        "distinct-1-nopunct": 0.08734662204762597,
        "vocab_size-1-nopunct": 1801,
        "unique-1-nopunct": 755,
        "entropy-1-nopunct": 5.8245414869495,
        "distinct-2-nopunct": 0.22252597047566977,
        "vocab_size-2-nopunct": 4477,
        "unique-2-nopunct": 2377,
        "entropy-2-nopunct": 10.103627893805221,
        "cond_entropy-2-nopunct": 4.367115632571,
        "distinct-3-nopunct": 0.3986441714664356,
        "vocab_size-3-nopunct": 7821,
        "unique-3-nopunct": 5000,
        "entropy-3-nopunct": 11.778980537393876,
        "cond_entropy-3-nopunct": 1.7120278815125907,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.41893,
            "recall": 0.40053,
            "fmeasure": 0.40291
        },
        "rouge2": {
            "precision": 0.19637,
            "recall": 0.18886,
            "fmeasure": 0.18966
        },
        "rougeL": {
            "precision": 0.39394,
            "recall": 0.37806,
            "fmeasure": 0.3793
        },
        "rougeLsum": {
            "precision": 0.39394,
            "recall": 0.37806,
            "fmeasure": 0.3793
        },
        "local_recall": {
            "1": 0.09126466753585398,
            "2": 0.1796969696969697,
            "3": 0.25528317836010145,
            "4": 0.17777777777777778,
            "5": 0.4,
            "6": 0.3333333333333333
        },
        "nist": 1.1069845315353166,
        "bleu": 1.9484,
        "bleurt": -0.48665,
        "nubia": {
            "semantic_relation": 3.3057,
            "contradiction": 34.24066,
            "irrelevancy": 16.98107,
            "logical_agreement": 48.77827,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.643,
            "nubia_score": 0.15914
        },
        "meteor": 0.12238217557500618,
        "bertscore": {
            "precision": 0.8603,
            "recall": 0.87153,
            "f1": 0.8654
        }
    },
    "web_nlg_en_challenge_test_scramble_parent": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 500,
        "msttr-100": 0.5359,
        "msttr-100_nopunct": 0.54972,
        "total_length": 12278,
        "mean_pred_length": 24.556,
        "std_pred_length": 12.318070628146275,
        "median_pred_length": 22.0,
        "min_pred_length": 7,
        "max_pred_length": 65,
        "distinct-1": 0.12200684150513112,
        "vocab_size-1": 1498,
        "unique-1": 581,
        "entropy-1": 7.977443126874158,
        "distinct-2": 0.36890813380879606,
        "vocab_size-2": 4345,
        "unique-2": 2516,
        "entropy-2": 11.163998307284702,
        "cond_entropy-2": 3.0160025966794453,
        "distinct-3": 0.5747472956197908,
        "vocab_size-3": 6482,
        "unique-3": 4599,
        "entropy-3": 12.188389567190267,
        "cond_entropy-3": 1.06873654665216,
        "total_length-nopunct": 10836,
        "mean_pred_length-nopunct": 21.672,
        "std_pred_length-nopunct": 11.09794647671361,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 58,
        "distinct-1-nopunct": 0.1374123292727944,
        "vocab_size-1-nopunct": 1489,
        "unique-1-nopunct": 580,
        "entropy-1-nopunct": 8.261722611942911,
        "distinct-2-nopunct": 0.38651315789473684,
        "vocab_size-2-nopunct": 3995,
        "unique-2-nopunct": 2417,
        "entropy-2-nopunct": 11.075457889608039,
        "cond_entropy-2-nopunct": 2.944452058345909,
        "distinct-3-nopunct": 0.5890605937372916,
        "vocab_size-3-nopunct": 5794,
        "unique-3-nopunct": 4215,
        "entropy-3-nopunct": 12.030412940410187,
        "cond_entropy-3-nopunct": 0.9946861040828038,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.67123,
            "recall": 0.67334,
            "fmeasure": 0.66552
        },
        "rouge2": {
            "precision": 0.38774,
            "recall": 0.38719,
            "fmeasure": 0.38333
        },
        "rougeL": {
            "precision": 0.51566,
            "recall": 0.5174,
            "fmeasure": 0.51091
        },
        "rougeLsum": {
            "precision": 0.51566,
            "recall": 0.5174,
            "fmeasure": 0.51091
        },
        "local_recall": {
            "1": 0.22020162087369044,
            "2": 0.5232439769256871,
            "3": 0.7741211667913238,
            "4": 0.4,
            "5": 0.6111111111111112
        },
        "nist": 7.671191470478472,
        "bleu": 37.82927,
        "bleurt": -0.03601,
        "nubia": {
            "semantic_relation": 3.96046,
            "contradiction": 22.61788,
            "irrelevancy": 11.18517,
            "logical_agreement": 66.19695,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.63877,
            "nubia_score": 0.64953
        },
        "meteor": 0.3334851424449668,
        "bertscore": {
            "precision": 0.89153,
            "recall": 0.89331,
            "f1": 0.89121
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "T5-large (Baseline)/e2e_nlg_test",
        "N": 1406,
        "msttr-100": 0.31003,
        "msttr-100_nopunct": 0.30319,
        "total_length": 37569,
        "mean_pred_length": 26.720483641536273,
        "std_pred_length": 4.957368043314237,
        "median_pred_length": 26.0,
        "min_pred_length": 16,
        "max_pred_length": 51,
        "distinct-1": 0.006627804839096064,
        "vocab_size-1": 249,
        "unique-1": 42,
        "entropy-1": 5.874427395008609,
        "distinct-2": 0.03301717224787767,
        "vocab_size-2": 1194,
        "unique-2": 266,
        "entropy-2": 8.016286365352778,
        "cond_entropy-2": 2.064684110539164,
        "distinct-3": 0.0733952872802601,
        "vocab_size-3": 2551,
        "unique-3": 630,
        "entropy-3": 9.355031439916294,
        "cond_entropy-3": 1.343360048032234,
        "total_length-nopunct": 34293,
        "mean_pred_length-nopunct": 24.390469416785205,
        "std_pred_length-nopunct": 4.541936118625974,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 48,
        "distinct-1-nopunct": 0.007173475636427259,
        "vocab_size-1-nopunct": 246,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.900733760049398,
        "distinct-2-nopunct": 0.0360932891416061,
        "vocab_size-2-nopunct": 1187,
        "unique-2-nopunct": 277,
        "entropy-2-nopunct": 7.961131278856932,
        "cond_entropy-2-nopunct": 2.0963498003530248,
        "distinct-3-nopunct": 0.07849178869794479,
        "vocab_size-3-nopunct": 2471,
        "unique-3-nopunct": 644,
        "entropy-3-nopunct": 9.332964567308595,
        "cond_entropy-3-nopunct": 1.3626792299239074,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.77522,
            "recall": 0.71194,
            "fmeasure": 0.7334
        },
        "rouge2": {
            "precision": 0.46183,
            "recall": 0.42466,
            "fmeasure": 0.43701
        },
        "rougeL": {
            "precision": 0.52615,
            "recall": 0.48382,
            "fmeasure": 0.49811
        },
        "rougeLsum": {
            "precision": 0.52615,
            "recall": 0.48382,
            "fmeasure": 0.49811
        },
        "local_recall": {
            "1": 0.6939153680245451
        },
        "nist": 5.126043574764579,
        "bleu": 30.07551,
        "bleurt": 0.23896,
        "nubia": {
            "semantic_relation": 4.45793,
            "contradiction": 2.3159,
            "irrelevancy": 13.58851,
            "logical_agreement": 84.09559,
            "grammar_ref": 4.68084,
            "grammar_hyp": 4.46125,
            "nubia_score": 0.81541
        },
        "meteor": 0.3621641877583726,
        "bertscore": {
            "precision": 0.91988,
            "recall": 0.90647,
            "f1": 0.91289
        }
    },
    "web_nlg_en_challenge_test_numbers_parent": {
        "predictions_file": "T5-large (Baseline)/web_nlg_en_test",
        "N": 500,
        "msttr-100": 0.64161,
        "msttr-100_nopunct": 0.68615,
        "total_length": 12422,
        "mean_pred_length": 24.844,
        "std_pred_length": 12.312743967126092,
        "median_pred_length": 23.0,
        "min_pred_length": 5,
        "max_pred_length": 66,
        "distinct-1": 0.12155852519723072,
        "vocab_size-1": 1510,
        "unique-1": 591,
        "entropy-1": 8.001727956661586,
        "distinct-2": 0.3633618520382486,
        "vocab_size-2": 4332,
        "unique-2": 2511,
        "entropy-2": 11.158628524807728,
        "cond_entropy-2": 2.988866780934818,
        "distinct-3": 0.5661880581334268,
        "vocab_size-3": 6467,
        "unique-3": 4612,
        "entropy-3": 12.153682391147326,
        "cond_entropy-3": 1.0408412638082516,
        "total_length-nopunct": 10975,
        "mean_pred_length-nopunct": 21.95,
        "std_pred_length-nopunct": 11.078786034579782,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 59,
        "distinct-1-nopunct": 0.1366742596810934,
        "vocab_size-1-nopunct": 1500,
        "unique-1-nopunct": 590,
        "entropy-1-nopunct": 8.284259178842646,
        "distinct-2-nopunct": 0.3794749403341289,
        "vocab_size-2-nopunct": 3975,
        "unique-2-nopunct": 2405,
        "entropy-2-nopunct": 11.05862146871004,
        "cond_entropy-2-nopunct": 2.904039067703903,
        "distinct-3-nopunct": 0.5796491228070175,
        "vocab_size-3-nopunct": 5782,
        "unique-3-nopunct": 4243,
        "entropy-3-nopunct": 11.990996300659628,
        "cond_entropy-3-nopunct": 0.974050059314666,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.68739,
            "recall": 0.67937,
            "fmeasure": 0.67617
        },
        "rouge2": {
            "precision": 0.41056,
            "recall": 0.40726,
            "fmeasure": 0.40415
        },
        "rougeL": {
            "precision": 0.53094,
            "recall": 0.52831,
            "fmeasure": 0.52354
        },
        "rougeLsum": {
            "precision": 0.53094,
            "recall": 0.52831,
            "fmeasure": 0.52354
        },
        "local_recall": {
            "1": 0.2195274932051014,
            "2": 0.5300997592019264,
            "3": 0.777379458684352,
            "4": 0.7777777777777778,
            "5": 0.8181818181818182
        },
        "nist": 7.759626229298737,
        "bleu": 39.72001,
        "bleurt": -0.02332,
        "nubia": {
            "semantic_relation": 3.98573,
            "contradiction": 23.25859,
            "irrelevancy": 11.00787,
            "logical_agreement": 65.73355,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.59679,
            "nubia_score": 0.65151
        },
        "meteor": 0.3399342667733884,
        "bertscore": {
            "precision": 0.89742,
            "recall": 0.89678,
            "f1": 0.89567
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 5049,
        "msttr-100": 0.57019,
        "msttr-100_nopunct": 0.59648,
        "total_length": 37665,
        "mean_pred_length": 7.459893048128342,
        "std_pred_length": 2.8313011600869875,
        "median_pred_length": 7.0,
        "min_pred_length": 2,
        "max_pred_length": 28,
        "distinct-1": 0.03201911589008363,
        "vocab_size-1": 1206,
        "unique-1": 515,
        "entropy-1": 6.875650459341122,
        "distinct-2": 0.12978292862398821,
        "vocab_size-2": 4233,
        "unique-2": 2144,
        "entropy-2": 9.555880507112544,
        "cond_entropy-2": 2.298278356047676,
        "distinct-3": 0.23524503935865346,
        "vocab_size-3": 6485,
        "unique-3": 3949,
        "entropy-3": 10.551502558751903,
        "cond_entropy-3": 1.014135224474609,
        "total_length-nopunct": 32111,
        "mean_pred_length-nopunct": 6.359873242226183,
        "std_pred_length-nopunct": 2.6314937623799994,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.03724580361869764,
        "vocab_size-1-nopunct": 1196,
        "unique-1-nopunct": 515,
        "entropy-1-nopunct": 7.054450531794985,
        "distinct-2-nopunct": 0.13435814056610745,
        "vocab_size-2-nopunct": 3636,
        "unique-2-nopunct": 1916,
        "entropy-2-nopunct": 9.263066301835522,
        "cond_entropy-2-nopunct": 2.4091674684541053,
        "distinct-3-nopunct": 0.23912451185178457,
        "vocab_size-3-nopunct": 5266,
        "unique-3-nopunct": 3295,
        "entropy-3-nopunct": 10.170797739089277,
        "cond_entropy-3-nopunct": 1.0301378873302787,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.50377,
            "recall": 0.47931,
            "fmeasure": 0.47834
        },
        "rouge2": {
            "precision": 0.29567,
            "recall": 0.28366,
            "fmeasure": 0.28117
        },
        "rougeL": {
            "precision": 0.47741,
            "recall": 0.45334,
            "fmeasure": 0.45315
        },
        "rougeLsum": {
            "precision": 0.47741,
            "recall": 0.45334,
            "fmeasure": 0.45315
        },
        "local_recall": {
            "1": 0.45859928558880364
        },
        "nist": 4.685727706213998,
        "bleu": 25.82414,
        "bleurt": -0.11573,
        "nubia": {
            "semantic_relation": 3.15154,
            "contradiction": 7.47363,
            "irrelevancy": 25.11821,
            "logical_agreement": 67.40816,
            "grammar_ref": 4.77787,
            "grammar_hyp": 4.5935,
            "nubia_score": 0.57307
        },
        "meteor": 0.261622145266956,
        "bertscore": {
            "precision": 0.85792,
            "recall": 0.85031,
            "f1": 0.85348
        }
    },
    "e2e_nlg_challenge_test_scramble_parent": {
        "predictions_file": "T5-large (Baseline)/e2e_nlg_test",
        "N": 500,
        "msttr-100": 0.50732,
        "msttr-100_nopunct": 0.5244,
        "total_length": 12723,
        "mean_pred_length": 25.446,
        "std_pred_length": 6.771933549585377,
        "median_pred_length": 25.0,
        "min_pred_length": 8,
        "max_pred_length": 51,
        "distinct-1": 0.021850192564646702,
        "vocab_size-1": 278,
        "unique-1": 68,
        "entropy-1": 6.104342715204899,
        "distinct-2": 0.09629387220813221,
        "vocab_size-2": 1177,
        "unique-2": 495,
        "entropy-2": 8.28991337048038,
        "cond_entropy-2": 2.0962342625279686,
        "distinct-3": 0.19406295316898406,
        "vocab_size-3": 2275,
        "unique-3": 1139,
        "entropy-3": 9.598479182904232,
        "cond_entropy-3": 1.3190447907842735,
        "total_length-nopunct": 11614,
        "mean_pred_length-nopunct": 23.228,
        "std_pred_length-nopunct": 6.22736027542971,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 48,
        "distinct-1-nopunct": 0.023678319269846735,
        "vocab_size-1-nopunct": 275,
        "unique-1-nopunct": 67,
        "entropy-1-nopunct": 6.153551491525368,
        "distinct-2-nopunct": 0.10284326075220443,
        "vocab_size-2-nopunct": 1143,
        "unique-2-nopunct": 503,
        "entropy-2-nopunct": 8.236313199281868,
        "cond_entropy-2-nopunct": 2.128359254974714,
        "distinct-3-nopunct": 0.2034105897870737,
        "vocab_size-3-nopunct": 2159,
        "unique-3-nopunct": 1101,
        "entropy-3-nopunct": 9.581766387082025,
        "cond_entropy-3-nopunct": 1.3417676974015313,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.73396,
            "recall": 0.70888,
            "fmeasure": 0.71005
        },
        "rouge2": {
            "precision": 0.42972,
            "recall": 0.41474,
            "fmeasure": 0.41534
        },
        "rougeL": {
            "precision": 0.50598,
            "recall": 0.48902,
            "fmeasure": 0.48956
        },
        "rougeLsum": {
            "precision": 0.50598,
            "recall": 0.48902,
            "fmeasure": 0.48956
        },
        "local_recall": {
            "1": 0.6990607272389101
        },
        "nist": 5.2177301870558495,
        "bleu": 29.99039,
        "bleurt": 0.15665,
        "nubia": {
            "semantic_relation": 4.2591,
            "contradiction": 3.37442,
            "irrelevancy": 27.02069,
            "logical_agreement": 69.60489,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.49923,
            "nubia_score": 0.76401
        },
        "meteor": 0.35914859598912297,
        "bertscore": {
            "precision": 0.91149,
            "recall": 0.90427,
            "f1": 0.90753
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation_parent": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72264,
        "msttr-100_nopunct": 0.76841,
        "total_length": 7213,
        "mean_pred_length": 20.091922005571032,
        "std_pred_length": 9.49445910452566,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.3666990156661583,
        "vocab_size-1": 2645,
        "unique-1": 1952,
        "entropy-1": 9.126331215578004,
        "distinct-2": 0.8262328567259994,
        "vocab_size-2": 5663,
        "unique-2": 5225,
        "entropy-2": 12.115099856400926,
        "cond_entropy-2": 2.7291720972784907,
        "distinct-3": 0.9575057736720555,
        "vocab_size-3": 6219,
        "unique-3": 6091,
        "entropy-3": 12.51846472638313,
        "cond_entropy-3": 0.42154667407596275,
        "total_length-nopunct": 6370,
        "mean_pred_length-nopunct": 17.74373259052925,
        "std_pred_length-nopunct": 8.28470137515936,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.41334379905808477,
        "vocab_size-1-nopunct": 2633,
        "unique-1-nopunct": 1949,
        "entropy-1-nopunct": 9.490784012020617,
        "distinct-2-nopunct": 0.8481117950424222,
        "vocab_size-2-nopunct": 5098,
        "unique-2-nopunct": 4740,
        "entropy-2-nopunct": 12.022647785553223,
        "cond_entropy-2-nopunct": 2.672958492128687,
        "distinct-3-nopunct": 0.97310686482661,
        "vocab_size-3-nopunct": 5500,
        "unique-3-nopunct": 5399,
        "entropy-3-nopunct": 12.396973766549186,
        "cond_entropy-3-nopunct": 0.40135611026316653,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.88638,
            "recall": 0.86124,
            "fmeasure": 0.86462
        },
        "rouge2": {
            "precision": 0.78287,
            "recall": 0.76144,
            "fmeasure": 0.76029
        },
        "rougeL": {
            "precision": 0.86875,
            "recall": 0.8461,
            "fmeasure": 0.84782
        },
        "rougeLsum": {
            "precision": 0.86875,
            "recall": 0.8461,
            "fmeasure": 0.84782
        },
        "local_recall": {
            "1": 0.03031973539140022,
            "2": 0.15566037735849056,
            "3": 0.336144578313253,
            "4": 0.555045871559633,
            "5": 0.6722306525037937,
            "6": 0.7492957746478873,
            "7": 0.8292349726775956,
            "8": 0.8576598311218335,
            "9": 0.9026455026455027,
            "10": 0.9441860465116279
        },
        "nist": 13.071812397108598,
        "bleu": 84.31801,
        "bleurt": 0.21901,
        "nubia": {
            "semantic_relation": 4.20837,
            "contradiction": 3.35002,
            "irrelevancy": 31.71486,
            "logical_agreement": 64.93513,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.775,
            "nubia_score": 0.6471
        },
        "meteor": 0.5239953121659693,
        "bertscore": {
            "precision": 0.96702,
            "recall": 0.96512,
            "f1": 0.9629
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-11": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 1246,
        "msttr-100": 0.66495,
        "msttr-100_nopunct": 0.68337,
        "total_length": 19231,
        "mean_pred_length": 15.434189406099518,
        "std_pred_length": 5.3645665493756995,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 42,
        "distinct-1": 0.09957880505433934,
        "vocab_size-1": 1915,
        "unique-1": 915,
        "entropy-1": 7.915953675784717,
        "distinct-2": 0.29702529886016127,
        "vocab_size-2": 5342,
        "unique-2": 3253,
        "entropy-2": 10.742566136828449,
        "cond_entropy-2": 2.6240901963328653,
        "distinct-3": 0.48354143019296253,
        "vocab_size-3": 8094,
        "unique-3": 5822,
        "entropy-3": 12.00742263445101,
        "cond_entropy-3": 1.3196037511294259,
        "total_length-nopunct": 17220,
        "mean_pred_length-nopunct": 13.820224719101123,
        "std_pred_length-nopunct": 4.844759404704141,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.11033681765389082,
        "vocab_size-1-nopunct": 1900,
        "unique-1-nopunct": 913,
        "entropy-1-nopunct": 8.069755825921265,
        "distinct-2-nopunct": 0.3042443971453612,
        "vocab_size-2-nopunct": 4860,
        "unique-2-nopunct": 3066,
        "entropy-2-nopunct": 10.570162280723213,
        "cond_entropy-2-nopunct": 2.6546045583537543,
        "distinct-3-nopunct": 0.493549701249321,
        "vocab_size-3-nopunct": 7269,
        "unique-3-nopunct": 5340,
        "entropy-3-nopunct": 11.843159161846838,
        "cond_entropy-3-nopunct": 1.3558023632971783,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.67912,
            "recall": 0.66067,
            "fmeasure": 0.65809
        },
        "rouge2": {
            "precision": 0.4725,
            "recall": 0.45878,
            "fmeasure": 0.45658
        },
        "rougeL": {
            "precision": 0.59591,
            "recall": 0.57926,
            "fmeasure": 0.57736
        },
        "rougeLsum": {
            "precision": 0.59591,
            "recall": 0.57926,
            "fmeasure": 0.57736
        },
        "local_recall": {
            "1": 0.6359026369168357
        },
        "nist": 7.121847713285896,
        "bleu": 38.12107,
        "bleurt": -0.01879,
        "nubia": {
            "semantic_relation": 4.29222,
            "contradiction": 6.77633,
            "irrelevancy": 20.28596,
            "logical_agreement": 72.93771,
            "grammar_ref": 4.92094,
            "grammar_hyp": 4.7947,
            "nubia_score": 0.76627
        },
        "meteor": 0.3625951156648216,
        "bertscore": {
            "precision": 0.89784,
            "recall": 0.88995,
            "f1": 0.89345
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-12": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.33452,
        "msttr-100_nopunct": 0.34027,
        "total_length": 4242,
        "mean_pred_length": 8.484,
        "std_pred_length": 1.596791783545995,
        "median_pred_length": 8.0,
        "min_pred_length": 5,
        "max_pred_length": 14,
        "distinct-1": 0.02498821310702499,
        "vocab_size-1": 106,
        "unique-1": 32,
        "entropy-1": 4.8933199955745,
        "distinct-2": 0.08417958311063603,
        "vocab_size-2": 315,
        "unique-2": 136,
        "entropy-2": 6.483490186298275,
        "cond_entropy-2": 1.359592843407184,
        "distinct-3": 0.1579272054287477,
        "vocab_size-3": 512,
        "unique-3": 252,
        "entropy-3": 7.281005410809506,
        "cond_entropy-3": 0.8959122955689369,
        "total_length-nopunct": 3748,
        "mean_pred_length-nopunct": 7.496,
        "std_pred_length-nopunct": 1.5943600597104781,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.028014941302027748,
        "vocab_size-1-nopunct": 105,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 4.950777493894312,
        "distinct-2-nopunct": 0.08559113300492611,
        "vocab_size-2-nopunct": 278,
        "unique-2-nopunct": 124,
        "entropy-2-nopunct": 6.186189398944223,
        "cond_entropy-2-nopunct": 1.4490225031643178,
        "distinct-3-nopunct": 0.15574963609898107,
        "vocab_size-3-nopunct": 428,
        "unique-3-nopunct": 217,
        "entropy-3-nopunct": 6.899928820096973,
        "cond_entropy-3-nopunct": 0.9849723236336564,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.53998,
            "recall": 0.52683,
            "fmeasure": 0.5245
        },
        "rouge2": {
            "precision": 0.30928,
            "recall": 0.30069,
            "fmeasure": 0.29932
        },
        "rougeL": {
            "precision": 0.51734,
            "recall": 0.50558,
            "fmeasure": 0.50301
        },
        "rougeLsum": {
            "precision": 0.51734,
            "recall": 0.50558,
            "fmeasure": 0.50301
        },
        "local_recall": {
            "1": 0.5136713565171224
        },
        "nist": 3.5299979181601873,
        "bleu": 26.41222,
        "bleurt": 0.03321,
        "nubia": {
            "semantic_relation": 3.56833,
            "contradiction": 7.13952,
            "irrelevancy": 23.59319,
            "logical_agreement": 69.26729,
            "grammar_ref": 4.43492,
            "grammar_hyp": 4.03701,
            "nubia_score": 0.67907
        },
        "meteor": 0.28310790251237344,
        "bertscore": {
            "precision": 0.88381,
            "recall": 0.88184,
            "f1": 0.8825
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "T5-large (Baseline)/e2e_nlg_test",
        "N": 774,
        "msttr-100": 0.33816,
        "msttr-100_nopunct": 0.32455,
        "total_length": 25580,
        "mean_pred_length": 33.049095607235145,
        "std_pred_length": 4.5828765617248015,
        "median_pred_length": 33.0,
        "min_pred_length": 18,
        "max_pred_length": 46,
        "distinct-1": 0.007740422204847537,
        "vocab_size-1": 198,
        "unique-1": 18,
        "entropy-1": 5.9798103836739935,
        "distinct-2": 0.036523421752801745,
        "vocab_size-2": 906,
        "unique-2": 119,
        "entropy-2": 8.05153964571427,
        "cond_entropy-2": 2.0077815704689357,
        "distinct-3": 0.07789613848202397,
        "vocab_size-3": 1872,
        "unique-3": 311,
        "entropy-3": 9.303296024128828,
        "cond_entropy-3": 1.2550872570475795,
        "total_length-nopunct": 23377,
        "mean_pred_length-nopunct": 30.202842377260982,
        "std_pred_length-nopunct": 4.100663862995105,
        "median_pred_length-nopunct": 30.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.008298755186721992,
        "vocab_size-1-nopunct": 194,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 6.007029572791313,
        "distinct-2-nopunct": 0.03964075565190461,
        "vocab_size-2-nopunct": 896,
        "unique-2-nopunct": 122,
        "entropy-2-nopunct": 8.003580095147566,
        "cond_entropy-2-nopunct": 2.0176849644395753,
        "distinct-3-nopunct": 0.08223006092812314,
        "vocab_size-3-nopunct": 1795,
        "unique-3-nopunct": 308,
        "entropy-3-nopunct": 9.283519985685984,
        "cond_entropy-3-nopunct": 1.2636047341853243,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.77628,
            "recall": 0.7396,
            "fmeasure": 0.75214
        },
        "rouge2": {
            "precision": 0.47007,
            "recall": 0.44823,
            "fmeasure": 0.45564
        },
        "rougeL": {
            "precision": 0.51323,
            "recall": 0.49007,
            "fmeasure": 0.49785
        },
        "rougeLsum": {
            "precision": 0.51323,
            "recall": 0.49007,
            "fmeasure": 0.49785
        },
        "local_recall": {
            "1": 0.7206670082444455
        },
        "nist": 5.481141741371311,
        "bleu": 33.15291,
        "bleurt": 0.26628,
        "nubia": {
            "semantic_relation": 4.47527,
            "contradiction": 2.85081,
            "irrelevancy": 13.20619,
            "logical_agreement": 83.943,
            "grammar_ref": 4.52626,
            "grammar_hyp": 4.24959,
            "nubia_score": 0.82973
        },
        "meteor": 0.37276173751235814,
        "bertscore": {
            "precision": 0.91812,
            "recall": 0.90953,
            "f1": 0.91365
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "T5-large (Baseline)/e2e_nlg_test",
        "N": 73,
        "msttr-100": 0.39833,
        "msttr-100_nopunct": 0.39591,
        "total_length": 2426,
        "mean_pred_length": 33.23287671232877,
        "std_pred_length": 4.433745279555224,
        "median_pred_length": 33.0,
        "min_pred_length": 24,
        "max_pred_length": 43,
        "distinct-1": 0.04740313272877164,
        "vocab_size-1": 115,
        "unique-1": 16,
        "entropy-1": 5.771582871865526,
        "distinct-2": 0.16829579260518487,
        "vocab_size-2": 396,
        "unique-2": 134,
        "entropy-2": 7.616013464173687,
        "cond_entropy-2": 1.789472500785995,
        "distinct-3": 0.29912280701754385,
        "vocab_size-3": 682,
        "unique-3": 326,
        "entropy-3": 8.624015300316643,
        "cond_entropy-3": 1.0204726588497137,
        "total_length-nopunct": 2239,
        "mean_pred_length-nopunct": 30.671232876712327,
        "std_pred_length-nopunct": 4.194108047682064,
        "median_pred_length-nopunct": 30.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.05046895935685574,
        "vocab_size-1-nopunct": 113,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 5.778209027614195,
        "distinct-2-nopunct": 0.17174515235457063,
        "vocab_size-2-nopunct": 372,
        "unique-2-nopunct": 127,
        "entropy-2-nopunct": 7.5616838969368185,
        "cond_entropy-2-nopunct": 1.8131056615151846,
        "distinct-3-nopunct": 0.3129479216435738,
        "vocab_size-3-nopunct": 655,
        "unique-3-nopunct": 320,
        "entropy-3-nopunct": 8.61564969773702,
        "cond_entropy-3-nopunct": 1.045139976109466,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.79012,
            "recall": 0.79022,
            "fmeasure": 0.78731
        },
        "rouge2": {
            "precision": 0.51942,
            "recall": 0.52026,
            "fmeasure": 0.51805
        },
        "rougeL": {
            "precision": 0.54693,
            "recall": 0.54949,
            "fmeasure": 0.54624
        },
        "rougeLsum": {
            "precision": 0.54693,
            "recall": 0.54949,
            "fmeasure": 0.54624
        },
        "local_recall": {
            "1": 0.7789634146341463
        },
        "nist": 5.6658346080815285,
        "bleu": 40.5571,
        "bleurt": 0.32633,
        "nubia": {
            "semantic_relation": 4.51114,
            "contradiction": 3.61786,
            "irrelevancy": 14.16992,
            "logical_agreement": 82.21222,
            "grammar_ref": 4.71083,
            "grammar_hyp": 4.32208,
            "nubia_score": 0.85327
        },
        "meteor": 0.40530146494596214,
        "bertscore": {
            "precision": 0.92568,
            "recall": 0.92095,
            "f1": 0.92321
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "T5-large (Baseline)/e2e_nlg_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 76,
        "mean_pred_length": 38.0,
        "std_pred_length": 0.0,
        "median_pred_length": 38.0,
        "min_pred_length": 38,
        "max_pred_length": 38,
        "distinct-1": 0.42105263157894735,
        "vocab_size-1": 32,
        "unique-1": 0,
        "entropy-1": 4.892407118592879,
        "distinct-2": 0.4864864864864865,
        "vocab_size-2": 36,
        "unique-2": 0,
        "entropy-2": 5.155399311574899,
        "cond_entropy-2": 0.24557382527528143,
        "distinct-3": 0.5,
        "vocab_size-3": 36,
        "unique-3": 0,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": 0.016027191368918267,
        "total_length-nopunct": 72,
        "mean_pred_length-nopunct": 36.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 36.0,
        "min_pred_length-nopunct": 36,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.4305555555555556,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 4.850209029099895,
        "distinct-2-nopunct": 0.4857142857142857,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 5.072140159802107,
        "cond_entropy-2-nopunct": 0.23106587276913781,
        "distinct-3-nopunct": 0.5,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": 0.017003353717137487,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.80201,
            "fmeasure": 0.84269
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.54252,
            "fmeasure": 0.56944
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.3797,
            "fmeasure": 0.39709
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.3797,
            "fmeasure": 0.39709
        },
        "local_recall": {
            "1": 0.8285714285714286
        },
        "nist": 4.692781591740953,
        "bleu": 44.20222,
        "bleurt": 0.20718,
        "nubia": {
            "semantic_relation": 4.81183,
            "contradiction": 0.18437,
            "irrelevancy": 0.41698,
            "logical_agreement": 99.39865,
            "grammar_ref": 4.16331,
            "grammar_hyp": 4.32092,
            "nubia_score": 0.85936
        },
        "meteor": 0.42873182965360607,
        "bertscore": {
            "precision": 0.93319,
            "recall": 0.92175,
            "f1": 0.92744
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 166,
        "msttr-100": 0.70889,
        "msttr-100_nopunct": 0.75957,
        "total_length": 2723,
        "mean_pred_length": 16.403614457831324,
        "std_pred_length": 7.498577307362361,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 46,
        "distinct-1": 0.442159383033419,
        "vocab_size-1": 1204,
        "unique-1": 955,
        "entropy-1": 8.430004895374077,
        "distinct-2": 0.852561595619867,
        "vocab_size-2": 2180,
        "unique-2": 2041,
        "entropy-2": 10.826199363216507,
        "cond_entropy-2": 2.1043956129960035,
        "distinct-3": 0.9577582601421999,
        "vocab_size-3": 2290,
        "unique-3": 2234,
        "entropy-3": 11.108575079921739,
        "cond_entropy-3": 0.30246955666009445,
        "total_length-nopunct": 2381,
        "mean_pred_length-nopunct": 14.343373493975903,
        "std_pred_length-nopunct": 6.438507886169068,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.502309953800924,
        "vocab_size-1-nopunct": 1196,
        "unique-1-nopunct": 954,
        "entropy-1-nopunct": 8.764455969770733,
        "distinct-2-nopunct": 0.8659142212189617,
        "vocab_size-2-nopunct": 1918,
        "unique-2-nopunct": 1808,
        "entropy-2-nopunct": 10.658296617314727,
        "cond_entropy-2-nopunct": 2.04448878117599,
        "distinct-3-nopunct": 0.9673011224987799,
        "vocab_size-3-nopunct": 1982,
        "unique-3-nopunct": 1936,
        "entropy-3-nopunct": 10.922549576240598,
        "cond_entropy-3-nopunct": 0.2924497344215621,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.89248,
            "recall": 0.86588,
            "fmeasure": 0.87029
        },
        "rouge2": {
            "precision": 0.78267,
            "recall": 0.76877,
            "fmeasure": 0.76365
        },
        "rougeL": {
            "precision": 0.87125,
            "recall": 0.84718,
            "fmeasure": 0.84966
        },
        "rougeLsum": {
            "precision": 0.87125,
            "recall": 0.84718,
            "fmeasure": 0.84966
        },
        "local_recall": {
            "1": 0.025135534746180386,
            "2": 0.13261648745519714,
            "3": 0.29537366548042704,
            "4": 0.4978540772532189,
            "5": 0.6589861751152074,
            "6": 0.7386363636363636,
            "7": 0.795774647887324,
            "8": 0.842443729903537,
            "9": 0.8737373737373737,
            "10": 0.9323432343234324
        },
        "nist": 11.809955652722103,
        "bleu": 83.73623,
        "bleurt": 0.26722,
        "nubia": {
            "semantic_relation": 4.23151,
            "contradiction": 3.31857,
            "irrelevancy": 27.61104,
            "logical_agreement": 69.07038,
            "grammar_ref": 4.62208,
            "grammar_hyp": 4.88823,
            "nubia_score": 0.66605
        },
        "meteor": 0.516499750983462,
        "bertscore": {
            "precision": 0.9697,
            "recall": 0.966,
            "f1": 0.96431
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level1": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 0,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json"
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 2517,
        "msttr-100": 0.68914,
        "msttr-100_nopunct": 0.71548,
        "total_length": 37468,
        "mean_pred_length": 14.885975367500993,
        "std_pred_length": 4.499956956068041,
        "median_pred_length": 14.0,
        "min_pred_length": 3,
        "max_pred_length": 49,
        "distinct-1": 0.06776449236681968,
        "vocab_size-1": 2539,
        "unique-1": 1209,
        "entropy-1": 8.095357959826114,
        "distinct-2": 0.25598695316299963,
        "vocab_size-2": 8947,
        "unique-2": 5288,
        "entropy-2": 11.509521386786208,
        "cond_entropy-2": 3.1878114499439687,
        "distinct-3": 0.45618795091570574,
        "vocab_size-3": 14796,
        "unique-3": 10467,
        "entropy-3": 12.876305384675486,
        "cond_entropy-3": 1.4190233373107517,
        "total_length-nopunct": 33016,
        "mean_pred_length-nopunct": 13.11720301946762,
        "std_pred_length-nopunct": 4.073345488430807,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.07647807123818755,
        "vocab_size-1-nopunct": 2525,
        "unique-1-nopunct": 1207,
        "entropy-1-nopunct": 8.303143589925941,
        "distinct-2-nopunct": 0.2728286173317158,
        "vocab_size-2-nopunct": 8321,
        "unique-2-nopunct": 5127,
        "entropy-2-nopunct": 11.382211112847342,
        "cond_entropy-2-nopunct": 3.2490534564246025,
        "distinct-3-nopunct": 0.47566292616682154,
        "vocab_size-3-nopunct": 13310,
        "unique-3-nopunct": 9683,
        "entropy-3-nopunct": 12.722346651545541,
        "cond_entropy-3-nopunct": 1.4229504300019287,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.62491,
            "recall": 0.60905,
            "fmeasure": 0.60553
        },
        "rouge2": {
            "precision": 0.39534,
            "recall": 0.3843,
            "fmeasure": 0.38217
        },
        "rougeL": {
            "precision": 0.54594,
            "recall": 0.53201,
            "fmeasure": 0.52904
        },
        "rougeLsum": {
            "precision": 0.54594,
            "recall": 0.53201,
            "fmeasure": 0.52904
        },
        "local_recall": {
            "1": 0.5856745523297603
        },
        "nist": 6.763719468753492,
        "bleu": 32.77583,
        "bleurt": -0.06405,
        "nubia": {
            "semantic_relation": 3.98715,
            "contradiction": 8.2749,
            "irrelevancy": 22.31613,
            "logical_agreement": 69.40898,
            "grammar_ref": 4.80017,
            "grammar_hyp": 4.65134,
            "nubia_score": 0.69341
        },
        "meteor": 0.3247159011677562,
        "bertscore": {
            "precision": 0.88232,
            "recall": 0.87713,
            "f1": 0.87933
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-13": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 2078,
        "msttr-100": 0.51134,
        "msttr-100_nopunct": 0.53346,
        "total_length": 21618,
        "mean_pred_length": 10.403272377285852,
        "std_pred_length": 5.745821503381153,
        "median_pred_length": 9.0,
        "min_pred_length": 2,
        "max_pred_length": 49,
        "distinct-1": 0.0246553797761125,
        "vocab_size-1": 533,
        "unique-1": 165,
        "entropy-1": 6.2825827493968065,
        "distinct-2": 0.12446264073694985,
        "vocab_size-2": 2432,
        "unique-2": 1085,
        "entropy-2": 9.151808142619666,
        "cond_entropy-2": 2.560939078807225,
        "distinct-3": 0.26514717672660637,
        "vocab_size-3": 4630,
        "unique-3": 2735,
        "entropy-3": 10.529220706258672,
        "cond_entropy-3": 1.439873027849088,
        "total_length-nopunct": 18833,
        "mean_pred_length-nopunct": 9.063041385948027,
        "std_pred_length-nopunct": 5.261805169080592,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.02798279615568417,
        "vocab_size-1-nopunct": 527,
        "unique-1-nopunct": 164,
        "entropy-1-nopunct": 6.4635146079832575,
        "distinct-2-nopunct": 0.13578036407042673,
        "vocab_size-2-nopunct": 2275,
        "unique-2-nopunct": 1116,
        "entropy-2-nopunct": 8.902781611853634,
        "cond_entropy-2-nopunct": 2.6379683901578703,
        "distinct-3-nopunct": 0.2752349816101349,
        "vocab_size-3-nopunct": 4041,
        "unique-3-nopunct": 2485,
        "entropy-3-nopunct": 10.251799560103182,
        "cond_entropy-3-nopunct": 1.4606414383764112,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.47701,
            "recall": 0.43619,
            "fmeasure": 0.4397
        },
        "rouge2": {
            "precision": 0.24411,
            "recall": 0.22414,
            "fmeasure": 0.22404
        },
        "rougeL": {
            "precision": 0.43455,
            "recall": 0.39911,
            "fmeasure": 0.40192
        },
        "rougeLsum": {
            "precision": 0.43455,
            "recall": 0.39911,
            "fmeasure": 0.40192
        },
        "local_recall": {
            "1": 0.4305893309877374
        },
        "nist": 3.688702534181495,
        "bleu": 17.66278,
        "bleurt": -0.28801,
        "nubia": {
            "semantic_relation": 3.12935,
            "contradiction": 10.25514,
            "irrelevancy": 26.62985,
            "logical_agreement": 63.11501,
            "grammar_ref": 4.54436,
            "grammar_hyp": 4.44388,
            "nubia_score": 0.52686
        },
        "meteor": 0.23381860925971218,
        "bertscore": {
            "precision": 0.84759,
            "recall": 0.83492,
            "f1": 0.84039
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-15": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 715,
        "msttr-100": 0.25354,
        "msttr-100_nopunct": 0.24474,
        "total_length": 6575,
        "mean_pred_length": 9.195804195804195,
        "std_pred_length": 3.4170668754928966,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 27,
        "distinct-1": 0.016273764258555132,
        "vocab_size-1": 107,
        "unique-1": 22,
        "entropy-1": 4.482161750757173,
        "distinct-2": 0.05324232081911263,
        "vocab_size-2": 312,
        "unique-2": 123,
        "entropy-2": 5.6723763822391975,
        "cond_entropy-2": 1.0386859321335802,
        "distinct-3": 0.0892128279883382,
        "vocab_size-3": 459,
        "unique-3": 228,
        "entropy-3": 6.103353153477009,
        "cond_entropy-3": 0.42575923768965857,
        "total_length-nopunct": 5771,
        "mean_pred_length-nopunct": 8.071328671328672,
        "std_pred_length-nopunct": 3.061002678122262,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.018021140183677006,
        "vocab_size-1-nopunct": 104,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.4025924409666715,
        "distinct-2-nopunct": 0.05676424050632911,
        "vocab_size-2-nopunct": 287,
        "unique-2-nopunct": 125,
        "entropy-2-nopunct": 5.403289046839068,
        "cond_entropy-2-nopunct": 0.9651646926544596,
        "distinct-3-nopunct": 0.09536973047684866,
        "vocab_size-3-nopunct": 414,
        "unique-3-nopunct": 224,
        "entropy-3-nopunct": 5.829442023386818,
        "cond_entropy-3-nopunct": 0.38233415767976675,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.54484,
            "recall": 0.56391,
            "fmeasure": 0.54173
        },
        "rouge2": {
            "precision": 0.30233,
            "recall": 0.31089,
            "fmeasure": 0.2978
        },
        "rougeL": {
            "precision": 0.46511,
            "recall": 0.47594,
            "fmeasure": 0.45968
        },
        "rougeLsum": {
            "precision": 0.46511,
            "recall": 0.47594,
            "fmeasure": 0.45968
        },
        "local_recall": {
            "1": 0.5573299838507088
        },
        "nist": 3.073412283849964,
        "bleu": 27.56849,
        "bleurt": 0.17786,
        "nubia": {
            "semantic_relation": 3.63328,
            "contradiction": 1.04944,
            "irrelevancy": 22.85807,
            "logical_agreement": 76.09249,
            "grammar_ref": 4.09289,
            "grammar_hyp": 3.50722,
            "nubia_score": 0.73355
        },
        "meteor": 0.2897651305317863,
        "bertscore": {
            "precision": 0.85705,
            "recall": 0.85762,
            "f1": 0.85675
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-0": {
        "predictions_file": "T5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.73957,
        "msttr-100_nopunct": 0.76048,
        "total_length": 2305,
        "mean_pred_length": 21.745283018867923,
        "std_pred_length": 4.545496051462655,
        "median_pred_length": 22.0,
        "min_pred_length": 13,
        "max_pred_length": 36,
        "distinct-1": 0.4290672451193059,
        "vocab_size-1": 989,
        "unique-1": 766,
        "entropy-1": 8.394142522501607,
        "distinct-2": 0.8663028649386084,
        "vocab_size-2": 1905,
        "unique-2": 1751,
        "entropy-2": 10.72873100584362,
        "cond_entropy-2": 2.1453514004082557,
        "distinct-3": 0.9718107978977544,
        "vocab_size-3": 2034,
        "unique-3": 1985,
        "entropy-3": 10.969539072134761,
        "cond_entropy-3": 0.2443287691545187,
        "total_length-nopunct": 2142,
        "mean_pred_length-nopunct": 20.20754716981132,
        "std_pred_length-nopunct": 4.316962989802226,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.4579831932773109,
        "vocab_size-1-nopunct": 981,
        "unique-1-nopunct": 764,
        "entropy-1-nopunct": 8.531680724827059,
        "distinct-2-nopunct": 0.8722986247544204,
        "vocab_size-2-nopunct": 1776,
        "unique-2-nopunct": 1638,
        "entropy-2-nopunct": 10.633333071629169,
        "cond_entropy-2-nopunct": 2.185462841585445,
        "distinct-3-nopunct": 0.9787564766839378,
        "vocab_size-3-nopunct": 1889,
        "unique-3-nopunct": 1850,
        "entropy-3-nopunct": 10.871115818681954,
        "cond_entropy-3-nopunct": 0.23983871083027178,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.47786,
            "recall": 0.48589,
            "fmeasure": 0.47159
        },
        "rouge2": {
            "precision": 0.24369,
            "recall": 0.24933,
            "fmeasure": 0.24078
        },
        "rougeL": {
            "precision": 0.38167,
            "recall": 0.38621,
            "fmeasure": 0.37595
        },
        "rougeLsum": {
            "precision": 0.38167,
            "recall": 0.38621,
            "fmeasure": 0.37595
        },
        "local_recall": {
            "1": 0.45869234668018244
        },
        "nist": 4.267435636062765,
        "bleu": 19.42457,
        "bleurt": -0.16564,
        "nubia": {
            "semantic_relation": 3.39125,
            "contradiction": 14.27112,
            "irrelevancy": 66.06138,
            "logical_agreement": 19.6675,
            "grammar_ref": 3.74062,
            "grammar_hyp": 3.63378,
            "nubia_score": 0.54662
        },
        "meteor": 0.23289188818390824,
        "bertscore": {
            "precision": 0.85885,
            "recall": 0.85579,
            "f1": 0.85696
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-1": {
        "predictions_file": "T5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.73773,
        "msttr-100_nopunct": 0.76095,
        "total_length": 2261,
        "mean_pred_length": 21.330188679245282,
        "std_pred_length": 4.334420590020377,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 31,
        "distinct-1": 0.41884122069880586,
        "vocab_size-1": 947,
        "unique-1": 728,
        "entropy-1": 8.318160540019111,
        "distinct-2": 0.8436194895591648,
        "vocab_size-2": 1818,
        "unique-2": 1667,
        "entropy-2": 10.608575706323906,
        "cond_entropy-2": 2.0984181425977053,
        "distinct-3": 0.9668130795510005,
        "vocab_size-3": 1981,
        "unique-3": 1928,
        "entropy-3": 10.928086412730583,
        "cond_entropy-3": 0.3298957837370919,
        "total_length-nopunct": 2111,
        "mean_pred_length-nopunct": 19.91509433962264,
        "std_pred_length-nopunct": 4.102732463900774,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.44576030317385124,
        "vocab_size-1-nopunct": 941,
        "unique-1-nopunct": 727,
        "entropy-1-nopunct": 8.44674646686615,
        "distinct-2-nopunct": 0.8433915211970074,
        "vocab_size-2-nopunct": 1691,
        "unique-2-nopunct": 1556,
        "entropy-2-nopunct": 10.496265956657256,
        "cond_entropy-2-nopunct": 2.146641397074545,
        "distinct-3-nopunct": 0.9689310163243813,
        "vocab_size-3-nopunct": 1840,
        "unique-3-nopunct": 1794,
        "entropy-3-nopunct": 10.82320218513664,
        "cond_entropy-3-nopunct": 0.33976726850580924,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.47873,
            "recall": 0.45154,
            "fmeasure": 0.45693
        },
        "rouge2": {
            "precision": 0.22155,
            "recall": 0.20866,
            "fmeasure": 0.21131
        },
        "rougeL": {
            "precision": 0.38009,
            "recall": 0.35831,
            "fmeasure": 0.36299
        },
        "rougeLsum": {
            "precision": 0.38009,
            "recall": 0.35831,
            "fmeasure": 0.36299
        },
        "local_recall": {
            "1": 0.42728564661297963
        },
        "nist": 4.090996272179945,
        "bleu": 15.0699,
        "bleurt": -0.23315,
        "nubia": {
            "semantic_relation": 3.2459,
            "contradiction": 16.4172,
            "irrelevancy": 65.45784,
            "logical_agreement": 18.12495,
            "grammar_ref": 3.75111,
            "grammar_hyp": 3.63329,
            "nubia_score": 0.51371
        },
        "meteor": 0.2079330953796368,
        "bertscore": {
            "precision": 0.85116,
            "recall": 0.84095,
            "f1": 0.84569
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-2": {
        "predictions_file": "T5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.74273,
        "msttr-100_nopunct": 0.7681,
        "total_length": 2281,
        "mean_pred_length": 21.5188679245283,
        "std_pred_length": 4.153269074045649,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 33,
        "distinct-1": 0.4296361245067953,
        "vocab_size-1": 980,
        "unique-1": 751,
        "entropy-1": 8.434036279629934,
        "distinct-2": 0.8616091954022989,
        "vocab_size-2": 1874,
        "unique-2": 1728,
        "entropy-2": 10.689214632149168,
        "cond_entropy-2": 2.061215774842826,
        "distinct-3": 0.9695505074915418,
        "vocab_size-3": 2006,
        "unique-3": 1960,
        "entropy-3": 10.943435211901726,
        "cond_entropy-3": 0.2504360689827258,
        "total_length-nopunct": 2121,
        "mean_pred_length-nopunct": 20.00943396226415,
        "std_pred_length-nopunct": 4.062008247204331,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.4592173503064592,
        "vocab_size-1-nopunct": 974,
        "unique-1-nopunct": 750,
        "entropy-1-nopunct": 8.582234041424606,
        "distinct-2-nopunct": 0.8674937965260546,
        "vocab_size-2-nopunct": 1748,
        "unique-2-nopunct": 1620,
        "entropy-2-nopunct": 10.59360933067251,
        "cond_entropy-2-nopunct": 2.088838574104089,
        "distinct-3-nopunct": 0.9759036144578314,
        "vocab_size-3-nopunct": 1863,
        "unique-3-nopunct": 1825,
        "entropy-3-nopunct": 10.84628378500457,
        "cond_entropy-3-nopunct": 0.2517988888649925,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.44231,
            "recall": 0.40646,
            "fmeasure": 0.41779
        },
        "rouge2": {
            "precision": 0.19862,
            "recall": 0.18509,
            "fmeasure": 0.18894
        },
        "rougeL": {
            "precision": 0.35653,
            "recall": 0.32896,
            "fmeasure": 0.33759
        },
        "rougeLsum": {
            "precision": 0.35653,
            "recall": 0.32896,
            "fmeasure": 0.33759
        },
        "local_recall": {
            "1": 0.38940092165898615
        },
        "nist": 3.7533143416060093,
        "bleu": 11.9854,
        "bleurt": -0.26668,
        "nubia": {
            "semantic_relation": 3.09122,
            "contradiction": 19.94504,
            "irrelevancy": 59.78217,
            "logical_agreement": 20.27279,
            "grammar_ref": 3.66018,
            "grammar_hyp": 3.59061,
            "nubia_score": 0.47095
        },
        "meteor": 0.19468518543023822,
        "bertscore": {
            "precision": 0.84276,
            "recall": 0.83337,
            "f1": 0.83772
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 1328,
        "msttr-100": 0.69469,
        "msttr-100_nopunct": 0.71969,
        "total_length": 25848,
        "mean_pred_length": 19.46385542168675,
        "std_pred_length": 5.050666860735645,
        "median_pred_length": 19.0,
        "min_pred_length": 6,
        "max_pred_length": 46,
        "distinct-1": 0.0805865057257815,
        "vocab_size-1": 2083,
        "unique-1": 1016,
        "entropy-1": 8.047054364794485,
        "distinct-2": 0.2814029363784666,
        "vocab_size-2": 6900,
        "unique-2": 4125,
        "entropy-2": 11.24971066068086,
        "cond_entropy-2": 3.0309198884211406,
        "distinct-3": 0.4807692307692308,
        "vocab_size-3": 11150,
        "unique-3": 7893,
        "entropy-3": 12.576825854612716,
        "cond_entropy-3": 1.3886062346937533,
        "total_length-nopunct": 22879,
        "mean_pred_length-nopunct": 17.22816265060241,
        "std_pred_length-nopunct": 4.496640874504843,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.09043227413785568,
        "vocab_size-1-nopunct": 2069,
        "unique-1-nopunct": 1014,
        "entropy-1-nopunct": 8.251677806936392,
        "distinct-2-nopunct": 0.30045009512319615,
        "vocab_size-2-nopunct": 6475,
        "unique-2-nopunct": 4005,
        "entropy-2-nopunct": 11.176993851718318,
        "cond_entropy-2-nopunct": 3.0703053476877575,
        "distinct-3-nopunct": 0.5050190377293181,
        "vocab_size-3-nopunct": 10213,
        "unique-3-nopunct": 7409,
        "entropy-3-nopunct": 12.493455055830344,
        "cond_entropy-3-nopunct": 1.3913134040130597,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.62738,
            "recall": 0.61521,
            "fmeasure": 0.60906
        },
        "rouge2": {
            "precision": 0.39863,
            "recall": 0.39357,
            "fmeasure": 0.38806
        },
        "rougeL": {
            "precision": 0.52913,
            "recall": 0.51998,
            "fmeasure": 0.51445
        },
        "rougeLsum": {
            "precision": 0.52913,
            "recall": 0.51998,
            "fmeasure": 0.51445
        },
        "local_recall": {
            "1": 0.5947301239970825
        },
        "nist": 6.580361217912939,
        "bleu": 31.21695,
        "bleurt": -0.06229,
        "nubia": {
            "semantic_relation": 4.16599,
            "contradiction": 5.32828,
            "irrelevancy": 21.46831,
            "logical_agreement": 73.20341,
            "grammar_ref": 4.79322,
            "grammar_hyp": 4.67134,
            "nubia_score": 0.71999
        },
        "meteor": 0.32575805954294235,
        "bertscore": {
            "precision": 0.88521,
            "recall": 0.87969,
            "f1": 0.88199
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 469,
        "msttr-100": 0.69058,
        "msttr-100_nopunct": 0.7137,
        "total_length": 10300,
        "mean_pred_length": 21.961620469083154,
        "std_pred_length": 5.682297571374187,
        "median_pred_length": 21.0,
        "min_pred_length": 9,
        "max_pred_length": 42,
        "distinct-1": 0.11689320388349514,
        "vocab_size-1": 1204,
        "unique-1": 597,
        "entropy-1": 7.826414871817958,
        "distinct-2": 0.3384192859322551,
        "vocab_size-2": 3327,
        "unique-2": 2065,
        "entropy-2": 10.494771592898905,
        "cond_entropy-2": 2.5352978653649263,
        "distinct-3": 0.5375988036744286,
        "vocab_size-3": 5033,
        "unique-3": 3662,
        "entropy-3": 11.656846931484962,
        "cond_entropy-3": 1.1894525206137603,
        "total_length-nopunct": 9259,
        "mean_pred_length-nopunct": 19.742004264392325,
        "std_pred_length-nopunct": 5.114839507721359,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.12906361378118586,
        "vocab_size-1-nopunct": 1195,
        "unique-1-nopunct": 596,
        "entropy-1-nopunct": 7.973349295029045,
        "distinct-2-nopunct": 0.3533560864618885,
        "vocab_size-2-nopunct": 3106,
        "unique-2-nopunct": 1965,
        "entropy-2-nopunct": 10.411412711742718,
        "cond_entropy-2-nopunct": 2.521726932488583,
        "distinct-3-nopunct": 0.5603893762768898,
        "vocab_size-3-nopunct": 4663,
        "unique-3-nopunct": 3452,
        "entropy-3-nopunct": 11.587288596236963,
        "cond_entropy-3-nopunct": 1.1933856951951929,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.64326,
            "recall": 0.64777,
            "fmeasure": 0.63412
        },
        "rouge2": {
            "precision": 0.42281,
            "recall": 0.42393,
            "fmeasure": 0.41557
        },
        "rougeL": {
            "precision": 0.55522,
            "recall": 0.55817,
            "fmeasure": 0.54694
        },
        "rougeLsum": {
            "precision": 0.55522,
            "recall": 0.55817,
            "fmeasure": 0.54694
        },
        "local_recall": {
            "1": 0.6301100173711639
        },
        "nist": 6.386187633752786,
        "bleu": 33.29997,
        "bleurt": -0.04479,
        "nubia": {
            "semantic_relation": 4.22597,
            "contradiction": 8.52409,
            "irrelevancy": 21.5554,
            "logical_agreement": 69.92051,
            "grammar_ref": 4.86994,
            "grammar_hyp": 4.72142,
            "nubia_score": 0.72289
        },
        "meteor": 0.3395735994401714,
        "bertscore": {
            "precision": 0.88727,
            "recall": 0.88541,
            "f1": 0.88593
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 335,
        "msttr-100": 0.64644,
        "msttr-100_nopunct": 0.65215,
        "total_length": 8757,
        "mean_pred_length": 26.140298507462685,
        "std_pred_length": 5.0868299280458995,
        "median_pred_length": 25.0,
        "min_pred_length": 15,
        "max_pred_length": 47,
        "distinct-1": 0.1065433367591641,
        "vocab_size-1": 933,
        "unique-1": 462,
        "entropy-1": 7.470472046420186,
        "distinct-2": 0.30622180004749466,
        "vocab_size-2": 2579,
        "unique-2": 1551,
        "entropy-2": 10.038638436510826,
        "cond_entropy-2": 2.486354987216961,
        "distinct-3": 0.49857796463459875,
        "vocab_size-3": 4032,
        "unique-3": 2881,
        "entropy-3": 11.213065520080237,
        "cond_entropy-3": 1.1549101170424367,
        "total_length-nopunct": 7977,
        "mean_pred_length-nopunct": 23.811940298507462,
        "std_pred_length-nopunct": 4.465841245083224,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.11545693869875893,
        "vocab_size-1-nopunct": 921,
        "unique-1-nopunct": 460,
        "entropy-1-nopunct": 7.520798941305409,
        "distinct-2-nopunct": 0.32269039518450665,
        "vocab_size-2-nopunct": 2466,
        "unique-2-nopunct": 1534,
        "entropy-2-nopunct": 9.984839228613065,
        "cond_entropy-2-nopunct": 2.481469489279979,
        "distinct-3-nopunct": 0.5143013548651978,
        "vocab_size-3-nopunct": 3758,
        "unique-3-nopunct": 2748,
        "entropy-3-nopunct": 11.105352422790197,
        "cond_entropy-3-nopunct": 1.1332488260306506,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.74649,
            "recall": 0.6986,
            "fmeasure": 0.71366
        },
        "rouge2": {
            "precision": 0.52662,
            "recall": 0.49365,
            "fmeasure": 0.50375
        },
        "rougeL": {
            "precision": 0.62994,
            "recall": 0.5903,
            "fmeasure": 0.60266
        },
        "rougeLsum": {
            "precision": 0.62994,
            "recall": 0.5903,
            "fmeasure": 0.60266
        },
        "local_recall": {
            "1": 0.6797452229299363
        },
        "nist": 7.029159666800865,
        "bleu": 40.14211,
        "bleurt": 0.07335,
        "nubia": {
            "semantic_relation": 4.45381,
            "contradiction": 2.81759,
            "irrelevancy": 8.63648,
            "logical_agreement": 88.54593,
            "grammar_ref": 4.45968,
            "grammar_hyp": 4.40288,
            "nubia_score": 0.80417
        },
        "meteor": 0.37860220805446526,
        "bertscore": {
            "precision": 0.9106,
            "recall": 0.89886,
            "f1": 0.90442
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-3": {
        "predictions_file": "T5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.73435,
        "msttr-100_nopunct": 0.75429,
        "total_length": 2332,
        "mean_pred_length": 22.0,
        "std_pred_length": 3.973971921162589,
        "median_pred_length": 22.0,
        "min_pred_length": 14,
        "max_pred_length": 32,
        "distinct-1": 0.40008576329331047,
        "vocab_size-1": 933,
        "unique-1": 694,
        "entropy-1": 8.293121325965119,
        "distinct-2": 0.8373764600179695,
        "vocab_size-2": 1864,
        "unique-2": 1695,
        "entropy-2": 10.6496574268031,
        "cond_entropy-2": 2.173979448108424,
        "distinct-3": 0.965566037735849,
        "vocab_size-3": 2047,
        "unique-3": 1994,
        "entropy-3": 10.97047087259295,
        "cond_entropy-3": 0.3275257303668093,
        "total_length-nopunct": 2174,
        "mean_pred_length-nopunct": 20.50943396226415,
        "std_pred_length-nopunct": 3.7973309470087955,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.42594296228150874,
        "vocab_size-1-nopunct": 926,
        "unique-1-nopunct": 694,
        "entropy-1-nopunct": 8.414655251903962,
        "distinct-2-nopunct": 0.8413926499032882,
        "vocab_size-2-nopunct": 1740,
        "unique-2-nopunct": 1588,
        "entropy-2-nopunct": 10.551527880141256,
        "cond_entropy-2-nopunct": 2.2233834882433774,
        "distinct-3-nopunct": 0.9699286442405708,
        "vocab_size-3-nopunct": 1903,
        "unique-3-nopunct": 1856,
        "entropy-3-nopunct": 10.872350126418873,
        "cond_entropy-3-nopunct": 0.32695827087764895,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.43737,
            "recall": 0.41716,
            "fmeasure": 0.4196
        },
        "rouge2": {
            "precision": 0.18287,
            "recall": 0.17526,
            "fmeasure": 0.17524
        },
        "rougeL": {
            "precision": 0.34104,
            "recall": 0.32514,
            "fmeasure": 0.32719
        },
        "rougeLsum": {
            "precision": 0.34104,
            "recall": 0.32514,
            "fmeasure": 0.32719
        },
        "local_recall": {
            "1": 0.38875878220140514
        },
        "nist": 3.7066773031280045,
        "bleu": 12.44779,
        "bleurt": -0.29783,
        "nubia": {
            "semantic_relation": 3.08021,
            "contradiction": 18.21265,
            "irrelevancy": 67.3823,
            "logical_agreement": 14.40505,
            "grammar_ref": 3.68583,
            "grammar_hyp": 3.56426,
            "nubia_score": 0.46598
        },
        "meteor": 0.18953660642322404,
        "bertscore": {
            "precision": 0.83962,
            "recall": 0.82826,
            "f1": 0.83361
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-4": {
        "predictions_file": "T5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.74864,
        "msttr-100_nopunct": 0.77762,
        "total_length": 2293,
        "mean_pred_length": 21.632075471698112,
        "std_pred_length": 4.1169815644293575,
        "median_pred_length": 22.0,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.4269515918011339,
        "vocab_size-1": 979,
        "unique-1": 729,
        "entropy-1": 8.43383256825314,
        "distinct-2": 0.866026520347508,
        "vocab_size-2": 1894,
        "unique-2": 1743,
        "entropy-2": 10.716501908775953,
        "cond_entropy-2": 2.0888578944216394,
        "distinct-3": 0.9764536280634311,
        "vocab_size-3": 2032,
        "unique-3": 2000,
        "entropy-3": 10.963958069312762,
        "cond_entropy-3": 0.25674884948583043,
        "total_length-nopunct": 2138,
        "mean_pred_length-nopunct": 20.169811320754718,
        "std_pred_length-nopunct": 4.0479943743743245,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.4546304957904584,
        "vocab_size-1-nopunct": 972,
        "unique-1-nopunct": 727,
        "entropy-1-nopunct": 8.570358477369263,
        "distinct-2-nopunct": 0.8690944881889764,
        "vocab_size-2-nopunct": 1766,
        "unique-2-nopunct": 1629,
        "entropy-2-nopunct": 10.618181462057876,
        "cond_entropy-2-nopunct": 2.142939322181426,
        "distinct-3-nopunct": 0.9807892004153687,
        "vocab_size-3-nopunct": 1889,
        "unique-3-nopunct": 1861,
        "entropy-3-nopunct": 10.867895395158437,
        "cond_entropy-3-nopunct": 0.262013195468238,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.42141,
            "recall": 0.38424,
            "fmeasure": 0.39469
        },
        "rouge2": {
            "precision": 0.15693,
            "recall": 0.14215,
            "fmeasure": 0.14627
        },
        "rougeL": {
            "precision": 0.31243,
            "recall": 0.28794,
            "fmeasure": 0.29451
        },
        "rougeLsum": {
            "precision": 0.31243,
            "recall": 0.28794,
            "fmeasure": 0.29451
        },
        "local_recall": {
            "1": 0.3542519326966803
        },
        "nist": 3.3681325095701804,
        "bleu": 9.40268,
        "bleurt": -0.25518,
        "nubia": {
            "semantic_relation": 3.15115,
            "contradiction": 13.11502,
            "irrelevancy": 65.90518,
            "logical_agreement": 20.9798,
            "grammar_ref": 3.83852,
            "grammar_hyp": 3.56248,
            "nubia_score": 0.49955
        },
        "meteor": 0.17531822831912539,
        "bertscore": {
            "precision": 0.8372,
            "recall": 0.8239,
            "f1": 0.83023
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-5": {
        "predictions_file": "T5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.74818,
        "msttr-100_nopunct": 0.7665,
        "total_length": 2254,
        "mean_pred_length": 21.264150943396228,
        "std_pred_length": 4.355222167485775,
        "median_pred_length": 22.0,
        "min_pred_length": 10,
        "max_pred_length": 32,
        "distinct-1": 0.422360248447205,
        "vocab_size-1": 952,
        "unique-1": 720,
        "entropy-1": 8.38817308757014,
        "distinct-2": 0.8687150837988827,
        "vocab_size-2": 1866,
        "unique-2": 1727,
        "entropy-2": 10.6842619941307,
        "cond_entropy-2": 2.0997904407091887,
        "distinct-3": 0.9725759059745348,
        "vocab_size-3": 1986,
        "unique-3": 1940,
        "entropy-3": 10.936742016199416,
        "cond_entropy-3": 0.26521451696948933,
        "total_length-nopunct": 2098,
        "mean_pred_length-nopunct": 19.79245283018868,
        "std_pred_length-nopunct": 4.221948448359501,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.449952335557674,
        "vocab_size-1-nopunct": 944,
        "unique-1-nopunct": 719,
        "entropy-1-nopunct": 8.517553506207951,
        "distinct-2-nopunct": 0.8689759036144579,
        "vocab_size-2-nopunct": 1731,
        "unique-2-nopunct": 1606,
        "entropy-2-nopunct": 10.569848272319835,
        "cond_entropy-2-nopunct": 2.1530850648659166,
        "distinct-3-nopunct": 0.9766702014846236,
        "vocab_size-3-nopunct": 1842,
        "unique-3-nopunct": 1803,
        "entropy-3-nopunct": 10.832453071220447,
        "cond_entropy-3-nopunct": 0.2706411804430492,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.43591,
            "recall": 0.39583,
            "fmeasure": 0.4078
        },
        "rouge2": {
            "precision": 0.18149,
            "recall": 0.16564,
            "fmeasure": 0.17005
        },
        "rougeL": {
            "precision": 0.3442,
            "recall": 0.31114,
            "fmeasure": 0.32132
        },
        "rougeLsum": {
            "precision": 0.3442,
            "recall": 0.31114,
            "fmeasure": 0.32132
        },
        "local_recall": {
            "1": 0.3703024747937672
        },
        "nist": 3.55437514922034,
        "bleu": 10.86294,
        "bleurt": -0.25843,
        "nubia": {
            "semantic_relation": 3.04563,
            "contradiction": 20.09072,
            "irrelevancy": 61.36187,
            "logical_agreement": 18.54741,
            "grammar_ref": 3.63886,
            "grammar_hyp": 3.53283,
            "nubia_score": 0.46625
        },
        "meteor": 0.1809626600456817,
        "bertscore": {
            "precision": 0.84559,
            "recall": 0.83205,
            "f1": 0.83845
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-6": {
        "predictions_file": "T5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.73636,
        "msttr-100_nopunct": 0.75714,
        "total_length": 2257,
        "mean_pred_length": 21.29245283018868,
        "std_pred_length": 4.2934064874692375,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 35,
        "distinct-1": 0.4240141781125388,
        "vocab_size-1": 957,
        "unique-1": 747,
        "entropy-1": 8.314264891435618,
        "distinct-2": 0.8493723849372385,
        "vocab_size-2": 1827,
        "unique-2": 1701,
        "entropy-2": 10.612275112509364,
        "cond_entropy-2": 2.1057222470447385,
        "distinct-3": 0.9667481662591687,
        "vocab_size-3": 1977,
        "unique-3": 1938,
        "entropy-3": 10.914648008276947,
        "cond_entropy-3": 0.3126873186855864,
        "total_length-nopunct": 2112,
        "mean_pred_length-nopunct": 19.92452830188679,
        "std_pred_length-nopunct": 4.129274487893583,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.4498106060606061,
        "vocab_size-1-nopunct": 950,
        "unique-1-nopunct": 744,
        "entropy-1-nopunct": 8.428912898276977,
        "distinct-2-nopunct": 0.8484546360917248,
        "vocab_size-2-nopunct": 1702,
        "unique-2-nopunct": 1583,
        "entropy-2-nopunct": 10.506249969599992,
        "cond_entropy-2-nopunct": 2.1776879135112424,
        "distinct-3-nopunct": 0.968421052631579,
        "vocab_size-3-nopunct": 1840,
        "unique-3-nopunct": 1804,
        "entropy-3-nopunct": 10.81391252059835,
        "cond_entropy-3-nopunct": 0.32346940275640673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.43123,
            "recall": 0.39241,
            "fmeasure": 0.4023
        },
        "rouge2": {
            "precision": 0.17538,
            "recall": 0.15689,
            "fmeasure": 0.16117
        },
        "rougeL": {
            "precision": 0.34382,
            "recall": 0.31432,
            "fmeasure": 0.321
        },
        "rougeLsum": {
            "precision": 0.34382,
            "recall": 0.31432,
            "fmeasure": 0.321
        },
        "local_recall": {
            "1": 0.36422613531047265
        },
        "nist": 3.4575727705442505,
        "bleu": 10.45058,
        "bleurt": -0.31323,
        "nubia": {
            "semantic_relation": 3.03501,
            "contradiction": 23.00881,
            "irrelevancy": 60.60936,
            "logical_agreement": 16.38183,
            "grammar_ref": 3.80483,
            "grammar_hyp": 3.59698,
            "nubia_score": 0.45069
        },
        "meteor": 0.17484776339205815,
        "bertscore": {
            "precision": 0.83957,
            "recall": 0.82944,
            "f1": 0.83407
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-7": {
        "predictions_file": "T5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.73048,
        "msttr-100_nopunct": 0.757,
        "total_length": 2181,
        "mean_pred_length": 20.57547169811321,
        "std_pred_length": 4.49936706913138,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 37,
        "distinct-1": 0.4236588720770289,
        "vocab_size-1": 924,
        "unique-1": 710,
        "entropy-1": 8.322029592680801,
        "distinct-2": 0.8587951807228915,
        "vocab_size-2": 1782,
        "unique-2": 1651,
        "entropy-2": 10.603480445055945,
        "cond_entropy-2": 2.0791989703430085,
        "distinct-3": 0.9700355510411376,
        "vocab_size-3": 1910,
        "unique-3": 1861,
        "entropy-3": 10.879235664049121,
        "cond_entropy-3": 0.2638031505566092,
        "total_length-nopunct": 2025,
        "mean_pred_length-nopunct": 19.10377358490566,
        "std_pred_length-nopunct": 4.442354562835316,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.4528395061728395,
        "vocab_size-1-nopunct": 917,
        "unique-1-nopunct": 707,
        "entropy-1-nopunct": 8.463717605578505,
        "distinct-2-nopunct": 0.8676393955184992,
        "vocab_size-2-nopunct": 1665,
        "unique-2-nopunct": 1549,
        "entropy-2-nopunct": 10.51378104128886,
        "cond_entropy-2-nopunct": 2.131914886542422,
        "distinct-3-nopunct": 0.9762824048538334,
        "vocab_size-3-nopunct": 1770,
        "unique-3-nopunct": 1732,
        "entropy-3-nopunct": 10.774646145480288,
        "cond_entropy-3-nopunct": 0.26542428015779973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.39677,
            "recall": 0.34846,
            "fmeasure": 0.36391
        },
        "rouge2": {
            "precision": 0.14922,
            "recall": 0.12897,
            "fmeasure": 0.13563
        },
        "rougeL": {
            "precision": 0.31291,
            "recall": 0.2752,
            "fmeasure": 0.28691
        },
        "rougeLsum": {
            "precision": 0.31291,
            "recall": 0.2752,
            "fmeasure": 0.28691
        },
        "local_recall": {
            "1": 0.32897806812879143
        },
        "nist": 3.102009127058715,
        "bleu": 8.43891,
        "bleurt": -0.32017,
        "nubia": {
            "semantic_relation": 2.91149,
            "contradiction": 16.03834,
            "irrelevancy": 68.83728,
            "logical_agreement": 15.12438,
            "grammar_ref": 3.75874,
            "grammar_hyp": 3.64269,
            "nubia_score": 0.43191
        },
        "meteor": 0.15820080776261805,
        "bertscore": {
            "precision": 0.83175,
            "recall": 0.81514,
            "f1": 0.82313
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 256,
        "msttr-100": 0.61797,
        "msttr-100_nopunct": 0.61515,
        "total_length": 7421,
        "mean_pred_length": 28.98828125,
        "std_pred_length": 7.100001332457511,
        "median_pred_length": 28.0,
        "min_pred_length": 11,
        "max_pred_length": 58,
        "distinct-1": 0.08179490634685352,
        "vocab_size-1": 607,
        "unique-1": 262,
        "entropy-1": 7.07597735131491,
        "distinct-2": 0.2595952547103978,
        "vocab_size-2": 1860,
        "unique-2": 1010,
        "entropy-2": 9.576260945597056,
        "cond_entropy-2": 2.441231231059415,
        "distinct-3": 0.4611376465479809,
        "vocab_size-3": 3186,
        "unique-3": 2198,
        "entropy-3": 10.83303771604227,
        "cond_entropy-3": 1.276604655512762,
        "total_length-nopunct": 6800,
        "mean_pred_length-nopunct": 26.5625,
        "std_pred_length-nopunct": 6.231535224164267,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 50,
        "distinct-1-nopunct": 0.08808823529411765,
        "vocab_size-1-nopunct": 599,
        "unique-1-nopunct": 261,
        "entropy-1-nopunct": 7.104441407246229,
        "distinct-2-nopunct": 0.2716992665036675,
        "vocab_size-2-nopunct": 1778,
        "unique-2-nopunct": 986,
        "entropy-2-nopunct": 9.50643808152575,
        "cond_entropy-2-nopunct": 2.443003172166354,
        "distinct-3-nopunct": 0.47630407124681934,
        "vocab_size-3-nopunct": 2995,
        "unique-3-nopunct": 2100,
        "entropy-3-nopunct": 10.750604609975891,
        "cond_entropy-3-nopunct": 1.2672734344533805,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.70708,
            "recall": 0.63641,
            "fmeasure": 0.6605
        },
        "rouge2": {
            "precision": 0.46265,
            "recall": 0.41632,
            "fmeasure": 0.43217
        },
        "rougeL": {
            "precision": 0.59027,
            "recall": 0.53078,
            "fmeasure": 0.55131
        },
        "rougeLsum": {
            "precision": 0.59027,
            "recall": 0.53078,
            "fmeasure": 0.55131
        },
        "local_recall": {
            "1": 0.6251854049243548
        },
        "nist": 6.284386566060284,
        "bleu": 34.50687,
        "bleurt": -0.02046,
        "nubia": {
            "semantic_relation": 3.9377,
            "contradiction": 5.77209,
            "irrelevancy": 18.81046,
            "logical_agreement": 75.41745,
            "grammar_ref": 4.19274,
            "grammar_hyp": 4.11091,
            "nubia_score": 0.65072
        },
        "meteor": 0.34055457934021033,
        "bertscore": {
            "precision": 0.90315,
            "recall": 0.8867,
            "f1": 0.89456
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-8": {
        "predictions_file": "T5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.73318,
        "msttr-100_nopunct": 0.7595,
        "total_length": 2215,
        "mean_pred_length": 20.89622641509434,
        "std_pred_length": 4.410384925833483,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 31,
        "distinct-1": 0.4257336343115124,
        "vocab_size-1": 943,
        "unique-1": 710,
        "entropy-1": 8.320892727543072,
        "distinct-2": 0.8667614983404457,
        "vocab_size-2": 1828,
        "unique-2": 1702,
        "entropy-2": 10.643028492471878,
        "cond_entropy-2": 2.124323269405529,
        "distinct-3": 0.9775336994508238,
        "vocab_size-3": 1958,
        "unique-3": 1922,
        "entropy-3": 10.918950717052159,
        "cond_entropy-3": 0.2818946909207281,
        "total_length-nopunct": 2071,
        "mean_pred_length-nopunct": 19.537735849056602,
        "std_pred_length-nopunct": 4.271835203480581,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.4519555770159343,
        "vocab_size-1-nopunct": 936,
        "unique-1-nopunct": 709,
        "entropy-1-nopunct": 8.44431138273357,
        "distinct-2-nopunct": 0.8702290076335878,
        "vocab_size-2-nopunct": 1710,
        "unique-2-nopunct": 1594,
        "entropy-2-nopunct": 10.548966736145614,
        "cond_entropy-2-nopunct": 2.200310370098955,
        "distinct-3-nopunct": 0.9811726734803657,
        "vocab_size-3-nopunct": 1824,
        "unique-3-nopunct": 1794,
        "entropy-3-nopunct": 10.820626042810446,
        "cond_entropy-3-nopunct": 0.27981468007602,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.40768,
            "recall": 0.36497,
            "fmeasure": 0.37752
        },
        "rouge2": {
            "precision": 0.14201,
            "recall": 0.12601,
            "fmeasure": 0.13061
        },
        "rougeL": {
            "precision": 0.3142,
            "recall": 0.2793,
            "fmeasure": 0.28973
        },
        "rougeLsum": {
            "precision": 0.3142,
            "recall": 0.2793,
            "fmeasure": 0.28973
        },
        "local_recall": {
            "1": 0.3313364055299539
        },
        "nist": 3.0981917798769936,
        "bleu": 7.6728,
        "bleurt": -0.29729,
        "nubia": {
            "semantic_relation": 2.98586,
            "contradiction": 21.45985,
            "irrelevancy": 63.56752,
            "logical_agreement": 14.97263,
            "grammar_ref": 3.78639,
            "grammar_hyp": 3.62725,
            "nubia_score": 0.44241
        },
        "meteor": 0.1609264276764268,
        "bertscore": {
            "precision": 0.83491,
            "recall": 0.82238,
            "f1": 0.82832
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-9": {
        "predictions_file": "T5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.74143,
        "msttr-100_nopunct": 0.7665,
        "total_length": 2193,
        "mean_pred_length": 20.68867924528302,
        "std_pred_length": 5.559902278812695,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 38,
        "distinct-1": 0.42863657090743273,
        "vocab_size-1": 940,
        "unique-1": 738,
        "entropy-1": 8.337674276687649,
        "distinct-2": 0.8538572113080978,
        "vocab_size-2": 1782,
        "unique-2": 1642,
        "entropy-2": 10.605723715588303,
        "cond_entropy-2": 2.0665679385345657,
        "distinct-3": 0.9621403331650682,
        "vocab_size-3": 1906,
        "unique-3": 1857,
        "entropy-3": 10.862328786837038,
        "cond_entropy-3": 0.2652715472551562,
        "total_length-nopunct": 2047,
        "mean_pred_length-nopunct": 19.31132075471698,
        "std_pred_length-nopunct": 5.241998768198602,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.45578895945285786,
        "vocab_size-1-nopunct": 933,
        "unique-1-nopunct": 734,
        "entropy-1-nopunct": 8.47522387337233,
        "distinct-2-nopunct": 0.854198866563627,
        "vocab_size-2-nopunct": 1658,
        "unique-2-nopunct": 1531,
        "entropy-2-nopunct": 10.497346170673952,
        "cond_entropy-2-nopunct": 2.117606995582192,
        "distinct-3-nopunct": 0.9618528610354223,
        "vocab_size-3-nopunct": 1765,
        "unique-3-nopunct": 1719,
        "entropy-3-nopunct": 10.751283828426486,
        "cond_entropy-3-nopunct": 0.2716942787332783,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.37155,
            "recall": 0.33318,
            "fmeasure": 0.34602
        },
        "rouge2": {
            "precision": 0.15146,
            "recall": 0.13562,
            "fmeasure": 0.14083
        },
        "rougeL": {
            "precision": 0.29978,
            "recall": 0.26744,
            "fmeasure": 0.2784
        },
        "rougeLsum": {
            "precision": 0.29978,
            "recall": 0.26744,
            "fmeasure": 0.2784
        },
        "local_recall": {
            "1": 0.3089201877934272
        },
        "nist": 2.976976314347985,
        "bleu": 9.28302,
        "bleurt": -0.35752,
        "nubia": {
            "semantic_relation": 2.76502,
            "contradiction": 16.72038,
            "irrelevancy": 66.40956,
            "logical_agreement": 16.87007,
            "grammar_ref": 3.81724,
            "grammar_hyp": 3.60442,
            "nubia_score": 0.40258
        },
        "meteor": 0.15317782679891767,
        "bertscore": {
            "precision": 0.82837,
            "recall": 0.81331,
            "f1": 0.82048
        }
    },
    "e2e_nlg_validation": {
        "predictions_file": "T5-large (Baseline)/e2e_nlg_validation",
        "N": 4299,
        "msttr-100": 0.32462,
        "msttr-100_nopunct": 0.31795,
        "total_length": 108456,
        "mean_pred_length": 25.228192602930914,
        "std_pred_length": 6.7692699285488604,
        "median_pred_length": 25.0,
        "min_pred_length": 7,
        "max_pred_length": 57,
        "distinct-1": 0.004757689754370436,
        "vocab_size-1": 516,
        "unique-1": 79,
        "entropy-1": 6.2292281959717615,
        "distinct-2": 0.025394356596292137,
        "vocab_size-2": 2645,
        "unique-2": 602,
        "entropy-2": 8.567108992145197,
        "cond_entropy-2": 2.244621581238698,
        "distinct-3": 0.05546876564721905,
        "vocab_size-3": 5539,
        "unique-3": 1476,
        "entropy-3": 10.051623428166993,
        "cond_entropy-3": 1.4983605778755626,
        "total_length-nopunct": 98528,
        "mean_pred_length-nopunct": 22.91881832984415,
        "std_pred_length-nopunct": 6.24663049617452,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.005186342968496265,
        "vocab_size-1-nopunct": 511,
        "unique-1-nopunct": 79,
        "entropy-1-nopunct": 6.295272708357188,
        "distinct-2-nopunct": 0.028600536989674092,
        "vocab_size-2-nopunct": 2695,
        "unique-2-nopunct": 638,
        "entropy-2-nopunct": 8.51625322548672,
        "cond_entropy-2-nopunct": 2.266261103500427,
        "distinct-3-nopunct": 0.06002446347158901,
        "vocab_size-3-nopunct": 5398,
        "unique-3-nopunct": 1472,
        "entropy-3-nopunct": 10.033733798901354,
        "cond_entropy-3-nopunct": 1.510267551222038,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_validation.json",
        "rouge1": {
            "precision": 0.67535,
            "recall": 0.69091,
            "fmeasure": 0.67146
        },
        "rouge2": {
            "precision": 0.3949,
            "recall": 0.40252,
            "fmeasure": 0.39217
        },
        "rougeL": {
            "precision": 0.48624,
            "recall": 0.49929,
            "fmeasure": 0.48424
        },
        "rougeLsum": {
            "precision": 0.48624,
            "recall": 0.49929,
            "fmeasure": 0.48424
        },
        "local_recall": {
            "1": 0.6816449648280547
        },
        "nist": 4.790091473117747,
        "bleu": 29.10889,
        "bleurt": 0.14659,
        "nubia": {
            "semantic_relation": 4.18719,
            "contradiction": 3.93119,
            "irrelevancy": 28.73745,
            "logical_agreement": 67.33137,
            "grammar_ref": 4.85661,
            "grammar_hyp": 4.4957,
            "nubia_score": 0.74099
        },
        "meteor": 0.3529337809200531,
        "bertscore": {
            "precision": 0.89921,
            "recall": 0.89923,
            "f1": 0.89889
        }
    },
    "e2e_nlg_test": {
        "predictions_file": "T5-large (Baseline)/e2e_nlg_test",
        "N": 4693,
        "msttr-100": 0.31811,
        "msttr-100_nopunct": 0.31021,
        "total_length": 119736,
        "mean_pred_length": 25.513743873854676,
        "std_pred_length": 6.533370281588092,
        "median_pred_length": 25.0,
        "min_pred_length": 8,
        "max_pred_length": 51,
        "distinct-1": 0.0038000267254626845,
        "vocab_size-1": 455,
        "unique-1": 61,
        "entropy-1": 6.106948851552228,
        "distinct-2": 0.021435463261563068,
        "vocab_size-2": 2466,
        "unique-2": 521,
        "entropy-2": 8.387233938611597,
        "cond_entropy-2": 2.1898936898396926,
        "distinct-3": 0.049179882193022204,
        "vocab_size-3": 5427,
        "unique-3": 1340,
        "entropy-3": 9.837321741012865,
        "cond_entropy-3": 1.4582249218089096,
        "total_length-nopunct": 109367,
        "mean_pred_length-nopunct": 23.304282974643087,
        "std_pred_length-nopunct": 5.985519209844984,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 48,
        "distinct-1-nopunct": 0.004114586666910494,
        "vocab_size-1-nopunct": 450,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 6.159567609965023,
        "distinct-2-nopunct": 0.02378814223207291,
        "vocab_size-2-nopunct": 2490,
        "unique-2-nopunct": 544,
        "entropy-2-nopunct": 8.35729809311823,
        "cond_entropy-2-nopunct": 2.242691931456469,
        "distinct-3-nopunct": 0.05294005861113612,
        "vocab_size-3-nopunct": 5293,
        "unique-3-nopunct": 1342,
        "entropy-3-nopunct": 9.85729238906292,
        "cond_entropy-3-nopunct": 1.4928769445539434,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.73003,
            "recall": 0.70882,
            "fmeasure": 0.70764
        },
        "rouge2": {
            "precision": 0.43042,
            "recall": 0.41769,
            "fmeasure": 0.41677
        },
        "rougeL": {
            "precision": 0.51272,
            "recall": 0.49864,
            "fmeasure": 0.49715
        },
        "rougeLsum": {
            "precision": 0.51272,
            "recall": 0.49864,
            "fmeasure": 0.49715
        },
        "local_recall": {
            "1": 0.6957179888002849
        },
        "nist": 5.230121427220737,
        "bleu": 30.35478,
        "bleurt": 0.17248,
        "nubia": {
            "semantic_relation": 4.26404,
            "contradiction": 3.29249,
            "irrelevancy": 25.73485,
            "logical_agreement": 70.97266,
            "grammar_ref": 4.83021,
            "grammar_hyp": 4.49372,
            "nubia_score": 0.768
        },
        "meteor": 0.3585019209969777,
        "bertscore": {
            "precision": 0.91168,
            "recall": 0.90467,
            "f1": 0.9078
        }
    },
    "e2e_nlg_challenge_train_sample": {
        "predictions_file": "T5-large (Baseline)/e2e_nlg_challenge_train_sample",
        "N": 500
    },
    "e2e_nlg_challenge_validation_sample": {
        "predictions_file": "T5-large (Baseline)/e2e_nlg_challenge_validation_sample",
        "N": 500
    },
    "e2e_nlg_challenge_test_scramble": {
        "predictions_file": "T5-large (Baseline)/e2e_nlg_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.51333,
        "msttr-100_nopunct": 0.52339,
        "total_length": 12639,
        "mean_pred_length": 25.278,
        "std_pred_length": 6.873188197627067,
        "median_pred_length": 25.0,
        "min_pred_length": 8,
        "max_pred_length": 57,
        "distinct-1": 0.023815175251206584,
        "vocab_size-1": 301,
        "unique-1": 98,
        "entropy-1": 6.1028445620710725,
        "distinct-2": 0.10569239640827086,
        "vocab_size-2": 1283,
        "unique-2": 626,
        "entropy-2": 8.325709832708224,
        "cond_entropy-2": 2.1287647010263435,
        "distinct-3": 0.21556834779620243,
        "vocab_size-3": 2509,
        "unique-3": 1434,
        "entropy-3": 9.666858999997233,
        "cond_entropy-3": 1.3461209538366325,
        "total_length-nopunct": 11530,
        "mean_pred_length-nopunct": 23.06,
        "std_pred_length-nopunct": 6.341640166392288,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 53,
        "distinct-1-nopunct": 0.025845620121422375,
        "vocab_size-1-nopunct": 298,
        "unique-1-nopunct": 97,
        "entropy-1-nopunct": 6.157584715937467,
        "distinct-2-nopunct": 0.11368993653671804,
        "vocab_size-2-nopunct": 1254,
        "unique-2-nopunct": 643,
        "entropy-2-nopunct": 8.290006623724569,
        "cond_entropy-2-nopunct": 2.1734585498150047,
        "distinct-3-nopunct": 0.22744539411206077,
        "vocab_size-3-nopunct": 2395,
        "unique-3-nopunct": 1380,
        "entropy-3-nopunct": 9.675337057427047,
        "cond_entropy-3-nopunct": 1.3734492878124092,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_challenge_test_scramble.json",
        "rouge1": {
            "precision": 0.72521,
            "recall": 0.6951,
            "fmeasure": 0.69811
        },
        "rouge2": {
            "precision": 0.41852,
            "recall": 0.40043,
            "fmeasure": 0.40241
        },
        "rougeL": {
            "precision": 0.49858,
            "recall": 0.47759,
            "fmeasure": 0.47965
        },
        "rougeLsum": {
            "precision": 0.49858,
            "recall": 0.47759,
            "fmeasure": 0.47965
        },
        "local_recall": {
            "1": 0.6829721938063796
        },
        "nist": 5.055298834186903,
        "bleu": 28.59036,
        "bleurt": 0.14511,
        "nubia": {
            "semantic_relation": 4.24369,
            "contradiction": 3.42449,
            "irrelevancy": 26.12657,
            "logical_agreement": 70.44895,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.48966,
            "nubia_score": 0.75905
        },
        "meteor": 0.35035112010693964,
        "bertscore": {
            "precision": 0.90948,
            "recall": 0.90068,
            "f1": 0.90472
        }
    },
    "mlsum_de_validation": {
        "predictions_file": "T5-large (Baseline)/mlsum_de_validation",
        "N": 11392,
        "msttr-100": 0.72905,
        "msttr-100_nopunct": 0.77925,
        "total_length": 306946,
        "mean_pred_length": 26.943995786516854,
        "std_pred_length": 7.209314534417403,
        "median_pred_length": 26.0,
        "min_pred_length": 6,
        "max_pred_length": 79,
        "distinct-1": 0.11584448078815167,
        "vocab_size-1": 35558,
        "unique-1": 21099,
        "entropy-1": 10.255283928935642,
        "distinct-2": 0.4932499644734972,
        "vocab_size-2": 145782,
        "unique-2": 116262,
        "entropy-2": 15.59764407312253,
        "cond_entropy-2": 5.094056400711695,
        "distinct-3": 0.7948494168819195,
        "vocab_size-3": 225866,
        "unique-3": 203937,
        "entropy-3": 17.389493203492027,
        "cond_entropy-3": 1.777622634120018,
        "total_length-nopunct": 272250,
        "mean_pred_length-nopunct": 23.898349719101123,
        "std_pred_length-nopunct": 6.4653373588864955,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 70,
        "distinct-1-nopunct": 0.13055280073461892,
        "vocab_size-1-nopunct": 35543,
        "unique-1-nopunct": 21097,
        "entropy-1-nopunct": 10.822099697130815,
        "distinct-2-nopunct": 0.5531246885278581,
        "vocab_size-2-nopunct": 144287,
        "unique-2-nopunct": 117702,
        "entropy-2-nopunct": 15.947311064961713,
        "cond_entropy-2-nopunct": 5.241243380885641,
        "distinct-3-nopunct": 0.8415816183367674,
        "vocab_size-3-nopunct": 209946,
        "unique-3-nopunct": 193274,
        "entropy-3-nopunct": 17.404266942956742,
        "cond_entropy-3-nopunct": 1.5072331497520113,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_validation.json",
        "rouge1": {
            "precision": 0.33404,
            "recall": 0.34112,
            "fmeasure": 0.32868
        },
        "rouge2": {
            "precision": 0.19343,
            "recall": 0.19551,
            "fmeasure": 0.18959
        },
        "rougeL": {
            "precision": 0.28184,
            "recall": 0.28743,
            "fmeasure": 0.27726
        },
        "rougeLsum": {
            "precision": 0.28184,
            "recall": 0.28743,
            "fmeasure": 0.27726
        },
        "local_recall": {
            "1": 0.3349414031144646
        },
        "nist": 4.753184273957675,
        "bleu": 20.40739,
        "bleurt": -0.51691,
        "nubia": {
            "semantic_relation": 2.27341,
            "contradiction": 27.27511,
            "irrelevancy": 51.5857,
            "logical_agreement": 21.13919,
            "grammar_ref": 5.04919,
            "grammar_hyp": 4.82268,
            "nubia_score": 0.29003
        },
        "meteor": 0.2828907075227362,
        "bertscore": {
            "precision": 0.86923,
            "recall": 0.87081,
            "f1": 0.86984
        }
    },
    "common_gen_validation": {
        "predictions_file": "T5-large (Baseline)/common_gen_validation",
        "N": 993,
        "msttr-100": 0.59861,
        "msttr-100_nopunct": 0.62189,
        "total_length": 11529,
        "mean_pred_length": 11.610271903323262,
        "std_pred_length": 3.0956837746798063,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 25,
        "distinct-1": 0.14025500910746813,
        "vocab_size-1": 1617,
        "unique-1": 838,
        "entropy-1": 7.458436809513101,
        "distinct-2": 0.48139711465451784,
        "vocab_size-2": 5072,
        "unique-2": 3729,
        "entropy-2": 11.16645062475037,
        "cond_entropy-2": 3.5057033061313345,
        "distinct-3": 0.7480876034789898,
        "vocab_size-3": 7139,
        "unique-3": 6125,
        "entropy-3": 12.414102424785982,
        "cond_entropy-3": 1.3237522058923386,
        "total_length-nopunct": 10680,
        "mean_pred_length-nopunct": 10.755287009063444,
        "std_pred_length-nopunct": 2.9768382057351195,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.151123595505618,
        "vocab_size-1-nopunct": 1614,
        "unique-1-nopunct": 837,
        "entropy-1-nopunct": 7.612549900797279,
        "distinct-2-nopunct": 0.4788892329926706,
        "vocab_size-2-nopunct": 4639,
        "unique-2-nopunct": 3457,
        "entropy-2-nopunct": 10.984457919112101,
        "cond_entropy-2-nopunct": 3.6833809387151066,
        "distinct-3-nopunct": 0.7518978605935127,
        "vocab_size-3-nopunct": 6537,
        "unique-3-nopunct": 5639,
        "entropy-3-nopunct": 12.280947650829361,
        "cond_entropy-3-nopunct": 1.3934107867402141,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/common_gen_validation.json",
        "rouge1": {
            "precision": 0.57205,
            "recall": 0.59011,
            "fmeasure": 0.56766
        },
        "rouge2": {
            "precision": 0.26292,
            "recall": 0.26856,
            "fmeasure": 0.2579
        },
        "rougeL": {
            "precision": 0.49375,
            "recall": 0.50895,
            "fmeasure": 0.48979
        },
        "rougeLsum": {
            "precision": 0.49375,
            "recall": 0.50895,
            "fmeasure": 0.48979
        },
        "local_recall": {
            "1": 0.10598675165604299,
            "2": 0.3093085106382979,
            "3": 0.47953216374269003,
            "4": 0.7156052503646086,
            "5": 0.6909871244635193,
            "6": 0.8452380952380952,
            "7": 0.8333333333333334,
            "8": 0.8
        },
        "nist": 6.093598312925217,
        "bleu": 20.43328,
        "bleurt": -0.55879,
        "nubia": {
            "semantic_relation": 2.86624,
            "contradiction": 31.64593,
            "irrelevancy": 36.79644,
            "logical_agreement": 31.55763,
            "grammar_ref": 4.64808,
            "grammar_hyp": 4.62409,
            "nubia_score": 0.38802
        },
        "meteor": 0.23896475524535246,
        "bertscore": {
            "precision": 0.86785,
            "recall": 0.87253,
            "f1": 0.86871
        }
    },
    "common_gen_test": {
        "predictions_file": "T5-large (Baseline)/common_gen_test",
        "N": 1497
    },
    "totto_validation": {
        "predictions_file": "T5-large (Baseline)/totto_validation",
        "N": 7700,
        "msttr-100": 0.72402,
        "msttr-100_nopunct": 0.77854,
        "total_length": 127119,
        "mean_pred_length": 16.50896103896104,
        "std_pred_length": 6.8378661295958585,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 64,
        "distinct-1": 0.17068258875541814,
        "vocab_size-1": 21697,
        "unique-1": 14846,
        "entropy-1": 10.07495293771847,
        "distinct-2": 0.5482125959855635,
        "vocab_size-2": 65467,
        "unique-2": 54675,
        "entropy-2": 14.656040841167602,
        "cond_entropy-2": 4.190932268164699,
        "distinct-3": 0.7830360099893483,
        "vocab_size-3": 87480,
        "unique-3": 79748,
        "entropy-3": 15.944713950667396,
        "cond_entropy-3": 1.26311460166356,
        "total_length-nopunct": 110350,
        "mean_pred_length-nopunct": 14.331168831168831,
        "std_pred_length-nopunct": 5.836868038936941,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.19643860444041686,
        "vocab_size-1-nopunct": 21677,
        "unique-1-nopunct": 14842,
        "entropy-1-nopunct": 10.647904484259062,
        "distinct-2-nopunct": 0.5940769605455432,
        "vocab_size-2-nopunct": 60982,
        "unique-2-nopunct": 52049,
        "entropy-2-nopunct": 14.663130428785879,
        "cond_entropy-2-nopunct": 4.187693818103014,
        "distinct-3-nopunct": 0.8111532385466035,
        "vocab_size-3-nopunct": 77019,
        "unique-3-nopunct": 71120,
        "entropy-3-nopunct": 15.822572083868609,
        "cond_entropy-3-nopunct": 1.2267298325826774,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_validation.json",
        "rouge1": {
            "precision": 0.75999,
            "recall": 0.73504,
            "fmeasure": 0.73587
        },
        "rouge2": {
            "precision": 0.53691,
            "recall": 0.52155,
            "fmeasure": 0.52089
        },
        "rougeL": {
            "precision": 0.66256,
            "recall": 0.64354,
            "fmeasure": 0.64268
        },
        "rougeLsum": {
            "precision": 0.66256,
            "recall": 0.64354,
            "fmeasure": 0.64268
        },
        "local_recall": {
            "1": 0.21552927650488626,
            "2": 0.46361871899935303,
            "3": 0.7726515217963337
        },
        "nist": 10.78341883948259,
        "bleu": 47.04345,
        "bleurt": 0.2698,
        "nubia": {
            "semantic_relation": 4.18002,
            "contradiction": 8.08039,
            "irrelevancy": 30.31511,
            "logical_agreement": 61.6045,
            "grammar_ref": 4.66172,
            "grammar_hyp": 4.64894,
            "nubia_score": 0.7262
        },
        "meteor": 0.3947006823548486,
        "bertscore": {
            "precision": 0.92788,
            "recall": 0.92455,
            "f1": 0.92459
        }
    },
    "totto_test": {
        "predictions_file": "T5-large (Baseline)/totto_test",
        "N": 7700,
        "msttr-100": 0.72421,
        "msttr-100_nopunct": 0.77845,
        "total_length": 126923,
        "mean_pred_length": 16.483506493506493,
        "std_pred_length": 6.873295824908969,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 65,
        "distinct-1": 0.17059949733302868,
        "vocab_size-1": 21653,
        "unique-1": 14892,
        "entropy-1": 10.06252883752081,
        "distinct-2": 0.548107328283972,
        "vocab_size-2": 65347,
        "unique-2": 54669,
        "entropy-2": 14.647895491579591,
        "cond_entropy-2": 4.195485422447916,
        "distinct-3": 0.7828161007146508,
        "vocab_size-3": 87302,
        "unique-3": 79518,
        "entropy-3": 15.94504745505158,
        "cond_entropy-3": 1.273359382254325,
        "total_length-nopunct": 110247,
        "mean_pred_length-nopunct": 14.317792207792207,
        "std_pred_length-nopunct": 5.925855327243469,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 53,
        "distinct-1-nopunct": 0.19623209701851296,
        "vocab_size-1-nopunct": 21634,
        "unique-1-nopunct": 14890,
        "entropy-1-nopunct": 10.634914539491836,
        "distinct-2-nopunct": 0.59352296995524,
        "vocab_size-2-nopunct": 60864,
        "unique-2-nopunct": 52023,
        "entropy-2-nopunct": 14.656103694377412,
        "cond_entropy-2-nopunct": 4.196930903852694,
        "distinct-3-nopunct": 0.8107056628043059,
        "vocab_size-3-nopunct": 76893,
        "unique-3-nopunct": 70918,
        "entropy-3-nopunct": 15.823109162390823,
        "cond_entropy-3-nopunct": 1.23854452170388,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7639,
            "recall": 0.73647,
            "fmeasure": 0.73817
        },
        "rouge2": {
            "precision": 0.53807,
            "recall": 0.52078,
            "fmeasure": 0.52077
        },
        "rougeL": {
            "precision": 0.66374,
            "recall": 0.64332,
            "fmeasure": 0.6429
        },
        "rougeLsum": {
            "precision": 0.66374,
            "recall": 0.64332,
            "fmeasure": 0.6429
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.46066927422859627,
            "3": 0.7756511692160852
        },
        "nist": 10.800615311915474,
        "bleu": 46.80157,
        "bleurt": 0.27499,
        "nubia": {
            "semantic_relation": 4.19081,
            "contradiction": 8.34319,
            "irrelevancy": 29.37983,
            "logical_agreement": 62.27698,
            "grammar_ref": 4.66736,
            "grammar_hyp": 4.65547,
            "nubia_score": 0.7283
        },
        "meteor": 0.39522015845861946,
        "bertscore": {
            "precision": 0.92856,
            "recall": 0.92506,
            "f1": 0.92512
        }
    },
    "totto_challenge_train_sample": {
        "predictions_file": "T5-large (Baseline)/totto_challenge_train_sample",
        "N": 500
    },
    "totto_challenge_validation_sample": {
        "predictions_file": "T5-large (Baseline)/totto_challenge_validation_sample",
        "N": 500
    },
    "totto_challenge_test_scramble": {
        "predictions_file": "T5-large (Baseline)/totto_challenge_test_scramble",
        "N": 378
    },
    "mlsum_de_test": {
        "predictions_file": "T5-large (Baseline)/mlsum_de_test",
        "N": 10695,
        "msttr-100": 0.7302,
        "msttr-100_nopunct": 0.78108,
        "total_length": 288061,
        "mean_pred_length": 26.93417484805984,
        "std_pred_length": 7.001553685139734,
        "median_pred_length": 26.0,
        "min_pred_length": 8,
        "max_pred_length": 73,
        "distinct-1": 0.1204640683744068,
        "vocab_size-1": 34701,
        "unique-1": 20831,
        "entropy-1": 10.25423481342681,
        "distinct-2": 0.5024804770591925,
        "vocab_size-2": 139371,
        "unique-2": 111824,
        "entropy-2": 15.570273572707858,
        "cond_entropy-2": 5.067587381068223,
        "distinct-3": 0.8030119510557954,
        "vocab_size-3": 214140,
        "unique-3": 194100,
        "entropy-3": 17.333472851519314,
        "cond_entropy-3": 1.7503101683588145,
        "total_length-nopunct": 255450,
        "mean_pred_length-nopunct": 23.88499298737728,
        "std_pred_length-nopunct": 6.271991073915354,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 63,
        "distinct-1-nopunct": 0.1357839107457428,
        "vocab_size-1-nopunct": 34686,
        "unique-1-nopunct": 20830,
        "entropy-1-nopunct": 10.821770023683044,
        "distinct-2-nopunct": 0.5630855345141059,
        "vocab_size-2-nopunct": 137818,
        "unique-2-nopunct": 113023,
        "entropy-2-nopunct": 15.916590270211136,
        "cond_entropy-2-nopunct": 5.212085013427123,
        "distinct-3-nopunct": 0.8497821071520123,
        "vocab_size-3-nopunct": 198900,
        "unique-3-nopunct": 183787,
        "entropy-3-nopunct": 17.34822978012792,
        "cond_entropy-3-nopunct": 1.4807987158677,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_test.json",
        "rouge1": {
            "precision": 0.3406,
            "recall": 0.34515,
            "fmeasure": 0.33459
        },
        "rouge2": {
            "precision": 0.19974,
            "recall": 0.20104,
            "fmeasure": 0.19575
        },
        "rougeL": {
            "precision": 0.28724,
            "recall": 0.29107,
            "fmeasure": 0.28226
        },
        "rougeLsum": {
            "precision": 0.28724,
            "recall": 0.29107,
            "fmeasure": 0.28226
        },
        "local_recall": {
            "1": 0.33773555336244615
        },
        "nist": 4.847793147012845,
        "bleu": 20.98789,
        "bleurt": -0.5109,
        "nubia": {
            "semantic_relation": 2.2815,
            "contradiction": 27.37821,
            "irrelevancy": 51.25385,
            "logical_agreement": 21.36794,
            "grammar_ref": 5.03454,
            "grammar_hyp": 4.84097,
            "nubia_score": 0.29371
        },
        "meteor": 0.2860744673455013,
        "bertscore": {
            "precision": 0.87038,
            "recall": 0.87138,
            "f1": 0.8707
        }
    },
    "mlsum_de_challenge_train_sample": {
        "predictions_file": "T5-large (Baseline)/mlsum_de_challenge_train_sample",
        "N": 500
    },
    "mlsum_de_challenge_validation_sample": {
        "predictions_file": "T5-large (Baseline)/mlsum_de_challenge_validation_sample",
        "N": 500
    },
    "schema_guided_dialog_validation": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_validation",
        "N": 10000,
        "msttr-100": 0.69577,
        "msttr-100_nopunct": 0.72449,
        "total_length": 123613,
        "mean_pred_length": 12.3613,
        "std_pred_length": 7.382232881046222,
        "median_pred_length": 10.0,
        "min_pred_length": 1,
        "max_pred_length": 51,
        "distinct-1": 0.034438125439880916,
        "vocab_size-1": 4257,
        "unique-1": 1791,
        "entropy-1": 8.13123064420368,
        "distinct-2": 0.14963956589474797,
        "vocab_size-2": 17001,
        "unique-2": 9055,
        "entropy-2": 11.703356108165584,
        "cond_entropy-2": 3.3110581305507543,
        "distinct-3": 0.31278953057442865,
        "vocab_size-3": 32410,
        "unique-3": 21039,
        "entropy-3": 13.337445979556097,
        "cond_entropy-3": 1.652537469711069,
        "total_length-nopunct": 108521,
        "mean_pred_length-nopunct": 10.8521,
        "std_pred_length-nopunct": 6.769477497562128,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.03907077892758084,
        "vocab_size-1-nopunct": 4240,
        "unique-1-nopunct": 1787,
        "entropy-1-nopunct": 8.361519305285276,
        "distinct-2-nopunct": 0.16513230681783578,
        "vocab_size-2-nopunct": 16269,
        "unique-2-nopunct": 9096,
        "entropy-2-nopunct": 11.605437086300576,
        "cond_entropy-2-nopunct": 3.392340310256294,
        "distinct-3-nopunct": 0.3371999774100638,
        "vocab_size-3-nopunct": 29854,
        "unique-3-nopunct": 20101,
        "entropy-3-nopunct": 13.231412679769312,
        "cond_entropy-3-nopunct": 1.662749077437972,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_validation.json",
        "rouge1": {
            "precision": 0.62206,
            "recall": 0.60826,
            "fmeasure": 0.60114
        },
        "rouge2": {
            "precision": 0.40397,
            "recall": 0.39631,
            "fmeasure": 0.39022
        },
        "rougeL": {
            "precision": 0.56309,
            "recall": 0.55019,
            "fmeasure": 0.544
        },
        "rougeLsum": {
            "precision": 0.56309,
            "recall": 0.55019,
            "fmeasure": 0.544
        },
        "local_recall": {
            "1": 0.6129455316615819
        },
        "nist": 7.474640983099759,
        "bleu": 35.37064,
        "bleurt": 0.02151,
        "nubia": {
            "semantic_relation": 3.85628,
            "contradiction": 3.58729,
            "irrelevancy": 19.2841,
            "logical_agreement": 77.12861,
            "grammar_ref": 4.88727,
            "grammar_hyp": 4.70356,
            "nubia_score": 0.70365
        },
        "meteor": 0.34319983599081766,
        "bertscore": {
            "precision": 0.88295,
            "recall": 0.87795,
            "f1": 0.87985
        }
    },
    "schema_guided_dialog_test": {
        "predictions_file": "T5-large (Baseline)/schema_guided_dialog_test",
        "N": 10000,
        "msttr-100": 0.68623,
        "msttr-100_nopunct": 0.71334,
        "total_length": 128834,
        "mean_pred_length": 12.8834,
        "std_pred_length": 7.4690430739151585,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 58,
        "distinct-1": 0.03392737941847649,
        "vocab_size-1": 4371,
        "unique-1": 1926,
        "entropy-1": 8.074509033848722,
        "distinct-2": 0.15195987680293518,
        "vocab_size-2": 18058,
        "unique-2": 9895,
        "entropy-2": 11.716897115033003,
        "cond_entropy-2": 3.3835633018329054,
        "distinct-3": 0.3182553246228201,
        "vocab_size-3": 34637,
        "unique-3": 22912,
        "entropy-3": 13.40263220974563,
        "cond_entropy-3": 1.7071074393351495,
        "total_length-nopunct": 113314,
        "mean_pred_length-nopunct": 11.3314,
        "std_pred_length-nopunct": 6.8591817325392395,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 50,
        "distinct-1-nopunct": 0.038424201775597015,
        "vocab_size-1-nopunct": 4354,
        "unique-1-nopunct": 1924,
        "entropy-1-nopunct": 8.290501171274489,
        "distinct-2-nopunct": 0.16746036355189034,
        "vocab_size-2-nopunct": 17301,
        "unique-2-nopunct": 9955,
        "entropy-2-nopunct": 11.61961660738543,
        "cond_entropy-2-nopunct": 3.4771228321673804,
        "distinct-3-nopunct": 0.3416949733720519,
        "vocab_size-3-nopunct": 31888,
        "unique-3-nopunct": 21738,
        "entropy-3-nopunct": 13.297786211251617,
        "cond_entropy-3-nopunct": 1.7275263422205125,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.57122,
            "recall": 0.55002,
            "fmeasure": 0.54828
        },
        "rouge2": {
            "precision": 0.3529,
            "recall": 0.34117,
            "fmeasure": 0.33896
        },
        "rougeL": {
            "precision": 0.51334,
            "recall": 0.49376,
            "fmeasure": 0.49256
        },
        "rougeLsum": {
            "precision": 0.51334,
            "recall": 0.49376,
            "fmeasure": 0.49256
        },
        "local_recall": {
            "1": 0.5616340967056795
        },
        "nist": 6.808680872395217,
        "bleu": 31.37328,
        "bleurt": -0.08375,
        "nubia": {
            "semantic_relation": 3.61341,
            "contradiction": 7.44574,
            "irrelevancy": 23.05215,
            "logical_agreement": 69.50211,
            "grammar_ref": 4.76329,
            "grammar_hyp": 4.6052,
            "nubia_score": 0.63952
        },
        "meteor": 0.3127408962746228,
        "bertscore": {
            "precision": 0.87214,
            "recall": 0.86536,
            "f1": 0.86823
        }
    },
    "mlsum_de_challenge_test_covid": {
        "predictions_file": "T5-large (Baseline)/mlsum_de_challenge_test_covid",
        "N": 5058,
        "msttr-100": 0.69562,
        "msttr-100_nopunct": 0.74308,
        "total_length": 131472,
        "mean_pred_length": 25.99288256227758,
        "std_pred_length": 8.059434026238948,
        "median_pred_length": 25.0,
        "min_pred_length": 7,
        "max_pred_length": 91,
        "distinct-1": 0.11406230984544237,
        "vocab_size-1": 14996,
        "unique-1": 9322,
        "entropy-1": 9.283070636661884,
        "distinct-2": 0.4409875488474378,
        "vocab_size-2": 55747,
        "unique-2": 45410,
        "entropy-2": 13.579693083364578,
        "cond_entropy-2": 4.088162655427712,
        "distinct-3": 0.6741899864860411,
        "vocab_size-3": 81817,
        "unique-3": 74794,
        "entropy-3": 14.890192069094793,
        "cond_entropy-3": 1.2947313295177667,
        "total_length-nopunct": 115911,
        "mean_pred_length-nopunct": 22.916370106761565,
        "std_pred_length-nopunct": 7.2122488259045525,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 82,
        "distinct-1-nopunct": 0.12926296900207918,
        "vocab_size-1-nopunct": 14983,
        "unique-1-nopunct": 9320,
        "entropy-1-nopunct": 9.76091048708157,
        "distinct-2-nopunct": 0.49325683562916656,
        "vocab_size-2-nopunct": 54679,
        "unique-2-nopunct": 45496,
        "entropy-2-nopunct": 13.819816169932558,
        "cond_entropy-2-nopunct": 4.15620908209473,
        "distinct-3-nopunct": 0.7116026277234274,
        "vocab_size-3-nopunct": 75284,
        "unique-3-nopunct": 69986,
        "entropy-3-nopunct": 14.89318410522354,
        "cond_entropy-3-nopunct": 1.0895824242889691,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_challenge_test_covid.json",
        "rouge1": {
            "precision": 0.2416,
            "recall": 0.30187,
            "fmeasure": 0.25887
        },
        "rouge2": {
            "precision": 0.13062,
            "recall": 0.16331,
            "fmeasure": 0.14015
        },
        "rougeL": {
            "precision": 0.2082,
            "recall": 0.2602,
            "fmeasure": 0.22307
        },
        "rougeLsum": {
            "precision": 0.2082,
            "recall": 0.2602,
            "fmeasure": 0.22307
        },
        "local_recall": {
            "1": 0.28968140542204435
        },
        "nist": 3.10002530106077,
        "bleu": 13.42268,
        "bleurt": -0.63795,
        "nubia": {
            "semantic_relation": 1.88832,
            "contradiction": 33.32049,
            "irrelevancy": 53.38951,
            "logical_agreement": 13.29,
            "grammar_ref": 5.17449,
            "grammar_hyp": 4.74998,
            "nubia_score": 0.22311
        },
        "meteor": 0.236931573359321,
        "bertscore": {
            "precision": 0.85014,
            "recall": 0.86103,
            "f1": 0.85533
        }
    },
    "mlsum_es_validation": {
        "predictions_file": "T5-large (Baseline)/mlsum_es_validation",
        "N": 9977,
        "msttr-100": 0.67805,
        "msttr-100_nopunct": 0.68269,
        "total_length": 223850,
        "mean_pred_length": 22.436604189636164,
        "std_pred_length": 6.8843461509008215,
        "median_pred_length": 21.0,
        "min_pred_length": 9,
        "max_pred_length": 76,
        "distinct-1": 0.10923832923832924,
        "vocab_size-1": 24453,
        "unique-1": 13831,
        "entropy-1": 9.644784844193751,
        "distinct-2": 0.4486681348276781,
        "vocab_size-2": 95958,
        "unique-2": 74919,
        "entropy-2": 14.782386802578854,
        "cond_entropy-2": 5.325718394646787,
        "distinct-3": 0.7547426138815867,
        "vocab_size-3": 153889,
        "unique-3": 138091,
        "entropy-3": 16.68599593419996,
        "cond_entropy-3": 1.9476342980126204,
        "total_length-nopunct": 215156,
        "mean_pred_length-nopunct": 21.565199959907787,
        "std_pred_length-nopunct": 6.382874606756177,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 63,
        "distinct-1-nopunct": 0.1135780549926565,
        "vocab_size-1-nopunct": 24437,
        "unique-1-nopunct": 13828,
        "entropy-1-nopunct": 9.722779098608262,
        "distinct-2-nopunct": 0.4611241891226685,
        "vocab_size-2-nopunct": 94613,
        "unique-2-nopunct": 74585,
        "entropy-2-nopunct": 14.804724816401643,
        "cond_entropy-2-nopunct": 5.280313550163737,
        "distinct-3-nopunct": 0.7637677892644542,
        "vocab_size-3-nopunct": 149089,
        "unique-3-nopunct": 134465,
        "entropy-3-nopunct": 16.65831176165555,
        "cond_entropy-3-nopunct": 1.8953265150474217,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_validation.json",
        "rouge1": {
            "precision": 0.30385,
            "recall": 0.27769,
            "fmeasure": 0.27968
        },
        "rouge2": {
            "precision": 0.10708,
            "recall": 0.09925,
            "fmeasure": 0.09929
        },
        "rougeL": {
            "precision": 0.23783,
            "recall": 0.21896,
            "fmeasure": 0.21978
        },
        "rougeLsum": {
            "precision": 0.23783,
            "recall": 0.21896,
            "fmeasure": 0.21978
        },
        "local_recall": {
            "1": 0.25521943341357334
        },
        "nist": 2.5854633700785437,
        "bleu": 6.9576,
        "bleurt": -0.53988,
        "nubia": {
            "semantic_relation": 1.59854,
            "contradiction": 30.42164,
            "irrelevancy": 58.09689,
            "logical_agreement": 11.48146,
            "grammar_ref": 5.2776,
            "grammar_hyp": 5.43248,
            "nubia_score": 0.16755
        },
        "meteor": 0.18854248808821533,
        "bertscore": {
            "precision": 0.83351,
            "recall": 0.83258,
            "f1": 0.83285
        }
    },
    "wiki_auto_asset_turk_validation": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_validation",
        "N": 20000,
        "msttr-100": 0.26072,
        "msttr-100_nopunct": 0.24511,
        "total_length": 396340,
        "mean_pred_length": 19.817,
        "std_pred_length": 9.39082057117481,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 98,
        "distinct-1": 0.021592572034112127,
        "vocab_size-1": 8558,
        "unique-1": 0,
        "entropy-1": 9.697481439206836,
        "distinct-2": 0.06917680820534623,
        "vocab_size-2": 26034,
        "unique-2": 0,
        "entropy-2": 13.883357261388127,
        "cond_entropy-2": 3.8936887961959137,
        "distinct-3": 0.09010214963237358,
        "vocab_size-3": 32107,
        "unique-3": 0,
        "entropy-3": 14.757579887328918,
        "cond_entropy-3": 0.8967050398196922,
        "total_length-nopunct": 349020,
        "mean_pred_length-nopunct": 17.451,
        "std_pred_length-nopunct": 8.281038521828044,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 93,
        "distinct-1-nopunct": 0.02447710732909289,
        "vocab_size-1-nopunct": 8543,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 10.143684885972593,
        "distinct-2-nopunct": 0.07232994954713999,
        "vocab_size-2-nopunct": 23798,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 13.857868521669479,
        "cond_entropy-2-nopunct": 3.8933443921375273,
        "distinct-3-nopunct": 0.09198757361983043,
        "vocab_size-3-nopunct": 28426,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 14.669039302987583,
        "cond_entropy-3-nopunct": 0.861675873818633,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_validation.json",
        "rouge1": {
            "precision": 0.73025,
            "recall": 0.73434,
            "fmeasure": 0.71416
        },
        "rouge2": {
            "precision": 0.54181,
            "recall": 0.54347,
            "fmeasure": 0.52838
        },
        "rougeL": {
            "precision": 0.68451,
            "recall": 0.68806,
            "fmeasure": 0.66946
        },
        "rougeLsum": {
            "precision": 0.68451,
            "recall": 0.68806,
            "fmeasure": 0.66946
        },
        "local_recall": {
            "1": 0.7216939316918709
        },
        "nist": 9.603692753774022,
        "bleu": 45.52261,
        "sari": 47.40182,
        "bleurt": 0.28012,
        "nubia": {
            "semantic_relation": 4.32206,
            "contradiction": 2.9509,
            "irrelevancy": 25.95603,
            "logical_agreement": 71.09307,
            "grammar_ref": 4.53224,
            "grammar_hyp": 4.72778,
            "nubia_score": 0.69492
        },
        "meteor": 0.3943990533848956,
        "bertscore": {
            "precision": 0.92068,
            "recall": 0.92301,
            "f1": 0.92094
        }
    },
    "wiki_auto_asset_turk_test_asset": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72264,
        "msttr-100_nopunct": 0.76841,
        "total_length": 7213,
        "mean_pred_length": 20.091922005571032,
        "std_pred_length": 9.49445910452566,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.3666990156661583,
        "vocab_size-1": 2645,
        "unique-1": 1952,
        "entropy-1": 9.126331215578004,
        "distinct-2": 0.8262328567259994,
        "vocab_size-2": 5663,
        "unique-2": 5225,
        "entropy-2": 12.115099856400926,
        "cond_entropy-2": 2.7291720972784907,
        "distinct-3": 0.9575057736720555,
        "vocab_size-3": 6219,
        "unique-3": 6091,
        "entropy-3": 12.51846472638313,
        "cond_entropy-3": 0.42154667407596275,
        "total_length-nopunct": 6370,
        "mean_pred_length-nopunct": 17.74373259052925,
        "std_pred_length-nopunct": 8.28470137515936,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.41334379905808477,
        "vocab_size-1-nopunct": 2633,
        "unique-1-nopunct": 1949,
        "entropy-1-nopunct": 9.490784012020617,
        "distinct-2-nopunct": 0.8481117950424222,
        "vocab_size-2-nopunct": 5098,
        "unique-2-nopunct": 4740,
        "entropy-2-nopunct": 12.022647785553223,
        "cond_entropy-2-nopunct": 2.672958492128687,
        "distinct-3-nopunct": 0.97310686482661,
        "vocab_size-3-nopunct": 5500,
        "unique-3-nopunct": 5399,
        "entropy-3-nopunct": 12.396973766549186,
        "cond_entropy-3-nopunct": 0.40135611026316653,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.88638,
            "recall": 0.86124,
            "fmeasure": 0.86462
        },
        "rouge2": {
            "precision": 0.78287,
            "recall": 0.76144,
            "fmeasure": 0.76029
        },
        "rougeL": {
            "precision": 0.86875,
            "recall": 0.8461,
            "fmeasure": 0.84782
        },
        "rougeLsum": {
            "precision": 0.86875,
            "recall": 0.8461,
            "fmeasure": 0.84782
        },
        "local_recall": {
            "1": 0.03031973539140022,
            "2": 0.15566037735849056,
            "3": 0.336144578313253,
            "4": 0.555045871559633,
            "5": 0.6722306525037937,
            "6": 0.7492957746478873,
            "7": 0.8292349726775956,
            "8": 0.8576598311218335,
            "9": 0.9026455026455027,
            "10": 0.9441860465116279
        },
        "nist": 13.071812397108598,
        "bleu": 84.31801,
        "sari": 46.8846,
        "bleurt": 0.21901,
        "nubia": {
            "semantic_relation": 4.20837,
            "contradiction": 3.35002,
            "irrelevancy": 31.71486,
            "logical_agreement": 64.93513,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.775,
            "nubia_score": 0.6471
        },
        "meteor": 0.5239953121659693,
        "bertscore": {
            "precision": 0.96702,
            "recall": 0.96512,
            "f1": 0.9629
        }
    },
    "wiki_auto_asset_turk_test_turk": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.72435,
        "msttr-100_nopunct": 0.76541,
        "total_length": 6957,
        "mean_pred_length": 19.37883008356546,
        "std_pred_length": 9.592894176785535,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.35518183124910163,
        "vocab_size-1": 2471,
        "unique-1": 1802,
        "entropy-1": 9.05504691719738,
        "distinct-2": 0.8243407093058502,
        "vocab_size-2": 5439,
        "unique-2": 5002,
        "entropy-2": 12.060159685285985,
        "cond_entropy-2": 2.735285609845925,
        "distinct-3": 0.9541593204039109,
        "vocab_size-3": 5953,
        "unique-3": 5824,
        "entropy-3": 12.443872967783085,
        "cond_entropy-3": 0.4019231058393918,
        "total_length-nopunct": 6171,
        "mean_pred_length-nopunct": 17.18941504178273,
        "std_pred_length-nopunct": 8.415584392103106,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.3986387943607195,
        "vocab_size-1-nopunct": 2460,
        "unique-1-nopunct": 1800,
        "entropy-1-nopunct": 9.4005582577569,
        "distinct-2-nopunct": 0.8470406056434963,
        "vocab_size-2-nopunct": 4923,
        "unique-2-nopunct": 4562,
        "entropy-2-nopunct": 11.977220121622265,
        "cond_entropy-2-nopunct": 2.7196221359150345,
        "distinct-3-nopunct": 0.9719420502475702,
        "vocab_size-3-nopunct": 5300,
        "unique-3-nopunct": 5199,
        "entropy-3-nopunct": 12.342783592540554,
        "cond_entropy-3-nopunct": 0.39303752247397783,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.84006,
            "recall": 0.75493,
            "fmeasure": 0.77952
        },
        "rouge2": {
            "precision": 0.6877,
            "recall": 0.61926,
            "fmeasure": 0.63642
        },
        "rougeL": {
            "precision": 0.81097,
            "recall": 0.72754,
            "fmeasure": 0.75098
        },
        "rougeLsum": {
            "precision": 0.81097,
            "recall": 0.72754,
            "fmeasure": 0.75098
        },
        "local_recall": {
            "1": 0.04690152801358234,
            "2": 0.15197956577266922,
            "3": 0.3610503282275711,
            "4": 0.5071315372424723,
            "5": 0.592938733125649,
            "6": 0.7185990338164251,
            "7": 0.8468881252386407
        },
        "nist": 10.679929126928785,
        "bleu": 64.19993,
        "sari": 46.62489,
        "bleurt": 0.15481,
        "nubia": {
            "semantic_relation": 4.17358,
            "contradiction": 4.55557,
            "irrelevancy": 17.94298,
            "logical_agreement": 77.50146,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.94561,
            "nubia_score": 0.65904
        },
        "meteor": 0.43673495570659426,
        "bertscore": {
            "precision": 0.9506,
            "recall": 0.93397,
            "f1": 0.93935
        }
    },
    "wiki_auto_asset_turk_challenge_train_sample": {
        "predictions_file": "T5-large (Baseline)/wiki_auto_asset_turk_challenge_train_sample",
        "N": 500
    },
    "mlsum_es_test": {
        "predictions_file": "T5-large (Baseline)/mlsum_es_test",
        "N": 13366,
        "msttr-100": 0.67998,
        "msttr-100_nopunct": 0.6841,
        "total_length": 299363,
        "mean_pred_length": 22.397351488852312,
        "std_pred_length": 6.583415802401971,
        "median_pred_length": 21.0,
        "min_pred_length": 8,
        "max_pred_length": 73,
        "distinct-1": 0.09529233739640504,
        "vocab_size-1": 28527,
        "unique-1": 15501,
        "entropy-1": 9.682002501660115,
        "distinct-2": 0.41965125508309525,
        "vocab_size-2": 120019,
        "unique-2": 92333,
        "entropy-2": 14.947106687000153,
        "cond_entropy-2": 5.455189293606069,
        "distinct-3": 0.7312998155015387,
        "vocab_size-3": 199375,
        "unique-3": 177394,
        "entropy-3": 16.977336759561787,
        "cond_entropy-3": 2.075091917195012,
        "total_length-nopunct": 287982,
        "mean_pred_length-nopunct": 21.545862636540477,
        "std_pred_length-nopunct": 6.115486569695329,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 65,
        "distinct-1-nopunct": 0.09900271544749324,
        "vocab_size-1-nopunct": 28511,
        "unique-1-nopunct": 15500,
        "entropy-1-nopunct": 9.759159568985957,
        "distinct-2-nopunct": 0.432640487080141,
        "vocab_size-2-nopunct": 118810,
        "unique-2-nopunct": 92466,
        "entropy-2-nopunct": 14.978321289376517,
        "cond_entropy-2-nopunct": 5.419266804455665,
        "distinct-3-nopunct": 0.7418526315789473,
        "vocab_size-3-nopunct": 193809,
        "unique-3-nopunct": 173502,
        "entropy-3-nopunct": 16.958574532464418,
        "cond_entropy-3-nopunct": 2.02240554996083,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_test.json",
        "rouge1": {
            "precision": 0.30384,
            "recall": 0.2763,
            "fmeasure": 0.27893
        },
        "rouge2": {
            "precision": 0.10557,
            "recall": 0.09643,
            "fmeasure": 0.09716
        },
        "rougeL": {
            "precision": 0.2376,
            "recall": 0.21755,
            "fmeasure": 0.21892
        },
        "rougeLsum": {
            "precision": 0.2376,
            "recall": 0.21755,
            "fmeasure": 0.21892
        },
        "local_recall": {
            "1": 0.25153606058086897
        },
        "nist": 2.5792223732752255,
        "bleu": 6.54353,
        "bleurt": -0.54741,
        "nubia": {
            "semantic_relation": 1.58005,
            "contradiction": 30.79089,
            "irrelevancy": 58.03962,
            "logical_agreement": 11.1695,
            "grammar_ref": 5.26998,
            "grammar_hyp": 5.44009,
            "nubia_score": 0.16485
        },
        "meteor": 0.18626413429187458,
        "bertscore": {
            "precision": 0.8335,
            "recall": 0.83199,
            "f1": 0.83254
        }
    },
    "mlsum_es_challenge_train_sample": {
        "predictions_file": "T5-large (Baseline)/mlsum_es_challenge_train_sample",
        "N": 500
    },
    "mlsum_es_challenge_validation_sample": {
        "predictions_file": "T5-large (Baseline)/mlsum_es_challenge_validation_sample",
        "N": 500
    },
    "mlsum_es_challenge_test_covid": {
        "predictions_file": "T5-large (Baseline)/mlsum_es_challenge_test_covid",
        "N": 1938,
        "msttr-100": 0.67061,
        "msttr-100_nopunct": 0.67078,
        "total_length": 42314,
        "mean_pred_length": 21.833849329205368,
        "std_pred_length": 6.024909570895105,
        "median_pred_length": 21.0,
        "min_pred_length": 10,
        "max_pred_length": 57,
        "distinct-1": 0.16864394762962612,
        "vocab_size-1": 7136,
        "unique-1": 4335,
        "entropy-1": 8.956314658779403,
        "distinct-2": 0.5295224886070933,
        "vocab_size-2": 21380,
        "unique-2": 17250,
        "entropy-2": 13.158682272082554,
        "cond_entropy-2": 4.355255633341704,
        "distinct-3": 0.7988709089963058,
        "vocab_size-3": 30707,
        "unique-3": 27846,
        "entropy-3": 14.535098675157387,
        "cond_entropy-3": 1.391288697270252,
        "total_length-nopunct": 40960,
        "mean_pred_length-nopunct": 21.135190918472652,
        "std_pred_length-nopunct": 5.647112195657232,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 54,
        "distinct-1-nopunct": 0.17392578125,
        "vocab_size-1-nopunct": 7124,
        "unique-1-nopunct": 4333,
        "entropy-1-nopunct": 8.991101146412129,
        "distinct-2-nopunct": 0.5397980626313361,
        "vocab_size-2-nopunct": 21064,
        "unique-2-nopunct": 17103,
        "entropy-2-nopunct": 13.1563737471998,
        "cond_entropy-2-nopunct": 4.322783546935676,
        "distinct-3-nopunct": 0.8050372128141516,
        "vocab_size-3-nopunct": 29854,
        "unique-3-nopunct": 27180,
        "entropy-3-nopunct": 14.50315417701116,
        "cond_entropy-3-nopunct": 1.3592981803494042,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_challenge_test_covid.json",
        "rouge1": {
            "precision": 0.31727,
            "recall": 0.25972,
            "fmeasure": 0.2755
        },
        "rouge2": {
            "precision": 0.10097,
            "recall": 0.08304,
            "fmeasure": 0.08781
        },
        "rougeL": {
            "precision": 0.24185,
            "recall": 0.19977,
            "fmeasure": 0.21107
        },
        "rougeLsum": {
            "precision": 0.24185,
            "recall": 0.19977,
            "fmeasure": 0.21107
        },
        "local_recall": {
            "1": 0.23699547249783257
        },
        "nist": 2.175856336469782,
        "bleu": 5.19234,
        "bleurt": -0.58056,
        "nubia": {
            "semantic_relation": 1.51627,
            "contradiction": 27.72558,
            "irrelevancy": 62.09148,
            "logical_agreement": 10.18294,
            "grammar_ref": 5.23427,
            "grammar_hyp": 5.46707,
            "nubia_score": 0.15405
        },
        "meteor": 0.1790473587690474,
        "bertscore": {
            "precision": 0.83577,
            "recall": 0.82953,
            "f1": 0.83246
        }
    },
    "wiki_lingua_spanish_es_validation": {
        "predictions_file": "T5-large (Baseline)/wiki_lingua_spanish_es_validation",
        "N": 11316,
        "msttr-100": 0.5154,
        "msttr-100_nopunct": 0.58268,
        "total_length": 346069,
        "mean_pred_length": 30.58227288794627,
        "std_pred_length": 16.498236256358936,
        "median_pred_length": 27.0,
        "min_pred_length": 3,
        "max_pred_length": 147,
        "distinct-1": 0.03436886863602345,
        "vocab_size-1": 11894,
        "unique-1": 4284,
        "entropy-1": 8.468458595723675,
        "distinct-2": 0.2044134033152802,
        "vocab_size-2": 68428,
        "unique-2": 41534,
        "entropy-2": 13.521608004657047,
        "cond_entropy-2": 4.8657705356735335,
        "distinct-3": 0.4916011464365549,
        "vocab_size-3": 159002,
        "unique-3": 121514,
        "entropy-3": 16.057921912980245,
        "cond_entropy-3": 2.555534631377694,
        "total_length-nopunct": 290247,
        "mean_pred_length-nopunct": 25.649257688229056,
        "std_pred_length-nopunct": 14.461663292145145,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 123,
        "distinct-1-nopunct": 0.04090998356572161,
        "vocab_size-1-nopunct": 11874,
        "unique-1-nopunct": 4281,
        "entropy-1-nopunct": 9.292176035172078,
        "distinct-2-nopunct": 0.31571607315070754,
        "vocab_size-2-nopunct": 88063,
        "unique-2-nopunct": 61213,
        "entropy-2-nopunct": 14.240363670956002,
        "cond_entropy-2-nopunct": 5.088391322240219,
        "distinct-3-nopunct": 0.6221923285316593,
        "vocab_size-3-nopunct": 166508,
        "unique-3-nopunct": 137477,
        "entropy-3-nopunct": 16.552195255589602,
        "cond_entropy-3-nopunct": 2.3730259296041973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_validation.json",
        "rouge1": {
            "precision": 0.43124,
            "recall": 0.33899,
            "fmeasure": 0.3575
        },
        "rouge2": {
            "precision": 0.15866,
            "recall": 0.12621,
            "fmeasure": 0.13247
        },
        "rougeL": {
            "precision": 0.35291,
            "recall": 0.28031,
            "fmeasure": 0.29385
        },
        "rougeLsum": {
            "precision": 0.35291,
            "recall": 0.28031,
            "fmeasure": 0.29385
        },
        "local_recall": {
            "1": 0.2882791681451641
        },
        "nist": 3.6648752304918615,
        "bleu": 10.4281,
        "sari": 68.08088,
        "bleurt": -0.38429,
        "nubia": {
            "semantic_relation": 2.84723,
            "contradiction": 17.91559,
            "irrelevancy": 38.50637,
            "logical_agreement": 43.57804,
            "grammar_ref": 3.95671,
            "grammar_hyp": 3.64652,
            "nubia_score": 0.38776
        },
        "meteor": 0.16214319555976722,
        "bertscore": {
            "precision": 0.86,
            "recall": 0.83203,
            "f1": 0.8452
        }
    },
    "wiki_lingua_spanish_es_test": {
        "predictions_file": "T5-large (Baseline)/wiki_lingua_spanish_es_test",
        "N": 22632,
        "msttr-100": 0.51454,
        "msttr-100_nopunct": 0.58263,
        "total_length": 685713,
        "mean_pred_length": 30.29838282078473,
        "std_pred_length": 16.30019238188939,
        "median_pred_length": 27.0,
        "min_pred_length": 4,
        "max_pred_length": 139,
        "distinct-1": 0.023404835550733326,
        "vocab_size-1": 16049,
        "unique-1": 5596,
        "entropy-1": 8.506216989685626,
        "distinct-2": 0.16172081540565933,
        "vocab_size-2": 107234,
        "unique-2": 63008,
        "entropy-2": 13.737312738209994,
        "cond_entropy-2": 5.040870135630532,
        "distinct-3": 0.4288834864290521,
        "vocab_size-3": 274678,
        "unique-3": 202345,
        "entropy-3": 16.55998673291388,
        "cond_entropy-3": 2.840125845099876,
        "total_length-nopunct": 575185,
        "mean_pred_length-nopunct": 25.414678331565923,
        "std_pred_length-nopunct": 14.343543538647012,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 121,
        "distinct-1-nopunct": 0.02786407851386945,
        "vocab_size-1-nopunct": 16027,
        "unique-1-nopunct": 5594,
        "entropy-1-nopunct": 9.335797168920697,
        "distinct-2-nopunct": 0.2632869607078416,
        "vocab_size-2-nopunct": 145480,
        "unique-2-nopunct": 97386,
        "entropy-2-nopunct": 14.557525560409717,
        "cond_entropy-2-nopunct": 5.365938550148122,
        "distinct-3-nopunct": 0.564308642231578,
        "vocab_size-3-nopunct": 299039,
        "unique-3-nopunct": 239888,
        "entropy-3-nopunct": 17.19084990284557,
        "cond_entropy-3-nopunct": 2.6992028599255327,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_test.json",
        "rouge1": {
            "precision": 0.4305,
            "recall": 0.33464,
            "fmeasure": 0.35398
        },
        "rouge2": {
            "precision": 0.15672,
            "recall": 0.12314,
            "fmeasure": 0.12973
        },
        "rougeL": {
            "precision": 0.35145,
            "recall": 0.27609,
            "fmeasure": 0.29034
        },
        "rougeLsum": {
            "precision": 0.35145,
            "recall": 0.27609,
            "fmeasure": 0.29034
        },
        "local_recall": {
            "1": 0.2823995521444196
        },
        "nist": 3.531988360057073,
        "bleu": 9.99765,
        "sari": 68.00576,
        "bleurt": -0.39748,
        "nubia": {
            "semantic_relation": 2.8376,
            "contradiction": 18.32286,
            "irrelevancy": 38.24931,
            "logical_agreement": 43.42782,
            "grammar_ref": 3.9494,
            "grammar_hyp": 3.65144,
            "nubia_score": 0.3842
        },
        "meteor": 0.1584151029856265,
        "bertscore": {
            "precision": 0.85932,
            "recall": 0.8299,
            "f1": 0.84378
        }
    },
    "wiki_lingua_turkish_tr_validation": {
        "predictions_file": "T5-large (Baseline)/wiki_lingua_turkish_tr_validation",
        "N": 449,
        "msttr-100": 0.54827,
        "msttr-100_nopunct": 0.61562,
        "total_length": 19181,
        "mean_pred_length": 42.71937639198218,
        "std_pred_length": 18.68688435312716,
        "median_pred_length": 40.0,
        "min_pred_length": 5,
        "max_pred_length": 109,
        "distinct-1": 0.08873364266722278,
        "vocab_size-1": 1702,
        "unique-1": 718,
        "entropy-1": 7.57859602500001,
        "distinct-2": 0.28293828742259236,
        "vocab_size-2": 5300,
        "unique-2": 3197,
        "entropy-2": 10.885554637566807,
        "cond_entropy-2": 3.194474336597492,
        "distinct-3": 0.43488486572225565,
        "vocab_size-3": 7951,
        "unique-3": 5650,
        "entropy-3": 11.986800678435984,
        "cond_entropy-3": 1.120375102969562,
        "total_length-nopunct": 16074,
        "mean_pred_length-nopunct": 35.799554565701555,
        "std_pred_length-nopunct": 16.291331532376415,
        "median_pred_length-nopunct": 33.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 96,
        "distinct-1-nopunct": 0.10520094562647754,
        "vocab_size-1-nopunct": 1691,
        "unique-1-nopunct": 717,
        "entropy-1-nopunct": 8.153987791017043,
        "distinct-2-nopunct": 0.342528,
        "vocab_size-2-nopunct": 5352,
        "unique-2-nopunct": 3470,
        "entropy-2-nopunct": 11.139885140015846,
        "cond_entropy-2-nopunct": 3.0565557728243626,
        "distinct-3-nopunct": 0.49848444913020556,
        "vocab_size-3-nopunct": 7565,
        "unique-3-nopunct": 5709,
        "entropy-3-nopunct": 12.01984324148866,
        "cond_entropy-3-nopunct": 0.9020378294432921,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_validation.json",
        "rouge1": {
            "precision": 0.23562,
            "recall": 0.2289,
            "fmeasure": 0.21263
        },
        "rouge2": {
            "precision": 0.08186,
            "recall": 0.07382,
            "fmeasure": 0.07171
        },
        "rougeL": {
            "precision": 0.19627,
            "recall": 0.19017,
            "fmeasure": 0.17649
        },
        "rougeLsum": {
            "precision": 0.19627,
            "recall": 0.19017,
            "fmeasure": 0.17649
        },
        "local_recall": {
            "1": 0.21347402597402598
        },
        "nist": 2.0298085062739135,
        "bleu": 8.50253,
        "sari": 64.79693,
        "bleurt": -0.91366,
        "nubia": {
            "semantic_relation": 2.04571,
            "contradiction": 30.09595,
            "irrelevancy": 48.24484,
            "logical_agreement": 21.6592,
            "grammar_ref": 3.85457,
            "grammar_hyp": 3.6099,
            "nubia_score": 0.22491
        },
        "meteor": 0.11113077444785768,
        "bertscore": {
            "precision": 0.78407,
            "recall": 0.78253,
            "f1": 0.7828
        }
    },
    "wiki_lingua_turkish_tr_test": {
        "predictions_file": "T5-large (Baseline)/wiki_lingua_turkish_tr_test",
        "N": 900,
        "msttr-100": 0.54707,
        "msttr-100_nopunct": 0.60937,
        "total_length": 39675,
        "mean_pred_length": 44.083333333333336,
        "std_pred_length": 20.784255526185625,
        "median_pred_length": 41.0,
        "min_pred_length": 2,
        "max_pred_length": 117,
        "distinct-1": 0.06215500945179584,
        "vocab_size-1": 2466,
        "unique-1": 944,
        "entropy-1": 7.72322723400995,
        "distinct-2": 0.2289103803997421,
        "vocab_size-2": 8876,
        "unique-2": 4880,
        "entropy-2": 11.342064016051676,
        "cond_entropy-2": 3.507346590036334,
        "distinct-3": 0.38442244224422445,
        "vocab_size-3": 14560,
        "unique-3": 9506,
        "entropy-3": 12.683584374825124,
        "cond_entropy-3": 1.3551718197333362,
        "total_length-nopunct": 33266,
        "mean_pred_length-nopunct": 36.96222222222222,
        "std_pred_length-nopunct": 18.135989865321985,
        "median_pred_length-nopunct": 33.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 103,
        "distinct-1-nopunct": 0.07358864907112367,
        "vocab_size-1-nopunct": 2448,
        "unique-1-nopunct": 939,
        "entropy-1-nopunct": 8.318262313031166,
        "distinct-2-nopunct": 0.28724587530124207,
        "vocab_size-2-nopunct": 9297,
        "unique-2-nopunct": 5507,
        "entropy-2-nopunct": 11.693248142150816,
        "cond_entropy-2-nopunct": 3.440774533804062,
        "distinct-3-nopunct": 0.45150320981376724,
        "vocab_size-3-nopunct": 14207,
        "unique-3-nopunct": 9817,
        "entropy-3-nopunct": 12.81908320118469,
        "cond_entropy-3-nopunct": 1.1470083927476613,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_test.json",
        "rouge1": {
            "precision": 0.23817,
            "recall": 0.23988,
            "fmeasure": 0.21825
        },
        "rouge2": {
            "precision": 0.07663,
            "recall": 0.07309,
            "fmeasure": 0.06936
        },
        "rougeL": {
            "precision": 0.19168,
            "recall": 0.19492,
            "fmeasure": 0.17593
        },
        "rougeLsum": {
            "precision": 0.19168,
            "recall": 0.19492,
            "fmeasure": 0.17593
        },
        "local_recall": {
            "1": 0.22127486804709703
        },
        "nist": 2.083871778778125,
        "bleu": 8.24193,
        "sari": 64.60387,
        "bleurt": -0.89043,
        "nubia": {
            "semantic_relation": 2.09292,
            "contradiction": 29.65688,
            "irrelevancy": 48.24424,
            "logical_agreement": 22.09888,
            "grammar_ref": 3.87672,
            "grammar_hyp": 3.58864,
            "nubia_score": 0.22505
        },
        "meteor": 0.11585745122675216,
        "bertscore": {
            "precision": 0.78638,
            "recall": 0.7868,
            "f1": 0.78613
        }
    },
    "wiki_lingua_vietnamese_vi_validation": {
        "predictions_file": "T5-large (Baseline)/wiki_lingua_vietnamese_vi_validation",
        "N": 1957,
        "msttr-100": 0.56256,
        "msttr-100_nopunct": 0.63117,
        "total_length": 74978,
        "mean_pred_length": 38.31272355646398,
        "std_pred_length": 16.911392712199856,
        "median_pred_length": 35.0,
        "min_pred_length": 4,
        "max_pred_length": 120,
        "distinct-1": 0.05057483528501694,
        "vocab_size-1": 3792,
        "unique-1": 1530,
        "entropy-1": 7.863925523192801,
        "distinct-2": 0.1950397830761014,
        "vocab_size-2": 14242,
        "unique-2": 8588,
        "entropy-2": 11.413397085016785,
        "cond_entropy-2": 3.414259182438984,
        "distinct-3": 0.33642913430147475,
        "vocab_size-3": 23908,
        "unique-3": 17631,
        "entropy-3": 12.553440391301631,
        "cond_entropy-3": 1.154629580017942,
        "total_length-nopunct": 62594,
        "mean_pred_length-nopunct": 31.984670413898826,
        "std_pred_length-nopunct": 14.765091966630074,
        "median_pred_length-nopunct": 30.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 109,
        "distinct-1-nopunct": 0.06037319870914145,
        "vocab_size-1-nopunct": 3779,
        "unique-1-nopunct": 1527,
        "entropy-1-nopunct": 8.53347828436823,
        "distinct-2-nopunct": 0.25072150667084453,
        "vocab_size-2-nopunct": 15203,
        "unique-2-nopunct": 10102,
        "entropy-2-nopunct": 11.632811031348337,
        "cond_entropy-2-nopunct": 3.178779473221429,
        "distinct-3-nopunct": 0.3959441036128153,
        "vocab_size-3-nopunct": 23234,
        "unique-3-nopunct": 18171,
        "entropy-3-nopunct": 12.61051796958906,
        "cond_entropy-3-nopunct": 0.999608383144568,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_validation.json",
        "rouge1": {
            "precision": 0.19653,
            "recall": 0.19204,
            "fmeasure": 0.1787
        },
        "rouge2": {
            "precision": 0.03921,
            "recall": 0.03788,
            "fmeasure": 0.03572
        },
        "rougeL": {
            "precision": 0.15202,
            "recall": 0.1503,
            "fmeasure": 0.13873
        },
        "rougeLsum": {
            "precision": 0.15202,
            "recall": 0.1503,
            "fmeasure": 0.13873
        },
        "local_recall": {
            "1": 0.1699421490994133
        },
        "nist": 1.741543611912958,
        "bleu": 4.46245,
        "sari": 63.75569,
        "bleurt": -0.87915,
        "nubia": {
            "semantic_relation": 1.70536,
            "contradiction": 28.93208,
            "irrelevancy": 51.55357,
            "logical_agreement": 19.51435,
            "grammar_ref": 3.90718,
            "grammar_hyp": 3.59824,
            "nubia_score": 0.18315
        },
        "meteor": 0.09716983232404901,
        "bertscore": {
            "precision": 0.7808,
            "recall": 0.77575,
            "f1": 0.77785
        }
    },
    "wiki_lingua_vietnamese_vi_test": {
        "predictions_file": "T5-large (Baseline)/wiki_lingua_vietnamese_vi_test",
        "N": 3917,
        "msttr-100": 0.55951,
        "msttr-100_nopunct": 0.62801,
        "total_length": 150548,
        "mean_pred_length": 38.43451621138627,
        "std_pred_length": 16.75368152461088,
        "median_pred_length": 35.0,
        "min_pred_length": 4,
        "max_pred_length": 127,
        "distinct-1": 0.034580333182772274,
        "vocab_size-1": 5206,
        "unique-1": 1835,
        "entropy-1": 7.924256862286696,
        "distinct-2": 0.15378739829913182,
        "vocab_size-2": 22550,
        "unique-2": 12639,
        "entropy-2": 11.661051815701768,
        "cond_entropy-2": 3.6013424549047808,
        "distinct-3": 0.2905461272194739,
        "vocab_size-3": 41465,
        "unique-3": 28991,
        "entropy-3": 12.987778791410118,
        "cond_entropy-3": 1.3401627111969496,
        "total_length-nopunct": 125646,
        "mean_pred_length-nopunct": 32.0770998212918,
        "std_pred_length-nopunct": 14.713524419075469,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 115,
        "distinct-1-nopunct": 0.041290610126864365,
        "vocab_size-1-nopunct": 5188,
        "unique-1-nopunct": 1833,
        "entropy-1-nopunct": 8.606065122168241,
        "distinct-2-nopunct": 0.20612179513509518,
        "vocab_size-2-nopunct": 25091,
        "unique-2-nopunct": 15682,
        "entropy-2-nopunct": 11.96131329571033,
        "cond_entropy-2-nopunct": 3.4363122095480114,
        "distinct-3-nopunct": 0.3530115777679693,
        "vocab_size-3-nopunct": 41589,
        "unique-3-nopunct": 31065,
        "entropy-3-nopunct": 13.127306268479973,
        "cond_entropy-3-nopunct": 1.1901502126932735,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_test.json",
        "rouge1": {
            "precision": 0.20042,
            "recall": 0.19872,
            "fmeasure": 0.18403
        },
        "rouge2": {
            "precision": 0.04317,
            "recall": 0.04234,
            "fmeasure": 0.03974
        },
        "rougeL": {
            "precision": 0.15634,
            "recall": 0.15683,
            "fmeasure": 0.14395
        },
        "rougeLsum": {
            "precision": 0.15634,
            "recall": 0.15683,
            "fmeasure": 0.14395
        },
        "local_recall": {
            "1": 0.1780336673597977
        },
        "nist": 1.8422666231266616,
        "bleu": 4.87527,
        "sari": 63.49133,
        "bleurt": -0.88172,
        "nubia": {
            "semantic_relation": 1.7456,
            "contradiction": 28.12036,
            "irrelevancy": 51.53396,
            "logical_agreement": 20.34568,
            "grammar_ref": 3.92068,
            "grammar_hyp": 3.58959,
            "nubia_score": 0.19231
        },
        "meteor": 0.10084186430878848,
        "bertscore": {
            "precision": 0.78288,
            "recall": 0.7785,
            "f1": 0.78026
        }
    },
    "wiki_lingua_russian_ru_validation": {
        "predictions_file": "T5-large (Baseline)/wiki_lingua_russian_ru_validation",
        "N": 5288,
        "msttr-100": 0.38261,
        "msttr-100_nopunct": 0.42946,
        "total_length": 156958,
        "mean_pred_length": 29.681921331316186,
        "std_pred_length": 24.43868718045734,
        "median_pred_length": 22.0,
        "min_pred_length": 3,
        "max_pred_length": 128,
        "distinct-1": 0.03416200512238943,
        "vocab_size-1": 5362,
        "unique-1": 1564,
        "entropy-1": 7.944291965010042,
        "distinct-2": 0.15324058811894245,
        "vocab_size-2": 23242,
        "unique-2": 11236,
        "entropy-2": 12.16318418659614,
        "cond_entropy-2": 4.042897738954522,
        "distinct-3": 0.3300815674058286,
        "vocab_size-3": 48318,
        "unique-3": 30714,
        "entropy-3": 14.075546908948366,
        "cond_entropy-3": 1.9505032695241722,
        "total_length-nopunct": 131229,
        "mean_pred_length-nopunct": 24.816376701966718,
        "std_pred_length-nopunct": 20.92667255897655,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 117,
        "distinct-1-nopunct": 0.04072270610916794,
        "vocab_size-1-nopunct": 5344,
        "unique-1-nopunct": 1561,
        "entropy-1-nopunct": 8.694653721140428,
        "distinct-2-nopunct": 0.2251371674037843,
        "vocab_size-2-nopunct": 28354,
        "unique-2-nopunct": 16419,
        "entropy-2-nopunct": 12.676095298306262,
        "cond_entropy-2-nopunct": 4.124818215905414,
        "distinct-3-nopunct": 0.41973262165051844,
        "vocab_size-3-nopunct": 50642,
        "unique-3-nopunct": 35563,
        "entropy-3-nopunct": 14.492765742667693,
        "cond_entropy-3-nopunct": 1.8829647511627097,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_validation.json",
        "rouge1": {
            "precision": 0.31052,
            "recall": 0.21074,
            "fmeasure": 0.22665
        },
        "rouge2": {
            "precision": 0.07888,
            "recall": 0.05398,
            "fmeasure": 0.05766
        },
        "rougeL": {
            "precision": 0.25522,
            "recall": 0.17529,
            "fmeasure": 0.18703
        },
        "rougeLsum": {
            "precision": 0.25522,
            "recall": 0.17529,
            "fmeasure": 0.18703
        },
        "local_recall": {
            "1": 0.16916253161552555
        },
        "nist": 1.868979798633358,
        "bleu": 4.65279,
        "sari": 66.75546,
        "bleurt": -0.62458,
        "nubia": {
            "semantic_relation": 2.42015,
            "contradiction": 21.88114,
            "irrelevancy": 43.81503,
            "logical_agreement": 34.30384,
            "grammar_ref": 3.95099,
            "grammar_hyp": 3.24206,
            "nubia_score": 0.33545
        },
        "meteor": 0.10142283003182882,
        "bertscore": {
            "precision": 0.82638,
            "recall": 0.78942,
            "f1": 0.80682
        }
    },
    "wiki_lingua_russian_ru_test": {
        "predictions_file": "T5-large (Baseline)/wiki_lingua_russian_ru_test",
        "N": 10580,
        "msttr-100": 0.40068,
        "msttr-100_nopunct": 0.44987,
        "total_length": 364480,
        "mean_pred_length": 34.449905482041586,
        "std_pred_length": 25.284633830264873,
        "median_pred_length": 26.0,
        "min_pred_length": 4,
        "max_pred_length": 129,
        "distinct-1": 0.021704894644424932,
        "vocab_size-1": 7911,
        "unique-1": 2300,
        "entropy-1": 7.996296198936956,
        "distinct-2": 0.11384006781576717,
        "vocab_size-2": 40288,
        "unique-2": 19327,
        "entropy-2": 12.444370101456963,
        "cond_entropy-2": 4.296849094714974,
        "distinct-3": 0.2819264825818478,
        "vocab_size-3": 96791,
        "unique-3": 60653,
        "entropy-3": 14.677176977860878,
        "cond_entropy-3": 2.2625813379305053,
        "total_length-nopunct": 304102,
        "mean_pred_length-nopunct": 28.743100189035918,
        "std_pred_length-nopunct": 21.738103772091513,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 119,
        "distinct-1-nopunct": 0.025955107167989686,
        "vocab_size-1-nopunct": 7893,
        "unique-1-nopunct": 2298,
        "entropy-1-nopunct": 8.770054892447096,
        "distinct-2-nopunct": 0.18240200053147634,
        "vocab_size-2-nopunct": 53539,
        "unique-2-nopunct": 30768,
        "entropy-2-nopunct": 13.099879314189007,
        "cond_entropy-2-nopunct": 4.451736711527468,
        "distinct-3-nopunct": 0.37975627513766075,
        "vocab_size-3-nopunct": 107449,
        "unique-3-nopunct": 74616,
        "entropy-3-nopunct": 15.276402712193098,
        "cond_entropy-3-nopunct": 2.2331350936103926,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_test.json",
        "rouge1": {
            "precision": 0.30904,
            "recall": 0.24318,
            "fmeasure": 0.24818
        },
        "rouge2": {
            "precision": 0.08492,
            "recall": 0.06815,
            "fmeasure": 0.06904
        },
        "rougeL": {
            "precision": 0.25186,
            "recall": 0.2014,
            "fmeasure": 0.20346
        },
        "rougeLsum": {
            "precision": 0.25186,
            "recall": 0.2014,
            "fmeasure": 0.20346
        },
        "local_recall": {
            "1": 0.19435082530794232
        },
        "nist": 2.5139513093622528,
        "bleu": 6.1058,
        "sari": 67.16289,
        "bleurt": -0.58838,
        "nubia": {
            "semantic_relation": 2.43361,
            "contradiction": 26.41649,
            "irrelevancy": 38.61887,
            "logical_agreement": 34.96464,
            "grammar_ref": 3.95647,
            "grammar_hyp": 3.14203,
            "nubia_score": 0.3175
        },
        "meteor": 0.11432582841230908,
        "bertscore": {
            "precision": 0.82715,
            "recall": 0.79679,
            "f1": 0.81104
        }
    },
    "dart_validation": {
        "predictions_file": "T5-large (Baseline)/dart_validation",
        "N": 2768,
        "msttr-100": 0.46623,
        "msttr-100_nopunct": 0.47544,
        "total_length": 61552,
        "mean_pred_length": 22.23699421965318,
        "std_pred_length": 9.394041967720609,
        "median_pred_length": 22.0,
        "min_pred_length": 4,
        "max_pred_length": 64,
        "distinct-1": 0.05923446841694827,
        "vocab_size-1": 3646,
        "unique-1": 1598,
        "entropy-1": 7.776905310079115,
        "distinct-2": 0.20859417528579205,
        "vocab_size-2": 12262,
        "unique-2": 7587,
        "entropy-2": 10.879673404373005,
        "cond_entropy-2": 2.924938636547747,
        "distinct-3": 0.3417594972864896,
        "vocab_size-3": 19144,
        "unique-3": 13697,
        "entropy-3": 12.265868848154204,
        "cond_entropy-3": 1.429348874207655,
        "total_length-nopunct": 55379,
        "mean_pred_length-nopunct": 20.006864161849713,
        "std_pred_length-nopunct": 8.567668202750095,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 58,
        "distinct-1-nopunct": 0.06551219776449557,
        "vocab_size-1-nopunct": 3628,
        "unique-1-nopunct": 1592,
        "entropy-1-nopunct": 7.98380230060772,
        "distinct-2-nopunct": 0.21552527038071886,
        "vocab_size-2-nopunct": 11339,
        "unique-2-nopunct": 7160,
        "entropy-2-nopunct": 10.767949016247075,
        "cond_entropy-2-nopunct": 2.9044025125929704,
        "distinct-3-nopunct": 0.34596633428966955,
        "vocab_size-3-nopunct": 17244,
        "unique-3-nopunct": 12379,
        "entropy-3-nopunct": 12.158100569959714,
        "cond_entropy-3-nopunct": 1.4312009138478525,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/dart_validation.json",
        "rouge1": {
            "precision": 0.03911,
            "recall": 0.73692,
            "fmeasure": 0.07349
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.03911,
            "recall": 0.73692,
            "fmeasure": 0.07349
        },
        "rougeLsum": {
            "precision": 0.03911,
            "recall": 0.73692,
            "fmeasure": 0.07349
        },
        "local_recall": {
            "1": 0.030163693213169026,
            "2": 0.0172292897926475,
            "3": 0.014002828854314003,
            "4": 0.02766506824050166,
            "5": 0.0448283402580363,
            "6": 0.05875892366831411,
            "7": 0.07919463087248323,
            "8": 0.09274193548387097,
            "9": 0.09864712514092447,
            "10": 0.11086637298091043,
            "11": 0.10647639956092206,
            "12": 0.11700468018720749,
            "13": 0.087527352297593,
            "14": 0.06956521739130435,
            "15": 0.08490566037735849,
            "16": 0.125,
            "17": 0.038461538461538464,
            "18": 0.04,
            "19": 0.10416666666666667,
            "20": 0.11764705882352941,
            "21": 0.08695652173913043,
            "22": 0.0,
            "23": 0.06666666666666667,
            "24": 0.1,
            "25": 0.3333333333333333,
            "26": 0.25,
            "27": 0,
            "28": 0.0,
            "29": 0.0,
            "30": 0.0,
            "31": 0.0,
            "32": 0,
            "33": 0,
            "34": 0,
            "35": 0,
            "36": 0,
            "37": 0.0,
            "38": 0,
            "39": 0,
            "40": 0,
            "41": 0,
            "42": 0,
            "43": 0,
            "44": 0,
            "45": 0,
            "46": 0,
            "47": 0,
            "48": 0,
            "49": 0,
            "50": 0,
            "51": 0,
            "52": 0,
            "53": 0,
            "54": 0,
            "55": 0,
            "56": 0,
            "57": 0,
            "58": 0,
            "59": 0,
            "60": 0,
            "61": 0,
            "62": 0,
            "63": 0,
            "64": 0,
            "65": 0,
            "66": 0,
            "67": 0,
            "68": 0,
            "69": 0,
            "70": 0,
            "71": 0,
            "72": 0
        },
        "nist": 0.5913999250461949,
        "bleu": 0.00538,
        "bleurt": 0.19486,
        "nubia": {
            "semantic_relation": 4.28249,
            "contradiction": 6.56426,
            "irrelevancy": 19.11216,
            "logical_agreement": 74.32358,
            "grammar_ref": 4.89251,
            "grammar_hyp": 4.66684,
            "nubia_score": 0.75963
        },
        "meteor": 0.07852236420114085,
        "bertscore": {
            "precision": 0.90777,
            "recall": 0.90227,
            "f1": 0.9047
        }
    },
    "dart_test": {
        "predictions_file": "T5-large (Baseline)/dart_test",
        "N": 6959
    },
    "web_nlg_ru_validation": {
        "predictions_file": "T5-large (Baseline)/web_nlg_ru_validation",
        "N": 790,
        "msttr-100": 0.37374,
        "msttr-100_nopunct": 0.36538,
        "total_length": 35833,
        "mean_pred_length": 45.358227848101265,
        "std_pred_length": 19.793670562273995,
        "median_pred_length": 47.0,
        "min_pred_length": 9,
        "max_pred_length": 82,
        "distinct-1": 0.039572461139173384,
        "vocab_size-1": 1418,
        "unique-1": 424,
        "entropy-1": 5.606112287660552,
        "distinct-2": 0.11294695088890791,
        "vocab_size-2": 3958,
        "unique-2": 1510,
        "entropy-2": 9.735220650652286,
        "cond_entropy-2": 4.129867673090615,
        "distinct-3": 0.21817067118208625,
        "vocab_size-3": 7473,
        "unique-3": 3484,
        "entropy-3": 11.355783144708212,
        "cond_entropy-3": 1.6571412747813412,
        "total_length-nopunct": 33158,
        "mean_pred_length-nopunct": 41.972151898734175,
        "std_pred_length-nopunct": 18.79218081879519,
        "median_pred_length-nopunct": 44.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 77,
        "distinct-1-nopunct": 0.04252367452801737,
        "vocab_size-1-nopunct": 1410,
        "unique-1-nopunct": 423,
        "entropy-1-nopunct": 5.4919596688703045,
        "distinct-2-nopunct": 0.11276569451309935,
        "vocab_size-2-nopunct": 3650,
        "unique-2-nopunct": 1396,
        "entropy-2-nopunct": 9.59918767316667,
        "cond_entropy-2-nopunct": 4.177884521555498,
        "distinct-3-nopunct": 0.21784153524605737,
        "vocab_size-3-nopunct": 6879,
        "unique-3-nopunct": 3290,
        "entropy-3-nopunct": 11.193056903384852,
        "cond_entropy-3-nopunct": 1.6315268605689592,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_validation.json",
        "rouge1": {
            "precision": 0.29766,
            "recall": 0.29594,
            "fmeasure": 0.29272
        },
        "rouge2": {
            "precision": 0.10517,
            "recall": 0.10275,
            "fmeasure": 0.10249
        },
        "rougeL": {
            "precision": 0.28197,
            "recall": 0.28125,
            "fmeasure": 0.2776
        },
        "rougeLsum": {
            "precision": 0.28197,
            "recall": 0.28125,
            "fmeasure": 0.2776
        },
        "local_recall": {
            "1": 0.06896915927334178,
            "2": 0.1689040272490483,
            "3": 0.23504831548707233,
            "4": 0.2727272727272727,
            "5": 0.2692307692307692,
            "6": 0.2,
            "7": 0.125,
            "8": 0,
            "9": 0.0
        },
        "nist": 0.9107383711531053,
        "bleu": 1.22199,
        "bleurt": -0.51769,
        "nubia": {
            "semantic_relation": 3.26381,
            "contradiction": 35.58689,
            "irrelevancy": 17.25167,
            "logical_agreement": 47.16144,
            "grammar_ref": 2.60252,
            "grammar_hyp": 2.5486,
            "nubia_score": 0.14566
        },
        "meteor": 0.10613024966491194,
        "bertscore": {
            "precision": 0.85072,
            "recall": 0.86457,
            "f1": 0.85703
        }
    }
}
