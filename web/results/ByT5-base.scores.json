{
    "submission_name": "ByT5-base (Baseline)",
    "param_count": 0,
    "web_nlg_ru_challenge_train_sample": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_challenge_train_sample",
        "N": 501
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 166,
        "total_length": 2457,
        "mean_pred_length": 14.801204819277109,
        "std_pred_length": 5.872357010746496,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 26,
        "distinct-1": 0.4517704517704518,
        "vocab_size-1": 1110,
        "unique-1": 879,
        "entropy-1": 8.421863162730324,
        "distinct-2": 0.8729812309035355,
        "vocab_size-2": 2000,
        "unique-2": 1875,
        "entropy-2": 10.761901146946485,
        "cond_entropy-2": 2.0872780500006716,
        "distinct-3": 0.9745882352941176,
        "vocab_size-3": 2071,
        "unique-3": 2028,
        "entropy-3": 10.995941508260083,
        "cond_entropy-3": 0.25503893613452,
        "total_length-nopunct": 2174,
        "mean_pred_length-nopunct": 13.096385542168674,
        "std_pred_length-nopunct": 5.308811628942791,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.5059797608095676,
        "vocab_size-1-nopunct": 1100,
        "unique-1-nopunct": 877,
        "entropy-1-nopunct": 8.695526165389333,
        "distinct-2-nopunct": 0.8794820717131474,
        "vocab_size-2-nopunct": 1766,
        "unique-2-nopunct": 1665,
        "entropy-2-nopunct": 10.579505404141493,
        "cond_entropy-2-nopunct": 2.0369918845426884,
        "distinct-3-nopunct": 0.9820846905537459,
        "vocab_size-3-nopunct": 1809,
        "unique-3-nopunct": 1779,
        "entropy-3-nopunct": 10.809731131377848,
        "cond_entropy-3-nopunct": 0.2584984378053668,
        "msttr-100": 0.71667,
        "msttr-100_nopunct": 0.75714,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.028092656481025137,
            "2": 0.15591397849462366,
            "3": 0.3274021352313167,
            "4": 0.44635193133047213,
            "5": 0.5483870967741935,
            "6": 0.6818181818181818,
            "7": 0.676056338028169,
            "8": 0.7138263665594855,
            "9": 0.8181818181818182,
            "10": 0.8564356435643564
        },
        "nist": 11.365449807251613,
        "bleu": 78.65616,
        "rouge1": {
            "precision": 0.87295,
            "recall": 0.81117,
            "fmeasure": 0.82924
        },
        "rouge2": {
            "precision": 0.75711,
            "recall": 0.69727,
            "fmeasure": 0.71348
        },
        "rougeL": {
            "precision": 0.85094,
            "recall": 0.79495,
            "fmeasure": 0.81155
        },
        "rougeLsum": {
            "precision": 0.85094,
            "recall": 0.79495,
            "fmeasure": 0.81155
        },
        "nubia": {
            "semantic_relation": 4.04043,
            "contradiction": 4.27002,
            "irrelevancy": 27.90988,
            "logical_agreement": 67.82009,
            "grammar_ref": 4.62208,
            "grammar_hyp": 4.94876,
            "nubia_score": 0.63044
        },
        "meteor": 0.46343603231034103,
        "bleurt": 0.1854,
        "bertscore": {
            "precision": 0.9645,
            "recall": 0.95002,
            "f1": 0.95315
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level1": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 0,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json"
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 58,
        "total_length": 1051,
        "mean_pred_length": 18.120689655172413,
        "std_pred_length": 5.239365538737842,
        "median_pred_length": 18.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.5118934348239772,
        "vocab_size-1": 538,
        "unique-1": 434,
        "entropy-1": 7.953349797577419,
        "distinct-2": 0.9224572004028198,
        "vocab_size-2": 916,
        "unique-2": 880,
        "entropy-2": 9.749136727969773,
        "cond_entropy-2": 1.6879994293992409,
        "distinct-3": 0.9850267379679144,
        "vocab_size-3": 921,
        "unique-3": 913,
        "entropy-3": 9.831154874615562,
        "cond_entropy-3": 0.09268955243677603,
        "total_length-nopunct": 945,
        "mean_pred_length-nopunct": 16.29310344827586,
        "std_pred_length-nopunct": 5.112555945869276,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5597883597883598,
        "vocab_size-1-nopunct": 529,
        "unique-1-nopunct": 432,
        "entropy-1-nopunct": 8.082671669656802,
        "distinct-2-nopunct": 0.9413754227733935,
        "vocab_size-2-nopunct": 835,
        "unique-2-nopunct": 806,
        "entropy-2-nopunct": 9.64501418785285,
        "cond_entropy-2-nopunct": 1.6506383669412699,
        "distinct-3-nopunct": 0.9927623642943305,
        "vocab_size-3-nopunct": 823,
        "unique-3-nopunct": 817,
        "entropy-3-nopunct": 9.680753020084516,
        "cond_entropy-3-nopunct": 0.04366526669966051,
        "msttr-100": 0.722,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03404255319148936,
            "2": 0.1511627906976744,
            "3": 0.2913907284768212,
            "4": 0.4,
            "5": 0.4962962962962963,
            "6": 0.5961538461538461,
            "7": 0.6666666666666666,
            "8": 0.7414965986394558,
            "9": 0.7189542483660131,
            "10": 0.8779342723004695
        },
        "nist": 10.054878992427533,
        "bleu": 75.85324,
        "rouge1": {
            "precision": 0.8384,
            "recall": 0.74312,
            "fmeasure": 0.77457
        },
        "rouge2": {
            "precision": 0.72229,
            "recall": 0.63253,
            "fmeasure": 0.66024
        },
        "rougeL": {
            "precision": 0.81171,
            "recall": 0.72526,
            "fmeasure": 0.7524
        },
        "rougeLsum": {
            "precision": 0.81171,
            "recall": 0.72526,
            "fmeasure": 0.7524
        },
        "nubia": {
            "semantic_relation": 3.84534,
            "contradiction": 6.62808,
            "irrelevancy": 31.88217,
            "logical_agreement": 61.48975,
            "grammar_ref": 4.50862,
            "grammar_hyp": 4.79406,
            "nubia_score": 0.57094
        },
        "meteor": 0.4265265081715586,
        "bleurt": 0.04034,
        "bertscore": {
            "precision": 0.94576,
            "recall": 0.93033,
            "f1": 0.93475
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "ByT5-base (Baseline)/cs_restaurants_test",
        "N": 183,
        "total_length": 2097,
        "mean_pred_length": 11.459016393442623,
        "std_pred_length": 1.6944825651701707,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 14,
        "distinct-1": 0.023843586075345733,
        "vocab_size-1": 50,
        "unique-1": 15,
        "entropy-1": 3.8375463680133355,
        "distinct-2": 0.03657262277951933,
        "vocab_size-2": 70,
        "unique-2": 23,
        "entropy-2": 4.275191770128402,
        "cond_entropy-2": 0.4118108827175002,
        "distinct-3": 0.038128249566724434,
        "vocab_size-3": 66,
        "unique-3": 21,
        "entropy-3": 4.143761426821728,
        "cond_entropy-3": -0.11658860056560139,
        "total_length-nopunct": 1444,
        "mean_pred_length-nopunct": 7.890710382513661,
        "std_pred_length-nopunct": 1.0605035602804984,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.03254847645429363,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8803323466663433,
        "distinct-2-nopunct": 0.04203013481363997,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 3.8119001136799153,
        "cond_entropy-2-nopunct": -0.050543925969970246,
        "distinct-3-nopunct": 0.04452690166975881,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.608503197843731,
        "cond_entropy-3-nopunct": -0.18422927606261433,
        "msttr-100": 0.1885,
        "msttr-100_nopunct": 0.19714,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.16650049850448653
        },
        "nist": 0.8702110617479639,
        "bleu": 5.18478,
        "rouge1": {
            "precision": 0.23036,
            "recall": 0.39403,
            "fmeasure": 0.27697
        },
        "rouge2": {
            "precision": 0.08865,
            "recall": 0.14695,
            "fmeasure": 0.10186
        },
        "rougeL": {
            "precision": 0.21823,
            "recall": 0.37227,
            "fmeasure": 0.26211
        },
        "rougeLsum": {
            "precision": 0.21823,
            "recall": 0.37227,
            "fmeasure": 0.26211
        },
        "nubia": {
            "semantic_relation": 2.32581,
            "contradiction": 45.66458,
            "irrelevancy": 40.45112,
            "logical_agreement": 13.8843,
            "grammar_ref": 6.72681,
            "grammar_hyp": 6.28321,
            "nubia_score": 0.22754
        },
        "meteor": 0.09228820384902037,
        "bleurt": -0.92583,
        "bertscore": {
            "precision": 0.81152,
            "recall": 0.86643,
            "f1": 0.83772
        }
    },
    "web_nlg_ru_challenge_validation_sample": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_challenge_validation_sample",
        "N": 500
    },
    "web_nlg_ru_challenge_test_scramble": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_challenge_test_scramble",
        "N": 500,
        "total_length": 5634,
        "mean_pred_length": 11.268,
        "std_pred_length": 2.9597594496850586,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 21,
        "distinct-1": 0.2884274050408236,
        "vocab_size-1": 1625,
        "unique-1": 962,
        "entropy-1": 8.854592307579296,
        "distinct-2": 0.5944682508765096,
        "vocab_size-2": 3052,
        "unique-2": 2257,
        "entropy-2": 11.069827602334358,
        "cond_entropy-2": 2.2461059733267907,
        "distinct-3": 0.770392749244713,
        "vocab_size-3": 3570,
        "unique-3": 2960,
        "entropy-3": 11.60568828578123,
        "cond_entropy-3": 0.6148296795150583,
        "total_length-nopunct": 4795,
        "mean_pred_length-nopunct": 9.59,
        "std_pred_length-nopunct": 2.5771883904751705,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.33743482794577684,
        "vocab_size-1-nopunct": 1618,
        "unique-1-nopunct": 961,
        "entropy-1-nopunct": 9.341518179647219,
        "distinct-2-nopunct": 0.6339930151338766,
        "vocab_size-2-nopunct": 2723,
        "unique-2-nopunct": 2087,
        "entropy-2-nopunct": 10.967532462625089,
        "cond_entropy-2-nopunct": 1.8083313576726878,
        "distinct-3-nopunct": 0.7868247694334651,
        "vocab_size-3-nopunct": 2986,
        "unique-3-nopunct": 2519,
        "entropy-3-nopunct": 11.358078231722372,
        "cond_entropy-3-nopunct": 0.48912871378785466,
        "msttr-100": 0.65714,
        "msttr-100_nopunct": 0.71447,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.1719361147327249,
            "2": 0.36393939393939395,
            "3": 0.5092983939137785,
            "4": 0.6444444444444445,
            "5": 0.6,
            "6": 1.0
        },
        "nist": 1.6968434604442897,
        "bleu": 22.54669,
        "rouge1": {
            "precision": 0.29487,
            "recall": 0.23385,
            "fmeasure": 0.25088
        },
        "rouge2": {
            "precision": 0.13127,
            "recall": 0.10248,
            "fmeasure": 0.10949
        },
        "rougeL": {
            "precision": 0.28701,
            "recall": 0.22758,
            "fmeasure": 0.24407
        },
        "rougeLsum": {
            "precision": 0.28701,
            "recall": 0.22758,
            "fmeasure": 0.24407
        },
        "nubia": {
            "semantic_relation": 3.61589,
            "contradiction": 21.97698,
            "irrelevancy": 22.07222,
            "logical_agreement": 55.9508,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.73069,
            "nubia_score": 0.7055
        },
        "meteor": 0.40233119482738866,
        "bleurt": 0.12705,
        "bertscore": {
            "precision": 0.95271,
            "recall": 0.91587,
            "f1": 0.93296
        }
    },
    "mlsum_de_validation": {
        "predictions_file": "ByT5-base (Baseline)/mlsum_de_validation",
        "N": 11392,
        "total_length": 225993,
        "mean_pred_length": 19.83786867977528,
        "std_pred_length": 2.7187567553116536,
        "median_pred_length": 20.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.1352696764944047,
        "vocab_size-1": 30570,
        "unique-1": 19021,
        "entropy-1": 10.377112892468446,
        "distinct-2": 0.5276489857922377,
        "vocab_size-2": 113234,
        "unique-2": 92004,
        "entropy-2": 15.369090161864369,
        "cond_entropy-2": 5.060336306577616,
        "distinct-3": 0.8187531064076886,
        "vocab_size-3": 166378,
        "unique-3": 152343,
        "entropy-3": 16.98480303260381,
        "cond_entropy-3": 1.6751796972394346,
        "total_length-nopunct": 206819,
        "mean_pred_length-nopunct": 18.1547577247191,
        "std_pred_length-nopunct": 2.4996165810495303,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.14775238251804718,
        "vocab_size-1-nopunct": 30558,
        "unique-1-nopunct": 19021,
        "entropy-1-nopunct": 10.73924600456843,
        "distinct-2-nopunct": 0.5774381226749631,
        "vocab_size-2-nopunct": 112847,
        "unique-2-nopunct": 93170,
        "entropy-2-nopunct": 15.705357530838857,
        "cond_entropy-2-nopunct": 5.127649968820669,
        "distinct-3-nopunct": 0.8601244328524466,
        "vocab_size-3-nopunct": 158293,
        "unique-3-nopunct": 147223,
        "entropy-3-nopunct": 17.03042527934853,
        "cond_entropy-3-nopunct": 1.3905981473309719,
        "msttr-100": 0.74766,
        "msttr-100_nopunct": 0.77827,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_validation.json",
        "local_recall": {
            "1": 0.3548242093433938
        },
        "nist": 5.224069778519772,
        "bleu": 25.54815,
        "rouge1": {
            "precision": 0.45961,
            "recall": 0.35617,
            "fmeasure": 0.39532
        },
        "rouge2": {
            "precision": 0.3378,
            "recall": 0.25156,
            "fmeasure": 0.28449
        },
        "rougeL": {
            "precision": 0.42225,
            "recall": 0.32562,
            "fmeasure": 0.36229
        },
        "rougeLsum": {
            "precision": 0.42225,
            "recall": 0.32562,
            "fmeasure": 0.36229
        },
        "nubia": {
            "semantic_relation": 2.41706,
            "contradiction": 25.53956,
            "irrelevancy": 41.07868,
            "logical_agreement": 33.38176,
            "grammar_ref": 5.04919,
            "grammar_hyp": 5.05091,
            "nubia_score": 0.28854
        },
        "meteor": 0.30813248460412557,
        "bleurt": -0.45167,
        "bertscore": {
            "precision": 0.89173,
            "recall": 0.87136,
            "f1": 0.88123
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 32,
        "total_length": 546,
        "mean_pred_length": 17.0625,
        "std_pred_length": 5.147435647970744,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 29,
        "distinct-1": 0.5622710622710623,
        "vocab_size-1": 307,
        "unique-1": 250,
        "entropy-1": 7.446355081519125,
        "distinct-2": 0.9105058365758755,
        "vocab_size-2": 468,
        "unique-2": 443,
        "entropy-2": 8.786180993708555,
        "cond_entropy-2": 1.2089375566850002,
        "distinct-3": 0.9771784232365145,
        "vocab_size-3": 471,
        "unique-3": 466,
        "entropy-3": 8.854798049922849,
        "cond_entropy-3": 0.08111123417191644,
        "total_length-nopunct": 484,
        "mean_pred_length-nopunct": 15.125,
        "std_pred_length-nopunct": 4.608077147791691,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6198347107438017,
        "vocab_size-1-nopunct": 300,
        "unique-1-nopunct": 249,
        "entropy-1-nopunct": 7.549353488692116,
        "distinct-2-nopunct": 0.9292035398230089,
        "vocab_size-2-nopunct": 420,
        "unique-2-nopunct": 401,
        "entropy-2-nopunct": 8.649196191363941,
        "cond_entropy-2-nopunct": 1.1787240897365208,
        "distinct-3-nopunct": 0.9976190476190476,
        "vocab_size-3-nopunct": 419,
        "unique-3-nopunct": 418,
        "entropy-3-nopunct": 8.709483612904231,
        "cond_entropy-3-nopunct": 0.07331468028699248,
        "msttr-100": 0.714,
        "msttr-100_nopunct": 0.735,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.024640657084188913,
            "2": 0.11214953271028037,
            "3": 0.2535211267605634,
            "4": 0.453125,
            "5": 0.5454545454545454,
            "6": 0.5,
            "7": 0.7424242424242424,
            "8": 0.7619047619047619,
            "9": 0.7738095238095238,
            "10": 0.8951612903225806
        },
        "nist": 9.085674834569877,
        "bleu": 77.10324,
        "rouge1": {
            "precision": 0.85168,
            "recall": 0.80011,
            "fmeasure": 0.81206
        },
        "rouge2": {
            "precision": 0.73224,
            "recall": 0.67186,
            "fmeasure": 0.68531
        },
        "rougeL": {
            "precision": 0.82855,
            "recall": 0.78619,
            "fmeasure": 0.79214
        },
        "rougeLsum": {
            "precision": 0.82855,
            "recall": 0.78619,
            "fmeasure": 0.79214
        },
        "nubia": {
            "semantic_relation": 4.14535,
            "contradiction": 4.3478,
            "irrelevancy": 27.17558,
            "logical_agreement": 68.47662,
            "grammar_ref": 4.51508,
            "grammar_hyp": 4.73678,
            "nubia_score": 0.64799
        },
        "meteor": 0.4494475950014313,
        "bleurt": 0.13428,
        "bertscore": {
            "precision": 0.95547,
            "recall": 0.95009,
            "f1": 0.94744
        }
    },
    "e2e_nlg_challenge_test_scramble_parent": {
        "predictions_file": "ByT5-base (Baseline)/e2e_nlg_test",
        "N": 500,
        "total_length": 11403,
        "mean_pred_length": 22.806,
        "std_pred_length": 3.954790007067379,
        "median_pred_length": 24.0,
        "min_pred_length": 10,
        "max_pred_length": 30,
        "distinct-1": 0.029465930018416207,
        "vocab_size-1": 336,
        "unique-1": 100,
        "entropy-1": 6.220298014381201,
        "distinct-2": 0.11373016600935522,
        "vocab_size-2": 1240,
        "unique-2": 541,
        "entropy-2": 8.384731236523638,
        "cond_entropy-2": 2.2229247268248864,
        "distinct-3": 0.22416610593098144,
        "vocab_size-3": 2332,
        "unique-3": 1213,
        "entropy-3": 9.738900010423794,
        "cond_entropy-3": 1.4345683961330677,
        "total_length-nopunct": 10694,
        "mean_pred_length-nopunct": 21.388,
        "std_pred_length-nopunct": 3.873171310437998,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.031232466803815223,
        "vocab_size-1-nopunct": 334,
        "unique-1-nopunct": 100,
        "entropy-1-nopunct": 6.228025652560301,
        "distinct-2-nopunct": 0.11859917598587405,
        "vocab_size-2-nopunct": 1209,
        "unique-2-nopunct": 558,
        "entropy-2-nopunct": 8.359474964965035,
        "cond_entropy-2-nopunct": 2.245417877653806,
        "distinct-3-nopunct": 0.23220548793067877,
        "vocab_size-3-nopunct": 2251,
        "unique-3-nopunct": 1195,
        "entropy-3-nopunct": 9.736220128593118,
        "cond_entropy-3-nopunct": 1.4519001862239158,
        "msttr-100": 0.52263,
        "msttr-100_nopunct": 0.52783,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6238259090486376
        },
        "nist": 4.656303217473173,
        "bleu": 25.18811,
        "rouge1": {
            "precision": 0.70879,
            "recall": 0.6397,
            "fmeasure": 0.66144
        },
        "rouge2": {
            "precision": 0.4101,
            "recall": 0.36792,
            "fmeasure": 0.38149
        },
        "rougeL": {
            "precision": 0.49834,
            "recall": 0.45183,
            "fmeasure": 0.46606
        },
        "rougeLsum": {
            "precision": 0.49834,
            "recall": 0.45183,
            "fmeasure": 0.46606
        },
        "nubia": {
            "semantic_relation": 3.95855,
            "contradiction": 3.96303,
            "irrelevancy": 28.60802,
            "logical_agreement": 67.42896,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.74216,
            "nubia_score": 0.65452
        },
        "meteor": 0.31768119551312785,
        "bleurt": -0.05235,
        "bertscore": {
            "precision": 0.90126,
            "recall": 0.88642,
            "f1": 0.89339
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_32": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 18,
        "unique-1": 14,
        "entropy-1": 4.095795255000933,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 18,
        "unique-2": 15,
        "entropy-2": 4.106603137064475,
        "cond_entropy-2": 0.02812389937955851,
        "distinct-3": 0.9,
        "vocab_size-3": 18,
        "unique-3": 16,
        "entropy-3": 4.1219280948873624,
        "cond_entropy-3": 0.029610672108602003,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.921928094887362,
        "distinct-2-nopunct": 0.8421052631578947,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.932138039759374,
        "cond_entropy-2-nopunct": -0.021369002496408357,
        "distinct-3-nopunct": 0.8888888888888888,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.94770277922009,
        "cond_entropy-3-nopunct": -0.0224469564457176,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.17857142857142858
        },
        "nist": 0.3198626035358589,
        "bleu": 14.74095,
        "rouge1": {
            "precision": 0.61905,
            "recall": 0.31364,
            "fmeasure": 0.41595
        },
        "rouge2": {
            "precision": 0.45,
            "recall": 0.22362,
            "fmeasure": 0.29829
        },
        "rougeL": {
            "precision": 0.61905,
            "recall": 0.31364,
            "fmeasure": 0.41595
        },
        "rougeLsum": {
            "precision": 0.61905,
            "recall": 0.31364,
            "fmeasure": 0.41595
        },
        "nubia": {
            "semantic_relation": 1.59984,
            "contradiction": 60.4173,
            "irrelevancy": 26.75267,
            "logical_agreement": 12.83003,
            "grammar_ref": 4.14314,
            "grammar_hyp": 3.1913,
            "nubia_score": 0.10286
        },
        "meteor": 0.16459065627692146,
        "bleurt": -0.9971,
        "bertscore": {
            "precision": 0.91861,
            "recall": 0.73064,
            "f1": 0.81391
        }
    },
    "mlsum_de_test": {
        "predictions_file": "ByT5-base (Baseline)/mlsum_de_test",
        "N": 10695,
        "total_length": 212956,
        "mean_pred_length": 19.911734455352967,
        "std_pred_length": 2.720357299323823,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.14075677604763426,
        "vocab_size-1": 29975,
        "unique-1": 18766,
        "entropy-1": 10.389916515442556,
        "distinct-2": 0.5377705044472242,
        "vocab_size-2": 108770,
        "unique-2": 88841,
        "entropy-2": 15.346953709919328,
        "cond_entropy-2": 5.032512838395163,
        "distinct-3": 0.8265871814413831,
        "vocab_size-3": 158346,
        "unique-3": 145445,
        "entropy-3": 16.93309193194598,
        "cond_entropy-3": 1.6464669976996553,
        "total_length-nopunct": 194979,
        "mean_pred_length-nopunct": 18.230855539971948,
        "std_pred_length-nopunct": 2.4741584989383822,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.15366270213715325,
        "vocab_size-1-nopunct": 29961,
        "unique-1-nopunct": 18764,
        "entropy-1-nopunct": 10.749443527731412,
        "distinct-2-nopunct": 0.5881845412515465,
        "vocab_size-2-nopunct": 108393,
        "unique-2-nopunct": 89932,
        "entropy-2-nopunct": 15.68167235978814,
        "cond_entropy-2-nopunct": 5.093783217481754,
        "distinct-3-nopunct": 0.867480082263277,
        "vocab_size-3-nopunct": 150585,
        "unique-3-nopunct": 140477,
        "entropy-3-nopunct": 16.97244162215679,
        "cond_entropy-3-nopunct": 1.3553187885144264,
        "msttr-100": 0.75046,
        "msttr-100_nopunct": 0.78073,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_test.json",
        "local_recall": {
            "1": 0.3643775969639083
        },
        "nist": 5.342222154862975,
        "bleu": 26.6176,
        "rouge1": {
            "precision": 0.47433,
            "recall": 0.36606,
            "fmeasure": 0.40727
        },
        "rouge2": {
            "precision": 0.35569,
            "recall": 0.26407,
            "fmeasure": 0.2992
        },
        "rougeL": {
            "precision": 0.43755,
            "recall": 0.336,
            "fmeasure": 0.37475
        },
        "rougeLsum": {
            "precision": 0.43755,
            "recall": 0.336,
            "fmeasure": 0.37475
        },
        "nubia": {
            "semantic_relation": 2.44406,
            "contradiction": 25.27502,
            "irrelevancy": 40.43826,
            "logical_agreement": 34.28672,
            "grammar_ref": 5.03454,
            "grammar_hyp": 5.055,
            "nubia_score": 0.29382
        },
        "meteor": 0.3177392617122339,
        "bleurt": -0.44314,
        "bertscore": {
            "precision": 0.89405,
            "recall": 0.87278,
            "f1": 0.88309
        }
    },
    "mlsum_de_challenge_train_sample": {
        "predictions_file": "ByT5-base (Baseline)/mlsum_de_challenge_train_sample",
        "N": 500
    },
    "mlsum_de_challenge_validation_sample": {
        "predictions_file": "ByT5-base (Baseline)/mlsum_de_challenge_validation_sample",
        "N": 500
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 5,
        "total_length": 76,
        "mean_pred_length": 15.2,
        "std_pred_length": 4.995998398718719,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 22,
        "distinct-1": 0.7631578947368421,
        "vocab_size-1": 58,
        "unique-1": 50,
        "entropy-1": 5.596483105491919,
        "distinct-2": 0.9859154929577465,
        "vocab_size-2": 70,
        "unique-2": 69,
        "entropy-2": 6.12157810542017,
        "cond_entropy-2": 0.4442108033051377,
        "distinct-3": 1.0,
        "vocab_size-3": 66,
        "unique-3": 66,
        "entropy-3": 6.044394119358462,
        "cond_entropy-3": -0.09020148499471337,
        "total_length-nopunct": 71,
        "mean_pred_length-nopunct": 14.2,
        "std_pred_length-nopunct": 4.995998398718719,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7887323943661971,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.565102401133876,
        "distinct-2-nopunct": 0.9848484848484849,
        "vocab_size-2-nopunct": 65,
        "unique-2-nopunct": 64,
        "entropy-2-nopunct": 6.014091089055431,
        "cond_entropy-2-nopunct": 0.46297692416175534,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 61,
        "unique-3-nopunct": 61,
        "entropy-3-nopunct": 5.930737337562883,
        "cond_entropy-3-nopunct": -0.09726333917261658,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.027777777777777776,
            "2": 0.23809523809523808,
            "3": 0.375,
            "4": 0.5,
            "5": 0.42857142857142855,
            "6": 0.6923076923076923,
            "7": 0.6666666666666666,
            "8": 0.8333333333333334,
            "9": 0.75,
            "10": 0.8571428571428571
        },
        "nist": 7.3914616276601,
        "bleu": 84.7594,
        "rouge1": {
            "precision": 0.86583,
            "recall": 0.83604,
            "fmeasure": 0.84292
        },
        "rouge2": {
            "precision": 0.7894,
            "recall": 0.70109,
            "fmeasure": 0.73416
        },
        "rougeL": {
            "precision": 0.85992,
            "recall": 0.78183,
            "fmeasure": 0.81198
        },
        "rougeLsum": {
            "precision": 0.85992,
            "recall": 0.78183,
            "fmeasure": 0.81198
        },
        "nubia": {
            "semantic_relation": 3.75883,
            "contradiction": 0.34061,
            "irrelevancy": 42.80154,
            "logical_agreement": 56.85784,
            "grammar_ref": 5.04038,
            "grammar_hyp": 5.17714,
            "nubia_score": 0.60284
        },
        "meteor": 0.49801995767988105,
        "bleurt": 0.16502,
        "bertscore": {
            "precision": 0.96603,
            "recall": 0.94529,
            "f1": 0.95239
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-base (Baseline)/cs_restaurants_test",
        "N": 267,
        "total_length": 2254,
        "mean_pred_length": 8.441947565543071,
        "std_pred_length": 2.177386492409084,
        "median_pred_length": 8.0,
        "min_pred_length": 5,
        "max_pred_length": 18,
        "distinct-1": 0.1401952085181899,
        "vocab_size-1": 316,
        "unique-1": 155,
        "entropy-1": 6.081383446891841,
        "distinct-2": 0.3271263210870659,
        "vocab_size-2": 650,
        "unique-2": 393,
        "entropy-2": 7.999368296033542,
        "cond_entropy-2": 1.6750596934626323,
        "distinct-3": 0.45872093023255817,
        "vocab_size-3": 789,
        "unique-3": 578,
        "entropy-3": 8.658934612381433,
        "cond_entropy-3": 0.9844630113328009,
        "total_length-nopunct": 1979,
        "mean_pred_length-nopunct": 7.411985018726591,
        "std_pred_length-nopunct": 1.8549272858337649,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.15816068721576554,
        "vocab_size-1-nopunct": 313,
        "unique-1-nopunct": 155,
        "entropy-1-nopunct": 6.232795874647554,
        "distinct-2-nopunct": 0.290303738317757,
        "vocab_size-2-nopunct": 497,
        "unique-2-nopunct": 294,
        "entropy-2-nopunct": 7.5251929637247095,
        "cond_entropy-2-nopunct": 1.8240637878827493,
        "distinct-3-nopunct": 0.4207612456747405,
        "vocab_size-3-nopunct": 608,
        "unique-3-nopunct": 439,
        "entropy-3-nopunct": 8.206552692280228,
        "cond_entropy-3-nopunct": 1.135544611651977,
        "msttr-100": 0.485,
        "msttr-100_nopunct": 0.51368,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.577191235059761
        },
        "nist": 4.769623419776808,
        "bleu": 24.44426,
        "rouge1": {
            "precision": 0.63179,
            "recall": 0.61818,
            "fmeasure": 0.61453
        },
        "rouge2": {
            "precision": 0.36811,
            "recall": 0.36423,
            "fmeasure": 0.35929
        },
        "rougeL": {
            "precision": 0.57204,
            "recall": 0.56024,
            "fmeasure": 0.55693
        },
        "rougeLsum": {
            "precision": 0.57204,
            "recall": 0.56024,
            "fmeasure": 0.55693
        },
        "nubia": {
            "semantic_relation": 3.80065,
            "contradiction": 13.7246,
            "irrelevancy": 31.50758,
            "logical_agreement": 54.76782,
            "grammar_ref": 7.44295,
            "grammar_hyp": 7.34439,
            "nubia_score": 0.61002
        },
        "meteor": 0.2927487027708635,
        "bleurt": 0.03473,
        "bertscore": {
            "precision": 0.91448,
            "recall": 0.91678,
            "f1": 0.9154
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 28,
        "total_length": 563,
        "mean_pred_length": 20.107142857142858,
        "std_pred_length": 5.857469503086792,
        "median_pred_length": 20.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.5683836589698046,
        "vocab_size-1": 320,
        "unique-1": 254,
        "entropy-1": 7.5453089456297455,
        "distinct-2": 0.9214953271028037,
        "vocab_size-2": 493,
        "unique-2": 466,
        "entropy-2": 8.87430861501051,
        "cond_entropy-2": 1.2409021939530323,
        "distinct-3": 0.9783037475345168,
        "vocab_size-3": 496,
        "unique-3": 489,
        "entropy-3": 8.934559885721404,
        "cond_entropy-3": 0.06280436944013706,
        "total_length-nopunct": 504,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 5.11998883927355,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6190476190476191,
        "vocab_size-1-nopunct": 312,
        "unique-1-nopunct": 252,
        "entropy-1-nopunct": 7.601191362624244,
        "distinct-2-nopunct": 0.9453781512605042,
        "vocab_size-2-nopunct": 450,
        "unique-2-nopunct": 431,
        "entropy-2-nopunct": 8.76632772242833,
        "cond_entropy-2-nopunct": 1.2364504715766351,
        "distinct-3-nopunct": 0.9955357142857143,
        "vocab_size-3-nopunct": 446,
        "unique-3-nopunct": 444,
        "entropy-3-nopunct": 8.798426350629013,
        "cond_entropy-3-nopunct": 0.03566497004146912,
        "msttr-100": 0.748,
        "msttr-100_nopunct": 0.764,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.023121387283236993,
            "2": 0.15789473684210525,
            "3": 0.21052631578947367,
            "4": 0.5483870967741935,
            "5": 0.41935483870967744,
            "6": 0.5873015873015873,
            "7": 0.5679012345679012,
            "8": 0.7096774193548387,
            "9": 0.8545454545454545,
            "10": 0.9534883720930233
        },
        "nist": 9.53014379736608,
        "bleu": 78.12532,
        "rouge1": {
            "precision": 0.85258,
            "recall": 0.76439,
            "fmeasure": 0.7947
        },
        "rouge2": {
            "precision": 0.74206,
            "recall": 0.65579,
            "fmeasure": 0.68428
        },
        "rougeL": {
            "precision": 0.84672,
            "recall": 0.74538,
            "fmeasure": 0.78054
        },
        "rougeLsum": {
            "precision": 0.84672,
            "recall": 0.74538,
            "fmeasure": 0.78054
        },
        "nubia": {
            "semantic_relation": 3.98335,
            "contradiction": 3.62992,
            "irrelevancy": 30.75436,
            "logical_agreement": 65.61572,
            "grammar_ref": 4.66117,
            "grammar_hyp": 4.90797,
            "nubia_score": 0.6022
        },
        "meteor": 0.45845973517743716,
        "bleurt": 0.00954,
        "bertscore": {
            "precision": 0.95739,
            "recall": 0.9518,
            "f1": 0.94809
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 7,
        "total_length": 143,
        "mean_pred_length": 20.428571428571427,
        "std_pred_length": 4.16986271980755,
        "median_pred_length": 22.0,
        "min_pred_length": 11,
        "max_pred_length": 24,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 104,
        "unique-1": 91,
        "entropy-1": 6.301919959896852,
        "distinct-2": 0.9558823529411765,
        "vocab_size-2": 130,
        "unique-2": 127,
        "entropy-2": 6.97268607305594,
        "cond_entropy-2": 0.6295603717159725,
        "distinct-3": 1.0,
        "vocab_size-3": 129,
        "unique-3": 129,
        "entropy-3": 7.011227255423235,
        "cond_entropy-3": 0.029265503122037267,
        "total_length-nopunct": 130,
        "mean_pred_length-nopunct": 18.571428571428573,
        "std_pred_length-nopunct": 3.8861344310672696,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7615384615384615,
        "vocab_size-1-nopunct": 99,
        "unique-1-nopunct": 90,
        "entropy-1-nopunct": 6.235271513663376,
        "distinct-2-nopunct": 0.959349593495935,
        "vocab_size-2-nopunct": 118,
        "unique-2-nopunct": 116,
        "entropy-2-nopunct": 6.831867021807221,
        "cond_entropy-2-nopunct": 0.6413896064817094,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 116,
        "unique-3-nopunct": 116,
        "entropy-3-nopunct": 6.857980995127556,
        "cond_entropy-3-nopunct": 0.03279097663692543,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.79,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.01764705882352941,
            "2": 0.09090909090909091,
            "3": 0.5333333333333333,
            "4": 0.5833333333333334,
            "5": 0.6875,
            "6": 0.6666666666666666,
            "7": 0.8,
            "8": 0.88,
            "9": 1.0,
            "10": 0.8333333333333334
        },
        "nist": 8.503961649646177,
        "bleu": 89.9214,
        "rouge1": {
            "precision": 0.90326,
            "recall": 0.8339,
            "fmeasure": 0.86052
        },
        "rouge2": {
            "precision": 0.83876,
            "recall": 0.77811,
            "fmeasure": 0.79837
        },
        "rougeL": {
            "precision": 0.89767,
            "recall": 0.82895,
            "fmeasure": 0.85527
        },
        "rougeLsum": {
            "precision": 0.89767,
            "recall": 0.82895,
            "fmeasure": 0.85527
        },
        "nubia": {
            "semantic_relation": 4.22701,
            "contradiction": 2.94088,
            "irrelevancy": 37.7765,
            "logical_agreement": 59.28263,
            "grammar_ref": 4.66733,
            "grammar_hyp": 4.76988,
            "nubia_score": 0.67938
        },
        "meteor": 0.502985300609064,
        "bleurt": 0.17079,
        "bertscore": {
            "precision": 0.97358,
            "recall": 0.96317,
            "f1": 0.96332
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_33": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.12336199461765363,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.03310859910983796,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.08333333333333333,
            "3": 0.17647058823529413
        },
        "nist": 0.8137401375764001,
        "bleu": 2.5828,
        "rouge1": {
            "precision": 0.35,
            "recall": 0.18919,
            "fmeasure": 0.24561
        },
        "rouge2": {
            "precision": 0.15789,
            "recall": 0.08333,
            "fmeasure": 0.10909
        },
        "rougeL": {
            "precision": 0.21667,
            "recall": 0.16626,
            "fmeasure": 0.18546
        },
        "rougeLsum": {
            "precision": 0.21667,
            "recall": 0.16626,
            "fmeasure": 0.18546
        },
        "nubia": {
            "semantic_relation": 2.44235,
            "contradiction": 0.93668,
            "irrelevancy": 98.96676,
            "logical_agreement": 0.09656,
            "grammar_ref": 4.39709,
            "grammar_hyp": 3.02346,
            "nubia_score": 0.27003
        },
        "meteor": 0.1398225629977407,
        "bleurt": -0.62717,
        "bertscore": {
            "precision": 0.80964,
            "recall": 0.7399,
            "f1": 0.7732
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 63,
        "total_length": 1329,
        "mean_pred_length": 21.095238095238095,
        "std_pred_length": 5.487979029861498,
        "median_pred_length": 23.0,
        "min_pred_length": 9,
        "max_pred_length": 32,
        "distinct-1": 0.49360421369450713,
        "vocab_size-1": 656,
        "unique-1": 527,
        "entropy-1": 8.185533006025397,
        "distinct-2": 0.9036334913112164,
        "vocab_size-2": 1144,
        "unique-2": 1092,
        "entropy-2": 10.020361363436407,
        "cond_entropy-2": 1.8141938154018165,
        "distinct-3": 0.9684123025768911,
        "vocab_size-3": 1165,
        "unique-3": 1157,
        "entropy-3": 10.119274033724928,
        "cond_entropy-3": 0.11138076716056855,
        "total_length-nopunct": 1197,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 5.092789798971477,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5405179615705932,
        "vocab_size-1-nopunct": 647,
        "unique-1-nopunct": 524,
        "entropy-1-nopunct": 8.33358857126561,
        "distinct-2-nopunct": 0.9426807760141094,
        "vocab_size-2-nopunct": 1069,
        "unique-2-nopunct": 1028,
        "entropy-2-nopunct": 10.01046890199182,
        "cond_entropy-2-nopunct": 1.7461896364525646,
        "distinct-3-nopunct": 0.9981325863678805,
        "vocab_size-3-nopunct": 1069,
        "unique-3-nopunct": 1067,
        "entropy-3-nopunct": 10.061007937486016,
        "cond_entropy-3-nopunct": 0.055781210513874295,
        "msttr-100": 0.75385,
        "msttr-100_nopunct": 0.77273,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.022857142857142857,
            "2": 0.13387978142076504,
            "3": 0.2982456140350877,
            "4": 0.5276073619631901,
            "5": 0.5389221556886228,
            "6": 0.5806451612903226,
            "7": 0.6987951807228916,
            "8": 0.7255813953488373,
            "9": 0.7413793103448276,
            "10": 0.8657407407407407
        },
        "nist": 10.756923028074551,
        "bleu": 80.11382,
        "rouge1": {
            "precision": 0.85333,
            "recall": 0.76717,
            "fmeasure": 0.79774
        },
        "rouge2": {
            "precision": 0.7417,
            "recall": 0.6574,
            "fmeasure": 0.68696
        },
        "rougeL": {
            "precision": 0.82878,
            "recall": 0.74766,
            "fmeasure": 0.77722
        },
        "rougeLsum": {
            "precision": 0.82878,
            "recall": 0.74766,
            "fmeasure": 0.77722
        },
        "nubia": {
            "semantic_relation": 3.89702,
            "contradiction": 2.59614,
            "irrelevancy": 36.76071,
            "logical_agreement": 60.64315,
            "grammar_ref": 4.4268,
            "grammar_hyp": 4.78473,
            "nubia_score": 0.56787
        },
        "meteor": 0.4445549699177836,
        "bleurt": -0.07812,
        "bertscore": {
            "precision": 0.94874,
            "recall": 0.93928,
            "f1": 0.93988
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 3,
        "total_length": 36,
        "mean_pred_length": 12.0,
        "std_pred_length": 3.7416573867739413,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 16,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 24,
        "unique-1": 16,
        "entropy-1": 4.41938194564637,
        "distinct-2": 0.8787878787878788,
        "vocab_size-2": 29,
        "unique-2": 25,
        "entropy-2": 4.801969876934213,
        "cond_entropy-2": 0.4205160878753491,
        "distinct-3": 0.9666666666666667,
        "vocab_size-3": 29,
        "unique-3": 28,
        "entropy-3": 4.840223928941852,
        "cond_entropy-3": 0.06249647625006527,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 10.333333333333334,
        "std_pred_length-nopunct": 3.0912061651652345,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7096774193548387,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.300497519854926,
        "distinct-2-nopunct": 0.8928571428571429,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.593069207771891,
        "cond_entropy-2-nopunct": 0.306005040448202,
        "distinct-3-nopunct": 0.96,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.5638561897747225,
        "cond_entropy-3-nopunct": -0.04349873228287957,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.10810810810810811,
            "2": 0.25,
            "3": 0.42857142857142855
        },
        "nist": 0.6634923096547144,
        "bleu": 7.1878,
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "nubia": {
            "semantic_relation": 3.49476,
            "contradiction": 18.88798,
            "irrelevancy": 23.27262,
            "logical_agreement": 57.8394,
            "grammar_ref": 2.52713,
            "grammar_hyp": 2.79638,
            "nubia_score": 0.64753
        },
        "meteor": 0.31777120487488847,
        "bleurt": -0.01898,
        "bertscore": {
            "precision": 0.93666,
            "recall": 0.89566,
            "f1": 0.91533
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_34": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.8,
        "vocab_size-1": 20,
        "unique-1": 15,
        "entropy-1": 4.243856189774722,
        "distinct-2": 0.9583333333333334,
        "vocab_size-2": 23,
        "unique-2": 22,
        "entropy-2": 4.501629167387823,
        "cond_entropy-2": 0.27443964427976514,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": 0.025555977074987163,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7619047619047619,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.916126946588283,
        "distinct-2-nopunct": 0.95,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.221928094887362,
        "cond_entropy-2-nopunct": 0.279610672108602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.02136900249640835,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.5238095238095238
        },
        "nist": 3.3899967525381203,
        "bleu": 28.63071,
        "rouge1": {
            "precision": 0.60317,
            "recall": 0.60054,
            "fmeasure": 0.59858
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.26852,
            "fmeasure": 0.25877
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.45865,
            "fmeasure": 0.44286
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.45865,
            "fmeasure": 0.44286
        },
        "nubia": {
            "semantic_relation": 3.50405,
            "contradiction": 0.38939,
            "irrelevancy": 0.56912,
            "logical_agreement": 99.04148,
            "grammar_ref": 4.75948,
            "grammar_hyp": 3.96482,
            "nubia_score": 0.62625
        },
        "meteor": 0.2769905154511575,
        "bleurt": 0.03619,
        "bertscore": {
            "precision": 0.91643,
            "recall": 0.86923,
            "f1": 0.8922
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 174,
        "total_length": 2540,
        "mean_pred_length": 14.597701149425287,
        "std_pred_length": 5.650673380917957,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.44606299212598427,
        "vocab_size-1": 1133,
        "unique-1": 891,
        "entropy-1": 8.449197910615501,
        "distinct-2": 0.8753169907016061,
        "vocab_size-2": 2071,
        "unique-2": 1950,
        "entropy-2": 10.817206770731005,
        "cond_entropy-2": 2.0892247425255626,
        "distinct-3": 0.9776459854014599,
        "vocab_size-3": 2143,
        "unique-3": 2108,
        "entropy-3": 11.046828236720597,
        "cond_entropy-3": 0.24845536778841207,
        "total_length-nopunct": 2260,
        "mean_pred_length-nopunct": 12.988505747126437,
        "std_pred_length-nopunct": 5.195033554201292,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.49734513274336284,
        "vocab_size-1-nopunct": 1124,
        "unique-1-nopunct": 890,
        "entropy-1-nopunct": 8.734214401057505,
        "distinct-2-nopunct": 0.8811121764141898,
        "vocab_size-2-nopunct": 1838,
        "unique-2-nopunct": 1737,
        "entropy-2-nopunct": 10.642825449251136,
        "cond_entropy-2-nopunct": 2.0610560708358645,
        "distinct-3-nopunct": 0.9827405857740585,
        "vocab_size-3-nopunct": 1879,
        "unique-3-nopunct": 1851,
        "entropy-3-nopunct": 10.864117507506627,
        "cond_entropy-3-nopunct": 0.24701302495399524,
        "msttr-100": 0.7256,
        "msttr-100_nopunct": 0.77091,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.039349422875131164,
            "2": 0.1485148514851485,
            "3": 0.3439153439153439,
            "4": 0.4153225806451613,
            "5": 0.5634674922600619,
            "6": 0.6701492537313433,
            "7": 0.7848101265822784
        },
        "nist": 8.383002263254925,
        "bleu": 59.80912,
        "rouge1": {
            "precision": 0.8467,
            "recall": 0.7267,
            "fmeasure": 0.76736
        },
        "rouge2": {
            "precision": 0.67768,
            "recall": 0.56852,
            "fmeasure": 0.60478
        },
        "rougeL": {
            "precision": 0.80293,
            "recall": 0.6849,
            "fmeasure": 0.72512
        },
        "rougeLsum": {
            "precision": 0.80293,
            "recall": 0.6849,
            "fmeasure": 0.72512
        },
        "nubia": {
            "semantic_relation": 4.03479,
            "contradiction": 6.14399,
            "irrelevancy": 16.26993,
            "logical_agreement": 77.58608,
            "grammar_ref": 4.58509,
            "grammar_hyp": 5.08642,
            "nubia_score": 0.62822
        },
        "meteor": 0.40641096559111,
        "bleurt": 0.12674,
        "bertscore": {
            "precision": 0.94954,
            "recall": 0.92116,
            "f1": 0.932
        }
    },
    "mlsum_de_challenge_test_covid": {
        "predictions_file": "ByT5-base (Baseline)/mlsum_de_challenge_test_covid",
        "N": 5058,
        "total_length": 103341,
        "mean_pred_length": 20.43119810201661,
        "std_pred_length": 3.102268871479283,
        "median_pred_length": 20.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.12203288143137767,
        "vocab_size-1": 12611,
        "unique-1": 8199,
        "entropy-1": 9.162050905828217,
        "distinct-2": 0.4321296663716004,
        "vocab_size-2": 42471,
        "unique-2": 35455,
        "entropy-2": 12.653772023596927,
        "cond_entropy-2": 3.555135117023925,
        "distinct-3": 0.6205309734513275,
        "vocab_size-3": 57849,
        "unique-3": 53996,
        "entropy-3": 13.528573959152977,
        "cond_entropy-3": 0.9287059794763103,
        "total_length-nopunct": 93403,
        "mean_pred_length-nopunct": 18.466389877421907,
        "std_pred_length-nopunct": 2.472497447870777,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.13488860100853292,
        "vocab_size-1-nopunct": 12599,
        "unique-1-nopunct": 8196,
        "entropy-1-nopunct": 9.466543825527474,
        "distinct-2-nopunct": 0.4734733148452091,
        "vocab_size-2-nopunct": 41829,
        "unique-2-nopunct": 35531,
        "entropy-2-nopunct": 12.826540187675773,
        "cond_entropy-2-nopunct": 3.4908551797613283,
        "distinct-3-nopunct": 0.6490448689471346,
        "vocab_size-3-nopunct": 54057,
        "unique-3-nopunct": 51156,
        "entropy-3-nopunct": 13.5098658507108,
        "cond_entropy-3-nopunct": 0.7384606836240588,
        "msttr-100": 0.69359,
        "msttr-100_nopunct": 0.7202,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_challenge_test_covid.json",
        "local_recall": {
            "1": 0.3044238253336558
        },
        "nist": 4.329164388278779,
        "bleu": 20.6925,
        "rouge1": {
            "precision": 0.32707,
            "recall": 0.30805,
            "fmeasure": 0.31085
        },
        "rouge2": {
            "precision": 0.22855,
            "recall": 0.206,
            "fmeasure": 0.21266
        },
        "rougeL": {
            "precision": 0.30181,
            "recall": 0.28311,
            "fmeasure": 0.28627
        },
        "rougeLsum": {
            "precision": 0.30181,
            "recall": 0.28311,
            "fmeasure": 0.28627
        },
        "nubia": {
            "semantic_relation": 1.94344,
            "contradiction": 24.59679,
            "irrelevancy": 57.34661,
            "logical_agreement": 18.0566,
            "grammar_ref": 5.17449,
            "grammar_hyp": 5.10713,
            "nubia_score": 0.24541
        },
        "meteor": 0.258632736381373,
        "bleurt": -0.5265,
        "bertscore": {
            "precision": 0.87268,
            "recall": 0.86404,
            "f1": 0.86817
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 58,
        "total_length": 986,
        "mean_pred_length": 17.0,
        "std_pred_length": 5.7625425422919125,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.5111561866125761,
        "vocab_size-1": 504,
        "unique-1": 405,
        "entropy-1": 7.844634654233381,
        "distinct-2": 0.9202586206896551,
        "vocab_size-2": 854,
        "unique-2": 815,
        "entropy-2": 9.655828972073827,
        "cond_entropy-2": 1.6719698560121337,
        "distinct-3": 0.9816091954022989,
        "vocab_size-3": 854,
        "unique-3": 845,
        "entropy-3": 9.718924270677485,
        "cond_entropy-3": 0.07657210014045243,
        "total_length-nopunct": 895,
        "mean_pred_length-nopunct": 15.431034482758621,
        "std_pred_length-nopunct": 5.37270261717546,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5575418994413408,
        "vocab_size-1-nopunct": 499,
        "unique-1-nopunct": 404,
        "entropy-1-nopunct": 7.996271576440051,
        "distinct-2-nopunct": 0.9390681003584229,
        "vocab_size-2-nopunct": 786,
        "unique-2-nopunct": 755,
        "entropy-2-nopunct": 9.559432222387745,
        "cond_entropy-2-nopunct": 1.6706270654832596,
        "distinct-3-nopunct": 0.9922978177150192,
        "vocab_size-3-nopunct": 773,
        "unique-3-nopunct": 767,
        "entropy-3-nopunct": 9.59007515349163,
        "cond_entropy-3-nopunct": 0.04178515476188005,
        "msttr-100": 0.72222,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.041031652989449004,
            "2": 0.18309859154929578,
            "3": 0.23376623376623376,
            "4": 0.3269230769230769,
            "5": 0.5027932960893855,
            "6": 0.6057347670250897,
            "7": 0.704225352112676
        },
        "nist": 6.306884489105411,
        "bleu": 54.48763,
        "rouge1": {
            "precision": 0.77798,
            "recall": 0.64101,
            "fmeasure": 0.68634
        },
        "rouge2": {
            "precision": 0.61773,
            "recall": 0.50442,
            "fmeasure": 0.54087
        },
        "rougeL": {
            "precision": 0.74779,
            "recall": 0.61998,
            "fmeasure": 0.66172
        },
        "rougeLsum": {
            "precision": 0.74779,
            "recall": 0.61998,
            "fmeasure": 0.66172
        },
        "nubia": {
            "semantic_relation": 3.89601,
            "contradiction": 8.72013,
            "irrelevancy": 19.32587,
            "logical_agreement": 71.95399,
            "grammar_ref": 4.54049,
            "grammar_hyp": 4.97201,
            "nubia_score": 0.59686
        },
        "meteor": 0.35999943467687173,
        "bleurt": -0.03996,
        "bertscore": {
            "precision": 0.9307,
            "recall": 0.90255,
            "f1": 0.91384
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-base (Baseline)/cs_restaurants_test",
        "N": 297,
        "total_length": 3445,
        "mean_pred_length": 11.599326599326599,
        "std_pred_length": 3.6280426057621122,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 22,
        "distinct-1": 0.10943396226415095,
        "vocab_size-1": 377,
        "unique-1": 166,
        "entropy-1": 6.76152508227278,
        "distinct-2": 0.3014612452350699,
        "vocab_size-2": 949,
        "unique-2": 537,
        "entropy-2": 8.667756557673075,
        "cond_entropy-2": 1.6432333679151918,
        "distinct-3": 0.46054016134689585,
        "vocab_size-3": 1313,
        "unique-3": 904,
        "entropy-3": 9.30749187682409,
        "cond_entropy-3": 0.6311157527224512,
        "total_length-nopunct": 3007,
        "mean_pred_length-nopunct": 10.124579124579125,
        "std_pred_length-nopunct": 3.3183453811583754,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.12404389757233122,
        "vocab_size-1-nopunct": 373,
        "unique-1-nopunct": 165,
        "entropy-1-nopunct": 6.958366013255698,
        "distinct-2-nopunct": 0.314760147601476,
        "vocab_size-2-nopunct": 853,
        "unique-2-nopunct": 484,
        "entropy-2-nopunct": 8.54703554597327,
        "cond_entropy-2-nopunct": 1.669198181164777,
        "distinct-3-nopunct": 0.4757563199336925,
        "vocab_size-3-nopunct": 1148,
        "unique-3-nopunct": 805,
        "entropy-3-nopunct": 9.12201710204151,
        "cond_entropy-3-nopunct": 0.6581876340867964,
        "msttr-100": 0.58853,
        "msttr-100_nopunct": 0.62567,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.47043888284367064
        },
        "nist": 3.684074411655722,
        "bleu": 16.87037,
        "rouge1": {
            "precision": 0.5254,
            "recall": 0.52933,
            "fmeasure": 0.51288
        },
        "rouge2": {
            "precision": 0.29325,
            "recall": 0.29826,
            "fmeasure": 0.28797
        },
        "rougeL": {
            "precision": 0.45854,
            "recall": 0.46245,
            "fmeasure": 0.44835
        },
        "rougeLsum": {
            "precision": 0.45854,
            "recall": 0.46245,
            "fmeasure": 0.44835
        },
        "nubia": {
            "semantic_relation": 3.48916,
            "contradiction": 16.55006,
            "irrelevancy": 37.06214,
            "logical_agreement": 46.3878,
            "grammar_ref": 6.65825,
            "grammar_hyp": 6.62282,
            "nubia_score": 0.52797
        },
        "meteor": 0.23866464980798704,
        "bleurt": -0.15175,
        "bertscore": {
            "precision": 0.89817,
            "recall": 0.89568,
            "f1": 0.89672
        }
    },
    "schema_guided_dialog_validation": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_validation",
        "N": 10000,
        "total_length": 121965,
        "mean_pred_length": 12.1965,
        "std_pred_length": 6.680949614388661,
        "median_pred_length": 10.0,
        "min_pred_length": 1,
        "max_pred_length": 32,
        "distinct-1": 0.03623170581724265,
        "vocab_size-1": 4419,
        "unique-1": 1907,
        "entropy-1": 8.199462145406358,
        "distinct-2": 0.160737730540794,
        "vocab_size-2": 17997,
        "unique-2": 9782,
        "entropy-2": 11.911208544768888,
        "cond_entropy-2": 3.4633349906645123,
        "distinct-3": 0.3392927192844814,
        "vocab_size-3": 34597,
        "unique-3": 22850,
        "entropy-3": 13.607845082913903,
        "cond_entropy-3": 1.7247171922150653,
        "total_length-nopunct": 107272,
        "mean_pred_length-nopunct": 10.7272,
        "std_pred_length-nopunct": 6.230054587240789,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.04102654933253785,
        "vocab_size-1-nopunct": 4401,
        "unique-1-nopunct": 1904,
        "entropy-1-nopunct": 8.43720728485214,
        "distinct-2-nopunct": 0.177224689530389,
        "vocab_size-2-nopunct": 17239,
        "unique-2-nopunct": 9742,
        "entropy-2-nopunct": 11.82879565121012,
        "cond_entropy-2-nopunct": 3.5525614592109243,
        "distinct-3-nopunct": 0.3653890212609971,
        "vocab_size-3-nopunct": 31897,
        "unique-3-nopunct": 21880,
        "entropy-3-nopunct": 13.501569104915827,
        "cond_entropy-3-nopunct": 1.7242268516384227,
        "msttr-100": 0.70243,
        "msttr-100_nopunct": 0.73299,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_validation.json",
        "local_recall": {
            "1": 0.6030303594017412
        },
        "nist": 7.470582589213289,
        "bleu": 35.29787,
        "rouge1": {
            "precision": 0.6119,
            "recall": 0.59777,
            "fmeasure": 0.59181
        },
        "rouge2": {
            "precision": 0.39953,
            "recall": 0.39193,
            "fmeasure": 0.38653
        },
        "rougeL": {
            "precision": 0.55491,
            "recall": 0.54251,
            "fmeasure": 0.53691
        },
        "rougeLsum": {
            "precision": 0.55491,
            "recall": 0.54251,
            "fmeasure": 0.53691
        },
        "nubia": {
            "semantic_relation": 3.78407,
            "contradiction": 4.09421,
            "irrelevancy": 20.58016,
            "logical_agreement": 75.32563,
            "grammar_ref": 4.88727,
            "grammar_hyp": 4.79501,
            "nubia_score": 0.68001
        },
        "meteor": 0.3366110755151708,
        "bleurt": -0.01099,
        "bertscore": {
            "precision": 0.88013,
            "recall": 0.87589,
            "f1": 0.87744
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 22,
        "total_length": 374,
        "mean_pred_length": 17.0,
        "std_pred_length": 5.939084716749482,
        "median_pred_length": 16.5,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.606951871657754,
        "vocab_size-1": 227,
        "unique-1": 186,
        "entropy-1": 7.1688341073096415,
        "distinct-2": 0.9403409090909091,
        "vocab_size-2": 331,
        "unique-2": 316,
        "entropy-2": 8.324460666920432,
        "cond_entropy-2": 1.01606332477463,
        "distinct-3": 0.990909090909091,
        "vocab_size-3": 327,
        "unique-3": 324,
        "entropy-3": 8.348140396064046,
        "cond_entropy-3": 0.026617186530721097,
        "total_length-nopunct": 336,
        "mean_pred_length-nopunct": 15.272727272727273,
        "std_pred_length-nopunct": 5.561080815337136,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6577380952380952,
        "vocab_size-1-nopunct": 221,
        "unique-1-nopunct": 186,
        "entropy-1-nopunct": 7.223731562387683,
        "distinct-2-nopunct": 0.9490445859872612,
        "vocab_size-2-nopunct": 298,
        "unique-2-nopunct": 288,
        "entropy-2-nopunct": 8.175162866712265,
        "cond_entropy-2-nopunct": 0.9956832397939938,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 292,
        "unique-3-nopunct": 292,
        "entropy-3-nopunct": 8.189824558880057,
        "cond_entropy-3-nopunct": 0.016812628496359033,
        "msttr-100": 0.73667,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.05,
            "2": 0.15254237288135594,
            "3": 0.25,
            "4": 0.16326530612244897,
            "5": 0.4189189189189189,
            "6": 0.5656565656565656,
            "7": 0.7678571428571429
        },
        "nist": 5.100845724355978,
        "bleu": 52.44943,
        "rouge1": {
            "precision": 0.78626,
            "recall": 0.64437,
            "fmeasure": 0.68886
        },
        "rouge2": {
            "precision": 0.60586,
            "recall": 0.48999,
            "fmeasure": 0.52683
        },
        "rougeL": {
            "precision": 0.75862,
            "recall": 0.62375,
            "fmeasure": 0.66659
        },
        "rougeLsum": {
            "precision": 0.75862,
            "recall": 0.62375,
            "fmeasure": 0.66659
        },
        "nubia": {
            "semantic_relation": 3.89003,
            "contradiction": 3.38894,
            "irrelevancy": 13.88056,
            "logical_agreement": 82.7305,
            "grammar_ref": 4.50363,
            "grammar_hyp": 4.79852,
            "nubia_score": 0.6158
        },
        "meteor": 0.3388800133783628,
        "bleurt": 0.03277,
        "bertscore": {
            "precision": 0.94161,
            "recall": 0.9106,
            "f1": 0.92369
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-base (Baseline)/cs_restaurants_test",
        "N": 86,
        "total_length": 1394,
        "mean_pred_length": 16.209302325581394,
        "std_pred_length": 3.7295684614441984,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.20588235294117646,
        "vocab_size-1": 287,
        "unique-1": 135,
        "entropy-1": 6.8269270607570185,
        "distinct-2": 0.4923547400611621,
        "vocab_size-2": 644,
        "unique-2": 434,
        "entropy-2": 8.707548082506625,
        "cond_entropy-2": 1.719563000187099,
        "distinct-3": 0.6620294599018003,
        "vocab_size-3": 809,
        "unique-3": 634,
        "entropy-3": 9.259318831439952,
        "cond_entropy-3": 0.5522536960858031,
        "total_length-nopunct": 1232,
        "mean_pred_length-nopunct": 14.325581395348838,
        "std_pred_length-nopunct": 3.3146674057613468,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.2305194805194805,
        "vocab_size-1-nopunct": 284,
        "unique-1-nopunct": 135,
        "entropy-1-nopunct": 6.996621814535346,
        "distinct-2-nopunct": 0.5069808027923212,
        "vocab_size-2-nopunct": 581,
        "unique-2-nopunct": 391,
        "entropy-2-nopunct": 8.607671731271974,
        "cond_entropy-2-nopunct": 1.6848436498235428,
        "distinct-3-nopunct": 0.6867924528301886,
        "vocab_size-3-nopunct": 728,
        "unique-3-nopunct": 574,
        "entropy-3-nopunct": 9.158600091892994,
        "cond_entropy-3-nopunct": 0.5448134282119718,
        "msttr-100": 0.61,
        "msttr-100_nopunct": 0.66333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.4699619771863118
        },
        "nist": 3.989839953032706,
        "bleu": 17.87034,
        "rouge1": {
            "precision": 0.57586,
            "recall": 0.52412,
            "fmeasure": 0.54083
        },
        "rouge2": {
            "precision": 0.31791,
            "recall": 0.28939,
            "fmeasure": 0.29803
        },
        "rougeL": {
            "precision": 0.47819,
            "recall": 0.43295,
            "fmeasure": 0.44795
        },
        "rougeLsum": {
            "precision": 0.47819,
            "recall": 0.43295,
            "fmeasure": 0.44795
        },
        "nubia": {
            "semantic_relation": 3.32606,
            "contradiction": 15.72772,
            "irrelevancy": 22.90126,
            "logical_agreement": 61.37102,
            "grammar_ref": 6.22337,
            "grammar_hyp": 6.22159,
            "nubia_score": 0.53387
        },
        "meteor": 0.2345136373543041,
        "bleurt": -0.0561,
        "bertscore": {
            "precision": 0.91897,
            "recall": 0.91248,
            "f1": 0.91559
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 414,
        "total_length": 7624,
        "mean_pred_length": 18.415458937198068,
        "std_pred_length": 4.80502481124912,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.15005246589716684,
        "vocab_size-1": 1144,
        "unique-1": 463,
        "entropy-1": 8.005406138604961,
        "distinct-2": 0.40540915395284327,
        "vocab_size-2": 2923,
        "unique-2": 1763,
        "entropy-2": 10.71760909747717,
        "cond_entropy-2": 2.568537825268271,
        "distinct-3": 0.5990288404944085,
        "vocab_size-3": 4071,
        "unique-3": 2964,
        "entropy-3": 11.548252985158282,
        "cond_entropy-3": 0.9043700632029188,
        "total_length-nopunct": 6844,
        "mean_pred_length-nopunct": 16.531400966183575,
        "std_pred_length-nopunct": 4.4708102637111935,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.16598480420806547,
        "vocab_size-1-nopunct": 1136,
        "unique-1-nopunct": 462,
        "entropy-1-nopunct": 8.208623414902922,
        "distinct-2-nopunct": 0.4031104199066874,
        "vocab_size-2-nopunct": 2592,
        "unique-2-nopunct": 1583,
        "entropy-2-nopunct": 10.531493665132954,
        "cond_entropy-2-nopunct": 2.4901989031743046,
        "distinct-3-nopunct": 0.5955784574468085,
        "vocab_size-3-nopunct": 3583,
        "unique-3-nopunct": 2624,
        "entropy-3-nopunct": 11.347992283030605,
        "cond_entropy-3-nopunct": 0.8804169762774815,
        "msttr-100": 0.52224,
        "msttr-100_nopunct": 0.53397,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.20744529695936345,
            "2": 0.5816172777498745,
            "3": 0.86828025477707,
            "4": 0.7272727272727273,
            "5": 1.0
        },
        "nist": 8.986724861027199,
        "bleu": 51.46168,
        "rouge1": {
            "precision": 0.78421,
            "recall": 0.75097,
            "fmeasure": 0.75985
        },
        "rouge2": {
            "precision": 0.54535,
            "recall": 0.52108,
            "fmeasure": 0.52663
        },
        "rougeL": {
            "precision": 0.66371,
            "recall": 0.63541,
            "fmeasure": 0.64214
        },
        "rougeLsum": {
            "precision": 0.66371,
            "recall": 0.63541,
            "fmeasure": 0.64214
        },
        "nubia": {
            "semantic_relation": 4.46109,
            "contradiction": 8.5921,
            "irrelevancy": 8.62982,
            "logical_agreement": 82.77808,
            "grammar_ref": 4.63681,
            "grammar_hyp": 4.73316,
            "nubia_score": 0.77931
        },
        "meteor": 0.3971198595295394,
        "bleurt": 0.20723,
        "bertscore": {
            "precision": 0.93146,
            "recall": 0.92546,
            "f1": 0.92686
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation_parent": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 6165,
        "mean_pred_length": 17.172701949860723,
        "std_pred_length": 6.145699059785652,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.3772911597729116,
        "vocab_size-1": 2326,
        "unique-1": 1733,
        "entropy-1": 9.077575132617426,
        "distinct-2": 0.83861522562866,
        "vocab_size-2": 4869,
        "unique-2": 4517,
        "entropy-2": 11.942408546717669,
        "cond_entropy-2": 2.689547949982116,
        "distinct-3": 0.965669175693042,
        "vocab_size-3": 5260,
        "unique-3": 5169,
        "entropy-3": 12.295947924068003,
        "cond_entropy-3": 0.37620181953121684,
        "total_length-nopunct": 5505,
        "mean_pred_length-nopunct": 15.334261838440112,
        "std_pred_length-nopunct": 5.655841897975462,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4201634877384196,
        "vocab_size-1-nopunct": 2313,
        "unique-1-nopunct": 1730,
        "entropy-1-nopunct": 9.359233858545359,
        "distinct-2-nopunct": 0.8608628060629615,
        "vocab_size-2-nopunct": 4430,
        "unique-2-nopunct": 4135,
        "entropy-2-nopunct": 11.868219550916795,
        "cond_entropy-2-nopunct": 2.659361395204831,
        "distinct-3-nopunct": 0.9826613745560894,
        "vocab_size-3-nopunct": 4704,
        "unique-3-nopunct": 4633,
        "entropy-3-nopunct": 12.187748308605366,
        "cond_entropy-3-nopunct": 0.3455766021230233,
        "msttr-100": 0.73377,
        "msttr-100_nopunct": 0.76345,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.02682837192208747,
            "2": 0.14690026954177898,
            "3": 0.3,
            "4": 0.4724770642201835,
            "5": 0.5250379362670713,
            "6": 0.6169014084507042,
            "7": 0.6762295081967213,
            "8": 0.7310012062726177,
            "9": 0.7915343915343915,
            "10": 0.8713178294573644
        },
        "nist": 12.365759009195251,
        "bleu": 78.74022,
        "rouge1": {
            "precision": 0.86093,
            "recall": 0.78861,
            "fmeasure": 0.81145
        },
        "rouge2": {
            "precision": 0.74743,
            "recall": 0.67594,
            "fmeasure": 0.69738
        },
        "rougeL": {
            "precision": 0.83942,
            "recall": 0.77122,
            "fmeasure": 0.79268
        },
        "rougeLsum": {
            "precision": 0.83942,
            "recall": 0.77122,
            "fmeasure": 0.79268
        },
        "nubia": {
            "semantic_relation": 3.98836,
            "contradiction": 4.23361,
            "irrelevancy": 30.66105,
            "logical_agreement": 65.10535,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.8726,
            "nubia_score": 0.60978
        },
        "meteor": 0.4522843957100267,
        "bleurt": 0.09688,
        "bertscore": {
            "precision": 0.95755,
            "recall": 0.94529,
            "f1": 0.94713
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 200,
        "total_length": 2326,
        "mean_pred_length": 11.63,
        "std_pred_length": 2.2678403823902595,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 18,
        "distinct-1": 0.41444539982803097,
        "vocab_size-1": 964,
        "unique-1": 650,
        "entropy-1": 8.569966294753325,
        "distinct-2": 0.7587017873941675,
        "vocab_size-2": 1613,
        "unique-2": 1335,
        "entropy-2": 10.404544395310204,
        "cond_entropy-2": 1.8090211803301663,
        "distinct-3": 0.9029075804776739,
        "vocab_size-3": 1739,
        "unique-3": 1586,
        "entropy-3": 10.70051336169796,
        "cond_entropy-3": 0.34188534939472565,
        "total_length-nopunct": 1987,
        "mean_pred_length-nopunct": 9.935,
        "std_pred_length-nopunct": 1.9080814972112694,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.4821338701560141,
        "vocab_size-1-nopunct": 958,
        "unique-1-nopunct": 649,
        "entropy-1-nopunct": 8.993383235215505,
        "distinct-2-nopunct": 0.7946278679350868,
        "vocab_size-2-nopunct": 1420,
        "unique-2-nopunct": 1212,
        "entropy-2-nopunct": 10.267560958063111,
        "cond_entropy-2-nopunct": 1.395799928940019,
        "distinct-3-nopunct": 0.9143037177063642,
        "vocab_size-3-nopunct": 1451,
        "unique-3-nopunct": 1343,
        "entropy-3-nopunct": 10.443597008961596,
        "cond_entropy-3-nopunct": 0.22569751415779774,
        "msttr-100": 0.78696,
        "msttr-100_nopunct": 0.84737,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.19990224828934505,
            "2": 0.4586693548387097,
            "3": 0.6853055916775033,
            "4": 0.75,
            "5": 0.7307692307692307,
            "6": 0.6666666666666666,
            "7": 1.0
        },
        "nist": 5.763918592448674,
        "bleu": 35.96935,
        "rouge1": {
            "precision": 0.27592,
            "recall": 0.25735,
            "fmeasure": 0.26277
        },
        "rouge2": {
            "precision": 0.12753,
            "recall": 0.11915,
            "fmeasure": 0.12125
        },
        "rougeL": {
            "precision": 0.262,
            "recall": 0.24472,
            "fmeasure": 0.24956
        },
        "rougeLsum": {
            "precision": 0.262,
            "recall": 0.24472,
            "fmeasure": 0.24956
        },
        "nubia": {
            "semantic_relation": 3.70828,
            "contradiction": 20.45475,
            "irrelevancy": 23.94173,
            "logical_agreement": 55.60352,
            "grammar_ref": 2.7039,
            "grammar_hyp": 2.72956,
            "nubia_score": 0.73967
        },
        "meteor": 0.5213270834680681,
        "bleurt": 0.12476,
        "bertscore": {
            "precision": 0.95394,
            "recall": 0.93293,
            "f1": 0.94229
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 986,
        "total_length": 11042,
        "mean_pred_length": 11.198782961460447,
        "std_pred_length": 2.864243886638106,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 19,
        "distinct-1": 0.21563122622713277,
        "vocab_size-1": 2381,
        "unique-1": 1241,
        "entropy-1": 9.089720585577144,
        "distinct-2": 0.5052704852824185,
        "vocab_size-2": 5081,
        "unique-2": 3496,
        "entropy-2": 11.629237323749951,
        "cond_entropy-2": 2.579258900257856,
        "distinct-3": 0.7002205071664829,
        "vocab_size-3": 6351,
        "unique-3": 5027,
        "entropy-3": 12.331272973650972,
        "cond_entropy-3": 0.8109844150296763,
        "total_length-nopunct": 9362,
        "mean_pred_length-nopunct": 9.494929006085192,
        "std_pred_length-nopunct": 2.480445766763792,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.2534714804528947,
        "vocab_size-1-nopunct": 2373,
        "unique-1-nopunct": 1241,
        "entropy-1-nopunct": 9.630497769663487,
        "distinct-2-nopunct": 0.5558739255014327,
        "vocab_size-2-nopunct": 4656,
        "unique-2-nopunct": 3373,
        "entropy-2-nopunct": 11.57924429399687,
        "cond_entropy-2-nopunct": 2.1557756466363163,
        "distinct-3-nopunct": 0.7313937753721245,
        "vocab_size-3-nopunct": 5405,
        "unique-3-nopunct": 4423,
        "entropy-3-nopunct": 12.116472403455035,
        "cond_entropy-3-nopunct": 0.6653626788344956,
        "msttr-100": 0.66645,
        "msttr-100_nopunct": 0.71108,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.16738863914997956,
            "2": 0.35862283844835646,
            "3": 0.5016884761502743,
            "4": 0.7012987012987013,
            "5": 0.7567567567567568,
            "6": 0.8461538461538461,
            "7": 1.0
        },
        "nist": 1.794449111647902,
        "bleu": 22.98282,
        "rouge1": {
            "precision": 0.3124,
            "recall": 0.25565,
            "fmeasure": 0.27164
        },
        "rouge2": {
            "precision": 0.14753,
            "recall": 0.11521,
            "fmeasure": 0.12357
        },
        "rougeL": {
            "precision": 0.30425,
            "recall": 0.24862,
            "fmeasure": 0.26418
        },
        "rougeLsum": {
            "precision": 0.30425,
            "recall": 0.24862,
            "fmeasure": 0.26418
        },
        "nubia": {
            "semantic_relation": 3.61748,
            "contradiction": 21.41078,
            "irrelevancy": 22.56941,
            "logical_agreement": 56.01981,
            "grammar_ref": 2.66553,
            "grammar_hyp": 2.73895,
            "nubia_score": 0.70388
        },
        "meteor": 0.4105248251036844,
        "bleurt": 0.11595,
        "bertscore": {
            "precision": 0.95181,
            "recall": 0.91623,
            "f1": 0.93278
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02_parent": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 6165,
        "mean_pred_length": 17.172701949860723,
        "std_pred_length": 6.145699059785652,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.3772911597729116,
        "vocab_size-1": 2326,
        "unique-1": 1733,
        "entropy-1": 9.077575132617426,
        "distinct-2": 0.83861522562866,
        "vocab_size-2": 4869,
        "unique-2": 4517,
        "entropy-2": 11.942408546717669,
        "cond_entropy-2": 2.689547949982116,
        "distinct-3": 0.965669175693042,
        "vocab_size-3": 5260,
        "unique-3": 5169,
        "entropy-3": 12.295947924068003,
        "cond_entropy-3": 0.37620181953121684,
        "total_length-nopunct": 5505,
        "mean_pred_length-nopunct": 15.334261838440112,
        "std_pred_length-nopunct": 5.655841897975462,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4201634877384196,
        "vocab_size-1-nopunct": 2313,
        "unique-1-nopunct": 1730,
        "entropy-1-nopunct": 9.359233858545359,
        "distinct-2-nopunct": 0.8608628060629615,
        "vocab_size-2-nopunct": 4430,
        "unique-2-nopunct": 4135,
        "entropy-2-nopunct": 11.868219550916795,
        "cond_entropy-2-nopunct": 2.659361395204831,
        "distinct-3-nopunct": 0.9826613745560894,
        "vocab_size-3-nopunct": 4704,
        "unique-3-nopunct": 4633,
        "entropy-3-nopunct": 12.187748308605366,
        "cond_entropy-3-nopunct": 0.3455766021230233,
        "msttr-100": 0.73377,
        "msttr-100_nopunct": 0.76345,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.02682837192208747,
            "2": 0.14690026954177898,
            "3": 0.3,
            "4": 0.4724770642201835,
            "5": 0.5250379362670713,
            "6": 0.6169014084507042,
            "7": 0.6762295081967213,
            "8": 0.7310012062726177,
            "9": 0.7915343915343915,
            "10": 0.8713178294573644
        },
        "nist": 12.365759009195251,
        "bleu": 78.74022,
        "rouge1": {
            "precision": 0.86093,
            "recall": 0.78861,
            "fmeasure": 0.81145
        },
        "rouge2": {
            "precision": 0.74743,
            "recall": 0.67594,
            "fmeasure": 0.69738
        },
        "rougeL": {
            "precision": 0.83942,
            "recall": 0.77122,
            "fmeasure": 0.79268
        },
        "rougeLsum": {
            "precision": 0.83942,
            "recall": 0.77122,
            "fmeasure": 0.79268
        },
        "nubia": {
            "semantic_relation": 3.98836,
            "contradiction": 4.23361,
            "irrelevancy": 30.66105,
            "logical_agreement": 65.10535,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.8726,
            "nubia_score": 0.60978
        },
        "meteor": 0.4522843957100267,
        "bleurt": 0.09688,
        "bertscore": {
            "precision": 0.95755,
            "recall": 0.94529,
            "f1": 0.94713
        }
    },
    "mlsum_es_validation": {
        "predictions_file": "ByT5-base (Baseline)/mlsum_es_validation",
        "N": 9977,
        "total_length": 199242,
        "mean_pred_length": 19.970131301994588,
        "std_pred_length": 3.7185094772076663,
        "median_pred_length": 20.0,
        "min_pred_length": 7,
        "max_pred_length": 36,
        "distinct-1": 0.12385942722919867,
        "vocab_size-1": 24678,
        "unique-1": 14118,
        "entropy-1": 9.953913724589142,
        "distinct-2": 0.4992418038200407,
        "vocab_size-2": 94489,
        "unique-2": 74599,
        "entropy-2": 15.10166673949667,
        "cond_entropy-2": 5.339008314870795,
        "distinct-3": 0.8146892151175762,
        "vocab_size-3": 146064,
        "unique-3": 132553,
        "entropy-3": 16.850612729541904,
        "cond_entropy-3": 1.805832304912576,
        "total_length-nopunct": 193320,
        "mean_pred_length-nopunct": 19.37656610203468,
        "std_pred_length-nopunct": 3.403684735099633,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.1275553486447341,
        "vocab_size-1-nopunct": 24659,
        "unique-1-nopunct": 14115,
        "entropy-1-nopunct": 10.000395689959335,
        "distinct-2-nopunct": 0.5075732370475011,
        "vocab_size-2-nopunct": 93060,
        "unique-2-nopunct": 73878,
        "entropy-2-nopunct": 15.105359568478423,
        "cond_entropy-2-nopunct": 5.304981761919779,
        "distinct-3-nopunct": 0.8192263765674931,
        "vocab_size-3-nopunct": 142026,
        "unique-3-nopunct": 129264,
        "entropy-3-nopunct": 16.81709275407305,
        "cond_entropy-3-nopunct": 1.7686049533601953,
        "msttr-100": 0.7025,
        "msttr-100_nopunct": 0.70355,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_validation.json",
        "local_recall": {
            "1": 0.2748603466163761
        },
        "nist": 3.0631826887972036,
        "bleu": 9.08555,
        "rouge1": {
            "precision": 0.32647,
            "recall": 0.29543,
            "fmeasure": 0.30204
        },
        "rouge2": {
            "precision": 0.13157,
            "recall": 0.12009,
            "fmeasure": 0.12227
        },
        "rougeL": {
            "precision": 0.26403,
            "recall": 0.24077,
            "fmeasure": 0.24527
        },
        "rougeLsum": {
            "precision": 0.26403,
            "recall": 0.24077,
            "fmeasure": 0.24527
        },
        "nubia": {
            "semantic_relation": 1.7489,
            "contradiction": 27.52712,
            "irrelevancy": 59.59412,
            "logical_agreement": 12.87876,
            "grammar_ref": 5.2776,
            "grammar_hyp": 5.20987,
            "nubia_score": 0.19893
        },
        "meteor": 0.21847053423268106,
        "bleurt": -0.4143,
        "bertscore": {
            "precision": 0.84497,
            "recall": 0.83795,
            "f1": 0.84127
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 382,
        "total_length": 8394,
        "mean_pred_length": 21.973821989528794,
        "std_pred_length": 3.7624968803435563,
        "median_pred_length": 23.0,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.1310459852275435,
        "vocab_size-1": 1100,
        "unique-1": 373,
        "entropy-1": 7.979147854189347,
        "distinct-2": 0.3706939590614079,
        "vocab_size-2": 2970,
        "unique-2": 1690,
        "entropy-2": 10.698209948528637,
        "cond_entropy-2": 2.686274794111559,
        "distinct-3": 0.5647444298820445,
        "vocab_size-3": 4309,
        "unique-3": 3036,
        "entropy-3": 11.593596256684652,
        "cond_entropy-3": 0.9667265532038275,
        "total_length-nopunct": 7628,
        "mean_pred_length-nopunct": 19.968586387434556,
        "std_pred_length-nopunct": 3.699307645937431,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.14315679077084426,
        "vocab_size-1-nopunct": 1092,
        "unique-1-nopunct": 373,
        "entropy-1-nopunct": 8.13872798234562,
        "distinct-2-nopunct": 0.38007176373171403,
        "vocab_size-2-nopunct": 2754,
        "unique-2-nopunct": 1637,
        "entropy-2-nopunct": 10.594357634046538,
        "cond_entropy-2-nopunct": 2.602199946692028,
        "distinct-3-nopunct": 0.5697843822843823,
        "vocab_size-3-nopunct": 3911,
        "unique-3-nopunct": 2806,
        "entropy-3-nopunct": 11.44713214779311,
        "cond_entropy-3-nopunct": 0.9159347009663114,
        "msttr-100": 0.50711,
        "msttr-100_nopunct": 0.50342,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.19646854016413828,
            "2": 0.5151909722222222,
            "3": 0.7959007551240561,
            "4": 0.6666666666666666,
            "5": 0.7142857142857143
        },
        "nist": 7.755167918218445,
        "bleu": 41.86998,
        "rouge1": {
            "precision": 0.76264,
            "recall": 0.69051,
            "fmeasure": 0.71562
        },
        "rouge2": {
            "precision": 0.4961,
            "recall": 0.44352,
            "fmeasure": 0.46145
        },
        "rougeL": {
            "precision": 0.60317,
            "recall": 0.54354,
            "fmeasure": 0.56403
        },
        "rougeLsum": {
            "precision": 0.60317,
            "recall": 0.54354,
            "fmeasure": 0.56403
        },
        "nubia": {
            "semantic_relation": 4.15304,
            "contradiction": 8.51376,
            "irrelevancy": 11.3929,
            "logical_agreement": 80.09334,
            "grammar_ref": 4.39371,
            "grammar_hyp": 4.6072,
            "nubia_score": 0.68043
        },
        "meteor": 0.3489671664988887,
        "bleurt": 0.03015,
        "bertscore": {
            "precision": 0.91412,
            "recall": 0.89917,
            "f1": 0.90476
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 32,
        "total_length": 387,
        "mean_pred_length": 12.09375,
        "std_pred_length": 2.1412521891407374,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 16,
        "distinct-1": 0.43669250645994834,
        "vocab_size-1": 169,
        "unique-1": 95,
        "entropy-1": 6.716103877221094,
        "distinct-2": 0.6901408450704225,
        "vocab_size-2": 245,
        "unique-2": 179,
        "entropy-2": 7.724248225657442,
        "cond_entropy-2": 1.140780778094027,
        "distinct-3": 0.8080495356037152,
        "vocab_size-3": 261,
        "unique-3": 213,
        "entropy-3": 7.9172521193194525,
        "cond_entropy-3": 0.2546684869731975,
        "total_length-nopunct": 338,
        "mean_pred_length-nopunct": 10.5625,
        "std_pred_length-nopunct": 1.9515618744994994,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.48520710059171596,
        "vocab_size-1-nopunct": 164,
        "unique-1-nopunct": 95,
        "entropy-1-nopunct": 6.811331797831576,
        "distinct-2-nopunct": 0.7026143790849673,
        "vocab_size-2-nopunct": 215,
        "unique-2-nopunct": 162,
        "entropy-2-nopunct": 7.532463640089835,
        "cond_entropy-2-nopunct": 0.8470327390802138,
        "distinct-3-nopunct": 0.8102189781021898,
        "vocab_size-3-nopunct": 222,
        "unique-3-nopunct": 183,
        "entropy-3-nopunct": 7.680865066450281,
        "cond_entropy-3-nopunct": 0.2184655668104723,
        "msttr-100": 0.66667,
        "msttr-100_nopunct": 0.64,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.0896551724137931,
            "2": 0.19015659955257272,
            "3": 0.36741214057507987
        },
        "nist": 0.018801785481883788,
        "bleu": 6.3204,
        "rouge1": {
            "precision": 0.47917,
            "recall": 0.27912,
            "fmeasure": 0.33703
        },
        "rouge2": {
            "precision": 0.23958,
            "recall": 0.12309,
            "fmeasure": 0.1463
        },
        "rougeL": {
            "precision": 0.47917,
            "recall": 0.27912,
            "fmeasure": 0.33703
        },
        "rougeLsum": {
            "precision": 0.47917,
            "recall": 0.27912,
            "fmeasure": 0.33703
        },
        "nubia": {
            "semantic_relation": 3.12974,
            "contradiction": 22.75836,
            "irrelevancy": 24.63481,
            "logical_agreement": 52.60683,
            "grammar_ref": 2.45871,
            "grammar_hyp": 2.67819,
            "nubia_score": 0.59125
        },
        "meteor": 0.2641957074940569,
        "bleurt": 0.00742,
        "bertscore": {
            "precision": 0.93863,
            "recall": 0.85777,
            "f1": 0.89583
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 124,
        "total_length": 2818,
        "mean_pred_length": 22.725806451612904,
        "std_pred_length": 4.102199861595544,
        "median_pred_length": 23.0,
        "min_pred_length": 8,
        "max_pred_length": 34,
        "distinct-1": 0.44570617459190914,
        "vocab_size-1": 1256,
        "unique-1": 988,
        "entropy-1": 8.634391391230361,
        "distinct-2": 0.8466963622865628,
        "vocab_size-2": 2281,
        "unique-2": 2101,
        "entropy-2": 10.905524573227517,
        "cond_entropy-2": 2.2378656665499896,
        "distinct-3": 0.9696498054474708,
        "vocab_size-3": 2492,
        "unique-3": 2430,
        "entropy-3": 11.261247730464506,
        "cond_entropy-3": 0.3693735407826336,
        "total_length-nopunct": 2511,
        "mean_pred_length-nopunct": 20.25,
        "std_pred_length-nopunct": 3.811326498401751,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4962166467542812,
        "vocab_size-1-nopunct": 1246,
        "unique-1-nopunct": 987,
        "entropy-1-nopunct": 8.86946992796876,
        "distinct-2-nopunct": 0.8734813573523251,
        "vocab_size-2-nopunct": 2085,
        "unique-2-nopunct": 1952,
        "entropy-2-nopunct": 10.807733076291141,
        "cond_entropy-2-nopunct": 2.0189282687874326,
        "distinct-3-nopunct": 0.9761378700839594,
        "vocab_size-3-nopunct": 2209,
        "unique-3-nopunct": 2168,
        "entropy-3-nopunct": 11.091149132416916,
        "cond_entropy-3-nopunct": 0.2950197971252956,
        "msttr-100": 0.72214,
        "msttr-100_nopunct": 0.7564,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18840579710144928,
            "2": 0.39503386004514673,
            "3": 0.6781376518218624
        },
        "nist": 6.715841941018298,
        "bleu": 32.31989,
        "rouge1": {
            "precision": 0.71054,
            "recall": 0.64067,
            "fmeasure": 0.66409
        },
        "rouge2": {
            "precision": 0.42718,
            "recall": 0.39388,
            "fmeasure": 0.4025
        },
        "rougeL": {
            "precision": 0.56765,
            "recall": 0.51783,
            "fmeasure": 0.53313
        },
        "rougeLsum": {
            "precision": 0.56765,
            "recall": 0.51783,
            "fmeasure": 0.53313
        },
        "nubia": {
            "semantic_relation": 3.8463,
            "contradiction": 10.30998,
            "irrelevancy": 36.91492,
            "logical_agreement": 52.7751,
            "grammar_ref": 4.3248,
            "grammar_hyp": 4.50012,
            "nubia_score": 0.60337
        },
        "meteor": 0.3194504038532196,
        "bleurt": -0.01609,
        "bertscore": {
            "precision": 0.90929,
            "recall": 0.89541,
            "f1": 0.90053
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 116,
        "total_length": 1464,
        "mean_pred_length": 12.620689655172415,
        "std_pred_length": 2.384053243785325,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 21,
        "distinct-1": 0.366120218579235,
        "vocab_size-1": 536,
        "unique-1": 327,
        "entropy-1": 7.902949605451961,
        "distinct-2": 0.6565281899109793,
        "vocab_size-2": 885,
        "unique-2": 660,
        "entropy-2": 9.447090425288204,
        "cond_entropy-2": 1.6681663929962072,
        "distinct-3": 0.8027597402597403,
        "vocab_size-3": 989,
        "unique-3": 824,
        "entropy-3": 9.80476708051635,
        "cond_entropy-3": 0.43557741844432096,
        "total_length-nopunct": 1256,
        "mean_pred_length-nopunct": 10.827586206896552,
        "std_pred_length-nopunct": 2.1386261383911283,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.42197452229299365,
        "vocab_size-1-nopunct": 530,
        "unique-1-nopunct": 326,
        "entropy-1-nopunct": 8.22922059113287,
        "distinct-2-nopunct": 0.6929824561403509,
        "vocab_size-2-nopunct": 790,
        "unique-2-nopunct": 601,
        "entropy-2-nopunct": 9.34659576048721,
        "cond_entropy-2-nopunct": 1.256066712389401,
        "distinct-3-nopunct": 0.828125,
        "vocab_size-3-nopunct": 848,
        "unique-3-nopunct": 729,
        "entropy-3-nopunct": 9.595693008372542,
        "cond_entropy-3-nopunct": 0.32469680104028054,
        "msttr-100": 0.63714,
        "msttr-100_nopunct": 0.68,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.14808558558558557,
            "2": 0.3561320754716981,
            "3": 0.5136876006441223
        },
        "nist": 1.2253677983028728,
        "bleu": 19.56052,
        "rouge1": {
            "precision": 0.06609,
            "recall": 0.05747,
            "fmeasure": 0.06034
        },
        "rouge2": {
            "precision": 0.01293,
            "recall": 0.01293,
            "fmeasure": 0.01293
        },
        "rougeL": {
            "precision": 0.06609,
            "recall": 0.05747,
            "fmeasure": 0.06034
        },
        "rougeLsum": {
            "precision": 0.06609,
            "recall": 0.05747,
            "fmeasure": 0.06034
        },
        "nubia": {
            "semantic_relation": 3.52375,
            "contradiction": 23.60331,
            "irrelevancy": 22.28998,
            "logical_agreement": 54.10671,
            "grammar_ref": 2.53819,
            "grammar_hyp": 2.64803,
            "nubia_score": 0.66732
        },
        "meteor": 0.352427517114738,
        "bleurt": 0.00064,
        "bertscore": {
            "precision": 0.94424,
            "recall": 0.90005,
            "f1": 0.92095
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05_parent": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 6165,
        "mean_pred_length": 17.172701949860723,
        "std_pred_length": 6.145699059785652,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.3772911597729116,
        "vocab_size-1": 2326,
        "unique-1": 1733,
        "entropy-1": 9.077575132617426,
        "distinct-2": 0.83861522562866,
        "vocab_size-2": 4869,
        "unique-2": 4517,
        "entropy-2": 11.942408546717669,
        "cond_entropy-2": 2.689547949982116,
        "distinct-3": 0.965669175693042,
        "vocab_size-3": 5260,
        "unique-3": 5169,
        "entropy-3": 12.295947924068003,
        "cond_entropy-3": 0.37620181953121684,
        "total_length-nopunct": 5505,
        "mean_pred_length-nopunct": 15.334261838440112,
        "std_pred_length-nopunct": 5.655841897975462,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4201634877384196,
        "vocab_size-1-nopunct": 2313,
        "unique-1-nopunct": 1730,
        "entropy-1-nopunct": 9.359233858545359,
        "distinct-2-nopunct": 0.8608628060629615,
        "vocab_size-2-nopunct": 4430,
        "unique-2-nopunct": 4135,
        "entropy-2-nopunct": 11.868219550916795,
        "cond_entropy-2-nopunct": 2.659361395204831,
        "distinct-3-nopunct": 0.9826613745560894,
        "vocab_size-3-nopunct": 4704,
        "unique-3-nopunct": 4633,
        "entropy-3-nopunct": 12.187748308605366,
        "cond_entropy-3-nopunct": 0.3455766021230233,
        "msttr-100": 0.73377,
        "msttr-100_nopunct": 0.76345,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.02682837192208747,
            "2": 0.14690026954177898,
            "3": 0.3,
            "4": 0.4724770642201835,
            "5": 0.5250379362670713,
            "6": 0.6169014084507042,
            "7": 0.6762295081967213,
            "8": 0.7310012062726177,
            "9": 0.7915343915343915,
            "10": 0.8713178294573644
        },
        "nist": 12.365759009195251,
        "bleu": 78.74022,
        "rouge1": {
            "precision": 0.86093,
            "recall": 0.78861,
            "fmeasure": 0.81145
        },
        "rouge2": {
            "precision": 0.74743,
            "recall": 0.67594,
            "fmeasure": 0.69738
        },
        "rougeL": {
            "precision": 0.83942,
            "recall": 0.77122,
            "fmeasure": 0.79268
        },
        "rougeLsum": {
            "precision": 0.83942,
            "recall": 0.77122,
            "fmeasure": 0.79268
        },
        "nubia": {
            "semantic_relation": 3.98836,
            "contradiction": 4.23361,
            "irrelevancy": 30.66105,
            "logical_agreement": 65.10535,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.8726,
            "nubia_score": 0.60978
        },
        "meteor": 0.4522843957100267,
        "bleurt": 0.09688,
        "bertscore": {
            "precision": 0.95755,
            "recall": 0.94529,
            "f1": 0.94713
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 128,
        "total_length": 3091,
        "mean_pred_length": 24.1484375,
        "std_pred_length": 4.027425208317809,
        "median_pred_length": 25.0,
        "min_pred_length": 7,
        "max_pred_length": 35,
        "distinct-1": 0.4115173083144613,
        "vocab_size-1": 1272,
        "unique-1": 1000,
        "entropy-1": 8.482530791788902,
        "distinct-2": 0.7873776577792777,
        "vocab_size-2": 2333,
        "unique-2": 2134,
        "entropy-2": 10.788843885938157,
        "cond_entropy-2": 2.3137886605765896,
        "distinct-3": 0.9125220458553792,
        "vocab_size-3": 2587,
        "unique-3": 2504,
        "entropy-3": 11.183286640106235,
        "cond_entropy-3": 0.41697091897360083,
        "total_length-nopunct": 2697,
        "mean_pred_length-nopunct": 21.0703125,
        "std_pred_length-nopunct": 3.4418917258309785,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.4682981090100111,
        "vocab_size-1-nopunct": 1263,
        "unique-1-nopunct": 998,
        "entropy-1-nopunct": 8.768268862233732,
        "distinct-2-nopunct": 0.8170494355780459,
        "vocab_size-2-nopunct": 2099,
        "unique-2-nopunct": 1943,
        "entropy-2-nopunct": 10.691717006507798,
        "cond_entropy-2-nopunct": 1.9941785987048457,
        "distinct-3-nopunct": 0.9274887341253585,
        "vocab_size-3-nopunct": 2264,
        "unique-3-nopunct": 2204,
        "entropy-3-nopunct": 11.01340329923331,
        "cond_entropy-3-nopunct": 0.34800267042247807,
        "msttr-100": 0.70467,
        "msttr-100_nopunct": 0.73769,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21315192743764172,
            "2": 0.4186046511627907,
            "3": 0.653968253968254
        },
        "nist": 5.994544894752811,
        "bleu": 35.1216,
        "rouge1": {
            "precision": 0.72685,
            "recall": 0.60811,
            "fmeasure": 0.64908
        },
        "rouge2": {
            "precision": 0.48672,
            "recall": 0.39363,
            "fmeasure": 0.42516
        },
        "rougeL": {
            "precision": 0.59188,
            "recall": 0.49407,
            "fmeasure": 0.52569
        },
        "rougeLsum": {
            "precision": 0.59188,
            "recall": 0.49407,
            "fmeasure": 0.52569
        },
        "nubia": {
            "semantic_relation": 3.60221,
            "contradiction": 14.42616,
            "irrelevancy": 29.8193,
            "logical_agreement": 55.75454,
            "grammar_ref": 4.11595,
            "grammar_hyp": 4.32928,
            "nubia_score": 0.52906
        },
        "meteor": 0.3155732412690857,
        "bleurt": -0.08422,
        "bertscore": {
            "precision": 0.90737,
            "recall": 0.89068,
            "f1": 0.89766
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 642,
        "total_length": 6941,
        "mean_pred_length": 10.811526479750778,
        "std_pred_length": 3.048975800674621,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 19,
        "distinct-1": 0.26365077078230803,
        "vocab_size-1": 1830,
        "unique-1": 1003,
        "entropy-1": 9.004005343441039,
        "distinct-2": 0.5862835370693761,
        "vocab_size-2": 3693,
        "unique-2": 2678,
        "entropy-2": 11.36160916583398,
        "cond_entropy-2": 2.2852481002168052,
        "distinct-3": 0.7691355842319251,
        "vocab_size-3": 4351,
        "unique-3": 3617,
        "entropy-3": 11.86828792306892,
        "cond_entropy-3": 0.5797806689679907,
        "total_length-nopunct": 5887,
        "mean_pred_length-nopunct": 9.169781931464174,
        "std_pred_length-nopunct": 2.7041256611103335,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.30949549855614067,
        "vocab_size-1-nopunct": 1822,
        "unique-1-nopunct": 1003,
        "entropy-1-nopunct": 9.512996337702848,
        "distinct-2-nopunct": 0.6236415633937082,
        "vocab_size-2-nopunct": 3271,
        "unique-2-nopunct": 2472,
        "entropy-2-nopunct": 11.224443218355733,
        "cond_entropy-2-nopunct": 1.891005436327603,
        "distinct-3-nopunct": 0.7912231153595481,
        "vocab_size-3-nopunct": 3642,
        "unique-3-nopunct": 3098,
        "entropy-3-nopunct": 11.624870236445336,
        "cond_entropy-3-nopunct": 0.5006986073007481,
        "msttr-100": 0.66652,
        "msttr-100_nopunct": 0.71586,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.1977715877437326,
            "2": 0.3915531335149864,
            "3": 0.516445066480056,
            "4": 0.6973684210526315,
            "5": 0.7272727272727273,
            "6": 0.8181818181818182,
            "7": 1.0
        },
        "nist": 2.6848433084814762,
        "bleu": 27.27257,
        "rouge1": {
            "precision": 0.34907,
            "recall": 0.28064,
            "fmeasure": 0.29962
        },
        "rouge2": {
            "precision": 0.19023,
            "recall": 0.15068,
            "fmeasure": 0.16109
        },
        "rougeL": {
            "precision": 0.33734,
            "recall": 0.27062,
            "fmeasure": 0.28896
        },
        "rougeLsum": {
            "precision": 0.33734,
            "recall": 0.27062,
            "fmeasure": 0.28896
        },
        "nubia": {
            "semantic_relation": 3.69426,
            "contradiction": 20.95687,
            "irrelevancy": 22.62837,
            "logical_agreement": 56.41477,
            "grammar_ref": 2.74601,
            "grammar_hyp": 2.78097,
            "nubia_score": 0.72593
        },
        "meteor": 0.44990667043741933,
        "bleurt": 0.17076,
        "bertscore": {
            "precision": 0.95591,
            "recall": 0.9267,
            "f1": 0.9402
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 251,
        "total_length": 5851,
        "mean_pred_length": 23.310756972111555,
        "std_pred_length": 3.2869177827652707,
        "median_pred_length": 23.0,
        "min_pred_length": 11,
        "max_pred_length": 31,
        "distinct-1": 0.1551871474961545,
        "vocab_size-1": 908,
        "unique-1": 321,
        "entropy-1": 7.880788641504424,
        "distinct-2": 0.38321428571428573,
        "vocab_size-2": 2146,
        "unique-2": 1185,
        "entropy-2": 10.292947929305639,
        "cond_entropy-2": 2.447664874581267,
        "distinct-3": 0.5526266591886334,
        "vocab_size-3": 2956,
        "unique-3": 1999,
        "entropy-3": 11.051463333162788,
        "cond_entropy-3": 0.8170671658708275,
        "total_length-nopunct": 5378,
        "mean_pred_length-nopunct": 21.426294820717132,
        "std_pred_length-nopunct": 3.2647986424937376,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.16772034213462253,
        "vocab_size-1-nopunct": 902,
        "unique-1-nopunct": 321,
        "entropy-1-nopunct": 7.9973321549244805,
        "distinct-2-nopunct": 0.39633313828749756,
        "vocab_size-2-nopunct": 2032,
        "unique-2-nopunct": 1146,
        "entropy-2-nopunct": 10.26554357962328,
        "cond_entropy-2-nopunct": 2.3716715375738215,
        "distinct-3-nopunct": 0.5656275635767022,
        "vocab_size-3-nopunct": 2758,
        "unique-3-nopunct": 1899,
        "entropy-3-nopunct": 10.968790270512416,
        "cond_entropy-3-nopunct": 0.7597310456458268,
        "msttr-100": 0.50293,
        "msttr-100_nopunct": 0.50736,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.1767758676613688,
            "2": 0.48578199052132703,
            "3": 0.6887005649717514
        },
        "nist": 4.776039111662453,
        "bleu": 33.46694,
        "rouge1": {
            "precision": 0.7698,
            "recall": 0.58874,
            "fmeasure": 0.6515
        },
        "rouge2": {
            "precision": 0.49386,
            "recall": 0.36726,
            "fmeasure": 0.41003
        },
        "rougeL": {
            "precision": 0.60947,
            "recall": 0.46087,
            "fmeasure": 0.51175
        },
        "rougeLsum": {
            "precision": 0.60947,
            "recall": 0.46087,
            "fmeasure": 0.51175
        },
        "nubia": {
            "semantic_relation": 3.71896,
            "contradiction": 7.13305,
            "irrelevancy": 14.32311,
            "logical_agreement": 78.54384,
            "grammar_ref": 4.22372,
            "grammar_hyp": 4.59346,
            "nubia_score": 0.53593
        },
        "meteor": 0.28955496434606437,
        "bleurt": -0.15503,
        "bertscore": {
            "precision": 0.91077,
            "recall": 0.87069,
            "f1": 0.88862
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-base (Baseline)/cs_restaurants_test",
        "N": 9,
        "total_length": 168,
        "mean_pred_length": 18.666666666666668,
        "std_pred_length": 2.70801280154532,
        "median_pred_length": 19.0,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.5476190476190477,
        "vocab_size-1": 92,
        "unique-1": 65,
        "entropy-1": 6.035137358370721,
        "distinct-2": 0.8553459119496856,
        "vocab_size-2": 136,
        "unique-2": 115,
        "entropy-2": 7.0140793389049145,
        "cond_entropy-2": 0.9236880219158208,
        "distinct-3": 0.92,
        "vocab_size-3": 138,
        "unique-3": 126,
        "entropy-3": 7.068818690495863,
        "cond_entropy-3": 0.05933423524037173,
        "total_length-nopunct": 149,
        "mean_pred_length-nopunct": 16.555555555555557,
        "std_pred_length-nopunct": 2.499382639822665,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6040268456375839,
        "vocab_size-1-nopunct": 90,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 6.105393332438388,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 120,
        "unique-2-nopunct": 102,
        "entropy-2-nopunct": 6.832784624056929,
        "cond_entropy-2-nopunct": 0.7704196965629178,
        "distinct-3-nopunct": 0.9312977099236641,
        "vocab_size-3-nopunct": 122,
        "unique-3-nopunct": 113,
        "entropy-3-nopunct": 6.896018421384779,
        "cond_entropy-3-nopunct": 0.06070315256444522,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.72,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.4
        },
        "nist": 2.3349821283982535,
        "bleu": 10.32957,
        "rouge1": {
            "precision": 0.48045,
            "recall": 0.49171,
            "fmeasure": 0.48034
        },
        "rouge2": {
            "precision": 0.19192,
            "recall": 0.20076,
            "fmeasure": 0.1935
        },
        "rougeL": {
            "precision": 0.32422,
            "recall": 0.3374,
            "fmeasure": 0.32657
        },
        "rougeLsum": {
            "precision": 0.32422,
            "recall": 0.3374,
            "fmeasure": 0.32657
        },
        "nubia": {
            "semantic_relation": 3.05216,
            "contradiction": 23.35023,
            "irrelevancy": 32.42917,
            "logical_agreement": 44.2206,
            "grammar_ref": 6.01604,
            "grammar_hyp": 5.93845,
            "nubia_score": 0.47931
        },
        "meteor": 0.200999702482168,
        "bleurt": -0.12125,
        "bertscore": {
            "precision": 0.90101,
            "recall": 0.90479,
            "f1": 0.90286
        }
    },
    "totto_test_contrast_challenge_gender-male": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 300,
        "total_length": 4829,
        "mean_pred_length": 16.096666666666668,
        "std_pred_length": 5.410544232227373,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.37896044729757716,
        "vocab_size-1": 1830,
        "unique-1": 1421,
        "entropy-1": 8.793437144231929,
        "distinct-2": 0.7838374917200265,
        "vocab_size-2": 3550,
        "unique-2": 3170,
        "entropy-2": 11.45109835895781,
        "cond_entropy-2": 2.3885618942076854,
        "distinct-3": 0.9323717190825255,
        "vocab_size-3": 3943,
        "unique-3": 3783,
        "entropy-3": 11.874727219690039,
        "cond_entropy-3": 0.41686424252586257,
        "total_length-nopunct": 4217,
        "mean_pred_length-nopunct": 14.056666666666667,
        "std_pred_length-nopunct": 4.969251005489213,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.431823571259189,
        "vocab_size-1-nopunct": 1821,
        "unique-1-nopunct": 1420,
        "entropy-1-nopunct": 9.176049442421508,
        "distinct-2-nopunct": 0.8141434771508808,
        "vocab_size-2-nopunct": 3189,
        "unique-2-nopunct": 2916,
        "entropy-2-nopunct": 11.320202730255918,
        "cond_entropy-2-nopunct": 2.25169713274066,
        "distinct-3-nopunct": 0.9499585291678186,
        "vocab_size-3-nopunct": 3436,
        "unique-3-nopunct": 3325,
        "entropy-3-nopunct": 11.699942161944264,
        "cond_entropy-3-nopunct": 0.4002326332514449,
        "msttr-100": 0.73125,
        "msttr-100_nopunct": 0.78095,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19953325554259044,
            "2": 0.44302176696542894,
            "3": 0.813109756097561
        },
        "nist": 8.902889987404095,
        "bleu": 48.83597,
        "rouge1": {
            "precision": 0.80486,
            "recall": 0.77641,
            "fmeasure": 0.78173
        },
        "rouge2": {
            "precision": 0.58115,
            "recall": 0.56134,
            "fmeasure": 0.56435
        },
        "rougeL": {
            "precision": 0.69797,
            "recall": 0.67634,
            "fmeasure": 0.67918
        },
        "rougeLsum": {
            "precision": 0.69797,
            "recall": 0.67634,
            "fmeasure": 0.67918
        },
        "nubia": {
            "semantic_relation": 4.42596,
            "contradiction": 4.24717,
            "irrelevancy": 24.64741,
            "logical_agreement": 71.10542,
            "grammar_ref": 4.83962,
            "grammar_hyp": 4.81433,
            "nubia_score": 0.79872
        },
        "meteor": 0.41472430132147137,
        "bleurt": 0.37743,
        "bertscore": {
            "precision": 0.94249,
            "recall": 0.93873,
            "f1": 0.93924
        }
    },
    "totto_test_contrast_challenge_gender-female": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 300,
        "total_length": 5155,
        "mean_pred_length": 17.183333333333334,
        "std_pred_length": 5.050715020887857,
        "median_pred_length": 17.0,
        "min_pred_length": 4,
        "max_pred_length": 31,
        "distinct-1": 0.3629485935984481,
        "vocab_size-1": 1871,
        "unique-1": 1494,
        "entropy-1": 8.554797509404235,
        "distinct-2": 0.7396498455200824,
        "vocab_size-2": 3591,
        "unique-2": 3214,
        "entropy-2": 11.296799702339582,
        "cond_entropy-2": 2.516989957472915,
        "distinct-3": 0.903622392974753,
        "vocab_size-3": 4116,
        "unique-3": 3924,
        "entropy-3": 11.880007493691657,
        "cond_entropy-3": 0.6005576303400613,
        "total_length-nopunct": 4546,
        "mean_pred_length-nopunct": 15.153333333333334,
        "std_pred_length-nopunct": 4.7605835309923465,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4089309282886054,
        "vocab_size-1-nopunct": 1859,
        "unique-1-nopunct": 1489,
        "entropy-1-nopunct": 8.858667264700113,
        "distinct-2-nopunct": 0.75765426283561,
        "vocab_size-2-nopunct": 3217,
        "unique-2-nopunct": 2923,
        "entropy-2-nopunct": 11.136765767244684,
        "cond_entropy-2-nopunct": 2.424622691535085,
        "distinct-3-nopunct": 0.9181449569183984,
        "vocab_size-3-nopunct": 3623,
        "unique-3-nopunct": 3473,
        "entropy-3-nopunct": 11.717935002098178,
        "cond_entropy-3-nopunct": 0.6361218090035233,
        "msttr-100": 0.70569,
        "msttr-100_nopunct": 0.74644,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21906923950056753,
            "2": 0.384180790960452,
            "3": 0.7787107258938245
        },
        "nist": 8.56014846720126,
        "bleu": 44.96936,
        "rouge1": {
            "precision": 0.80019,
            "recall": 0.7554,
            "fmeasure": 0.76811
        },
        "rouge2": {
            "precision": 0.55036,
            "recall": 0.51746,
            "fmeasure": 0.52697
        },
        "rougeL": {
            "precision": 0.67908,
            "recall": 0.64129,
            "fmeasure": 0.6519
        },
        "rougeLsum": {
            "precision": 0.67908,
            "recall": 0.64129,
            "fmeasure": 0.6519
        },
        "nubia": {
            "semantic_relation": 4.40009,
            "contradiction": 4.78989,
            "irrelevancy": 24.05842,
            "logical_agreement": 71.15169,
            "grammar_ref": 4.91577,
            "grammar_hyp": 4.97007,
            "nubia_score": 0.7675
        },
        "meteor": 0.3959026716272094,
        "bleurt": 0.30822,
        "bertscore": {
            "precision": 0.93821,
            "recall": 0.93209,
            "f1": 0.93395
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 460,
        "total_length": 5565,
        "mean_pred_length": 12.097826086956522,
        "std_pred_length": 2.3528880616433536,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 21,
        "distinct-1": 0.2537286612758311,
        "vocab_size-1": 1412,
        "unique-1": 763,
        "entropy-1": 8.605780359570431,
        "distinct-2": 0.5263467189030362,
        "vocab_size-2": 2687,
        "unique-2": 1833,
        "entropy-2": 10.783723089944514,
        "cond_entropy-2": 2.3445464661110496,
        "distinct-3": 0.7072120559741658,
        "vocab_size-3": 3285,
        "unique-3": 2547,
        "entropy-3": 11.442225087232577,
        "cond_entropy-3": 0.7681801940276707,
        "total_length-nopunct": 4731,
        "mean_pred_length-nopunct": 10.284782608695652,
        "std_pred_length-nopunct": 1.9525309540834592,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.2971887550200803,
        "vocab_size-1-nopunct": 1406,
        "unique-1-nopunct": 762,
        "entropy-1-nopunct": 9.0939991386761,
        "distinct-2-nopunct": 0.5830016389604308,
        "vocab_size-2-nopunct": 2490,
        "unique-2-nopunct": 1773,
        "entropy-2-nopunct": 10.797391661373128,
        "cond_entropy-2-nopunct": 1.8863465112751807,
        "distinct-3-nopunct": 0.7423248491209656,
        "vocab_size-3-nopunct": 2829,
        "unique-3-nopunct": 2280,
        "entropy-3-nopunct": 11.250629240154318,
        "cond_entropy-3-nopunct": 0.568003163178651,
        "msttr-100": 0.63382,
        "msttr-100_nopunct": 0.68064,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.1337969401947149,
            "2": 0.3244370308590492,
            "3": 0.4878048780487805,
            "4": 1.0,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0
        },
        "nist": 0.9102858967153782,
        "bleu": 17.70762,
        "rouge1": {
            "precision": 0.19909,
            "recall": 0.1708,
            "fmeasure": 0.1793
        },
        "rouge2": {
            "precision": 0.05399,
            "recall": 0.03992,
            "fmeasure": 0.0433
        },
        "rougeL": {
            "precision": 0.19801,
            "recall": 0.16972,
            "fmeasure": 0.17821
        },
        "rougeLsum": {
            "precision": 0.19801,
            "recall": 0.16972,
            "fmeasure": 0.17821
        },
        "nubia": {
            "semantic_relation": 3.48669,
            "contradiction": 22.59718,
            "irrelevancy": 22.41666,
            "logical_agreement": 54.98616,
            "grammar_ref": 2.52111,
            "grammar_hyp": 2.65737,
            "nubia_score": 0.66389
        },
        "meteor": 0.35382554351853307,
        "bleurt": 0.01037,
        "bertscore": {
            "precision": 0.94418,
            "recall": 0.89753,
            "f1": 0.91944
        }
    },
    "totto_test_contrast_challenge_ethnicity-african_american": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 128,
        "total_length": 2042,
        "mean_pred_length": 15.953125,
        "std_pred_length": 5.53237541516978,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.3907933398628795,
        "vocab_size-1": 798,
        "unique-1": 620,
        "entropy-1": 7.969216483941088,
        "distinct-2": 0.7690700104493208,
        "vocab_size-2": 1472,
        "unique-2": 1301,
        "entropy-2": 10.141895012959644,
        "cond_entropy-2": 1.953525634626245,
        "distinct-3": 0.9305711086226204,
        "vocab_size-3": 1662,
        "unique-3": 1593,
        "entropy-3": 10.609720800538966,
        "cond_entropy-3": 0.40631117403279426,
        "total_length-nopunct": 1788,
        "mean_pred_length-nopunct": 13.96875,
        "std_pred_length-nopunct": 5.206572619055649,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.4407158836689038,
        "vocab_size-1-nopunct": 788,
        "unique-1-nopunct": 616,
        "entropy-1-nopunct": 8.236639032427787,
        "distinct-2-nopunct": 0.8066265060240964,
        "vocab_size-2-nopunct": 1339,
        "unique-2-nopunct": 1214,
        "entropy-2-nopunct": 10.053188284950116,
        "cond_entropy-2-nopunct": 1.8332072261582375,
        "distinct-3-nopunct": 0.9516971279373369,
        "vocab_size-3-nopunct": 1458,
        "unique-3-nopunct": 1412,
        "entropy-3-nopunct": 10.459674429507103,
        "cond_entropy-3-nopunct": 0.37829159318715744,
        "msttr-100": 0.7065,
        "msttr-100_nopunct": 0.76059,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17272727272727273,
            "2": 0.32558139534883723,
            "3": 0.7867298578199052
        },
        "nist": 7.603228514290027,
        "bleu": 47.29988,
        "rouge1": {
            "precision": 0.7982,
            "recall": 0.75843,
            "fmeasure": 0.77082
        },
        "rouge2": {
            "precision": 0.56011,
            "recall": 0.54186,
            "fmeasure": 0.54567
        },
        "rougeL": {
            "precision": 0.70735,
            "recall": 0.67586,
            "fmeasure": 0.68442
        },
        "rougeLsum": {
            "precision": 0.70735,
            "recall": 0.67586,
            "fmeasure": 0.68442
        },
        "nubia": {
            "semantic_relation": 4.40157,
            "contradiction": 5.82042,
            "irrelevancy": 27.78477,
            "logical_agreement": 66.39482,
            "grammar_ref": 4.21731,
            "grammar_hyp": 4.27294,
            "nubia_score": 0.80936
        },
        "meteor": 0.4026399241877967,
        "bleurt": 0.34846,
        "bertscore": {
            "precision": 0.93808,
            "recall": 0.93606,
            "f1": 0.93548
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_35": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 3.0,
        "median_pred_length": 19.0,
        "min_pred_length": 16,
        "max_pred_length": 22,
        "distinct-1": 0.8421052631578947,
        "vocab_size-1": 32,
        "unique-1": 26,
        "entropy-1": 4.932138039759376,
        "distinct-2": 0.9166666666666666,
        "vocab_size-2": 33,
        "unique-2": 30,
        "entropy-2": 5.003258334775643,
        "cond_entropy-2": 0.08866415466539349,
        "distinct-3": 0.9705882352941176,
        "vocab_size-3": 33,
        "unique-3": 32,
        "entropy-3": 5.028639311838573,
        "cond_entropy-3": 0.03518489863155644,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.843568731230678,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.8625759375402735,
        "cond_entropy-2-nopunct": 0.03632322362560796,
        "distinct-3-nopunct": 0.967741935483871,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.889680181354619,
        "cond_entropy-3-nopunct": 0.038834449092937956,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 0.4318181818181818
        },
        "nist": 1.512300681953521,
        "bleu": 18.17137,
        "rouge1": {
            "precision": 0.4821,
            "recall": 0.40351,
            "fmeasure": 0.43868
        },
        "rouge2": {
            "precision": 0.24716,
            "recall": 0.20785,
            "fmeasure": 0.22549
        },
        "rougeL": {
            "precision": 0.46036,
            "recall": 0.38684,
            "fmeasure": 0.41981
        },
        "rougeLsum": {
            "precision": 0.46036,
            "recall": 0.38684,
            "fmeasure": 0.41981
        },
        "nubia": {
            "semantic_relation": 2.87251,
            "contradiction": 50.32614,
            "irrelevancy": 48.09162,
            "logical_agreement": 1.58224,
            "grammar_ref": 3.96887,
            "grammar_hyp": 4.14604,
            "nubia_score": 0.28567
        },
        "meteor": 0.19039893141979358,
        "bleurt": -0.05772,
        "bertscore": {
            "precision": 0.86446,
            "recall": 0.84131,
            "f1": 0.85072
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 213,
        "total_length": 5203,
        "mean_pred_length": 24.427230046948356,
        "std_pred_length": 2.676731650233189,
        "median_pred_length": 25.0,
        "min_pred_length": 17,
        "max_pred_length": 31,
        "distinct-1": 0.17720545838939072,
        "vocab_size-1": 922,
        "unique-1": 363,
        "entropy-1": 7.887565005682032,
        "distinct-2": 0.43987975951903807,
        "vocab_size-2": 2195,
        "unique-2": 1312,
        "entropy-2": 10.405604341654074,
        "cond_entropy-2": 2.6053905164948485,
        "distinct-3": 0.6271718651873561,
        "vocab_size-3": 2996,
        "unique-3": 2166,
        "entropy-3": 11.185549231941941,
        "cond_entropy-3": 0.8363639737104286,
        "total_length-nopunct": 4784,
        "mean_pred_length-nopunct": 22.460093896713616,
        "std_pred_length-nopunct": 2.590077489117673,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.19126254180602006,
        "vocab_size-1-nopunct": 915,
        "unique-1-nopunct": 361,
        "entropy-1-nopunct": 8.009713683682381,
        "distinct-2-nopunct": 0.45723036534675127,
        "vocab_size-2-nopunct": 2090,
        "unique-2-nopunct": 1292,
        "entropy-2-nopunct": 10.380436153225025,
        "cond_entropy-2-nopunct": 2.482666071047088,
        "distinct-3-nopunct": 0.6390546122074346,
        "vocab_size-3-nopunct": 2785,
        "unique-3-nopunct": 2055,
        "entropy-3-nopunct": 11.084225434594096,
        "cond_entropy-3-nopunct": 0.7630064628228576,
        "msttr-100": 0.65538,
        "msttr-100_nopunct": 0.67021,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.1608318890814558,
            "2": 0.40048989589712186,
            "3": 0.658114730469876
        },
        "nist": 4.171505530265325,
        "bleu": 30.59803,
        "rouge1": {
            "precision": 0.74949,
            "recall": 0.53466,
            "fmeasure": 0.61469
        },
        "rouge2": {
            "precision": 0.45972,
            "recall": 0.31386,
            "fmeasure": 0.36624
        },
        "rougeL": {
            "precision": 0.57954,
            "recall": 0.40886,
            "fmeasure": 0.47163
        },
        "rougeLsum": {
            "precision": 0.57954,
            "recall": 0.40886,
            "fmeasure": 0.47163
        },
        "nubia": {
            "semantic_relation": 3.49232,
            "contradiction": 10.84568,
            "irrelevancy": 12.85564,
            "logical_agreement": 76.29868,
            "grammar_ref": 4.14495,
            "grammar_hyp": 4.54915,
            "nubia_score": 0.46502
        },
        "meteor": 0.2692859215061164,
        "bleurt": -0.31479,
        "bertscore": {
            "precision": 0.89851,
            "recall": 0.85374,
            "f1": 0.87401
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_38": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.11251249881411757,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.9130434782608695,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.349648912578752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.11768784439846626,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333
        },
        "nist": 0.6666666666666666,
        "bleu": 3.74194,
        "rouge1": {
            "precision": 0.17391,
            "recall": 0.26667,
            "fmeasure": 0.21053
        },
        "rouge2": {
            "precision": 0.04545,
            "recall": 0.07143,
            "fmeasure": 0.05556
        },
        "rougeL": {
            "precision": 0.08696,
            "recall": 0.13333,
            "fmeasure": 0.10526
        },
        "rougeLsum": {
            "precision": 0.08696,
            "recall": 0.13333,
            "fmeasure": 0.10526
        },
        "nubia": {
            "semantic_relation": 2.13045,
            "contradiction": 22.9477,
            "irrelevancy": 76.56527,
            "logical_agreement": 0.48702,
            "grammar_ref": 5.48676,
            "grammar_hyp": 4.4836,
            "nubia_score": 0.286
        },
        "meteor": 0.11059885031200481,
        "bleurt": -0.70696,
        "bertscore": {
            "precision": 0.74983,
            "recall": 0.79725,
            "f1": 0.77147
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 349,
        "total_length": 5681,
        "mean_pred_length": 16.277936962750715,
        "std_pred_length": 3.7516147868511616,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.17268086604471045,
        "vocab_size-1": 981,
        "unique-1": 414,
        "entropy-1": 7.877896960192446,
        "distinct-2": 0.4358589647411853,
        "vocab_size-2": 2324,
        "unique-2": 1433,
        "entropy-2": 10.461622570155232,
        "cond_entropy-2": 2.349718462077616,
        "distinct-3": 0.6185029098936383,
        "vocab_size-3": 3082,
        "unique-3": 2276,
        "entropy-3": 11.180793345223812,
        "cond_entropy-3": 0.7993401623178167,
        "total_length-nopunct": 5088,
        "mean_pred_length-nopunct": 14.578796561604584,
        "std_pred_length-nopunct": 3.612729442473571,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.19123427672955975,
        "vocab_size-1-nopunct": 973,
        "unique-1-nopunct": 413,
        "entropy-1-nopunct": 8.104612835140921,
        "distinct-2-nopunct": 0.4254062038404727,
        "vocab_size-2-nopunct": 2016,
        "unique-2-nopunct": 1241,
        "entropy-2-nopunct": 10.236219355494287,
        "cond_entropy-2-nopunct": 2.3170465522984367,
        "distinct-3-nopunct": 0.6100227790432802,
        "vocab_size-3-nopunct": 2678,
        "unique-3-nopunct": 1976,
        "entropy-3-nopunct": 10.959206002050514,
        "cond_entropy-3-nopunct": 0.7900574258345372,
        "msttr-100": 0.66607,
        "msttr-100_nopunct": 0.7024,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.22062923138191956,
            "2": 0.5815363881401617,
            "3": 0.8995215311004785,
            "4": 1.0
        },
        "nist": 9.198982734511763,
        "bleu": 55.87822,
        "rouge1": {
            "precision": 0.79218,
            "recall": 0.78294,
            "fmeasure": 0.781
        },
        "rouge2": {
            "precision": 0.56569,
            "recall": 0.55833,
            "fmeasure": 0.55609
        },
        "rougeL": {
            "precision": 0.68213,
            "recall": 0.67344,
            "fmeasure": 0.67103
        },
        "rougeLsum": {
            "precision": 0.68213,
            "recall": 0.67344,
            "fmeasure": 0.67103
        },
        "nubia": {
            "semantic_relation": 4.61536,
            "contradiction": 5.85908,
            "irrelevancy": 5.35746,
            "logical_agreement": 88.78346,
            "grammar_ref": 4.75348,
            "grammar_hyp": 4.81962,
            "nubia_score": 0.83157
        },
        "meteor": 0.4311037657158266,
        "bleurt": 0.30178,
        "bertscore": {
            "precision": 0.93766,
            "recall": 0.93493,
            "f1": 0.93451
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_40": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.690116517593666,
        "distinct-2": 0.9375,
        "vocab_size-2": 15,
        "unique-2": 14,
        "entropy-2": 3.875,
        "cond_entropy-2": 0.20971762763487733,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": 0.04022392894185189,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.577819531114783,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.773557262275185,
        "cond_entropy-2-nopunct": 0.2238830957527498,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": 0.04332146930622849,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.46153846153846156
        },
        "nist": 1.5263157894736843,
        "bleu": 5.726,
        "rouge1": {
            "precision": 0.46667,
            "recall": 0.46667,
            "fmeasure": 0.46667
        },
        "rouge2": {
            "precision": 0.21429,
            "recall": 0.21429,
            "fmeasure": 0.21429
        },
        "rougeL": {
            "precision": 0.46667,
            "recall": 0.46667,
            "fmeasure": 0.46667
        },
        "rougeLsum": {
            "precision": 0.46667,
            "recall": 0.46667,
            "fmeasure": 0.46667
        },
        "nubia": {
            "semantic_relation": 3.06361,
            "contradiction": 0.67932,
            "irrelevancy": 99.06809,
            "logical_agreement": 0.25259,
            "grammar_ref": 5.57252,
            "grammar_hyp": 4.76546,
            "nubia_score": 0.39922
        },
        "meteor": 0.18480519628039963,
        "bleurt": -0.73297,
        "bertscore": {
            "precision": 0.78002,
            "recall": 0.8313,
            "f1": 0.80484
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 369,
        "total_length": 3584,
        "mean_pred_length": 9.712737127371273,
        "std_pred_length": 2.6285642394106103,
        "median_pred_length": 9.0,
        "min_pred_length": 4,
        "max_pred_length": 24,
        "distinct-1": 0.22433035714285715,
        "vocab_size-1": 804,
        "unique-1": 458,
        "entropy-1": 7.568630897528908,
        "distinct-2": 0.5362363919129083,
        "vocab_size-2": 1724,
        "unique-2": 1217,
        "entropy-2": 10.193955173702218,
        "cond_entropy-2": 2.1361853540033224,
        "distinct-3": 0.7301475755446241,
        "vocab_size-3": 2078,
        "unique-3": 1707,
        "entropy-3": 10.752710937773587,
        "cond_entropy-3": 0.6495404728537821,
        "total_length-nopunct": 3138,
        "mean_pred_length-nopunct": 8.504065040650406,
        "std_pred_length-nopunct": 2.3834592055220076,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.2539834289356278,
        "vocab_size-1-nopunct": 797,
        "unique-1-nopunct": 457,
        "entropy-1-nopunct": 7.878638400438901,
        "distinct-2-nopunct": 0.5139039364391477,
        "vocab_size-2-nopunct": 1423,
        "unique-2-nopunct": 984,
        "entropy-2-nopunct": 9.883508636966594,
        "cond_entropy-2-nopunct": 2.3071757089633746,
        "distinct-3-nopunct": 0.7183333333333334,
        "vocab_size-3-nopunct": 1724,
        "unique-3-nopunct": 1407,
        "entropy-3-nopunct": 10.465898653432797,
        "cond_entropy-3-nopunct": 0.7056480247881022,
        "msttr-100": 0.64229,
        "msttr-100_nopunct": 0.69129,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.23040254237288135,
            "2": 0.6843393148450244,
            "3": 0.8924302788844621,
            "4": 0.9473684210526315
        },
        "nist": 9.306919054320243,
        "bleu": 62.62251,
        "rouge1": {
            "precision": 0.83245,
            "recall": 0.7921,
            "fmeasure": 0.80474
        },
        "rouge2": {
            "precision": 0.62031,
            "recall": 0.5891,
            "fmeasure": 0.59853
        },
        "rougeL": {
            "precision": 0.75801,
            "recall": 0.72164,
            "fmeasure": 0.73258
        },
        "rougeLsum": {
            "precision": 0.75801,
            "recall": 0.72164,
            "fmeasure": 0.73258
        },
        "nubia": {
            "semantic_relation": 4.63,
            "contradiction": 6.44602,
            "irrelevancy": 6.36537,
            "logical_agreement": 87.18861,
            "grammar_ref": 5.18632,
            "grammar_hyp": 5.33127,
            "nubia_score": 0.83571
        },
        "meteor": 0.46960523004667176,
        "bleurt": 0.42439,
        "bertscore": {
            "precision": 0.95185,
            "recall": 0.94851,
            "f1": 0.9493
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 158,
        "total_length": 3883,
        "mean_pred_length": 24.575949367088608,
        "std_pred_length": 2.4682651720310815,
        "median_pred_length": 25.0,
        "min_pred_length": 17,
        "max_pred_length": 30,
        "distinct-1": 0.1859387071851661,
        "vocab_size-1": 722,
        "unique-1": 276,
        "entropy-1": 7.6907393849680314,
        "distinct-2": 0.43409395973154363,
        "vocab_size-2": 1617,
        "unique-2": 929,
        "entropy-2": 10.003700250507821,
        "cond_entropy-2": 2.3966930749312767,
        "distinct-3": 0.6075133165124754,
        "vocab_size-3": 2167,
        "unique-3": 1521,
        "entropy-3": 10.694354612784304,
        "cond_entropy-3": 0.7439472560071551,
        "total_length-nopunct": 3572,
        "mean_pred_length-nopunct": 22.60759493670886,
        "std_pred_length-nopunct": 2.51535900509874,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.20016797312430012,
        "vocab_size-1-nopunct": 715,
        "unique-1-nopunct": 275,
        "entropy-1-nopunct": 7.784977311675705,
        "distinct-2-nopunct": 0.4502050380785003,
        "vocab_size-2-nopunct": 1537,
        "unique-2-nopunct": 913,
        "entropy-2-nopunct": 9.966909787007559,
        "cond_entropy-2-nopunct": 2.2872582064077345,
        "distinct-3-nopunct": 0.621007371007371,
        "vocab_size-3-nopunct": 2022,
        "unique-3-nopunct": 1458,
        "entropy-3-nopunct": 10.59577676563327,
        "cond_entropy-3-nopunct": 0.6860367238382452,
        "msttr-100": 0.52079,
        "msttr-100_nopunct": 0.52171,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.15588499550763701,
            "2": 0.3927958833619211,
            "3": 0.6223801065719361
        },
        "nist": 3.0561502664831344,
        "bleu": 28.03272,
        "rouge1": {
            "precision": 0.75948,
            "recall": 0.52072,
            "fmeasure": 0.60552
        },
        "rouge2": {
            "precision": 0.47156,
            "recall": 0.31116,
            "fmeasure": 0.36601
        },
        "rougeL": {
            "precision": 0.59234,
            "recall": 0.40179,
            "fmeasure": 0.46801
        },
        "rougeLsum": {
            "precision": 0.59234,
            "recall": 0.40179,
            "fmeasure": 0.46801
        },
        "nubia": {
            "semantic_relation": 3.42706,
            "contradiction": 11.30122,
            "irrelevancy": 11.56634,
            "logical_agreement": 77.13244,
            "grammar_ref": 4.0976,
            "grammar_hyp": 4.52074,
            "nubia_score": 0.45651
        },
        "meteor": 0.2545116083096935,
        "bleurt": -0.35173,
        "bertscore": {
            "precision": 0.89695,
            "recall": 0.84479,
            "f1": 0.86852
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 350,
        "total_length": 7360,
        "mean_pred_length": 21.02857142857143,
        "std_pred_length": 3.8876045822273517,
        "median_pred_length": 21.5,
        "min_pred_length": 9,
        "max_pred_length": 30,
        "distinct-1": 0.1391304347826087,
        "vocab_size-1": 1024,
        "unique-1": 360,
        "entropy-1": 7.954498979518086,
        "distinct-2": 0.3854493580599144,
        "vocab_size-2": 2702,
        "unique-2": 1547,
        "entropy-2": 10.628856673207038,
        "cond_entropy-2": 2.579301083336886,
        "distinct-3": 0.584984984984985,
        "vocab_size-3": 3896,
        "unique-3": 2785,
        "entropy-3": 11.489386553464211,
        "cond_entropy-3": 0.9259359483515037,
        "total_length-nopunct": 6653,
        "mean_pred_length-nopunct": 19.00857142857143,
        "std_pred_length-nopunct": 3.8250954369846535,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.15271306177664212,
        "vocab_size-1-nopunct": 1016,
        "unique-1-nopunct": 359,
        "entropy-1-nopunct": 8.123907379494765,
        "distinct-2-nopunct": 0.3898143741075678,
        "vocab_size-2-nopunct": 2457,
        "unique-2-nopunct": 1456,
        "entropy-2-nopunct": 10.48658381185526,
        "cond_entropy-2-nopunct": 2.509212525038327,
        "distinct-3-nopunct": 0.5850831513522594,
        "vocab_size-3-nopunct": 3483,
        "unique-3-nopunct": 2509,
        "entropy-3-nopunct": 11.320779557948812,
        "cond_entropy-3-nopunct": 0.8905808120844023,
        "msttr-100": 0.66986,
        "msttr-100_nopunct": 0.70121,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.2140953509031685,
            "2": 0.562935190144617,
            "3": 0.8520249221183801,
            "4": 0.5,
            "5": 0.7931034482758621
        },
        "nist": 8.622099681450699,
        "bleu": 47.22746,
        "rouge1": {
            "precision": 0.77158,
            "recall": 0.73657,
            "fmeasure": 0.74703
        },
        "rouge2": {
            "precision": 0.51386,
            "recall": 0.48575,
            "fmeasure": 0.49434
        },
        "rougeL": {
            "precision": 0.62511,
            "recall": 0.59131,
            "fmeasure": 0.60158
        },
        "rougeLsum": {
            "precision": 0.62511,
            "recall": 0.59131,
            "fmeasure": 0.60158
        },
        "nubia": {
            "semantic_relation": 4.37405,
            "contradiction": 8.10121,
            "irrelevancy": 10.01629,
            "logical_agreement": 81.8825,
            "grammar_ref": 4.50573,
            "grammar_hyp": 4.65271,
            "nubia_score": 0.75248
        },
        "meteor": 0.3855861060501596,
        "bleurt": 0.1288,
        "bertscore": {
            "precision": 0.9194,
            "recall": 0.91294,
            "f1": 0.91442
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 114,
        "total_length": 2787,
        "mean_pred_length": 24.44736842105263,
        "std_pred_length": 2.8193943148950305,
        "median_pred_length": 24.0,
        "min_pred_length": 15,
        "max_pred_length": 31,
        "distinct-1": 0.2256907068532472,
        "vocab_size-1": 629,
        "unique-1": 309,
        "entropy-1": 7.591010910093328,
        "distinct-2": 0.4728769173213618,
        "vocab_size-2": 1264,
        "unique-2": 787,
        "entropy-2": 9.72751067459556,
        "cond_entropy-2": 2.213362227518163,
        "distinct-3": 0.6240719030871434,
        "vocab_size-3": 1597,
        "unique-3": 1140,
        "entropy-3": 10.304231551745627,
        "cond_entropy-3": 0.6278065034064843,
        "total_length-nopunct": 2557,
        "mean_pred_length-nopunct": 22.42982456140351,
        "std_pred_length-nopunct": 2.717614079484203,
        "median_pred_length-nopunct": 22.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.2428627297614392,
        "vocab_size-1-nopunct": 621,
        "unique-1-nopunct": 306,
        "entropy-1-nopunct": 7.687407954669304,
        "distinct-2-nopunct": 0.4899713467048711,
        "vocab_size-2-nopunct": 1197,
        "unique-2-nopunct": 764,
        "entropy-2-nopunct": 9.686452927509093,
        "cond_entropy-2-nopunct": 2.0968546286340666,
        "distinct-3-nopunct": 0.6384714469729498,
        "vocab_size-3-nopunct": 1487,
        "unique-3-nopunct": 1085,
        "entropy-3-nopunct": 10.211355881237239,
        "cond_entropy-3-nopunct": 0.5811163406076053,
        "msttr-100": 0.64593,
        "msttr-100_nopunct": 0.668,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.13759909399773498,
            "2": 0.3960573476702509,
            "3": 0.593483709273183
        },
        "nist": 1.8085088048282876,
        "bleu": 24.09916,
        "rouge1": {
            "precision": 0.77981,
            "recall": 0.46886,
            "fmeasure": 0.5776
        },
        "rouge2": {
            "precision": 0.4789,
            "recall": 0.27403,
            "fmeasure": 0.34338
        },
        "rougeL": {
            "precision": 0.59973,
            "recall": 0.35376,
            "fmeasure": 0.43864
        },
        "rougeLsum": {
            "precision": 0.59973,
            "recall": 0.35376,
            "fmeasure": 0.43864
        },
        "nubia": {
            "semantic_relation": 3.26607,
            "contradiction": 9.08595,
            "irrelevancy": 13.62777,
            "logical_agreement": 77.28628,
            "grammar_ref": 4.06233,
            "grammar_hyp": 4.59242,
            "nubia_score": 0.36681
        },
        "meteor": 0.2305920430801937,
        "bleurt": -0.39243,
        "bertscore": {
            "precision": 0.89816,
            "recall": 0.83119,
            "f1": 0.86194
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 305,
        "total_length": 7270,
        "mean_pred_length": 23.83606557377049,
        "std_pred_length": 3.1507497305486734,
        "median_pred_length": 24.0,
        "min_pred_length": 11,
        "max_pred_length": 31,
        "distinct-1": 0.150343878954608,
        "vocab_size-1": 1093,
        "unique-1": 442,
        "entropy-1": 7.96774229248907,
        "distinct-2": 0.39712849964106245,
        "vocab_size-2": 2766,
        "unique-2": 1638,
        "entropy-2": 10.600488409382029,
        "cond_entropy-2": 2.662174072025268,
        "distinct-3": 0.5896396396396396,
        "vocab_size-3": 3927,
        "unique-3": 2821,
        "entropy-3": 11.485174384859475,
        "cond_entropy-3": 0.9423511186014484,
        "total_length-nopunct": 6657,
        "mean_pred_length-nopunct": 21.82622950819672,
        "std_pred_length-nopunct": 3.1382307660158792,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.16298633017875921,
        "vocab_size-1-nopunct": 1085,
        "unique-1-nopunct": 440,
        "entropy-1-nopunct": 8.100799066451213,
        "distinct-2-nopunct": 0.4108942065491184,
        "vocab_size-2-nopunct": 2610,
        "unique-2-nopunct": 1582,
        "entropy-2-nopunct": 10.56476211270611,
        "cond_entropy-2-nopunct": 2.573922382806893,
        "distinct-3-nopunct": 0.6022821233669589,
        "vocab_size-3-nopunct": 3642,
        "unique-3-nopunct": 2670,
        "entropy-3-nopunct": 11.387565473675894,
        "cond_entropy-3-nopunct": 0.8791138287700015,
        "msttr-100": 0.66028,
        "msttr-100_nopunct": 0.67909,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.17851147174034696,
            "2": 0.5266485998193315,
            "3": 0.7639270547089683
        },
        "nist": 7.068295186640241,
        "bleu": 40.07128,
        "rouge1": {
            "precision": 0.76054,
            "recall": 0.64241,
            "fmeasure": 0.6883
        },
        "rouge2": {
            "precision": 0.48663,
            "recall": 0.40216,
            "fmeasure": 0.43431
        },
        "rougeL": {
            "precision": 0.59743,
            "recall": 0.50095,
            "fmeasure": 0.53801
        },
        "rougeLsum": {
            "precision": 0.59743,
            "recall": 0.50095,
            "fmeasure": 0.53801
        },
        "nubia": {
            "semantic_relation": 3.86509,
            "contradiction": 10.69613,
            "irrelevancy": 15.61502,
            "logical_agreement": 73.68886,
            "grammar_ref": 4.27079,
            "grammar_hyp": 4.5533,
            "nubia_score": 0.59266
        },
        "meteor": 0.3270368047412358,
        "bleurt": -0.08406,
        "bertscore": {
            "precision": 0.91019,
            "recall": 0.88405,
            "f1": 0.89548
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 80,
        "total_length": 2030,
        "mean_pred_length": 25.375,
        "std_pred_length": 2.6850279328155975,
        "median_pred_length": 25.5,
        "min_pred_length": 15,
        "max_pred_length": 31,
        "distinct-1": 0.26157635467980295,
        "vocab_size-1": 531,
        "unique-1": 288,
        "entropy-1": 7.438953339694335,
        "distinct-2": 0.5394871794871795,
        "vocab_size-2": 1052,
        "unique-2": 707,
        "entropy-2": 9.525303734970567,
        "cond_entropy-2": 2.147186063280825,
        "distinct-3": 0.7,
        "vocab_size-3": 1309,
        "unique-3": 1006,
        "entropy-3": 10.079378827994926,
        "cond_entropy-3": 0.6010813436433151,
        "total_length-nopunct": 1867,
        "mean_pred_length-nopunct": 23.3375,
        "std_pred_length-nopunct": 2.568772810117703,
        "median_pred_length-nopunct": 23.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.2811997857525442,
        "vocab_size-1-nopunct": 525,
        "unique-1-nopunct": 286,
        "entropy-1-nopunct": 7.528231499995436,
        "distinct-2-nopunct": 0.5579182988248461,
        "vocab_size-2-nopunct": 997,
        "unique-2-nopunct": 689,
        "entropy-2-nopunct": 9.487155301411741,
        "cond_entropy-2-nopunct": 2.040837764862723,
        "distinct-3-nopunct": 0.7141183362624487,
        "vocab_size-3-nopunct": 1219,
        "unique-3-nopunct": 961,
        "entropy-3-nopunct": 9.982811955106815,
        "cond_entropy-3-nopunct": 0.5470252296157523,
        "msttr-100": 0.5335,
        "msttr-100_nopunct": 0.535,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.13581183611532624,
            "2": 0.35254691689008044,
            "3": 0.6187584345479082
        },
        "nist": 2.2255553549735825,
        "bleu": 25.92153,
        "rouge1": {
            "precision": 0.77025,
            "recall": 0.48191,
            "fmeasure": 0.58573
        },
        "rouge2": {
            "precision": 0.46228,
            "recall": 0.27681,
            "fmeasure": 0.34167
        },
        "rougeL": {
            "precision": 0.58728,
            "recall": 0.35977,
            "fmeasure": 0.44024
        },
        "rougeLsum": {
            "precision": 0.58728,
            "recall": 0.35977,
            "fmeasure": 0.44024
        },
        "nubia": {
            "semantic_relation": 3.27914,
            "contradiction": 10.71618,
            "irrelevancy": 14.63822,
            "logical_agreement": 74.6456,
            "grammar_ref": 4.0565,
            "grammar_hyp": 4.61283,
            "nubia_score": 0.38157
        },
        "meteor": 0.23560967899088564,
        "bleurt": -0.37953,
        "bertscore": {
            "precision": 0.89386,
            "recall": 0.83064,
            "f1": 0.85945
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 79,
        "total_length": 1906,
        "mean_pred_length": 24.126582278481013,
        "std_pred_length": 2.9311383221341534,
        "median_pred_length": 24.0,
        "min_pred_length": 18,
        "max_pred_length": 32,
        "distinct-1": 0.2465897166841553,
        "vocab_size-1": 470,
        "unique-1": 249,
        "entropy-1": 7.417733524001469,
        "distinct-2": 0.48440065681444994,
        "vocab_size-2": 885,
        "unique-2": 576,
        "entropy-2": 9.272398904713372,
        "cond_entropy-2": 1.928029341681605,
        "distinct-3": 0.6092677345537757,
        "vocab_size-3": 1065,
        "unique-3": 791,
        "entropy-3": 9.67889443483726,
        "cond_entropy-3": 0.4518880809051905,
        "total_length-nopunct": 1731,
        "mean_pred_length-nopunct": 21.911392405063292,
        "std_pred_length-nopunct": 2.9775101033646414,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.268053148469093,
        "vocab_size-1-nopunct": 464,
        "unique-1-nopunct": 248,
        "entropy-1-nopunct": 7.500770674758115,
        "distinct-2-nopunct": 0.5012106537530266,
        "vocab_size-2-nopunct": 828,
        "unique-2-nopunct": 555,
        "entropy-2-nopunct": 9.201206267726285,
        "cond_entropy-2-nopunct": 1.779589322469743,
        "distinct-3-nopunct": 0.6223776223776224,
        "vocab_size-3-nopunct": 979,
        "unique-3-nopunct": 743,
        "entropy-3-nopunct": 9.561520414832284,
        "cond_entropy-3-nopunct": 0.41302392254981946,
        "msttr-100": 0.68105,
        "msttr-100_nopunct": 0.69,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.12675070028011204,
            "2": 0.27344782034346105,
            "3": 0.5202973127501429
        },
        "nist": 0.6121407281777214,
        "bleu": 17.40641,
        "rouge1": {
            "precision": 0.78673,
            "recall": 0.39173,
            "fmeasure": 0.51594
        },
        "rouge2": {
            "precision": 0.47686,
            "recall": 0.22485,
            "fmeasure": 0.30063
        },
        "rougeL": {
            "precision": 0.62034,
            "recall": 0.30112,
            "fmeasure": 0.39958
        },
        "rougeLsum": {
            "precision": 0.62034,
            "recall": 0.30112,
            "fmeasure": 0.39958
        },
        "nubia": {
            "semantic_relation": 3.11602,
            "contradiction": 8.11853,
            "irrelevancy": 9.93058,
            "logical_agreement": 81.95089,
            "grammar_ref": 3.96506,
            "grammar_hyp": 4.63333,
            "nubia_score": 0.32587
        },
        "meteor": 0.19826300720262333,
        "bleurt": -0.53418,
        "bertscore": {
            "precision": 0.9013,
            "recall": 0.81668,
            "f1": 0.85564
        }
    },
    "web_nlg_en_validation": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_validation",
        "N": 1667,
        "total_length": 31011,
        "mean_pred_length": 18.602879424115176,
        "std_pred_length": 6.525990039684319,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.11492696140079327,
        "vocab_size-1": 3564,
        "unique-1": 1420,
        "entropy-1": 8.76493348447635,
        "distinct-2": 0.3721714830970556,
        "vocab_size-2": 10921,
        "unique-2": 6650,
        "entropy-2": 12.230522996068885,
        "cond_entropy-2": 3.359989167567696,
        "distinct-3": 0.5990533656104347,
        "vocab_size-3": 16580,
        "unique-3": 12319,
        "entropy-3": 13.451571549039317,
        "cond_entropy-3": 1.295835728529684,
        "total_length-nopunct": 27738,
        "mean_pred_length-nopunct": 16.639472105578886,
        "std_pred_length-nopunct": 6.067127131925353,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.12809142692335423,
        "vocab_size-1-nopunct": 3553,
        "unique-1-nopunct": 1419,
        "entropy-1-nopunct": 9.078702408924181,
        "distinct-2-nopunct": 0.38678991983429867,
        "vocab_size-2-nopunct": 10084,
        "unique-2-nopunct": 6262,
        "entropy-2-nopunct": 12.141831773406505,
        "cond_entropy-2-nopunct": 3.2367816534066636,
        "distinct-3-nopunct": 0.608097033273234,
        "vocab_size-3-nopunct": 14840,
        "unique-3-nopunct": 11170,
        "entropy-3-nopunct": 13.294529932878843,
        "cond_entropy-3-nopunct": 1.232315367476755,
        "msttr-100": 0.57061,
        "msttr-100_nopunct": 0.59199,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_validation.json",
        "local_recall": {
            "1": 0.2907987411958639,
            "2": 0.6335249042145594,
            "3": 0.8133769538349691,
            "4": 0.8794326241134752,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0,
            "8": 1.0
        },
        "nist": 9.871229981469103,
        "bleu": 52.89169,
        "rouge1": {
            "precision": 0.82126,
            "recall": 0.75093,
            "fmeasure": 0.77545
        },
        "rouge2": {
            "precision": 0.60296,
            "recall": 0.5531,
            "fmeasure": 0.56981
        },
        "rougeL": {
            "precision": 0.69509,
            "recall": 0.64084,
            "fmeasure": 0.65885
        },
        "rougeLsum": {
            "precision": 0.69509,
            "recall": 0.64084,
            "fmeasure": 0.65885
        },
        "nubia": {
            "semantic_relation": 4.41661,
            "contradiction": 4.27218,
            "irrelevancy": 5.78604,
            "logical_agreement": 89.94177,
            "grammar_ref": 4.59465,
            "grammar_hyp": 4.69982,
            "nubia_score": 0.77614
        },
        "meteor": 0.3915038589531795,
        "bleurt": 0.26671,
        "bertscore": {
            "precision": 0.94532,
            "recall": 0.93173,
            "f1": 0.93741
        }
    },
    "schema_guided_dialog_test": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 10000,
        "total_length": 125673,
        "mean_pred_length": 12.5673,
        "std_pred_length": 6.6177390935273355,
        "median_pred_length": 11.0,
        "min_pred_length": 1,
        "max_pred_length": 33,
        "distinct-1": 0.03529795580594081,
        "vocab_size-1": 4436,
        "unique-1": 1954,
        "entropy-1": 8.150511795385517,
        "distinct-2": 0.1628297009673822,
        "vocab_size-2": 18835,
        "unique-2": 10492,
        "entropy-2": 11.92565211658962,
        "cond_entropy-2": 3.524128426814384,
        "distinct-3": 0.3458845127467494,
        "vocab_size-3": 36551,
        "unique-3": 24635,
        "entropy-3": 13.664065442360169,
        "cond_entropy-3": 1.7612720442157825,
        "total_length-nopunct": 110527,
        "mean_pred_length-nopunct": 11.0527,
        "std_pred_length-nopunct": 6.14857078596319,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.039963085942801305,
        "vocab_size-1-nopunct": 4417,
        "unique-1-nopunct": 1950,
        "entropy-1-nopunct": 8.380061771448087,
        "distinct-2-nopunct": 0.18001134023695126,
        "vocab_size-2-nopunct": 18096,
        "unique-2-nopunct": 10464,
        "entropy-2-nopunct": 11.853258004031616,
        "cond_entropy-2-nopunct": 3.627800229069703,
        "distinct-3-nopunct": 0.37303112642764047,
        "vocab_size-3-nopunct": 33772,
        "unique-3-nopunct": 23547,
        "entropy-3-nopunct": 13.568077891361694,
        "cond_entropy-3-nopunct": 1.7732186063396134,
        "msttr-100": 0.6926,
        "msttr-100_nopunct": 0.72151,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.557288472988705
        },
        "nist": 6.885949783988616,
        "bleu": 31.36341,
        "rouge1": {
            "precision": 0.5706,
            "recall": 0.5439,
            "fmeasure": 0.54561
        },
        "rouge2": {
            "precision": 0.35346,
            "recall": 0.33795,
            "fmeasure": 0.33801
        },
        "rougeL": {
            "precision": 0.512,
            "recall": 0.4881,
            "fmeasure": 0.48961
        },
        "rougeLsum": {
            "precision": 0.512,
            "recall": 0.4881,
            "fmeasure": 0.48961
        },
        "nubia": {
            "semantic_relation": 3.60237,
            "contradiction": 5.81123,
            "irrelevancy": 23.53477,
            "logical_agreement": 70.65399,
            "grammar_ref": 4.76329,
            "grammar_hyp": 4.70046,
            "nubia_score": 0.63323
        },
        "meteor": 0.311328312058901,
        "bleurt": -0.105,
        "bertscore": {
            "precision": 0.86951,
            "recall": 0.8633,
            "f1": 0.8659
        }
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 297,
        "total_length": 2806,
        "mean_pred_length": 9.447811447811448,
        "std_pred_length": 2.5302487051478986,
        "median_pred_length": 9.0,
        "min_pred_length": 4,
        "max_pred_length": 24,
        "distinct-1": 0.24554526015680683,
        "vocab_size-1": 689,
        "unique-1": 383,
        "entropy-1": 7.4648184443394285,
        "distinct-2": 0.5683539258668793,
        "vocab_size-2": 1426,
        "unique-2": 1011,
        "entropy-2": 9.970857666958876,
        "cond_entropy-2": 2.009776813695652,
        "distinct-3": 0.7631103074141049,
        "vocab_size-3": 1688,
        "unique-3": 1406,
        "entropy-3": 10.496028043218557,
        "cond_entropy-3": 0.6107812333449307,
        "total_length-nopunct": 2463,
        "mean_pred_length-nopunct": 8.292929292929292,
        "std_pred_length-nopunct": 2.3836671741291218,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.27689809175801866,
        "vocab_size-1-nopunct": 682,
        "unique-1-nopunct": 382,
        "entropy-1-nopunct": 7.774601583950456,
        "distinct-2-nopunct": 0.5461680517082179,
        "vocab_size-2-nopunct": 1183,
        "unique-2-nopunct": 824,
        "entropy-2-nopunct": 9.664103647623763,
        "cond_entropy-2-nopunct": 2.1828193699779677,
        "distinct-3-nopunct": 0.7495987158908507,
        "vocab_size-3-nopunct": 1401,
        "unique-3-nopunct": 1155,
        "entropy-3-nopunct": 10.210812095049134,
        "cond_entropy-3-nopunct": 0.6699117148091641,
        "msttr-100": 0.63964,
        "msttr-100_nopunct": 0.68875,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.22845417236662108,
            "2": 0.6818652849740933,
            "3": 0.8954970263381479,
            "4": 0.9473684210526315
        },
        "nist": 9.30657278902667,
        "bleu": 65.22391,
        "rouge1": {
            "precision": 0.83519,
            "recall": 0.80011,
            "fmeasure": 0.80993
        },
        "rouge2": {
            "precision": 0.63038,
            "recall": 0.60249,
            "fmeasure": 0.61003
        },
        "rougeL": {
            "precision": 0.76574,
            "recall": 0.7333,
            "fmeasure": 0.74201
        },
        "rougeLsum": {
            "precision": 0.76574,
            "recall": 0.7333,
            "fmeasure": 0.74201
        },
        "nubia": {
            "semantic_relation": 4.63255,
            "contradiction": 6.74007,
            "irrelevancy": 6.3834,
            "logical_agreement": 86.87654,
            "grammar_ref": 5.16054,
            "grammar_hyp": 5.23664,
            "nubia_score": 0.84711
        },
        "meteor": 0.48010802999853314,
        "bleurt": 0.44158,
        "bertscore": {
            "precision": 0.9555,
            "recall": 0.95265,
            "f1": 0.95324
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 3,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 2.943920288775949,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 20,
        "distinct-1": 0.875,
        "vocab_size-1": 42,
        "unique-1": 37,
        "entropy-1": 5.319235677759421,
        "distinct-2": 1.0,
        "vocab_size-2": 45,
        "unique-2": 45,
        "entropy-2": 5.491853096329673,
        "cond_entropy-2": 0.08466837338629611,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.0995356735509143,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 2.494438257849294,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.277613436819114,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.357552004618081,
        "cond_entropy-2-nopunct": 0.09324233720029841,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.10962449117449787,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.02564102564102564,
            "2": 0.0,
            "3": 0.25,
            "4": 0.7142857142857143,
            "5": 0.6666666666666666,
            "6": 0.5714285714285714,
            "7": 0.8571428571428571
        },
        "nist": 4.64347687950523,
        "bleu": 55.45988,
        "rouge1": {
            "precision": 0.83995,
            "recall": 0.76563,
            "fmeasure": 0.79305
        },
        "rouge2": {
            "precision": 0.71912,
            "recall": 0.62529,
            "fmeasure": 0.6576
        },
        "rougeL": {
            "precision": 0.81217,
            "recall": 0.73569,
            "fmeasure": 0.76424
        },
        "rougeLsum": {
            "precision": 0.81217,
            "recall": 0.73569,
            "fmeasure": 0.76424
        },
        "nubia": {
            "semantic_relation": 4.38042,
            "contradiction": 0.37997,
            "irrelevancy": 18.95411,
            "logical_agreement": 80.66593,
            "grammar_ref": 4.54431,
            "grammar_hyp": 5.0257,
            "nubia_score": 0.72799
        },
        "meteor": 0.4126035487740927,
        "bleurt": 0.32015,
        "bertscore": {
            "precision": 0.96597,
            "recall": 0.94849,
            "f1": 0.95484
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc_parent": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 6165,
        "mean_pred_length": 17.172701949860723,
        "std_pred_length": 6.145699059785652,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.3772911597729116,
        "vocab_size-1": 2326,
        "unique-1": 1733,
        "entropy-1": 9.077575132617426,
        "distinct-2": 0.83861522562866,
        "vocab_size-2": 4869,
        "unique-2": 4517,
        "entropy-2": 11.942408546717669,
        "cond_entropy-2": 2.689547949982116,
        "distinct-3": 0.965669175693042,
        "vocab_size-3": 5260,
        "unique-3": 5169,
        "entropy-3": 12.295947924068003,
        "cond_entropy-3": 0.37620181953121684,
        "total_length-nopunct": 5505,
        "mean_pred_length-nopunct": 15.334261838440112,
        "std_pred_length-nopunct": 5.655841897975462,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4201634877384196,
        "vocab_size-1-nopunct": 2313,
        "unique-1-nopunct": 1730,
        "entropy-1-nopunct": 9.359233858545359,
        "distinct-2-nopunct": 0.8608628060629615,
        "vocab_size-2-nopunct": 4430,
        "unique-2-nopunct": 4135,
        "entropy-2-nopunct": 11.868219550916795,
        "cond_entropy-2-nopunct": 2.659361395204831,
        "distinct-3-nopunct": 0.9826613745560894,
        "vocab_size-3-nopunct": 4704,
        "unique-3-nopunct": 4633,
        "entropy-3-nopunct": 12.187748308605366,
        "cond_entropy-3-nopunct": 0.3455766021230233,
        "msttr-100": 0.73377,
        "msttr-100_nopunct": 0.76345,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.02682837192208747,
            "2": 0.14690026954177898,
            "3": 0.3,
            "4": 0.4724770642201835,
            "5": 0.5250379362670713,
            "6": 0.6169014084507042,
            "7": 0.6762295081967213,
            "8": 0.7310012062726177,
            "9": 0.7915343915343915,
            "10": 0.8713178294573644
        },
        "nist": 12.365759009195251,
        "bleu": 78.74022,
        "rouge1": {
            "precision": 0.86093,
            "recall": 0.78861,
            "fmeasure": 0.81145
        },
        "rouge2": {
            "precision": 0.74743,
            "recall": 0.67594,
            "fmeasure": 0.69738
        },
        "rougeL": {
            "precision": 0.83942,
            "recall": 0.77122,
            "fmeasure": 0.79268
        },
        "rougeLsum": {
            "precision": 0.83942,
            "recall": 0.77122,
            "fmeasure": 0.79268
        },
        "nubia": {
            "semantic_relation": 3.98836,
            "contradiction": 4.23361,
            "irrelevancy": 30.66105,
            "logical_agreement": 65.10535,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.8726,
            "nubia_score": 0.60978
        },
        "meteor": 0.4522843957100267,
        "bleurt": 0.09688,
        "bertscore": {
            "precision": 0.95755,
            "recall": 0.94529,
            "f1": 0.94713
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_41": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.14421971022094907,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.09400842804332114,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.25,
            "3": 0.6666666666666666
        },
        "nist": 0.9947025013448653,
        "bleu": 5.09121,
        "rouge1": {
            "precision": 0.22222,
            "recall": 0.6,
            "fmeasure": 0.31762
        },
        "rouge2": {
            "precision": 0.1,
            "recall": 0.38889,
            "fmeasure": 0.15278
        },
        "rougeL": {
            "precision": 0.20635,
            "recall": 0.66154,
            "fmeasure": 0.30317
        },
        "rougeLsum": {
            "precision": 0.20635,
            "recall": 0.66154,
            "fmeasure": 0.30317
        },
        "nubia": {
            "semantic_relation": 2.37988,
            "contradiction": 66.82268,
            "irrelevancy": 31.39154,
            "logical_agreement": 1.78578,
            "grammar_ref": 6.66832,
            "grammar_hyp": 4.15848,
            "nubia_score": 0.30101
        },
        "meteor": 0.29061134042487863,
        "bleurt": 0.37382,
        "bertscore": {
            "precision": 0.8563,
            "recall": 0.9484,
            "f1": 0.85626
        }
    },
    "schema_guided_dialog_challenge_train_sample": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_challenge_train_sample",
        "N": 500
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 30,
        "total_length": 599,
        "mean_pred_length": 19.966666666666665,
        "std_pred_length": 5.205659313563354,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 29,
        "distinct-1": 0.5325542570951586,
        "vocab_size-1": 319,
        "unique-1": 252,
        "entropy-1": 7.521817148788592,
        "distinct-2": 0.9068541300527241,
        "vocab_size-2": 516,
        "unique-2": 484,
        "entropy-2": 8.92177778519585,
        "cond_entropy-2": 1.3123212878679096,
        "distinct-3": 0.9721706864564007,
        "vocab_size-3": 524,
        "unique-3": 517,
        "entropy-3": 8.998038401511918,
        "cond_entropy-3": 0.08909032264892541,
        "total_length-nopunct": 534,
        "mean_pred_length-nopunct": 17.8,
        "std_pred_length-nopunct": 4.840110191583107,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5842696629213483,
        "vocab_size-1-nopunct": 312,
        "unique-1-nopunct": 252,
        "entropy-1-nopunct": 7.589512750467009,
        "distinct-2-nopunct": 0.9365079365079365,
        "vocab_size-2-nopunct": 472,
        "unique-2-nopunct": 447,
        "entropy-2-nopunct": 8.836169972153096,
        "cond_entropy-2-nopunct": 1.31906126781088,
        "distinct-3-nopunct": 0.9936708860759493,
        "vocab_size-3-nopunct": 471,
        "unique-3-nopunct": 468,
        "entropy-3-nopunct": 8.876085021050113,
        "cond_entropy-3-nopunct": 0.046736353834552956,
        "msttr-100": 0.718,
        "msttr-100_nopunct": 0.752,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.05429864253393665,
            "2": 0.12345679012345678,
            "3": 0.3220338983050847,
            "4": 0.37681159420289856,
            "5": 0.43478260869565216,
            "6": 0.564935064935065,
            "7": 0.7808219178082192
        },
        "nist": 6.511409420981274,
        "bleu": 53.03473,
        "rouge1": {
            "precision": 0.73465,
            "recall": 0.66327,
            "fmeasure": 0.68299
        },
        "rouge2": {
            "precision": 0.56978,
            "recall": 0.49159,
            "fmeasure": 0.51268
        },
        "rougeL": {
            "precision": 0.6873,
            "recall": 0.62414,
            "fmeasure": 0.63761
        },
        "rougeLsum": {
            "precision": 0.6873,
            "recall": 0.62414,
            "fmeasure": 0.63761
        },
        "nubia": {
            "semantic_relation": 3.84273,
            "contradiction": 4.79301,
            "irrelevancy": 27.28811,
            "logical_agreement": 67.91889,
            "grammar_ref": 4.65355,
            "grammar_hyp": 5.00947,
            "nubia_score": 0.56481
        },
        "meteor": 0.37193394460491563,
        "bleurt": -0.1298,
        "bertscore": {
            "precision": 0.92069,
            "recall": 0.90901,
            "f1": 0.90926
        }
    },
    "web_nlg_en_test": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 1779,
        "total_length": 33791,
        "mean_pred_length": 18.994378864530635,
        "std_pred_length": 6.432507022369304,
        "median_pred_length": 21.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.05809239146518304,
        "vocab_size-1": 1963,
        "unique-1": 652,
        "entropy-1": 8.148897947743496,
        "distinct-2": 0.20507934524553292,
        "vocab_size-2": 6565,
        "unique-2": 3162,
        "entropy-2": 11.240836637755992,
        "cond_entropy-2": 3.0375189647010155,
        "distinct-3": 0.36949690735289253,
        "vocab_size-3": 11171,
        "unique-3": 6809,
        "entropy-3": 12.469150529509806,
        "cond_entropy-3": 1.3398929655321543,
        "total_length-nopunct": 30608,
        "mean_pred_length-nopunct": 17.205171444631816,
        "std_pred_length-nopunct": 6.1133251570603395,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.06383951907997909,
        "vocab_size-1-nopunct": 1954,
        "unique-1-nopunct": 652,
        "entropy-1-nopunct": 8.34004773626422,
        "distinct-2-nopunct": 0.21540809601442992,
        "vocab_size-2-nopunct": 6210,
        "unique-2-nopunct": 3192,
        "entropy-2-nopunct": 11.134309771068043,
        "cond_entropy-2-nopunct": 2.9842340461241257,
        "distinct-3-nopunct": 0.38048059149722735,
        "vocab_size-3-nopunct": 10292,
        "unique-3-nopunct": 6498,
        "entropy-3-nopunct": 12.329954977609155,
        "cond_entropy-3-nopunct": 1.3005786378413153,
        "msttr-100": 0.66507,
        "msttr-100_nopunct": 0.69131,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.1857823168282747,
            "2": 0.5071380013596193,
            "3": 0.7534871794871795,
            "4": 0.8727272727272727,
            "5": 0.7931034482758621
        },
        "nist": 7.027901353556544,
        "bleu": 40.54509,
        "rouge1": {
            "precision": 0.78491,
            "recall": 0.6844,
            "fmeasure": 0.71863
        },
        "rouge2": {
            "precision": 0.53107,
            "recall": 0.46136,
            "fmeasure": 0.48416
        },
        "rougeL": {
            "precision": 0.65182,
            "recall": 0.56901,
            "fmeasure": 0.59651
        },
        "rougeLsum": {
            "precision": 0.65182,
            "recall": 0.56901,
            "fmeasure": 0.59651
        },
        "nubia": {
            "semantic_relation": 4.15478,
            "contradiction": 8.15539,
            "irrelevancy": 9.87251,
            "logical_agreement": 81.97211,
            "grammar_ref": 4.5596,
            "grammar_hyp": 4.79204,
            "nubia_score": 0.67978
        },
        "meteor": 0.3318559757305916,
        "bleurt": 0.0716,
        "bertscore": {
            "precision": 0.92347,
            "recall": 0.90308,
            "f1": 0.91154
        }
    },
    "schema_guided_dialog_challenge_validation_sample": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_challenge_validation_sample",
        "N": 500
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 72,
        "total_length": 778,
        "mean_pred_length": 10.805555555555555,
        "std_pred_length": 2.741851001345669,
        "median_pred_length": 10.0,
        "min_pred_length": 7,
        "max_pred_length": 18,
        "distinct-1": 0.34575835475578404,
        "vocab_size-1": 269,
        "unique-1": 170,
        "entropy-1": 6.768950673382023,
        "distinct-2": 0.6628895184135978,
        "vocab_size-2": 468,
        "unique-2": 343,
        "entropy-2": 8.602575003091536,
        "cond_entropy-2": 1.4934855878562963,
        "distinct-3": 0.7902208201892744,
        "vocab_size-3": 501,
        "unique-3": 414,
        "entropy-3": 8.813145807717362,
        "cond_entropy-3": 0.25295083486909153,
        "total_length-nopunct": 675,
        "mean_pred_length-nopunct": 9.375,
        "std_pred_length-nopunct": 2.1758618981911515,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.3896296296296296,
        "vocab_size-1-nopunct": 263,
        "unique-1-nopunct": 169,
        "entropy-1-nopunct": 6.926588861558316,
        "distinct-2-nopunct": 0.6434494195688225,
        "vocab_size-2-nopunct": 388,
        "unique-2-nopunct": 276,
        "entropy-2-nopunct": 8.323981103399374,
        "cond_entropy-2-nopunct": 1.588121359774477,
        "distinct-3-nopunct": 0.7796610169491526,
        "vocab_size-3-nopunct": 414,
        "unique-3-nopunct": 341,
        "entropy-3-nopunct": 8.529117009343672,
        "cond_entropy-3-nopunct": 0.2437356373389903,
        "msttr-100": 0.61857,
        "msttr-100_nopunct": 0.66,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.23708920187793428,
            "2": 0.6934865900383141,
            "3": 0.8814589665653495
        },
        "nist": 7.412332313519639,
        "bleu": 53.03127,
        "rouge1": {
            "precision": 0.82118,
            "recall": 0.75904,
            "fmeasure": 0.78331
        },
        "rouge2": {
            "precision": 0.57877,
            "recall": 0.53386,
            "fmeasure": 0.55109
        },
        "rougeL": {
            "precision": 0.72614,
            "recall": 0.67353,
            "fmeasure": 0.69368
        },
        "rougeLsum": {
            "precision": 0.72614,
            "recall": 0.67353,
            "fmeasure": 0.69368
        },
        "nubia": {
            "semantic_relation": 4.61947,
            "contradiction": 5.23307,
            "irrelevancy": 6.29099,
            "logical_agreement": 88.47594,
            "grammar_ref": 5.29268,
            "grammar_hyp": 5.72164,
            "nubia_score": 0.78865
        },
        "meteor": 0.4341187909086417,
        "bleurt": 0.35347,
        "bertscore": {
            "precision": 0.93676,
            "recall": 0.93145,
            "f1": 0.93301
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 61,
        "total_length": 1381,
        "mean_pred_length": 22.639344262295083,
        "std_pred_length": 4.250488060250956,
        "median_pred_length": 23.0,
        "min_pred_length": 14,
        "max_pred_length": 33,
        "distinct-1": 0.5097755249818972,
        "vocab_size-1": 704,
        "unique-1": 575,
        "entropy-1": 8.139715625770489,
        "distinct-2": 0.8962121212121212,
        "vocab_size-2": 1183,
        "unique-2": 1115,
        "entropy-2": 10.071938610390172,
        "cond_entropy-2": 1.8765842044201768,
        "distinct-3": 0.9793486894360603,
        "vocab_size-3": 1233,
        "unique-3": 1209,
        "entropy-3": 10.255560760725677,
        "cond_entropy-3": 0.18279247753012345,
        "total_length-nopunct": 1186,
        "mean_pred_length-nopunct": 19.442622950819672,
        "std_pred_length-nopunct": 3.881543508113093,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5868465430016864,
        "vocab_size-1-nopunct": 696,
        "unique-1-nopunct": 572,
        "entropy-1-nopunct": 8.449239542395045,
        "distinct-2-nopunct": 0.9315555555555556,
        "vocab_size-2-nopunct": 1048,
        "unique-2-nopunct": 1002,
        "entropy-2-nopunct": 9.953730488849773,
        "cond_entropy-2-nopunct": 1.5562539989518387,
        "distinct-3-nopunct": 0.9915413533834586,
        "vocab_size-3-nopunct": 1055,
        "unique-3-nopunct": 1046,
        "entropy-3-nopunct": 10.038365142268171,
        "cond_entropy-3-nopunct": 0.08811998162290746,
        "msttr-100": 0.70923,
        "msttr-100_nopunct": 0.77455,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14516129032258066,
            "2": 0.3891402714932127,
            "3": 0.662839248434238
        },
        "nist": 5.9460121633318,
        "bleu": 33.12373,
        "rouge1": {
            "precision": 0.69909,
            "recall": 0.6167,
            "fmeasure": 0.64502
        },
        "rouge2": {
            "precision": 0.42634,
            "recall": 0.37448,
            "fmeasure": 0.39212
        },
        "rougeL": {
            "precision": 0.56218,
            "recall": 0.49921,
            "fmeasure": 0.51998
        },
        "rougeLsum": {
            "precision": 0.56218,
            "recall": 0.49921,
            "fmeasure": 0.51998
        },
        "nubia": {
            "semantic_relation": 3.68791,
            "contradiction": 16.47479,
            "irrelevancy": 29.69059,
            "logical_agreement": 53.83462,
            "grammar_ref": 4.28842,
            "grammar_hyp": 4.57436,
            "nubia_score": 0.55352
        },
        "meteor": 0.3198789684319967,
        "bleurt": -0.03981,
        "bertscore": {
            "precision": 0.90714,
            "recall": 0.89401,
            "f1": 0.89957
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 9,
        "total_length": 169,
        "mean_pred_length": 18.77777777777778,
        "std_pred_length": 5.2446327649804205,
        "median_pred_length": 19.0,
        "min_pred_length": 11,
        "max_pred_length": 26,
        "distinct-1": 0.7337278106508875,
        "vocab_size-1": 124,
        "unique-1": 108,
        "entropy-1": 6.549610300998345,
        "distinct-2": 0.9625,
        "vocab_size-2": 154,
        "unique-2": 153,
        "entropy-2": 7.199106317047348,
        "cond_entropy-2": 0.5661299049087062,
        "distinct-3": 1.0,
        "vocab_size-3": 151,
        "unique-3": 151,
        "entropy-3": 7.238404739325059,
        "cond_entropy-3": 0.046618925592705036,
        "total_length-nopunct": 152,
        "mean_pred_length-nopunct": 16.88888888888889,
        "std_pred_length-nopunct": 4.931631338038255,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7697368421052632,
        "vocab_size-1-nopunct": 117,
        "unique-1-nopunct": 105,
        "entropy-1-nopunct": 6.498819066976678,
        "distinct-2-nopunct": 0.958041958041958,
        "vocab_size-2-nopunct": 137,
        "unique-2-nopunct": 136,
        "entropy-2-nopunct": 7.022448368565787,
        "cond_entropy-2-nopunct": 0.5707759870310604,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 134,
        "unique-3-nopunct": 134,
        "entropy-3-nopunct": 7.06608919045778,
        "cond_entropy-3-nopunct": 0.05287072274209348,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.82,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.05925925925925926,
            "2": 0.18181818181818182,
            "3": 0.0,
            "4": 0.6,
            "5": 0.5294117647058824,
            "6": 0.64,
            "7": 0.7142857142857143
        },
        "nist": 5.846830558887682,
        "bleu": 54.81868,
        "rouge1": {
            "precision": 0.82136,
            "recall": 0.67033,
            "fmeasure": 0.73282
        },
        "rouge2": {
            "precision": 0.62929,
            "recall": 0.49987,
            "fmeasure": 0.55251
        },
        "rougeL": {
            "precision": 0.76723,
            "recall": 0.61071,
            "fmeasure": 0.67544
        },
        "rougeLsum": {
            "precision": 0.76723,
            "recall": 0.61071,
            "fmeasure": 0.67544
        },
        "nubia": {
            "semantic_relation": 3.89059,
            "contradiction": 7.64252,
            "irrelevancy": 21.12363,
            "logical_agreement": 71.23385,
            "grammar_ref": 4.59683,
            "grammar_hyp": 5.25222,
            "nubia_score": 0.55507
        },
        "meteor": 0.3519446820315933,
        "bleurt": -0.0004,
        "bertscore": {
            "precision": 0.93684,
            "recall": 0.90156,
            "f1": 0.91583
        }
    },
    "web_nlg_en_challenge_train_sample": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_challenge_train_sample",
        "N": 502
    },
    "totto_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 40,
        "total_length": 907,
        "mean_pred_length": 22.675,
        "std_pred_length": 4.996936561534477,
        "median_pred_length": 23.0,
        "min_pred_length": 11,
        "max_pred_length": 34,
        "distinct-1": 0.4906284454244763,
        "vocab_size-1": 445,
        "unique-1": 347,
        "entropy-1": 7.708456221798474,
        "distinct-2": 0.8673587081891581,
        "vocab_size-2": 752,
        "unique-2": 707,
        "entropy-2": 9.37639425521527,
        "cond_entropy-2": 1.6724597406133668,
        "distinct-3": 0.9600967351874244,
        "vocab_size-3": 794,
        "unique-3": 774,
        "entropy-3": 9.593604148604442,
        "cond_entropy-3": 0.22794789278666633,
        "total_length-nopunct": 805,
        "mean_pred_length-nopunct": 20.125,
        "std_pred_length-nopunct": 4.2964374777250045,
        "median_pred_length-nopunct": 21.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5403726708074534,
        "vocab_size-1-nopunct": 435,
        "unique-1-nopunct": 342,
        "entropy-1-nopunct": 7.823544467675301,
        "distinct-2-nopunct": 0.8875816993464052,
        "vocab_size-2-nopunct": 679,
        "unique-2-nopunct": 646,
        "entropy-2-nopunct": 9.248113558360542,
        "cond_entropy-2-nopunct": 1.4850427045438048,
        "distinct-3-nopunct": 0.9710344827586207,
        "vocab_size-3-nopunct": 704,
        "unique-3-nopunct": 691,
        "entropy-3-nopunct": 9.429552533927607,
        "cond_entropy-3-nopunct": 0.19356127011922636,
        "msttr-100": 0.70556,
        "msttr-100_nopunct": 0.74125,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19863013698630136,
            "2": 0.4556213017751479,
            "3": 0.687888198757764
        },
        "nist": 6.025306675438672,
        "bleu": 38.40344,
        "rouge1": {
            "precision": 0.76679,
            "recall": 0.65662,
            "fmeasure": 0.69571
        },
        "rouge2": {
            "precision": 0.50616,
            "recall": 0.43023,
            "fmeasure": 0.45877
        },
        "rougeL": {
            "precision": 0.62385,
            "recall": 0.54544,
            "fmeasure": 0.57314
        },
        "rougeLsum": {
            "precision": 0.62385,
            "recall": 0.54544,
            "fmeasure": 0.57314
        },
        "nubia": {
            "semantic_relation": 3.73983,
            "contradiction": 21.78,
            "irrelevancy": 31.9696,
            "logical_agreement": 46.25041,
            "grammar_ref": 4.29053,
            "grammar_hyp": 4.42059,
            "nubia_score": 0.56639
        },
        "meteor": 0.33318131748161967,
        "bleurt": 0.01929,
        "bertscore": {
            "precision": 0.91636,
            "recall": 0.89956,
            "f1": 0.9067
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 63,
        "total_length": 1270,
        "mean_pred_length": 20.158730158730158,
        "std_pred_length": 5.883003091247712,
        "median_pred_length": 22.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.48031496062992124,
        "vocab_size-1": 610,
        "unique-1": 483,
        "entropy-1": 8.075508239710238,
        "distinct-2": 0.8931234465617233,
        "vocab_size-2": 1078,
        "unique-2": 1028,
        "entropy-2": 9.894272773865419,
        "cond_entropy-2": 1.75749611033834,
        "distinct-3": 0.9615384615384616,
        "vocab_size-3": 1100,
        "unique-3": 1090,
        "entropy-3": 10.009847669770988,
        "cond_entropy-3": 0.12850993773424824,
        "total_length-nopunct": 1144,
        "mean_pred_length-nopunct": 18.158730158730158,
        "std_pred_length-nopunct": 5.523991969254847,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5270979020979021,
        "vocab_size-1-nopunct": 603,
        "unique-1-nopunct": 480,
        "entropy-1-nopunct": 8.225383158691608,
        "distinct-2-nopunct": 0.9343200740055504,
        "vocab_size-2-nopunct": 1010,
        "unique-2-nopunct": 967,
        "entropy-2-nopunct": 9.918590611627925,
        "cond_entropy-2-nopunct": 1.764391896713604,
        "distinct-3-nopunct": 0.9941060903732809,
        "vocab_size-3-nopunct": 1012,
        "unique-3-nopunct": 1006,
        "entropy-3-nopunct": 9.979734026822332,
        "cond_entropy-3-nopunct": 0.06179172062827698,
        "msttr-100": 0.74167,
        "msttr-100_nopunct": 0.76727,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.044358727097396335,
            "2": 0.11801242236024845,
            "3": 0.2978723404255319,
            "4": 0.41044776119402987,
            "5": 0.4627450980392157,
            "6": 0.5566750629722922,
            "7": 0.7094339622641509
        },
        "nist": 6.2426177093505135,
        "bleu": 53.31814,
        "rouge1": {
            "precision": 0.77996,
            "recall": 0.62217,
            "fmeasure": 0.67372
        },
        "rouge2": {
            "precision": 0.62686,
            "recall": 0.49984,
            "fmeasure": 0.53822
        },
        "rougeL": {
            "precision": 0.75134,
            "recall": 0.60686,
            "fmeasure": 0.65124
        },
        "rougeLsum": {
            "precision": 0.75134,
            "recall": 0.60686,
            "fmeasure": 0.65124
        },
        "nubia": {
            "semantic_relation": 3.71093,
            "contradiction": 8.86887,
            "irrelevancy": 24.96555,
            "logical_agreement": 66.16558,
            "grammar_ref": 4.43738,
            "grammar_hyp": 4.96467,
            "nubia_score": 0.52898
        },
        "meteor": 0.34591602478106853,
        "bleurt": -0.19459,
        "bertscore": {
            "precision": 0.92349,
            "recall": 0.89949,
            "f1": 0.9061
        }
    },
    "web_nlg_en_challenge_validation_sample": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_challenge_validation_sample",
        "N": 499
    },
    "totto_test_contrast_challenge_ethnicity-all_usa": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 128,
        "total_length": 2045,
        "mean_pred_length": 15.9765625,
        "std_pred_length": 5.305458338691743,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.42200488997555013,
        "vocab_size-1": 863,
        "unique-1": 684,
        "entropy-1": 8.166316503304612,
        "distinct-2": 0.8268127282211789,
        "vocab_size-2": 1585,
        "unique-2": 1438,
        "entropy-2": 10.392008847671672,
        "cond_entropy-2": 1.9731456490623516,
        "distinct-3": 0.951369480156512,
        "vocab_size-3": 1702,
        "unique-3": 1644,
        "entropy-3": 10.685106595223784,
        "cond_entropy-3": 0.25101635862920396,
        "total_length-nopunct": 1779,
        "mean_pred_length-nopunct": 13.8984375,
        "std_pred_length-nopunct": 4.837741989667674,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4822934232715008,
        "vocab_size-1-nopunct": 858,
        "unique-1-nopunct": 684,
        "entropy-1-nopunct": 8.497837549776238,
        "distinct-2-nopunct": 0.854633555420957,
        "vocab_size-2-nopunct": 1411,
        "unique-2-nopunct": 1302,
        "entropy-2-nopunct": 10.254996449207525,
        "cond_entropy-2-nopunct": 1.8161390101494324,
        "distinct-3-nopunct": 0.9671700590938936,
        "vocab_size-3-nopunct": 1473,
        "unique-3-nopunct": 1437,
        "entropy-3-nopunct": 10.49712991530539,
        "cond_entropy-3-nopunct": 0.2380778204707498,
        "msttr-100": 0.698,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19174041297935104,
            "2": 0.32653061224489793,
            "3": 0.8171390013495277
        },
        "nist": 8.038501776317943,
        "bleu": 48.21895,
        "rouge1": {
            "precision": 0.81443,
            "recall": 0.78216,
            "fmeasure": 0.79155
        },
        "rouge2": {
            "precision": 0.56831,
            "recall": 0.55066,
            "fmeasure": 0.55448
        },
        "rougeL": {
            "precision": 0.70227,
            "recall": 0.68281,
            "fmeasure": 0.68586
        },
        "rougeLsum": {
            "precision": 0.70227,
            "recall": 0.68281,
            "fmeasure": 0.68586
        },
        "nubia": {
            "semantic_relation": 4.51686,
            "contradiction": 5.15293,
            "irrelevancy": 19.02262,
            "logical_agreement": 75.82445,
            "grammar_ref": 4.60573,
            "grammar_hyp": 4.54863,
            "nubia_score": 0.83055
        },
        "meteor": 0.4134293851759436,
        "bleurt": 0.38668,
        "bertscore": {
            "precision": 0.93953,
            "recall": 0.93819,
            "f1": 0.93748
        }
    },
    "web_nlg_en_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 1295,
        "total_length": 28363,
        "mean_pred_length": 21.9019305019305,
        "std_pred_length": 4.440124626389751,
        "median_pred_length": 23.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.06258153227796777,
        "vocab_size-1": 1775,
        "unique-1": 609,
        "entropy-1": 8.112067187437672,
        "distinct-2": 0.21183685532732377,
        "vocab_size-2": 5734,
        "unique-2": 2798,
        "entropy-2": 11.101549588940241,
        "cond_entropy-2": 2.9942602021844915,
        "distinct-3": 0.375121250921507,
        "vocab_size-3": 9668,
        "unique-3": 5911,
        "entropy-3": 12.299184738447439,
        "cond_entropy-3": 1.2978446233180276,
        "total_length-nopunct": 25821,
        "mean_pred_length-nopunct": 19.93899613899614,
        "std_pred_length-nopunct": 4.315562275850257,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.06839394291468184,
        "vocab_size-1-nopunct": 1766,
        "unique-1-nopunct": 609,
        "entropy-1-nopunct": 8.27828375708934,
        "distinct-2-nopunct": 0.22465954497268206,
        "vocab_size-2-nopunct": 5510,
        "unique-2-nopunct": 2875,
        "entropy-2-nopunct": 11.03467477686022,
        "cond_entropy-2-nopunct": 2.9200275183184226,
        "distinct-3-nopunct": 0.38861865610606516,
        "vocab_size-3-nopunct": 9028,
        "unique-3-nopunct": 5723,
        "entropy-3-nopunct": 12.18782791809653,
        "cond_entropy-3-nopunct": 1.2474609065775581,
        "msttr-100": 0.66325,
        "msttr-100_nopunct": 0.68849,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.1782386943216593,
            "2": 0.47893751462672596,
            "3": 0.7338775989662869,
            "4": 0.7058823529411765,
            "5": 0.7931034482758621
        },
        "nist": 6.307103852376967,
        "bleu": 37.40241,
        "rouge1": {
            "precision": 0.76889,
            "recall": 0.64645,
            "fmeasure": 0.68851
        },
        "rouge2": {
            "precision": 0.5007,
            "recall": 0.41702,
            "fmeasure": 0.44465
        },
        "rougeL": {
            "precision": 0.6158,
            "recall": 0.51594,
            "fmeasure": 0.54954
        },
        "rougeLsum": {
            "precision": 0.6158,
            "recall": 0.51594,
            "fmeasure": 0.54954
        },
        "nubia": {
            "semantic_relation": 3.98084,
            "contradiction": 9.06226,
            "irrelevancy": 11.38467,
            "logical_agreement": 79.55307,
            "grammar_ref": 4.37017,
            "grammar_hyp": 4.64524,
            "nubia_score": 0.62165
        },
        "meteor": 0.31326964476139113,
        "bleurt": -0.0521,
        "bertscore": {
            "precision": 0.91352,
            "recall": 0.88695,
            "f1": 0.89825
        }
    },
    "mlsum_es_test": {
        "predictions_file": "ByT5-base (Baseline)/mlsum_es_test",
        "N": 13366,
        "total_length": 267380,
        "mean_pred_length": 20.004489001945235,
        "std_pred_length": 3.7166163869761695,
        "median_pred_length": 20.0,
        "min_pred_length": 9,
        "max_pred_length": 36,
        "distinct-1": 0.10994090807091031,
        "vocab_size-1": 29396,
        "unique-1": 16295,
        "entropy-1": 10.01365285468189,
        "distinct-2": 0.4704150164951538,
        "vocab_size-2": 119492,
        "unique-2": 93138,
        "entropy-2": 15.29398611040638,
        "cond_entropy-2": 5.477830490118696,
        "distinct-3": 0.791853661779861,
        "vocab_size-3": 190558,
        "unique-3": 171684,
        "entropy-3": 17.16440001276337,
        "cond_entropy-3": 1.9319525841770966,
        "total_length-nopunct": 259546,
        "mean_pred_length-nopunct": 19.418374981295827,
        "std_pred_length-nopunct": 3.420310242297954,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.11319766053031062,
        "vocab_size-1-nopunct": 29380,
        "unique-1-nopunct": 16293,
        "entropy-1-nopunct": 10.061159227658386,
        "distinct-2-nopunct": 0.47852790640994397,
        "vocab_size-2-nopunct": 117804,
        "unique-2-nopunct": 92413,
        "entropy-2-nopunct": 15.297713710333172,
        "cond_entropy-2-nopunct": 5.4425745437264625,
        "distinct-3-nopunct": 0.7966531222349171,
        "vocab_size-3-nopunct": 185472,
        "unique-3-nopunct": 167614,
        "entropy-3-nopunct": 17.13207962545171,
        "cond_entropy-3-nopunct": 1.8956338613589314,
        "msttr-100": 0.70358,
        "msttr-100_nopunct": 0.70469,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_test.json",
        "local_recall": {
            "1": 0.2717296835677416
        },
        "nist": 3.024545921510099,
        "bleu": 8.58073,
        "rouge1": {
            "precision": 0.3275,
            "recall": 0.29453,
            "fmeasure": 0.30202
        },
        "rouge2": {
            "precision": 0.12977,
            "recall": 0.1176,
            "fmeasure": 0.12019
        },
        "rougeL": {
            "precision": 0.26276,
            "recall": 0.23849,
            "fmeasure": 0.24356
        },
        "rougeLsum": {
            "precision": 0.26276,
            "recall": 0.23849,
            "fmeasure": 0.24356
        },
        "nubia": {
            "semantic_relation": 1.74211,
            "contradiction": 28.18715,
            "irrelevancy": 59.0074,
            "logical_agreement": 12.80545,
            "grammar_ref": 5.26998,
            "grammar_hyp": 5.22116,
            "nubia_score": 0.19685
        },
        "meteor": 0.21625661747502464,
        "bleurt": -0.42162,
        "bertscore": {
            "precision": 0.84503,
            "recall": 0.83761,
            "f1": 0.84113
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_11": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 20,
        "total_length": 442,
        "mean_pred_length": 22.1,
        "std_pred_length": 6.081940479813987,
        "median_pred_length": 22.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.581447963800905,
        "vocab_size-1": 257,
        "unique-1": 217,
        "entropy-1": 7.174995505536617,
        "distinct-2": 0.9241706161137441,
        "vocab_size-2": 390,
        "unique-2": 372,
        "entropy-2": 8.534047774087382,
        "cond_entropy-2": 1.3715123184964908,
        "distinct-3": 0.9875621890547264,
        "vocab_size-3": 397,
        "unique-3": 392,
        "entropy-3": 8.626176069288334,
        "cond_entropy-3": 0.09445086577395756,
        "total_length-nopunct": 375,
        "mean_pred_length-nopunct": 18.75,
        "std_pred_length-nopunct": 4.9180788932265,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 250,
        "unique-1-nopunct": 215,
        "entropy-1-nopunct": 7.356316920465572,
        "distinct-2-nopunct": 0.9492957746478873,
        "vocab_size-2-nopunct": 337,
        "unique-2-nopunct": 325,
        "entropy-2-nopunct": 8.357508101679464,
        "cond_entropy-2-nopunct": 1.060032300364149,
        "distinct-3-nopunct": 0.9970149253731343,
        "vocab_size-3-nopunct": 334,
        "unique-3-nopunct": 333,
        "entropy-3-nopunct": 8.382047136091437,
        "cond_entropy-3-nopunct": 0.03135498143960024,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.77667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14942528735632185,
            "2": 0.32967032967032966,
            "3": 0.6054216867469879
        },
        "nist": 3.647556830234721,
        "bleu": 30.83105,
        "rouge1": {
            "precision": 0.69145,
            "recall": 0.55746,
            "fmeasure": 0.59212
        },
        "rouge2": {
            "precision": 0.45674,
            "recall": 0.36852,
            "fmeasure": 0.39027
        },
        "rougeL": {
            "precision": 0.53303,
            "recall": 0.44118,
            "fmeasure": 0.46105
        },
        "rougeLsum": {
            "precision": 0.53303,
            "recall": 0.44118,
            "fmeasure": 0.46105
        },
        "nubia": {
            "semantic_relation": 3.30263,
            "contradiction": 22.92149,
            "irrelevancy": 24.12677,
            "logical_agreement": 52.95173,
            "grammar_ref": 4.38156,
            "grammar_hyp": 4.58653,
            "nubia_score": 0.43922
        },
        "meteor": 0.2772571098005006,
        "bleurt": -0.1502,
        "bertscore": {
            "precision": 0.90587,
            "recall": 0.88005,
            "f1": 0.88741
        }
    },
    "mlsum_es_challenge_train_sample": {
        "predictions_file": "ByT5-base (Baseline)/mlsum_es_challenge_train_sample",
        "N": 500
    },
    "mlsum_es_challenge_validation_sample": {
        "predictions_file": "ByT5-base (Baseline)/mlsum_es_challenge_validation_sample",
        "N": 500
    },
    "web_nlg_en_challenge_test_scramble": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_challenge_test_scramble",
        "N": 500,
        "total_length": 9397,
        "mean_pred_length": 18.794,
        "std_pred_length": 6.588441697397041,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.13323401085452805,
        "vocab_size-1": 1252,
        "unique-1": 491,
        "entropy-1": 8.02894811376328,
        "distinct-2": 0.3819264920759807,
        "vocab_size-2": 3398,
        "unique-2": 2037,
        "entropy-2": 10.83719175967446,
        "cond_entropy-2": 2.744454312442494,
        "distinct-3": 0.5799690365606764,
        "vocab_size-3": 4870,
        "unique-3": 3525,
        "entropy-3": 11.754196289363394,
        "cond_entropy-3": 0.9997667625798056,
        "total_length-nopunct": 8491,
        "mean_pred_length-nopunct": 16.982,
        "std_pred_length-nopunct": 6.19690858412483,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.14650806736544578,
        "vocab_size-1-nopunct": 1244,
        "unique-1-nopunct": 489,
        "entropy-1-nopunct": 8.224163021941038,
        "distinct-2-nopunct": 0.3908146664998123,
        "vocab_size-2-nopunct": 3123,
        "unique-2-nopunct": 1917,
        "entropy-2-nopunct": 10.720207985116378,
        "cond_entropy-2-nopunct": 2.6598404227303605,
        "distinct-3-nopunct": 0.5908423441463089,
        "vocab_size-3-nopunct": 4426,
        "unique-3-nopunct": 3272,
        "entropy-3-nopunct": 11.612062844375625,
        "cond_entropy-3-nopunct": 0.967403925075198,
        "msttr-100": 0.52753,
        "msttr-100_nopunct": 0.54036,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.19035382486657443,
            "2": 0.513403461146929,
            "3": 0.7518698578908003,
            "4": 0.4,
            "5": 0.7777777777777778
        },
        "nist": 6.8407577514308535,
        "bleu": 40.8543,
        "rouge1": {
            "precision": 0.78423,
            "recall": 0.68293,
            "fmeasure": 0.7184
        },
        "rouge2": {
            "precision": 0.53499,
            "recall": 0.46462,
            "fmeasure": 0.48866
        },
        "rougeL": {
            "precision": 0.65149,
            "recall": 0.56841,
            "fmeasure": 0.59679
        },
        "rougeLsum": {
            "precision": 0.65149,
            "recall": 0.56841,
            "fmeasure": 0.59679
        },
        "nubia": {
            "semantic_relation": 4.14025,
            "contradiction": 8.28023,
            "irrelevancy": 9.64702,
            "logical_agreement": 82.07275,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.8003,
            "nubia_score": 0.67684
        },
        "meteor": 0.3326188498801334,
        "bleurt": 0.07199,
        "bertscore": {
            "precision": 0.92382,
            "recall": 0.90319,
            "f1": 0.91182
        }
    },
    "web_nlg_en_challenge_test_numbers": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_challenge_test_numbers",
        "N": 500,
        "total_length": 9622,
        "mean_pred_length": 19.244,
        "std_pred_length": 6.389402475975355,
        "median_pred_length": 21.0,
        "min_pred_length": 4,
        "max_pred_length": 31,
        "distinct-1": 0.1359384743296612,
        "vocab_size-1": 1308,
        "unique-1": 567,
        "entropy-1": 8.049434404476102,
        "distinct-2": 0.3770006577504933,
        "vocab_size-2": 3439,
        "unique-2": 2105,
        "entropy-2": 10.833754541569533,
        "cond_entropy-2": 2.719894169675903,
        "distinct-3": 0.5727209464161448,
        "vocab_size-3": 4938,
        "unique-3": 3585,
        "entropy-3": 11.750580014244834,
        "cond_entropy-3": 0.9984726307413875,
        "total_length-nopunct": 8722,
        "mean_pred_length-nopunct": 17.444,
        "std_pred_length-nopunct": 6.112844182538927,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.14904838339830315,
        "vocab_size-1-nopunct": 1300,
        "unique-1-nopunct": 567,
        "entropy-1-nopunct": 8.225024692341783,
        "distinct-2-nopunct": 0.38263196302602775,
        "vocab_size-2-nopunct": 3146,
        "unique-2-nopunct": 1962,
        "entropy-2-nopunct": 10.709240623597722,
        "cond_entropy-2-nopunct": 2.6435397738377024,
        "distinct-3-nopunct": 0.5766640766640767,
        "vocab_size-3-nopunct": 4453,
        "unique-3-nopunct": 3287,
        "entropy-3-nopunct": 11.586695732126323,
        "cond_entropy-3-nopunct": 0.9508876682957248,
        "msttr-100": 0.66573,
        "msttr-100_nopunct": 0.69184,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_numbers.json",
        "local_recall": {
            "1": 0.186075684716705,
            "2": 0.5070519435844513,
            "3": 0.7495967019179064,
            "4": 0.6666666666666666,
            "5": 0.9090909090909091
        },
        "nist": 6.678968879282478,
        "bleu": 40.67313,
        "rouge1": {
            "precision": 0.78298,
            "recall": 0.67333,
            "fmeasure": 0.71175
        },
        "rouge2": {
            "precision": 0.52832,
            "recall": 0.45233,
            "fmeasure": 0.47797
        },
        "rougeL": {
            "precision": 0.65134,
            "recall": 0.56081,
            "fmeasure": 0.59172
        },
        "rougeLsum": {
            "precision": 0.65134,
            "recall": 0.56081,
            "fmeasure": 0.59172
        },
        "nubia": {
            "semantic_relation": 4.0112,
            "contradiction": 19.2637,
            "irrelevancy": 8.88602,
            "logical_agreement": 71.85028,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.74699,
            "nubia_score": 0.63577
        },
        "meteor": 0.32986472802073,
        "bleurt": 0.06491,
        "bertscore": {
            "precision": 0.92404,
            "recall": 0.90296,
            "f1": 0.91164
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 254,
        "total_length": 2154,
        "mean_pred_length": 8.48031496062992,
        "std_pred_length": 2.169402086430919,
        "median_pred_length": 8.0,
        "min_pred_length": 4,
        "max_pred_length": 14,
        "distinct-1": 0.42896935933147634,
        "vocab_size-1": 924,
        "unique-1": 635,
        "entropy-1": 8.429466254299927,
        "distinct-2": 0.7705263157894737,
        "vocab_size-2": 1464,
        "unique-2": 1207,
        "entropy-2": 10.291420613865258,
        "cond_entropy-2": 1.2829948073650386,
        "distinct-3": 0.8930741190765492,
        "vocab_size-3": 1470,
        "unique-3": 1331,
        "entropy-3": 10.444506098894673,
        "cond_entropy-3": 0.13933581319115645,
        "total_length-nopunct": 1759,
        "mean_pred_length-nopunct": 6.925196850393701,
        "std_pred_length-nopunct": 2.011364112032225,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.5224559408754974,
        "vocab_size-1-nopunct": 919,
        "unique-1-nopunct": 635,
        "entropy-1-nopunct": 9.072754791572926,
        "distinct-2-nopunct": 0.7946843853820598,
        "vocab_size-2-nopunct": 1196,
        "unique-2-nopunct": 1008,
        "entropy-2-nopunct": 10.025683597821326,
        "cond_entropy-2-nopunct": 1.079028257319156,
        "distinct-3-nopunct": 0.9024780175859313,
        "vocab_size-3-nopunct": 1129,
        "unique-3-nopunct": 1032,
        "entropy-3-nopunct": 10.06940537277182,
        "cond_entropy-3-nopunct": 0.10170840338325597,
        "msttr-100": 0.76048,
        "msttr-100_nopunct": 0.87353,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.391304347826087,
            "2": 0.7212205270457698,
            "3": 0.8054607508532423,
            "4": 0.8285714285714286,
            "5": 0.8181818181818182,
            "6": 0.9,
            "7": 1.0
        },
        "nist": 8.526768049367975,
        "bleu": 59.99053,
        "rouge1": {
            "precision": 0.3033,
            "recall": 0.30207,
            "fmeasure": 0.30148
        },
        "rouge2": {
            "precision": 0.17982,
            "recall": 0.1787,
            "fmeasure": 0.17812
        },
        "rougeL": {
            "precision": 0.29969,
            "recall": 0.29862,
            "fmeasure": 0.29797
        },
        "rougeLsum": {
            "precision": 0.29969,
            "recall": 0.29862,
            "fmeasure": 0.29797
        },
        "nubia": {
            "semantic_relation": 4.19579,
            "contradiction": 19.65559,
            "irrelevancy": 20.75245,
            "logical_agreement": 59.59197,
            "grammar_ref": 2.90382,
            "grammar_hyp": 2.88406,
            "nubia_score": 0.84629
        },
        "meteor": 0.7446970701097708,
        "bleurt": 0.40662,
        "bertscore": {
            "precision": 0.9703,
            "recall": 0.96879,
            "f1": 0.96905
        }
    },
    "totto_test_contrast_challenge_continent-africa": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 45,
        "total_length": 711,
        "mean_pred_length": 15.8,
        "std_pred_length": 5.057887130237509,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 26,
        "distinct-1": 0.4669479606188467,
        "vocab_size-1": 332,
        "unique-1": 252,
        "entropy-1": 7.264122812680317,
        "distinct-2": 0.8243243243243243,
        "vocab_size-2": 549,
        "unique-2": 488,
        "entropy-2": 8.875695996347796,
        "cond_entropy-2": 1.4367573055472636,
        "distinct-3": 0.9516908212560387,
        "vocab_size-3": 591,
        "unique-3": 566,
        "entropy-3": 9.174174277057524,
        "cond_entropy-3": 0.3081175829269617,
        "total_length-nopunct": 639,
        "mean_pred_length-nopunct": 14.2,
        "std_pred_length-nopunct": 4.973708654291863,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5117370892018779,
        "vocab_size-1-nopunct": 327,
        "unique-1-nopunct": 250,
        "entropy-1-nopunct": 7.407306967943398,
        "distinct-2-nopunct": 0.8198653198653199,
        "vocab_size-2-nopunct": 487,
        "unique-2-nopunct": 433,
        "entropy-2-nopunct": 8.687066938316862,
        "cond_entropy-2-nopunct": 1.357444367503784,
        "distinct-3-nopunct": 0.9508196721311475,
        "vocab_size-3-nopunct": 522,
        "unique-3-nopunct": 500,
        "entropy-3-nopunct": 8.993640685995842,
        "cond_entropy-3-nopunct": 0.32913567519964215,
        "msttr-100": 0.69571,
        "msttr-100_nopunct": 0.74333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18,
            "2": 0.46875,
            "3": 0.7773279352226721
        },
        "nist": 6.97364952799829,
        "bleu": 44.55556,
        "rouge1": {
            "precision": 0.80216,
            "recall": 0.74154,
            "fmeasure": 0.75706
        },
        "rouge2": {
            "precision": 0.55456,
            "recall": 0.51671,
            "fmeasure": 0.52373
        },
        "rougeL": {
            "precision": 0.66185,
            "recall": 0.61171,
            "fmeasure": 0.62406
        },
        "rougeLsum": {
            "precision": 0.66185,
            "recall": 0.61171,
            "fmeasure": 0.62406
        },
        "nubia": {
            "semantic_relation": 4.3593,
            "contradiction": 3.32389,
            "irrelevancy": 23.65253,
            "logical_agreement": 73.02358,
            "grammar_ref": 4.86201,
            "grammar_hyp": 4.93125,
            "nubia_score": 0.76715
        },
        "meteor": 0.39869803648489066,
        "bleurt": 0.3304,
        "bertscore": {
            "precision": 0.93927,
            "recall": 0.9303,
            "f1": 0.93399
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation_parent": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 5986,
        "mean_pred_length": 16.67409470752089,
        "std_pred_length": 6.112881754523878,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.36886067490811897,
        "vocab_size-1": 2208,
        "unique-1": 1641,
        "entropy-1": 9.001750926260584,
        "distinct-2": 0.8324151412830993,
        "vocab_size-2": 4684,
        "unique-2": 4336,
        "entropy-2": 11.870352365250671,
        "cond_entropy-2": 2.6610286399774434,
        "distinct-3": 0.961085801063022,
        "vocab_size-3": 5063,
        "unique-3": 4970,
        "entropy-3": 12.228966809207297,
        "cond_entropy-3": 0.3835869085849308,
        "total_length-nopunct": 5365,
        "mean_pred_length-nopunct": 14.944289693593316,
        "std_pred_length-nopunct": 5.665928515603843,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4093196644920783,
        "vocab_size-1-nopunct": 2196,
        "unique-1-nopunct": 1638,
        "entropy-1-nopunct": 9.280172905984818,
        "distinct-2-nopunct": 0.853775469436676,
        "vocab_size-2-nopunct": 4274,
        "unique-2-nopunct": 3972,
        "entropy-2-nopunct": 11.806624112593747,
        "cond_entropy-2-nopunct": 2.6804708872569805,
        "distinct-3-nopunct": 0.978480740262535,
        "vocab_size-3-nopunct": 4547,
        "unique-3-nopunct": 4469,
        "entropy-3-nopunct": 12.133531549707403,
        "cond_entropy-3-nopunct": 0.35101702544693203,
        "msttr-100": 0.73542,
        "msttr-100_nopunct": 0.77038,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.0432937181663837,
            "2": 0.14431673052362706,
            "3": 0.3041575492341357,
            "4": 0.38510301109350237,
            "5": 0.5015576323987538,
            "6": 0.6147342995169082,
            "7": 0.7541046200840015
        },
        "nist": 8.236004323684183,
        "bleu": 56.24873,
        "rouge1": {
            "precision": 0.81013,
            "recall": 0.68308,
            "fmeasure": 0.72532
        },
        "rouge2": {
            "precision": 0.64479,
            "recall": 0.53362,
            "fmeasure": 0.56943
        },
        "rougeL": {
            "precision": 0.77178,
            "recall": 0.65045,
            "fmeasure": 0.69009
        },
        "rougeLsum": {
            "precision": 0.77178,
            "recall": 0.65045,
            "fmeasure": 0.69009
        },
        "nubia": {
            "semantic_relation": 3.92989,
            "contradiction": 6.74605,
            "irrelevancy": 19.20804,
            "logical_agreement": 74.04591,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.02615,
            "nubia_score": 0.59868
        },
        "meteor": 0.3762137184057809,
        "bleurt": 0.01465,
        "bertscore": {
            "precision": 0.93885,
            "recall": 0.91243,
            "f1": 0.9219
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_12": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 26,
        "total_length": 661,
        "mean_pred_length": 25.423076923076923,
        "std_pred_length": 4.691834780708658,
        "median_pred_length": 25.0,
        "min_pred_length": 14,
        "max_pred_length": 35,
        "distinct-1": 0.5249621785173979,
        "vocab_size-1": 347,
        "unique-1": 269,
        "entropy-1": 7.461690926353288,
        "distinct-2": 0.8834645669291339,
        "vocab_size-2": 561,
        "unique-2": 514,
        "entropy-2": 9.014023139545289,
        "cond_entropy-2": 1.5716912547650208,
        "distinct-3": 0.9720853858784894,
        "vocab_size-3": 592,
        "unique-3": 578,
        "entropy-3": 9.189945564865113,
        "cond_entropy-3": 0.18694267276624899,
        "total_length-nopunct": 569,
        "mean_pred_length-nopunct": 21.884615384615383,
        "std_pred_length-nopunct": 3.609036980829385,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5975395430579965,
        "vocab_size-1-nopunct": 340,
        "unique-1-nopunct": 267,
        "entropy-1-nopunct": 7.669536679981095,
        "distinct-2-nopunct": 0.9244935543278084,
        "vocab_size-2-nopunct": 502,
        "unique-2-nopunct": 473,
        "entropy-2-nopunct": 8.90824429391683,
        "cond_entropy-2-nopunct": 1.2796129587195624,
        "distinct-3-nopunct": 0.9806576402321083,
        "vocab_size-3-nopunct": 507,
        "unique-3-nopunct": 499,
        "entropy-3-nopunct": 8.971467278825658,
        "cond_entropy-3-nopunct": 0.06436547318934856,
        "msttr-100": 0.70333,
        "msttr-100_nopunct": 0.742,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14166666666666666,
            "2": 0.40336134453781514,
            "3": 0.6607929515418502
        },
        "nist": 4.729445451098401,
        "bleu": 32.56527,
        "rouge1": {
            "precision": 0.76209,
            "recall": 0.59868,
            "fmeasure": 0.65953
        },
        "rouge2": {
            "precision": 0.49123,
            "recall": 0.38114,
            "fmeasure": 0.42192
        },
        "rougeL": {
            "precision": 0.62134,
            "recall": 0.48561,
            "fmeasure": 0.53599
        },
        "rougeLsum": {
            "precision": 0.62134,
            "recall": 0.48561,
            "fmeasure": 0.53599
        },
        "nubia": {
            "semantic_relation": 3.41978,
            "contradiction": 20.87728,
            "irrelevancy": 23.691,
            "logical_agreement": 55.43172,
            "grammar_ref": 4.04917,
            "grammar_hyp": 4.28703,
            "nubia_score": 0.48731
        },
        "meteor": 0.3009277850833875,
        "bleurt": -0.08762,
        "bertscore": {
            "precision": 0.91052,
            "recall": 0.88988,
            "f1": 0.89804
        }
    },
    "wiki_auto_asset_turk_test_turk": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 5986,
        "mean_pred_length": 16.67409470752089,
        "std_pred_length": 6.112881754523878,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.36886067490811897,
        "vocab_size-1": 2208,
        "unique-1": 1641,
        "entropy-1": 9.001750926260584,
        "distinct-2": 0.8324151412830993,
        "vocab_size-2": 4684,
        "unique-2": 4336,
        "entropy-2": 11.870352365250671,
        "cond_entropy-2": 2.6610286399774434,
        "distinct-3": 0.961085801063022,
        "vocab_size-3": 5063,
        "unique-3": 4970,
        "entropy-3": 12.228966809207297,
        "cond_entropy-3": 0.3835869085849308,
        "total_length-nopunct": 5365,
        "mean_pred_length-nopunct": 14.944289693593316,
        "std_pred_length-nopunct": 5.665928515603843,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4093196644920783,
        "vocab_size-1-nopunct": 2196,
        "unique-1-nopunct": 1638,
        "entropy-1-nopunct": 9.280172905984818,
        "distinct-2-nopunct": 0.853775469436676,
        "vocab_size-2-nopunct": 4274,
        "unique-2-nopunct": 3972,
        "entropy-2-nopunct": 11.806624112593747,
        "cond_entropy-2-nopunct": 2.6804708872569805,
        "distinct-3-nopunct": 0.978480740262535,
        "vocab_size-3-nopunct": 4547,
        "unique-3-nopunct": 4469,
        "entropy-3-nopunct": 12.133531549707403,
        "cond_entropy-3-nopunct": 0.35101702544693203,
        "msttr-100": 0.73542,
        "msttr-100_nopunct": 0.77038,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.0432937181663837,
            "2": 0.14431673052362706,
            "3": 0.3041575492341357,
            "4": 0.38510301109350237,
            "5": 0.5015576323987538,
            "6": 0.6147342995169082,
            "7": 0.7541046200840015
        },
        "nist": 8.236004323684183,
        "bleu": 56.24873,
        "rouge1": {
            "precision": 0.81013,
            "recall": 0.68308,
            "fmeasure": 0.72532
        },
        "rouge2": {
            "precision": 0.64479,
            "recall": 0.53362,
            "fmeasure": 0.56943
        },
        "rougeL": {
            "precision": 0.77178,
            "recall": 0.65045,
            "fmeasure": 0.69009
        },
        "rougeLsum": {
            "precision": 0.77178,
            "recall": 0.65045,
            "fmeasure": 0.69009
        },
        "sari": 41.30457,
        "nubia": {
            "semantic_relation": 3.92989,
            "contradiction": 6.74605,
            "irrelevancy": 19.20804,
            "logical_agreement": 74.04591,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.02615,
            "nubia_score": 0.59868
        },
        "meteor": 0.3762137184057809,
        "bleurt": 0.01465,
        "bertscore": {
            "precision": 0.93885,
            "recall": 0.91243,
            "f1": 0.9219
        }
    },
    "web_nlg_en_test_contrast_challenge_combinations-seen": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 115,
        "total_length": 1844,
        "mean_pred_length": 16.034782608695654,
        "std_pred_length": 3.940713761838206,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.27765726681127983,
        "vocab_size-1": 512,
        "unique-1": 258,
        "entropy-1": 7.484955654569055,
        "distinct-2": 0.5841526894158473,
        "vocab_size-2": 1010,
        "unique-2": 694,
        "entropy-2": 9.540897413412589,
        "cond_entropy-2": 1.8540091454150962,
        "distinct-3": 0.7422552664188352,
        "vocab_size-3": 1198,
        "unique-3": 950,
        "entropy-3": 10.003243469466328,
        "cond_entropy-3": 0.5127504673168949,
        "total_length-nopunct": 1649,
        "mean_pred_length-nopunct": 14.339130434782609,
        "std_pred_length-nopunct": 3.85810711984571,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.3068526379624015,
        "vocab_size-1-nopunct": 506,
        "unique-1-nopunct": 256,
        "entropy-1-nopunct": 7.678403081428188,
        "distinct-2-nopunct": 0.5723598435462842,
        "vocab_size-2-nopunct": 878,
        "unique-2-nopunct": 602,
        "entropy-2-nopunct": 9.314592838671832,
        "cond_entropy-2-nopunct": 1.7724645277847317,
        "distinct-3-nopunct": 0.7315010570824524,
        "vocab_size-3-nopunct": 1038,
        "unique-3-nopunct": 817,
        "entropy-3-nopunct": 9.782251057551312,
        "cond_entropy-3-nopunct": 0.5155594462099696,
        "msttr-100": 0.66222,
        "msttr-100_nopunct": 0.70188,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.21770334928229665,
            "2": 0.5523809523809524,
            "3": 0.8822314049586777
        },
        "nist": 8.546875786059049,
        "bleu": 57.89084,
        "rouge1": {
            "precision": 0.81278,
            "recall": 0.76617,
            "fmeasure": 0.78149
        },
        "rouge2": {
            "precision": 0.58683,
            "recall": 0.55088,
            "fmeasure": 0.56215
        },
        "rougeL": {
            "precision": 0.7167,
            "recall": 0.67685,
            "fmeasure": 0.68884
        },
        "rougeLsum": {
            "precision": 0.7167,
            "recall": 0.67685,
            "fmeasure": 0.68884
        },
        "nubia": {
            "semantic_relation": 4.58873,
            "contradiction": 3.4281,
            "irrelevancy": 4.09753,
            "logical_agreement": 92.47437,
            "grammar_ref": 4.68186,
            "grammar_hyp": 4.71485,
            "nubia_score": 0.83405
        },
        "meteor": 0.4269737919777563,
        "bleurt": 0.33255,
        "bertscore": {
            "precision": 0.9445,
            "recall": 0.93892,
            "f1": 0.94
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_42": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 16,
        "unique-1": 11,
        "entropy-1": 3.8035088547976788,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 22,
        "unique-2": 21,
        "entropy-2": 4.436605434317882,
        "cond_entropy-2": 0.667072824995138,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": 0.02677875348937534,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6521739130434783,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.708132064658602,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.368522527728205,
        "cond_entropy-2-nopunct": 0.6974554581331694,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": 0.02812389937955851,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.8,
            "2": 0.0,
            "3": 0.4166666666666667
        },
        "nist": 2.3816486707831834,
        "bleu": 10.43633,
        "rouge1": {
            "precision": 0.46377,
            "recall": 0.49778,
            "fmeasure": 0.47368
        },
        "rouge2": {
            "precision": 0.24242,
            "recall": 0.2619,
            "fmeasure": 0.24799
        },
        "rougeL": {
            "precision": 0.36232,
            "recall": 0.39556,
            "fmeasure": 0.37281
        },
        "rougeLsum": {
            "precision": 0.36232,
            "recall": 0.39556,
            "fmeasure": 0.37281
        },
        "nubia": {
            "semantic_relation": 3.13413,
            "contradiction": 4.27926,
            "irrelevancy": 76.89607,
            "logical_agreement": 18.82468,
            "grammar_ref": 4.19943,
            "grammar_hyp": 4.33119,
            "nubia_score": 0.43052
        },
        "meteor": 0.20322122932139822,
        "bleurt": -0.5411,
        "bertscore": {
            "precision": 0.83385,
            "recall": 0.79824,
            "f1": 0.80517
        }
    },
    "wiki_auto_asset_turk_challenge_train_sample": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_challenge_train_sample",
        "N": 500
    },
    "wiki_auto_asset_turk_challenge_validation_sample": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_challenge_validation_sample",
        "N": 500
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 41,
        "total_length": 1051,
        "mean_pred_length": 25.634146341463413,
        "std_pred_length": 2.8176802217857713,
        "median_pred_length": 25.0,
        "min_pred_length": 18,
        "max_pred_length": 32,
        "distinct-1": 0.3292102759276879,
        "vocab_size-1": 346,
        "unique-1": 214,
        "entropy-1": 7.185408373084221,
        "distinct-2": 0.6158415841584158,
        "vocab_size-2": 622,
        "unique-2": 460,
        "entropy-2": 8.900461407690596,
        "cond_entropy-2": 1.7699807457577212,
        "distinct-3": 0.7450980392156863,
        "vocab_size-3": 722,
        "unique-3": 597,
        "entropy-3": 9.264688269832316,
        "cond_entropy-3": 0.39212984075613716,
        "total_length-nopunct": 959,
        "mean_pred_length-nopunct": 23.390243902439025,
        "std_pred_length-nopunct": 2.81006942697401,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.3555787278415016,
        "vocab_size-1-nopunct": 341,
        "unique-1-nopunct": 213,
        "entropy-1-nopunct": 7.261745742508112,
        "distinct-2-nopunct": 0.6318082788671024,
        "vocab_size-2-nopunct": 580,
        "unique-2-nopunct": 433,
        "entropy-2-nopunct": 8.836439536507307,
        "cond_entropy-2-nopunct": 1.6355298086474763,
        "distinct-3-nopunct": 0.7594070695553021,
        "vocab_size-3-nopunct": 666,
        "unique-3-nopunct": 556,
        "entropy-3-nopunct": 9.163275493022526,
        "cond_entropy-3-nopunct": 0.35763815080549494,
        "msttr-100": 0.533,
        "msttr-100_nopunct": 0.58,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.11027190332326284,
            "2": 0.29846938775510207,
            "3": 0.5704697986577181
        },
        "nist": 1.5426378403751204,
        "bleu": 22.28855,
        "rouge1": {
            "precision": 0.77103,
            "recall": 0.43898,
            "fmeasure": 0.55509
        },
        "rouge2": {
            "precision": 0.45913,
            "recall": 0.2521,
            "fmeasure": 0.32241
        },
        "rougeL": {
            "precision": 0.59028,
            "recall": 0.33159,
            "fmeasure": 0.42151
        },
        "rougeLsum": {
            "precision": 0.59028,
            "recall": 0.33159,
            "fmeasure": 0.42151
        },
        "nubia": {
            "semantic_relation": 3.17744,
            "contradiction": 10.94648,
            "irrelevancy": 9.82968,
            "logical_agreement": 79.22384,
            "grammar_ref": 3.92594,
            "grammar_hyp": 4.51442,
            "nubia_score": 0.32856
        },
        "meteor": 0.22070617115832,
        "bleurt": -0.47726,
        "bertscore": {
            "precision": 0.89375,
            "recall": 0.82252,
            "f1": 0.85551
        }
    },
    "mlsum_es_challenge_test_covid": {
        "predictions_file": "ByT5-base (Baseline)/mlsum_es_challenge_test_covid",
        "N": 1938,
        "total_length": 38884,
        "mean_pred_length": 20.063983488132095,
        "std_pred_length": 3.3417385808529985,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 30,
        "distinct-1": 0.1926499331344512,
        "vocab_size-1": 7491,
        "unique-1": 4716,
        "entropy-1": 9.24030653628544,
        "distinct-2": 0.5876684891463216,
        "vocab_size-2": 21712,
        "unique-2": 17821,
        "entropy-2": 13.431962703393609,
        "cond_entropy-2": 4.352815761655096,
        "distinct-3": 0.8534906307129799,
        "vocab_size-3": 29879,
        "unique-3": 27521,
        "entropy-3": 14.667645678774763,
        "cond_entropy-3": 1.2648799669737916,
        "total_length-nopunct": 38019,
        "mean_pred_length-nopunct": 19.61764705882353,
        "std_pred_length-nopunct": 3.0894537868409557,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.19679633867276888,
        "vocab_size-1-nopunct": 7482,
        "unique-1-nopunct": 4715,
        "entropy-1-nopunct": 9.249980189684129,
        "distinct-2-nopunct": 0.5936919708433802,
        "vocab_size-2-nopunct": 21421,
        "unique-2-nopunct": 17655,
        "entropy-2-nopunct": 13.418463093909876,
        "cond_entropy-2-nopunct": 4.3337055839873315,
        "distinct-3-nopunct": 0.856163781741499,
        "vocab_size-3-nopunct": 29232,
        "unique-3-nopunct": 26991,
        "entropy-3-nopunct": 14.637949576052483,
        "cond_entropy-3-nopunct": 1.2492472736149054,
        "msttr-100": 0.69441,
        "msttr-100_nopunct": 0.69329,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_challenge_test_covid.json",
        "local_recall": {
            "1": 0.25561121279260185
        },
        "nist": 2.3291564734920835,
        "bleu": 6.80412,
        "rouge1": {
            "precision": 0.3313,
            "recall": 0.27541,
            "fmeasure": 0.29177
        },
        "rouge2": {
            "precision": 0.11912,
            "recall": 0.09831,
            "fmeasure": 0.10462
        },
        "rougeL": {
            "precision": 0.25866,
            "recall": 0.2169,
            "fmeasure": 0.22883
        },
        "rougeLsum": {
            "precision": 0.25866,
            "recall": 0.2169,
            "fmeasure": 0.22883
        },
        "nubia": {
            "semantic_relation": 1.65074,
            "contradiction": 25.98964,
            "irrelevancy": 63.0774,
            "logical_agreement": 10.93296,
            "grammar_ref": 5.23427,
            "grammar_hyp": 5.21895,
            "nubia_score": 0.17585
        },
        "meteor": 0.20305705614717762,
        "bleurt": -0.46191,
        "bertscore": {
            "precision": 0.84588,
            "recall": 0.83403,
            "f1": 0.83975
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02_parent": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 5986,
        "mean_pred_length": 16.67409470752089,
        "std_pred_length": 6.112881754523878,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.36886067490811897,
        "vocab_size-1": 2208,
        "unique-1": 1641,
        "entropy-1": 9.001750926260584,
        "distinct-2": 0.8324151412830993,
        "vocab_size-2": 4684,
        "unique-2": 4336,
        "entropy-2": 11.870352365250671,
        "cond_entropy-2": 2.6610286399774434,
        "distinct-3": 0.961085801063022,
        "vocab_size-3": 5063,
        "unique-3": 4970,
        "entropy-3": 12.228966809207297,
        "cond_entropy-3": 0.3835869085849308,
        "total_length-nopunct": 5365,
        "mean_pred_length-nopunct": 14.944289693593316,
        "std_pred_length-nopunct": 5.665928515603843,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4093196644920783,
        "vocab_size-1-nopunct": 2196,
        "unique-1-nopunct": 1638,
        "entropy-1-nopunct": 9.280172905984818,
        "distinct-2-nopunct": 0.853775469436676,
        "vocab_size-2-nopunct": 4274,
        "unique-2-nopunct": 3972,
        "entropy-2-nopunct": 11.806624112593747,
        "cond_entropy-2-nopunct": 2.6804708872569805,
        "distinct-3-nopunct": 0.978480740262535,
        "vocab_size-3-nopunct": 4547,
        "unique-3-nopunct": 4469,
        "entropy-3-nopunct": 12.133531549707403,
        "cond_entropy-3-nopunct": 0.35101702544693203,
        "msttr-100": 0.73542,
        "msttr-100_nopunct": 0.77038,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.0432937181663837,
            "2": 0.14431673052362706,
            "3": 0.3041575492341357,
            "4": 0.38510301109350237,
            "5": 0.5015576323987538,
            "6": 0.6147342995169082,
            "7": 0.7541046200840015
        },
        "nist": 8.236004323684183,
        "bleu": 56.24873,
        "rouge1": {
            "precision": 0.81013,
            "recall": 0.68308,
            "fmeasure": 0.72532
        },
        "rouge2": {
            "precision": 0.64479,
            "recall": 0.53362,
            "fmeasure": 0.56943
        },
        "rougeL": {
            "precision": 0.77178,
            "recall": 0.65045,
            "fmeasure": 0.69009
        },
        "rougeLsum": {
            "precision": 0.77178,
            "recall": 0.65045,
            "fmeasure": 0.69009
        },
        "nubia": {
            "semantic_relation": 3.92989,
            "contradiction": 6.74605,
            "irrelevancy": 19.20804,
            "logical_agreement": 74.04591,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.02615,
            "nubia_score": 0.59868
        },
        "meteor": 0.3762137184057809,
        "bleurt": 0.01465,
        "bertscore": {
            "precision": 0.93885,
            "recall": 0.91243,
            "f1": 0.9219
        }
    },
    "web_nlg_en_test_contrast_challenge_args-both_seen": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 518,
        "total_length": 10755,
        "mean_pred_length": 20.76254826254826,
        "std_pred_length": 4.832282336506949,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.09139934913993492,
        "vocab_size-1": 983,
        "unique-1": 375,
        "entropy-1": 7.731086703897327,
        "distinct-2": 0.2510501123375989,
        "vocab_size-2": 2570,
        "unique-2": 1318,
        "entropy-2": 10.150614759841837,
        "cond_entropy-2": 2.436825289014625,
        "distinct-3": 0.38779709846692045,
        "vocab_size-3": 3769,
        "unique-3": 2333,
        "entropy-3": 10.981872051530784,
        "cond_entropy-3": 0.9308873723296676,
        "total_length-nopunct": 9741,
        "mean_pred_length-nopunct": 18.805019305019304,
        "std_pred_length-nopunct": 4.659715418300789,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.10009239297813366,
        "vocab_size-1-nopunct": 975,
        "unique-1-nopunct": 374,
        "entropy-1-nopunct": 7.883098264275247,
        "distinct-2-nopunct": 0.2582673750406592,
        "vocab_size-2-nopunct": 2382,
        "unique-2-nopunct": 1263,
        "entropy-2-nopunct": 10.026203191293572,
        "cond_entropy-2-nopunct": 2.2993162477594975,
        "distinct-3-nopunct": 0.3919586444572085,
        "vocab_size-3-nopunct": 3412,
        "unique-3-nopunct": 2142,
        "entropy-3-nopunct": 10.817381889131305,
        "cond_entropy-3-nopunct": 0.8897852670727279,
        "msttr-100": 0.66551,
        "msttr-100_nopunct": 0.69351,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.19674426746017853,
            "2": 0.4806470248411323,
            "3": 0.6939125464418405,
            "4": 0.9473684210526315
        },
        "nist": 4.580825214795803,
        "bleu": 38.69816,
        "rouge1": {
            "precision": 0.81457,
            "recall": 0.6439,
            "fmeasure": 0.7005
        },
        "rouge2": {
            "precision": 0.57782,
            "recall": 0.45218,
            "fmeasure": 0.49287
        },
        "rougeL": {
            "precision": 0.68096,
            "recall": 0.53748,
            "fmeasure": 0.58483
        },
        "rougeLsum": {
            "precision": 0.68096,
            "recall": 0.53748,
            "fmeasure": 0.58483
        },
        "nubia": {
            "semantic_relation": 4.03419,
            "contradiction": 5.42177,
            "irrelevancy": 8.36314,
            "logical_agreement": 86.21509,
            "grammar_ref": 4.28317,
            "grammar_hyp": 4.53916,
            "nubia_score": 0.63984
        },
        "meteor": 0.31297335785009617,
        "bleurt": 0.01993,
        "bertscore": {
            "precision": 0.93258,
            "recall": 0.89624,
            "f1": 0.91251
        }
    },
    "totto_test_contrast_challenge_continent-asia": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 150,
        "total_length": 2519,
        "mean_pred_length": 16.793333333333333,
        "std_pred_length": 4.710692329395141,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.42635966653433904,
        "vocab_size-1": 1074,
        "unique-1": 860,
        "entropy-1": 8.358611228945874,
        "distinct-2": 0.7948501477416632,
        "vocab_size-2": 1883,
        "unique-2": 1685,
        "entropy-2": 10.568657547961672,
        "cond_entropy-2": 1.988541102763291,
        "distinct-3": 0.9238395673726904,
        "vocab_size-3": 2050,
        "unique-3": 1962,
        "entropy-3": 10.918307498700987,
        "cond_entropy-3": 0.35752615284877953,
        "total_length-nopunct": 2195,
        "mean_pred_length-nopunct": 14.633333333333333,
        "std_pred_length-nopunct": 4.33192284736877,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.48519362186788156,
        "vocab_size-1-nopunct": 1065,
        "unique-1-nopunct": 856,
        "entropy-1-nopunct": 8.679198600579852,
        "distinct-2-nopunct": 0.8136919315403423,
        "vocab_size-2-nopunct": 1664,
        "unique-2-nopunct": 1525,
        "entropy-2-nopunct": 10.386421199001553,
        "cond_entropy-2-nopunct": 1.8138040268106748,
        "distinct-3-nopunct": 0.9387862796833774,
        "vocab_size-3-nopunct": 1779,
        "unique-3-nopunct": 1722,
        "entropy-3-nopunct": 10.725530648947366,
        "cond_entropy-3-nopunct": 0.37242501655457144,
        "msttr-100": 0.7252,
        "msttr-100_nopunct": 0.77429,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1973392461197339,
            "2": 0.5027027027027027,
            "3": 0.8018327605956472
        },
        "nist": 8.468088648616934,
        "bleu": 49.77259,
        "rouge1": {
            "precision": 0.81154,
            "recall": 0.78517,
            "fmeasure": 0.79091
        },
        "rouge2": {
            "precision": 0.59142,
            "recall": 0.57801,
            "fmeasure": 0.57883
        },
        "rougeL": {
            "precision": 0.69388,
            "recall": 0.6762,
            "fmeasure": 0.67845
        },
        "rougeLsum": {
            "precision": 0.69388,
            "recall": 0.6762,
            "fmeasure": 0.67845
        },
        "nubia": {
            "semantic_relation": 4.49376,
            "contradiction": 3.8943,
            "irrelevancy": 23.32353,
            "logical_agreement": 72.78217,
            "grammar_ref": 5.14336,
            "grammar_hyp": 5.12687,
            "nubia_score": 0.79836
        },
        "meteor": 0.41462940857908087,
        "bleurt": 0.39567,
        "bertscore": {
            "precision": 0.95042,
            "recall": 0.94675,
            "f1": 0.9475
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05_parent": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 5986,
        "mean_pred_length": 16.67409470752089,
        "std_pred_length": 6.112881754523878,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.36886067490811897,
        "vocab_size-1": 2208,
        "unique-1": 1641,
        "entropy-1": 9.001750926260584,
        "distinct-2": 0.8324151412830993,
        "vocab_size-2": 4684,
        "unique-2": 4336,
        "entropy-2": 11.870352365250671,
        "cond_entropy-2": 2.6610286399774434,
        "distinct-3": 0.961085801063022,
        "vocab_size-3": 5063,
        "unique-3": 4970,
        "entropy-3": 12.228966809207297,
        "cond_entropy-3": 0.3835869085849308,
        "total_length-nopunct": 5365,
        "mean_pred_length-nopunct": 14.944289693593316,
        "std_pred_length-nopunct": 5.665928515603843,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4093196644920783,
        "vocab_size-1-nopunct": 2196,
        "unique-1-nopunct": 1638,
        "entropy-1-nopunct": 9.280172905984818,
        "distinct-2-nopunct": 0.853775469436676,
        "vocab_size-2-nopunct": 4274,
        "unique-2-nopunct": 3972,
        "entropy-2-nopunct": 11.806624112593747,
        "cond_entropy-2-nopunct": 2.6804708872569805,
        "distinct-3-nopunct": 0.978480740262535,
        "vocab_size-3-nopunct": 4547,
        "unique-3-nopunct": 4469,
        "entropy-3-nopunct": 12.133531549707403,
        "cond_entropy-3-nopunct": 0.35101702544693203,
        "msttr-100": 0.73542,
        "msttr-100_nopunct": 0.77038,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.0432937181663837,
            "2": 0.14431673052362706,
            "3": 0.3041575492341357,
            "4": 0.38510301109350237,
            "5": 0.5015576323987538,
            "6": 0.6147342995169082,
            "7": 0.7541046200840015
        },
        "nist": 8.236004323684183,
        "bleu": 56.24873,
        "rouge1": {
            "precision": 0.81013,
            "recall": 0.68308,
            "fmeasure": 0.72532
        },
        "rouge2": {
            "precision": 0.64479,
            "recall": 0.53362,
            "fmeasure": 0.56943
        },
        "rougeL": {
            "precision": 0.77178,
            "recall": 0.65045,
            "fmeasure": 0.69009
        },
        "rougeLsum": {
            "precision": 0.77178,
            "recall": 0.65045,
            "fmeasure": 0.69009
        },
        "nubia": {
            "semantic_relation": 3.92989,
            "contradiction": 6.74605,
            "irrelevancy": 19.20804,
            "logical_agreement": 74.04591,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.02615,
            "nubia_score": 0.59868
        },
        "meteor": 0.3762137184057809,
        "bleurt": 0.01465,
        "bertscore": {
            "precision": 0.93885,
            "recall": 0.91243,
            "f1": 0.9219
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_13": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 10,
        "total_length": 257,
        "mean_pred_length": 25.7,
        "std_pred_length": 4.960846701924985,
        "median_pred_length": 26.5,
        "min_pred_length": 15,
        "max_pred_length": 33,
        "distinct-1": 0.6186770428015564,
        "vocab_size-1": 159,
        "unique-1": 131,
        "entropy-1": 6.696745317449094,
        "distinct-2": 0.9068825910931174,
        "vocab_size-2": 224,
        "unique-2": 209,
        "entropy-2": 7.73025264461739,
        "cond_entropy-2": 1.070304057198439,
        "distinct-3": 0.9746835443037974,
        "vocab_size-3": 231,
        "unique-3": 226,
        "entropy-3": 7.834925158171872,
        "cond_entropy-3": 0.11387566068389249,
        "total_length-nopunct": 221,
        "mean_pred_length-nopunct": 22.1,
        "std_pred_length-nopunct": 4.158124577258358,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.7013574660633484,
        "vocab_size-1-nopunct": 155,
        "unique-1-nopunct": 131,
        "entropy-1-nopunct": 6.831688475534168,
        "distinct-2-nopunct": 0.957345971563981,
        "vocab_size-2-nopunct": 202,
        "unique-2-nopunct": 195,
        "entropy-2-nopunct": 7.626312458849392,
        "cond_entropy-2-nopunct": 0.830463513355811,
        "distinct-3-nopunct": 0.9950248756218906,
        "vocab_size-3-nopunct": 200,
        "unique-3-nopunct": 199,
        "entropy-3-nopunct": 7.641101442422721,
        "cond_entropy-3-nopunct": 0.019504741277713667,
        "msttr-100": 0.675,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1095890410958904,
            "2": 0.4067796610169492,
            "3": 0.636986301369863
        },
        "nist": 4.926627439277558,
        "bleu": 46.95975,
        "rouge1": {
            "precision": 0.65578,
            "recall": 0.57128,
            "fmeasure": 0.60374
        },
        "rouge2": {
            "precision": 0.46269,
            "recall": 0.39582,
            "fmeasure": 0.42137
        },
        "rougeL": {
            "precision": 0.54108,
            "recall": 0.47162,
            "fmeasure": 0.49715
        },
        "rougeLsum": {
            "precision": 0.54108,
            "recall": 0.47162,
            "fmeasure": 0.49715
        },
        "nubia": {
            "semantic_relation": 3.25648,
            "contradiction": 9.21822,
            "irrelevancy": 42.1469,
            "logical_agreement": 48.63489,
            "grammar_ref": 4.57725,
            "grammar_hyp": 4.80981,
            "nubia_score": 0.46324
        },
        "meteor": 0.32177560820584183,
        "bleurt": -0.27626,
        "bertscore": {
            "precision": 0.89649,
            "recall": 0.88828,
            "f1": 0.89139
        }
    },
    "web_nlg_en_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 1177,
        "total_length": 22143,
        "mean_pred_length": 18.813084112149532,
        "std_pred_length": 6.664867404764071,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 31,
        "distinct-1": 0.057083502687079436,
        "vocab_size-1": 1264,
        "unique-1": 431,
        "entropy-1": 7.750998203301852,
        "distinct-2": 0.20514165792235048,
        "vocab_size-2": 4301,
        "unique-2": 2071,
        "entropy-2": 10.704492308826138,
        "cond_entropy-2": 2.8903569816950148,
        "distinct-3": 0.37576431350750417,
        "vocab_size-3": 7436,
        "unique-3": 4551,
        "entropy-3": 11.908917610081483,
        "cond_entropy-3": 1.3110676581973124,
        "total_length-nopunct": 20077,
        "mean_pred_length-nopunct": 17.057774001699237,
        "std_pred_length-nopunct": 6.339453900661351,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.06260895552124321,
        "vocab_size-1-nopunct": 1257,
        "unique-1-nopunct": 431,
        "entropy-1-nopunct": 7.899150898480538,
        "distinct-2-nopunct": 0.21576719576719577,
        "vocab_size-2-nopunct": 4078,
        "unique-2-nopunct": 2122,
        "entropy-2-nopunct": 10.584754009494631,
        "cond_entropy-2-nopunct": 2.869213694299142,
        "distinct-3-nopunct": 0.3883089770354906,
        "vocab_size-3-nopunct": 6882,
        "unique-3-nopunct": 4398,
        "entropy-3-nopunct": 11.76836078633833,
        "cond_entropy-3-nopunct": 1.2772801616613425,
        "msttr-100": 0.64475,
        "msttr-100_nopunct": 0.66905,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.18025483382339838,
            "2": 0.5144296839212094,
            "3": 0.7838061367959639,
            "4": 0.5,
            "5": 0.7931034482758621
        },
        "nist": 7.378737417888754,
        "bleu": 40.44687,
        "rouge1": {
            "precision": 0.76875,
            "recall": 0.69588,
            "fmeasure": 0.72141
        },
        "rouge2": {
            "precision": 0.50531,
            "recall": 0.45799,
            "fmeasure": 0.47368
        },
        "rougeL": {
            "precision": 0.63289,
            "recall": 0.57451,
            "fmeasure": 0.59404
        },
        "rougeLsum": {
            "precision": 0.63289,
            "recall": 0.57451,
            "fmeasure": 0.59404
        },
        "nubia": {
            "semantic_relation": 4.18573,
            "contradiction": 9.24896,
            "irrelevancy": 10.72819,
            "logical_agreement": 80.02284,
            "grammar_ref": 4.6454,
            "grammar_hyp": 4.87561,
            "nubia_score": 0.68951
        },
        "meteor": 0.3395616800253307,
        "bleurt": 0.07447,
        "bertscore": {
            "precision": 0.91771,
            "recall": 0.90335,
            "f1": 0.90882
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc_parent": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 5986,
        "mean_pred_length": 16.67409470752089,
        "std_pred_length": 6.112881754523878,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.36886067490811897,
        "vocab_size-1": 2208,
        "unique-1": 1641,
        "entropy-1": 9.001750926260584,
        "distinct-2": 0.8324151412830993,
        "vocab_size-2": 4684,
        "unique-2": 4336,
        "entropy-2": 11.870352365250671,
        "cond_entropy-2": 2.6610286399774434,
        "distinct-3": 0.961085801063022,
        "vocab_size-3": 5063,
        "unique-3": 4970,
        "entropy-3": 12.228966809207297,
        "cond_entropy-3": 0.3835869085849308,
        "total_length-nopunct": 5365,
        "mean_pred_length-nopunct": 14.944289693593316,
        "std_pred_length-nopunct": 5.665928515603843,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4093196644920783,
        "vocab_size-1-nopunct": 2196,
        "unique-1-nopunct": 1638,
        "entropy-1-nopunct": 9.280172905984818,
        "distinct-2-nopunct": 0.853775469436676,
        "vocab_size-2-nopunct": 4274,
        "unique-2-nopunct": 3972,
        "entropy-2-nopunct": 11.806624112593747,
        "cond_entropy-2-nopunct": 2.6804708872569805,
        "distinct-3-nopunct": 0.978480740262535,
        "vocab_size-3-nopunct": 4547,
        "unique-3-nopunct": 4469,
        "entropy-3-nopunct": 12.133531549707403,
        "cond_entropy-3-nopunct": 0.35101702544693203,
        "msttr-100": 0.73542,
        "msttr-100_nopunct": 0.77038,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.0432937181663837,
            "2": 0.14431673052362706,
            "3": 0.3041575492341357,
            "4": 0.38510301109350237,
            "5": 0.5015576323987538,
            "6": 0.6147342995169082,
            "7": 0.7541046200840015
        },
        "nist": 8.236004323684183,
        "bleu": 56.24873,
        "rouge1": {
            "precision": 0.81013,
            "recall": 0.68308,
            "fmeasure": 0.72532
        },
        "rouge2": {
            "precision": 0.64479,
            "recall": 0.53362,
            "fmeasure": 0.56943
        },
        "rougeL": {
            "precision": 0.77178,
            "recall": 0.65045,
            "fmeasure": 0.69009
        },
        "rougeLsum": {
            "precision": 0.77178,
            "recall": 0.65045,
            "fmeasure": 0.69009
        },
        "nubia": {
            "semantic_relation": 3.92989,
            "contradiction": 6.74605,
            "irrelevancy": 19.20804,
            "logical_agreement": 74.04591,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.02615,
            "nubia_score": 0.59868
        },
        "meteor": 0.3762137184057809,
        "bleurt": 0.01465,
        "bertscore": {
            "precision": 0.93885,
            "recall": 0.91243,
            "f1": 0.9219
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_14": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 14,
        "total_length": 317,
        "mean_pred_length": 22.642857142857142,
        "std_pred_length": 4.185129164368643,
        "median_pred_length": 22.5,
        "min_pred_length": 14,
        "max_pred_length": 30,
        "distinct-1": 0.6309148264984227,
        "vocab_size-1": 200,
        "unique-1": 161,
        "entropy-1": 6.9752846874155985,
        "distinct-2": 0.9141914191419142,
        "vocab_size-2": 277,
        "unique-2": 262,
        "entropy-2": 8.03149422938906,
        "cond_entropy-2": 1.0562719334202173,
        "distinct-3": 0.986159169550173,
        "vocab_size-3": 285,
        "unique-3": 281,
        "entropy-3": 8.147244021601004,
        "cond_entropy-3": 0.12600417476273706,
        "total_length-nopunct": 283,
        "mean_pred_length-nopunct": 20.214285714285715,
        "std_pred_length-nopunct": 3.384387925852038,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6855123674911661,
        "vocab_size-1-nopunct": 194,
        "unique-1-nopunct": 161,
        "entropy-1-nopunct": 7.032891847985997,
        "distinct-2-nopunct": 0.9219330855018587,
        "vocab_size-2-nopunct": 248,
        "unique-2-nopunct": 237,
        "entropy-2-nopunct": 7.873008541050075,
        "cond_entropy-2-nopunct": 0.8905431968850597,
        "distinct-3-nopunct": 0.9921568627450981,
        "vocab_size-3-nopunct": 253,
        "unique-3-nopunct": 251,
        "entropy-3-nopunct": 7.978667162349067,
        "cond_entropy-3-nopunct": 0.11655412522479883,
        "msttr-100": 0.73333,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.4927536231884058,
            "3": 0.5466101694915254
        },
        "nist": 3.8286521094397754,
        "bleu": 24.79602,
        "rouge1": {
            "precision": 0.62385,
            "recall": 0.54625,
            "fmeasure": 0.56247
        },
        "rouge2": {
            "precision": 0.36903,
            "recall": 0.32611,
            "fmeasure": 0.33301
        },
        "rougeL": {
            "precision": 0.52304,
            "recall": 0.46492,
            "fmeasure": 0.47538
        },
        "rougeLsum": {
            "precision": 0.52304,
            "recall": 0.46492,
            "fmeasure": 0.47538
        },
        "nubia": {
            "semantic_relation": 3.31941,
            "contradiction": 19.63938,
            "irrelevancy": 37.25199,
            "logical_agreement": 43.10863,
            "grammar_ref": 4.37064,
            "grammar_hyp": 4.649,
            "nubia_score": 0.42503
        },
        "meteor": 0.2611272646394804,
        "bleurt": -0.22124,
        "bertscore": {
            "precision": 0.88279,
            "recall": 0.86194,
            "f1": 0.87022
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_15": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 14,
        "total_length": 318,
        "mean_pred_length": 22.714285714285715,
        "std_pred_length": 5.4304508024994895,
        "median_pred_length": 24.0,
        "min_pred_length": 13,
        "max_pred_length": 34,
        "distinct-1": 0.5943396226415094,
        "vocab_size-1": 189,
        "unique-1": 156,
        "entropy-1": 6.870030625205451,
        "distinct-2": 0.9342105263157895,
        "vocab_size-2": 284,
        "unique-2": 272,
        "entropy-2": 8.091645358824088,
        "cond_entropy-2": 1.2212292161670684,
        "distinct-3": 0.993103448275862,
        "vocab_size-3": 288,
        "unique-3": 286,
        "entropy-3": 8.166115986566655,
        "cond_entropy-3": 0.07856700762075224,
        "total_length-nopunct": 273,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 4.403732183370957,
        "median_pred_length-nopunct": 21.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 182,
        "unique-1-nopunct": 155,
        "entropy-1-nopunct": 6.946007735603311,
        "distinct-2-nopunct": 0.9613899613899614,
        "vocab_size-2-nopunct": 249,
        "unique-2-nopunct": 242,
        "entropy-2-nopunct": 7.928951579183959,
        "cond_entropy-2-nopunct": 1.0372082902000925,
        "distinct-3-nopunct": 0.9959183673469387,
        "vocab_size-3-nopunct": 244,
        "unique-3-nopunct": 243,
        "entropy-3-nopunct": 7.92847467369648,
        "cond_entropy-3-nopunct": 0.0004618452023980945,
        "msttr-100": 0.68333,
        "msttr-100_nopunct": 0.705,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2619047619047619,
            "2": 0.23529411764705882,
            "3": 0.467680608365019
        },
        "nist": 3.119415219828633,
        "bleu": 17.72774,
        "rouge1": {
            "precision": 0.63619,
            "recall": 0.50572,
            "fmeasure": 0.54778
        },
        "rouge2": {
            "precision": 0.31215,
            "recall": 0.23977,
            "fmeasure": 0.26359
        },
        "rougeL": {
            "precision": 0.47918,
            "recall": 0.38602,
            "fmeasure": 0.41597
        },
        "rougeLsum": {
            "precision": 0.47918,
            "recall": 0.38602,
            "fmeasure": 0.41597
        },
        "nubia": {
            "semantic_relation": 3.16351,
            "contradiction": 54.78436,
            "irrelevancy": 20.51337,
            "logical_agreement": 24.70227,
            "grammar_ref": 3.91022,
            "grammar_hyp": 4.42601,
            "nubia_score": 0.41326
        },
        "meteor": 0.22952756348506867,
        "bleurt": -0.19655,
        "bertscore": {
            "precision": 0.88756,
            "recall": 0.85145,
            "f1": 0.86864
        }
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 1654,
        "total_length": 30862,
        "mean_pred_length": 18.6590084643289,
        "std_pred_length": 6.4417058946415855,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.062309636446114966,
        "vocab_size-1": 1923,
        "unique-1": 638,
        "entropy-1": 8.168149079241598,
        "distinct-2": 0.2168241577649959,
        "vocab_size-2": 6333,
        "unique-2": 3094,
        "entropy-2": 11.238581679377727,
        "cond_entropy-2": 3.0070552666569546,
        "distinct-3": 0.3842636277854395,
        "vocab_size-3": 10588,
        "unique-3": 6550,
        "entropy-3": 12.433458301292653,
        "cond_entropy-3": 1.305535464828759,
        "total_length-nopunct": 27936,
        "mean_pred_length-nopunct": 16.889963724304717,
        "std_pred_length-nopunct": 6.119229181736171,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.06851374570446736,
        "vocab_size-1-nopunct": 1914,
        "unique-1-nopunct": 638,
        "entropy-1-nopunct": 8.36333218659127,
        "distinct-2-nopunct": 0.2265428810592801,
        "vocab_size-2-nopunct": 5954,
        "unique-2-nopunct": 3104,
        "entropy-2-nopunct": 11.122825396122476,
        "cond_entropy-2-nopunct": 2.950752011308963,
        "distinct-3-nopunct": 0.39398245898976775,
        "vocab_size-3-nopunct": 9703,
        "unique-3-nopunct": 6213,
        "entropy-3-nopunct": 12.284803823196198,
        "cond_entropy-3-nopunct": 1.2672628725539055,
        "msttr-100": 0.51756,
        "msttr-100_nopunct": 0.5243,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.18821974702661884,
            "2": 0.5130581297388374,
            "3": 0.7556116722783389,
            "4": 0.8727272727272727,
            "5": 0.7931034482758621
        },
        "nist": 7.062921498803089,
        "bleu": 41.25347,
        "rouge1": {
            "precision": 0.79017,
            "recall": 0.68894,
            "fmeasure": 0.72357
        },
        "rouge2": {
            "precision": 0.53891,
            "recall": 0.46786,
            "fmeasure": 0.49134
        },
        "rougeL": {
            "precision": 0.65996,
            "recall": 0.57605,
            "fmeasure": 0.60411
        },
        "rougeLsum": {
            "precision": 0.65996,
            "recall": 0.57605,
            "fmeasure": 0.60411
        },
        "nubia": {
            "semantic_relation": 4.17615,
            "contradiction": 7.8324,
            "irrelevancy": 9.30349,
            "logical_agreement": 82.86411,
            "grammar_ref": 4.57661,
            "grammar_hyp": 4.81,
            "nubia_score": 0.68681
        },
        "meteor": 0.33524802837588513,
        "bleurt": 0.08769,
        "bertscore": {
            "precision": 0.92537,
            "recall": 0.90542,
            "f1": 0.9137
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_16": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 7,
        "total_length": 164,
        "mean_pred_length": 23.428571428571427,
        "std_pred_length": 2.5555062599997598,
        "median_pred_length": 22.0,
        "min_pred_length": 21,
        "max_pred_length": 27,
        "distinct-1": 0.6280487804878049,
        "vocab_size-1": 103,
        "unique-1": 81,
        "entropy-1": 6.176032048634012,
        "distinct-2": 0.9426751592356688,
        "vocab_size-2": 148,
        "unique-2": 139,
        "entropy-2": 7.179971067362961,
        "cond_entropy-2": 1.0438793989320758,
        "distinct-3": 0.9933333333333333,
        "vocab_size-3": 149,
        "unique-3": 148,
        "entropy-3": 7.215485357162529,
        "cond_entropy-3": 0.04086460827092058,
        "total_length-nopunct": 137,
        "mean_pred_length-nopunct": 19.571428571428573,
        "std_pred_length-nopunct": 2.4411439272335804,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.708029197080292,
        "vocab_size-1-nopunct": 97,
        "unique-1-nopunct": 78,
        "entropy-1-nopunct": 6.3220922105240325,
        "distinct-2-nopunct": 0.9692307692307692,
        "vocab_size-2-nopunct": 126,
        "unique-2-nopunct": 122,
        "entropy-2-nopunct": 6.960829351489994,
        "cond_entropy-2-nopunct": 0.6728262110202226,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 123,
        "unique-3-nopunct": 123,
        "entropy-3-nopunct": 6.942514505339227,
        "cond_entropy-3-nopunct": -0.014812657282710525,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.72,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3157894736842105,
            "2": 0.4166666666666667,
            "3": 0.7391304347826086
        },
        "nist": 3.8398024941926785,
        "bleu": 36.83852,
        "rouge1": {
            "precision": 0.7546,
            "recall": 0.57744,
            "fmeasure": 0.64487
        },
        "rouge2": {
            "precision": 0.50397,
            "recall": 0.39994,
            "fmeasure": 0.43899
        },
        "rougeL": {
            "precision": 0.67233,
            "recall": 0.51722,
            "fmeasure": 0.57532
        },
        "rougeLsum": {
            "precision": 0.67233,
            "recall": 0.51722,
            "fmeasure": 0.57532
        },
        "nubia": {
            "semantic_relation": 3.33055,
            "contradiction": 3.75953,
            "irrelevancy": 60.32818,
            "logical_agreement": 35.9123,
            "grammar_ref": 3.5611,
            "grammar_hyp": 3.91432,
            "nubia_score": 0.46183
        },
        "meteor": 0.3152391009533562,
        "bleurt": -0.11658,
        "bertscore": {
            "precision": 0.90875,
            "recall": 0.88358,
            "f1": 0.89382
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_17": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 6,
        "total_length": 157,
        "mean_pred_length": 26.166666666666668,
        "std_pred_length": 4.179978734661485,
        "median_pred_length": 27.0,
        "min_pred_length": 21,
        "max_pred_length": 32,
        "distinct-1": 0.7006369426751592,
        "vocab_size-1": 110,
        "unique-1": 94,
        "entropy-1": 6.393145345700193,
        "distinct-2": 0.9668874172185431,
        "vocab_size-2": 146,
        "unique-2": 142,
        "entropy-2": 7.167180318780931,
        "cond_entropy-2": 0.809855187777103,
        "distinct-3": 1.0,
        "vocab_size-3": 145,
        "unique-3": 145,
        "entropy-3": 7.179909090014958,
        "cond_entropy-3": 0.015675988635810552,
        "total_length-nopunct": 134,
        "mean_pred_length-nopunct": 22.333333333333332,
        "std_pred_length-nopunct": 3.197221015541813,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.7835820895522388,
        "vocab_size-1-nopunct": 105,
        "unique-1-nopunct": 92,
        "entropy-1-nopunct": 6.488283802657624,
        "distinct-2-nopunct": 0.984375,
        "vocab_size-2-nopunct": 126,
        "unique-2-nopunct": 124,
        "entropy-2-nopunct": 6.96875,
        "cond_entropy-2-nopunct": 0.5075508248955124,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 122,
        "unique-3-nopunct": 122,
        "entropy-3-nopunct": 6.930737337562902,
        "cond_entropy-3-nopunct": -0.03647577719121211,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.8,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.3611111111111111,
            "3": 0.6106194690265486
        },
        "nist": 4.380549275950689,
        "bleu": 43.07206,
        "rouge1": {
            "precision": 0.7307,
            "recall": 0.55176,
            "fmeasure": 0.61903
        },
        "rouge2": {
            "precision": 0.57556,
            "recall": 0.42098,
            "fmeasure": 0.47898
        },
        "rougeL": {
            "precision": 0.65587,
            "recall": 0.49941,
            "fmeasure": 0.55825
        },
        "rougeLsum": {
            "precision": 0.65587,
            "recall": 0.49941,
            "fmeasure": 0.55825
        },
        "nubia": {
            "semantic_relation": 3.15697,
            "contradiction": 33.78195,
            "irrelevancy": 26.55351,
            "logical_agreement": 39.66454,
            "grammar_ref": 3.81267,
            "grammar_hyp": 3.86771,
            "nubia_score": 0.41929
        },
        "meteor": 0.3186624265444492,
        "bleurt": -0.14273,
        "bertscore": {
            "precision": 0.89696,
            "recall": 0.88129,
            "f1": 0.88768
        }
    },
    "cs_restaurants_challenge_test_scramble_parent": {
        "predictions_file": "ByT5-base (Baseline)/cs_restaurants_test",
        "N": 500,
        "total_length": 5612,
        "mean_pred_length": 11.224,
        "std_pred_length": 3.7317320375396728,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 23,
        "distinct-1": 0.09497505345687812,
        "vocab_size-1": 533,
        "unique-1": 227,
        "entropy-1": 6.88811048643535,
        "distinct-2": 0.26780125195618154,
        "vocab_size-2": 1369,
        "unique-2": 800,
        "entropy-2": 8.839319446377313,
        "cond_entropy-2": 1.752520937467866,
        "distinct-3": 0.4130529054640069,
        "vocab_size-3": 1905,
        "unique-3": 1407,
        "entropy-3": 9.43943282584802,
        "cond_entropy-3": 0.6562608300114352,
        "total_length-nopunct": 4691,
        "mean_pred_length-nopunct": 9.382,
        "std_pred_length-nopunct": 3.4170273630745185,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.11276913238115541,
        "vocab_size-1-nopunct": 529,
        "unique-1-nopunct": 227,
        "entropy-1-nopunct": 7.167875750120851,
        "distinct-2-nopunct": 0.2858506323073252,
        "vocab_size-2-nopunct": 1198,
        "unique-2-nopunct": 714,
        "entropy-2-nopunct": 8.731026721221717,
        "cond_entropy-2-nopunct": 1.7238090699457504,
        "distinct-3-nopunct": 0.44784611216472503,
        "vocab_size-3-nopunct": 1653,
        "unique-3-nopunct": 1246,
        "entropy-3-nopunct": 9.384172270832654,
        "cond_entropy-3-nopunct": 0.743514023163234,
        "msttr-100": 0.59286,
        "msttr-100_nopunct": 0.64109,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.46657349173072443
        },
        "nist": 3.763856243877352,
        "bleu": 16.49444,
        "rouge1": {
            "precision": 0.49958,
            "recall": 0.53339,
            "fmeasure": 0.49886
        },
        "rouge2": {
            "precision": 0.27398,
            "recall": 0.2886,
            "fmeasure": 0.27204
        },
        "rougeL": {
            "precision": 0.44024,
            "recall": 0.47189,
            "fmeasure": 0.44049
        },
        "rougeLsum": {
            "precision": 0.44024,
            "recall": 0.47189,
            "fmeasure": 0.44049
        },
        "nubia": {
            "semantic_relation": 3.31688,
            "contradiction": 22.54268,
            "irrelevancy": 33.94747,
            "logical_agreement": 43.50985,
            "grammar_ref": 6.87434,
            "grammar_hyp": 6.71075,
            "nubia_score": 0.49068
        },
        "meteor": 0.23484176834717863,
        "bleurt": -0.25301,
        "bertscore": {
            "precision": 0.88692,
            "recall": 0.89864,
            "f1": 0.89232
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_52": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 21,
        "entropy-1": 4.386842188131012,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.14533369456035533,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.07400058144377676,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5
        },
        "nist": 0.3912586887391284,
        "bleu": 19.77212,
        "rouge1": {
            "precision": 0.7381,
            "recall": 0.40714,
            "fmeasure": 0.52381
        },
        "rouge2": {
            "precision": 0.45,
            "recall": 0.24462,
            "fmeasure": 0.31633
        },
        "rougeL": {
            "precision": 0.61905,
            "recall": 0.34048,
            "fmeasure": 0.43849
        },
        "rougeLsum": {
            "precision": 0.61905,
            "recall": 0.34048,
            "fmeasure": 0.43849
        },
        "nubia": {
            "semantic_relation": 3.11644,
            "contradiction": 0.72633,
            "irrelevancy": 79.48299,
            "logical_agreement": 19.79067,
            "grammar_ref": 3.72412,
            "grammar_hyp": 3.7673,
            "nubia_score": 0.31264
        },
        "meteor": 0.22075918674796763,
        "bleurt": -0.1724,
        "bertscore": {
            "precision": 0.90011,
            "recall": 0.83739,
            "f1": 0.86762
        }
    },
    "wiki_lingua_spanish_es_validation": {
        "predictions_file": "ByT5-base (Baseline)/wiki_lingua_spanish_es_validation",
        "N": 11316,
        "total_length": 277759,
        "mean_pred_length": 24.545687522092614,
        "std_pred_length": 5.21293985373107,
        "median_pred_length": 26.0,
        "min_pred_length": 2,
        "max_pred_length": 47,
        "distinct-1": 0.04802004615512009,
        "vocab_size-1": 13338,
        "unique-1": 5331,
        "entropy-1": 9.022522897291788,
        "distinct-2": 0.2813997740604932,
        "vocab_size-2": 74977,
        "unique-2": 49931,
        "entropy-2": 14.073635545278682,
        "cond_entropy-2": 5.075889375564872,
        "distinct-3": 0.611189721197678,
        "vocab_size-3": 155931,
        "unique-3": 127565,
        "entropy-3": 16.4033644365314,
        "cond_entropy-3": 2.389118992082609,
        "total_length-nopunct": 239688,
        "mean_pred_length-nopunct": 21.181336161187698,
        "std_pred_length-nopunct": 4.898942490155295,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.05554303928440306,
        "vocab_size-1-nopunct": 13313,
        "unique-1-nopunct": 5328,
        "entropy-1-nopunct": 9.728197488765705,
        "distinct-2-nopunct": 0.39889741299283626,
        "vocab_size-2-nopunct": 91097,
        "unique-2-nopunct": 67100,
        "entropy-2-nopunct": 14.762237275047148,
        "cond_entropy-2-nopunct": 5.170105786606297,
        "distinct-3-nopunct": 0.7324527658633446,
        "vocab_size-3-nopunct": 158984,
        "unique-3-nopunct": 137387,
        "entropy-3-nopunct": 16.80408204397408,
        "cond_entropy-3-nopunct": 2.114718018558523,
        "msttr-100": 0.59561,
        "msttr-100_nopunct": 0.6602,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_validation.json",
        "local_recall": {
            "1": 0.2728610490721994
        },
        "nist": 2.0276194829055645,
        "bleu": 8.25757,
        "rouge1": {
            "precision": 0.44881,
            "recall": 0.32215,
            "fmeasure": 0.35396
        },
        "rouge2": {
            "precision": 0.17437,
            "recall": 0.12492,
            "fmeasure": 0.13709
        },
        "rougeL": {
            "precision": 0.36878,
            "recall": 0.26966,
            "fmeasure": 0.29384
        },
        "rougeLsum": {
            "precision": 0.36878,
            "recall": 0.26966,
            "fmeasure": 0.29384
        },
        "sari": 67.59697,
        "nubia": {
            "semantic_relation": 2.86896,
            "contradiction": 15.52922,
            "irrelevancy": 44.3164,
            "logical_agreement": 40.15438,
            "grammar_ref": 3.95671,
            "grammar_hyp": 3.97442,
            "nubia_score": 0.37279
        },
        "meteor": 0.14332199152918712,
        "bleurt": -0.47233,
        "bertscore": {
            "precision": 0.85634,
            "recall": 0.83093,
            "f1": 0.8429
        }
    },
    "totto_test_contrast_challenge_continent-europe": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 150,
        "total_length": 2420,
        "mean_pred_length": 16.133333333333333,
        "std_pred_length": 5.438954147832304,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.41198347107438016,
        "vocab_size-1": 997,
        "unique-1": 785,
        "entropy-1": 8.22335849445509,
        "distinct-2": 0.8074889867841409,
        "vocab_size-2": 1833,
        "unique-2": 1652,
        "entropy-2": 10.531583768468154,
        "cond_entropy-2": 2.093495310486234,
        "distinct-3": 0.9443396226415094,
        "vocab_size-3": 2002,
        "unique-3": 1921,
        "entropy-3": 10.91801787284011,
        "cond_entropy-3": 0.3986533173780516,
        "total_length-nopunct": 2148,
        "mean_pred_length-nopunct": 14.32,
        "std_pred_length-nopunct": 5.081102242624133,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4613594040968343,
        "vocab_size-1-nopunct": 991,
        "unique-1-nopunct": 784,
        "entropy-1-nopunct": 8.485879949325557,
        "distinct-2-nopunct": 0.8213213213213213,
        "vocab_size-2-nopunct": 1641,
        "unique-2-nopunct": 1500,
        "entropy-2-nopunct": 10.367036696564455,
        "cond_entropy-2-nopunct": 1.997724558947475,
        "distinct-3-nopunct": 0.9523809523809523,
        "vocab_size-3-nopunct": 1760,
        "unique-3-nopunct": 1700,
        "entropy-3-nopunct": 10.738271445689657,
        "cond_entropy-3-nopunct": 0.4038088194674365,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.76095,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21767241379310345,
            "2": 0.47297297297297297,
            "3": 0.8047016274864376
        },
        "nist": 8.258444293361784,
        "bleu": 48.06655,
        "rouge1": {
            "precision": 0.79054,
            "recall": 0.76755,
            "fmeasure": 0.77134
        },
        "rouge2": {
            "precision": 0.56127,
            "recall": 0.54067,
            "fmeasure": 0.54478
        },
        "rougeL": {
            "precision": 0.67713,
            "recall": 0.66313,
            "fmeasure": 0.66274
        },
        "rougeLsum": {
            "precision": 0.67713,
            "recall": 0.66313,
            "fmeasure": 0.66274
        },
        "nubia": {
            "semantic_relation": 4.40895,
            "contradiction": 5.22079,
            "irrelevancy": 23.60407,
            "logical_agreement": 71.17515,
            "grammar_ref": 4.85127,
            "grammar_hyp": 4.79773,
            "nubia_score": 0.78694
        },
        "meteor": 0.409823594730569,
        "bleurt": 0.33587,
        "bertscore": {
            "precision": 0.93618,
            "recall": 0.93515,
            "f1": 0.93453
        }
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 125,
        "total_length": 2929,
        "mean_pred_length": 23.432,
        "std_pred_length": 4.316176085379279,
        "median_pred_length": 24.0,
        "min_pred_length": 11,
        "max_pred_length": 30,
        "distinct-1": 0.14475930351655855,
        "vocab_size-1": 424,
        "unique-1": 155,
        "entropy-1": 7.040790809099561,
        "distinct-2": 0.3698288159771755,
        "vocab_size-2": 1037,
        "unique-2": 579,
        "entropy-2": 9.241120377692026,
        "cond_entropy-2": 2.2175847942012847,
        "distinct-3": 0.53826054497947,
        "vocab_size-3": 1442,
        "unique-3": 978,
        "entropy-3": 9.972740667783011,
        "cond_entropy-3": 0.7932953795736075,
        "total_length-nopunct": 2672,
        "mean_pred_length-nopunct": 21.376,
        "std_pred_length-nopunct": 4.207923953685475,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.156437125748503,
        "vocab_size-1-nopunct": 418,
        "unique-1-nopunct": 153,
        "entropy-1-nopunct": 7.106231574101213,
        "distinct-2-nopunct": 0.3800549666274048,
        "vocab_size-2-nopunct": 968,
        "unique-2-nopunct": 560,
        "entropy-2-nopunct": 9.141046883836701,
        "cond_entropy-2-nopunct": 2.1430097596778364,
        "distinct-3-nopunct": 0.5478943022295624,
        "vocab_size-3-nopunct": 1327,
        "unique-3-nopunct": 921,
        "entropy-3-nopunct": 9.847717020296994,
        "cond_entropy-3-nopunct": 0.7549559959798353,
        "msttr-100": 0.46655,
        "msttr-100_nopunct": 0.46615,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.16059817945383614,
            "2": 0.4369538077403246,
            "3": 0.7309523809523809
        },
        "nist": 5.647463070835051,
        "bleu": 32.75632,
        "rouge1": {
            "precision": 0.71526,
            "recall": 0.62435,
            "fmeasure": 0.65325
        },
        "rouge2": {
            "precision": 0.4274,
            "recall": 0.37532,
            "fmeasure": 0.38917
        },
        "rougeL": {
            "precision": 0.54411,
            "recall": 0.47588,
            "fmeasure": 0.49586
        },
        "rougeLsum": {
            "precision": 0.54411,
            "recall": 0.47588,
            "fmeasure": 0.49586
        },
        "nubia": {
            "semantic_relation": 3.87211,
            "contradiction": 12.42918,
            "irrelevancy": 17.40167,
            "logical_agreement": 70.16915,
            "grammar_ref": 4.33462,
            "grammar_hyp": 4.55438,
            "nubia_score": 0.58679
        },
        "meteor": 0.29614652382428225,
        "bleurt": -0.14134,
        "bertscore": {
            "precision": 0.89831,
            "recall": 0.87204,
            "f1": 0.88295
        }
    },
    "schema_guided_dialog_challenge_test_backtranslation_parent": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6235,
        "mean_pred_length": 12.47,
        "std_pred_length": 6.4663049727027255,
        "median_pred_length": 11.0,
        "min_pred_length": 1,
        "max_pred_length": 30,
        "distinct-1": 0.16343223736968726,
        "vocab_size-1": 1019,
        "unique-1": 567,
        "entropy-1": 7.8696311784646795,
        "distinct-2": 0.5136878814298169,
        "vocab_size-2": 2946,
        "unique-2": 2102,
        "entropy-2": 10.800209510178824,
        "cond_entropy-2": 2.6826005615429422,
        "distinct-3": 0.7309014514896868,
        "vocab_size-3": 3827,
        "unique-3": 3195,
        "entropy-3": 11.562580872442982,
        "cond_entropy-3": 0.7715877432741309,
        "total_length-nopunct": 5454,
        "mean_pred_length-nopunct": 10.908,
        "std_pred_length-nopunct": 6.025241571920581,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.18445177851118444,
        "vocab_size-1-nopunct": 1006,
        "unique-1-nopunct": 563,
        "entropy-1-nopunct": 8.07717069640075,
        "distinct-2-nopunct": 0.535123132821962,
        "vocab_size-2-nopunct": 2651,
        "unique-2-nopunct": 1936,
        "entropy-2-nopunct": 10.649754209023738,
        "cond_entropy-2-nopunct": 2.7008012220301465,
        "distinct-3-nopunct": 0.7488215488215488,
        "vocab_size-3-nopunct": 3336,
        "unique-3-nopunct": 2851,
        "entropy-3-nopunct": 11.359582791407613,
        "cond_entropy-3-nopunct": 0.7466892965597864,
        "msttr-100": 0.68806,
        "msttr-100_nopunct": 0.7237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5628709198813057
        },
        "nist": 6.007052693104327,
        "bleu": 31.66028,
        "rouge1": {
            "precision": 0.55566,
            "recall": 0.5383,
            "fmeasure": 0.53549
        },
        "rouge2": {
            "precision": 0.34239,
            "recall": 0.33178,
            "fmeasure": 0.32923
        },
        "rougeL": {
            "precision": 0.50127,
            "recall": 0.48496,
            "fmeasure": 0.48288
        },
        "rougeLsum": {
            "precision": 0.50127,
            "recall": 0.48496,
            "fmeasure": 0.48288
        },
        "nubia": {
            "semantic_relation": 3.57861,
            "contradiction": 6.21379,
            "irrelevancy": 24.31611,
            "logical_agreement": 69.47009,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.62402,
            "nubia_score": 0.63598
        },
        "meteor": 0.3132312457727076,
        "bleurt": -0.08128,
        "bertscore": {
            "precision": 0.86831,
            "recall": 0.86402,
            "f1": 0.86564
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_60": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 3.0,
        "median_pred_length": 20.0,
        "min_pred_length": 17,
        "max_pred_length": 23,
        "distinct-1": 0.625,
        "vocab_size-1": 25,
        "unique-1": 15,
        "entropy-1": 4.431687083026442,
        "distinct-2": 0.8421052631578947,
        "vocab_size-2": 32,
        "unique-2": 26,
        "entropy-2": 4.932138039759377,
        "cond_entropy-2": 0.49467416788350776,
        "distinct-3": 0.8611111111111112,
        "vocab_size-3": 31,
        "unique-3": 26,
        "entropy-3": 4.892147223664533,
        "cond_entropy-3": -0.0224469564457176,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.696969696969697,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.377727452691788,
        "distinct-2-nopunct": 0.8387096774193549,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.631615665225586,
        "cond_entropy-2-nopunct": 0.29689896522197023,
        "distinct-3-nopunct": 0.8620689655172413,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.582118926162054,
        "cond_entropy-3-nopunct": -0.02724979801792366,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8333333333333334
        },
        "nist": 5.014186237381212,
        "bleu": 66.61126,
        "rouge1": {
            "precision": 0.93797,
            "recall": 0.84114,
            "fmeasure": 0.88637
        },
        "rouge2": {
            "precision": 0.75356,
            "recall": 0.67357,
            "fmeasure": 0.71081
        },
        "rougeL": {
            "precision": 0.76003,
            "recall": 0.67891,
            "fmeasure": 0.71686
        },
        "rougeLsum": {
            "precision": 0.76003,
            "recall": 0.67891,
            "fmeasure": 0.71686
        },
        "nubia": {
            "semantic_relation": 3.86732,
            "contradiction": 33.69707,
            "irrelevancy": 20.49491,
            "logical_agreement": 45.80802,
            "grammar_ref": 4.80653,
            "grammar_hyp": 4.84431,
            "nubia_score": 0.55741
        },
        "meteor": 0.4570043229609257,
        "bleurt": 0.30732,
        "bertscore": {
            "precision": 0.96572,
            "recall": 0.94801,
            "f1": 0.95628
        }
    },
    "e2e_nlg_validation": {
        "predictions_file": "ByT5-base (Baseline)/e2e_nlg_validation",
        "N": 4299,
        "total_length": 97047,
        "mean_pred_length": 22.574319609211443,
        "std_pred_length": 4.207764422353176,
        "median_pred_length": 24.0,
        "min_pred_length": 9,
        "max_pred_length": 33,
        "distinct-1": 0.006234092759178542,
        "vocab_size-1": 605,
        "unique-1": 91,
        "entropy-1": 6.259255253446197,
        "distinct-2": 0.030534351145038167,
        "vocab_size-2": 2832,
        "unique-2": 636,
        "entropy-2": 8.574571032931685,
        "cond_entropy-2": 2.3498584824708852,
        "distinct-3": 0.0651674976540153,
        "vocab_size-3": 5764,
        "unique-3": 1618,
        "entropy-3": 10.11126663344645,
        "cond_entropy-3": 1.6283393084533315,
        "total_length-nopunct": 90213,
        "mean_pred_length-nopunct": 20.984647592463364,
        "std_pred_length-nopunct": 4.101100412898256,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.006650926141465199,
        "vocab_size-1-nopunct": 600,
        "unique-1-nopunct": 91,
        "entropy-1-nopunct": 6.283403998123715,
        "distinct-2-nopunct": 0.033114509858695906,
        "vocab_size-2-nopunct": 2845,
        "unique-2-nopunct": 669,
        "entropy-2-nopunct": 8.54729582975993,
        "cond_entropy-2-nopunct": 2.3854280332964244,
        "distinct-3-nopunct": 0.06856582736016664,
        "vocab_size-3-nopunct": 5596,
        "unique-3-nopunct": 1611,
        "entropy-3-nopunct": 10.114745149460848,
        "cond_entropy-3-nopunct": 1.6512729502949397,
        "msttr-100": 0.31545,
        "msttr-100_nopunct": 0.30603,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_validation.json",
        "local_recall": {
            "1": 0.6280063090756283
        },
        "nist": 4.701974262425899,
        "bleu": 26.35201,
        "rouge1": {
            "precision": 0.67803,
            "recall": 0.64879,
            "fmeasure": 0.65264
        },
        "rouge2": {
            "precision": 0.39242,
            "recall": 0.37257,
            "fmeasure": 0.37623
        },
        "rougeL": {
            "precision": 0.49269,
            "recall": 0.47301,
            "fmeasure": 0.47507
        },
        "rougeLsum": {
            "precision": 0.49269,
            "recall": 0.47301,
            "fmeasure": 0.47507
        },
        "nubia": {
            "semantic_relation": 3.97651,
            "contradiction": 4.85797,
            "irrelevancy": 27.20139,
            "logical_agreement": 67.94065,
            "grammar_ref": 4.85661,
            "grammar_hyp": 4.74156,
            "nubia_score": 0.65861
        },
        "meteor": 0.32308796155065506,
        "bleurt": -0.02641,
        "bertscore": {
            "precision": 0.89643,
            "recall": 0.88655,
            "f1": 0.89114
        }
    },
    "schema_guided_dialog_challenge_test_bfp02_parent": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6388,
        "mean_pred_length": 12.776,
        "std_pred_length": 6.8423551500926925,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 31,
        "distinct-1": 0.16155291170945524,
        "vocab_size-1": 1032,
        "unique-1": 567,
        "entropy-1": 7.904274113526804,
        "distinct-2": 0.5030570652173914,
        "vocab_size-2": 2962,
        "unique-2": 2078,
        "entropy-2": 10.82317845788572,
        "cond_entropy-2": 2.6978271060107524,
        "distinct-3": 0.7301410541945063,
        "vocab_size-3": 3934,
        "unique-3": 3258,
        "entropy-3": 11.63192984058653,
        "cond_entropy-3": 0.8332675636201858,
        "total_length-nopunct": 5645,
        "mean_pred_length-nopunct": 11.29,
        "std_pred_length-nopunct": 6.36945052575181,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.18033658104517272,
        "vocab_size-1-nopunct": 1018,
        "unique-1-nopunct": 563,
        "entropy-1-nopunct": 8.081116591827428,
        "distinct-2-nopunct": 0.5175898931000972,
        "vocab_size-2-nopunct": 2663,
        "unique-2-nopunct": 1904,
        "entropy-2-nopunct": 10.669446059790133,
        "cond_entropy-2-nopunct": 2.71785601269042,
        "distinct-3-nopunct": 0.7389151958674128,
        "vocab_size-3-nopunct": 3433,
        "unique-3-nopunct": 2883,
        "entropy-3-nopunct": 11.432274312556602,
        "cond_entropy-3-nopunct": 0.8102763193742971,
        "msttr-100": 0.70048,
        "msttr-100_nopunct": 0.72214,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5637092557085585
        },
        "nist": 6.178850412757962,
        "bleu": 32.50928,
        "rouge1": {
            "precision": 0.58296,
            "recall": 0.55205,
            "fmeasure": 0.55581
        },
        "rouge2": {
            "precision": 0.37436,
            "recall": 0.35222,
            "fmeasure": 0.35483
        },
        "rougeL": {
            "precision": 0.5315,
            "recall": 0.50126,
            "fmeasure": 0.50578
        },
        "rougeLsum": {
            "precision": 0.5315,
            "recall": 0.50126,
            "fmeasure": 0.50578
        },
        "nubia": {
            "semantic_relation": 3.60423,
            "contradiction": 6.15619,
            "irrelevancy": 24.14666,
            "logical_agreement": 69.69715,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.73156,
            "nubia_score": 0.62937
        },
        "meteor": 0.3137732678704105,
        "bleurt": -0.11867,
        "bertscore": {
            "precision": 0.87198,
            "recall": 0.86426,
            "f1": 0.86762
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_75": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 30,
        "mean_pred_length": 30.0,
        "std_pred_length": 0.0,
        "median_pred_length": 30.0,
        "min_pred_length": 30,
        "max_pred_length": 30,
        "distinct-1": 0.6,
        "vocab_size-1": 18,
        "unique-1": 15,
        "entropy-1": 3.66818194698418,
        "distinct-2": 0.8275862068965517,
        "vocab_size-2": 24,
        "unique-2": 23,
        "entropy-2": 4.32316116739216,
        "cond_entropy-2": 0.6976933117398546,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": 0.5032944627988511,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6956521739130435,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.5821930667351345,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.7924210049596309,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5833333333333334
        },
        "nist": 1.386090780343264,
        "bleu": 7.42587,
        "rouge1": {
            "precision": 0.3913,
            "recall": 0.53125,
            "fmeasure": 0.45028
        },
        "rouge2": {
            "precision": 0.13636,
            "recall": 0.18824,
            "fmeasure": 0.158
        },
        "rougeL": {
            "precision": 0.34783,
            "recall": 0.47222,
            "fmeasure": 0.40025
        },
        "rougeLsum": {
            "precision": 0.34783,
            "recall": 0.47222,
            "fmeasure": 0.40025
        },
        "nubia": {
            "semantic_relation": 2.82059,
            "contradiction": 14.15404,
            "irrelevancy": 66.48839,
            "logical_agreement": 19.35757,
            "grammar_ref": 4.60656,
            "grammar_hyp": 3.30675,
            "nubia_score": 0.49484
        },
        "meteor": 0.25983314586050726,
        "bleurt": 0.20481,
        "bertscore": {
            "precision": 0.83796,
            "recall": 0.87787,
            "f1": 0.85745
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?request": {
        "predictions_file": "ByT5-base (Baseline)/cs_restaurants_test",
        "N": 149,
        "total_length": 1788,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.005592841163310962,
        "vocab_size-1": 10,
        "unique-1": 0,
        "entropy-1": 3.188721875540867,
        "distinct-2": 0.006711409395973154,
        "vocab_size-2": 11,
        "unique-2": 0,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.30673161811281985,
        "distinct-3": 0.006711409395973154,
        "vocab_size-3": 10,
        "unique-3": 0,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 1192,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.006711409395973154,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 0.006711409395973154,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 0.006711409395973154,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": 0.1,
        "msttr-100_nopunct": 0.08,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.09785522788203753
        },
        "nist": 0.4722844955395275,
        "bleu": 0.696,
        "rouge1": {
            "precision": 0.17833,
            "recall": 0.38229,
            "fmeasure": 0.23855
        },
        "rouge2": {
            "precision": 0.03975,
            "recall": 0.11333,
            "fmeasure": 0.0579
        },
        "rougeL": {
            "precision": 0.16635,
            "recall": 0.35865,
            "fmeasure": 0.22326
        },
        "rougeLsum": {
            "precision": 0.16635,
            "recall": 0.35865,
            "fmeasure": 0.22326
        },
        "nubia": {
            "semantic_relation": 2.21147,
            "contradiction": 50.78054,
            "irrelevancy": 43.97333,
            "logical_agreement": 5.24613,
            "grammar_ref": 6.81129,
            "grammar_hyp": 6.2034,
            "nubia_score": 0.20101
        },
        "meteor": 0.05941689963779256,
        "bleurt": -1.10101,
        "bertscore": {
            "precision": 0.79134,
            "recall": 0.85869,
            "f1": 0.82349
        }
    },
    "schema_guided_dialog_challenge_test_bfp05_parent": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "total_length": 5989,
        "mean_pred_length": 11.978,
        "std_pred_length": 6.302818099866123,
        "median_pred_length": 10.0,
        "min_pred_length": 2,
        "max_pred_length": 30,
        "distinct-1": 0.1668058106528636,
        "vocab_size-1": 999,
        "unique-1": 563,
        "entropy-1": 7.844313660650554,
        "distinct-2": 0.5155766077609765,
        "vocab_size-2": 2830,
        "unique-2": 2037,
        "entropy-2": 10.734345630954435,
        "cond_entropy-2": 2.6400023424997014,
        "distinct-3": 0.7420324714371618,
        "vocab_size-3": 3702,
        "unique-3": 3138,
        "entropy-3": 11.521866903161182,
        "cond_entropy-3": 0.8100193285235233,
        "total_length-nopunct": 5270,
        "mean_pred_length-nopunct": 10.54,
        "std_pred_length-nopunct": 5.888327436547666,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.1872865275142315,
        "vocab_size-1-nopunct": 987,
        "unique-1-nopunct": 559,
        "entropy-1-nopunct": 8.034384056430532,
        "distinct-2-nopunct": 0.5314465408805031,
        "vocab_size-2-nopunct": 2535,
        "unique-2-nopunct": 1864,
        "entropy-2-nopunct": 10.564569559664427,
        "cond_entropy-2-nopunct": 2.6737980012154083,
        "distinct-3-nopunct": 0.751288056206089,
        "vocab_size-3-nopunct": 3208,
        "unique-3-nopunct": 2752,
        "entropy-3-nopunct": 11.309947311403555,
        "cond_entropy-3-nopunct": 0.7885544348336716,
        "msttr-100": 0.69525,
        "msttr-100_nopunct": 0.72288,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5556980578966655
        },
        "nist": 6.076470033418804,
        "bleu": 31.83191,
        "rouge1": {
            "precision": 0.57127,
            "recall": 0.53799,
            "fmeasure": 0.5426
        },
        "rouge2": {
            "precision": 0.35704,
            "recall": 0.3354,
            "fmeasure": 0.33823
        },
        "rougeL": {
            "precision": 0.51295,
            "recall": 0.48304,
            "fmeasure": 0.48737
        },
        "rougeLsum": {
            "precision": 0.51295,
            "recall": 0.48304,
            "fmeasure": 0.48737
        },
        "nubia": {
            "semantic_relation": 3.55152,
            "contradiction": 5.60129,
            "irrelevancy": 25.83734,
            "logical_agreement": 68.56137,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.77444,
            "nubia_score": 0.61875
        },
        "meteor": 0.31297574180760857,
        "bleurt": -0.1223,
        "bertscore": {
            "precision": 0.86784,
            "recall": 0.86126,
            "f1": 0.86404
        }
    },
    "e2e_nlg_test": {
        "predictions_file": "ByT5-base (Baseline)/e2e_nlg_test",
        "N": 4693,
        "total_length": 106908,
        "mean_pred_length": 22.78031110164074,
        "std_pred_length": 3.7584906576170654,
        "median_pred_length": 24.0,
        "min_pred_length": 9,
        "max_pred_length": 32,
        "distinct-1": 0.005565532981629064,
        "vocab_size-1": 595,
        "unique-1": 94,
        "entropy-1": 6.246828509553332,
        "distinct-2": 0.02633664334980189,
        "vocab_size-2": 2692,
        "unique-2": 590,
        "entropy-2": 8.520316552165403,
        "cond_entropy-2": 2.3400423581233913,
        "distinct-3": 0.060242817005393655,
        "vocab_size-3": 5875,
        "unique-3": 1542,
        "entropy-3": 10.043471579654945,
        "cond_entropy-3": 1.6247462642872699,
        "total_length-nopunct": 100284,
        "mean_pred_length-nopunct": 21.368847219262733,
        "std_pred_length-nopunct": 3.717906218415939,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.005903234813130709,
        "vocab_size-1-nopunct": 592,
        "unique-1-nopunct": 94,
        "entropy-1-nopunct": 6.255803577379708,
        "distinct-2-nopunct": 0.028381332970677155,
        "vocab_size-2-nopunct": 2713,
        "unique-2-nopunct": 623,
        "entropy-2-nopunct": 8.50527633057781,
        "cond_entropy-2-nopunct": 2.378463151256464,
        "distinct-3-nopunct": 0.06315870536205417,
        "vocab_size-3-nopunct": 5741,
        "unique-3-nopunct": 1519,
        "entropy-3-nopunct": 10.056769241106194,
        "cond_entropy-3-nopunct": 1.646700294259664,
        "msttr-100": 0.32039,
        "msttr-100_nopunct": 0.31187,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6335259314957358
        },
        "nist": 4.829044040578936,
        "bleu": 26.44467,
        "rouge1": {
            "precision": 0.72016,
            "recall": 0.6517,
            "fmeasure": 0.67318
        },
        "rouge2": {
            "precision": 0.42417,
            "recall": 0.38207,
            "fmeasure": 0.39528
        },
        "rougeL": {
            "precision": 0.51654,
            "recall": 0.46949,
            "fmeasure": 0.48386
        },
        "rougeLsum": {
            "precision": 0.51654,
            "recall": 0.46949,
            "fmeasure": 0.48386
        },
        "nubia": {
            "semantic_relation": 3.98583,
            "contradiction": 4.17145,
            "irrelevancy": 29.0918,
            "logical_agreement": 66.73675,
            "grammar_ref": 4.83021,
            "grammar_hyp": 4.76956,
            "nubia_score": 0.65934
        },
        "meteor": 0.3228153578236942,
        "bleurt": -0.02994,
        "bertscore": {
            "precision": 0.90506,
            "recall": 0.8896,
            "f1": 0.89688
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 159,
        "total_length": 1915,
        "mean_pred_length": 12.044025157232705,
        "std_pred_length": 2.3561665698815717,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 20,
        "distinct-1": 0.41096605744125325,
        "vocab_size-1": 787,
        "unique-1": 525,
        "entropy-1": 8.325165271118646,
        "distinct-2": 0.7283599088838268,
        "vocab_size-2": 1279,
        "unique-2": 1036,
        "entropy-2": 10.033173054161983,
        "cond_entropy-2": 1.8657584854348064,
        "distinct-3": 0.8778960551033187,
        "vocab_size-3": 1402,
        "unique-3": 1254,
        "entropy-3": 10.367621190762023,
        "cond_entropy-3": 0.3903079451649417,
        "total_length-nopunct": 1646,
        "mean_pred_length-nopunct": 10.352201257861635,
        "std_pred_length-nopunct": 1.8123904947353986,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.4738760631834751,
        "vocab_size-1-nopunct": 780,
        "unique-1-nopunct": 523,
        "entropy-1-nopunct": 8.698177913693216,
        "distinct-2-nopunct": 0.7700067249495629,
        "vocab_size-2-nopunct": 1145,
        "unique-2-nopunct": 956,
        "entropy-2-nopunct": 9.93562554876347,
        "cond_entropy-2-nopunct": 1.3767282208226141,
        "distinct-3-nopunct": 0.8930722891566265,
        "vocab_size-3-nopunct": 1186,
        "unique-3-nopunct": 1084,
        "entropy-3-nopunct": 10.13245491782611,
        "cond_entropy-3-nopunct": 0.25831488098555594,
        "msttr-100": 0.77789,
        "msttr-100_nopunct": 0.84375,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.10396361273554255,
            "2": 0.2514469453376206,
            "3": 0.40226876090750435
        },
        "nist": 0.15598710533948854,
        "bleu": 10.09004,
        "rouge1": {
            "precision": 0.21069,
            "recall": 0.14013,
            "fmeasure": 0.15961
        },
        "rouge2": {
            "precision": 0.07582,
            "recall": 0.04213,
            "fmeasure": 0.05197
        },
        "rougeL": {
            "precision": 0.20755,
            "recall": 0.13698,
            "fmeasure": 0.15646
        },
        "rougeLsum": {
            "precision": 0.20755,
            "recall": 0.13698,
            "fmeasure": 0.15646
        },
        "nubia": {
            "semantic_relation": 3.25391,
            "contradiction": 23.03653,
            "irrelevancy": 21.80277,
            "logical_agreement": 55.1607,
            "grammar_ref": 2.45758,
            "grammar_hyp": 2.65532,
            "nubia_score": 0.57541
        },
        "meteor": 0.2828433260883539,
        "bleurt": -0.04249,
        "bertscore": {
            "precision": 0.93919,
            "recall": 0.87339,
            "f1": 0.90438
        }
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 1510,
        "total_length": 27465,
        "mean_pred_length": 18.188741721854306,
        "std_pred_length": 6.427342699617433,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.06633897687966503,
        "vocab_size-1": 1822,
        "unique-1": 639,
        "entropy-1": 8.120713403698035,
        "distinct-2": 0.22130610672317472,
        "vocab_size-2": 5744,
        "unique-2": 2804,
        "entropy-2": 11.13078542699159,
        "cond_entropy-2": 2.9305959555085974,
        "distinct-3": 0.3845367150746574,
        "vocab_size-3": 9400,
        "unique-3": 5759,
        "entropy-3": 12.270402333579876,
        "cond_entropy-3": 1.252341754309269,
        "total_length-nopunct": 24848,
        "mean_pred_length-nopunct": 16.455629139072848,
        "std_pred_length-nopunct": 6.1087564527394616,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.0729636188023181,
        "vocab_size-1-nopunct": 1813,
        "unique-1-nopunct": 639,
        "entropy-1-nopunct": 8.320143133994389,
        "distinct-2-nopunct": 0.22829719770331647,
        "vocab_size-2-nopunct": 5328,
        "unique-2-nopunct": 2742,
        "entropy-2-nopunct": 11.000503121735608,
        "cond_entropy-2-nopunct": 2.8771114855168127,
        "distinct-3-nopunct": 0.39064504306395453,
        "vocab_size-3-nopunct": 8527,
        "unique-3-nopunct": 5359,
        "entropy-3-nopunct": 12.11002766620291,
        "cond_entropy-3-nopunct": 1.2173013727621278,
        "msttr-100": 0.5046,
        "msttr-100_nopunct": 0.51056,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.1939225732991745,
            "2": 0.5218211842415664,
            "3": 0.7596844984415749,
            "4": 0.9215686274509803,
            "5": 0.7142857142857143
        },
        "nist": 7.185447769122368,
        "bleu": 42.11197,
        "rouge1": {
            "precision": 0.79343,
            "recall": 0.69723,
            "fmeasure": 0.72915
        },
        "rouge2": {
            "precision": 0.54637,
            "recall": 0.47877,
            "fmeasure": 0.50026
        },
        "rougeL": {
            "precision": 0.66698,
            "recall": 0.58707,
            "fmeasure": 0.61296
        },
        "rougeLsum": {
            "precision": 0.66698,
            "recall": 0.58707,
            "fmeasure": 0.61296
        },
        "nubia": {
            "semantic_relation": 4.21929,
            "contradiction": 7.50658,
            "irrelevancy": 9.09829,
            "logical_agreement": 83.39513,
            "grammar_ref": 4.59892,
            "grammar_hyp": 4.81293,
            "nubia_score": 0.70143
        },
        "meteor": 0.3396674186034721,
        "bleurt": 0.11736,
        "bertscore": {
            "precision": 0.92793,
            "recall": 0.9086,
            "f1": 0.91657
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_100": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.14285714285714285
        },
        "nist": 2.2849572167886243,
        "bleu": 7.433,
        "rouge1": {
            "precision": 0.25,
            "recall": 0.2,
            "fmeasure": 0.21591
        },
        "rouge2": {
            "precision": 0.04545,
            "recall": 0.02632,
            "fmeasure": 0.03333
        },
        "rougeL": {
            "precision": 0.16667,
            "recall": 0.125,
            "fmeasure": 0.1392
        },
        "rougeLsum": {
            "precision": 0.16667,
            "recall": 0.125,
            "fmeasure": 0.1392
        },
        "nubia": {
            "semantic_relation": 1.72771,
            "contradiction": 90.69762,
            "irrelevancy": 6.28932,
            "logical_agreement": 3.01307,
            "grammar_ref": 5.69136,
            "grammar_hyp": 5.49328,
            "nubia_score": 0.10606
        },
        "meteor": 0.08506246167475755,
        "bleurt": -0.51699,
        "bertscore": {
            "precision": 0.79398,
            "recall": 0.73842,
            "f1": 0.76363
        }
    },
    "web_nlg_en_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 56,
        "total_length": 600,
        "mean_pred_length": 10.714285714285714,
        "std_pred_length": 4.50283357499271,
        "median_pred_length": 9.0,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.31666666666666665,
        "vocab_size-1": 190,
        "unique-1": 115,
        "entropy-1": 6.348056324156982,
        "distinct-2": 0.6139705882352942,
        "vocab_size-2": 334,
        "unique-2": 247,
        "entropy-2": 8.002399674563922,
        "cond_entropy-2": 1.3539033132694045,
        "distinct-3": 0.7622950819672131,
        "vocab_size-3": 372,
        "unique-3": 310,
        "entropy-3": 8.330384769890443,
        "cond_entropy-3": 0.3882289669613833,
        "total_length-nopunct": 530,
        "mean_pred_length-nopunct": 9.464285714285714,
        "std_pred_length-nopunct": 4.217160036743946,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.35283018867924526,
        "vocab_size-1-nopunct": 187,
        "unique-1-nopunct": 115,
        "entropy-1-nopunct": 6.482986457260084,
        "distinct-2-nopunct": 0.5949367088607594,
        "vocab_size-2-nopunct": 282,
        "unique-2-nopunct": 208,
        "entropy-2-nopunct": 7.72596909869006,
        "cond_entropy-2-nopunct": 1.3870173200045781,
        "distinct-3-nopunct": 0.7464114832535885,
        "vocab_size-3-nopunct": 312,
        "unique-3-nopunct": 259,
        "entropy-3-nopunct": 8.050164417923643,
        "cond_entropy-3-nopunct": 0.37239613269372596,
        "msttr-100": 0.59667,
        "msttr-100_nopunct": 0.642,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.2023121387283237,
            "2": 0.6458333333333334,
            "3": 0.8768115942028986
        },
        "nist": 6.8496297919999165,
        "bleu": 55.182,
        "rouge1": {
            "precision": 0.82915,
            "recall": 0.76928,
            "fmeasure": 0.78999
        },
        "rouge2": {
            "precision": 0.60199,
            "recall": 0.56312,
            "fmeasure": 0.57576
        },
        "rougeL": {
            "precision": 0.73822,
            "recall": 0.68427,
            "fmeasure": 0.70301
        },
        "rougeLsum": {
            "precision": 0.73822,
            "recall": 0.68427,
            "fmeasure": 0.70301
        },
        "nubia": {
            "semantic_relation": 4.56999,
            "contradiction": 5.18336,
            "irrelevancy": 8.08406,
            "logical_agreement": 86.73258,
            "grammar_ref": 5.25554,
            "grammar_hyp": 5.35048,
            "nubia_score": 0.82175
        },
        "meteor": 0.44476568404127637,
        "bleurt": 0.3446,
        "bertscore": {
            "precision": 0.953,
            "recall": 0.94543,
            "f1": 0.94809
        }
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 269,
        "total_length": 6326,
        "mean_pred_length": 23.516728624535315,
        "std_pred_length": 4.201776364121215,
        "median_pred_length": 24.0,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.1302560859943092,
        "vocab_size-1": 824,
        "unique-1": 350,
        "entropy-1": 7.638057343541779,
        "distinct-2": 0.36668317649001153,
        "vocab_size-2": 2221,
        "unique-2": 1317,
        "entropy-2": 10.236769426507722,
        "cond_entropy-2": 2.631378957204846,
        "distinct-3": 0.5616793365583966,
        "vocab_size-3": 3251,
        "unique-3": 2323,
        "entropy-3": 11.150991011074625,
        "cond_entropy-3": 0.9770805726632835,
        "total_length-nopunct": 5760,
        "mean_pred_length-nopunct": 21.412639405204462,
        "std_pred_length-nopunct": 4.10240523611119,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.14166666666666666,
        "vocab_size-1-nopunct": 816,
        "unique-1-nopunct": 347,
        "entropy-1-nopunct": 7.739469798470585,
        "distinct-2-nopunct": 0.3804407211801129,
        "vocab_size-2-nopunct": 2089,
        "unique-2-nopunct": 1290,
        "entropy-2-nopunct": 10.158470329699549,
        "cond_entropy-2-nopunct": 2.5445328497684785,
        "distinct-3-nopunct": 0.5752585216392186,
        "vocab_size-3-nopunct": 3004,
        "unique-3-nopunct": 2199,
        "entropy-3-nopunct": 11.034694658831782,
        "cond_entropy-3-nopunct": 0.9383261930449409,
        "msttr-100": 0.54968,
        "msttr-100_nopunct": 0.55175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.1519099792715428,
            "2": 0.43870258383727323,
            "3": 0.7277057422598571,
            "4": 0.25,
            "5": 1.0
        },
        "nist": 5.641748779866753,
        "bleu": 33.58041,
        "rouge1": {
            "precision": 0.73709,
            "recall": 0.61235,
            "fmeasure": 0.6596
        },
        "rouge2": {
            "precision": 0.44521,
            "recall": 0.36364,
            "fmeasure": 0.39379
        },
        "rougeL": {
            "precision": 0.5667,
            "recall": 0.46762,
            "fmeasure": 0.50416
        },
        "rougeLsum": {
            "precision": 0.5667,
            "recall": 0.46762,
            "fmeasure": 0.50416
        },
        "nubia": {
            "semantic_relation": 3.79269,
            "contradiction": 11.7974,
            "irrelevancy": 14.21846,
            "logical_agreement": 73.98413,
            "grammar_ref": 4.33889,
            "grammar_hyp": 4.67475,
            "nubia_score": 0.55827
        },
        "meteor": 0.29915049190610726,
        "bleurt": -0.1853,
        "bertscore": {
            "precision": 0.89845,
            "recall": 0.87207,
            "f1": 0.88327
        }
    },
    "wiki_lingua_spanish_es_test": {
        "predictions_file": "ByT5-base (Baseline)/wiki_lingua_spanish_es_test",
        "N": 22632,
        "total_length": 553578,
        "mean_pred_length": 24.45996818663839,
        "std_pred_length": 5.224492526772003,
        "median_pred_length": 26.0,
        "min_pred_length": 3,
        "max_pred_length": 44,
        "distinct-1": 0.03292218982690786,
        "vocab_size-1": 18225,
        "unique-1": 7113,
        "entropy-1": 9.068087349756231,
        "distinct-2": 0.23035299258304986,
        "vocab_size-2": 122305,
        "unique-2": 79826,
        "entropy-2": 14.33610671918226,
        "cond_entropy-2": 5.297625546051427,
        "distinct-3": 0.5503881459098117,
        "vocab_size-3": 279770,
        "unique-3": 223153,
        "entropy-3": 16.99647493636782,
        "cond_entropy-3": 2.727615262361788,
        "total_length-nopunct": 478470,
        "mean_pred_length-nopunct": 21.141304347826086,
        "std_pred_length-nopunct": 4.905190316598222,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.03803791251280122,
        "vocab_size-1-nopunct": 18200,
        "unique-1-nopunct": 7111,
        "entropy-1-nopunct": 9.773406604287402,
        "distinct-2-nopunct": 0.3397851868426941,
        "vocab_size-2-nopunct": 154887,
        "unique-2-nopunct": 110874,
        "entropy-2-nopunct": 15.127557793148753,
        "cond_entropy-2-nopunct": 5.496831287259863,
        "distinct-3-nopunct": 0.6779938412672031,
        "vocab_size-3-nopunct": 293711,
        "unique-3-nopunct": 248347,
        "entropy-3-nopunct": 17.52011648795555,
        "cond_entropy-3-nopunct": 2.4759928729313128,
        "msttr-100": 0.59541,
        "msttr-100_nopunct": 0.66051,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_test.json",
        "local_recall": {
            "1": 0.26963428583276605
        },
        "nist": 1.949024793741037,
        "bleu": 8.0697,
        "rouge1": {
            "precision": 0.44772,
            "recall": 0.31869,
            "fmeasure": 0.35132
        },
        "rouge2": {
            "precision": 0.17356,
            "recall": 0.12303,
            "fmeasure": 0.13543
        },
        "rougeL": {
            "precision": 0.36711,
            "recall": 0.26597,
            "fmeasure": 0.29083
        },
        "rougeLsum": {
            "precision": 0.36711,
            "recall": 0.26597,
            "fmeasure": 0.29083
        },
        "sari": 67.52109,
        "nubia": {
            "semantic_relation": 2.85496,
            "contradiction": 15.36351,
            "irrelevancy": 44.68668,
            "logical_agreement": 39.94981,
            "grammar_ref": 3.9494,
            "grammar_hyp": 3.97022,
            "nubia_score": 0.36967
        },
        "meteor": 0.14113305845363955,
        "bleurt": -0.47953,
        "bertscore": {
            "precision": 0.8556,
            "recall": 0.82958,
            "f1": 0.84184
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_123": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 24,
        "unique-1": 22,
        "entropy-1": 4.504706483564823,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.20535558144544924,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.05658352836636749,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 26.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 26,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8846153846153846,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.440636352673265,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.2136119717201712,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.058893689053568274,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.10526315789473684,
            "2": 0.6363636363636364
        },
        "nist": 1.7932955656993634,
        "bleu": 36.95081,
        "rouge1": {
            "precision": 0.68519,
            "recall": 0.46515,
            "fmeasure": 0.54215
        },
        "rouge2": {
            "precision": 0.34615,
            "recall": 0.20658,
            "fmeasure": 0.25341
        },
        "rougeL": {
            "precision": 0.57407,
            "recall": 0.36515,
            "fmeasure": 0.43688
        },
        "rougeLsum": {
            "precision": 0.57407,
            "recall": 0.36515,
            "fmeasure": 0.43688
        },
        "nubia": {
            "semantic_relation": 2.80285,
            "contradiction": 35.94204,
            "irrelevancy": 15.92859,
            "logical_agreement": 48.12937,
            "grammar_ref": 4.34131,
            "grammar_hyp": 4.96983,
            "nubia_score": 0.24044
        },
        "meteor": 0.22422752094950904,
        "bleurt": -0.19811,
        "bertscore": {
            "precision": 0.91195,
            "recall": 0.85661,
            "f1": 0.86658
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_18": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 112,
        "mean_pred_length": 22.4,
        "std_pred_length": 5.499090833947008,
        "median_pred_length": 23.0,
        "min_pred_length": 12,
        "max_pred_length": 27,
        "distinct-1": 0.6875,
        "vocab_size-1": 77,
        "unique-1": 59,
        "entropy-1": 5.989786784421019,
        "distinct-2": 0.9532710280373832,
        "vocab_size-2": 102,
        "unique-2": 98,
        "entropy-2": 6.640954019091199,
        "cond_entropy-2": 0.6613339700737612,
        "distinct-3": 0.9803921568627451,
        "vocab_size-3": 100,
        "unique-3": 98,
        "entropy-3": 6.63320965569699,
        "cond_entropy-3": -0.00281725715353893,
        "total_length-nopunct": 96,
        "mean_pred_length-nopunct": 19.2,
        "std_pred_length-nopunct": 4.261455150532504,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 72,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.955729459506924,
        "distinct-2-nopunct": 0.967032967032967,
        "vocab_size-2-nopunct": 88,
        "unique-2-nopunct": 85,
        "entropy-2-nopunct": 6.441860574264634,
        "cond_entropy-2-nopunct": 0.49872633680244866,
        "distinct-3-nopunct": 0.9767441860465116,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 82,
        "entropy-3-nopunct": 6.379753126795122,
        "cond_entropy-3-nopunct": -0.058274071543109686,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.5238095238095238,
            "3": 0.4666666666666667
        },
        "nist": 2.5044260147616866,
        "bleu": 19.83534,
        "rouge1": {
            "precision": 0.65022,
            "recall": 0.54487,
            "fmeasure": 0.57777
        },
        "rouge2": {
            "precision": 0.3915,
            "recall": 0.35805,
            "fmeasure": 0.36768
        },
        "rougeL": {
            "precision": 0.55263,
            "recall": 0.48037,
            "fmeasure": 0.50371
        },
        "rougeLsum": {
            "precision": 0.55263,
            "recall": 0.48037,
            "fmeasure": 0.50371
        },
        "nubia": {
            "semantic_relation": 3.26152,
            "contradiction": 25.8541,
            "irrelevancy": 21.58013,
            "logical_agreement": 52.56578,
            "grammar_ref": 3.87874,
            "grammar_hyp": 4.06917,
            "nubia_score": 0.50477
        },
        "meteor": 0.22381867370601607,
        "bleurt": -0.1326,
        "bertscore": {
            "precision": 0.88158,
            "recall": 0.87037,
            "f1": 0.87574
        }
    },
    "totto_test_contrast_challenge_continent-north_ameria": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 150,
        "total_length": 2537,
        "mean_pred_length": 16.913333333333334,
        "std_pred_length": 5.163896031314168,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 33,
        "distinct-1": 0.4193929838391801,
        "vocab_size-1": 1064,
        "unique-1": 826,
        "entropy-1": 8.315956385955229,
        "distinct-2": 0.8098031001256808,
        "vocab_size-2": 1933,
        "unique-2": 1746,
        "entropy-2": 10.627664673324098,
        "cond_entropy-2": 2.0886268265394605,
        "distinct-3": 0.9423334823424229,
        "vocab_size-3": 2108,
        "unique-3": 2030,
        "entropy-3": 10.986121704015194,
        "cond_entropy-3": 0.34147204084910826,
        "total_length-nopunct": 2197,
        "mean_pred_length-nopunct": 14.646666666666667,
        "std_pred_length-nopunct": 4.584229003393652,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4797451069640419,
        "vocab_size-1-nopunct": 1054,
        "unique-1-nopunct": 824,
        "entropy-1-nopunct": 8.632715919262614,
        "distinct-2-nopunct": 0.8387884709330727,
        "vocab_size-2-nopunct": 1717,
        "unique-2-nopunct": 1581,
        "entropy-2-nopunct": 10.480860128520753,
        "cond_entropy-2-nopunct": 1.9424699981822466,
        "distinct-3-nopunct": 0.9588824459673169,
        "vocab_size-3-nopunct": 1819,
        "unique-3-nopunct": 1771,
        "entropy-3-nopunct": 10.788078750974222,
        "cond_entropy-3-nopunct": 0.3271596877806879,
        "msttr-100": 0.722,
        "msttr-100_nopunct": 0.77476,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16945107398568018,
            "2": 0.3462897526501767,
            "3": 0.7975295381310419
        },
        "nist": 8.23599363302999,
        "bleu": 49.91006,
        "rouge1": {
            "precision": 0.81736,
            "recall": 0.77534,
            "fmeasure": 0.78934
        },
        "rouge2": {
            "precision": 0.57938,
            "recall": 0.54953,
            "fmeasure": 0.55887
        },
        "rougeL": {
            "precision": 0.71422,
            "recall": 0.67739,
            "fmeasure": 0.68953
        },
        "rougeLsum": {
            "precision": 0.71422,
            "recall": 0.67739,
            "fmeasure": 0.68953
        },
        "nubia": {
            "semantic_relation": 4.48531,
            "contradiction": 3.68962,
            "irrelevancy": 17.94043,
            "logical_agreement": 78.36995,
            "grammar_ref": 4.5685,
            "grammar_hyp": 4.62528,
            "nubia_score": 0.81391
        },
        "meteor": 0.4151960326634576,
        "bleurt": 0.39557,
        "bertscore": {
            "precision": 0.94133,
            "recall": 0.93744,
            "f1": 0.93849
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_19": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 102,
        "mean_pred_length": 20.4,
        "std_pred_length": 1.8547236990991407,
        "median_pred_length": 20.0,
        "min_pred_length": 18,
        "max_pred_length": 23,
        "distinct-1": 0.7647058823529411,
        "vocab_size-1": 78,
        "unique-1": 65,
        "entropy-1": 6.0619874742608095,
        "distinct-2": 1.0,
        "vocab_size-2": 97,
        "unique-2": 97,
        "entropy-2": 6.599912842187142,
        "cond_entropy-2": 0.5384634023443995,
        "distinct-3": 1.0,
        "vocab_size-3": 92,
        "unique-3": 92,
        "entropy-3": 6.523561956057027,
        "cond_entropy-3": -0.07635088613011487,
        "total_length-nopunct": 93,
        "mean_pred_length-nopunct": 18.6,
        "std_pred_length-nopunct": 2.4979991993593593,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7956989247311828,
        "vocab_size-1-nopunct": 74,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 5.985290262674412,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 88,
        "unique-2-nopunct": 88,
        "entropy-2-nopunct": 6.459431618637305,
        "cond_entropy-2-nopunct": 0.5056111598511634,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 83,
        "unique-3-nopunct": 83,
        "entropy-3-nopunct": 6.375039431346932,
        "cond_entropy-3-nopunct": -0.0843921872903726,
        "msttr-100": 0.77,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.42424242424242425,
            "3": 0.6857142857142857
        },
        "nist": 3.9494868925382693,
        "bleu": 23.36058,
        "rouge1": {
            "precision": 0.53021,
            "recall": 0.52916,
            "fmeasure": 0.52189
        },
        "rouge2": {
            "precision": 0.24881,
            "recall": 0.22431,
            "fmeasure": 0.23452
        },
        "rougeL": {
            "precision": 0.44855,
            "recall": 0.46336,
            "fmeasure": 0.44916
        },
        "rougeLsum": {
            "precision": 0.44855,
            "recall": 0.46336,
            "fmeasure": 0.44916
        },
        "nubia": {
            "semantic_relation": 3.11557,
            "contradiction": 33.68519,
            "irrelevancy": 61.10088,
            "logical_agreement": 5.21393,
            "grammar_ref": 5.00025,
            "grammar_hyp": 4.52659,
            "nubia_score": 0.45551
        },
        "meteor": 0.27156691012149736,
        "bleurt": -0.09663,
        "bertscore": {
            "precision": 0.86917,
            "recall": 0.87365,
            "f1": 0.86868
        }
    },
    "totto_test_contrast_challenge_continent-oceania": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 105,
        "total_length": 1594,
        "mean_pred_length": 15.18095238095238,
        "std_pred_length": 5.120976380825294,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.4629861982434128,
        "vocab_size-1": 738,
        "unique-1": 594,
        "entropy-1": 7.994022987465983,
        "distinct-2": 0.8462055070517126,
        "vocab_size-2": 1260,
        "unique-2": 1159,
        "entropy-2": 10.063220160047512,
        "cond_entropy-2": 1.8257326240581877,
        "distinct-3": 0.9552023121387283,
        "vocab_size-3": 1322,
        "unique-3": 1281,
        "entropy-3": 10.33021818900673,
        "cond_entropy-3": 0.2830570623685175,
        "total_length-nopunct": 1392,
        "mean_pred_length-nopunct": 13.257142857142858,
        "std_pred_length-nopunct": 4.820647202999024,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5251436781609196,
        "vocab_size-1-nopunct": 731,
        "unique-1-nopunct": 593,
        "entropy-1-nopunct": 8.28318619680636,
        "distinct-2-nopunct": 0.8609168609168609,
        "vocab_size-2-nopunct": 1108,
        "unique-2-nopunct": 1032,
        "entropy-2-nopunct": 9.876231431699704,
        "cond_entropy-2-nopunct": 1.7206720851115473,
        "distinct-3-nopunct": 0.9737732656514383,
        "vocab_size-3-nopunct": 1151,
        "unique-3-nopunct": 1124,
        "entropy-3-nopunct": 10.15159149868497,
        "cond_entropy-3-nopunct": 0.2977411077495106,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.77462,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1930379746835443,
            "2": 0.2966101694915254,
            "3": 0.7771135781383433
        },
        "nist": 7.5213907236205655,
        "bleu": 43.63455,
        "rouge1": {
            "precision": 0.80203,
            "recall": 0.74503,
            "fmeasure": 0.76316
        },
        "rouge2": {
            "precision": 0.53531,
            "recall": 0.50132,
            "fmeasure": 0.51084
        },
        "rougeL": {
            "precision": 0.68314,
            "recall": 0.63666,
            "fmeasure": 0.65109
        },
        "rougeLsum": {
            "precision": 0.68314,
            "recall": 0.63666,
            "fmeasure": 0.65109
        },
        "nubia": {
            "semantic_relation": 4.46825,
            "contradiction": 5.38011,
            "irrelevancy": 20.4509,
            "logical_agreement": 74.169,
            "grammar_ref": 5.02637,
            "grammar_hyp": 5.14845,
            "nubia_score": 0.79217
        },
        "meteor": 0.3863174890538968,
        "bleurt": 0.35752,
        "bertscore": {
            "precision": 0.93596,
            "recall": 0.92932,
            "f1": 0.93162
        }
    },
    "wiki_lingua_turkish_tr_validation": {
        "predictions_file": "ByT5-base (Baseline)/wiki_lingua_turkish_tr_validation",
        "N": 449,
        "total_length": 11064,
        "mean_pred_length": 24.64142538975501,
        "std_pred_length": 4.792177527133178,
        "median_pred_length": 26.0,
        "min_pred_length": 5,
        "max_pred_length": 34,
        "distinct-1": 0.18600867678958785,
        "vocab_size-1": 2058,
        "unique-1": 1061,
        "entropy-1": 8.303453478953731,
        "distinct-2": 0.5640131888836553,
        "vocab_size-2": 5987,
        "unique-2": 4548,
        "entropy-2": 11.793862825439978,
        "cond_entropy-2": 3.5048550333413804,
        "distinct-3": 0.8265787920519378,
        "vocab_size-3": 8403,
        "unique-3": 7507,
        "entropy-3": 12.820388723796793,
        "cond_entropy-3": 1.0590235980333138,
        "total_length-nopunct": 9502,
        "mean_pred_length-nopunct": 21.16258351893096,
        "std_pred_length-nopunct": 4.413264931613593,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.21511260787202693,
        "vocab_size-1-nopunct": 2044,
        "unique-1-nopunct": 1056,
        "entropy-1-nopunct": 8.916634574563743,
        "distinct-2-nopunct": 0.6687285982547222,
        "vocab_size-2-nopunct": 6054,
        "unique-2-nopunct": 4927,
        "entropy-2-nopunct": 12.072639670517475,
        "cond_entropy-2-nopunct": 3.2506477511063645,
        "distinct-3-nopunct": 0.9036494653649465,
        "vocab_size-3-nopunct": 7775,
        "unique-3-nopunct": 7248,
        "entropy-3-nopunct": 12.823410104369227,
        "cond_entropy-3-nopunct": 0.7828580605419927,
        "msttr-100": 0.61427,
        "msttr-100_nopunct": 0.68358,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_validation.json",
        "local_recall": {
            "1": 0.2898629148629149
        },
        "nist": 1.7854437959155236,
        "bleu": 11.3306,
        "rouge1": {
            "precision": 0.45809,
            "recall": 0.32178,
            "fmeasure": 0.35703
        },
        "rouge2": {
            "precision": 0.20409,
            "recall": 0.13762,
            "fmeasure": 0.15533
        },
        "rougeL": {
            "precision": 0.38075,
            "recall": 0.26956,
            "fmeasure": 0.29757
        },
        "rougeLsum": {
            "precision": 0.38075,
            "recall": 0.26956,
            "fmeasure": 0.29757
        },
        "sari": 68.54159,
        "nubia": {
            "semantic_relation": 2.65891,
            "contradiction": 23.60258,
            "irrelevancy": 44.2926,
            "logical_agreement": 32.10482,
            "grammar_ref": 3.85457,
            "grammar_hyp": 4.32207,
            "nubia_score": 0.28938
        },
        "meteor": 0.14900321034244046,
        "bleurt": -0.55227,
        "bertscore": {
            "precision": 0.85626,
            "recall": 0.83396,
            "f1": 0.84442
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 29,
        "total_length": 362,
        "mean_pred_length": 12.482758620689655,
        "std_pred_length": 2.2532840348557985,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 19,
        "distinct-1": 0.44751381215469616,
        "vocab_size-1": 162,
        "unique-1": 101,
        "entropy-1": 6.490503833826313,
        "distinct-2": 0.6876876876876877,
        "vocab_size-2": 229,
        "unique-2": 168,
        "entropy-2": 7.612476189951866,
        "cond_entropy-2": 1.2519320141062857,
        "distinct-3": 0.805921052631579,
        "vocab_size-3": 245,
        "unique-3": 199,
        "entropy-3": 7.825875663036349,
        "cond_entropy-3": 0.2832684307702339,
        "total_length-nopunct": 312,
        "mean_pred_length-nopunct": 10.758620689655173,
        "std_pred_length-nopunct": 1.8128881969786088,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.5096153846153846,
        "vocab_size-1-nopunct": 159,
        "unique-1-nopunct": 101,
        "entropy-1-nopunct": 6.693416793095257,
        "distinct-2-nopunct": 0.7208480565371025,
        "vocab_size-2-nopunct": 204,
        "unique-2-nopunct": 155,
        "entropy-2-nopunct": 7.472512781623267,
        "cond_entropy-2-nopunct": 0.889248723193674,
        "distinct-3-nopunct": 0.8188976377952756,
        "vocab_size-3-nopunct": 208,
        "unique-3-nopunct": 170,
        "entropy-3-nopunct": 7.602703978042578,
        "cond_entropy-3-nopunct": 0.20299520576991137,
        "msttr-100": 0.64333,
        "msttr-100_nopunct": 0.71333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.07342657342657342,
            "2": 0.18823529411764706,
            "3": 0.3343108504398827
        },
        "nist": 0.00808392127558229,
        "bleu": 5.11912,
        "rouge1": {
            "precision": 0.48276,
            "recall": 0.28161,
            "fmeasure": 0.33581
        },
        "rouge2": {
            "precision": 0.27586,
            "recall": 0.15735,
            "fmeasure": 0.18247
        },
        "rougeL": {
            "precision": 0.48276,
            "recall": 0.28161,
            "fmeasure": 0.33581
        },
        "rougeLsum": {
            "precision": 0.48276,
            "recall": 0.28161,
            "fmeasure": 0.33581
        },
        "nubia": {
            "semantic_relation": 3.05439,
            "contradiction": 25.04329,
            "irrelevancy": 24.6536,
            "logical_agreement": 50.30311,
            "grammar_ref": 2.50557,
            "grammar_hyp": 2.68332,
            "nubia_score": 0.65417
        },
        "meteor": 0.25615530126692176,
        "bleurt": -0.02068,
        "bertscore": {
            "precision": 0.93744,
            "recall": 0.85009,
            "f1": 0.89134
        }
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 253,
        "total_length": 2146,
        "mean_pred_length": 8.482213438735178,
        "std_pred_length": 2.1734746234160705,
        "median_pred_length": 8.0,
        "min_pred_length": 4,
        "max_pred_length": 14,
        "distinct-1": 0.4282385834109972,
        "vocab_size-1": 919,
        "unique-1": 631,
        "entropy-1": 8.422929286893492,
        "distinct-2": 0.7696777601690439,
        "vocab_size-2": 1457,
        "unique-2": 1200,
        "entropy-2": 10.283875563230797,
        "cond_entropy-2": 1.2834938118938752,
        "distinct-3": 0.8926829268292683,
        "vocab_size-3": 1464,
        "unique-3": 1325,
        "entropy-3": 10.438358641924053,
        "cond_entropy-3": 0.14065951038465604,
        "total_length-nopunct": 1753,
        "mean_pred_length-nopunct": 6.928853754940712,
        "std_pred_length-nopunct": 2.014492322778454,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.5213918996006845,
        "vocab_size-1-nopunct": 914,
        "unique-1-nopunct": 631,
        "entropy-1-nopunct": 9.063120963813475,
        "distinct-2-nopunct": 0.794,
        "vocab_size-2-nopunct": 1191,
        "unique-2-nopunct": 1003,
        "entropy-2-nopunct": 10.019116397644671,
        "cond_entropy-2-nopunct": 1.0821701586115486,
        "distinct-3-nopunct": 0.9021651964715317,
        "vocab_size-3-nopunct": 1125,
        "unique-3-nopunct": 1028,
        "entropy-3-nopunct": 10.06408108467811,
        "cond_entropy-3-nopunct": 0.10307074967616688,
        "msttr-100": 0.76143,
        "msttr-100_nopunct": 0.87118,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.3918088737201365,
            "2": 0.7210599721059973,
            "3": 0.8054607508532423,
            "4": 0.8285714285714286,
            "5": 0.8181818181818182,
            "6": 0.9,
            "7": 1.0
        },
        "nist": 8.520433265052427,
        "bleu": 59.9794,
        "rouge1": {
            "precision": 0.3045,
            "recall": 0.30326,
            "fmeasure": 0.30267
        },
        "rouge2": {
            "precision": 0.18053,
            "recall": 0.1794,
            "fmeasure": 0.17883
        },
        "rougeL": {
            "precision": 0.30088,
            "recall": 0.2998,
            "fmeasure": 0.29915
        },
        "rougeLsum": {
            "precision": 0.30088,
            "recall": 0.2998,
            "fmeasure": 0.29915
        },
        "nubia": {
            "semantic_relation": 4.19437,
            "contradiction": 19.66624,
            "irrelevancy": 20.79459,
            "logical_agreement": 59.53917,
            "grammar_ref": 2.90527,
            "grammar_hyp": 2.88502,
            "nubia_score": 0.84602
        },
        "meteor": 0.7435920441570049,
        "bleurt": 0.40636,
        "bertscore": {
            "precision": 0.9702,
            "recall": 0.96868,
            "f1": 0.96894
        }
    },
    "e2e_nlg_challenge_train_sample": {
        "predictions_file": "ByT5-base (Baseline)/e2e_nlg_challenge_train_sample",
        "N": 500
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.75
        },
        "nist": 3.26173829582196,
        "bleu": 62.40195,
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "nubia": {
            "semantic_relation": 4.55283,
            "contradiction": 16.96119,
            "irrelevancy": 10.08982,
            "logical_agreement": 72.94899,
            "grammar_ref": 2.53664,
            "grammar_hyp": 2.64314,
            "nubia_score": 0.91507
        },
        "meteor": 1.0,
        "bleurt": 0.47284,
        "bertscore": {
            "precision": 0.99592,
            "recall": 0.99697,
            "f1": 0.99644
        }
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 1322,
        "total_length": 23897,
        "mean_pred_length": 18.076399394856278,
        "std_pred_length": 6.834729528778581,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.06779093610076578,
        "vocab_size-1": 1620,
        "unique-1": 591,
        "entropy-1": 8.018319568570897,
        "distinct-2": 0.22551495016611295,
        "vocab_size-2": 5091,
        "unique-2": 2525,
        "entropy-2": 11.005948069829678,
        "cond_entropy-2": 2.8944445842808393,
        "distinct-3": 0.39109772737966403,
        "vocab_size-3": 8312,
        "unique-3": 5073,
        "entropy-3": 12.138649600637248,
        "cond_entropy-3": 1.2396245029852757,
        "total_length-nopunct": 21665,
        "mean_pred_length-nopunct": 16.38804841149773,
        "std_pred_length-nopunct": 6.496940462583776,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.0743595661204708,
        "vocab_size-1-nopunct": 1611,
        "unique-1-nopunct": 591,
        "entropy-1-nopunct": 8.202220091836713,
        "distinct-2-nopunct": 0.23162758688492355,
        "vocab_size-2-nopunct": 4712,
        "unique-2-nopunct": 2418,
        "entropy-2-nopunct": 10.878252133387342,
        "cond_entropy-2-nopunct": 2.86802101667894,
        "distinct-3-nopunct": 0.3996109563114452,
        "vocab_size-3-nopunct": 7601,
        "unique-3-nopunct": 4778,
        "entropy-3-nopunct": 11.99003524614388,
        "cond_entropy-3-nopunct": 1.211894163147052,
        "msttr-100": 0.51508,
        "msttr-100_nopunct": 0.52282,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.1920765258613392,
            "2": 0.534926212227688,
            "3": 0.7796432318992654,
            "4": 0.9215686274509803,
            "5": 0.7142857142857143
        },
        "nist": 7.790981918376593,
        "bleu": 43.37984,
        "rouge1": {
            "precision": 0.78608,
            "recall": 0.71131,
            "fmeasure": 0.73687
        },
        "rouge2": {
            "precision": 0.5379,
            "recall": 0.48634,
            "fmeasure": 0.50315
        },
        "rougeL": {
            "precision": 0.6579,
            "recall": 0.59745,
            "fmeasure": 0.61734
        },
        "rougeLsum": {
            "precision": 0.6579,
            "recall": 0.59745,
            "fmeasure": 0.61734
        },
        "nubia": {
            "semantic_relation": 4.25003,
            "contradiction": 7.79245,
            "irrelevancy": 9.32857,
            "logical_agreement": 82.87897,
            "grammar_ref": 4.6229,
            "grammar_hyp": 4.82691,
            "nubia_score": 0.71382
        },
        "meteor": 0.3507392861164349,
        "bleurt": 0.14189,
        "bertscore": {
            "precision": 0.92593,
            "recall": 0.91054,
            "f1": 0.91658
        }
    },
    "e2e_nlg_challenge_validation_sample": {
        "predictions_file": "ByT5-base (Baseline)/e2e_nlg_challenge_validation_sample",
        "N": 500
    },
    "web_nlg_ru_test_contrast_challenge_combinations-seen": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 494,
        "total_length": 6046,
        "mean_pred_length": 12.238866396761134,
        "std_pred_length": 2.5545917082609026,
        "median_pred_length": 12.0,
        "min_pred_length": 6,
        "max_pred_length": 21,
        "distinct-1": 0.2707575256367846,
        "vocab_size-1": 1637,
        "unique-1": 937,
        "entropy-1": 8.822364341017606,
        "distinct-2": 0.5886167146974063,
        "vocab_size-2": 3268,
        "unique-2": 2403,
        "entropy-2": 11.154707319907951,
        "cond_entropy-2": 2.4605731221579337,
        "distinct-3": 0.7799525504151839,
        "vocab_size-3": 3945,
        "unique-3": 3286,
        "entropy-3": 11.754931820630269,
        "cond_entropy-3": 0.6924659257689357,
        "total_length-nopunct": 5152,
        "mean_pred_length-nopunct": 10.429149797570851,
        "std_pred_length-nopunct": 2.0672010859583563,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.31618788819875776,
        "vocab_size-1-nopunct": 1629,
        "unique-1-nopunct": 936,
        "entropy-1-nopunct": 9.303928651893226,
        "distinct-2-nopunct": 0.6414770287677115,
        "vocab_size-2-nopunct": 2988,
        "unique-2-nopunct": 2304,
        "entropy-2-nopunct": 11.107625412515038,
        "cond_entropy-2-nopunct": 1.9873046573952073,
        "distinct-3-nopunct": 0.8112391930835735,
        "vocab_size-3-nopunct": 3378,
        "unique-3-nopunct": 2902,
        "entropy-3-nopunct": 11.5510093861053,
        "cond_entropy-3-nopunct": 0.5392491067315572,
        "msttr-100": 0.773,
        "msttr-100_nopunct": 0.8402,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.14634146341463414,
            "2": 0.32172131147540983,
            "3": 0.5297377170299225,
            "4": 1.0,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0
        },
        "nist": 1.5789128129314445,
        "bleu": 20.37482,
        "rouge1": {
            "precision": 0.25247,
            "recall": 0.19398,
            "fmeasure": 0.21099
        },
        "rouge2": {
            "precision": 0.10861,
            "recall": 0.07548,
            "fmeasure": 0.08534
        },
        "rougeL": {
            "precision": 0.24296,
            "recall": 0.18659,
            "fmeasure": 0.20274
        },
        "rougeLsum": {
            "precision": 0.24296,
            "recall": 0.18659,
            "fmeasure": 0.20274
        },
        "nubia": {
            "semantic_relation": 3.46377,
            "contradiction": 21.81012,
            "irrelevancy": 23.15867,
            "logical_agreement": 55.03121,
            "grammar_ref": 2.60025,
            "grammar_hyp": 2.68834,
            "nubia_score": 0.66674
        },
        "meteor": 0.377076148055641,
        "bleurt": 0.01613,
        "bertscore": {
            "precision": 0.94481,
            "recall": 0.90368,
            "f1": 0.9229
        }
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 457,
        "total_length": 9894,
        "mean_pred_length": 21.64989059080963,
        "std_pred_length": 4.055949649483534,
        "median_pred_length": 22.0,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.12249848392965433,
        "vocab_size-1": 1212,
        "unique-1": 534,
        "entropy-1": 7.901771337154164,
        "distinct-2": 0.3361237681466568,
        "vocab_size-2": 3172,
        "unique-2": 1896,
        "entropy-2": 10.558289945064042,
        "cond_entropy-2": 2.681244414939617,
        "distinct-3": 0.5105790645879733,
        "vocab_size-3": 4585,
        "unique-3": 3283,
        "entropy-3": 11.467633856908675,
        "cond_entropy-3": 0.9929969430652773,
        "total_length-nopunct": 8943,
        "mean_pred_length-nopunct": 19.568927789934353,
        "std_pred_length-nopunct": 3.9824776973217757,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.13451861791345185,
        "vocab_size-1-nopunct": 1203,
        "unique-1-nopunct": 532,
        "entropy-1-nopunct": 8.059906466480598,
        "distinct-2-nopunct": 0.3475135517322649,
        "vocab_size-2-nopunct": 2949,
        "unique-2-nopunct": 1822,
        "entropy-2-nopunct": 10.460717533004418,
        "cond_entropy-2-nopunct": 2.5500327959509197,
        "distinct-3-nopunct": 0.5191181965375514,
        "vocab_size-3-nopunct": 4168,
        "unique-3-nopunct": 3049,
        "entropy-3-nopunct": 11.323351091992931,
        "cond_entropy-3-nopunct": 0.9442087119224959,
        "msttr-100": 0.49561,
        "msttr-100_nopunct": 0.49787,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.17254273504273504,
            "2": 0.4450031426775613,
            "3": 0.6968171484248132,
            "4": 0.25,
            "5": 1.0
        },
        "nist": 4.537891353585666,
        "bleu": 34.38603,
        "rouge1": {
            "precision": 0.78151,
            "recall": 0.60655,
            "fmeasure": 0.66588
        },
        "rouge2": {
            "precision": 0.51133,
            "recall": 0.38911,
            "fmeasure": 0.42923
        },
        "rougeL": {
            "precision": 0.63422,
            "recall": 0.48675,
            "fmeasure": 0.53624
        },
        "rougeLsum": {
            "precision": 0.63422,
            "recall": 0.48675,
            "fmeasure": 0.53624
        },
        "nubia": {
            "semantic_relation": 3.87926,
            "contradiction": 9.20527,
            "irrelevancy": 11.44598,
            "logical_agreement": 79.34875,
            "grammar_ref": 4.37649,
            "grammar_hyp": 4.69115,
            "nubia_score": 0.58131
        },
        "meteor": 0.29345667091118627,
        "bleurt": -0.13176,
        "bertscore": {
            "precision": 0.91635,
            "recall": 0.88149,
            "f1": 0.89696
        }
    },
    "web_nlg_ru_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 354,
        "total_length": 4306,
        "mean_pred_length": 12.163841807909604,
        "std_pred_length": 2.2689859199472275,
        "median_pred_length": 12.0,
        "min_pred_length": 6,
        "max_pred_length": 20,
        "distinct-1": 0.2786809103576405,
        "vocab_size-1": 1200,
        "unique-1": 714,
        "entropy-1": 8.471974080528591,
        "distinct-2": 0.5490890688259109,
        "vocab_size-2": 2170,
        "unique-2": 1565,
        "entropy-2": 10.467426614418239,
        "cond_entropy-2": 2.1736671298925625,
        "distinct-3": 0.7117843246247916,
        "vocab_size-3": 2561,
        "unique-3": 2068,
        "entropy-3": 11.024007253709177,
        "cond_entropy-3": 0.6639962761877529,
        "total_length-nopunct": 3707,
        "mean_pred_length-nopunct": 10.471751412429379,
        "std_pred_length-nopunct": 1.8550720775162595,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.3220933369301322,
        "vocab_size-1-nopunct": 1194,
        "unique-1-nopunct": 714,
        "entropy-1-nopunct": 8.878034529734084,
        "distinct-2-nopunct": 0.5908141962421712,
        "vocab_size-2-nopunct": 1981,
        "unique-2-nopunct": 1488,
        "entropy-2-nopunct": 10.400537907753376,
        "cond_entropy-2-nopunct": 1.7065617078016362,
        "distinct-3-nopunct": 0.7299099699899967,
        "vocab_size-3-nopunct": 2189,
        "unique-3-nopunct": 1817,
        "entropy-3-nopunct": 10.795536504672466,
        "cond_entropy-3-nopunct": 0.514655947530706,
        "msttr-100": 0.75442,
        "msttr-100_nopunct": 0.81838,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.12755964681570542,
            "2": 0.3146964856230032,
            "3": 0.4349300551080966,
            "4": 0.5405405405405406,
            "5": 0.6818181818181818,
            "6": 0.0,
            "7": 1.0
        },
        "nist": 0.5152644974897784,
        "bleu": 15.58889,
        "rouge1": {
            "precision": 0.32183,
            "recall": 0.24348,
            "fmeasure": 0.26562
        },
        "rouge2": {
            "precision": 0.13456,
            "recall": 0.09159,
            "fmeasure": 0.10153
        },
        "rougeL": {
            "precision": 0.315,
            "recall": 0.23666,
            "fmeasure": 0.25889
        },
        "rougeLsum": {
            "precision": 0.315,
            "recall": 0.23666,
            "fmeasure": 0.25889
        },
        "nubia": {
            "semantic_relation": 3.38633,
            "contradiction": 22.83133,
            "irrelevancy": 22.95924,
            "logical_agreement": 54.20943,
            "grammar_ref": 2.54394,
            "grammar_hyp": 2.67566,
            "nubia_score": 0.64154
        },
        "meteor": 0.34050501847325176,
        "bleurt": 0.0089,
        "bertscore": {
            "precision": 0.94583,
            "recall": 0.89072,
            "f1": 0.91666
        }
    },
    "wiki_lingua_turkish_tr_test": {
        "predictions_file": "ByT5-base (Baseline)/wiki_lingua_turkish_tr_test",
        "N": 900,
        "total_length": 22281,
        "mean_pred_length": 24.756666666666668,
        "std_pred_length": 5.241046333192129,
        "median_pred_length": 26.0,
        "min_pred_length": 4,
        "max_pred_length": 36,
        "distinct-1": 0.13226515865535657,
        "vocab_size-1": 2947,
        "unique-1": 1352,
        "entropy-1": 8.405806835187422,
        "distinct-2": 0.47121275899162807,
        "vocab_size-2": 10075,
        "unique-2": 7162,
        "entropy-2": 12.222697804122589,
        "cond_entropy-2": 3.8450466541548307,
        "distinct-3": 0.7537229627459596,
        "vocab_size-3": 15437,
        "unique-3": 13288,
        "entropy-3": 13.541707562415462,
        "cond_entropy-3": 1.3644898506759608,
        "total_length-nopunct": 19196,
        "mean_pred_length-nopunct": 21.32888888888889,
        "std_pred_length-nopunct": 4.774311921207878,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.15274015419879142,
        "vocab_size-1-nopunct": 2932,
        "unique-1-nopunct": 1347,
        "entropy-1-nopunct": 9.026001961017842,
        "distinct-2-nopunct": 0.5789790118058592,
        "vocab_size-2-nopunct": 10593,
        "unique-2-nopunct": 8182,
        "entropy-2-nopunct": 12.619849588687744,
        "cond_entropy-2-nopunct": 3.7000676235053,
        "distinct-3-nopunct": 0.8455966888939986,
        "vocab_size-3-nopunct": 14710,
        "unique-3-nopunct": 13270,
        "entropy-3-nopunct": 13.658742667928225,
        "cond_entropy-3-nopunct": 1.0828650087706142,
        "msttr-100": 0.61144,
        "msttr-100_nopunct": 0.68094,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_test.json",
        "local_recall": {
            "1": 0.29336400956376596
        },
        "nist": 1.85730849049632,
        "bleu": 11.35085,
        "rouge1": {
            "precision": 0.45954,
            "recall": 0.32593,
            "fmeasure": 0.35854
        },
        "rouge2": {
            "precision": 0.20826,
            "recall": 0.14036,
            "fmeasure": 0.15789
        },
        "rougeL": {
            "precision": 0.38076,
            "recall": 0.27219,
            "fmeasure": 0.2982
        },
        "rougeLsum": {
            "precision": 0.38076,
            "recall": 0.27219,
            "fmeasure": 0.2982
        },
        "sari": 67.68535,
        "nubia": {
            "semantic_relation": 2.61683,
            "contradiction": 24.60995,
            "irrelevancy": 43.49327,
            "logical_agreement": 31.89678,
            "grammar_ref": 3.87672,
            "grammar_hyp": 4.26011,
            "nubia_score": 0.29148
        },
        "meteor": 0.14766169729059866,
        "bleurt": -0.54645,
        "bertscore": {
            "precision": 0.85455,
            "recall": 0.83316,
            "f1": 0.84322
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_20": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 119,
        "mean_pred_length": 23.8,
        "std_pred_length": 5.114684741017769,
        "median_pred_length": 27.0,
        "min_pred_length": 15,
        "max_pred_length": 28,
        "distinct-1": 0.6890756302521008,
        "vocab_size-1": 82,
        "unique-1": 69,
        "entropy-1": 5.962936645748439,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 108,
        "unique-2": 102,
        "entropy-2": 6.727626856270016,
        "cond_entropy-2": 0.7741151498818832,
        "distinct-3": 0.9908256880733946,
        "vocab_size-3": 108,
        "unique-3": 107,
        "entropy-3": 6.749835700923704,
        "cond_entropy-3": 0.027037429878239365,
        "total_length-nopunct": 99,
        "mean_pred_length-nopunct": 19.8,
        "std_pred_length-nopunct": 3.919183588453085,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 77,
        "unique-1-nopunct": 68,
        "entropy-1-nopunct": 6.032190807162811,
        "distinct-2-nopunct": 0.9680851063829787,
        "vocab_size-2-nopunct": 91,
        "unique-2-nopunct": 88,
        "entropy-2-nopunct": 6.490759064443582,
        "cond_entropy-2-nopunct": 0.4903323962657279,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 89,
        "unique-3-nopunct": 89,
        "entropy-3-nopunct": 6.47573343096641,
        "cond_entropy-3-nopunct": -0.011439690374160845,
        "msttr-100": 0.66,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.3125,
            "3": 0.5802469135802469
        },
        "nist": 2.6504655051996004,
        "bleu": 23.17405,
        "rouge1": {
            "precision": 0.69085,
            "recall": 0.51047,
            "fmeasure": 0.57478
        },
        "rouge2": {
            "precision": 0.37435,
            "recall": 0.29062,
            "fmeasure": 0.32037
        },
        "rougeL": {
            "precision": 0.55588,
            "recall": 0.4274,
            "fmeasure": 0.47323
        },
        "rougeLsum": {
            "precision": 0.55588,
            "recall": 0.4274,
            "fmeasure": 0.47323
        },
        "nubia": {
            "semantic_relation": 3.13701,
            "contradiction": 26.32564,
            "irrelevancy": 28.01936,
            "logical_agreement": 45.65501,
            "grammar_ref": 4.13756,
            "grammar_hyp": 4.58254,
            "nubia_score": 0.38939
        },
        "meteor": 0.25227576401415314,
        "bleurt": -0.30834,
        "bertscore": {
            "precision": 0.90285,
            "recall": 0.85854,
            "f1": 0.87909
        }
    },
    "schema_guided_dialog_challenge_test_nopunc_parent": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6637,
        "mean_pred_length": 13.274,
        "std_pred_length": 6.836879697639852,
        "median_pred_length": 12.0,
        "min_pred_length": 1,
        "max_pred_length": 33,
        "distinct-1": 0.16362814524634625,
        "vocab_size-1": 1086,
        "unique-1": 614,
        "entropy-1": 7.945233376010623,
        "distinct-2": 0.5087176144696106,
        "vocab_size-2": 3122,
        "unique-2": 2244,
        "entropy-2": 10.861778898288831,
        "cond_entropy-2": 2.714121741356677,
        "distinct-3": 0.7316424263923377,
        "vocab_size-3": 4125,
        "unique-3": 3448,
        "entropy-3": 11.679474043773697,
        "cond_entropy-3": 0.8378400942435758,
        "total_length-nopunct": 5859,
        "mean_pred_length-nopunct": 11.718,
        "std_pred_length-nopunct": 6.385176270080569,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.18313705410479603,
        "vocab_size-1-nopunct": 1073,
        "unique-1-nopunct": 611,
        "entropy-1-nopunct": 8.12517587884771,
        "distinct-2-nopunct": 0.525657771972383,
        "vocab_size-2-nopunct": 2817,
        "unique-2-nopunct": 2074,
        "entropy-2-nopunct": 10.7088830800221,
        "cond_entropy-2-nopunct": 2.7139626705738378,
        "distinct-3-nopunct": 0.7432098765432099,
        "vocab_size-3-nopunct": 3612,
        "unique-3-nopunct": 3063,
        "entropy-3-nopunct": 11.486013524175629,
        "cond_entropy-3-nopunct": 0.8090769075229453,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.72707,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5581587196832206
        },
        "nist": 6.172954209937336,
        "bleu": 31.9114,
        "rouge1": {
            "precision": 0.58548,
            "recall": 0.54408,
            "fmeasure": 0.55266
        },
        "rouge2": {
            "precision": 0.36087,
            "recall": 0.33438,
            "fmeasure": 0.33972
        },
        "rougeL": {
            "precision": 0.52047,
            "recall": 0.48517,
            "fmeasure": 0.49212
        },
        "rougeLsum": {
            "precision": 0.52047,
            "recall": 0.48517,
            "fmeasure": 0.49212
        },
        "nubia": {
            "semantic_relation": 3.67353,
            "contradiction": 6.09496,
            "irrelevancy": 22.16891,
            "logical_agreement": 71.73613,
            "grammar_ref": 4.79983,
            "grammar_hyp": 4.67673,
            "nubia_score": 0.64387
        },
        "meteor": 0.3134249142171666,
        "bleurt": -0.08466,
        "bertscore": {
            "precision": 0.87253,
            "recall": 0.86248,
            "f1": 0.86702
        }
    },
    "wiki_lingua_vietnamese_vi_validation": {
        "predictions_file": "ByT5-base (Baseline)/wiki_lingua_vietnamese_vi_validation",
        "N": 1957,
        "total_length": 47550,
        "mean_pred_length": 24.2973939703628,
        "std_pred_length": 4.7001514837267715,
        "median_pred_length": 25.0,
        "min_pred_length": 4,
        "max_pred_length": 36,
        "distinct-1": 0.10443743427970557,
        "vocab_size-1": 4966,
        "unique-1": 2243,
        "entropy-1": 8.754703650631892,
        "distinct-2": 0.4343649244401553,
        "vocab_size-2": 19804,
        "unique-2": 14119,
        "entropy-2": 13.09716242798067,
        "cond_entropy-2": 4.35829578634892,
        "distinct-3": 0.762214685122376,
        "vocab_size-3": 33260,
        "unique-3": 29037,
        "entropy-3": 14.66254676532174,
        "cond_entropy-3": 1.6113522452395341,
        "total_length-nopunct": 40882,
        "mean_pred_length-nopunct": 20.89013796627491,
        "std_pred_length-nopunct": 4.456419279701954,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.1211535639156597,
        "vocab_size-1-nopunct": 4953,
        "unique-1-nopunct": 2240,
        "entropy-1-nopunct": 9.4567892329891,
        "distinct-2-nopunct": 0.5632883750802826,
        "vocab_size-2-nopunct": 21926,
        "unique-2-nopunct": 17295,
        "entropy-2-nopunct": 13.561678781104941,
        "cond_entropy-2-nopunct": 4.227750549562869,
        "distinct-3-nopunct": 0.862610906730145,
        "vocab_size-3-nopunct": 31889,
        "unique-3-nopunct": 29282,
        "entropy-3-nopunct": 14.785281016822337,
        "cond_entropy-3-nopunct": 1.2731774216402219,
        "msttr-100": 0.64002,
        "msttr-100_nopunct": 0.71564,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_validation.json",
        "local_recall": {
            "1": 0.2508513519057974
        },
        "nist": 1.818185189751345,
        "bleu": 7.62952,
        "rouge1": {
            "precision": 0.39431,
            "recall": 0.28705,
            "fmeasure": 0.31435
        },
        "rouge2": {
            "precision": 0.13983,
            "recall": 0.0996,
            "fmeasure": 0.10983
        },
        "rougeL": {
            "precision": 0.31687,
            "recall": 0.23303,
            "fmeasure": 0.25383
        },
        "rougeLsum": {
            "precision": 0.31687,
            "recall": 0.23303,
            "fmeasure": 0.25383
        },
        "sari": 66.59372,
        "nubia": {
            "semantic_relation": 2.496,
            "contradiction": 19.68429,
            "irrelevancy": 47.93212,
            "logical_agreement": 32.38359,
            "grammar_ref": 3.90718,
            "grammar_hyp": 4.23452,
            "nubia_score": 0.28076
        },
        "meteor": 0.13196675794205556,
        "bleurt": -0.51816,
        "bertscore": {
            "precision": 0.84388,
            "recall": 0.82472,
            "f1": 0.83372
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_challenge_test_asset_backtranslation",
        "N": 359,
        "total_length": 5521,
        "mean_pred_length": 15.37883008356546,
        "std_pred_length": 6.113248571917195,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.38036587574714725,
        "vocab_size-1": 2100,
        "unique-1": 1600,
        "entropy-1": 8.892296223450618,
        "distinct-2": 0.831654397520341,
        "vocab_size-2": 4293,
        "unique-2": 3972,
        "entropy-2": 11.731324898901713,
        "cond_entropy-2": 2.569633673231358,
        "distinct-3": 0.9564855298771601,
        "vocab_size-3": 4594,
        "unique-3": 4523,
        "entropy-3": 12.056549720563556,
        "cond_entropy-3": 0.35569909306271175,
        "total_length-nopunct": 4891,
        "mean_pred_length-nopunct": 13.623955431754874,
        "std_pred_length-nopunct": 5.461497030500856,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.42711102024125946,
        "vocab_size-1-nopunct": 2089,
        "unique-1-nopunct": 1598,
        "entropy-1-nopunct": 9.215686845779352,
        "distinct-2-nopunct": 0.8598852603706972,
        "vocab_size-2-nopunct": 3897,
        "unique-2-nopunct": 3627,
        "entropy-2-nopunct": 11.693094827647707,
        "cond_entropy-2-nopunct": 2.64590285298339,
        "distinct-3-nopunct": 0.9825065899832255,
        "vocab_size-3-nopunct": 4100,
        "unique-3-nopunct": 4046,
        "entropy-3-nopunct": 11.987291319930709,
        "cond_entropy-3-nopunct": 0.32566160963683294,
        "msttr-100": 0.72055,
        "msttr-100_nopunct": 0.76208,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_backtranslation.json",
        "local_recall": {
            "1": 0.04792270531400966,
            "2": 0.11469780219780219,
            "3": 0.19343493552168817,
            "4": 0.2790368271954674,
            "5": 0.33067729083665337,
            "6": 0.39039408866995073,
            "7": 0.454337899543379,
            "8": 0.5793650793650794,
            "9": 0.6992805755395683
        },
        "nist": 7.442467574689095,
        "bleu": 38.79046,
        "rouge1": {
            "precision": 0.67694,
            "recall": 0.58623,
            "fmeasure": 0.61469
        },
        "rouge2": {
            "precision": 0.44108,
            "recall": 0.3832,
            "fmeasure": 0.39633
        },
        "rougeL": {
            "precision": 0.61781,
            "recall": 0.54699,
            "fmeasure": 0.56656
        },
        "rougeLsum": {
            "precision": 0.61781,
            "recall": 0.54699,
            "fmeasure": 0.56656
        },
        "sari": 42.46791,
        "nubia": {
            "semantic_relation": 3.26878,
            "contradiction": 13.81851,
            "irrelevancy": 32.91507,
            "logical_agreement": 53.26642,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.25516,
            "nubia_score": 0.4242
        },
        "meteor": 0.30470824234894645,
        "bleurt": -0.25689,
        "bertscore": {
            "precision": 0.9007,
            "recall": 0.88869,
            "f1": 0.88981
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform": {
        "predictions_file": "ByT5-base (Baseline)/cs_restaurants_test",
        "N": 609,
        "total_length": 6619,
        "mean_pred_length": 10.86863711001642,
        "std_pred_length": 3.9974316403017545,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 23,
        "distinct-1": 0.09185677594802841,
        "vocab_size-1": 608,
        "unique-1": 227,
        "entropy-1": 6.937071834589991,
        "distinct-2": 0.2753743760399334,
        "vocab_size-2": 1655,
        "unique-2": 900,
        "entropy-2": 9.277354013721766,
        "cond_entropy-2": 2.070631962593634,
        "distinct-3": 0.4491760785039807,
        "vocab_size-3": 2426,
        "unique-3": 1721,
        "entropy-3": 10.164861939528883,
        "cond_entropy-3": 0.9990260243154093,
        "total_length-nopunct": 5804,
        "mean_pred_length-nopunct": 9.530377668308702,
        "std_pred_length-nopunct": 3.5732283180204516,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.10406616126809097,
        "vocab_size-1-nopunct": 604,
        "unique-1-nopunct": 226,
        "entropy-1-nopunct": 7.157837247619336,
        "distinct-2-nopunct": 0.27564966313763234,
        "vocab_size-2-nopunct": 1432,
        "unique-2-nopunct": 802,
        "entropy-2-nopunct": 9.043934743977626,
        "cond_entropy-2-nopunct": 2.155652414431048,
        "distinct-3-nopunct": 0.4555167902311382,
        "vocab_size-3-nopunct": 2089,
        "unique-3-nopunct": 1518,
        "entropy-3-nopunct": 9.941410312811108,
        "cond_entropy-3-nopunct": 1.091568478485189,
        "msttr-100": 0.595,
        "msttr-100_nopunct": 0.62707,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.5102077045979052
        },
        "nist": 4.44888561835173,
        "bleu": 19.83068,
        "rouge1": {
            "precision": 0.57569,
            "recall": 0.56723,
            "fmeasure": 0.55934
        },
        "rouge2": {
            "precision": 0.32456,
            "recall": 0.32273,
            "fmeasure": 0.31667
        },
        "rougeL": {
            "precision": 0.50772,
            "recall": 0.50041,
            "fmeasure": 0.49378
        },
        "rougeLsum": {
            "precision": 0.50772,
            "recall": 0.50041,
            "fmeasure": 0.49378
        },
        "nubia": {
            "semantic_relation": 3.60416,
            "contradiction": 14.75122,
            "irrelevancy": 33.62468,
            "logical_agreement": 51.62409,
            "grammar_ref": 6.96179,
            "grammar_hyp": 6.89804,
            "nubia_score": 0.56663
        },
        "meteor": 0.25668952142422063,
        "bleurt": -0.06101,
        "bertscore": {
            "precision": 0.90682,
            "recall": 0.90614,
            "f1": 0.90627
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-base (Baseline)/e2e_nlg_test",
        "N": 5,
        "total_length": 72,
        "mean_pred_length": 14.4,
        "std_pred_length": 2.244994432064365,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 18,
        "distinct-1": 0.5,
        "vocab_size-1": 36,
        "unique-1": 17,
        "entropy-1": 4.885154258886506,
        "distinct-2": 0.7164179104477612,
        "vocab_size-2": 48,
        "unique-2": 31,
        "entropy-2": 5.4763910560648315,
        "cond_entropy-2": 0.5138369947655219,
        "distinct-3": 0.7741935483870968,
        "vocab_size-3": 48,
        "unique-3": 34,
        "entropy-3": 5.502583407161075,
        "cond_entropy-3": 0.041490587740827596,
        "total_length-nopunct": 66,
        "mean_pred_length-nopunct": 13.2,
        "std_pred_length-nopunct": 1.9390719429665315,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.5151515151515151,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.818729680122381,
        "distinct-2-nopunct": 0.7049180327868853,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 5.3158229932296575,
        "cond_entropy-2-nopunct": 0.5647707261594189,
        "distinct-3-nopunct": 0.7678571428571429,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 5.343069207771895,
        "cond_entropy-3-nopunct": 0.04643499528627043,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.5
        },
        "nist": 2.3380261252709826,
        "bleu": 11.76303,
        "rouge1": {
            "precision": 0.45657,
            "recall": 0.50535,
            "fmeasure": 0.45622
        },
        "rouge2": {
            "precision": 0.19761,
            "recall": 0.21818,
            "fmeasure": 0.19392
        },
        "rougeL": {
            "precision": 0.39901,
            "recall": 0.44977,
            "fmeasure": 0.40037
        },
        "rougeLsum": {
            "precision": 0.39901,
            "recall": 0.44977,
            "fmeasure": 0.40037
        },
        "nubia": {
            "semantic_relation": 3.11852,
            "contradiction": 0.08566,
            "irrelevancy": 42.82184,
            "logical_agreement": 57.09249,
            "grammar_ref": 5.06674,
            "grammar_hyp": 4.79553,
            "nubia_score": 0.49681
        },
        "meteor": 0.23473180137243443,
        "bleurt": -0.25671,
        "bertscore": {
            "precision": 0.86165,
            "recall": 0.86385,
            "f1": 0.86235
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?confirm": {
        "predictions_file": "ByT5-base (Baseline)/cs_restaurants_test",
        "N": 22,
        "total_length": 229,
        "mean_pred_length": 10.409090909090908,
        "std_pred_length": 2.480085975582498,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 14,
        "distinct-1": 0.10480349344978165,
        "vocab_size-1": 24,
        "unique-1": 0,
        "entropy-1": 4.227921671097431,
        "distinct-2": 0.13526570048309178,
        "vocab_size-2": 28,
        "unique-2": 0,
        "entropy-2": 4.459912085269145,
        "cond_entropy-2": 0.14184892124402473,
        "distinct-3": 0.14594594594594595,
        "vocab_size-3": 27,
        "unique-3": 0,
        "entropy-3": 4.4014909993174856,
        "cond_entropy-3": 0.005656939312774056,
        "total_length-nopunct": 186,
        "mean_pred_length-nopunct": 8.454545454545455,
        "std_pred_length-nopunct": 2.0610516452281153,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.11827956989247312,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 4.116376857857957,
        "distinct-2-nopunct": 0.13414634146341464,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 4.141971740709088,
        "cond_entropy-2-nopunct": 0.12325945880453006,
        "distinct-3-nopunct": 0.14788732394366197,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 4.05792054516307,
        "cond_entropy-3-nopunct": -0.003357158286486679,
        "msttr-100": 0.215,
        "msttr-100_nopunct": 0.22,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.4114285714285714
        },
        "nist": 2.404235708483786,
        "bleu": 27.90808,
        "rouge1": {
            "precision": 0.47635,
            "recall": 0.49599,
            "fmeasure": 0.48104
        },
        "rouge2": {
            "precision": 0.31905,
            "recall": 0.3239,
            "fmeasure": 0.31812
        },
        "rougeL": {
            "precision": 0.45666,
            "recall": 0.47508,
            "fmeasure": 0.46097
        },
        "rougeLsum": {
            "precision": 0.45666,
            "recall": 0.47508,
            "fmeasure": 0.46097
        },
        "nubia": {
            "semantic_relation": 2.94573,
            "contradiction": 24.16791,
            "irrelevancy": 25.76543,
            "logical_agreement": 50.06667,
            "grammar_ref": 6.09546,
            "grammar_hyp": 6.30646,
            "nubia_score": 0.3904
        },
        "meteor": 0.22325627256399455,
        "bleurt": -0.10798,
        "bertscore": {
            "precision": 0.90793,
            "recall": 0.9116,
            "f1": 0.90969
        }
    },
    "schema_guided_dialog_challenge_test_scramble_parent": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6452,
        "mean_pred_length": 12.904,
        "std_pred_length": 6.48002962956189,
        "median_pred_length": 12.0,
        "min_pred_length": 3,
        "max_pred_length": 31,
        "distinct-1": 0.15933044017358958,
        "vocab_size-1": 1028,
        "unique-1": 571,
        "entropy-1": 7.836715174062347,
        "distinct-2": 0.4986559139784946,
        "vocab_size-2": 2968,
        "unique-2": 2072,
        "entropy-2": 10.81256581592999,
        "cond_entropy-2": 2.7561000173836,
        "distinct-3": 0.7338591342626559,
        "vocab_size-3": 4001,
        "unique-3": 3307,
        "entropy-3": 11.653604084295479,
        "cond_entropy-3": 0.8685843643383052,
        "total_length-nopunct": 5680,
        "mean_pred_length-nopunct": 11.36,
        "std_pred_length-nopunct": 6.054287736802737,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.1790492957746479,
        "vocab_size-1-nopunct": 1017,
        "unique-1-nopunct": 569,
        "entropy-1-nopunct": 8.023721649143585,
        "distinct-2-nopunct": 0.5142857142857142,
        "vocab_size-2-nopunct": 2664,
        "unique-2-nopunct": 1900,
        "entropy-2-nopunct": 10.643142717399522,
        "cond_entropy-2-nopunct": 2.7668221414877454,
        "distinct-3-nopunct": 0.7455128205128205,
        "vocab_size-3-nopunct": 3489,
        "unique-3-nopunct": 2933,
        "entropy-3-nopunct": 11.449796946409343,
        "cond_entropy-3-nopunct": 0.8632929942286515,
        "msttr-100": 0.69203,
        "msttr-100_nopunct": 0.7225,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5584236792290483
        },
        "nist": 6.081498102798947,
        "bleu": 30.91422,
        "rouge1": {
            "precision": 0.57435,
            "recall": 0.54511,
            "fmeasure": 0.54919
        },
        "rouge2": {
            "precision": 0.35141,
            "recall": 0.33113,
            "fmeasure": 0.33424
        },
        "rougeL": {
            "precision": 0.51133,
            "recall": 0.4861,
            "fmeasure": 0.48916
        },
        "rougeLsum": {
            "precision": 0.51133,
            "recall": 0.4861,
            "fmeasure": 0.48916
        },
        "nubia": {
            "semantic_relation": 3.54519,
            "contradiction": 7.03643,
            "irrelevancy": 23.17538,
            "logical_agreement": 69.78819,
            "grammar_ref": 4.7801,
            "grammar_hyp": 4.70144,
            "nubia_score": 0.61566
        },
        "meteor": 0.30732551898164445,
        "bleurt": -0.13731,
        "bertscore": {
            "precision": 0.86784,
            "recall": 0.86084,
            "f1": 0.8639
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_only_match": {
        "predictions_file": "ByT5-base (Baseline)/cs_restaurants_test",
        "N": 16,
        "total_length": 297,
        "mean_pred_length": 18.5625,
        "std_pred_length": 3.4635377506243525,
        "median_pred_length": 19.5,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.2727272727272727,
        "vocab_size-1": 81,
        "unique-1": 39,
        "entropy-1": 5.49065726179645,
        "distinct-2": 0.46619217081850534,
        "vocab_size-2": 131,
        "unique-2": 84,
        "entropy-2": 6.464259264118158,
        "cond_entropy-2": 0.9738347792627171,
        "distinct-3": 0.569811320754717,
        "vocab_size-3": 151,
        "unique-3": 108,
        "entropy-3": 6.7992424554054605,
        "cond_entropy-3": 0.4015713320442892,
        "total_length-nopunct": 259,
        "mean_pred_length-nopunct": 16.1875,
        "std_pred_length-nopunct": 3.3395125018481364,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.30115830115830117,
        "vocab_size-1-nopunct": 78,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.512320289047145,
        "distinct-2-nopunct": 0.48559670781893005,
        "vocab_size-2-nopunct": 118,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 6.354572434457528,
        "cond_entropy-2-nopunct": 0.9412711971561051,
        "distinct-3-nopunct": 0.5947136563876652,
        "vocab_size-3-nopunct": 135,
        "unique-3-nopunct": 99,
        "entropy-3-nopunct": 6.680617199155226,
        "cond_entropy-3-nopunct": 0.3754586435997404,
        "msttr-100": 0.44,
        "msttr-100_nopunct": 0.455,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.4777327935222672
        },
        "nist": 3.0394732293233173,
        "bleu": 17.11715,
        "rouge1": {
            "precision": 0.53321,
            "recall": 0.55102,
            "fmeasure": 0.53099
        },
        "rouge2": {
            "precision": 0.2835,
            "recall": 0.30482,
            "fmeasure": 0.28644
        },
        "rougeL": {
            "precision": 0.40792,
            "recall": 0.43037,
            "fmeasure": 0.40945
        },
        "rougeLsum": {
            "precision": 0.40792,
            "recall": 0.43037,
            "fmeasure": 0.40945
        },
        "nubia": {
            "semantic_relation": 3.25799,
            "contradiction": 26.90749,
            "irrelevancy": 29.88257,
            "logical_agreement": 43.20994,
            "grammar_ref": 5.92126,
            "grammar_hyp": 5.99334,
            "nubia_score": 0.48855
        },
        "meteor": 0.2407270952695524,
        "bleurt": -0.07837,
        "bertscore": {
            "precision": 0.90687,
            "recall": 0.912,
            "f1": 0.90935
        }
    },
    "xsum_challenge_test_backtranslation_parent": {
        "predictions_file": "ByT5-base (Baseline)/xsum_test",
        "N": 500,
        "total_length": 10682,
        "mean_pred_length": 21.364,
        "std_pred_length": 3.4367868714833048,
        "median_pred_length": 22.0,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.27073581726268486,
        "vocab_size-1": 2892,
        "unique-1": 1840,
        "entropy-1": 9.12176479539065,
        "distinct-2": 0.7323708505205264,
        "vocab_size-2": 7457,
        "unique-2": 6453,
        "entropy-2": 12.380937577206044,
        "cond_entropy-2": 3.1857895164004124,
        "distinct-3": 0.9300764304895682,
        "vocab_size-3": 9005,
        "unique-3": 8597,
        "entropy-3": 13.059611314267276,
        "cond_entropy-3": 0.6987575216977235,
        "total_length-nopunct": 10160,
        "mean_pred_length-nopunct": 20.32,
        "std_pred_length-nopunct": 3.586864926366757,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.28356299212598424,
        "vocab_size-1-nopunct": 2881,
        "unique-1-nopunct": 1838,
        "entropy-1-nopunct": 9.2075559931255,
        "distinct-2-nopunct": 0.7366459627329193,
        "vocab_size-2-nopunct": 7116,
        "unique-2-nopunct": 6185,
        "entropy-2-nopunct": 12.317097838657869,
        "cond_entropy-2-nopunct": 3.224614866848749,
        "distinct-3-nopunct": 0.9348253275109171,
        "vocab_size-3-nopunct": 8563,
        "unique-3-nopunct": 8186,
        "entropy-3-nopunct": 12.999464832214732,
        "cond_entropy-3-nopunct": 0.7027782495407264,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.74941,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.34832709996967554
        },
        "nist": 3.5134307570034258,
        "bleu": 9.10588,
        "rouge1": {
            "precision": 0.3904,
            "recall": 0.38129,
            "fmeasure": 0.37918
        },
        "rouge2": {
            "precision": 0.14657,
            "recall": 0.14332,
            "fmeasure": 0.1423
        },
        "rougeL": {
            "precision": 0.30133,
            "recall": 0.29447,
            "fmeasure": 0.29263
        },
        "rougeLsum": {
            "precision": 0.30133,
            "recall": 0.29447,
            "fmeasure": 0.29263
        },
        "nubia": {
            "semantic_relation": 2.7098,
            "contradiction": 26.38388,
            "irrelevancy": 63.50213,
            "logical_agreement": 10.11398,
            "grammar_ref": 3.78538,
            "grammar_hyp": 4.10882,
            "nubia_score": 0.34961
        },
        "meteor": 0.16212101649441732,
        "bleurt": -0.45092,
        "bertscore": {
            "precision": 0.82351,
            "recall": 0.8188,
            "f1": 0.82083
        }
    },
    "e2e_nlg_challenge_test_scramble": {
        "predictions_file": "ByT5-base (Baseline)/e2e_nlg_challenge_test_scramble",
        "N": 500,
        "total_length": 11301,
        "mean_pred_length": 22.602,
        "std_pred_length": 3.7271431418715326,
        "median_pred_length": 23.0,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.03203256348995664,
        "vocab_size-1": 362,
        "unique-1": 133,
        "entropy-1": 6.19669706085993,
        "distinct-2": 0.121099898157578,
        "vocab_size-2": 1308,
        "unique-2": 643,
        "entropy-2": 8.37204103852237,
        "cond_entropy-2": 2.2248833191634425,
        "distinct-3": 0.24094748082710415,
        "vocab_size-3": 2482,
        "unique-3": 1421,
        "entropy-3": 9.75644974120657,
        "cond_entropy-3": 1.4657569243723094,
        "total_length-nopunct": 10616,
        "mean_pred_length-nopunct": 21.232,
        "std_pred_length-nopunct": 3.737134731314888,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.03372268274302939,
        "vocab_size-1-nopunct": 358,
        "unique-1-nopunct": 131,
        "entropy-1-nopunct": 6.202811241946322,
        "distinct-2-nopunct": 0.12613681296955317,
        "vocab_size-2-nopunct": 1276,
        "unique-2-nopunct": 645,
        "entropy-2-nopunct": 8.351233171998986,
        "cond_entropy-2-nopunct": 2.266026211718244,
        "distinct-3-nopunct": 0.24948003327787022,
        "vocab_size-3-nopunct": 2399,
        "unique-3-nopunct": 1381,
        "entropy-3-nopunct": 9.768868745405264,
        "cond_entropy-3-nopunct": 1.4847638134938739,
        "msttr-100": 0.52168,
        "msttr-100_nopunct": 0.5184,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.6233609225332465
        },
        "nist": 4.5583836157061794,
        "bleu": 24.21825,
        "rouge1": {
            "precision": 0.71045,
            "recall": 0.63872,
            "fmeasure": 0.6618
        },
        "rouge2": {
            "precision": 0.40249,
            "recall": 0.36012,
            "fmeasure": 0.37382
        },
        "rougeL": {
            "precision": 0.49572,
            "recall": 0.44726,
            "fmeasure": 0.46255
        },
        "rougeLsum": {
            "precision": 0.49572,
            "recall": 0.44726,
            "fmeasure": 0.46255
        },
        "nubia": {
            "semantic_relation": 3.9853,
            "contradiction": 5.12361,
            "irrelevancy": 28.93312,
            "logical_agreement": 65.94327,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.76283,
            "nubia_score": 0.65842
        },
        "meteor": 0.31701739749313396,
        "bleurt": -0.03086,
        "bertscore": {
            "precision": 0.90227,
            "recall": 0.88629,
            "f1": 0.89387
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_125": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 14,
        "unique-1": 11,
        "entropy-1": 3.68354236243323,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.43253122228823104,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7647058823529411,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.572469458770136,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.45971762763487756,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "nist": 1.1729520220840473,
        "bleu": 5.75139,
        "rouge1": {
            "precision": 0.23529,
            "recall": 0.28356,
            "fmeasure": 0.25621
        },
        "rouge2": {
            "precision": 0.0625,
            "recall": 0.07639,
            "fmeasure": 0.06845
        },
        "rougeL": {
            "precision": 0.21569,
            "recall": 0.23379,
            "fmeasure": 0.22353
        },
        "rougeLsum": {
            "precision": 0.21569,
            "recall": 0.23379,
            "fmeasure": 0.22353
        },
        "nubia": {
            "semantic_relation": 1.31376,
            "contradiction": 22.12994,
            "irrelevancy": 76.12684,
            "logical_agreement": 1.74322,
            "grammar_ref": 4.12033,
            "grammar_hyp": 3.32162,
            "nubia_score": 0.13504
        },
        "meteor": 0.1189948230202452,
        "bleurt": -0.50823,
        "bertscore": {
            "precision": 0.68034,
            "recall": 0.68077,
            "f1": 0.68053
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_challenge_test_asset_bfp02",
        "N": 359,
        "total_length": 5578,
        "mean_pred_length": 15.537604456824512,
        "std_pred_length": 6.259753913091092,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.39888849049838654,
        "vocab_size-1": 2225,
        "unique-1": 1749,
        "entropy-1": 9.02058203953411,
        "distinct-2": 0.8428817781184135,
        "vocab_size-2": 4399,
        "unique-2": 4100,
        "entropy-2": 11.788175912262334,
        "cond_entropy-2": 2.4965752593791355,
        "distinct-3": 0.9594650205761317,
        "vocab_size-3": 4663,
        "unique-3": 4583,
        "entropy-3": 12.093428196652294,
        "cond_entropy-3": 0.3310632791899647,
        "total_length-nopunct": 4971,
        "mean_pred_length-nopunct": 13.846796657381615,
        "std_pred_length-nopunct": 5.66830945506938,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.44538322269161135,
        "vocab_size-1-nopunct": 2214,
        "unique-1-nopunct": 1745,
        "entropy-1-nopunct": 9.340014344057074,
        "distinct-2-nopunct": 0.8657849089332177,
        "vocab_size-2-nopunct": 3993,
        "unique-2-nopunct": 3735,
        "entropy-2-nopunct": 11.7346009073696,
        "cond_entropy-2-nopunct": 2.560859978321028,
        "distinct-3-nopunct": 0.9826005172819187,
        "vocab_size-3-nopunct": 4179,
        "unique-3-nopunct": 4118,
        "entropy-3-nopunct": 12.016812938234835,
        "cond_entropy-3-nopunct": 0.309359346125288,
        "msttr-100": 0.73273,
        "msttr-100_nopunct": 0.77469,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp02.json",
        "local_recall": {
            "1": 0.041932367149758454,
            "2": 0.13942307692307693,
            "3": 0.22860492379835873,
            "4": 0.3286118980169972,
            "5": 0.4037184594953519,
            "6": 0.4458128078817734,
            "7": 0.5490867579908676,
            "8": 0.6339285714285714,
            "9": 0.7503597122302158
        },
        "nist": 8.725821371108403,
        "bleu": 49.57038,
        "rouge1": {
            "precision": 0.73528,
            "recall": 0.64682,
            "fmeasure": 0.6724
        },
        "rouge2": {
            "precision": 0.52871,
            "recall": 0.46101,
            "fmeasure": 0.47614
        },
        "rougeL": {
            "precision": 0.69316,
            "recall": 0.61789,
            "fmeasure": 0.63734
        },
        "rougeLsum": {
            "precision": 0.69316,
            "recall": 0.61789,
            "fmeasure": 0.63734
        },
        "sari": 44.43405,
        "nubia": {
            "semantic_relation": 3.63407,
            "contradiction": 7.78268,
            "irrelevancy": 26.42804,
            "logical_agreement": 65.78928,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.70015,
            "nubia_score": 0.45395
        },
        "meteor": 0.33565616041784946,
        "bleurt": -0.38186,
        "bertscore": {
            "precision": 0.90521,
            "recall": 0.90544,
            "f1": 0.89994
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_127": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9
        },
        "nist": 3.5326561416927635,
        "bleu": 57.72609,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.8022,
            "fmeasure": 0.84308
        },
        "rouge2": {
            "precision": 0.69697,
            "recall": 0.62393,
            "fmeasure": 0.65821
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.8022,
            "fmeasure": 0.84308
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.8022,
            "fmeasure": 0.84308
        },
        "nubia": {
            "semantic_relation": 3.04666,
            "contradiction": 44.20208,
            "irrelevancy": 26.99999,
            "logical_agreement": 28.79794,
            "grammar_ref": 4.48671,
            "grammar_hyp": 4.07927,
            "nubia_score": 0.41224
        },
        "meteor": 0.46990451422352364,
        "bleurt": 0.44898,
        "bertscore": {
            "precision": 0.99041,
            "recall": 0.97937,
            "f1": 0.98486
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_no_match": {
        "predictions_file": "ByT5-base (Baseline)/cs_restaurants_test",
        "N": 34,
        "total_length": 345,
        "mean_pred_length": 10.147058823529411,
        "std_pred_length": 2.8710763808674766,
        "median_pred_length": 9.0,
        "min_pred_length": 7,
        "max_pred_length": 18,
        "distinct-1": 0.28405797101449276,
        "vocab_size-1": 98,
        "unique-1": 42,
        "entropy-1": 5.868418064139843,
        "distinct-2": 0.5337620578778135,
        "vocab_size-2": 166,
        "unique-2": 98,
        "entropy-2": 6.998216840030384,
        "cond_entropy-2": 0.8838959143958303,
        "distinct-3": 0.6642599277978339,
        "vocab_size-3": 184,
        "unique-3": 127,
        "entropy-3": 7.2813651803802975,
        "cond_entropy-3": 0.18023750888763923,
        "total_length-nopunct": 304,
        "mean_pred_length-nopunct": 8.941176470588236,
        "std_pred_length-nopunct": 2.6561933893825027,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.3157894736842105,
        "vocab_size-1-nopunct": 96,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.960517733235102,
        "distinct-2-nopunct": 0.5481481481481482,
        "vocab_size-2-nopunct": 148,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.894403140316061,
        "cond_entropy-2-nopunct": 0.8656828402388878,
        "distinct-3-nopunct": 0.6822033898305084,
        "vocab_size-3-nopunct": 161,
        "unique-3-nopunct": 112,
        "entropy-3-nopunct": 7.113368155202354,
        "cond_entropy-3-nopunct": 0.16864809934365416,
        "msttr-100": 0.51667,
        "msttr-100_nopunct": 0.55667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.4059701492537313
        },
        "nist": 2.949569921077871,
        "bleu": 14.27439,
        "rouge1": {
            "precision": 0.57215,
            "recall": 0.51482,
            "fmeasure": 0.53251
        },
        "rouge2": {
            "precision": 0.3605,
            "recall": 0.32675,
            "fmeasure": 0.33511
        },
        "rougeL": {
            "precision": 0.50692,
            "recall": 0.45779,
            "fmeasure": 0.47231
        },
        "rougeLsum": {
            "precision": 0.50692,
            "recall": 0.45779,
            "fmeasure": 0.47231
        },
        "nubia": {
            "semantic_relation": 3.45599,
            "contradiction": 21.42816,
            "irrelevancy": 21.34697,
            "logical_agreement": 57.22487,
            "grammar_ref": 6.46033,
            "grammar_hyp": 6.45976,
            "nubia_score": 0.50044
        },
        "meteor": 0.22263343964722723,
        "bleurt": -0.09714,
        "bertscore": {
            "precision": 0.92052,
            "recall": 0.91118,
            "f1": 0.91567
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_133": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.4
        },
        "nist": 0.31592321743697377,
        "bleu": 15.98205,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.41176,
            "fmeasure": 0.53846
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.25,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.35294,
            "fmeasure": 0.46154
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.35294,
            "fmeasure": 0.46154
        },
        "nubia": {
            "semantic_relation": 2.15211,
            "contradiction": 97.26095,
            "irrelevancy": 1.79871,
            "logical_agreement": 0.94034,
            "grammar_ref": 4.28272,
            "grammar_hyp": 4.47104,
            "nubia_score": 0.12897
        },
        "meteor": 0.22923407173743382,
        "bleurt": -0.01146,
        "bertscore": {
            "precision": 0.88467,
            "recall": 0.83511,
            "f1": 0.85917
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_challenge_test_asset_bfp05",
        "N": 359,
        "total_length": 5719,
        "mean_pred_length": 15.930362116991644,
        "std_pred_length": 6.122077280710222,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.42734743836335026,
        "vocab_size-1": 2444,
        "unique-1": 2003,
        "entropy-1": 9.165119130777704,
        "distinct-2": 0.8535447761194029,
        "vocab_size-2": 4575,
        "unique-2": 4309,
        "entropy-2": 11.852972936138839,
        "cond_entropy-2": 2.4161284558155627,
        "distinct-3": 0.9600079984003199,
        "vocab_size-3": 4801,
        "unique-3": 4728,
        "entropy-3": 12.132037798651407,
        "cond_entropy-3": 0.3048471560642846,
        "total_length-nopunct": 5091,
        "mean_pred_length-nopunct": 14.181058495821727,
        "std_pred_length-nopunct": 5.517566577837366,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.4777057552543705,
        "vocab_size-1-nopunct": 2432,
        "unique-1-nopunct": 1999,
        "entropy-1-nopunct": 9.500277754030158,
        "distinct-2-nopunct": 0.8772189349112426,
        "vocab_size-2-nopunct": 4151,
        "unique-2-nopunct": 3926,
        "entropy-2-nopunct": 11.801579945654305,
        "cond_entropy-2-nopunct": 2.460983933896954,
        "distinct-3-nopunct": 0.983764006402927,
        "vocab_size-3-nopunct": 4302,
        "unique-3-nopunct": 4248,
        "entropy-3-nopunct": 12.058161693574828,
        "cond_entropy-3-nopunct": 0.28195105968311296,
        "msttr-100": 0.74158,
        "msttr-100_nopunct": 0.7826,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp05.json",
        "local_recall": {
            "1": 0.03729468599033817,
            "2": 0.12225274725274725,
            "3": 0.22860492379835873,
            "4": 0.32152974504249293,
            "5": 0.3612217795484728,
            "6": 0.44704433497536944,
            "7": 0.5136986301369864,
            "8": 0.5873015873015873,
            "9": 0.7107913669064748
        },
        "nist": 7.993773570463769,
        "bleu": 41.6304,
        "rouge1": {
            "precision": 0.68029,
            "recall": 0.61381,
            "fmeasure": 0.63221
        },
        "rouge2": {
            "precision": 0.45895,
            "recall": 0.40932,
            "fmeasure": 0.42048
        },
        "rougeL": {
            "precision": 0.64163,
            "recall": 0.58179,
            "fmeasure": 0.59691
        },
        "rougeLsum": {
            "precision": 0.64163,
            "recall": 0.58179,
            "fmeasure": 0.59691
        },
        "sari": 44.32592,
        "nubia": {
            "semantic_relation": 3.45179,
            "contradiction": 9.80315,
            "irrelevancy": 28.31943,
            "logical_agreement": 61.87742,
            "grammar_ref": 4.57404,
            "grammar_hyp": 6.1668,
            "nubia_score": 0.38827
        },
        "meteor": 0.3011637592960587,
        "bleurt": -0.61969,
        "bertscore": {
            "precision": 0.87547,
            "recall": 0.89082,
            "f1": 0.87871
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?select": {
        "predictions_file": "ByT5-base (Baseline)/cs_restaurants_test",
        "N": 12,
        "total_length": 80,
        "mean_pred_length": 6.666666666666667,
        "std_pred_length": 1.9720265943665387,
        "median_pred_length": 6.5,
        "min_pred_length": 5,
        "max_pred_length": 12,
        "distinct-1": 0.4375,
        "vocab_size-1": 35,
        "unique-1": 20,
        "entropy-1": 4.6812517538742595,
        "distinct-2": 0.6029411764705882,
        "vocab_size-2": 41,
        "unique-2": 27,
        "entropy-2": 5.149028465836737,
        "cond_entropy-2": 0.19769389265581278,
        "distinct-3": 0.625,
        "vocab_size-3": 35,
        "unique-3": 24,
        "entropy-3": 4.922553582385556,
        "cond_entropy-3": -0.19519921379695895,
        "total_length-nopunct": 66,
        "mean_pred_length-nopunct": 5.5,
        "std_pred_length-nopunct": 1.707825127659933,
        "median_pred_length-nopunct": 5.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.48484848484848486,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.662570490933637,
        "distinct-2-nopunct": 0.5740740740740741,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.749262270241281,
        "cond_entropy-2-nopunct": 0.19913823369228983,
        "distinct-3-nopunct": 0.5952380952380952,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.439005517604768,
        "cond_entropy-3-nopunct": -0.2731679959998638,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.2682926829268293
        },
        "nist": 1.742267995190236,
        "bleu": 16.90395,
        "rouge1": {
            "precision": 0.4254,
            "recall": 0.3529,
            "fmeasure": 0.37989
        },
        "rouge2": {
            "precision": 0.27338,
            "recall": 0.24004,
            "fmeasure": 0.25119
        },
        "rougeL": {
            "precision": 0.4254,
            "recall": 0.3529,
            "fmeasure": 0.37989
        },
        "rougeLsum": {
            "precision": 0.4254,
            "recall": 0.3529,
            "fmeasure": 0.37989
        },
        "nubia": {
            "semantic_relation": 2.60905,
            "contradiction": 21.55196,
            "irrelevancy": 23.6408,
            "logical_agreement": 54.80724,
            "grammar_ref": 6.83527,
            "grammar_hyp": 7.23158,
            "nubia_score": 0.25839
        },
        "meteor": 0.14614889351675783,
        "bleurt": -0.25017,
        "bertscore": {
            "precision": 0.88533,
            "recall": 0.87966,
            "f1": 0.88238
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_496": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 28,
        "mean_pred_length": 28.0,
        "std_pred_length": 0.0,
        "median_pred_length": 28.0,
        "min_pred_length": 28,
        "max_pred_length": 28,
        "distinct-1": 0.7857142857142857,
        "vocab_size-1": 22,
        "unique-1": 19,
        "entropy-1": 4.297902689682948,
        "distinct-2": 0.9259259259259259,
        "vocab_size-2": 25,
        "unique-2": 24,
        "entropy-2": 4.578780557638898,
        "cond_entropy-2": 0.29974646915501035,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": 0.12843250452237231,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.84,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.2634651896016456,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.386842188131012,
        "cond_entropy-2-nopunct": 0.13922662353657617,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": 0.14533369456035533,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714,
            "3": 0.6666666666666666
        },
        "nist": 3.677859618789786,
        "bleu": 27.42825,
        "rouge1": {
            "precision": 0.72,
            "recall": 0.58065,
            "fmeasure": 0.64286
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.4,
            "fmeasure": 0.44444
        },
        "rougeL": {
            "precision": 0.72,
            "recall": 0.58065,
            "fmeasure": 0.64286
        },
        "rougeLsum": {
            "precision": 0.72,
            "recall": 0.58065,
            "fmeasure": 0.64286
        },
        "nubia": {
            "semantic_relation": 2.38307,
            "contradiction": 78.514,
            "irrelevancy": 17.76263,
            "logical_agreement": 3.72337,
            "grammar_ref": 4.34568,
            "grammar_hyp": 4.19581,
            "nubia_score": 0.19912
        },
        "meteor": 0.2850342058607252,
        "bleurt": -0.30505,
        "bertscore": {
            "precision": 0.95523,
            "recall": 0.95679,
            "f1": 0.95601
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 144,
        "total_length": 2101,
        "mean_pred_length": 14.590277777777779,
        "std_pred_length": 5.965657729459656,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.37743931461208946,
        "vocab_size-1": 793,
        "unique-1": 573,
        "entropy-1": 8.060464444518084,
        "distinct-2": 0.7547266223811957,
        "vocab_size-2": 1477,
        "unique-2": 1271,
        "entropy-2": 10.205272003001966,
        "cond_entropy-2": 1.862517527649083,
        "distinct-3": 0.882515168229454,
        "vocab_size-3": 1600,
        "unique-3": 1488,
        "entropy-3": 10.519513779177228,
        "cond_entropy-3": 0.30663450616746657,
        "total_length-nopunct": 1820,
        "mean_pred_length-nopunct": 12.63888888888889,
        "std_pred_length-nopunct": 5.304101022258247,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4307692307692308,
        "vocab_size-1-nopunct": 784,
        "unique-1-nopunct": 572,
        "entropy-1-nopunct": 8.346002881673217,
        "distinct-2-nopunct": 0.7798329355608592,
        "vocab_size-2-nopunct": 1307,
        "unique-2-nopunct": 1152,
        "entropy-2-nopunct": 10.038023455272326,
        "cond_entropy-2-nopunct": 1.7758990426332835,
        "distinct-3-nopunct": 0.891644908616188,
        "vocab_size-3-nopunct": 1366,
        "unique-3-nopunct": 1279,
        "entropy-3-nopunct": 10.299769677402793,
        "cond_entropy-3-nopunct": 0.2731676960277988,
        "msttr-100": 0.71143,
        "msttr-100_nopunct": 0.75944,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2509727626459144,
            "2": 0.4900662251655629,
            "3": 0.7704280155642024
        },
        "nist": 7.881740835996158,
        "bleu": 49.95582,
        "rouge1": {
            "precision": 0.77305,
            "recall": 0.72355,
            "fmeasure": 0.73241
        },
        "rouge2": {
            "precision": 0.55199,
            "recall": 0.51746,
            "fmeasure": 0.52344
        },
        "rougeL": {
            "precision": 0.68833,
            "recall": 0.65222,
            "fmeasure": 0.65542
        },
        "rougeLsum": {
            "precision": 0.68833,
            "recall": 0.65222,
            "fmeasure": 0.65542
        },
        "nubia": {
            "semantic_relation": 4.11049,
            "contradiction": 5.92844,
            "irrelevancy": 33.40401,
            "logical_agreement": 60.66755,
            "grammar_ref": 4.70586,
            "grammar_hyp": 4.80758,
            "nubia_score": 0.70655
        },
        "meteor": 0.40842749911137716,
        "bleurt": 0.27739,
        "bertscore": {
            "precision": 0.93182,
            "recall": 0.92552,
            "f1": 0.92669
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 71,
        "total_length": 847,
        "mean_pred_length": 11.929577464788732,
        "std_pred_length": 4.566639420417588,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.4462809917355372,
        "vocab_size-1": 378,
        "unique-1": 302,
        "entropy-1": 7.231564196894356,
        "distinct-2": 0.8157216494845361,
        "vocab_size-2": 633,
        "unique-2": 579,
        "entropy-2": 9.040537761639696,
        "cond_entropy-2": 1.492220862636999,
        "distinct-3": 0.9134751773049645,
        "vocab_size-3": 644,
        "unique-3": 613,
        "entropy-3": 9.237603853070844,
        "cond_entropy-3": 0.206939486064719,
        "total_length-nopunct": 747,
        "mean_pred_length-nopunct": 10.52112676056338,
        "std_pred_length-nopunct": 4.110649703384096,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.499330655957162,
        "vocab_size-1-nopunct": 373,
        "unique-1-nopunct": 301,
        "entropy-1-nopunct": 7.421784021603499,
        "distinct-2-nopunct": 0.8165680473372781,
        "vocab_size-2-nopunct": 552,
        "unique-2-nopunct": 505,
        "entropy-2-nopunct": 8.839177462128188,
        "cond_entropy-2-nopunct": 1.5673190092499054,
        "distinct-3-nopunct": 0.9090909090909091,
        "vocab_size-3-nopunct": 550,
        "unique-3-nopunct": 522,
        "entropy-3-nopunct": 9.004299751303051,
        "cond_entropy-3-nopunct": 0.213545227462941,
        "msttr-100": 0.68375,
        "msttr-100_nopunct": 0.72429,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25139664804469275,
            "2": 0.5894736842105263,
            "3": 0.7971887550200804
        },
        "nist": 7.0538798706725165,
        "bleu": 54.37343,
        "rouge1": {
            "precision": 0.74196,
            "recall": 0.75555,
            "fmeasure": 0.73276
        },
        "rouge2": {
            "precision": 0.54886,
            "recall": 0.57382,
            "fmeasure": 0.54749
        },
        "rougeL": {
            "precision": 0.69844,
            "recall": 0.72045,
            "fmeasure": 0.69408
        },
        "rougeLsum": {
            "precision": 0.69844,
            "recall": 0.72045,
            "fmeasure": 0.69408
        },
        "nubia": {
            "semantic_relation": 4.01921,
            "contradiction": 8.497,
            "irrelevancy": 42.67406,
            "logical_agreement": 48.82894,
            "grammar_ref": 5.37595,
            "grammar_hyp": 5.36195,
            "nubia_score": 0.66219
        },
        "meteor": 0.422949391591493,
        "bleurt": 0.32127,
        "bertscore": {
            "precision": 0.93655,
            "recall": 0.94098,
            "f1": 0.93669
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_challenge_test_asset_nopunc",
        "N": 359,
        "total_length": 5485,
        "mean_pred_length": 15.278551532033426,
        "std_pred_length": 6.101770336923452,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.37119416590701915,
        "vocab_size-1": 2036,
        "unique-1": 1524,
        "entropy-1": 8.863044745266107,
        "distinct-2": 0.8269605930550137,
        "vocab_size-2": 4239,
        "unique-2": 3918,
        "entropy-2": 11.702931606606914,
        "cond_entropy-2": 2.5991802416392593,
        "distinct-3": 0.9557373610237047,
        "vocab_size-3": 4556,
        "unique-3": 4476,
        "entropy-3": 12.051631892794681,
        "cond_entropy-3": 0.38057234521190125,
        "total_length-nopunct": 4899,
        "mean_pred_length-nopunct": 13.646239554317548,
        "std_pred_length-nopunct": 5.55501039199285,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.41334966319657074,
        "vocab_size-1-nopunct": 2025,
        "unique-1-nopunct": 1521,
        "entropy-1-nopunct": 9.149737134531442,
        "distinct-2-nopunct": 0.8524229074889867,
        "vocab_size-2-nopunct": 3870,
        "unique-2-nopunct": 3593,
        "entropy-2-nopunct": 11.662424835993985,
        "cond_entropy-2-nopunct": 2.6921840016120684,
        "distinct-3-nopunct": 0.9811049988041138,
        "vocab_size-3-nopunct": 4102,
        "unique-3-nopunct": 4044,
        "entropy-3-nopunct": 11.986821106216265,
        "cond_entropy-3-nopunct": 0.3572711750294918,
        "msttr-100": 0.71926,
        "msttr-100_nopunct": 0.7575,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_nopunc.json",
        "local_recall": {
            "1": 0.043671497584541065,
            "2": 0.13255494505494506,
            "3": 0.23563892145369286,
            "4": 0.34277620396600567,
            "5": 0.4169986719787517,
            "6": 0.48645320197044334,
            "7": 0.589041095890411,
            "8": 0.6726190476190477,
            "9": 0.8
        },
        "nist": 9.205766073920497,
        "bleu": 56.96974,
        "rouge1": {
            "precision": 0.78515,
            "recall": 0.68672,
            "fmeasure": 0.71694
        },
        "rouge2": {
            "precision": 0.59589,
            "recall": 0.51628,
            "fmeasure": 0.53624
        },
        "rougeL": {
            "precision": 0.74071,
            "recall": 0.65289,
            "fmeasure": 0.67791
        },
        "rougeLsum": {
            "precision": 0.74071,
            "recall": 0.65289,
            "fmeasure": 0.67791
        },
        "sari": 43.59953,
        "nubia": {
            "semantic_relation": 3.73853,
            "contradiction": 5.45278,
            "irrelevancy": 27.60387,
            "logical_agreement": 66.94335,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.0861,
            "nubia_score": 0.5335
        },
        "meteor": 0.3690041527692484,
        "bleurt": -0.02883,
        "bertscore": {
            "precision": 0.93419,
            "recall": 0.91815,
            "f1": 0.92114
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_7": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 47,
        "total_length": 737,
        "mean_pred_length": 15.680851063829786,
        "std_pred_length": 5.853191102655115,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.4491180461329715,
        "vocab_size-1": 331,
        "unique-1": 240,
        "entropy-1": 7.298568954540944,
        "distinct-2": 0.7840579710144927,
        "vocab_size-2": 541,
        "unique-2": 463,
        "entropy-2": 8.853809887726586,
        "cond_entropy-2": 1.3749575171082273,
        "distinct-3": 0.8709175738724728,
        "vocab_size-3": 560,
        "unique-3": 516,
        "entropy-3": 8.99013563439823,
        "cond_entropy-3": 0.15981284652417777,
        "total_length-nopunct": 639,
        "mean_pred_length-nopunct": 13.595744680851064,
        "std_pred_length-nopunct": 5.237587452042291,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.5070422535211268,
        "vocab_size-1-nopunct": 324,
        "unique-1-nopunct": 239,
        "entropy-1-nopunct": 7.440248265805876,
        "distinct-2-nopunct": 0.7956081081081081,
        "vocab_size-2-nopunct": 471,
        "unique-2-nopunct": 414,
        "entropy-2-nopunct": 8.647422658434422,
        "cond_entropy-2-nopunct": 1.3099161936206807,
        "distinct-3-nopunct": 0.8788990825688073,
        "vocab_size-3-nopunct": 479,
        "unique-3-nopunct": 446,
        "entropy-3-nopunct": 8.76850802810986,
        "cond_entropy-3-nopunct": 0.15456338478856135,
        "msttr-100": 0.67143,
        "msttr-100_nopunct": 0.73333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22758620689655173,
            "2": 0.37410071942446044,
            "3": 0.7139784946236559
        },
        "nist": 6.329531429819507,
        "bleu": 45.70794,
        "rouge1": {
            "precision": 0.71112,
            "recall": 0.70414,
            "fmeasure": 0.69806
        },
        "rouge2": {
            "precision": 0.47231,
            "recall": 0.47811,
            "fmeasure": 0.47031
        },
        "rougeL": {
            "precision": 0.63264,
            "recall": 0.62002,
            "fmeasure": 0.61812
        },
        "rougeLsum": {
            "precision": 0.63264,
            "recall": 0.62002,
            "fmeasure": 0.61812
        },
        "nubia": {
            "semantic_relation": 3.91687,
            "contradiction": 13.31839,
            "irrelevancy": 32.20808,
            "logical_agreement": 54.47353,
            "grammar_ref": 4.53522,
            "grammar_hyp": 4.50615,
            "nubia_score": 0.65888
        },
        "meteor": 0.3678275808158418,
        "bleurt": 0.20875,
        "bertscore": {
            "precision": 0.92073,
            "recall": 0.91708,
            "f1": 0.91701
        }
    },
    "common_gen_validation": {
        "predictions_file": "ByT5-base (Baseline)/common_gen_validation",
        "N": 993,
        "total_length": 11492,
        "mean_pred_length": 11.5730110775428,
        "std_pred_length": 3.2676751064152243,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 24,
        "distinct-1": 0.14183780020884093,
        "vocab_size-1": 1630,
        "unique-1": 829,
        "entropy-1": 7.626572812417639,
        "distinct-2": 0.5166206305362415,
        "vocab_size-2": 5424,
        "unique-2": 4131,
        "entropy-2": 11.38579030223201,
        "cond_entropy-2": 3.523205627694642,
        "distinct-3": 0.7971807279612876,
        "vocab_size-3": 7578,
        "unique-3": 6736,
        "entropy-3": 12.600366005033298,
        "cond_entropy-3": 1.2605646706933595,
        "total_length-nopunct": 10650,
        "mean_pred_length-nopunct": 10.725075528700906,
        "std_pred_length-nopunct": 3.136688913603067,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.1527699530516432,
        "vocab_size-1-nopunct": 1627,
        "unique-1-nopunct": 829,
        "entropy-1-nopunct": 7.801324512813734,
        "distinct-2-nopunct": 0.5174484829657243,
        "vocab_size-2-nopunct": 4997,
        "unique-2-nopunct": 3848,
        "entropy-2-nopunct": 11.227640362135984,
        "cond_entropy-2-nopunct": 3.709132828996501,
        "distinct-3-nopunct": 0.805286241920591,
        "vocab_size-3-nopunct": 6977,
        "unique-3-nopunct": 6238,
        "entropy-3-nopunct": 12.486491063528714,
        "cond_entropy-3-nopunct": 1.3213097366176498,
        "msttr-100": 0.62167,
        "msttr-100_nopunct": 0.645,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/common_gen_validation.json",
        "local_recall": {
            "1": 0.1052368453943257,
            "2": 0.3055851063829787,
            "3": 0.50157444894287,
            "4": 0.7695673310646572,
            "5": 0.759656652360515,
            "6": 0.7976190476190477,
            "7": 1.0,
            "8": 0.8
        },
        "nist": 6.258559186907789,
        "bleu": 19.4932,
        "rouge1": {
            "precision": 0.59659,
            "recall": 0.61489,
            "fmeasure": 0.59286
        },
        "rouge2": {
            "precision": 0.26354,
            "recall": 0.27066,
            "fmeasure": 0.26014
        },
        "rougeL": {
            "precision": 0.49382,
            "recall": 0.50789,
            "fmeasure": 0.49034
        },
        "rougeLsum": {
            "precision": 0.49382,
            "recall": 0.50789,
            "fmeasure": 0.49034
        },
        "nubia": {
            "semantic_relation": 2.95818,
            "contradiction": 30.91519,
            "irrelevancy": 38.30855,
            "logical_agreement": 30.77626,
            "grammar_ref": 4.64808,
            "grammar_hyp": 5.02577,
            "nubia_score": 0.36547
        },
        "meteor": 0.24581765571666378,
        "bleurt": -0.61994,
        "bertscore": {
            "precision": 0.86928,
            "recall": 0.8746,
            "f1": 0.87052
        }
    },
    "totto_test_contrast_challenge_continent-south_america": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 79,
        "total_length": 1299,
        "mean_pred_length": 16.443037974683545,
        "std_pred_length": 4.519288718099925,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.46420323325635104,
        "vocab_size-1": 603,
        "unique-1": 471,
        "entropy-1": 7.918799830446946,
        "distinct-2": 0.8491803278688524,
        "vocab_size-2": 1036,
        "unique-2": 939,
        "entropy-2": 9.843936981817478,
        "cond_entropy-2": 1.712678160973051,
        "distinct-3": 0.9623137598597721,
        "vocab_size-3": 1098,
        "unique-3": 1064,
        "entropy-3": 10.073896890915677,
        "cond_entropy-3": 0.2394075625560846,
        "total_length-nopunct": 1140,
        "mean_pred_length-nopunct": 14.430379746835444,
        "std_pred_length-nopunct": 4.298022931722808,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5219298245614035,
        "vocab_size-1-nopunct": 595,
        "unique-1-nopunct": 469,
        "entropy-1-nopunct": 8.18141444763633,
        "distinct-2-nopunct": 0.8642789820923656,
        "vocab_size-2-nopunct": 917,
        "unique-2-nopunct": 848,
        "entropy-2-nopunct": 9.666091495340233,
        "cond_entropy-2-nopunct": 1.5674297015670138,
        "distinct-3-nopunct": 0.9714867617107943,
        "vocab_size-3-nopunct": 954,
        "unique-3-nopunct": 930,
        "entropy-3-nopunct": 9.878978628770579,
        "cond_entropy-3-nopunct": 0.22799845288020915,
        "msttr-100": 0.72167,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19696969696969696,
            "2": 0.4174757281553398,
            "3": 0.8025889967637541
        },
        "nist": 7.681507446266344,
        "bleu": 47.1759,
        "rouge1": {
            "precision": 0.81243,
            "recall": 0.7745,
            "fmeasure": 0.78546
        },
        "rouge2": {
            "precision": 0.59687,
            "recall": 0.57053,
            "fmeasure": 0.5775
        },
        "rougeL": {
            "precision": 0.6898,
            "recall": 0.65416,
            "fmeasure": 0.66465
        },
        "rougeLsum": {
            "precision": 0.6898,
            "recall": 0.65416,
            "fmeasure": 0.66465
        },
        "nubia": {
            "semantic_relation": 4.41829,
            "contradiction": 2.55973,
            "irrelevancy": 25.04726,
            "logical_agreement": 72.39302,
            "grammar_ref": 4.82253,
            "grammar_hyp": 4.79889,
            "nubia_score": 0.79367
        },
        "meteor": 0.4067571936280125,
        "bleurt": 0.40775,
        "bertscore": {
            "precision": 0.94647,
            "recall": 0.93909,
            "f1": 0.94151
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 59,
        "total_length": 961,
        "mean_pred_length": 16.28813559322034,
        "std_pred_length": 4.758759443304694,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.47762747138397504,
        "vocab_size-1": 459,
        "unique-1": 372,
        "entropy-1": 7.6195862282406495,
        "distinct-2": 0.8314855875831486,
        "vocab_size-2": 750,
        "unique-2": 681,
        "entropy-2": 9.348657681069758,
        "cond_entropy-2": 1.5040022165965865,
        "distinct-3": 0.9217081850533808,
        "vocab_size-3": 777,
        "unique-3": 733,
        "entropy-3": 9.536810644194574,
        "cond_entropy-3": 0.20253191399614504,
        "total_length-nopunct": 839,
        "mean_pred_length-nopunct": 14.220338983050848,
        "std_pred_length-nopunct": 4.411340534216249,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5375446960667462,
        "vocab_size-1-nopunct": 451,
        "unique-1-nopunct": 370,
        "entropy-1-nopunct": 7.828002084675049,
        "distinct-2-nopunct": 0.8307692307692308,
        "vocab_size-2-nopunct": 648,
        "unique-2-nopunct": 590,
        "entropy-2-nopunct": 9.127631163307356,
        "cond_entropy-2-nopunct": 1.3860556843060423,
        "distinct-3-nopunct": 0.9181692094313454,
        "vocab_size-3-nopunct": 662,
        "unique-3-nopunct": 622,
        "entropy-3-nopunct": 9.303621724558228,
        "cond_entropy-3-nopunct": 0.19710766843408645,
        "msttr-100": 0.70556,
        "msttr-100_nopunct": 0.745,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2641509433962264,
            "2": 0.46616541353383456,
            "3": 0.812206572769953
        },
        "nist": 7.372569667557943,
        "bleu": 52.14359,
        "rouge1": {
            "precision": 0.77396,
            "recall": 0.75665,
            "fmeasure": 0.75939
        },
        "rouge2": {
            "precision": 0.56333,
            "recall": 0.55824,
            "fmeasure": 0.55544
        },
        "rougeL": {
            "precision": 0.68702,
            "recall": 0.67707,
            "fmeasure": 0.67609
        },
        "rougeLsum": {
            "precision": 0.68702,
            "recall": 0.67707,
            "fmeasure": 0.67609
        },
        "nubia": {
            "semantic_relation": 4.28133,
            "contradiction": 7.6494,
            "irrelevancy": 28.90564,
            "logical_agreement": 63.44495,
            "grammar_ref": 4.6237,
            "grammar_hyp": 4.53545,
            "nubia_score": 0.76409
        },
        "meteor": 0.414581464247338,
        "bleurt": 0.37317,
        "bertscore": {
            "precision": 0.94122,
            "recall": 0.9378,
            "f1": 0.93801
        }
    },
    "common_gen_test": {
        "predictions_file": "ByT5-base (Baseline)/common_gen_test",
        "N": 1497
    },
    "common_gen_challenge_train_sample": {
        "predictions_file": "ByT5-base (Baseline)/common_gen_challenge_train_sample",
        "N": 500
    },
    "xsum_challenge_test_bfp_02_parent": {
        "predictions_file": "ByT5-base (Baseline)/xsum_test",
        "N": 500,
        "total_length": 10764,
        "mean_pred_length": 21.528,
        "std_pred_length": 3.1857834201338924,
        "median_pred_length": 22.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.2685804533630621,
        "vocab_size-1": 2891,
        "unique-1": 1851,
        "entropy-1": 9.086378499112103,
        "distinct-2": 0.7262275915822292,
        "vocab_size-2": 7454,
        "unique-2": 6460,
        "entropy-2": 12.347801783919827,
        "cond_entropy-2": 3.18242321030903,
        "distinct-3": 0.9216509627201966,
        "vocab_size-3": 8999,
        "unique-3": 8544,
        "entropy-3": 13.047317584289493,
        "cond_entropy-3": 0.7209070469884028,
        "total_length-nopunct": 10216,
        "mean_pred_length-nopunct": 20.432,
        "std_pred_length-nopunct": 3.3330730565050626,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.28200861393891935,
        "vocab_size-1-nopunct": 2881,
        "unique-1-nopunct": 1848,
        "entropy-1-nopunct": 9.182893010738775,
        "distinct-2-nopunct": 0.732297241663236,
        "vocab_size-2-nopunct": 7115,
        "unique-2-nopunct": 6183,
        "entropy-2-nopunct": 12.290864467455004,
        "cond_entropy-2-nopunct": 3.2251643615263177,
        "distinct-3-nopunct": 0.9274088541666666,
        "vocab_size-3-nopunct": 8547,
        "unique-3-nopunct": 8135,
        "entropy-3-nopunct": 12.987154825332304,
        "cond_entropy-3-nopunct": 0.7194798663978558,
        "msttr-100": 0.74168,
        "msttr-100_nopunct": 0.74971,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.34320522979397783
        },
        "nist": 3.464753358617737,
        "bleu": 8.44393,
        "rouge1": {
            "precision": 0.38642,
            "recall": 0.37396,
            "fmeasure": 0.37419
        },
        "rouge2": {
            "precision": 0.14644,
            "recall": 0.14151,
            "fmeasure": 0.14147
        },
        "rougeL": {
            "precision": 0.29997,
            "recall": 0.29063,
            "fmeasure": 0.29049
        },
        "rougeLsum": {
            "precision": 0.29997,
            "recall": 0.29063,
            "fmeasure": 0.29049
        },
        "nubia": {
            "semantic_relation": 2.70434,
            "contradiction": 26.20998,
            "irrelevancy": 62.92699,
            "logical_agreement": 10.86303,
            "grammar_ref": 3.74155,
            "grammar_hyp": 4.07136,
            "nubia_score": 0.34928
        },
        "meteor": 0.15985344485985611,
        "bleurt": -0.45484,
        "bertscore": {
            "precision": 0.82471,
            "recall": 0.81869,
            "f1": 0.82141
        }
    },
    "xsum_challenge_test_bfp_05_parent": {
        "predictions_file": "ByT5-base (Baseline)/xsum_test",
        "N": 500,
        "total_length": 10633,
        "mean_pred_length": 21.266,
        "std_pred_length": 3.3327532161862807,
        "median_pred_length": 22.0,
        "min_pred_length": 4,
        "max_pred_length": 30,
        "distinct-1": 0.27668578952318257,
        "vocab_size-1": 2942,
        "unique-1": 1909,
        "entropy-1": 9.108972022292171,
        "distinct-2": 0.7314714299812494,
        "vocab_size-2": 7412,
        "unique-2": 6443,
        "entropy-2": 12.353592519497552,
        "cond_entropy-2": 3.154533499294728,
        "distinct-3": 0.922765493615696,
        "vocab_size-3": 8889,
        "unique-3": 8474,
        "entropy-3": 13.030246893422593,
        "cond_entropy-3": 0.6979334130278502,
        "total_length-nopunct": 10111,
        "mean_pred_length-nopunct": 20.222,
        "std_pred_length-nopunct": 3.49524190865239,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.2897834042132331,
        "vocab_size-1-nopunct": 2930,
        "unique-1-nopunct": 1905,
        "entropy-1-nopunct": 9.202415323747248,
        "distinct-2-nopunct": 0.7354073457496618,
        "vocab_size-2-nopunct": 7068,
        "unique-2-nopunct": 6154,
        "entropy-2-nopunct": 12.289552015366972,
        "cond_entropy-2-nopunct": 3.2058080210171105,
        "distinct-3-nopunct": 0.9278893645044451,
        "vocab_size-3-nopunct": 8454,
        "unique-3-nopunct": 8073,
        "entropy-3-nopunct": 12.969750608031292,
        "cond_entropy-3-nopunct": 0.701980080858684,
        "msttr-100": 0.73783,
        "msttr-100_nopunct": 0.74941,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.332536837913182
        },
        "nist": 3.364953434824925,
        "bleu": 8.08106,
        "rouge1": {
            "precision": 0.37631,
            "recall": 0.35929,
            "fmeasure": 0.3618
        },
        "rouge2": {
            "precision": 0.13511,
            "recall": 0.1276,
            "fmeasure": 0.12894
        },
        "rougeL": {
            "precision": 0.28925,
            "recall": 0.27697,
            "fmeasure": 0.27832
        },
        "rougeLsum": {
            "precision": 0.28925,
            "recall": 0.27697,
            "fmeasure": 0.27832
        },
        "nubia": {
            "semantic_relation": 2.61093,
            "contradiction": 30.43734,
            "irrelevancy": 59.29674,
            "logical_agreement": 10.26592,
            "grammar_ref": 3.79385,
            "grammar_hyp": 4.12846,
            "nubia_score": 0.32741
        },
        "meteor": 0.15594454015110235,
        "bleurt": -0.46646,
        "bertscore": {
            "precision": 0.82285,
            "recall": 0.81458,
            "f1": 0.81842
        }
    },
    "common_gen_challenge_validation_sample": {
        "predictions_file": "ByT5-base (Baseline)/common_gen_challenge_validation_sample",
        "N": 500
    },
    "common_gen_challenge_test_scramble": {
        "predictions_file": "ByT5-base (Baseline)/common_gen_challenge_test_scramble",
        "N": 500
    },
    "totto_test_contrast_challenge_input_size-input_length_21": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 81,
        "mean_pred_length": 20.25,
        "std_pred_length": 5.973901572674261,
        "median_pred_length": 23.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.7530864197530864,
        "vocab_size-1": 61,
        "unique-1": 51,
        "entropy-1": 5.7160311755638675,
        "distinct-2": 0.948051948051948,
        "vocab_size-2": 73,
        "unique-2": 70,
        "entropy-2": 6.15308670300447,
        "cond_entropy-2": 0.4358907587206163,
        "distinct-3": 1.0,
        "vocab_size-3": 73,
        "unique-3": 73,
        "entropy-3": 6.189824558880028,
        "cond_entropy-3": 0.021256168889805402,
        "total_length-nopunct": 74,
        "mean_pred_length-nopunct": 18.5,
        "std_pred_length-nopunct": 5.894913061275798,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7702702702702703,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.61790691278007,
        "distinct-2-nopunct": 0.9714285714285714,
        "vocab_size-2-nopunct": 68,
        "unique-2-nopunct": 67,
        "entropy-2-nopunct": 6.0613560526283505,
        "cond_entropy-2-nopunct": 0.44032375857219874,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 66,
        "unique-3-nopunct": 66,
        "entropy-3-nopunct": 6.044394119358462,
        "cond_entropy-3-nopunct": -0.036859730897993354,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 0.44047619047619047
        },
        "nist": 0.9193621796102998,
        "bleu": 14.23497,
        "rouge1": {
            "precision": 0.61755,
            "recall": 0.44476,
            "fmeasure": 0.49937
        },
        "rouge2": {
            "precision": 0.42827,
            "recall": 0.30287,
            "fmeasure": 0.33905
        },
        "rougeL": {
            "precision": 0.54346,
            "recall": 0.38106,
            "fmeasure": 0.43119
        },
        "rougeLsum": {
            "precision": 0.54346,
            "recall": 0.38106,
            "fmeasure": 0.43119
        },
        "nubia": {
            "semantic_relation": 3.15156,
            "contradiction": 5.80279,
            "irrelevancy": 75.28063,
            "logical_agreement": 18.91658,
            "grammar_ref": 3.12827,
            "grammar_hyp": 3.73284,
            "nubia_score": 0.39166
        },
        "meteor": 0.199681392027647,
        "bleurt": -0.31489,
        "bertscore": {
            "precision": 0.85748,
            "recall": 0.83121,
            "f1": 0.84234
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 52,
        "total_length": 791,
        "mean_pred_length": 15.211538461538462,
        "std_pred_length": 4.915972939391388,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.4424778761061947,
        "vocab_size-1": 350,
        "unique-1": 265,
        "entropy-1": 7.2076077414167585,
        "distinct-2": 0.790257104194858,
        "vocab_size-2": 584,
        "unique-2": 512,
        "entropy-2": 8.928657046230429,
        "cond_entropy-2": 1.5086397468803494,
        "distinct-3": 0.9053857350800583,
        "vocab_size-3": 622,
        "unique-3": 584,
        "entropy-3": 9.188156149826375,
        "cond_entropy-3": 0.25762268059511506,
        "total_length-nopunct": 684,
        "mean_pred_length-nopunct": 13.153846153846153,
        "std_pred_length-nopunct": 4.2759821875960915,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.5058479532163743,
        "vocab_size-1-nopunct": 346,
        "unique-1-nopunct": 265,
        "entropy-1-nopunct": 7.392341204685852,
        "distinct-2-nopunct": 0.8132911392405063,
        "vocab_size-2-nopunct": 514,
        "unique-2-nopunct": 459,
        "entropy-2-nopunct": 8.769139257172345,
        "cond_entropy-2-nopunct": 1.4490326996598752,
        "distinct-3-nopunct": 0.9120689655172414,
        "vocab_size-3-nopunct": 529,
        "unique-3-nopunct": 498,
        "entropy-3-nopunct": 8.962884429703022,
        "cond_entropy-3-nopunct": 0.22443716827588286,
        "msttr-100": 0.64714,
        "msttr-100_nopunct": 0.69833,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3092105263157895,
            "2": 0.6054054054054054,
            "3": 0.7994858611825193
        },
        "nist": 6.697963322221337,
        "bleu": 49.37243,
        "rouge1": {
            "precision": 0.7306,
            "recall": 0.77322,
            "fmeasure": 0.73531
        },
        "rouge2": {
            "precision": 0.53845,
            "recall": 0.53916,
            "fmeasure": 0.5285
        },
        "rougeL": {
            "precision": 0.67224,
            "recall": 0.70555,
            "fmeasure": 0.67467
        },
        "rougeLsum": {
            "precision": 0.67224,
            "recall": 0.70555,
            "fmeasure": 0.67467
        },
        "nubia": {
            "semantic_relation": 4.10685,
            "contradiction": 12.0617,
            "irrelevancy": 29.96744,
            "logical_agreement": 57.97086,
            "grammar_ref": 5.15177,
            "grammar_hyp": 4.91475,
            "nubia_score": 0.69207
        },
        "meteor": 0.4222009309529393,
        "bleurt": 0.37378,
        "bertscore": {
            "precision": 0.93373,
            "recall": 0.94246,
            "f1": 0.93645
        }
    },
    "wiki_auto_asset_turk_validation": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_validation",
        "N": 20000,
        "total_length": 344040,
        "mean_pred_length": 17.202,
        "std_pred_length": 5.940976014090614,
        "median_pred_length": 17.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.022883966980583655,
        "vocab_size-1": 7873,
        "unique-1": 0,
        "entropy-1": 9.692367741755131,
        "distinct-2": 0.07077521293667448,
        "vocab_size-2": 22934,
        "unique-2": 0,
        "entropy-2": 13.754426498191895,
        "cond_entropy-2": 3.8472715534259714,
        "distinct-3": 0.09106367583212735,
        "vocab_size-3": 27687,
        "unique-3": 0,
        "entropy-3": 14.572311656005034,
        "cond_entropy-3": 0.8546688863652212,
        "total_length-nopunct": 305960,
        "mean_pred_length-nopunct": 15.298,
        "std_pred_length-nopunct": 5.384161587471164,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.025679827428422015,
        "vocab_size-1-nopunct": 7857,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 10.055802481349343,
        "distinct-2-nopunct": 0.07362917890614072,
        "vocab_size-2-nopunct": 21055,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 13.744055505300267,
        "cond_entropy-2-nopunct": 3.8863984494274204,
        "distinct-3-nopunct": 0.0932095051887502,
        "vocab_size-3-nopunct": 24790,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 14.513721857945704,
        "cond_entropy-3-nopunct": 0.8233831647825184,
        "msttr-100": 0.23409,
        "msttr-100_nopunct": 0.22145,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_validation.json",
        "local_recall": {
            "1": 0.6386623618348528
        },
        "nist": 9.001818866476532,
        "bleu": 38.67071,
        "rouge1": {
            "precision": 0.71877,
            "recall": 0.66709,
            "fmeasure": 0.67256
        },
        "rouge2": {
            "precision": 0.51949,
            "recall": 0.47938,
            "fmeasure": 0.48355
        },
        "rougeL": {
            "precision": 0.66859,
            "recall": 0.62133,
            "fmeasure": 0.62629
        },
        "rougeLsum": {
            "precision": 0.66859,
            "recall": 0.62133,
            "fmeasure": 0.62629
        },
        "sari": 42.8838,
        "nubia": {
            "semantic_relation": 4.1003,
            "contradiction": 3.9484,
            "irrelevancy": 25.66968,
            "logical_agreement": 70.38191,
            "grammar_ref": 4.53224,
            "grammar_hyp": 4.84039,
            "nubia_score": 0.64798
        },
        "meteor": 0.34349727868531443,
        "bleurt": 0.1541,
        "bertscore": {
            "precision": 0.91354,
            "recall": 0.9032,
            "f1": 0.90742
        }
    },
    "web_nlg_en_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 28,
        "total_length": 293,
        "mean_pred_length": 10.464285714285714,
        "std_pred_length": 4.47598467105398,
        "median_pred_length": 9.0,
        "min_pred_length": 6,
        "max_pred_length": 26,
        "distinct-1": 0.40955631399317405,
        "vocab_size-1": 120,
        "unique-1": 78,
        "entropy-1": 5.900236362246569,
        "distinct-2": 0.7660377358490567,
        "vocab_size-2": 203,
        "unique-2": 168,
        "entropy-2": 7.474363668454229,
        "cond_entropy-2": 1.3321069711983036,
        "distinct-3": 0.8987341772151899,
        "vocab_size-3": 213,
        "unique-3": 194,
        "entropy-3": 7.666148786863852,
        "cond_entropy-3": 0.21758080055256826,
        "total_length-nopunct": 260,
        "mean_pred_length-nopunct": 9.285714285714286,
        "std_pred_length-nopunct": 4.130523512800274,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.4461538461538462,
        "vocab_size-1-nopunct": 116,
        "unique-1-nopunct": 76,
        "entropy-1-nopunct": 5.9611657297628176,
        "distinct-2-nopunct": 0.7543103448275862,
        "vocab_size-2-nopunct": 175,
        "unique-2-nopunct": 143,
        "entropy-2-nopunct": 7.252362488817134,
        "cond_entropy-2-nopunct": 1.4412259303294581,
        "distinct-3-nopunct": 0.8921568627450981,
        "vocab_size-3-nopunct": 182,
        "unique-3-nopunct": 165,
        "entropy-3-nopunct": 7.4334307953922645,
        "cond_entropy-3-nopunct": 0.2143398417479048,
        "msttr-100": 0.57,
        "msttr-100_nopunct": 0.585,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.6914893617021277,
            "3": 0.8740740740740741,
            "4": 1.0
        },
        "nist": 6.754460281388245,
        "bleu": 58.77694,
        "rouge1": {
            "precision": 0.827,
            "recall": 0.78146,
            "fmeasure": 0.7943
        },
        "rouge2": {
            "precision": 0.60737,
            "recall": 0.56961,
            "fmeasure": 0.58034
        },
        "rougeL": {
            "precision": 0.73559,
            "recall": 0.69034,
            "fmeasure": 0.70326
        },
        "rougeLsum": {
            "precision": 0.73559,
            "recall": 0.69034,
            "fmeasure": 0.70326
        },
        "nubia": {
            "semantic_relation": 4.25435,
            "contradiction": 18.70216,
            "irrelevancy": 5.40315,
            "logical_agreement": 75.89469,
            "grammar_ref": 4.67502,
            "grammar_hyp": 4.84037,
            "nubia_score": 0.72588
        },
        "meteor": 0.42968688588923065,
        "bleurt": 0.36071,
        "bertscore": {
            "precision": 0.93805,
            "recall": 0.93353,
            "f1": 0.93466
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_9": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 105,
        "total_length": 1579,
        "mean_pred_length": 15.038095238095238,
        "std_pred_length": 6.598591205377979,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 31,
        "distinct-1": 0.42115262824572514,
        "vocab_size-1": 665,
        "unique-1": 512,
        "entropy-1": 7.967601215136452,
        "distinct-2": 0.8080054274084125,
        "vocab_size-2": 1191,
        "unique-2": 1060,
        "entropy-2": 9.980429287361224,
        "cond_entropy-2": 1.7794623464501749,
        "distinct-3": 0.9233016800584368,
        "vocab_size-3": 1264,
        "unique-3": 1194,
        "entropy-3": 10.238640720738193,
        "cond_entropy-3": 0.27279868485640946,
        "total_length-nopunct": 1354,
        "mean_pred_length-nopunct": 12.895238095238096,
        "std_pred_length-nopunct": 5.58386077313778,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.48375184638109303,
        "vocab_size-1-nopunct": 655,
        "unique-1-nopunct": 510,
        "entropy-1-nopunct": 8.216810539450965,
        "distinct-2-nopunct": 0.8278622898318655,
        "vocab_size-2-nopunct": 1034,
        "unique-2-nopunct": 934,
        "entropy-2-nopunct": 9.792364216761321,
        "cond_entropy-2-nopunct": 1.7032892019266737,
        "distinct-3-nopunct": 0.9335664335664335,
        "vocab_size-3-nopunct": 1068,
        "unique-3-nopunct": 1017,
        "entropy-3-nopunct": 10.00305307592483,
        "cond_entropy-3-nopunct": 0.23270011341173105,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.76077,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22832369942196531,
            "2": 0.4055727554179567,
            "3": 0.6978494623655914
        },
        "nist": 6.6611580843229765,
        "bleu": 38.09634,
        "rouge1": {
            "precision": 0.65012,
            "recall": 0.62291,
            "fmeasure": 0.61631
        },
        "rouge2": {
            "precision": 0.39507,
            "recall": 0.38021,
            "fmeasure": 0.37571
        },
        "rougeL": {
            "precision": 0.55423,
            "recall": 0.53714,
            "fmeasure": 0.52803
        },
        "rougeLsum": {
            "precision": 0.55423,
            "recall": 0.53714,
            "fmeasure": 0.52803
        },
        "nubia": {
            "semantic_relation": 3.61618,
            "contradiction": 19.19458,
            "irrelevancy": 33.73641,
            "logical_agreement": 47.06901,
            "grammar_ref": 4.94529,
            "grammar_hyp": 4.9898,
            "nubia_score": 0.59293
        },
        "meteor": 0.34312587882140255,
        "bleurt": 0.05801,
        "bertscore": {
            "precision": 0.8957,
            "recall": 0.89306,
            "f1": 0.89256
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 898,
        "total_length": 10119,
        "mean_pred_length": 11.268374164810691,
        "std_pred_length": 3.8305305339867357,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 27,
        "distinct-1": 0.3292815495602332,
        "vocab_size-1": 3332,
        "unique-1": 2475,
        "entropy-1": 9.043351066359195,
        "distinct-2": 0.6905975490727687,
        "vocab_size-2": 6368,
        "unique-2": 5493,
        "entropy-2": 11.986745873253794,
        "cond_entropy-2": 2.409799280926654,
        "distinct-3": 0.8436861708518563,
        "vocab_size-3": 7022,
        "unique-3": 6414,
        "entropy-3": 12.559431271511963,
        "cond_entropy-3": 0.546424869435592,
        "total_length-nopunct": 8788,
        "mean_pred_length-nopunct": 9.78619153674833,
        "std_pred_length-nopunct": 3.404593512860612,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.37756030951297226,
        "vocab_size-1-nopunct": 3318,
        "unique-1-nopunct": 2472,
        "entropy-1-nopunct": 9.514496373634893,
        "distinct-2-nopunct": 0.7122940430925222,
        "vocab_size-2-nopunct": 5620,
        "unique-2-nopunct": 4928,
        "entropy-2-nopunct": 11.820506721886952,
        "cond_entropy-2-nopunct": 2.5148444455073897,
        "distinct-3-nopunct": 0.8498283752860412,
        "vocab_size-3-nopunct": 5942,
        "unique-3-nopunct": 5449,
        "entropy-3-nopunct": 12.320655572771928,
        "cond_entropy-3-nopunct": 0.5795314314863886,
        "msttr-100": 0.7097,
        "msttr-100_nopunct": 0.76218,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24940143655227454,
            "2": 0.5330490405117271,
            "3": 0.7590160902533752
        },
        "nist": 8.737683745127272,
        "bleu": 49.60023,
        "rouge1": {
            "precision": 0.73624,
            "recall": 0.72369,
            "fmeasure": 0.71495
        },
        "rouge2": {
            "precision": 0.53796,
            "recall": 0.53159,
            "fmeasure": 0.52296
        },
        "rougeL": {
            "precision": 0.69189,
            "recall": 0.68411,
            "fmeasure": 0.67372
        },
        "rougeLsum": {
            "precision": 0.69189,
            "recall": 0.68411,
            "fmeasure": 0.67372
        },
        "nubia": {
            "semantic_relation": 4.07389,
            "contradiction": 10.51364,
            "irrelevancy": 32.88358,
            "logical_agreement": 56.60278,
            "grammar_ref": 5.09815,
            "grammar_hyp": 5.06903,
            "nubia_score": 0.69897
        },
        "meteor": 0.40371787042312113,
        "bleurt": 0.31388,
        "bertscore": {
            "precision": 0.9295,
            "recall": 0.92821,
            "f1": 0.92737
        }
    },
    "wiki_auto_asset_turk_test_asset": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 6165,
        "mean_pred_length": 17.172701949860723,
        "std_pred_length": 6.145699059785652,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.3772911597729116,
        "vocab_size-1": 2326,
        "unique-1": 1733,
        "entropy-1": 9.077575132617426,
        "distinct-2": 0.83861522562866,
        "vocab_size-2": 4869,
        "unique-2": 4517,
        "entropy-2": 11.942408546717669,
        "cond_entropy-2": 2.689547949982116,
        "distinct-3": 0.965669175693042,
        "vocab_size-3": 5260,
        "unique-3": 5169,
        "entropy-3": 12.295947924068003,
        "cond_entropy-3": 0.37620181953121684,
        "total_length-nopunct": 5505,
        "mean_pred_length-nopunct": 15.334261838440112,
        "std_pred_length-nopunct": 5.655841897975462,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4201634877384196,
        "vocab_size-1-nopunct": 2313,
        "unique-1-nopunct": 1730,
        "entropy-1-nopunct": 9.359233858545359,
        "distinct-2-nopunct": 0.8608628060629615,
        "vocab_size-2-nopunct": 4430,
        "unique-2-nopunct": 4135,
        "entropy-2-nopunct": 11.868219550916795,
        "cond_entropy-2-nopunct": 2.659361395204831,
        "distinct-3-nopunct": 0.9826613745560894,
        "vocab_size-3-nopunct": 4704,
        "unique-3-nopunct": 4633,
        "entropy-3-nopunct": 12.187748308605366,
        "cond_entropy-3-nopunct": 0.3455766021230233,
        "msttr-100": 0.73377,
        "msttr-100_nopunct": 0.76345,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.02682837192208747,
            "2": 0.14690026954177898,
            "3": 0.3,
            "4": 0.4724770642201835,
            "5": 0.5250379362670713,
            "6": 0.6169014084507042,
            "7": 0.6762295081967213,
            "8": 0.7310012062726177,
            "9": 0.7915343915343915,
            "10": 0.8713178294573644
        },
        "nist": 12.365759009195251,
        "bleu": 78.74022,
        "rouge1": {
            "precision": 0.86093,
            "recall": 0.78861,
            "fmeasure": 0.81145
        },
        "rouge2": {
            "precision": 0.74743,
            "recall": 0.67594,
            "fmeasure": 0.69738
        },
        "rougeL": {
            "precision": 0.83942,
            "recall": 0.77122,
            "fmeasure": 0.79268
        },
        "rougeLsum": {
            "precision": 0.83942,
            "recall": 0.77122,
            "fmeasure": 0.79268
        },
        "sari": 42.61504,
        "nubia": {
            "semantic_relation": 3.98836,
            "contradiction": 4.23361,
            "irrelevancy": 30.66105,
            "logical_agreement": 65.10535,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.8726,
            "nubia_score": 0.60978
        },
        "meteor": 0.4522843957100267,
        "bleurt": 0.09688,
        "bertscore": {
            "precision": 0.95755,
            "recall": 0.94529,
            "f1": 0.94713
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 453,
        "total_length": 4958,
        "mean_pred_length": 10.944812362030905,
        "std_pred_length": 3.7942736885353483,
        "median_pred_length": 10.0,
        "min_pred_length": 4,
        "max_pred_length": 24,
        "distinct-1": 0.18354175070592982,
        "vocab_size-1": 910,
        "unique-1": 473,
        "entropy-1": 7.641693719385514,
        "distinct-2": 0.4716981132075472,
        "vocab_size-2": 2125,
        "unique-2": 1416,
        "entropy-2": 10.342785794796978,
        "cond_entropy-2": 2.290561453738305,
        "distinct-3": 0.6695459032576505,
        "vocab_size-3": 2713,
        "unique-3": 2126,
        "entropy-3": 11.03391269817908,
        "cond_entropy-3": 0.7870828140724041,
        "total_length-nopunct": 4360,
        "mean_pred_length-nopunct": 9.624724061810154,
        "std_pred_length-nopunct": 3.534816764645617,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.20711009174311926,
        "vocab_size-1-nopunct": 903,
        "unique-1-nopunct": 472,
        "entropy-1-nopunct": 7.922427396354954,
        "distinct-2-nopunct": 0.4527770668031738,
        "vocab_size-2-nopunct": 1769,
        "unique-2-nopunct": 1171,
        "entropy-2-nopunct": 10.037374313163056,
        "cond_entropy-2-nopunct": 2.3906164179827196,
        "distinct-3-nopunct": 0.6580775911986103,
        "vocab_size-3-nopunct": 2273,
        "unique-3-nopunct": 1774,
        "entropy-3-nopunct": 10.757172513256462,
        "cond_entropy-3-nopunct": 0.8280574049531295,
        "msttr-100": 0.55163,
        "msttr-100_nopunct": 0.57209,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.22076923076923077,
            "2": 0.6385390428211587,
            "3": 0.8958804889090086,
            "4": 0.9473684210526315
        },
        "nist": 9.298902933147673,
        "bleu": 59.91504,
        "rouge1": {
            "precision": 0.82541,
            "recall": 0.78646,
            "fmeasure": 0.79842
        },
        "rouge2": {
            "precision": 0.60755,
            "recall": 0.57789,
            "fmeasure": 0.58658
        },
        "rougeL": {
            "precision": 0.74317,
            "recall": 0.70649,
            "fmeasure": 0.71741
        },
        "rougeLsum": {
            "precision": 0.74317,
            "recall": 0.70649,
            "fmeasure": 0.71741
        },
        "nubia": {
            "semantic_relation": 4.61472,
            "contradiction": 6.21846,
            "irrelevancy": 5.83156,
            "logical_agreement": 87.94998,
            "grammar_ref": 5.12238,
            "grammar_hyp": 5.26313,
            "nubia_score": 0.83031
        },
        "meteor": 0.4558688215064586,
        "bleurt": 0.38516,
        "bertscore": {
            "precision": 0.94825,
            "recall": 0.94428,
            "f1": 0.94522
        }
    },
    "xsum_challenge_test_nopunc_parent": {
        "predictions_file": "ByT5-base (Baseline)/xsum_test",
        "N": 500,
        "total_length": 10711,
        "mean_pred_length": 21.422,
        "std_pred_length": 3.4298565567673527,
        "median_pred_length": 22.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.2749509849687237,
        "vocab_size-1": 2945,
        "unique-1": 1899,
        "entropy-1": 9.125241046460488,
        "distinct-2": 0.735677210851043,
        "vocab_size-2": 7512,
        "unique-2": 6532,
        "entropy-2": 12.388472325317402,
        "cond_entropy-2": 3.1863359716730684,
        "distinct-3": 0.9286376274328082,
        "vocab_size-3": 9018,
        "unique-3": 8597,
        "entropy-3": 13.06140852823795,
        "cond_entropy-3": 0.6970150915961482,
        "total_length-nopunct": 10202,
        "mean_pred_length-nopunct": 20.404,
        "std_pred_length-nopunct": 3.563254691991579,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.28768868849245244,
        "vocab_size-1-nopunct": 2935,
        "unique-1-nopunct": 1898,
        "entropy-1-nopunct": 9.213201620812471,
        "distinct-2-nopunct": 0.7389198103483817,
        "vocab_size-2-nopunct": 7169,
        "unique-2-nopunct": 6253,
        "entropy-2-nopunct": 12.323719591370816,
        "cond_entropy-2-nopunct": 3.232411961273853,
        "distinct-3-nopunct": 0.933275374918496,
        "vocab_size-3-nopunct": 8588,
        "unique-3-nopunct": 8198,
        "entropy-3-nopunct": 13.003460230864206,
        "cond_entropy-3-nopunct": 0.7011898476789965,
        "msttr-100": 0.74458,
        "msttr-100_nopunct": 0.75176,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3482322217758136
        },
        "nist": 3.5321119827295164,
        "bleu": 9.32002,
        "rouge1": {
            "precision": 0.38662,
            "recall": 0.37536,
            "fmeasure": 0.37529
        },
        "rouge2": {
            "precision": 0.14847,
            "recall": 0.14287,
            "fmeasure": 0.14337
        },
        "rougeL": {
            "precision": 0.30017,
            "recall": 0.29188,
            "fmeasure": 0.29143
        },
        "rougeLsum": {
            "precision": 0.30017,
            "recall": 0.29188,
            "fmeasure": 0.29143
        },
        "nubia": {
            "semantic_relation": 2.68148,
            "contradiction": 28.56031,
            "irrelevancy": 60.97434,
            "logical_agreement": 10.46535,
            "grammar_ref": 3.78318,
            "grammar_hyp": 4.10377,
            "nubia_score": 0.3444
        },
        "meteor": 0.16181713360149252,
        "bleurt": -0.45442,
        "bertscore": {
            "precision": 0.82475,
            "recall": 0.81847,
            "f1": 0.82134
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-both_seen": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 1075,
        "total_length": 12215,
        "mean_pred_length": 11.362790697674418,
        "std_pred_length": 2.8340966532412875,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 21,
        "distinct-1": 0.20761358984854686,
        "vocab_size-1": 2536,
        "unique-1": 1320,
        "entropy-1": 9.128352588260913,
        "distinct-2": 0.4940754039497307,
        "vocab_size-2": 5504,
        "unique-2": 3770,
        "entropy-2": 11.70756334840909,
        "cond_entropy-2": 2.6461616840395097,
        "distinct-3": 0.6909090909090909,
        "vocab_size-3": 6954,
        "unique-3": 5479,
        "entropy-3": 12.452548129100455,
        "cond_entropy-3": 0.8623690147913612,
        "total_length-nopunct": 10379,
        "mean_pred_length-nopunct": 9.654883720930233,
        "std_pred_length-nopunct": 2.469339778152766,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.24356874458040273,
        "vocab_size-1-nopunct": 2528,
        "unique-1-nopunct": 1320,
        "entropy-1-nopunct": 9.671022192137988,
        "distinct-2-nopunct": 0.5448194325021496,
        "vocab_size-2-nopunct": 5069,
        "unique-2-nopunct": 3652,
        "entropy-2-nopunct": 11.677743039681417,
        "cond_entropy-2-nopunct": 2.220786025522821,
        "distinct-3-nopunct": 0.723417183132823,
        "vocab_size-3-nopunct": 5953,
        "unique-3-nopunct": 4860,
        "entropy-3-nopunct": 12.247380634056727,
        "cond_entropy-3-nopunct": 0.7021939997730006,
        "msttr-100": 0.7732,
        "msttr-100_nopunct": 0.84835,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.16349010797883903,
            "2": 0.35717284814555633,
            "3": 0.5013368983957219,
            "4": 0.7012987012987013,
            "5": 0.7567567567567568,
            "6": 0.8461538461538461,
            "7": 1.0
        },
        "nist": 1.7050036625592198,
        "bleu": 22.3644,
        "rouge1": {
            "precision": 0.28514,
            "recall": 0.23402,
            "fmeasure": 0.24845
        },
        "rouge2": {
            "precision": 0.12906,
            "recall": 0.1013,
            "fmeasure": 0.10854
        },
        "rougeL": {
            "precision": 0.27801,
            "recall": 0.2277,
            "fmeasure": 0.24181
        },
        "rougeLsum": {
            "precision": 0.27801,
            "recall": 0.2277,
            "fmeasure": 0.24181
        },
        "nubia": {
            "semantic_relation": 3.60247,
            "contradiction": 21.58813,
            "irrelevancy": 22.50426,
            "logical_agreement": 55.90761,
            "grammar_ref": 2.64396,
            "grammar_hyp": 2.72263,
            "nubia_score": 0.69912
        },
        "meteor": 0.4017589041420168,
        "bleurt": 0.10271,
        "bertscore": {
            "precision": 0.95097,
            "recall": 0.91411,
            "f1": 0.93132
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 4,
        "total_length": 29,
        "mean_pred_length": 7.25,
        "std_pred_length": 1.6393596310755,
        "median_pred_length": 6.5,
        "min_pred_length": 6,
        "max_pred_length": 10,
        "distinct-1": 0.8275862068965517,
        "vocab_size-1": 24,
        "unique-1": 21,
        "entropy-1": 4.444187891679296,
        "distinct-2": 0.92,
        "vocab_size-2": 23,
        "unique-2": 21,
        "entropy-2": 4.4838561897747224,
        "cond_entropy-2": -0.21412480535284767,
        "distinct-3": 0.9523809523809523,
        "vocab_size-3": 20,
        "unique-3": 19,
        "entropy-3": 4.297079327540665,
        "cond_entropy-3": -0.25153876699596434,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 6.25,
        "std_pred_length-nopunct": 1.6393596310755,
        "median_pred_length-nopunct": 5.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.92,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.4838561897747224,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.297079327540665,
        "cond_entropy-2-nopunct": -0.25153876699596434,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.3048545815284209,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.5333333333333333,
            "2": 0.38461538461538464,
            "3": 1.0
        },
        "nist": 3.7320936607749555,
        "bleu": 52.73688,
        "rouge1": {
            "precision": 0.25,
            "recall": 0.25,
            "fmeasure": 0.25
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.25,
            "fmeasure": 0.25
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.25,
            "fmeasure": 0.25
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.25,
            "fmeasure": 0.25
        },
        "nubia": {
            "semantic_relation": 4.30622,
            "contradiction": 30.19447,
            "irrelevancy": 17.55284,
            "logical_agreement": 52.25269,
            "grammar_ref": 3.0388,
            "grammar_hyp": 3.1634,
            "nubia_score": 0.83751
        },
        "meteor": 0.7238919888291062,
        "bleurt": 0.42664,
        "bertscore": {
            "precision": 0.96443,
            "recall": 0.94582,
            "f1": 0.95128
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_22": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.0433214693062285,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.09090909090909091,
            "3": 0.6666666666666666
        },
        "nist": 1.311528584089974,
        "bleu": 10.3436,
        "rouge1": {
            "precision": 0.5641,
            "recall": 0.40952,
            "fmeasure": 0.47138
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.0924,
            "fmeasure": 0.11777
        },
        "rougeL": {
            "precision": 0.41026,
            "recall": 0.29524,
            "fmeasure": 0.34119
        },
        "rougeLsum": {
            "precision": 0.41026,
            "recall": 0.29524,
            "fmeasure": 0.34119
        },
        "nubia": {
            "semantic_relation": 3.7406,
            "contradiction": 0.42224,
            "irrelevancy": 71.38966,
            "logical_agreement": 28.1881,
            "grammar_ref": 4.03834,
            "grammar_hyp": 4.20189,
            "nubia_score": 0.56257
        },
        "meteor": 0.22011360018034345,
        "bleurt": 0.01348,
        "bertscore": {
            "precision": 0.87779,
            "recall": 0.86903,
            "f1": 0.86989
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 214,
        "total_length": 2674,
        "mean_pred_length": 12.495327102803738,
        "std_pred_length": 2.5444601056908622,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 21,
        "distinct-1": 0.36649214659685864,
        "vocab_size-1": 980,
        "unique-1": 616,
        "entropy-1": 8.486164266981957,
        "distinct-2": 0.6898373983739837,
        "vocab_size-2": 1697,
        "unique-2": 1327,
        "entropy-2": 10.401404148276002,
        "cond_entropy-2": 2.069900622748524,
        "distinct-3": 0.8419412288512912,
        "vocab_size-3": 1891,
        "unique-3": 1633,
        "entropy-3": 10.775175913014852,
        "cond_entropy-3": 0.4359116596560725,
        "total_length-nopunct": 2272,
        "mean_pred_length-nopunct": 10.616822429906541,
        "std_pred_length-nopunct": 2.003011096936353,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.42869718309859156,
        "vocab_size-1-nopunct": 974,
        "unique-1-nopunct": 616,
        "entropy-1-nopunct": 8.935052917199112,
        "distinct-2-nopunct": 0.7356656948493683,
        "vocab_size-2-nopunct": 1514,
        "unique-2-nopunct": 1217,
        "entropy-2-nopunct": 10.307191677178261,
        "cond_entropy-2-nopunct": 1.5167583033790288,
        "distinct-3-nopunct": 0.8633405639913232,
        "vocab_size-3-nopunct": 1592,
        "unique-3-nopunct": 1406,
        "entropy-3-nopunct": 10.540076579288403,
        "cond_entropy-3-nopunct": 0.2968399525985871,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.83409,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.13020247469066368,
            "2": 0.3019911504424779,
            "3": 0.441025641025641
        },
        "nist": 0.5147837168297293,
        "bleu": 14.63712,
        "rouge1": {
            "precision": 0.26659,
            "recall": 0.18812,
            "fmeasure": 0.21119
        },
        "rouge2": {
            "precision": 0.10267,
            "recall": 0.05878,
            "fmeasure": 0.07033
        },
        "rougeL": {
            "precision": 0.25647,
            "recall": 0.17936,
            "fmeasure": 0.20189
        },
        "rougeLsum": {
            "precision": 0.25647,
            "recall": 0.17936,
            "fmeasure": 0.20189
        },
        "nubia": {
            "semantic_relation": 3.34832,
            "contradiction": 23.16852,
            "irrelevancy": 22.75229,
            "logical_agreement": 54.0792,
            "grammar_ref": 2.5317,
            "grammar_hyp": 2.65438,
            "nubia_score": 0.62738
        },
        "meteor": 0.323250831076295,
        "bleurt": -0.0193,
        "bertscore": {
            "precision": 0.94137,
            "recall": 0.88557,
            "f1": 0.91197
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 19,
        "total_length": 216,
        "mean_pred_length": 11.368421052631579,
        "std_pred_length": 3.557209526045432,
        "median_pred_length": 10.0,
        "min_pred_length": 6,
        "max_pred_length": 18,
        "distinct-1": 0.5324074074074074,
        "vocab_size-1": 115,
        "unique-1": 78,
        "entropy-1": 6.355766713428592,
        "distinct-2": 0.8020304568527918,
        "vocab_size-2": 158,
        "unique-2": 131,
        "entropy-2": 7.170175931087542,
        "cond_entropy-2": 0.680314268349145,
        "distinct-3": 0.8707865168539326,
        "vocab_size-3": 155,
        "unique-3": 136,
        "entropy-3": 7.194834554561879,
        "cond_entropy-3": 0.027948746390099297,
        "total_length-nopunct": 175,
        "mean_pred_length-nopunct": 9.210526315789474,
        "std_pred_length-nopunct": 2.876016019434579,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.6285714285714286,
        "vocab_size-1-nopunct": 110,
        "unique-1-nopunct": 78,
        "entropy-1-nopunct": 6.483689755391452,
        "distinct-2-nopunct": 0.8589743589743589,
        "vocab_size-2-nopunct": 134,
        "unique-2-nopunct": 117,
        "entropy-2-nopunct": 6.976013356641172,
        "cond_entropy-2-nopunct": 0.5310611382336129,
        "distinct-3-nopunct": 0.9197080291970803,
        "vocab_size-3-nopunct": 126,
        "unique-3-nopunct": 115,
        "entropy-3-nopunct": 6.937448141354672,
        "cond_entropy-3-nopunct": -0.0029565409638354096,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.67,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.22699386503067484,
            "2": 0.4375,
            "3": 0.5869565217391305
        },
        "nist": 3.7042011098730354,
        "bleu": 33.76799,
        "rouge1": {
            "precision": 0.34649,
            "recall": 0.25689,
            "fmeasure": 0.28538
        },
        "rouge2": {
            "precision": 0.3136,
            "recall": 0.2231,
            "fmeasure": 0.24561
        },
        "rougeL": {
            "precision": 0.32719,
            "recall": 0.24937,
            "fmeasure": 0.27427
        },
        "rougeLsum": {
            "precision": 0.32719,
            "recall": 0.24937,
            "fmeasure": 0.27427
        },
        "nubia": {
            "semantic_relation": 3.74547,
            "contradiction": 23.1365,
            "irrelevancy": 24.87848,
            "logical_agreement": 51.98501,
            "grammar_ref": 2.97301,
            "grammar_hyp": 2.96083,
            "nubia_score": 0.73217
        },
        "meteor": 0.495772722310188,
        "bleurt": 0.07428,
        "bertscore": {
            "precision": 0.94923,
            "recall": 0.92916,
            "f1": 0.93778
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_27": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 40,
        "total_length": 597,
        "mean_pred_length": 14.925,
        "std_pred_length": 5.671805268166389,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 29,
        "distinct-1": 0.4639865996649916,
        "vocab_size-1": 277,
        "unique-1": 228,
        "entropy-1": 6.941154362970355,
        "distinct-2": 0.7989228007181328,
        "vocab_size-2": 445,
        "unique-2": 407,
        "entropy-2": 8.515400857923485,
        "cond_entropy-2": 1.403869493660288,
        "distinct-3": 0.8916827852998066,
        "vocab_size-3": 461,
        "unique-3": 441,
        "entropy-3": 8.697166432543014,
        "cond_entropy-3": 0.21026756953687012,
        "total_length-nopunct": 513,
        "mean_pred_length-nopunct": 12.825,
        "std_pred_length-nopunct": 4.989426319728551,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5282651072124757,
        "vocab_size-1-nopunct": 271,
        "unique-1-nopunct": 227,
        "entropy-1-nopunct": 7.102780552501925,
        "distinct-2-nopunct": 0.8076109936575053,
        "vocab_size-2-nopunct": 382,
        "unique-2-nopunct": 354,
        "entropy-2-nopunct": 8.292680568231138,
        "cond_entropy-2-nopunct": 1.307650003544479,
        "distinct-3-nopunct": 0.8937644341801386,
        "vocab_size-3-nopunct": 387,
        "unique-3-nopunct": 371,
        "entropy-3-nopunct": 8.449185021821137,
        "cond_entropy-3-nopunct": 0.2016562023264936,
        "msttr-100": 0.646,
        "msttr-100_nopunct": 0.686,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.38461538461538464,
            "3": 0.7470449172576832
        },
        "nist": 6.625970810566336,
        "bleu": 51.57618,
        "rouge1": {
            "precision": 0.78022,
            "recall": 0.73025,
            "fmeasure": 0.74116
        },
        "rouge2": {
            "precision": 0.58871,
            "recall": 0.5471,
            "fmeasure": 0.55647
        },
        "rougeL": {
            "precision": 0.69101,
            "recall": 0.64688,
            "fmeasure": 0.65579
        },
        "rougeLsum": {
            "precision": 0.69101,
            "recall": 0.64688,
            "fmeasure": 0.65579
        },
        "nubia": {
            "semantic_relation": 4.12952,
            "contradiction": 7.36683,
            "irrelevancy": 26.7817,
            "logical_agreement": 65.85148,
            "grammar_ref": 4.3823,
            "grammar_hyp": 4.51396,
            "nubia_score": 0.72029
        },
        "meteor": 0.3919891445158707,
        "bleurt": 0.30831,
        "bertscore": {
            "precision": 0.93068,
            "recall": 0.92552,
            "f1": 0.92639
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_challenge_test_turk_backtranslation",
        "N": 359,
        "total_length": 5926,
        "mean_pred_length": 16.506963788300837,
        "std_pred_length": 6.131277998105584,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.37310158623017214,
        "vocab_size-1": 2211,
        "unique-1": 1646,
        "entropy-1": 8.966005382687754,
        "distinct-2": 0.8406682234596731,
        "vocab_size-2": 4680,
        "unique-2": 4357,
        "entropy-2": 11.88451350559732,
        "cond_entropy-2": 2.696868499991214,
        "distinct-3": 0.9652457757296466,
        "vocab_size-3": 5027,
        "unique-3": 4941,
        "entropy-3": 12.23601208527774,
        "cond_entropy-3": 0.37130029676507864,
        "total_length-nopunct": 5314,
        "mean_pred_length-nopunct": 14.802228412256268,
        "std_pred_length-nopunct": 5.683127110389294,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.41400075272864134,
        "vocab_size-1-nopunct": 2200,
        "unique-1-nopunct": 1645,
        "entropy-1-nopunct": 9.239235693893988,
        "distinct-2-nopunct": 0.8621594349142281,
        "vocab_size-2-nopunct": 4272,
        "unique-2-nopunct": 4011,
        "entropy-2-nopunct": 11.802042369237661,
        "cond_entropy-2-nopunct": 2.714835107554485,
        "distinct-3-nopunct": 0.9812880765883377,
        "vocab_size-3-nopunct": 4510,
        "unique-3-nopunct": 4446,
        "entropy-3-nopunct": 12.123943957314712,
        "cond_entropy-3-nopunct": 0.3491318922927298,
        "msttr-100": 0.72492,
        "msttr-100_nopunct": 0.75868,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_backtranslation.json",
        "local_recall": {
            "1": 0.054541595925297115,
            "2": 0.14814814814814814,
            "3": 0.24945295404814005,
            "4": 0.2820919175911252,
            "5": 0.34683281412253375,
            "6": 0.47342995169082125,
            "7": 0.6422298587247041
        },
        "nist": 6.2246004191381745,
        "bleu": 35.13328,
        "rouge1": {
            "precision": 0.6845,
            "recall": 0.57723,
            "fmeasure": 0.61141
        },
        "rouge2": {
            "precision": 0.44097,
            "recall": 0.36677,
            "fmeasure": 0.38891
        },
        "rougeL": {
            "precision": 0.62728,
            "recall": 0.5291,
            "fmeasure": 0.56021
        },
        "rougeLsum": {
            "precision": 0.62728,
            "recall": 0.5291,
            "fmeasure": 0.56021
        },
        "sari": 41.55382,
        "nubia": {
            "semantic_relation": 3.44963,
            "contradiction": 14.22608,
            "irrelevancy": 25.28279,
            "logical_agreement": 60.49112,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.2032,
            "nubia_score": 0.47835
        },
        "meteor": 0.2955224162737972,
        "bleurt": -0.19501,
        "bertscore": {
            "precision": 0.90094,
            "recall": 0.87949,
            "f1": 0.88683
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_10": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 162,
        "total_length": 2438,
        "mean_pred_length": 15.049382716049383,
        "std_pred_length": 5.081803010859703,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.347005742411813,
        "vocab_size-1": 846,
        "unique-1": 613,
        "entropy-1": 8.023653047628079,
        "distinct-2": 0.7552724077328646,
        "vocab_size-2": 1719,
        "unique-2": 1500,
        "entropy-2": 10.41119103794718,
        "cond_entropy-2": 2.1134163542359308,
        "distinct-3": 0.9115421002838221,
        "vocab_size-3": 1927,
        "unique-3": 1830,
        "entropy-3": 10.813414433285534,
        "cond_entropy-3": 0.3971659640908974,
        "total_length-nopunct": 2114,
        "mean_pred_length-nopunct": 13.049382716049383,
        "std_pred_length-nopunct": 4.474623191440848,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.3959318826868496,
        "vocab_size-1-nopunct": 837,
        "unique-1-nopunct": 610,
        "entropy-1-nopunct": 8.349418342420654,
        "distinct-2-nopunct": 0.7838114754098361,
        "vocab_size-2-nopunct": 1530,
        "unique-2-nopunct": 1353,
        "entropy-2-nopunct": 10.274898224526227,
        "cond_entropy-2-nopunct": 2.0312496773122937,
        "distinct-3-nopunct": 0.9256983240223464,
        "vocab_size-3-nopunct": 1657,
        "unique-3-nopunct": 1591,
        "entropy-3-nopunct": 10.60712427901955,
        "cond_entropy-3-nopunct": 0.34948091846191864,
        "msttr-100": 0.70458,
        "msttr-100_nopunct": 0.76619,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19724770642201836,
            "2": 0.3914027149321267,
            "3": 0.7520661157024794
        },
        "nist": 7.451966680620618,
        "bleu": 41.40272,
        "rouge1": {
            "precision": 0.72345,
            "recall": 0.71881,
            "fmeasure": 0.70843
        },
        "rouge2": {
            "precision": 0.48044,
            "recall": 0.47174,
            "fmeasure": 0.46638
        },
        "rougeL": {
            "precision": 0.60415,
            "recall": 0.59829,
            "fmeasure": 0.58967
        },
        "rougeLsum": {
            "precision": 0.60415,
            "recall": 0.59829,
            "fmeasure": 0.58967
        },
        "nubia": {
            "semantic_relation": 4.17139,
            "contradiction": 6.67273,
            "irrelevancy": 31.99148,
            "logical_agreement": 61.3358,
            "grammar_ref": 4.55751,
            "grammar_hyp": 4.471,
            "nubia_score": 0.7408
        },
        "meteor": 0.3818006624838675,
        "bleurt": 0.26597,
        "bertscore": {
            "precision": 0.92098,
            "recall": 0.92161,
            "f1": 0.91914
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_48": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 114,
        "total_length": 1856,
        "mean_pred_length": 16.280701754385966,
        "std_pred_length": 4.919543503158663,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.4698275862068966,
        "vocab_size-1": 872,
        "unique-1": 695,
        "entropy-1": 8.296573059589386,
        "distinct-2": 0.8708381171067738,
        "vocab_size-2": 1517,
        "unique-2": 1400,
        "entropy-2": 10.400518730879023,
        "cond_entropy-2": 1.8817167899487204,
        "distinct-3": 0.9631449631449631,
        "vocab_size-3": 1568,
        "unique-3": 1517,
        "entropy-3": 10.590399457539542,
        "cond_entropy-3": 0.19391260675959987,
        "total_length-nopunct": 1627,
        "mean_pred_length-nopunct": 14.271929824561404,
        "std_pred_length-nopunct": 4.638294241287374,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5304240934234788,
        "vocab_size-1-nopunct": 863,
        "unique-1-nopunct": 693,
        "entropy-1-nopunct": 8.569486867413442,
        "distinct-2-nopunct": 0.8869795109054858,
        "vocab_size-2-nopunct": 1342,
        "unique-2-nopunct": 1249,
        "entropy-2-nopunct": 10.240400918540587,
        "cond_entropy-2-nopunct": 1.7864698393994638,
        "distinct-3-nopunct": 0.9714081486776269,
        "vocab_size-3-nopunct": 1359,
        "unique-3-nopunct": 1323,
        "entropy-3-nopunct": 10.390838181397399,
        "cond_entropy-3-nopunct": 0.17245203792370198,
        "msttr-100": 0.73222,
        "msttr-100_nopunct": 0.77812,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.208955223880597,
            "2": 0.4467005076142132,
            "3": 0.7541703248463565
        },
        "nist": 7.287746964170085,
        "bleu": 38.41106,
        "rouge1": {
            "precision": 0.7348,
            "recall": 0.7026,
            "fmeasure": 0.70653
        },
        "rouge2": {
            "precision": 0.48086,
            "recall": 0.45606,
            "fmeasure": 0.45949
        },
        "rougeL": {
            "precision": 0.61249,
            "recall": 0.58539,
            "fmeasure": 0.58828
        },
        "rougeLsum": {
            "precision": 0.61249,
            "recall": 0.58539,
            "fmeasure": 0.58828
        },
        "nubia": {
            "semantic_relation": 4.12209,
            "contradiction": 9.31345,
            "irrelevancy": 33.69964,
            "logical_agreement": 56.98691,
            "grammar_ref": 4.6714,
            "grammar_hyp": 4.62259,
            "nubia_score": 0.71081
        },
        "meteor": 0.36949890890262344,
        "bleurt": 0.17088,
        "bertscore": {
            "precision": 0.91795,
            "recall": 0.91865,
            "f1": 0.91693
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_28": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 77,
        "total_length": 1285,
        "mean_pred_length": 16.68831168831169,
        "std_pred_length": 5.012347715106775,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 28,
        "distinct-1": 0.4848249027237354,
        "vocab_size-1": 623,
        "unique-1": 498,
        "entropy-1": 7.952920801776999,
        "distinct-2": 0.8642384105960265,
        "vocab_size-2": 1044,
        "unique-2": 962,
        "entropy-2": 9.859770108332857,
        "cond_entropy-2": 1.6829722835146628,
        "distinct-3": 0.9425287356321839,
        "vocab_size-3": 1066,
        "unique-3": 1030,
        "entropy-3": 9.998743094592031,
        "cond_entropy-3": 0.1404275323088051,
        "total_length-nopunct": 1114,
        "mean_pred_length-nopunct": 14.467532467532468,
        "std_pred_length-nopunct": 4.694800704134656,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5493716337522442,
        "vocab_size-1-nopunct": 612,
        "unique-1-nopunct": 495,
        "entropy-1-nopunct": 8.18427196234325,
        "distinct-2-nopunct": 0.8804243008678881,
        "vocab_size-2-nopunct": 913,
        "unique-2-nopunct": 853,
        "entropy-2-nopunct": 9.676255485737645,
        "cond_entropy-2-nopunct": 1.5924895766467992,
        "distinct-3-nopunct": 0.9572916666666667,
        "vocab_size-3-nopunct": 919,
        "unique-3-nopunct": 894,
        "entropy-3-nopunct": 9.805277184127636,
        "cond_entropy-3-nopunct": 0.14298516595570349,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.76545,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22178988326848248,
            "2": 0.47674418604651164,
            "3": 0.8179453836150845
        },
        "nist": 7.764255824716075,
        "bleu": 51.74405,
        "rouge1": {
            "precision": 0.77985,
            "recall": 0.75385,
            "fmeasure": 0.7562
        },
        "rouge2": {
            "precision": 0.56624,
            "recall": 0.54507,
            "fmeasure": 0.54757
        },
        "rougeL": {
            "precision": 0.69278,
            "recall": 0.67527,
            "fmeasure": 0.6743
        },
        "rougeLsum": {
            "precision": 0.69278,
            "recall": 0.67527,
            "fmeasure": 0.6743
        },
        "nubia": {
            "semantic_relation": 4.16964,
            "contradiction": 6.90936,
            "irrelevancy": 30.46639,
            "logical_agreement": 62.62424,
            "grammar_ref": 4.69344,
            "grammar_hyp": 4.67174,
            "nubia_score": 0.72438
        },
        "meteor": 0.41015724735815534,
        "bleurt": 0.26671,
        "bertscore": {
            "precision": 0.93454,
            "recall": 0.93162,
            "f1": 0.93116
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 4,
        "total_length": 46,
        "mean_pred_length": 11.5,
        "std_pred_length": 1.118033988749895,
        "median_pred_length": 11.5,
        "min_pred_length": 10,
        "max_pred_length": 13,
        "distinct-1": 0.6739130434782609,
        "vocab_size-1": 31,
        "unique-1": 19,
        "entropy-1": 4.811499184270849,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 36,
        "unique-2": 30,
        "entropy-2": 5.106603137064476,
        "cond_entropy-2": 0.3629194548684968,
        "distinct-3": 0.9473684210526315,
        "vocab_size-3": 36,
        "unique-3": 34,
        "entropy-3": 5.142664355548852,
        "cond_entropy-3": 0.06613640645429875,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 9.75,
        "std_pred_length-nopunct": 1.479019945774904,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.717948717948718,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.7019435649606205,
        "distinct-2-nopunct": 0.8857142857142857,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.900711588373536,
        "cond_entropy-2-nopunct": 0.2368775838588172,
        "distinct-3-nopunct": 0.967741935483871,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.889680181354619,
        "cond_entropy-3-nopunct": 0.01846168053868283,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.38461538461538464,
            "3": 0.46153846153846156
        },
        "nist": 2.1501536220198947,
        "bleu": 23.04198,
        "rouge1": {
            "precision": 0.39583,
            "recall": 0.32273,
            "fmeasure": 0.33203
        },
        "rouge2": {
            "precision": 0.31667,
            "recall": 0.2412,
            "fmeasure": 0.24786
        },
        "rougeL": {
            "precision": 0.39583,
            "recall": 0.32273,
            "fmeasure": 0.33203
        },
        "rougeLsum": {
            "precision": 0.39583,
            "recall": 0.32273,
            "fmeasure": 0.33203
        },
        "nubia": {
            "semantic_relation": 3.63626,
            "contradiction": 20.34996,
            "irrelevancy": 26.02255,
            "logical_agreement": 53.62749,
            "grammar_ref": 2.93748,
            "grammar_hyp": 3.00976,
            "nubia_score": 0.65525
        },
        "meteor": 0.40185496861016257,
        "bleurt": 0.2177,
        "bertscore": {
            "precision": 0.95678,
            "recall": 0.92569,
            "f1": 0.94055
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_11": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 36,
        "total_length": 599,
        "mean_pred_length": 16.63888888888889,
        "std_pred_length": 5.864927667346792,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.4323873121869783,
        "vocab_size-1": 259,
        "unique-1": 206,
        "entropy-1": 6.913337248839053,
        "distinct-2": 0.7761989342806395,
        "vocab_size-2": 437,
        "unique-2": 383,
        "entropy-2": 8.514117949173428,
        "cond_entropy-2": 1.4379492825357814,
        "distinct-3": 0.9127134724857685,
        "vocab_size-3": 481,
        "unique-3": 448,
        "entropy-3": 8.846604146856448,
        "cond_entropy-3": 0.3363930399752671,
        "total_length-nopunct": 495,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 4.63306354130588,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.5111111111111111,
        "vocab_size-1-nopunct": 253,
        "unique-1-nopunct": 205,
        "entropy-1-nopunct": 7.084597641748197,
        "distinct-2-nopunct": 0.8257080610021786,
        "vocab_size-2-nopunct": 379,
        "unique-2-nopunct": 336,
        "entropy-2-nopunct": 8.412473451443317,
        "cond_entropy-2-nopunct": 1.3879765085281348,
        "distinct-3-nopunct": 0.9267139479905437,
        "vocab_size-3-nopunct": 392,
        "unique-3-nopunct": 369,
        "entropy-3-nopunct": 8.562505992569141,
        "cond_entropy-3-nopunct": 0.17479747755841707,
        "msttr-100": 0.632,
        "msttr-100_nopunct": 0.6875,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23684210526315788,
            "2": 0.5943396226415094,
            "3": 0.782991202346041
        },
        "nist": 6.9286099212490635,
        "bleu": 53.89999,
        "rouge1": {
            "precision": 0.79769,
            "recall": 0.76936,
            "fmeasure": 0.77595
        },
        "rouge2": {
            "precision": 0.61917,
            "recall": 0.59826,
            "fmeasure": 0.6019
        },
        "rougeL": {
            "precision": 0.72396,
            "recall": 0.70729,
            "fmeasure": 0.70842
        },
        "rougeLsum": {
            "precision": 0.72396,
            "recall": 0.70729,
            "fmeasure": 0.70842
        },
        "nubia": {
            "semantic_relation": 4.14794,
            "contradiction": 8.01664,
            "irrelevancy": 21.98143,
            "logical_agreement": 70.00192,
            "grammar_ref": 3.9304,
            "grammar_hyp": 3.85799,
            "nubia_score": 0.77621
        },
        "meteor": 0.4428461935073952,
        "bleurt": 0.44718,
        "bertscore": {
            "precision": 0.94851,
            "recall": 0.94642,
            "f1": 0.94598
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_23": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 47,
        "mean_pred_length": 23.5,
        "std_pred_length": 7.5,
        "median_pred_length": 23.5,
        "min_pred_length": 16,
        "max_pred_length": 31,
        "distinct-1": 0.8085106382978723,
        "vocab_size-1": 38,
        "unique-1": 33,
        "entropy-1": 5.0787478308989105,
        "distinct-2": 0.9777777777777777,
        "vocab_size-2": 44,
        "unique-2": 43,
        "entropy-2": 5.447408651885229,
        "cond_entropy-2": 0.38980931079871,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.019076713720599832,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 20.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 20.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.8780487804878049,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.095237675297022,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.285402218862247,
        "cond_entropy-2-nopunct": 0.20361656045348464,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.07594885323329875,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.2857142857142857,
            "3": 0.7894736842105263
        },
        "nist": 2.8220861956034216,
        "bleu": 19.13077,
        "rouge1": {
            "precision": 0.53984,
            "recall": 0.48062,
            "fmeasure": 0.50415
        },
        "rouge2": {
            "precision": 0.23026,
            "recall": 0.20006,
            "fmeasure": 0.21275
        },
        "rougeL": {
            "precision": 0.37729,
            "recall": 0.3304,
            "fmeasure": 0.34929
        },
        "rougeLsum": {
            "precision": 0.37729,
            "recall": 0.3304,
            "fmeasure": 0.34929
        },
        "nubia": {
            "semantic_relation": 2.48506,
            "contradiction": 61.41375,
            "irrelevancy": 24.59589,
            "logical_agreement": 13.99036,
            "grammar_ref": 4.17,
            "grammar_hyp": 4.03332,
            "nubia_score": 0.271
        },
        "meteor": 0.23989164406626187,
        "bleurt": -0.09791,
        "bertscore": {
            "precision": 0.87273,
            "recall": 0.8518,
            "f1": 0.86029
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_29": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 7,
        "total_length": 111,
        "mean_pred_length": 15.857142857142858,
        "std_pred_length": 7.059513771774763,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.6846846846846847,
        "vocab_size-1": 76,
        "unique-1": 62,
        "entropy-1": 5.899819245213648,
        "distinct-2": 0.9807692307692307,
        "vocab_size-2": 102,
        "unique-2": 100,
        "entropy-2": 6.661978179679561,
        "cond_entropy-2": 0.6604093846160065,
        "distinct-3": 1.0,
        "vocab_size-3": 97,
        "unique-3": 97,
        "entropy-3": 6.599912842187142,
        "cond_entropy-3": -0.05928976255190259,
        "total_length-nopunct": 97,
        "mean_pred_length-nopunct": 13.857142857142858,
        "std_pred_length-nopunct": 6.620931557860838,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7319587628865979,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 5.848429821675991,
        "distinct-2-nopunct": 0.9777777777777777,
        "vocab_size-2-nopunct": 88,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.447408651885218,
        "cond_entropy-2-nopunct": 0.6574275095823372,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 83,
        "unique-3-nopunct": 83,
        "entropy-3-nopunct": 6.375039431346932,
        "cond_entropy-3-nopunct": -0.06862089389841255,
        "msttr-100": 0.69,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.3448275862068966,
            "3": 0.7796610169491526
        },
        "nist": 4.685925842722773,
        "bleu": 40.1304,
        "rouge1": {
            "precision": 0.7505,
            "recall": 0.74971,
            "fmeasure": 0.74558
        },
        "rouge2": {
            "precision": 0.55858,
            "recall": 0.55444,
            "fmeasure": 0.55269
        },
        "rougeL": {
            "precision": 0.66633,
            "recall": 0.66711,
            "fmeasure": 0.66314
        },
        "rougeLsum": {
            "precision": 0.66633,
            "recall": 0.66711,
            "fmeasure": 0.66314
        },
        "nubia": {
            "semantic_relation": 4.27443,
            "contradiction": 25.47281,
            "irrelevancy": 9.8729,
            "logical_agreement": 64.65428,
            "grammar_ref": 4.56703,
            "grammar_hyp": 4.39689,
            "nubia_score": 0.75677
        },
        "meteor": 0.3516548211192549,
        "bleurt": 0.32995,
        "bertscore": {
            "precision": 0.92787,
            "recall": 0.93815,
            "f1": 0.93295
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_challenge_test_turk_bfp02",
        "N": 359,
        "total_length": 6036,
        "mean_pred_length": 16.813370473537603,
        "std_pred_length": 6.075774036621705,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.40092776673293573,
        "vocab_size-1": 2420,
        "unique-1": 1869,
        "entropy-1": 9.189812577137431,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 4866,
        "unique-2": 4553,
        "entropy-2": 11.981821719802388,
        "cond_entropy-2": 2.5744809435929352,
        "distinct-3": 0.9687852576156449,
        "vocab_size-3": 5152,
        "unique-3": 5067,
        "entropy-3": 12.275582700586426,
        "cond_entropy-3": 0.3171170837197353,
        "total_length-nopunct": 5422,
        "mean_pred_length-nopunct": 15.103064066852367,
        "std_pred_length-nopunct": 5.648276447129114,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.44411656215418666,
        "vocab_size-1-nopunct": 2408,
        "unique-1-nopunct": 1867,
        "entropy-1-nopunct": 9.473897044670517,
        "distinct-2-nopunct": 0.8751728224372901,
        "vocab_size-2-nopunct": 4431,
        "unique-2-nopunct": 4169,
        "entropy-2-nopunct": 11.894450385237356,
        "cond_entropy-2-nopunct": 2.565821730198402,
        "distinct-3-nopunct": 0.9823554421768708,
        "vocab_size-3-nopunct": 4621,
        "unique-3-nopunct": 4551,
        "entropy-3-nopunct": 12.16180266679975,
        "cond_entropy-3-nopunct": 0.2916486565880235,
        "msttr-100": 0.74683,
        "msttr-100_nopunct": 0.78167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp02.json",
        "local_recall": {
            "1": 0.03713921901528013,
            "2": 0.13537675606641125,
            "3": 0.2800875273522976,
            "4": 0.393026941362916,
            "5": 0.48390446521287644,
            "6": 0.5917874396135265,
            "7": 0.7140129820542191
        },
        "nist": 7.7440366971635575,
        "bleu": 49.90329,
        "rouge1": {
            "precision": 0.76853,
            "recall": 0.6537,
            "fmeasure": 0.69071
        },
        "rouge2": {
            "precision": 0.57913,
            "recall": 0.48495,
            "fmeasure": 0.51486
        },
        "rougeL": {
            "precision": 0.73584,
            "recall": 0.62632,
            "fmeasure": 0.66182
        },
        "rougeLsum": {
            "precision": 0.73584,
            "recall": 0.62632,
            "fmeasure": 0.66182
        },
        "sari": 44.70449,
        "nubia": {
            "semantic_relation": 3.82318,
            "contradiction": 9.29395,
            "irrelevancy": 17.6956,
            "logical_agreement": 73.01044,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.71999,
            "nubia_score": 0.50742
        },
        "meteor": 0.3435327663230931,
        "bleurt": -0.34665,
        "bertscore": {
            "precision": 0.90828,
            "recall": 0.90133,
            "f1": 0.90121
        }
    },
    "schema_guided_dialog_challenge_test_backtranslation": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_challenge_test_backtranslation",
        "N": 500,
        "total_length": 6186,
        "mean_pred_length": 12.372,
        "std_pred_length": 6.705640610709763,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 33,
        "distinct-1": 0.16731328806983511,
        "vocab_size-1": 1035,
        "unique-1": 585,
        "entropy-1": 7.872972413490223,
        "distinct-2": 0.5124868097080548,
        "vocab_size-2": 2914,
        "unique-2": 2051,
        "entropy-2": 10.808800291168616,
        "cond_entropy-2": 2.6690058827726477,
        "distinct-3": 0.7394909371384497,
        "vocab_size-3": 3835,
        "unique-3": 3197,
        "entropy-3": 11.593125715065101,
        "cond_entropy-3": 0.7983350212262162,
        "total_length-nopunct": 5409,
        "mean_pred_length-nopunct": 10.818,
        "std_pred_length-nopunct": 6.194261537907486,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.18894435200591606,
        "vocab_size-1-nopunct": 1022,
        "unique-1-nopunct": 582,
        "entropy-1-nopunct": 8.092010289848288,
        "distinct-2-nopunct": 0.5310653900998167,
        "vocab_size-2-nopunct": 2607,
        "unique-2-nopunct": 1890,
        "entropy-2-nopunct": 10.638163782296914,
        "cond_entropy-2-nopunct": 2.6853129136194682,
        "distinct-3-nopunct": 0.7536856430029485,
        "vocab_size-3-nopunct": 3323,
        "unique-3-nopunct": 2824,
        "entropy-3-nopunct": 11.38240472827517,
        "cond_entropy-3-nopunct": 0.7795829515919797,
        "msttr-100": 0.69164,
        "msttr-100_nopunct": 0.72574,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_backtranslation.json",
        "local_recall": {
            "1": 0.533753709198813
        },
        "nist": 5.6657169520801896,
        "bleu": 28.77674,
        "rouge1": {
            "precision": 0.53591,
            "recall": 0.51056,
            "fmeasure": 0.50972
        },
        "rouge2": {
            "precision": 0.3131,
            "recall": 0.29977,
            "fmeasure": 0.29803
        },
        "rougeL": {
            "precision": 0.47974,
            "recall": 0.45777,
            "fmeasure": 0.45677
        },
        "rougeLsum": {
            "precision": 0.47974,
            "recall": 0.45777,
            "fmeasure": 0.45677
        },
        "nubia": {
            "semantic_relation": 3.46488,
            "contradiction": 6.5476,
            "irrelevancy": 25.32854,
            "logical_agreement": 68.12387,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.69126,
            "nubia_score": 0.60258
        },
        "meteor": 0.29961358177339603,
        "bleurt": -0.16871,
        "bertscore": {
            "precision": 0.86063,
            "recall": 0.85297,
            "f1": 0.85625
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_49": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 18,
        "total_length": 296,
        "mean_pred_length": 16.444444444444443,
        "std_pred_length": 6.456884544785617,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.6283783783783784,
        "vocab_size-1": 186,
        "unique-1": 157,
        "entropy-1": 6.937035917387814,
        "distinct-2": 0.9496402877697842,
        "vocab_size-2": 264,
        "unique-2": 251,
        "entropy-2": 8.015506225593377,
        "cond_entropy-2": 0.9450297113291065,
        "distinct-3": 0.9923076923076923,
        "vocab_size-3": 258,
        "unique-3": 256,
        "entropy-3": 8.006983197643837,
        "cond_entropy-3": -0.0013621539175011216,
        "total_length-nopunct": 260,
        "mean_pred_length-nopunct": 14.444444444444445,
        "std_pred_length-nopunct": 5.678636595191394,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6923076923076923,
        "vocab_size-1-nopunct": 180,
        "unique-1-nopunct": 155,
        "entropy-1-nopunct": 7.009228260218861,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 231,
        "unique-2-nopunct": 221,
        "entropy-2-nopunct": 7.824834776521855,
        "cond_entropy-2-nopunct": 0.8785673094871799,
        "distinct-3-nopunct": 0.9955357142857143,
        "vocab_size-3-nopunct": 223,
        "unique-3-nopunct": 222,
        "entropy-3-nopunct": 7.798426350628997,
        "cond_entropy-3-nopunct": -0.023316853153760593,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.79,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18446601941747573,
            "2": 0.38636363636363635,
            "3": 0.7091836734693877
        },
        "nist": 5.603492222842938,
        "bleu": 33.77061,
        "rouge1": {
            "precision": 0.72256,
            "recall": 0.64903,
            "fmeasure": 0.66019
        },
        "rouge2": {
            "precision": 0.46721,
            "recall": 0.42521,
            "fmeasure": 0.42647
        },
        "rougeL": {
            "precision": 0.61607,
            "recall": 0.56566,
            "fmeasure": 0.56787
        },
        "rougeLsum": {
            "precision": 0.61607,
            "recall": 0.56566,
            "fmeasure": 0.56787
        },
        "nubia": {
            "semantic_relation": 3.86671,
            "contradiction": 12.11017,
            "irrelevancy": 34.09444,
            "logical_agreement": 53.79539,
            "grammar_ref": 4.5439,
            "grammar_hyp": 4.89495,
            "nubia_score": 0.61433
        },
        "meteor": 0.35647639109745727,
        "bleurt": 0.02027,
        "bertscore": {
            "precision": 0.90533,
            "recall": 0.90004,
            "f1": 0.90056
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_challenge_test_turk_bfp05",
        "N": 359,
        "total_length": 6067,
        "mean_pred_length": 16.899721448467968,
        "std_pred_length": 6.115506108589195,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.43975605735948575,
        "vocab_size-1": 2668,
        "unique-1": 2168,
        "entropy-1": 9.403592610751819,
        "distinct-2": 0.8777154870357393,
        "vocab_size-2": 5010,
        "unique-2": 4738,
        "entropy-2": 12.065415535130954,
        "cond_entropy-2": 2.4634740611481405,
        "distinct-3": 0.9766311460085998,
        "vocab_size-3": 5224,
        "unique-3": 5165,
        "entropy-3": 12.311241869323945,
        "cond_entropy-3": 0.26155099339397836,
        "total_length-nopunct": 5484,
        "mean_pred_length-nopunct": 15.275766016713092,
        "std_pred_length-nopunct": 5.72384426897228,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.4841356673960613,
        "vocab_size-1-nopunct": 2655,
        "unique-1-nopunct": 2166,
        "entropy-1-nopunct": 9.6795380832131,
        "distinct-2-nopunct": 0.8934634146341464,
        "vocab_size-2-nopunct": 4579,
        "unique-2-nopunct": 4359,
        "entropy-2-nopunct": 11.96562393403788,
        "cond_entropy-2-nopunct": 2.4244950016836255,
        "distinct-3-nopunct": 0.9882501049097776,
        "vocab_size-3-nopunct": 4710,
        "unique-3-nopunct": 4665,
        "entropy-3-nopunct": 12.19301257788044,
        "cond_entropy-3-nopunct": 0.2468542169515231,
        "msttr-100": 0.76583,
        "msttr-100_nopunct": 0.79815,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp05.json",
        "local_recall": {
            "1": 0.03459252971137521,
            "2": 0.1251596424010217,
            "3": 0.2603938730853392,
            "4": 0.3676703645007924,
            "5": 0.43509865005192105,
            "6": 0.5392512077294686,
            "7": 0.6678121420389461
        },
        "nist": 6.990967762095525,
        "bleu": 40.42457,
        "rouge1": {
            "precision": 0.70858,
            "recall": 0.60991,
            "fmeasure": 0.64116
        },
        "rouge2": {
            "precision": 0.49442,
            "recall": 0.42067,
            "fmeasure": 0.44244
        },
        "rougeL": {
            "precision": 0.67664,
            "recall": 0.58531,
            "fmeasure": 0.61318
        },
        "rougeLsum": {
            "precision": 0.67664,
            "recall": 0.58531,
            "fmeasure": 0.61318
        },
        "sari": 45.31402,
        "nubia": {
            "semantic_relation": 3.68768,
            "contradiction": 8.85224,
            "irrelevancy": 18.94966,
            "logical_agreement": 72.1981,
            "grammar_ref": 4.55265,
            "grammar_hyp": 6.26123,
            "nubia_score": 0.43743
        },
        "meteor": 0.3067851025968416,
        "bleurt": -0.64228,
        "bertscore": {
            "precision": 0.87697,
            "recall": 0.88539,
            "f1": 0.87765
        }
    },
    "wiki_lingua_vietnamese_vi_test": {
        "predictions_file": "ByT5-base (Baseline)/wiki_lingua_vietnamese_vi_test",
        "N": 3917,
        "total_length": 95230,
        "mean_pred_length": 24.311973449068166,
        "std_pred_length": 4.911022662421664,
        "median_pred_length": 25.0,
        "min_pred_length": 4,
        "max_pred_length": 37,
        "distinct-1": 0.07399978998214848,
        "vocab_size-1": 7047,
        "unique-1": 3074,
        "entropy-1": 8.852118352837781,
        "distinct-2": 0.3622923351549068,
        "vocab_size-2": 33082,
        "unique-2": 22953,
        "entropy-2": 13.478002718022477,
        "cond_entropy-2": 4.648717452766575,
        "distinct-3": 0.6993340656322944,
        "vocab_size-3": 61119,
        "unique-3": 52037,
        "entropy-3": 15.371955088932879,
        "cond_entropy-3": 1.9458427315472158,
        "total_length-nopunct": 81762,
        "mean_pred_length-nopunct": 20.87362777635946,
        "std_pred_length-nopunct": 4.6236023493634315,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.08598126268926885,
        "vocab_size-1-nopunct": 7030,
        "unique-1-nopunct": 3071,
        "entropy-1-nopunct": 9.572438521220606,
        "distinct-2-nopunct": 0.49231164493544866,
        "vocab_size-2-nopunct": 38324,
        "unique-2-nopunct": 29452,
        "entropy-2-nopunct": 14.077581521689098,
        "cond_entropy-2-nopunct": 4.635465727801741,
        "distinct-3-nopunct": 0.8165782923925982,
        "vocab_size-3-nopunct": 60368,
        "unique-3-nopunct": 54456,
        "entropy-3-nopunct": 15.610955533228989,
        "cond_entropy-3-nopunct": 1.5925690051820631,
        "msttr-100": 0.63791,
        "msttr-100_nopunct": 0.71124,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_test.json",
        "local_recall": {
            "1": 0.25477267740149007
        },
        "nist": 1.9326607978636003,
        "bleu": 7.77835,
        "rouge1": {
            "precision": 0.39502,
            "recall": 0.28915,
            "fmeasure": 0.31561
        },
        "rouge2": {
            "precision": 0.14076,
            "recall": 0.10047,
            "fmeasure": 0.1105
        },
        "rougeL": {
            "precision": 0.31559,
            "recall": 0.23465,
            "fmeasure": 0.25414
        },
        "rougeLsum": {
            "precision": 0.31559,
            "recall": 0.23465,
            "fmeasure": 0.25414
        },
        "sari": 66.32384,
        "nubia": {
            "semantic_relation": 2.5,
            "contradiction": 19.31856,
            "irrelevancy": 47.37298,
            "logical_agreement": 33.30846,
            "grammar_ref": 3.92068,
            "grammar_hyp": 4.24616,
            "nubia_score": 0.28105
        },
        "meteor": 0.13375963039058197,
        "bleurt": -0.52344,
        "bertscore": {
            "precision": 0.84439,
            "recall": 0.82543,
            "f1": 0.83432
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_50": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 55,
        "total_length": 890,
        "mean_pred_length": 16.181818181818183,
        "std_pred_length": 4.644022195119263,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 28,
        "distinct-1": 0.5325842696629214,
        "vocab_size-1": 474,
        "unique-1": 384,
        "entropy-1": 7.82533213963764,
        "distinct-2": 0.9053892215568863,
        "vocab_size-2": 756,
        "unique-2": 710,
        "entropy-2": 9.464287425118512,
        "cond_entropy-2": 1.4138717536230807,
        "distinct-3": 0.9794871794871794,
        "vocab_size-3": 764,
        "unique-3": 751,
        "entropy-3": 9.563401259254093,
        "cond_entropy-3": 0.07670240518821947,
        "total_length-nopunct": 758,
        "mean_pred_length-nopunct": 13.781818181818181,
        "std_pred_length-nopunct": 4.193895603204557,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6147757255936676,
        "vocab_size-1-nopunct": 466,
        "unique-1-nopunct": 382,
        "entropy-1-nopunct": 8.090048035525198,
        "distinct-2-nopunct": 0.9174964438122333,
        "vocab_size-2-nopunct": 645,
        "unique-2-nopunct": 612,
        "entropy-2-nopunct": 9.24683568921716,
        "cond_entropy-2-nopunct": 1.2376904927502541,
        "distinct-3-nopunct": 0.9830246913580247,
        "vocab_size-3-nopunct": 637,
        "unique-3-nopunct": 629,
        "entropy-3-nopunct": 9.302404536053553,
        "cond_entropy-3-nopunct": 0.06880956511124739,
        "msttr-100": 0.73125,
        "msttr-100_nopunct": 0.79429,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.27450980392156865,
            "2": 0.4098360655737705,
            "3": 0.7620817843866171
        },
        "nist": 7.210569504484128,
        "bleu": 48.08949,
        "rouge1": {
            "precision": 0.74862,
            "recall": 0.71573,
            "fmeasure": 0.72105
        },
        "rouge2": {
            "precision": 0.52498,
            "recall": 0.49831,
            "fmeasure": 0.50326
        },
        "rougeL": {
            "precision": 0.65269,
            "recall": 0.63535,
            "fmeasure": 0.63339
        },
        "rougeLsum": {
            "precision": 0.65269,
            "recall": 0.63535,
            "fmeasure": 0.63339
        },
        "nubia": {
            "semantic_relation": 4.21671,
            "contradiction": 6.66272,
            "irrelevancy": 34.03915,
            "logical_agreement": 59.29814,
            "grammar_ref": 4.83026,
            "grammar_hyp": 4.90686,
            "nubia_score": 0.72044
        },
        "meteor": 0.40465691618443794,
        "bleurt": 0.22578,
        "bertscore": {
            "precision": 0.92914,
            "recall": 0.92757,
            "f1": 0.92706
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 339,
        "total_length": 3088,
        "mean_pred_length": 9.109144542772862,
        "std_pred_length": 2.4112333298226862,
        "median_pred_length": 9.0,
        "min_pred_length": 4,
        "max_pred_length": 16,
        "distinct-1": 0.38309585492227977,
        "vocab_size-1": 1183,
        "unique-1": 793,
        "entropy-1": 8.64139027780139,
        "distinct-2": 0.7300836667879229,
        "vocab_size-2": 2007,
        "unique-2": 1633,
        "entropy-2": 10.670872045080609,
        "cond_entropy-2": 1.629670769712012,
        "distinct-3": 0.8759336099585062,
        "vocab_size-3": 2111,
        "unique-3": 1890,
        "entropy-3": 10.952819708306098,
        "cond_entropy-3": 0.3022246187708755,
        "total_length-nopunct": 2547,
        "mean_pred_length-nopunct": 7.513274336283186,
        "std_pred_length-nopunct": 2.2186460203641447,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.4625049077345897,
        "vocab_size-1-nopunct": 1178,
        "unique-1-nopunct": 793,
        "entropy-1-nopunct": 9.24960840611073,
        "distinct-2-nopunct": 0.7604166666666666,
        "vocab_size-2-nopunct": 1679,
        "unique-2-nopunct": 1403,
        "entropy-2-nopunct": 10.445873866397504,
        "cond_entropy-2-nopunct": 1.3525560455334742,
        "distinct-3-nopunct": 0.8855002675227395,
        "vocab_size-3-nopunct": 1655,
        "unique-3-nopunct": 1496,
        "entropy-3-nopunct": 10.60725018682629,
        "cond_entropy-3-nopunct": 0.23434678445984336,
        "msttr-100": 0.676,
        "msttr-100_nopunct": 0.7464,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.31892826274848746,
            "2": 0.614687216681777,
            "3": 0.7681895093062606,
            "4": 0.8333333333333334,
            "5": 0.8666666666666667,
            "6": 0.9166666666666666,
            "7": 1.0
        },
        "nist": 8.093745555662728,
        "bleu": 51.61457,
        "rouge1": {
            "precision": 0.2597,
            "recall": 0.25878,
            "fmeasure": 0.25834
        },
        "rouge2": {
            "precision": 0.13473,
            "recall": 0.13389,
            "fmeasure": 0.13346
        },
        "rougeL": {
            "precision": 0.257,
            "recall": 0.25619,
            "fmeasure": 0.2557
        },
        "rougeLsum": {
            "precision": 0.257,
            "recall": 0.25619,
            "fmeasure": 0.2557
        },
        "nubia": {
            "semantic_relation": 4.09152,
            "contradiction": 19.8572,
            "irrelevancy": 21.29901,
            "logical_agreement": 58.84379,
            "grammar_ref": 2.83259,
            "grammar_hyp": 2.82943,
            "nubia_score": 0.82621
        },
        "meteor": 0.671740618517573,
        "bleurt": 0.34078,
        "bertscore": {
            "precision": 0.96599,
            "recall": 0.96041,
            "f1": 0.96256
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1850,
        "total_length": 25301,
        "mean_pred_length": 13.676216216216217,
        "std_pred_length": 4.26709937010279,
        "median_pred_length": 13.0,
        "min_pred_length": 4,
        "max_pred_length": 31,
        "distinct-1": 0.2554839729654954,
        "vocab_size-1": 6464,
        "unique-1": 4775,
        "entropy-1": 9.188838072304739,
        "distinct-2": 0.6166474777195002,
        "vocab_size-2": 14461,
        "unique-2": 12660,
        "entropy-2": 12.589153610156478,
        "cond_entropy-2": 2.9848069353105924,
        "distinct-3": 0.786352483681311,
        "vocab_size-3": 16986,
        "unique-3": 15854,
        "entropy-3": 13.38150685429693,
        "cond_entropy-3": 0.8300582022717227,
        "total_length-nopunct": 22054,
        "mean_pred_length-nopunct": 11.92108108108108,
        "std_pred_length-nopunct": 3.7970456394439682,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.2923279223723588,
        "vocab_size-1-nopunct": 6447,
        "unique-1-nopunct": 4772,
        "entropy-1-nopunct": 9.639431785773073,
        "distinct-2-nopunct": 0.6398732924173431,
        "vocab_size-2-nopunct": 12928,
        "unique-2-nopunct": 11548,
        "entropy-2-nopunct": 12.425843335527466,
        "cond_entropy-2-nopunct": 3.018184218507895,
        "distinct-3-nopunct": 0.7950855399367985,
        "vocab_size-3-nopunct": 14593,
        "unique-3-nopunct": 13698,
        "entropy-3-nopunct": 13.174399992779824,
        "cond_entropy-3-nopunct": 0.8668183459526608,
        "msttr-100": 0.69344,
        "msttr-100_nopunct": 0.74191,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23029739776951672,
            "2": 0.5,
            "3": 0.7913535084802128
        },
        "nist": 9.635673843624133,
        "bleu": 52.29819,
        "rouge1": {
            "precision": 0.75016,
            "recall": 0.74295,
            "fmeasure": 0.73387
        },
        "rouge2": {
            "precision": 0.55474,
            "recall": 0.55009,
            "fmeasure": 0.5432
        },
        "rougeL": {
            "precision": 0.68254,
            "recall": 0.67933,
            "fmeasure": 0.66913
        },
        "rougeLsum": {
            "precision": 0.68254,
            "recall": 0.67933,
            "fmeasure": 0.66913
        },
        "nubia": {
            "semantic_relation": 4.16981,
            "contradiction": 8.24781,
            "irrelevancy": 31.05644,
            "logical_agreement": 60.69575,
            "grammar_ref": 4.71357,
            "grammar_hyp": 4.70133,
            "nubia_score": 0.72976
        },
        "meteor": 0.41127000750404624,
        "bleurt": 0.3179,
        "bertscore": {
            "precision": 0.92973,
            "recall": 0.9289,
            "f1": 0.92759
        }
    },
    "schema_guided_dialog_challenge_test_bfp02": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_challenge_test_bfp02",
        "N": 500,
        "total_length": 6320,
        "mean_pred_length": 12.64,
        "std_pred_length": 6.847364456489811,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 32,
        "distinct-1": 0.16376582278481014,
        "vocab_size-1": 1035,
        "unique-1": 577,
        "entropy-1": 7.919075258306177,
        "distinct-2": 0.5063573883161512,
        "vocab_size-2": 2947,
        "unique-2": 2061,
        "entropy-2": 10.813488886565079,
        "cond_entropy-2": 2.677733743467991,
        "distinct-3": 0.7330827067669173,
        "vocab_size-3": 3900,
        "unique-3": 3234,
        "entropy-3": 11.619594638141004,
        "cond_entropy-3": 0.8296834477700112,
        "total_length-nopunct": 5581,
        "mean_pred_length-nopunct": 11.162,
        "std_pred_length-nopunct": 6.376186634658681,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.18294212506719226,
        "vocab_size-1-nopunct": 1021,
        "unique-1-nopunct": 573,
        "entropy-1-nopunct": 8.096699165595954,
        "distinct-2-nopunct": 0.5223381224168471,
        "vocab_size-2-nopunct": 2654,
        "unique-2-nopunct": 1900,
        "entropy-2-nopunct": 10.659700192211245,
        "cond_entropy-2-nopunct": 2.692806180279591,
        "distinct-3-nopunct": 0.740506329113924,
        "vocab_size-3-nopunct": 3393,
        "unique-3-nopunct": 2849,
        "entropy-3-nopunct": 11.414684912356488,
        "cond_entropy-3-nopunct": 0.8081256204596842,
        "msttr-100": 0.69968,
        "msttr-100_nopunct": 0.72782,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp02.json",
        "local_recall": {
            "1": 0.5577828133170647
        },
        "nist": 6.123677932149919,
        "bleu": 32.21294,
        "rouge1": {
            "precision": 0.58106,
            "recall": 0.54771,
            "fmeasure": 0.55307
        },
        "rouge2": {
            "precision": 0.36932,
            "recall": 0.34759,
            "fmeasure": 0.35055
        },
        "rougeL": {
            "precision": 0.5294,
            "recall": 0.4966,
            "fmeasure": 0.50267
        },
        "rougeLsum": {
            "precision": 0.5294,
            "recall": 0.4966,
            "fmeasure": 0.50267
        },
        "nubia": {
            "semantic_relation": 3.58319,
            "contradiction": 5.86246,
            "irrelevancy": 23.81426,
            "logical_agreement": 70.32329,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.75696,
            "nubia_score": 0.62229
        },
        "meteor": 0.3108484506497999,
        "bleurt": -0.12503,
        "bertscore": {
            "precision": 0.87165,
            "recall": 0.86308,
            "f1": 0.86683
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 316,
        "total_length": 3864,
        "mean_pred_length": 12.227848101265822,
        "std_pred_length": 2.343584656080918,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 20,
        "distinct-1": 0.33203933747412007,
        "vocab_size-1": 1283,
        "unique-1": 789,
        "entropy-1": 8.69996602660336,
        "distinct-2": 0.6502254791431793,
        "vocab_size-2": 2307,
        "unique-2": 1746,
        "entropy-2": 10.757917670348462,
        "cond_entropy-2": 2.160076017651701,
        "distinct-3": 0.8233292079207921,
        "vocab_size-3": 2661,
        "unique-3": 2279,
        "entropy-3": 11.243513611053803,
        "cond_entropy-3": 0.5507140883428391,
        "total_length-nopunct": 3305,
        "mean_pred_length-nopunct": 10.458860759493671,
        "std_pred_length-nopunct": 1.8997544727046831,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.3863842662632375,
        "vocab_size-1-nopunct": 1277,
        "unique-1-nopunct": 788,
        "entropy-1-nopunct": 9.160491310465902,
        "distinct-2-nopunct": 0.6985613917698227,
        "vocab_size-2-nopunct": 2088,
        "unique-2-nopunct": 1644,
        "entropy-2-nopunct": 10.704001138448824,
        "cond_entropy-2-nopunct": 1.6916849484635776,
        "distinct-3-nopunct": 0.8447437336326226,
        "vocab_size-3-nopunct": 2258,
        "unique-3-nopunct": 1976,
        "entropy-3-nopunct": 11.02077946890912,
        "cond_entropy-3-nopunct": 0.38620754411698155,
        "msttr-100": 0.67842,
        "msttr-100_nopunct": 0.72667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.16143392689784442,
            "2": 0.4143753014954173,
            "3": 0.5753521126760563,
            "4": 0.7368421052631579,
            "5": 0.6818181818181818,
            "6": 0.0,
            "7": 1.0
        },
        "nist": 2.52435381097921,
        "bleu": 25.49895,
        "rouge1": {
            "precision": 0.26878,
            "recall": 0.24212,
            "fmeasure": 0.25006
        },
        "rouge2": {
            "precision": 0.11711,
            "recall": 0.10548,
            "fmeasure": 0.10865
        },
        "rougeL": {
            "precision": 0.25997,
            "recall": 0.23413,
            "fmeasure": 0.2417
        },
        "rougeLsum": {
            "precision": 0.25997,
            "recall": 0.23413,
            "fmeasure": 0.2417
        },
        "nubia": {
            "semantic_relation": 3.56108,
            "contradiction": 21.87945,
            "irrelevancy": 22.98719,
            "logical_agreement": 55.13336,
            "grammar_ref": 2.6064,
            "grammar_hyp": 2.68832,
            "nubia_score": 0.69116
        },
        "meteor": 0.42081680130646115,
        "bleurt": 0.03005,
        "bertscore": {
            "precision": 0.94844,
            "recall": 0.9114,
            "f1": 0.92865
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_51": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 11,
        "total_length": 166,
        "mean_pred_length": 15.090909090909092,
        "std_pred_length": 5.648081660730569,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.6385542168674698,
        "vocab_size-1": 106,
        "unique-1": 88,
        "entropy-1": 6.152749995788934,
        "distinct-2": 0.9483870967741935,
        "vocab_size-2": 147,
        "unique-2": 142,
        "entropy-2": 7.149610595761761,
        "cond_entropy-2": 0.8692857796003122,
        "distinct-3": 1.0,
        "vocab_size-3": 144,
        "unique-3": 144,
        "entropy-3": 7.169925001442332,
        "cond_entropy-3": 0.029978655018330524,
        "total_length-nopunct": 143,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 4.709757762541316,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7062937062937062,
        "vocab_size-1-nopunct": 101,
        "unique-1-nopunct": 88,
        "entropy-1-nopunct": 6.152673568251481,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 126,
        "unique-2-nopunct": 123,
        "entropy-2-nopunct": 6.9261392672793765,
        "cond_entropy-2-nopunct": 0.8573988464051523,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 121,
        "unique-3-nopunct": 121,
        "entropy-3-nopunct": 6.918863237274603,
        "cond_entropy-3-nopunct": 0.003474411093304956,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25925925925925924,
            "2": 0.5806451612903226,
            "3": 0.8152173913043478
        },
        "nist": 6.257655870722499,
        "bleu": 54.36029,
        "rouge1": {
            "precision": 0.78584,
            "recall": 0.75061,
            "fmeasure": 0.75126
        },
        "rouge2": {
            "precision": 0.60401,
            "recall": 0.58109,
            "fmeasure": 0.58167
        },
        "rougeL": {
            "precision": 0.7058,
            "recall": 0.67108,
            "fmeasure": 0.66968
        },
        "rougeLsum": {
            "precision": 0.7058,
            "recall": 0.67108,
            "fmeasure": 0.66968
        },
        "nubia": {
            "semantic_relation": 4.05286,
            "contradiction": 11.1475,
            "irrelevancy": 34.02618,
            "logical_agreement": 54.82632,
            "grammar_ref": 4.58752,
            "grammar_hyp": 4.65346,
            "nubia_score": 0.69547
        },
        "meteor": 0.44384253284654,
        "bleurt": 0.2282,
        "bertscore": {
            "precision": 0.94347,
            "recall": 0.9449,
            "f1": 0.94261
        }
    },
    "schema_guided_dialog_challenge_test_bfp05": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_challenge_test_bfp05",
        "N": 500,
        "total_length": 5942,
        "mean_pred_length": 11.884,
        "std_pred_length": 6.339601249290053,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 33,
        "distinct-1": 0.16879838438236283,
        "vocab_size-1": 1003,
        "unique-1": 566,
        "entropy-1": 7.847855910795556,
        "distinct-2": 0.5202131569276002,
        "vocab_size-2": 2831,
        "unique-2": 2029,
        "entropy-2": 10.755685331076444,
        "cond_entropy-2": 2.6491760424598882,
        "distinct-3": 0.7480777013354917,
        "vocab_size-3": 3697,
        "unique-3": 3137,
        "entropy-3": 11.540062902737224,
        "cond_entropy-3": 0.8049542669881313,
        "total_length-nopunct": 5212,
        "mean_pred_length-nopunct": 10.424,
        "std_pred_length-nopunct": 5.868579385166396,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.18994627782041443,
        "vocab_size-1-nopunct": 990,
        "unique-1-nopunct": 561,
        "entropy-1-nopunct": 8.051514110341522,
        "distinct-2-nopunct": 0.5360780984719864,
        "vocab_size-2-nopunct": 2526,
        "unique-2-nopunct": 1845,
        "entropy-2-nopunct": 10.587109195727917,
        "cond_entropy-2-nopunct": 2.6749540464033057,
        "distinct-3-nopunct": 0.7580721747388414,
        "vocab_size-3-nopunct": 3193,
        "unique-3-nopunct": 2755,
        "entropy-3-nopunct": 11.323459868939521,
        "cond_entropy-3-nopunct": 0.7700455024537048,
        "msttr-100": 0.69576,
        "msttr-100_nopunct": 0.72481,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp05.json",
        "local_recall": {
            "1": 0.5432392817882008
        },
        "nist": 5.956842615992069,
        "bleu": 30.57832,
        "rouge1": {
            "precision": 0.56627,
            "recall": 0.53018,
            "fmeasure": 0.53631
        },
        "rouge2": {
            "precision": 0.3454,
            "recall": 0.32175,
            "fmeasure": 0.32595
        },
        "rougeL": {
            "precision": 0.50756,
            "recall": 0.47382,
            "fmeasure": 0.48025
        },
        "rougeLsum": {
            "precision": 0.50756,
            "recall": 0.47382,
            "fmeasure": 0.48025
        },
        "nubia": {
            "semantic_relation": 3.5492,
            "contradiction": 5.54179,
            "irrelevancy": 23.39772,
            "logical_agreement": 71.06048,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.7994,
            "nubia_score": 0.61096
        },
        "meteor": 0.3064535450279651,
        "bleurt": -0.14446,
        "bertscore": {
            "precision": 0.86622,
            "recall": 0.8588,
            "f1": 0.86202
        }
    },
    "wiki_lingua_russian_ru_validation": {
        "predictions_file": "ByT5-base (Baseline)/wiki_lingua_russian_ru_validation",
        "N": 5288,
        "total_length": 124568,
        "mean_pred_length": 23.556732223903175,
        "std_pred_length": 6.182104442891547,
        "median_pred_length": 25.0,
        "min_pred_length": 3,
        "max_pred_length": 54,
        "distinct-1": 0.06007160747543511,
        "vocab_size-1": 7483,
        "unique-1": 2911,
        "entropy-1": 8.68688497559184,
        "distinct-2": 0.29231220657276996,
        "vocab_size-2": 34867,
        "unique-2": 22253,
        "entropy-2": 13.284308896575505,
        "cond_entropy-2": 4.5712903254406605,
        "distinct-3": 0.5989718576742228,
        "vocab_size-3": 68278,
        "unique-3": 54343,
        "entropy-3": 15.268484290866272,
        "cond_entropy-3": 2.03159988544419,
        "total_length-nopunct": 105162,
        "mean_pred_length-nopunct": 19.886913767019667,
        "std_pred_length-nopunct": 5.605648329882347,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.07099522641258249,
        "vocab_size-1-nopunct": 7466,
        "unique-1-nopunct": 2910,
        "entropy-1-nopunct": 9.498438887452853,
        "distinct-2-nopunct": 0.41883773554678894,
        "vocab_size-2-nopunct": 41831,
        "unique-2-nopunct": 30059,
        "entropy-2-nopunct": 13.953156285372653,
        "cond_entropy-2-nopunct": 4.592864091674075,
        "distinct-3-nopunct": 0.7298014505317911,
        "vocab_size-3-nopunct": 69029,
        "unique-3-nopunct": 58718,
        "entropy-3-nopunct": 15.640534330802522,
        "cond_entropy-3-nopunct": 1.7492784699448145,
        "msttr-100": 0.56288,
        "msttr-100_nopunct": 0.63637,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_validation.json",
        "local_recall": {
            "1": 0.22979016933312565
        },
        "nist": 1.4418592133817192,
        "bleu": 6.51927,
        "rouge1": {
            "precision": 0.41634,
            "recall": 0.27617,
            "fmeasure": 0.3122
        },
        "rouge2": {
            "precision": 0.14563,
            "recall": 0.09591,
            "fmeasure": 0.1089
        },
        "rougeL": {
            "precision": 0.3457,
            "recall": 0.23249,
            "fmeasure": 0.26115
        },
        "rougeLsum": {
            "precision": 0.3457,
            "recall": 0.23249,
            "fmeasure": 0.26115
        },
        "sari": 68.2199,
        "nubia": {
            "semantic_relation": 2.70166,
            "contradiction": 18.27523,
            "irrelevancy": 40.81185,
            "logical_agreement": 40.91292,
            "grammar_ref": 3.95099,
            "grammar_hyp": 3.90021,
            "nubia_score": 0.34951
        },
        "meteor": 0.12733187829552878,
        "bleurt": -0.50872,
        "bertscore": {
            "precision": 0.85154,
            "recall": 0.81846,
            "f1": 0.83413
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 217,
        "total_length": 2732,
        "mean_pred_length": 12.589861751152073,
        "std_pred_length": 2.4798707561206434,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 21,
        "distinct-1": 0.383601756954612,
        "vocab_size-1": 1048,
        "unique-1": 685,
        "entropy-1": 8.583965312814255,
        "distinct-2": 0.714910536779324,
        "vocab_size-2": 1798,
        "unique-2": 1422,
        "entropy-2": 10.529913751379759,
        "cond_entropy-2": 2.084880178101953,
        "distinct-3": 0.8629242819843342,
        "vocab_size-3": 1983,
        "unique-3": 1750,
        "entropy-3": 10.859784823296298,
        "cond_entropy-3": 0.38960770760266755,
        "total_length-nopunct": 2325,
        "mean_pred_length-nopunct": 10.714285714285714,
        "std_pred_length-nopunct": 2.0049313792292343,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.44731182795698926,
        "vocab_size-1-nopunct": 1040,
        "unique-1-nopunct": 684,
        "entropy-1-nopunct": 9.027525576346987,
        "distinct-2-nopunct": 0.7637571157495257,
        "vocab_size-2-nopunct": 1610,
        "unique-2-nopunct": 1328,
        "entropy-2-nopunct": 10.429087274609588,
        "cond_entropy-2-nopunct": 1.5404145720479603,
        "distinct-3-nopunct": 0.8810153358011634,
        "vocab_size-3-nopunct": 1666,
        "unique-3-nopunct": 1502,
        "entropy-3-nopunct": 10.61644376035273,
        "cond_entropy-3-nopunct": 0.24720482514737593,
        "msttr-100": 0.67333,
        "msttr-100_nopunct": 0.71609,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.13496932515337423,
            "2": 0.31961414790996784,
            "3": 0.48789435069699194,
            "4": 0.45454545454545453
        },
        "nist": 1.307862319356857,
        "bleu": 19.45966,
        "rouge1": {
            "precision": 0.29416,
            "recall": 0.22635,
            "fmeasure": 0.24613
        },
        "rouge2": {
            "precision": 0.1133,
            "recall": 0.07381,
            "fmeasure": 0.08564
        },
        "rougeL": {
            "precision": 0.28418,
            "recall": 0.21871,
            "fmeasure": 0.23774
        },
        "rougeLsum": {
            "precision": 0.28418,
            "recall": 0.21871,
            "fmeasure": 0.23774
        },
        "nubia": {
            "semantic_relation": 3.39025,
            "contradiction": 22.4781,
            "irrelevancy": 23.36665,
            "logical_agreement": 54.15525,
            "grammar_ref": 2.56565,
            "grammar_hyp": 2.68376,
            "nubia_score": 0.62916
        },
        "meteor": 0.360896587286407,
        "bleurt": -0.02063,
        "bertscore": {
            "precision": 0.94352,
            "recall": 0.89606,
            "f1": 0.91846
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2221,
        "total_length": 34171,
        "mean_pred_length": 15.385411976587124,
        "std_pred_length": 4.174281117651959,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 34,
        "distinct-1": 0.2519973076585409,
        "vocab_size-1": 8611,
        "unique-1": 6190,
        "entropy-1": 9.707733820191025,
        "distinct-2": 0.6649765258215963,
        "vocab_size-2": 21246,
        "unique-2": 18469,
        "entropy-2": 13.567774654425968,
        "cond_entropy-2": 3.4822721717812177,
        "distinct-3": 0.8681758552255373,
        "vocab_size-3": 25810,
        "unique-3": 24181,
        "entropy-3": 14.444713977203087,
        "cond_entropy-3": 0.867790016792671,
        "total_length-nopunct": 29774,
        "mean_pred_length-nopunct": 13.405673120216118,
        "std_pred_length-nopunct": 3.85961954058393,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.2886746826089877,
        "vocab_size-1-nopunct": 8595,
        "unique-1-nopunct": 6190,
        "entropy-1-nopunct": 10.224227818754121,
        "distinct-2-nopunct": 0.7030087467789351,
        "vocab_size-2-nopunct": 19370,
        "unique-2-nopunct": 17167,
        "entropy-2-nopunct": 13.491055804308223,
        "cond_entropy-2-nopunct": 3.4428605437183624,
        "distinct-3-nopunct": 0.891994315490289,
        "vocab_size-3-nopunct": 22596,
        "unique-3-nopunct": 21361,
        "entropy-3-nopunct": 14.305089540193164,
        "cond_entropy-3-nopunct": 0.8746694830161393,
        "msttr-100": 0.73317,
        "msttr-100_nopunct": 0.78926,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22281390134529147,
            "2": 0.473463687150838,
            "3": 0.7998380712486506
        },
        "nist": 10.35579088400878,
        "bleu": 49.53575,
        "rouge1": {
            "precision": 0.77943,
            "recall": 0.76211,
            "fmeasure": 0.76031
        },
        "rouge2": {
            "precision": 0.55164,
            "recall": 0.53877,
            "fmeasure": 0.53772
        },
        "rougeL": {
            "precision": 0.6743,
            "recall": 0.66291,
            "fmeasure": 0.65955
        },
        "rougeLsum": {
            "precision": 0.6743,
            "recall": 0.66291,
            "fmeasure": 0.65955
        },
        "nubia": {
            "semantic_relation": 4.32812,
            "contradiction": 6.69422,
            "irrelevancy": 27.14156,
            "logical_agreement": 66.16422,
            "grammar_ref": 4.79644,
            "grammar_hyp": 4.78046,
            "nubia_score": 0.76198
        },
        "meteor": 0.41225134549512954,
        "bleurt": 0.32409,
        "bertscore": {
            "precision": 0.93438,
            "recall": 0.93278,
            "f1": 0.932
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1369,
        "total_length": 25376,
        "mean_pred_length": 18.536157779401023,
        "std_pred_length": 4.5710413936955065,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 36,
        "distinct-1": 0.25453184110970994,
        "vocab_size-1": 6459,
        "unique-1": 4571,
        "entropy-1": 9.554214608365855,
        "distinct-2": 0.6665139334360811,
        "vocab_size-2": 16001,
        "unique-2": 13825,
        "entropy-2": 13.225269900951124,
        "cond_entropy-2": 3.424961753367809,
        "distinct-3": 0.8662867744500398,
        "vocab_size-3": 19611,
        "unique-3": 18317,
        "entropy-3": 14.052495650284712,
        "cond_entropy-3": 0.831336494248302,
        "total_length-nopunct": 22237,
        "mean_pred_length-nopunct": 16.243243243243242,
        "std_pred_length-nopunct": 4.078305839986798,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.289787291451185,
        "vocab_size-1-nopunct": 6444,
        "unique-1-nopunct": 4569,
        "entropy-1-nopunct": 10.006132025032278,
        "distinct-2-nopunct": 0.7059133601686793,
        "vocab_size-2-nopunct": 14731,
        "unique-2-nopunct": 12976,
        "entropy-2-nopunct": 13.161634696311928,
        "cond_entropy-2-nopunct": 3.292023342953602,
        "distinct-3-nopunct": 0.8878916867531669,
        "vocab_size-3-nopunct": 17313,
        "unique-3-nopunct": 16323,
        "entropy-3-nopunct": 13.91024740239471,
        "cond_entropy-3-nopunct": 0.7958802940937401,
        "msttr-100": 0.7287,
        "msttr-100_nopunct": 0.77833,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2322994652406417,
            "2": 0.44612753481553874,
            "3": 0.7808971804624766
        },
        "nist": 9.884456453196083,
        "bleu": 47.45427,
        "rouge1": {
            "precision": 0.75823,
            "recall": 0.74235,
            "fmeasure": 0.74075
        },
        "rouge2": {
            "precision": 0.52271,
            "recall": 0.51369,
            "fmeasure": 0.51131
        },
        "rougeL": {
            "precision": 0.63944,
            "recall": 0.62916,
            "fmeasure": 0.62595
        },
        "rougeLsum": {
            "precision": 0.63944,
            "recall": 0.62916,
            "fmeasure": 0.62595
        },
        "nubia": {
            "semantic_relation": 4.22099,
            "contradiction": 8.77398,
            "irrelevancy": 30.53842,
            "logical_agreement": 60.6876,
            "grammar_ref": 4.49662,
            "grammar_hyp": 4.46584,
            "nubia_score": 0.73806
        },
        "meteor": 0.4009793259126848,
        "bleurt": 0.25265,
        "bertscore": {
            "precision": 0.92855,
            "recall": 0.92741,
            "f1": 0.92642
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 483,
        "total_length": 10154,
        "mean_pred_length": 21.022774327122153,
        "std_pred_length": 4.0973529510893405,
        "median_pred_length": 21.0,
        "min_pred_length": 10,
        "max_pred_length": 33,
        "distinct-1": 0.3161315737640339,
        "vocab_size-1": 3210,
        "unique-1": 2372,
        "entropy-1": 9.20063327341677,
        "distinct-2": 0.7346706648743666,
        "vocab_size-2": 7105,
        "unique-2": 6185,
        "entropy-2": 12.319310568580665,
        "cond_entropy-2": 2.971030810586611,
        "distinct-3": 0.9149978232477144,
        "vocab_size-3": 8407,
        "unique-3": 7941,
        "entropy-3": 12.950604205862412,
        "cond_entropy-3": 0.640208501779048,
        "total_length-nopunct": 9008,
        "mean_pred_length-nopunct": 18.650103519668736,
        "std_pred_length-nopunct": 3.9173308968918246,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.3550177619893428,
        "vocab_size-1-nopunct": 3198,
        "unique-1-nopunct": 2370,
        "entropy-1-nopunct": 9.546130506506232,
        "distinct-2-nopunct": 0.7637536656891496,
        "vocab_size-2-nopunct": 6511,
        "unique-2-nopunct": 5776,
        "entropy-2-nopunct": 12.22352417756185,
        "cond_entropy-2-nopunct": 2.7780283205118503,
        "distinct-3-nopunct": 0.9250186520765978,
        "vocab_size-3-nopunct": 7439,
        "unique-3-nopunct": 7073,
        "entropy-3-nopunct": 12.783671752891562,
        "cond_entropy-3-nopunct": 0.5858753077214959,
        "msttr-100": 0.72941,
        "msttr-100_nopunct": 0.77033,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2164048865619546,
            "2": 0.4367741935483871,
            "3": 0.7535026269702276
        },
        "nist": 8.780421871396289,
        "bleu": 42.21712,
        "rouge1": {
            "precision": 0.74259,
            "recall": 0.72178,
            "fmeasure": 0.72307
        },
        "rouge2": {
            "precision": 0.49453,
            "recall": 0.48122,
            "fmeasure": 0.48161
        },
        "rougeL": {
            "precision": 0.60466,
            "recall": 0.59083,
            "fmeasure": 0.59002
        },
        "rougeLsum": {
            "precision": 0.60466,
            "recall": 0.59083,
            "fmeasure": 0.59002
        },
        "nubia": {
            "semantic_relation": 4.0838,
            "contradiction": 9.53797,
            "irrelevancy": 34.46665,
            "logical_agreement": 55.99538,
            "grammar_ref": 4.32701,
            "grammar_hyp": 4.32088,
            "nubia_score": 0.70454
        },
        "meteor": 0.3791415027428516,
        "bleurt": 0.15968,
        "bertscore": {
            "precision": 0.92064,
            "recall": 0.91748,
            "f1": 0.9172
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 379,
        "total_length": 8365,
        "mean_pred_length": 22.071240105540898,
        "std_pred_length": 3.9963956442669133,
        "median_pred_length": 22.0,
        "min_pred_length": 7,
        "max_pred_length": 34,
        "distinct-1": 0.34668260609683205,
        "vocab_size-1": 2900,
        "unique-1": 2158,
        "entropy-1": 9.219467163009757,
        "distinct-2": 0.7773603806661658,
        "vocab_size-2": 6208,
        "unique-2": 5501,
        "entropy-2": 12.2120637179946,
        "cond_entropy-2": 2.9024004842183695,
        "distinct-3": 0.9383462600236624,
        "vocab_size-3": 7138,
        "unique-3": 6834,
        "entropy-3": 12.746596333094521,
        "cond_entropy-3": 0.5401483735042387,
        "total_length-nopunct": 7354,
        "mean_pred_length-nopunct": 19.40369393139842,
        "std_pred_length-nopunct": 3.657224327950089,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.39230350829480554,
        "vocab_size-1-nopunct": 2885,
        "unique-1-nopunct": 2156,
        "entropy-1-nopunct": 9.569078902803133,
        "distinct-2-nopunct": 0.8130465949820789,
        "vocab_size-2-nopunct": 5671,
        "unique-2-nopunct": 5126,
        "entropy-2-nopunct": 12.141993037369687,
        "cond_entropy-2-nopunct": 2.669924090133771,
        "distinct-3-nopunct": 0.9525469981807155,
        "vocab_size-3-nopunct": 6283,
        "unique-3-nopunct": 6080,
        "entropy-3-nopunct": 12.574944683780313,
        "cond_entropy-3-nopunct": 0.45252608547622647,
        "msttr-100": 0.72373,
        "msttr-100_nopunct": 0.76014,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20907738095238096,
            "2": 0.42566619915848525,
            "3": 0.7326338639652678
        },
        "nist": 8.287606861874307,
        "bleu": 38.83949,
        "rouge1": {
            "precision": 0.74731,
            "recall": 0.69689,
            "fmeasure": 0.71199
        },
        "rouge2": {
            "precision": 0.48976,
            "recall": 0.4561,
            "fmeasure": 0.46558
        },
        "rougeL": {
            "precision": 0.59855,
            "recall": 0.56581,
            "fmeasure": 0.57357
        },
        "rougeLsum": {
            "precision": 0.59855,
            "recall": 0.56581,
            "fmeasure": 0.57357
        },
        "nubia": {
            "semantic_relation": 3.99001,
            "contradiction": 10.02143,
            "irrelevancy": 31.13489,
            "logical_agreement": 58.84368,
            "grammar_ref": 4.27824,
            "grammar_hyp": 4.36831,
            "nubia_score": 0.66673
        },
        "meteor": 0.35975897418895736,
        "bleurt": 0.09873,
        "bertscore": {
            "precision": 0.91833,
            "recall": 0.91046,
            "f1": 0.91275
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_73": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.1523912776298655,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.254547113768295,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.9841837197791885,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.28151981340693205,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.7647058823529411
        },
        "nist": 3.3507664496295355,
        "bleu": 16.13542,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.84211,
            "fmeasure": 0.82051
        },
        "rouge2": {
            "precision": 0.36842,
            "recall": 0.38889,
            "fmeasure": 0.37838
        },
        "rougeL": {
            "precision": 0.45,
            "recall": 0.47368,
            "fmeasure": 0.46154
        },
        "rougeLsum": {
            "precision": 0.45,
            "recall": 0.47368,
            "fmeasure": 0.46154
        },
        "nubia": {
            "semantic_relation": 4.44241,
            "contradiction": 0.59201,
            "irrelevancy": 50.2765,
            "logical_agreement": 49.1315,
            "grammar_ref": 4.70075,
            "grammar_hyp": 4.77602,
            "nubia_score": 0.74502
        },
        "meteor": 0.39020458537073555,
        "bleurt": 0.31063,
        "bertscore": {
            "precision": 0.92693,
            "recall": 0.92021,
            "f1": 0.92299
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_74": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "nist": 1.9877836651684964,
        "bleu": 41.72261,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.67407,
            "fmeasure": 0.67789
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.42857,
            "fmeasure": 0.42967
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.67407,
            "fmeasure": 0.67789
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.67407,
            "fmeasure": 0.67789
        },
        "nubia": {
            "semantic_relation": 4.14875,
            "contradiction": 0.05561,
            "irrelevancy": 34.18796,
            "logical_agreement": 65.75644,
            "grammar_ref": 4.68314,
            "grammar_hyp": 5.32832,
            "nubia_score": 0.69679
        },
        "meteor": 0.3832699063476993,
        "bleurt": 0.43554,
        "bertscore": {
            "precision": 0.95353,
            "recall": 0.96991,
            "f1": 0.96165
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_24": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 106,
        "mean_pred_length": 26.5,
        "std_pred_length": 4.924428900898052,
        "median_pred_length": 24.0,
        "min_pred_length": 23,
        "max_pred_length": 35,
        "distinct-1": 0.6320754716981132,
        "vocab_size-1": 67,
        "unique-1": 55,
        "entropy-1": 5.558297630820163,
        "distinct-2": 0.8529411764705882,
        "vocab_size-2": 87,
        "unique-2": 75,
        "entropy-2": 6.342919062810355,
        "cond_entropy-2": 0.8149501456593106,
        "distinct-3": 0.9183673469387755,
        "vocab_size-3": 90,
        "unique-3": 82,
        "entropy-3": 6.451444537992765,
        "cond_entropy-3": 0.11177062943388448,
        "total_length-nopunct": 82,
        "mean_pred_length-nopunct": 20.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7804878048780488,
        "vocab_size-1-nopunct": 64,
        "unique-1-nopunct": 55,
        "entropy-1-nopunct": 5.7629802058112105,
        "distinct-2-nopunct": 0.9102564102564102,
        "vocab_size-2-nopunct": 71,
        "unique-2-nopunct": 64,
        "entropy-2-nopunct": 6.105915039375072,
        "cond_entropy-2-nopunct": 0.3531056629806049,
        "distinct-3-nopunct": 0.9324324324324325,
        "vocab_size-3-nopunct": 69,
        "unique-3-nopunct": 64,
        "entropy-3-nopunct": 6.0743182304938195,
        "cond_entropy-3-nopunct": -0.03540831269275829,
        "msttr-100": 0.64,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.20454545454545456,
            "3": 0.5263157894736842
        },
        "nist": 3.050927771837811,
        "bleu": 33.20052,
        "rouge1": {
            "precision": 0.57997,
            "recall": 0.46246,
            "fmeasure": 0.50491
        },
        "rouge2": {
            "precision": 0.38331,
            "recall": 0.32911,
            "fmeasure": 0.33782
        },
        "rougeL": {
            "precision": 0.49904,
            "recall": 0.43369,
            "fmeasure": 0.44419
        },
        "rougeLsum": {
            "precision": 0.49904,
            "recall": 0.43369,
            "fmeasure": 0.44419
        },
        "nubia": {
            "semantic_relation": 2.98404,
            "contradiction": 4.16792,
            "irrelevancy": 49.29801,
            "logical_agreement": 46.53406,
            "grammar_ref": 4.25341,
            "grammar_hyp": 4.59233,
            "nubia_score": 0.35296
        },
        "meteor": 0.26924684287424894,
        "bleurt": -0.46576,
        "bertscore": {
            "precision": 0.86043,
            "recall": 0.86332,
            "f1": 0.85695
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_52": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 43,
        "total_length": 706,
        "mean_pred_length": 16.41860465116279,
        "std_pred_length": 5.1454769396745474,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.5325779036827195,
        "vocab_size-1": 376,
        "unique-1": 307,
        "entropy-1": 7.506546075156804,
        "distinct-2": 0.9049773755656109,
        "vocab_size-2": 600,
        "unique-2": 558,
        "entropy-2": 9.146786153005735,
        "cond_entropy-2": 1.4361953631757904,
        "distinct-3": 0.964516129032258,
        "vocab_size-3": 598,
        "unique-3": 579,
        "entropy-3": 9.200713296399806,
        "cond_entropy-3": 0.041365236944618154,
        "total_length-nopunct": 618,
        "mean_pred_length-nopunct": 14.372093023255815,
        "std_pred_length-nopunct": 4.730029036805281,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5954692556634305,
        "vocab_size-1-nopunct": 368,
        "unique-1-nopunct": 305,
        "entropy-1-nopunct": 7.681253392510649,
        "distinct-2-nopunct": 0.9095652173913044,
        "vocab_size-2-nopunct": 523,
        "unique-2-nopunct": 487,
        "entropy-2-nopunct": 8.952417010343892,
        "cond_entropy-2-nopunct": 1.3334329664621944,
        "distinct-3-nopunct": 0.9699248120300752,
        "vocab_size-3-nopunct": 516,
        "unique-3-nopunct": 501,
        "entropy-3-nopunct": 8.993713098091208,
        "cond_entropy-3-nopunct": 0.03745649460127064,
        "msttr-100": 0.71286,
        "msttr-100_nopunct": 0.76833,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2672413793103448,
            "2": 0.48120300751879697,
            "3": 0.8278301886792453
        },
        "nist": 6.991561978599554,
        "bleu": 52.84702,
        "rouge1": {
            "precision": 0.78156,
            "recall": 0.79425,
            "fmeasure": 0.77718
        },
        "rouge2": {
            "precision": 0.60127,
            "recall": 0.61105,
            "fmeasure": 0.59862
        },
        "rougeL": {
            "precision": 0.70695,
            "recall": 0.7246,
            "fmeasure": 0.70611
        },
        "rougeLsum": {
            "precision": 0.70695,
            "recall": 0.7246,
            "fmeasure": 0.70611
        },
        "nubia": {
            "semantic_relation": 4.24063,
            "contradiction": 10.13494,
            "irrelevancy": 28.63281,
            "logical_agreement": 61.23225,
            "grammar_ref": 4.51918,
            "grammar_hyp": 4.48654,
            "nubia_score": 0.75533
        },
        "meteor": 0.4268411186816352,
        "bleurt": 0.32572,
        "bertscore": {
            "precision": 0.93395,
            "recall": 0.93874,
            "f1": 0.93466
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_75": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 44,
        "total_length": 720,
        "mean_pred_length": 16.363636363636363,
        "std_pred_length": 6.060643939275569,
        "median_pred_length": 15.5,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.5333333333333333,
        "vocab_size-1": 384,
        "unique-1": 302,
        "entropy-1": 7.6498321079056675,
        "distinct-2": 0.915680473372781,
        "vocab_size-2": 619,
        "unique-2": 572,
        "entropy-2": 9.21461294669516,
        "cond_entropy-2": 1.3803745095018103,
        "distinct-3": 0.9762658227848101,
        "vocab_size-3": 617,
        "unique-3": 603,
        "entropy-3": 9.25511795149646,
        "cond_entropy-3": 0.03803797638315714,
        "total_length-nopunct": 618,
        "mean_pred_length-nopunct": 14.045454545454545,
        "std_pred_length-nopunct": 5.067519320744195,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6116504854368932,
        "vocab_size-1-nopunct": 378,
        "unique-1-nopunct": 302,
        "entropy-1-nopunct": 7.878448691265523,
        "distinct-2-nopunct": 0.9372822299651568,
        "vocab_size-2-nopunct": 538,
        "unique-2-nopunct": 511,
        "entropy-2-nopunct": 9.020026683716136,
        "cond_entropy-2-nopunct": 1.2048663697807673,
        "distinct-3-nopunct": 0.9886792452830189,
        "vocab_size-3-nopunct": 524,
        "unique-3-nopunct": 518,
        "entropy-3-nopunct": 9.027207040016611,
        "cond_entropy-3-nopunct": 0.008349871749527824,
        "msttr-100": 0.74714,
        "msttr-100_nopunct": 0.8,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21782178217821782,
            "2": 0.528,
            "3": 0.7840172786177105
        },
        "nist": 7.038534498704083,
        "bleu": 49.70584,
        "rouge1": {
            "precision": 0.79139,
            "recall": 0.75936,
            "fmeasure": 0.7668
        },
        "rouge2": {
            "precision": 0.56653,
            "recall": 0.5535,
            "fmeasure": 0.55319
        },
        "rougeL": {
            "precision": 0.69726,
            "recall": 0.67883,
            "fmeasure": 0.68007
        },
        "rougeLsum": {
            "precision": 0.69726,
            "recall": 0.67883,
            "fmeasure": 0.68007
        },
        "nubia": {
            "semantic_relation": 4.3099,
            "contradiction": 4.33654,
            "irrelevancy": 24.24496,
            "logical_agreement": 71.41849,
            "grammar_ref": 4.70505,
            "grammar_hyp": 4.76014,
            "nubia_score": 0.76949
        },
        "meteor": 0.41434142408704444,
        "bleurt": 0.32999,
        "bertscore": {
            "precision": 0.93249,
            "recall": 0.92869,
            "f1": 0.92935
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc": {
        "predictions_file": "ByT5-base (Baseline)/wiki_auto_asset_turk_challenge_test_turk_nopunc",
        "N": 359,
        "total_length": 5934,
        "mean_pred_length": 16.52924791086351,
        "std_pred_length": 6.059924270497689,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.37192450286484663,
        "vocab_size-1": 2207,
        "unique-1": 1638,
        "entropy-1": 9.015810267504348,
        "distinct-2": 0.8371300448430493,
        "vocab_size-2": 4667,
        "unique-2": 4327,
        "entropy-2": 11.878776031915287,
        "cond_entropy-2": 2.673068592962124,
        "distinct-3": 0.9649156441717791,
        "vocab_size-3": 5033,
        "unique-3": 4951,
        "entropy-3": 12.228416698977158,
        "cond_entropy-3": 0.3735085951291917,
        "total_length-nopunct": 5338,
        "mean_pred_length-nopunct": 14.869080779944289,
        "std_pred_length-nopunct": 5.613564649016124,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4112026976395654,
        "vocab_size-1-nopunct": 2195,
        "unique-1-nopunct": 1635,
        "entropy-1-nopunct": 9.283509861058992,
        "distinct-2-nopunct": 0.8578027716408917,
        "vocab_size-2-nopunct": 4271,
        "unique-2-nopunct": 3982,
        "entropy-2-nopunct": 11.812687132460374,
        "cond_entropy-2-nopunct": 2.6830905297429593,
        "distinct-3-nopunct": 0.9803030303030303,
        "vocab_size-3-nopunct": 4529,
        "unique-3-nopunct": 4460,
        "entropy-3-nopunct": 12.128737112721995,
        "cond_entropy-3-nopunct": 0.33992933290672284,
        "msttr-100": 0.73475,
        "msttr-100_nopunct": 0.76717,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_nopunc.json",
        "local_recall": {
            "1": 0.04138370118845501,
            "2": 0.14431673052362706,
            "3": 0.3063457330415755,
            "4": 0.39461172741679873,
            "5": 0.4984423676012461,
            "6": 0.6183574879227053,
            "7": 0.7541046200840015
        },
        "nist": 8.130911696550122,
        "bleu": 56.47645,
        "rouge1": {
            "precision": 0.81505,
            "recall": 0.68423,
            "fmeasure": 0.72786
        },
        "rouge2": {
            "precision": 0.64846,
            "recall": 0.53719,
            "fmeasure": 0.57278
        },
        "rougeL": {
            "precision": 0.77686,
            "recall": 0.65254,
            "fmeasure": 0.69327
        },
        "rougeLsum": {
            "precision": 0.77686,
            "recall": 0.65254,
            "fmeasure": 0.69327
        },
        "sari": 42.38017,
        "nubia": {
            "semantic_relation": 3.93994,
            "contradiction": 6.85396,
            "irrelevancy": 18.7837,
            "logical_agreement": 74.36234,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.02112,
            "nubia_score": 0.60046
        },
        "meteor": 0.37618837500301305,
        "bleurt": 0.01623,
        "bertscore": {
            "precision": 0.94003,
            "recall": 0.91233,
            "f1": 0.92249
        }
    },
    "cs_restaurants_validation": {
        "predictions_file": "ByT5-base (Baseline)/cs_restaurants_validation",
        "N": 781,
        "total_length": 8075,
        "mean_pred_length": 10.339308578745198,
        "std_pred_length": 4.1795617624073795,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 23,
        "distinct-1": 0.06043343653250774,
        "vocab_size-1": 488,
        "unique-1": 143,
        "entropy-1": 7.047032397531461,
        "distinct-2": 0.20962434877981903,
        "vocab_size-2": 1529,
        "unique-2": 694,
        "entropy-2": 9.397943859663126,
        "cond_entropy-2": 2.0457545573101314,
        "distinct-3": 0.3583602026715799,
        "vocab_size-3": 2334,
        "unique-3": 1335,
        "entropy-3": 10.29633149503424,
        "cond_entropy-3": 0.8140526963932333,
        "total_length-nopunct": 6996,
        "mean_pred_length-nopunct": 8.95774647887324,
        "std_pred_length-nopunct": 3.8251820161730605,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.06918238993710692,
        "vocab_size-1-nopunct": 484,
        "unique-1-nopunct": 143,
        "entropy-1-nopunct": 7.258321781741767,
        "distinct-2-nopunct": 0.2251005631536605,
        "vocab_size-2-nopunct": 1399,
        "unique-2-nopunct": 661,
        "entropy-2-nopunct": 9.31381624049866,
        "cond_entropy-2-nopunct": 2.0621830473793565,
        "distinct-3-nopunct": 0.38443135811556867,
        "vocab_size-3-nopunct": 2089,
        "unique-3-nopunct": 1238,
        "entropy-3-nopunct": 10.20841517732911,
        "cond_entropy-3-nopunct": 0.815202645515166,
        "msttr-100": 0.6205,
        "msttr-100_nopunct": 0.65623,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_validation.json",
        "local_recall": {
            "1": 0.40606508875739644
        },
        "nist": 3.4814034525207265,
        "bleu": 14.4633,
        "rouge1": {
            "precision": 0.44767,
            "recall": 0.45702,
            "fmeasure": 0.4382
        },
        "rouge2": {
            "precision": 0.25459,
            "recall": 0.26509,
            "fmeasure": 0.2502
        },
        "rougeL": {
            "precision": 0.40159,
            "recall": 0.41134,
            "fmeasure": 0.39353
        },
        "rougeLsum": {
            "precision": 0.40159,
            "recall": 0.41134,
            "fmeasure": 0.39353
        },
        "nubia": {
            "semantic_relation": 3.04912,
            "contradiction": 21.69843,
            "irrelevancy": 31.92631,
            "logical_agreement": 46.37526,
            "grammar_ref": 6.54085,
            "grammar_hyp": 6.54538,
            "nubia_score": 0.40993
        },
        "meteor": 0.2105287237165738,
        "bleurt": -0.22895,
        "bertscore": {
            "precision": 0.89016,
            "recall": 0.88684,
            "f1": 0.88827
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_54": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 80,
        "total_length": 1325,
        "mean_pred_length": 16.5625,
        "std_pred_length": 5.444822655514135,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.49056603773584906,
        "vocab_size-1": 650,
        "unique-1": 527,
        "entropy-1": 8.024817084093339,
        "distinct-2": 0.8795180722891566,
        "vocab_size-2": 1095,
        "unique-2": 1015,
        "entropy-2": 9.95888310432067,
        "cond_entropy-2": 1.7362262643668704,
        "distinct-3": 0.9742489270386266,
        "vocab_size-3": 1135,
        "unique-3": 1111,
        "entropy-3": 10.130724260989755,
        "cond_entropy-3": 0.1827845183047638,
        "total_length-nopunct": 1159,
        "mean_pred_length-nopunct": 14.4875,
        "std_pred_length-nopunct": 4.785378119856361,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5539257981018119,
        "vocab_size-1-nopunct": 642,
        "unique-1-nopunct": 525,
        "entropy-1-nopunct": 8.257571370448472,
        "distinct-2-nopunct": 0.8897126969416126,
        "vocab_size-2-nopunct": 960,
        "unique-2-nopunct": 899,
        "entropy-2-nopunct": 9.76995172254893,
        "cond_entropy-2-nopunct": 1.6175785894274735,
        "distinct-3-nopunct": 0.977977977977978,
        "vocab_size-3-nopunct": 977,
        "unique-3-nopunct": 961,
        "entropy-3-nopunct": 9.915762964876379,
        "cond_entropy-3-nopunct": 0.1646873500896611,
        "msttr-100": 0.72538,
        "msttr-100_nopunct": 0.76727,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1864406779661017,
            "2": 0.4298245614035088,
            "3": 0.7244501940491591
        },
        "nist": 6.750189496254066,
        "bleu": 40.34723,
        "rouge1": {
            "precision": 0.70415,
            "recall": 0.67226,
            "fmeasure": 0.67488
        },
        "rouge2": {
            "precision": 0.44233,
            "recall": 0.43221,
            "fmeasure": 0.42752
        },
        "rougeL": {
            "precision": 0.6022,
            "recall": 0.58159,
            "fmeasure": 0.57882
        },
        "rougeLsum": {
            "precision": 0.6022,
            "recall": 0.58159,
            "fmeasure": 0.57882
        },
        "nubia": {
            "semantic_relation": 3.8876,
            "contradiction": 14.08555,
            "irrelevancy": 35.26198,
            "logical_agreement": 50.65248,
            "grammar_ref": 4.56456,
            "grammar_hyp": 4.58807,
            "nubia_score": 0.62454
        },
        "meteor": 0.3465358859026684,
        "bleurt": 0.12407,
        "bertscore": {
            "precision": 0.91137,
            "recall": 0.90931,
            "f1": 0.90834
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_30": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 122,
        "total_length": 2006,
        "mean_pred_length": 16.442622950819672,
        "std_pred_length": 5.412567616399468,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.452642073778664,
        "vocab_size-1": 908,
        "unique-1": 718,
        "entropy-1": 8.337015794252384,
        "distinct-2": 0.8481953290870489,
        "vocab_size-2": 1598,
        "unique-2": 1450,
        "entropy-2": 10.47234807666879,
        "cond_entropy-2": 1.9168794202779016,
        "distinct-3": 0.9517593643586834,
        "vocab_size-3": 1677,
        "unique-3": 1618,
        "entropy-3": 10.66784846261572,
        "cond_entropy-3": 0.1899647138094279,
        "total_length-nopunct": 1781,
        "mean_pred_length-nopunct": 14.598360655737705,
        "std_pred_length-nopunct": 5.037010296037368,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5042111173498035,
        "vocab_size-1-nopunct": 898,
        "unique-1-nopunct": 715,
        "entropy-1-nopunct": 8.573123646398,
        "distinct-2-nopunct": 0.864376130198915,
        "vocab_size-2-nopunct": 1434,
        "unique-2-nopunct": 1321,
        "entropy-2-nopunct": 10.32480661889961,
        "cond_entropy-2-nopunct": 1.8383314087616134,
        "distinct-3-nopunct": 0.9583604424202993,
        "vocab_size-3-nopunct": 1473,
        "unique-3-nopunct": 1430,
        "entropy-3-nopunct": 10.48529690155604,
        "cond_entropy-3-nopunct": 0.17486339308990545,
        "msttr-100": 0.736,
        "msttr-100_nopunct": 0.77118,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1842696629213483,
            "2": 0.41839762611275966,
            "3": 0.7586972612879349
        },
        "nist": 7.501024888767768,
        "bleu": 45.73204,
        "rouge1": {
            "precision": 0.75099,
            "recall": 0.73107,
            "fmeasure": 0.72871
        },
        "rouge2": {
            "precision": 0.53008,
            "recall": 0.50537,
            "fmeasure": 0.50991
        },
        "rougeL": {
            "precision": 0.65386,
            "recall": 0.63433,
            "fmeasure": 0.63366
        },
        "rougeLsum": {
            "precision": 0.65386,
            "recall": 0.63433,
            "fmeasure": 0.63366
        },
        "nubia": {
            "semantic_relation": 4.17112,
            "contradiction": 10.03443,
            "irrelevancy": 26.30333,
            "logical_agreement": 63.66224,
            "grammar_ref": 4.69288,
            "grammar_hyp": 4.65694,
            "nubia_score": 0.7156
        },
        "meteor": 0.38695922944920297,
        "bleurt": 0.2306,
        "bertscore": {
            "precision": 0.92598,
            "recall": 0.92059,
            "f1": 0.92146
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_12": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 158,
        "total_length": 2565,
        "mean_pred_length": 16.234177215189874,
        "std_pred_length": 5.591774838279211,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.4226120857699805,
        "vocab_size-1": 1084,
        "unique-1": 843,
        "entropy-1": 8.445258990263055,
        "distinct-2": 0.8147071042791857,
        "vocab_size-2": 1961,
        "unique-2": 1782,
        "entropy-2": 10.66597834556136,
        "cond_entropy-2": 1.9731786408230814,
        "distinct-3": 0.9208537127612272,
        "vocab_size-3": 2071,
        "unique-3": 1995,
        "entropy-3": 10.915720555197971,
        "cond_entropy-3": 0.25906344498632,
        "total_length-nopunct": 2240,
        "mean_pred_length-nopunct": 14.177215189873417,
        "std_pred_length-nopunct": 5.013297491522266,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4785714285714286,
        "vocab_size-1-nopunct": 1072,
        "unique-1-nopunct": 839,
        "entropy-1-nopunct": 8.735615393231143,
        "distinct-2-nopunct": 0.8362151777137368,
        "vocab_size-2-nopunct": 1741,
        "unique-2-nopunct": 1606,
        "entropy-2-nopunct": 10.510349526946818,
        "cond_entropy-2-nopunct": 1.8846027584994878,
        "distinct-3-nopunct": 0.9261954261954262,
        "vocab_size-3-nopunct": 1782,
        "unique-3-nopunct": 1724,
        "entropy-3-nopunct": 10.702581852252303,
        "cond_entropy-3-nopunct": 0.21910410127461047,
        "msttr-100": 0.7312,
        "msttr-100_nopunct": 0.77773,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25618374558303886,
            "2": 0.4762845849802372,
            "3": 0.7557921102066374
        },
        "nist": 7.799010023746016,
        "bleu": 43.53123,
        "rouge1": {
            "precision": 0.74813,
            "recall": 0.71631,
            "fmeasure": 0.72031
        },
        "rouge2": {
            "precision": 0.49683,
            "recall": 0.47798,
            "fmeasure": 0.47872
        },
        "rougeL": {
            "precision": 0.63005,
            "recall": 0.60612,
            "fmeasure": 0.60806
        },
        "rougeLsum": {
            "precision": 0.63005,
            "recall": 0.60612,
            "fmeasure": 0.60806
        },
        "nubia": {
            "semantic_relation": 4.1205,
            "contradiction": 6.60542,
            "irrelevancy": 32.3441,
            "logical_agreement": 61.05048,
            "grammar_ref": 4.68014,
            "grammar_hyp": 4.68397,
            "nubia_score": 0.71518
        },
        "meteor": 0.3809266427476741,
        "bleurt": 0.21338,
        "bertscore": {
            "precision": 0.92549,
            "recall": 0.91853,
            "f1": 0.92053
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 36,
        "total_length": 569,
        "mean_pred_length": 15.805555555555555,
        "std_pred_length": 5.3945417087008956,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.5184534270650264,
        "vocab_size-1": 295,
        "unique-1": 238,
        "entropy-1": 7.26307811206406,
        "distinct-2": 0.8367729831144465,
        "vocab_size-2": 446,
        "unique-2": 407,
        "entropy-2": 8.611534986753052,
        "cond_entropy-2": 1.1314148703630322,
        "distinct-3": 0.9275653923541247,
        "vocab_size-3": 461,
        "unique-3": 439,
        "entropy-3": 8.785303091893796,
        "cond_entropy-3": 0.1572847650797727,
        "total_length-nopunct": 492,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 4.196559437338057,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.5772357723577236,
        "vocab_size-1-nopunct": 284,
        "unique-1-nopunct": 233,
        "entropy-1-nopunct": 7.359525958630203,
        "distinct-2-nopunct": 0.8399122807017544,
        "vocab_size-2-nopunct": 383,
        "unique-2-nopunct": 352,
        "entropy-2-nopunct": 8.387842009159106,
        "cond_entropy-2-nopunct": 1.0874564840219458,
        "distinct-3-nopunct": 0.9357142857142857,
        "vocab_size-3-nopunct": 393,
        "unique-3-nopunct": 376,
        "entropy-3-nopunct": 8.562163843902018,
        "cond_entropy-3-nopunct": 0.16543336016685783,
        "msttr-100": 0.708,
        "msttr-100_nopunct": 0.735,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18811881188118812,
            "2": 0.5238095238095238,
            "3": 0.718475073313783
        },
        "nist": 6.281258106314923,
        "bleu": 41.33342,
        "rouge1": {
            "precision": 0.73906,
            "recall": 0.71747,
            "fmeasure": 0.70942
        },
        "rouge2": {
            "precision": 0.51689,
            "recall": 0.50256,
            "fmeasure": 0.49501
        },
        "rougeL": {
            "precision": 0.65662,
            "recall": 0.64067,
            "fmeasure": 0.63131
        },
        "rougeLsum": {
            "precision": 0.65662,
            "recall": 0.64067,
            "fmeasure": 0.63131
        },
        "nubia": {
            "semantic_relation": 4.0649,
            "contradiction": 9.96102,
            "irrelevancy": 33.57011,
            "logical_agreement": 56.46887,
            "grammar_ref": 4.68979,
            "grammar_hyp": 4.61916,
            "nubia_score": 0.6905
        },
        "meteor": 0.3657492250833337,
        "bleurt": 0.24331,
        "bertscore": {
            "precision": 0.92575,
            "recall": 0.91781,
            "f1": 0.91961
        }
    },
    "cs_restaurants_test": {
        "predictions_file": "ByT5-base (Baseline)/cs_restaurants_test",
        "N": 842,
        "total_length": 9358,
        "mean_pred_length": 11.114014251781473,
        "std_pred_length": 3.728788725372721,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 23,
        "distinct-1": 0.07052789057490917,
        "vocab_size-1": 660,
        "unique-1": 242,
        "entropy-1": 6.929556357154123,
        "distinct-2": 0.21735556599342415,
        "vocab_size-2": 1851,
        "unique-2": 994,
        "entropy-2": 9.0100916876198,
        "cond_entropy-2": 1.879375897328946,
        "distinct-3": 0.35613760750586393,
        "vocab_size-3": 2733,
        "unique-3": 1892,
        "entropy-3": 9.70286710961635,
        "cond_entropy-3": 0.772488459914995,
        "total_length-nopunct": 7811,
        "mean_pred_length-nopunct": 9.276722090261282,
        "std_pred_length-nopunct": 3.369297549549165,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.08398412495199079,
        "vocab_size-1-nopunct": 656,
        "unique-1-nopunct": 242,
        "entropy-1-nopunct": 7.221875539200603,
        "distinct-2-nopunct": 0.2311665949203616,
        "vocab_size-2-nopunct": 1611,
        "unique-2-nopunct": 895,
        "entropy-2-nopunct": 8.894570956284237,
        "cond_entropy-2-nopunct": 1.8570995396499148,
        "distinct-3-nopunct": 0.38632283336053536,
        "vocab_size-3-nopunct": 2367,
        "unique-3-nopunct": 1683,
        "entropy-3-nopunct": 9.649305172043817,
        "cond_entropy-3-nopunct": 0.8807232140045119,
        "msttr-100": 0.59419,
        "msttr-100_nopunct": 0.63718,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.45649764477694654
        },
        "nist": 3.8346599015114298,
        "bleu": 16.33955,
        "rouge1": {
            "precision": 0.49969,
            "recall": 0.52716,
            "fmeasure": 0.49635
        },
        "rouge2": {
            "precision": 0.27396,
            "recall": 0.28435,
            "fmeasure": 0.27015
        },
        "rougeL": {
            "precision": 0.44288,
            "recall": 0.46951,
            "fmeasure": 0.44096
        },
        "rougeLsum": {
            "precision": 0.44288,
            "recall": 0.46951,
            "fmeasure": 0.44096
        },
        "nubia": {
            "semantic_relation": 3.31376,
            "contradiction": 21.97053,
            "irrelevancy": 34.54146,
            "logical_agreement": 43.48801,
            "grammar_ref": 6.8707,
            "grammar_hyp": 6.72952,
            "nubia_score": 0.48877
        },
        "meteor": 0.2300660395849057,
        "bleurt": -0.25076,
        "bertscore": {
            "precision": 0.88667,
            "recall": 0.89783,
            "f1": 0.89181
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_25": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714,
            "3": 0.1111111111111111
        },
        "nist": 1.4262048549433524,
        "bleu": 6.4798,
        "rouge1": {
            "precision": 0.38462,
            "recall": 0.3125,
            "fmeasure": 0.34483
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.06667,
            "fmeasure": 0.07407
        },
        "rougeL": {
            "precision": 0.38462,
            "recall": 0.3125,
            "fmeasure": 0.34483
        },
        "rougeLsum": {
            "precision": 0.38462,
            "recall": 0.3125,
            "fmeasure": 0.34483
        },
        "nubia": {
            "semantic_relation": 2.85838,
            "contradiction": 1.80584,
            "irrelevancy": 49.49075,
            "logical_agreement": 48.70341,
            "grammar_ref": 3.92881,
            "grammar_hyp": 4.01716,
            "nubia_score": 0.38558
        },
        "meteor": 0.13441419057808499,
        "bleurt": -0.52802,
        "bertscore": {
            "precision": 0.85274,
            "recall": 0.81393,
            "f1": 0.83289
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_76": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 33,
        "total_length": 540,
        "mean_pred_length": 16.363636363636363,
        "std_pred_length": 4.09595648220684,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.5703703703703704,
        "vocab_size-1": 308,
        "unique-1": 272,
        "entropy-1": 7.213220835326767,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 468,
        "unique-2": 446,
        "entropy-2": 8.769637812072165,
        "cond_entropy-2": 1.374796743046828,
        "distinct-3": 0.9852320675105485,
        "vocab_size-3": 467,
        "unique-3": 462,
        "entropy-3": 8.854987974636611,
        "cond_entropy-3": 0.0835247113467356,
        "total_length-nopunct": 467,
        "mean_pred_length-nopunct": 14.151515151515152,
        "std_pred_length-nopunct": 3.750726896185649,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6466809421841542,
        "vocab_size-1-nopunct": 302,
        "unique-1-nopunct": 271,
        "entropy-1-nopunct": 7.365316872877027,
        "distinct-2-nopunct": 0.9262672811059908,
        "vocab_size-2-nopunct": 402,
        "unique-2-nopunct": 385,
        "entropy-2-nopunct": 8.545847335347279,
        "cond_entropy-2-nopunct": 1.2774726018923659,
        "distinct-3-nopunct": 0.9875311720698254,
        "vocab_size-3-nopunct": 396,
        "unique-3-nopunct": 393,
        "entropy-3-nopunct": 8.61753323942242,
        "cond_entropy-3-nopunct": 0.08444956642979566,
        "msttr-100": 0.706,
        "msttr-100_nopunct": 0.7525,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2125,
            "2": 0.22388059701492538,
            "3": 0.7804878048780488
        },
        "nist": 6.873531684930377,
        "bleu": 47.18044,
        "rouge1": {
            "precision": 0.8178,
            "recall": 0.76604,
            "fmeasure": 0.78274
        },
        "rouge2": {
            "precision": 0.59669,
            "recall": 0.5554,
            "fmeasure": 0.56907
        },
        "rougeL": {
            "precision": 0.69766,
            "recall": 0.65776,
            "fmeasure": 0.67011
        },
        "rougeLsum": {
            "precision": 0.69766,
            "recall": 0.65776,
            "fmeasure": 0.67011
        },
        "nubia": {
            "semantic_relation": 4.47776,
            "contradiction": 3.05365,
            "irrelevancy": 23.87748,
            "logical_agreement": 73.06887,
            "grammar_ref": 4.92209,
            "grammar_hyp": 5.02063,
            "nubia_score": 0.78791
        },
        "meteor": 0.3997924607044112,
        "bleurt": 0.31831,
        "bertscore": {
            "precision": 0.94165,
            "recall": 0.93054,
            "f1": 0.93438
        }
    },
    "cs_restaurants_challenge_train_sample": {
        "predictions_file": "ByT5-base (Baseline)/cs_restaurants_challenge_train_sample",
        "N": 500
    },
    "cs_restaurants_challenge_validation_sample": {
        "predictions_file": "ByT5-base (Baseline)/cs_restaurants_challenge_validation_sample",
        "N": 500
    },
    "totto_test_contrast_challenge_table_size-table_size_13": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 35,
        "total_length": 535,
        "mean_pred_length": 15.285714285714286,
        "std_pred_length": 4.93136566753458,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.3644859813084112,
        "vocab_size-1": 195,
        "unique-1": 149,
        "entropy-1": 6.387223193549699,
        "distinct-2": 0.714,
        "vocab_size-2": 357,
        "unique-2": 311,
        "entropy-2": 8.125951240281493,
        "cond_entropy-2": 1.5791300669958894,
        "distinct-3": 0.8559139784946237,
        "vocab_size-3": 398,
        "unique-3": 375,
        "entropy-3": 8.450853923516728,
        "cond_entropy-3": 0.3293694071641459,
        "total_length-nopunct": 451,
        "mean_pred_length-nopunct": 12.885714285714286,
        "std_pred_length-nopunct": 4.111109885395417,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.4212860310421286,
        "vocab_size-1-nopunct": 190,
        "unique-1-nopunct": 149,
        "entropy-1-nopunct": 6.461944626271693,
        "distinct-2-nopunct": 0.7379807692307693,
        "vocab_size-2-nopunct": 307,
        "unique-2-nopunct": 272,
        "entropy-2-nopunct": 7.928013418222048,
        "cond_entropy-2-nopunct": 1.5354641628439738,
        "distinct-3-nopunct": 0.8556430446194225,
        "vocab_size-3-nopunct": 326,
        "unique-3-nopunct": 308,
        "entropy-3-nopunct": 8.157653291571933,
        "cond_entropy-3-nopunct": 0.26346589847380814,
        "msttr-100": 0.564,
        "msttr-100_nopunct": 0.5975,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19540229885057472,
            "2": 0.49038461538461536,
            "3": 0.7809798270893372
        },
        "nist": 6.796234884359934,
        "bleu": 54.8598,
        "rouge1": {
            "precision": 0.81699,
            "recall": 0.76055,
            "fmeasure": 0.78083
        },
        "rouge2": {
            "precision": 0.59041,
            "recall": 0.55619,
            "fmeasure": 0.56863
        },
        "rougeL": {
            "precision": 0.70688,
            "recall": 0.66851,
            "fmeasure": 0.68065
        },
        "rougeLsum": {
            "precision": 0.70688,
            "recall": 0.66851,
            "fmeasure": 0.68065
        },
        "nubia": {
            "semantic_relation": 4.15009,
            "contradiction": 3.60822,
            "irrelevancy": 21.0236,
            "logical_agreement": 75.36819,
            "grammar_ref": 4.23324,
            "grammar_hyp": 4.20692,
            "nubia_score": 0.7608
        },
        "meteor": 0.4167716725735804,
        "bleurt": 0.41268,
        "bertscore": {
            "precision": 0.94791,
            "recall": 0.9352,
            "f1": 0.94044
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_31": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 63,
        "mean_pred_length": 15.75,
        "std_pred_length": 4.437059837324712,
        "median_pred_length": 14.5,
        "min_pred_length": 11,
        "max_pred_length": 23,
        "distinct-1": 0.7936507936507936,
        "vocab_size-1": 50,
        "unique-1": 43,
        "entropy-1": 5.477124764701077,
        "distinct-2": 0.9661016949152542,
        "vocab_size-2": 57,
        "unique-2": 55,
        "entropy-2": 5.814846439192345,
        "cond_entropy-2": 0.29103918522062755,
        "distinct-3": 1.0,
        "vocab_size-3": 55,
        "unique-3": 55,
        "entropy-3": 5.7813597135246555,
        "cond_entropy-3": -0.028556063109908943,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.24037034920393,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.472446216661832,
        "distinct-2-nopunct": 0.9807692307692307,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.661978179679557,
        "cond_entropy-2-nopunct": 0.21529417112509297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.5849625007211605,
        "cond_entropy-3-nopunct": -0.07381055075326921,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.7272727272727273,
            "3": 0.7111111111111111
        },
        "nist": 4.866458635215782,
        "bleu": 56.11866,
        "rouge1": {
            "precision": 0.79405,
            "recall": 0.86318,
            "fmeasure": 0.80386
        },
        "rouge2": {
            "precision": 0.62413,
            "recall": 0.65529,
            "fmeasure": 0.6181
        },
        "rougeL": {
            "precision": 0.72247,
            "recall": 0.76932,
            "fmeasure": 0.72355
        },
        "rougeLsum": {
            "precision": 0.72247,
            "recall": 0.76932,
            "fmeasure": 0.72355
        },
        "nubia": {
            "semantic_relation": 3.92972,
            "contradiction": 0.24901,
            "irrelevancy": 50.3094,
            "logical_agreement": 49.44159,
            "grammar_ref": 4.43427,
            "grammar_hyp": 4.34598,
            "nubia_score": 0.67842
        },
        "meteor": 0.43794470355354953,
        "bleurt": 0.33772,
        "bertscore": {
            "precision": 0.94294,
            "recall": 0.95285,
            "f1": 0.9457
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_27": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 42,
        "mean_pred_length": 21.0,
        "std_pred_length": 10.0,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 31,
        "distinct-1": 0.8095238095238095,
        "vocab_size-1": 34,
        "unique-1": 31,
        "entropy-1": 4.829186840531065,
        "distinct-2": 0.95,
        "vocab_size-2": 38,
        "unique-2": 36,
        "entropy-2": 5.221928094887364,
        "cond_entropy-2": 0.4208977834686828,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": 0.03126257645096005,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.9393939393939394,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.923181998146335,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.03883444909293795,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.09621531525930291,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.3333333333333333,
            "3": 0.6666666666666666
        },
        "nist": 1.7983788408775132,
        "bleu": 15.55074,
        "rouge1": {
            "precision": 0.53977,
            "recall": 0.67601,
            "fmeasure": 0.56255
        },
        "rouge2": {
            "precision": 0.34855,
            "recall": 0.39744,
            "fmeasure": 0.34803
        },
        "rougeL": {
            "precision": 0.42109,
            "recall": 0.53425,
            "fmeasure": 0.44111
        },
        "rougeLsum": {
            "precision": 0.42109,
            "recall": 0.53425,
            "fmeasure": 0.44111
        },
        "nubia": {
            "semantic_relation": 3.87265,
            "contradiction": 0.54661,
            "irrelevancy": 66.34633,
            "logical_agreement": 33.10707,
            "grammar_ref": 5.41182,
            "grammar_hyp": 5.59566,
            "nubia_score": 0.40547
        },
        "meteor": 0.3272058257146578,
        "bleurt": -0.11859,
        "bertscore": {
            "precision": 0.82062,
            "recall": 0.90869,
            "f1": 0.8507
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_14": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 79,
        "total_length": 1363,
        "mean_pred_length": 17.253164556962027,
        "std_pred_length": 5.556313217220365,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.43653705062362436,
        "vocab_size-1": 595,
        "unique-1": 471,
        "entropy-1": 7.824493788093359,
        "distinct-2": 0.7850467289719626,
        "vocab_size-2": 1008,
        "unique-2": 924,
        "entropy-2": 9.629039647134201,
        "cond_entropy-2": 1.633525123560381,
        "distinct-3": 0.8863070539419087,
        "vocab_size-3": 1068,
        "unique-3": 1026,
        "entropy-3": 9.868246608318671,
        "cond_entropy-3": 0.26533489220929396,
        "total_length-nopunct": 1193,
        "mean_pred_length-nopunct": 15.10126582278481,
        "std_pred_length-nopunct": 4.897932750981348,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.4920368818105616,
        "vocab_size-1-nopunct": 587,
        "unique-1-nopunct": 470,
        "entropy-1-nopunct": 8.02681033334901,
        "distinct-2-nopunct": 0.7989228007181328,
        "vocab_size-2-nopunct": 890,
        "unique-2-nopunct": 822,
        "entropy-2-nopunct": 9.462290268081501,
        "cond_entropy-2-nopunct": 1.553630561729437,
        "distinct-3-nopunct": 0.8898550724637682,
        "vocab_size-3-nopunct": 921,
        "unique-3-nopunct": 885,
        "entropy-3-nopunct": 9.660740027276521,
        "cond_entropy-3-nopunct": 0.2430616684664164,
        "msttr-100": 0.72462,
        "msttr-100_nopunct": 0.74909,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1902834008097166,
            "2": 0.4891304347826087,
            "3": 0.7963594994311718
        },
        "nist": 7.329810697055224,
        "bleu": 48.70424,
        "rouge1": {
            "precision": 0.78196,
            "recall": 0.74943,
            "fmeasure": 0.75432
        },
        "rouge2": {
            "precision": 0.58518,
            "recall": 0.55666,
            "fmeasure": 0.5629
        },
        "rougeL": {
            "precision": 0.67255,
            "recall": 0.6453,
            "fmeasure": 0.6492
        },
        "rougeLsum": {
            "precision": 0.67255,
            "recall": 0.6453,
            "fmeasure": 0.6492
        },
        "nubia": {
            "semantic_relation": 4.06043,
            "contradiction": 11.69074,
            "irrelevancy": 30.41581,
            "logical_agreement": 57.89345,
            "grammar_ref": 4.4104,
            "grammar_hyp": 4.43861,
            "nubia_score": 0.69782
        },
        "meteor": 0.39189728604344976,
        "bleurt": 0.24191,
        "bertscore": {
            "precision": 0.93074,
            "recall": 0.93014,
            "f1": 0.92895
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_32": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 49,
        "total_length": 863,
        "mean_pred_length": 17.612244897959183,
        "std_pred_length": 5.2907941864807455,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.5388180764774044,
        "vocab_size-1": 465,
        "unique-1": 385,
        "entropy-1": 7.763343267025964,
        "distinct-2": 0.9078624078624079,
        "vocab_size-2": 739,
        "unique-2": 693,
        "entropy-2": 9.426878161931427,
        "cond_entropy-2": 1.501915123858889,
        "distinct-3": 0.9790849673202614,
        "vocab_size-3": 749,
        "unique-3": 734,
        "entropy-3": 9.536499091172084,
        "cond_entropy-3": 0.11727888256651915,
        "total_length-nopunct": 746,
        "mean_pred_length-nopunct": 15.224489795918368,
        "std_pred_length-nopunct": 4.72192154816646,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6112600536193029,
        "vocab_size-1-nopunct": 456,
        "unique-1-nopunct": 383,
        "entropy-1-nopunct": 7.954298998674367,
        "distinct-2-nopunct": 0.921090387374462,
        "vocab_size-2-nopunct": 642,
        "unique-2-nopunct": 609,
        "entropy-2-nopunct": 9.231630497412224,
        "cond_entropy-2-nopunct": 1.3696387200478268,
        "distinct-3-nopunct": 0.9876543209876543,
        "vocab_size-3-nopunct": 640,
        "unique-3-nopunct": 632,
        "entropy-3-nopunct": 9.315158644859864,
        "cond_entropy-3-nopunct": 0.09503406268599783,
        "msttr-100": 0.7125,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18556701030927836,
            "2": 0.4797687861271676,
            "3": 0.7703984819734345
        },
        "nist": 7.020867518247946,
        "bleu": 46.32368,
        "rouge1": {
            "precision": 0.76943,
            "recall": 0.71464,
            "fmeasure": 0.72932
        },
        "rouge2": {
            "precision": 0.53554,
            "recall": 0.49948,
            "fmeasure": 0.50788
        },
        "rougeL": {
            "precision": 0.66179,
            "recall": 0.61788,
            "fmeasure": 0.62904
        },
        "rougeLsum": {
            "precision": 0.66179,
            "recall": 0.61788,
            "fmeasure": 0.62904
        },
        "nubia": {
            "semantic_relation": 4.30809,
            "contradiction": 3.22109,
            "irrelevancy": 23.41397,
            "logical_agreement": 73.36494,
            "grammar_ref": 4.75318,
            "grammar_hyp": 4.82516,
            "nubia_score": 0.75477
        },
        "meteor": 0.38223907073638713,
        "bleurt": 0.30113,
        "bertscore": {
            "precision": 0.93325,
            "recall": 0.92423,
            "f1": 0.92675
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 41,
        "total_length": 553,
        "mean_pred_length": 13.487804878048781,
        "std_pred_length": 4.2490857049230115,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.45207956600361665,
        "vocab_size-1": 250,
        "unique-1": 200,
        "entropy-1": 6.869699994216003,
        "distinct-2": 0.794921875,
        "vocab_size-2": 407,
        "unique-2": 369,
        "entropy-2": 8.411265399847139,
        "cond_entropy-2": 1.2921022307036711,
        "distinct-3": 0.8938428874734607,
        "vocab_size-3": 421,
        "unique-3": 400,
        "entropy-3": 8.58248736979988,
        "cond_entropy-3": 0.16640614542976925,
        "total_length-nopunct": 474,
        "mean_pred_length-nopunct": 11.560975609756097,
        "std_pred_length-nopunct": 3.774424721068745,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.5147679324894515,
        "vocab_size-1-nopunct": 244,
        "unique-1-nopunct": 199,
        "entropy-1-nopunct": 7.002914056409227,
        "distinct-2-nopunct": 0.815242494226328,
        "vocab_size-2-nopunct": 353,
        "unique-2-nopunct": 322,
        "entropy-2-nopunct": 8.230979133044286,
        "cond_entropy-2-nopunct": 1.3002429536738522,
        "distinct-3-nopunct": 0.9107142857142857,
        "vocab_size-3-nopunct": 357,
        "unique-3-nopunct": 340,
        "entropy-3-nopunct": 8.371696770317183,
        "cond_entropy-3-nopunct": 0.1397406152039364,
        "msttr-100": 0.614,
        "msttr-100_nopunct": 0.665,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5289256198347108,
            "3": 0.8121212121212121
        },
        "nist": 6.88100359882096,
        "bleu": 53.70364,
        "rouge1": {
            "precision": 0.77072,
            "recall": 0.75483,
            "fmeasure": 0.75629
        },
        "rouge2": {
            "precision": 0.56644,
            "recall": 0.55215,
            "fmeasure": 0.55266
        },
        "rougeL": {
            "precision": 0.67621,
            "recall": 0.66044,
            "fmeasure": 0.66081
        },
        "rougeLsum": {
            "precision": 0.67621,
            "recall": 0.66044,
            "fmeasure": 0.66081
        },
        "nubia": {
            "semantic_relation": 4.04287,
            "contradiction": 5.01839,
            "irrelevancy": 34.04864,
            "logical_agreement": 60.93297,
            "grammar_ref": 4.45723,
            "grammar_hyp": 4.44504,
            "nubia_score": 0.7255
        },
        "meteor": 0.4251149419103563,
        "bleurt": 0.33847,
        "bertscore": {
            "precision": 0.93937,
            "recall": 0.93857,
            "f1": 0.93692
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-base (Baseline)/e2e_nlg_test",
        "N": 120,
        "total_length": 2109,
        "mean_pred_length": 17.575,
        "std_pred_length": 5.709148360307341,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.07965860597439545,
        "vocab_size-1": 168,
        "unique-1": 24,
        "entropy-1": 5.949214110048846,
        "distinct-2": 0.17647058823529413,
        "vocab_size-2": 351,
        "unique-2": 83,
        "entropy-2": 7.445150026569126,
        "cond_entropy-2": 1.417090141889549,
        "distinct-3": 0.24237560192616373,
        "vocab_size-3": 453,
        "unique-3": 121,
        "entropy-3": 8.065520761848012,
        "cond_entropy-3": 0.7025717914837577,
        "total_length-nopunct": 1948,
        "mean_pred_length-nopunct": 16.233333333333334,
        "std_pred_length-nopunct": 5.418691929074971,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.08521560574948665,
        "vocab_size-1-nopunct": 166,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 5.996038080172722,
        "distinct-2-nopunct": 0.17669584245076586,
        "vocab_size-2-nopunct": 323,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 7.312523262239096,
        "cond_entropy-2-nopunct": 1.4488669720340541,
        "distinct-3-nopunct": 0.24355971896955503,
        "vocab_size-3-nopunct": 416,
        "unique-3-nopunct": 110,
        "entropy-3-nopunct": 7.950488276605098,
        "cond_entropy-3-nopunct": 0.7130420010962912,
        "msttr-100": 0.33952,
        "msttr-100_nopunct": 0.33474,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.5869420386409061
        },
        "nist": 3.1251157514300103,
        "bleu": 17.15218,
        "rouge1": {
            "precision": 0.51694,
            "recall": 0.6304,
            "fmeasure": 0.5391
        },
        "rouge2": {
            "precision": 0.28654,
            "recall": 0.34949,
            "fmeasure": 0.29658
        },
        "rougeL": {
            "precision": 0.41876,
            "recall": 0.50456,
            "fmeasure": 0.43304
        },
        "rougeLsum": {
            "precision": 0.41876,
            "recall": 0.50456,
            "fmeasure": 0.43304
        },
        "nubia": {
            "semantic_relation": 3.56744,
            "contradiction": 13.53114,
            "irrelevancy": 72.49548,
            "logical_agreement": 13.97338,
            "grammar_ref": 5.42765,
            "grammar_hyp": 4.85074,
            "nubia_score": 0.54404
        },
        "meteor": 0.28119439877819963,
        "bleurt": -0.31376,
        "bertscore": {
            "precision": 0.86482,
            "recall": 0.87941,
            "f1": 0.87111
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_33": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 21,
        "total_length": 317,
        "mean_pred_length": 15.095238095238095,
        "std_pred_length": 6.085930393360941,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 26,
        "distinct-1": 0.5867507886435331,
        "vocab_size-1": 186,
        "unique-1": 154,
        "entropy-1": 6.875528852747058,
        "distinct-2": 0.9087837837837838,
        "vocab_size-2": 269,
        "unique-2": 259,
        "entropy-2": 7.958167756143761,
        "cond_entropy-2": 0.8875127725510411,
        "distinct-3": 0.9709090909090909,
        "vocab_size-3": 267,
        "unique-3": 264,
        "entropy-3": 8.027815490222343,
        "cond_entropy-3": 0.04661994253217551,
        "total_length-nopunct": 272,
        "mean_pred_length-nopunct": 12.952380952380953,
        "std_pred_length-nopunct": 4.990239907165361,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6654411764705882,
        "vocab_size-1-nopunct": 181,
        "unique-1-nopunct": 154,
        "entropy-1-nopunct": 6.998129120384238,
        "distinct-2-nopunct": 0.9243027888446215,
        "vocab_size-2-nopunct": 232,
        "unique-2-nopunct": 226,
        "entropy-2-nopunct": 7.756340317173859,
        "cond_entropy-2-nopunct": 0.7951289962468147,
        "distinct-3-nopunct": 0.9869565217391304,
        "vocab_size-3-nopunct": 227,
        "unique-3-nopunct": 226,
        "entropy-3-nopunct": 7.81070744224871,
        "cond_entropy-3-nopunct": 0.03923350756318337,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.745,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2318840579710145,
            "2": 0.41509433962264153,
            "3": 0.7978723404255319
        },
        "nist": 5.824864086805274,
        "bleu": 43.55336,
        "rouge1": {
            "precision": 0.7426,
            "recall": 0.73595,
            "fmeasure": 0.72835
        },
        "rouge2": {
            "precision": 0.50777,
            "recall": 0.50653,
            "fmeasure": 0.50018
        },
        "rougeL": {
            "precision": 0.63179,
            "recall": 0.63248,
            "fmeasure": 0.62201
        },
        "rougeLsum": {
            "precision": 0.63179,
            "recall": 0.63248,
            "fmeasure": 0.62201
        },
        "nubia": {
            "semantic_relation": 3.94442,
            "contradiction": 10.59155,
            "irrelevancy": 38.75567,
            "logical_agreement": 50.65278,
            "grammar_ref": 4.80447,
            "grammar_hyp": 5.03605,
            "nubia_score": 0.6539
        },
        "meteor": 0.373750840361211,
        "bleurt": 0.20188,
        "bertscore": {
            "precision": 0.92379,
            "recall": 0.92107,
            "f1": 0.92029
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-base (Baseline)/e2e_nlg_test",
        "N": 389,
        "total_length": 7081,
        "mean_pred_length": 18.203084832904885,
        "std_pred_length": 4.696155047682938,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 29,
        "distinct-1": 0.03346984889139952,
        "vocab_size-1": 237,
        "unique-1": 29,
        "entropy-1": 6.271268935859614,
        "distinct-2": 0.10938433950986252,
        "vocab_size-2": 732,
        "unique-2": 184,
        "entropy-2": 8.166142594377542,
        "cond_entropy-2": 1.798668821643161,
        "distinct-3": 0.17610661589719181,
        "vocab_size-3": 1110,
        "unique-3": 347,
        "entropy-3": 9.097194696938955,
        "cond_entropy-3": 0.9503337326829318,
        "total_length-nopunct": 6551,
        "mean_pred_length-nopunct": 16.840616966580978,
        "std_pred_length-nopunct": 4.566030336996828,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.03587238589528316,
        "vocab_size-1-nopunct": 235,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 6.319959819711929,
        "distinct-2-nopunct": 0.11116520610191497,
        "vocab_size-2-nopunct": 685,
        "unique-2-nopunct": 175,
        "entropy-2-nopunct": 8.055961771041513,
        "cond_entropy-2-nopunct": 1.8198646295187597,
        "distinct-3-nopunct": 0.18274727178243547,
        "vocab_size-3-nopunct": 1055,
        "unique-3-nopunct": 338,
        "entropy-3-nopunct": 9.046467122492222,
        "cond_entropy-3-nopunct": 0.9851907323461765,
        "msttr-100": 0.32529,
        "msttr-100_nopunct": 0.31738,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6080663522523988
        },
        "nist": 4.197839143661535,
        "bleu": 25.22953,
        "rouge1": {
            "precision": 0.6275,
            "recall": 0.6203,
            "fmeasure": 0.60776
        },
        "rouge2": {
            "precision": 0.37137,
            "recall": 0.36464,
            "fmeasure": 0.35798
        },
        "rougeL": {
            "precision": 0.49028,
            "recall": 0.48444,
            "fmeasure": 0.47506
        },
        "rougeLsum": {
            "precision": 0.49028,
            "recall": 0.48444,
            "fmeasure": 0.47506
        },
        "nubia": {
            "semantic_relation": 3.87426,
            "contradiction": 9.73915,
            "irrelevancy": 47.52354,
            "logical_agreement": 42.73732,
            "grammar_ref": 5.31197,
            "grammar_hyp": 4.94436,
            "nubia_score": 0.6479
        },
        "meteor": 0.31215233492449135,
        "bleurt": -0.04459,
        "bertscore": {
            "precision": 0.89295,
            "recall": 0.88864,
            "f1": 0.89027
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_28": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 2.5,
        "median_pred_length": 15.5,
        "min_pred_length": 13,
        "max_pred_length": 18,
        "distinct-1": 0.8709677419354839,
        "vocab_size-1": 27,
        "unique-1": 24,
        "entropy-1": 4.671780584510635,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.17119459860840283,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8518518518518519,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.430632409490749,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.1991641876977948,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.1,
            "3": 0.36363636363636365
        },
        "nist": 1.7694865382032472,
        "bleu": 5.46374,
        "rouge1": {
            "precision": 0.45518,
            "recall": 0.38333,
            "fmeasure": 0.39934
        },
        "rouge2": {
            "precision": 0.13221,
            "recall": 0.11786,
            "fmeasure": 0.11515
        },
        "rougeL": {
            "precision": 0.27801,
            "recall": 0.30298,
            "fmeasure": 0.27975
        },
        "rougeLsum": {
            "precision": 0.27801,
            "recall": 0.30298,
            "fmeasure": 0.27975
        },
        "nubia": {
            "semantic_relation": 2.9215,
            "contradiction": 45.41714,
            "irrelevancy": 53.79691,
            "logical_agreement": 0.78595,
            "grammar_ref": 5.71002,
            "grammar_hyp": 5.08423,
            "nubia_score": 0.29132
        },
        "meteor": 0.16314952255785234,
        "bleurt": -0.16561,
        "bertscore": {
            "precision": 0.81401,
            "recall": 0.84609,
            "f1": 0.81951
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_55": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 73,
        "total_length": 1243,
        "mean_pred_length": 17.027397260273972,
        "std_pred_length": 5.717008037162341,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.48189863234111024,
        "vocab_size-1": 599,
        "unique-1": 464,
        "entropy-1": 7.994502916401662,
        "distinct-2": 0.852991452991453,
        "vocab_size-2": 998,
        "unique-2": 891,
        "entropy-2": 9.808917733870818,
        "cond_entropy-2": 1.6236852325252968,
        "distinct-3": 0.9361896080218779,
        "vocab_size-3": 1027,
        "unique-3": 964,
        "entropy-3": 9.966910059705727,
        "cond_entropy-3": 0.146421387710879,
        "total_length-nopunct": 1072,
        "mean_pred_length-nopunct": 14.684931506849315,
        "std_pred_length-nopunct": 5.0555183800673795,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5503731343283582,
        "vocab_size-1-nopunct": 590,
        "unique-1-nopunct": 462,
        "entropy-1-nopunct": 8.238086618889644,
        "distinct-2-nopunct": 0.8638638638638638,
        "vocab_size-2-nopunct": 863,
        "unique-2-nopunct": 783,
        "entropy-2-nopunct": 9.597199319452912,
        "cond_entropy-2-nopunct": 1.434636076567925,
        "distinct-3-nopunct": 0.9470842332613391,
        "vocab_size-3-nopunct": 877,
        "unique-3-nopunct": 834,
        "entropy-3-nopunct": 9.744145570071181,
        "cond_entropy-3-nopunct": 0.1517642668449193,
        "msttr-100": 0.72167,
        "msttr-100_nopunct": 0.772,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3209302325581395,
            "2": 0.46987951807228917,
            "3": 0.776969696969697
        },
        "nist": 7.685549019323743,
        "bleu": 51.54985,
        "rouge1": {
            "precision": 0.78097,
            "recall": 0.7654,
            "fmeasure": 0.76497
        },
        "rouge2": {
            "precision": 0.58497,
            "recall": 0.57141,
            "fmeasure": 0.57066
        },
        "rougeL": {
            "precision": 0.68966,
            "recall": 0.6806,
            "fmeasure": 0.67736
        },
        "rougeLsum": {
            "precision": 0.68966,
            "recall": 0.6806,
            "fmeasure": 0.67736
        },
        "nubia": {
            "semantic_relation": 4.1554,
            "contradiction": 6.66447,
            "irrelevancy": 37.15319,
            "logical_agreement": 56.18235,
            "grammar_ref": 4.56245,
            "grammar_hyp": 4.61873,
            "nubia_score": 0.73051
        },
        "meteor": 0.41085442967231794,
        "bleurt": 0.27159,
        "bertscore": {
            "precision": 0.93643,
            "recall": 0.93227,
            "f1": 0.93303
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-base (Baseline)/e2e_nlg_test",
        "N": 737,
        "total_length": 15116,
        "mean_pred_length": 20.510176390773406,
        "std_pred_length": 3.5335518542981426,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 30,
        "distinct-1": 0.017134162476845727,
        "vocab_size-1": 259,
        "unique-1": 44,
        "entropy-1": 6.020874095614983,
        "distinct-2": 0.06432992558592392,
        "vocab_size-2": 925,
        "unique-2": 254,
        "entropy-2": 7.963661405684669,
        "cond_entropy-2": 1.8976201518684535,
        "distinct-3": 0.1208034012608122,
        "vocab_size-3": 1648,
        "unique-3": 530,
        "entropy-3": 9.045704257557512,
        "cond_entropy-3": 1.1190067330500977,
        "total_length-nopunct": 14015,
        "mean_pred_length-nopunct": 19.01628222523745,
        "std_pred_length-nopunct": 3.421498916391357,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.01833749554049233,
        "vocab_size-1-nopunct": 257,
        "unique-1-nopunct": 44,
        "entropy-1-nopunct": 6.039282867465207,
        "distinct-2-nopunct": 0.06642566651604158,
        "vocab_size-2-nopunct": 882,
        "unique-2-nopunct": 244,
        "entropy-2-nopunct": 7.86652523708637,
        "cond_entropy-2-nopunct": 1.9057736530244205,
        "distinct-3-nopunct": 0.12471094809026394,
        "vocab_size-3-nopunct": 1564,
        "unique-3-nopunct": 502,
        "entropy-3-nopunct": 8.976141316901616,
        "cond_entropy-3-nopunct": 1.1340005781475073,
        "msttr-100": 0.29285,
        "msttr-100_nopunct": 0.2885,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6726032588101554
        },
        "nist": 4.842580379123755,
        "bleu": 29.63131,
        "rouge1": {
            "precision": 0.70556,
            "recall": 0.69155,
            "fmeasure": 0.68836
        },
        "rouge2": {
            "precision": 0.42911,
            "recall": 0.41965,
            "fmeasure": 0.41798
        },
        "rougeL": {
            "precision": 0.53538,
            "recall": 0.52478,
            "fmeasure": 0.52242
        },
        "rougeLsum": {
            "precision": 0.53538,
            "recall": 0.52478,
            "fmeasure": 0.52242
        },
        "nubia": {
            "semantic_relation": 4.17802,
            "contradiction": 4.02458,
            "irrelevancy": 34.70728,
            "logical_agreement": 61.26814,
            "grammar_ref": 4.94689,
            "grammar_hyp": 4.71855,
            "nubia_score": 0.73309
        },
        "meteor": 0.34905795218090374,
        "bleurt": 0.11114,
        "bertscore": {
            "precision": 0.90846,
            "recall": 0.90332,
            "f1": 0.90552
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 143,
        "total_length": 1781,
        "mean_pred_length": 12.454545454545455,
        "std_pred_length": 2.543955602614508,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 19,
        "distinct-1": 0.39865244244806286,
        "vocab_size-1": 710,
        "unique-1": 465,
        "entropy-1": 8.246933717936717,
        "distinct-2": 0.7258852258852259,
        "vocab_size-2": 1189,
        "unique-2": 953,
        "entropy-2": 9.969891963226129,
        "cond_entropy-2": 1.8466774791442626,
        "distinct-3": 0.8602006688963211,
        "vocab_size-3": 1286,
        "unique-3": 1135,
        "entropy-3": 10.229206439294586,
        "cond_entropy-3": 0.31063722183254705,
        "total_length-nopunct": 1528,
        "mean_pred_length-nopunct": 10.685314685314685,
        "std_pred_length-nopunct": 1.9944664022350642,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.4607329842931937,
        "vocab_size-1-nopunct": 704,
        "unique-1-nopunct": 465,
        "entropy-1-nopunct": 8.607334324083238,
        "distinct-2-nopunct": 0.7660649819494585,
        "vocab_size-2-nopunct": 1061,
        "unique-2-nopunct": 884,
        "entropy-2-nopunct": 9.844594222810269,
        "cond_entropy-2-nopunct": 1.3438638531376303,
        "distinct-3-nopunct": 0.8792270531400966,
        "vocab_size-3-nopunct": 1092,
        "unique-3-nopunct": 991,
        "entropy-3-nopunct": 9.998476076154384,
        "cond_entropy-3-nopunct": 0.21121031176347535,
        "msttr-100": 0.67059,
        "msttr-100_nopunct": 0.70667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.11545912437039907,
            "2": 0.24403544648943423,
            "3": 0.388468809073724
        },
        "nist": 0.15969662183254754,
        "bleu": 9.99975,
        "rouge1": {
            "precision": 0.25909,
            "recall": 0.15786,
            "fmeasure": 0.18828
        },
        "rouge2": {
            "precision": 0.12568,
            "recall": 0.06115,
            "fmeasure": 0.07861
        },
        "rougeL": {
            "precision": 0.24745,
            "recall": 0.14824,
            "fmeasure": 0.17784
        },
        "rougeLsum": {
            "precision": 0.24745,
            "recall": 0.14824,
            "fmeasure": 0.17784
        },
        "nubia": {
            "semantic_relation": 3.22805,
            "contradiction": 23.57125,
            "irrelevancy": 22.20841,
            "logical_agreement": 54.22035,
            "grammar_ref": 2.5384,
            "grammar_hyp": 2.69009,
            "nubia_score": 0.58471
        },
        "meteor": 0.28304861342989124,
        "bleurt": -0.03703,
        "bertscore": {
            "precision": 0.93787,
            "recall": 0.87317,
            "f1": 0.90386
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 56,
        "total_length": 656,
        "mean_pred_length": 11.714285714285714,
        "std_pred_length": 2.526391311975342,
        "median_pred_length": 11.5,
        "min_pred_length": 7,
        "max_pred_length": 17,
        "distinct-1": 0.5396341463414634,
        "vocab_size-1": 354,
        "unique-1": 253,
        "entropy-1": 7.684811385694546,
        "distinct-2": 0.8566666666666667,
        "vocab_size-2": 514,
        "unique-2": 453,
        "entropy-2": 8.901855247988026,
        "cond_entropy-2": 1.3261561557029868,
        "distinct-3": 0.9503676470588235,
        "vocab_size-3": 517,
        "unique-3": 491,
        "entropy-3": 8.98681047451842,
        "cond_entropy-3": 0.11018498807401794,
        "total_length-nopunct": 573,
        "mean_pred_length-nopunct": 10.232142857142858,
        "std_pred_length-nopunct": 1.9638798281951562,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.6073298429319371,
        "vocab_size-1-nopunct": 348,
        "unique-1-nopunct": 252,
        "entropy-1-nopunct": 7.903502184426107,
        "distinct-2-nopunct": 0.8665377176015474,
        "vocab_size-2-nopunct": 448,
        "unique-2-nopunct": 401,
        "entropy-2-nopunct": 8.705658423888384,
        "cond_entropy-2-nopunct": 0.8963226048226124,
        "distinct-3-nopunct": 0.9566160520607375,
        "vocab_size-3-nopunct": 441,
        "unique-3-nopunct": 422,
        "entropy-3-nopunct": 8.760217544546148,
        "cond_entropy-3-nopunct": 0.08550982477904351,
        "msttr-100": 0.675,
        "msttr-100_nopunct": 0.746,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.09641873278236915,
            "2": 0.19236883942766295,
            "3": 0.38271604938271603
        },
        "nist": 0.0406463239581729,
        "bleu": 7.15314,
        "rouge1": {
            "precision": 0.39881,
            "recall": 0.212,
            "fmeasure": 0.2613
        },
        "rouge2": {
            "precision": 0.18552,
            "recall": 0.11068,
            "fmeasure": 0.13029
        },
        "rougeL": {
            "precision": 0.38988,
            "recall": 0.20308,
            "fmeasure": 0.25237
        },
        "rougeLsum": {
            "precision": 0.38988,
            "recall": 0.20308,
            "fmeasure": 0.25237
        },
        "nubia": {
            "semantic_relation": 3.09307,
            "contradiction": 22.09354,
            "irrelevancy": 23.41084,
            "logical_agreement": 54.49563,
            "grammar_ref": 2.50981,
            "grammar_hyp": 2.65183,
            "nubia_score": 0.61358
        },
        "meteor": 0.26384950040357064,
        "bleurt": -0.01646,
        "bertscore": {
            "precision": 0.9417,
            "recall": 0.86475,
            "f1": 0.9009
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_56": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 64,
        "total_length": 1086,
        "mean_pred_length": 16.96875,
        "std_pred_length": 5.226042808617243,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.511049723756906,
        "vocab_size-1": 555,
        "unique-1": 449,
        "entropy-1": 7.912594943748246,
        "distinct-2": 0.913894324853229,
        "vocab_size-2": 934,
        "unique-2": 877,
        "entropy-2": 9.776511140944923,
        "cond_entropy-2": 1.6685242096967603,
        "distinct-3": 0.9843423799582464,
        "vocab_size-3": 943,
        "unique-3": 930,
        "entropy-3": 9.870990640094838,
        "cond_entropy-3": 0.09903887937703809,
        "total_length-nopunct": 945,
        "mean_pred_length-nopunct": 14.765625,
        "std_pred_length-nopunct": 4.7392713954124845,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.580952380952381,
        "vocab_size-1-nopunct": 549,
        "unique-1-nopunct": 448,
        "entropy-1-nopunct": 8.178125206441859,
        "distinct-2-nopunct": 0.9205448354143019,
        "vocab_size-2-nopunct": 811,
        "unique-2-nopunct": 768,
        "entropy-2-nopunct": 9.571302983649252,
        "cond_entropy-2-nopunct": 1.486424912733003,
        "distinct-3-nopunct": 0.9914320685434517,
        "vocab_size-3-nopunct": 810,
        "unique-3-nopunct": 803,
        "entropy-3-nopunct": 9.657056405232465,
        "cond_entropy-3-nopunct": 0.10111265587645413,
        "msttr-100": 0.736,
        "msttr-100_nopunct": 0.79,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18803418803418803,
            "2": 0.4669603524229075,
            "3": 0.7594405594405594
        },
        "nist": 7.030878526040021,
        "bleu": 43.53855,
        "rouge1": {
            "precision": 0.75603,
            "recall": 0.71459,
            "fmeasure": 0.72763
        },
        "rouge2": {
            "precision": 0.50549,
            "recall": 0.4839,
            "fmeasure": 0.49016
        },
        "rougeL": {
            "precision": 0.6073,
            "recall": 0.58553,
            "fmeasure": 0.59154
        },
        "rougeLsum": {
            "precision": 0.6073,
            "recall": 0.58553,
            "fmeasure": 0.59154
        },
        "nubia": {
            "semantic_relation": 4.20088,
            "contradiction": 7.49206,
            "irrelevancy": 31.30007,
            "logical_agreement": 61.20788,
            "grammar_ref": 4.72038,
            "grammar_hyp": 4.70306,
            "nubia_score": 0.72439
        },
        "meteor": 0.3792145769365703,
        "bleurt": 0.23899,
        "bertscore": {
            "precision": 0.92505,
            "recall": 0.9178,
            "f1": 0.91946
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_57": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 12,
        "total_length": 150,
        "mean_pred_length": 12.5,
        "std_pred_length": 4.0722639076235385,
        "median_pred_length": 11.5,
        "min_pred_length": 7,
        "max_pred_length": 21,
        "distinct-1": 0.7,
        "vocab_size-1": 105,
        "unique-1": 89,
        "entropy-1": 6.316500454999327,
        "distinct-2": 0.9420289855072463,
        "vocab_size-2": 130,
        "unique-2": 125,
        "entropy-2": 6.966425612760509,
        "cond_entropy-2": 0.45350538255065354,
        "distinct-3": 0.9761904761904762,
        "vocab_size-3": 123,
        "unique-3": 120,
        "entropy-3": 6.929660875880879,
        "cond_entropy-3": -0.023231513639865014,
        "total_length-nopunct": 132,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 3.851406669430448,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7575757575757576,
        "vocab_size-1-nopunct": 100,
        "unique-1-nopunct": 86,
        "entropy-1-nopunct": 6.356560880574574,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 112,
        "unique-2-nopunct": 107,
        "entropy-2-nopunct": 6.743476924988228,
        "cond_entropy-2-nopunct": 0.4306993682920192,
        "distinct-3-nopunct": 0.9722222222222222,
        "vocab_size-3-nopunct": 105,
        "unique-3-nopunct": 102,
        "entropy-3-nopunct": 6.699331946607902,
        "cond_entropy-3-nopunct": -0.02598790386693142,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.79,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.7142857142857143,
            "3": 0.7934782608695652
        },
        "nist": 5.704934458912668,
        "bleu": 52.30239,
        "rouge1": {
            "precision": 0.80194,
            "recall": 0.77947,
            "fmeasure": 0.78574
        },
        "rouge2": {
            "precision": 0.58963,
            "recall": 0.56297,
            "fmeasure": 0.57161
        },
        "rougeL": {
            "precision": 0.68753,
            "recall": 0.67321,
            "fmeasure": 0.67681
        },
        "rougeLsum": {
            "precision": 0.68753,
            "recall": 0.67321,
            "fmeasure": 0.67681
        },
        "nubia": {
            "semantic_relation": 4.59155,
            "contradiction": 17.88938,
            "irrelevancy": 16.30039,
            "logical_agreement": 65.81023,
            "grammar_ref": 5.5602,
            "grammar_hyp": 5.70861,
            "nubia_score": 0.80939
        },
        "meteor": 0.43062667899259927,
        "bleurt": 0.40596,
        "bertscore": {
            "precision": 0.93952,
            "recall": 0.94149,
            "f1": 0.93902
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_96": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 50,
        "total_length": 823,
        "mean_pred_length": 16.46,
        "std_pred_length": 6.126042768378295,
        "median_pred_length": 15.5,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.5467800729040098,
        "vocab_size-1": 450,
        "unique-1": 374,
        "entropy-1": 7.6933208560233775,
        "distinct-2": 0.9159120310478654,
        "vocab_size-2": 708,
        "unique-2": 669,
        "entropy-2": 9.364795597501574,
        "cond_entropy-2": 1.4771583906443513,
        "distinct-3": 0.9930843706777317,
        "vocab_size-3": 718,
        "unique-3": 713,
        "entropy-3": 9.48402057830655,
        "cond_entropy-3": 0.1281827267540985,
        "total_length-nopunct": 723,
        "mean_pred_length-nopunct": 14.46,
        "std_pred_length-nopunct": 5.348682080662488,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6141078838174274,
        "vocab_size-1-nopunct": 444,
        "unique-1-nopunct": 373,
        "entropy-1-nopunct": 7.909066670110929,
        "distinct-2-nopunct": 0.9257057949479941,
        "vocab_size-2-nopunct": 623,
        "unique-2-nopunct": 598,
        "entropy-2-nopunct": 9.176526536418647,
        "cond_entropy-2-nopunct": 1.3515146859546463,
        "distinct-3-nopunct": 0.9983948635634029,
        "vocab_size-3-nopunct": 622,
        "unique-3-nopunct": 621,
        "entropy-3-nopunct": 9.27987808015071,
        "cond_entropy-3-nopunct": 0.11602699784074355,
        "msttr-100": 0.71625,
        "msttr-100_nopunct": 0.76714,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20666666666666667,
            "2": 0.5345911949685535,
            "3": 0.7262773722627737
        },
        "nist": 6.822133434712282,
        "bleu": 42.73852,
        "rouge1": {
            "precision": 0.78314,
            "recall": 0.73635,
            "fmeasure": 0.75079
        },
        "rouge2": {
            "precision": 0.53852,
            "recall": 0.51192,
            "fmeasure": 0.51836
        },
        "rougeL": {
            "precision": 0.66808,
            "recall": 0.63393,
            "fmeasure": 0.64359
        },
        "rougeLsum": {
            "precision": 0.66808,
            "recall": 0.63393,
            "fmeasure": 0.64359
        },
        "nubia": {
            "semantic_relation": 4.21614,
            "contradiction": 9.54941,
            "irrelevancy": 28.06692,
            "logical_agreement": 62.38367,
            "grammar_ref": 4.7145,
            "grammar_hyp": 4.73447,
            "nubia_score": 0.72455
        },
        "meteor": 0.3759711712378461,
        "bleurt": 0.23604,
        "bertscore": {
            "precision": 0.9304,
            "recall": 0.92286,
            "f1": 0.92522
        }
    },
    "cs_restaurants_challenge_test_scramble": {
        "predictions_file": "ByT5-base (Baseline)/cs_restaurants_challenge_test_scramble",
        "N": 500,
        "total_length": 5410,
        "mean_pred_length": 10.82,
        "std_pred_length": 3.451898028621355,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 23,
        "distinct-1": 0.09926062846580407,
        "vocab_size-1": 537,
        "unique-1": 229,
        "entropy-1": 6.919546928804905,
        "distinct-2": 0.2845213849287169,
        "vocab_size-2": 1397,
        "unique-2": 840,
        "entropy-2": 8.909411791199314,
        "cond_entropy-2": 1.7586777942367509,
        "distinct-3": 0.436281179138322,
        "vocab_size-3": 1924,
        "unique-3": 1440,
        "entropy-3": 9.508388328471554,
        "cond_entropy-3": 0.6638254017991564,
        "total_length-nopunct": 4484,
        "mean_pred_length-nopunct": 8.968,
        "std_pred_length-nopunct": 3.068383287661436,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.11886708296164139,
        "vocab_size-1-nopunct": 533,
        "unique-1-nopunct": 229,
        "entropy-1-nopunct": 7.234385962960713,
        "distinct-2-nopunct": 0.3019578313253012,
        "vocab_size-2-nopunct": 1203,
        "unique-2-nopunct": 735,
        "entropy-2-nopunct": 8.793961547407227,
        "cond_entropy-2-nopunct": 1.7388283433775327,
        "distinct-3-nopunct": 0.47158438576349027,
        "vocab_size-3-nopunct": 1643,
        "unique-3-nopunct": 1251,
        "entropy-3-nopunct": 9.44085483479862,
        "cond_entropy-3-nopunct": 0.7548174913190442,
        "msttr-100": 0.59944,
        "msttr-100_nopunct": 0.64773,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.45050081528068947
        },
        "nist": 3.802507303515136,
        "bleu": 16.53386,
        "rouge1": {
            "precision": 0.49816,
            "recall": 0.51536,
            "fmeasure": 0.48936
        },
        "rouge2": {
            "precision": 0.26902,
            "recall": 0.27303,
            "fmeasure": 0.26203
        },
        "rougeL": {
            "precision": 0.44246,
            "recall": 0.4593,
            "fmeasure": 0.43554
        },
        "rougeLsum": {
            "precision": 0.44246,
            "recall": 0.4593,
            "fmeasure": 0.43554
        },
        "nubia": {
            "semantic_relation": 3.28774,
            "contradiction": 23.54167,
            "irrelevancy": 31.5109,
            "logical_agreement": 44.94743,
            "grammar_ref": 6.87434,
            "grammar_hyp": 6.79597,
            "nubia_score": 0.47257
        },
        "meteor": 0.22774809304341687,
        "bleurt": -0.26178,
        "bertscore": {
            "precision": 0.88667,
            "recall": 0.89637,
            "f1": 0.89106
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_58": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966062,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.567101189180771,
        "bleu": 21.04299,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.9011,
            "fmeasure": 0.84729
        },
        "rouge2": {
            "precision": 0.30952,
            "recall": 0.3547,
            "fmeasure": 0.33048
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.60073,
            "fmeasure": 0.56486
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.60073,
            "fmeasure": 0.56486
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20989,
            "irrelevancy": 0.45147,
            "logical_agreement": 99.33864,
            "grammar_ref": 5.12321,
            "grammar_hyp": 3.9693,
            "nubia_score": 1.0
        },
        "meteor": 0.43072252252394466,
        "bleurt": 0.52217,
        "bertscore": {
            "precision": 0.92158,
            "recall": 0.94861,
            "f1": 0.9349
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_98": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 11,
        "total_length": 179,
        "mean_pred_length": 16.272727272727273,
        "std_pred_length": 3.332782323604247,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 22,
        "distinct-1": 0.6368715083798883,
        "vocab_size-1": 114,
        "unique-1": 88,
        "entropy-1": 6.369306213444647,
        "distinct-2": 0.9345238095238095,
        "vocab_size-2": 157,
        "unique-2": 150,
        "entropy-2": 7.228568762038748,
        "cond_entropy-2": 0.742371193522811,
        "distinct-3": 0.9872611464968153,
        "vocab_size-3": 155,
        "unique-3": 153,
        "entropy-3": 7.269143041885253,
        "cond_entropy-3": 0.03930826244615908,
        "total_length-nopunct": 154,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.2473765635439547,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7077922077922078,
        "vocab_size-1-nopunct": 109,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.428743358708151,
        "distinct-2-nopunct": 0.9300699300699301,
        "vocab_size-2-nopunct": 133,
        "unique-2-nopunct": 127,
        "entropy-2-nopunct": 6.981481301783102,
        "cond_entropy-2-nopunct": 0.5822377682627512,
        "distinct-3-nopunct": 0.9924242424242424,
        "vocab_size-3-nopunct": 131,
        "unique-3-nopunct": 130,
        "entropy-3-nopunct": 7.029242604206928,
        "cond_entropy-3-nopunct": 0.04747562352193485,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.27906976744186046,
            "2": 0.47368421052631576,
            "3": 0.6838235294117647
        },
        "nist": 5.82867497634863,
        "bleu": 45.20709,
        "rouge1": {
            "precision": 0.75841,
            "recall": 0.67525,
            "fmeasure": 0.70496
        },
        "rouge2": {
            "precision": 0.55542,
            "recall": 0.48409,
            "fmeasure": 0.50938
        },
        "rougeL": {
            "precision": 0.65763,
            "recall": 0.58145,
            "fmeasure": 0.6086
        },
        "rougeLsum": {
            "precision": 0.65763,
            "recall": 0.58145,
            "fmeasure": 0.6086
        },
        "nubia": {
            "semantic_relation": 4.19415,
            "contradiction": 4.53343,
            "irrelevancy": 19.84236,
            "logical_agreement": 75.6242,
            "grammar_ref": 4.3854,
            "grammar_hyp": 4.73056,
            "nubia_score": 0.72632
        },
        "meteor": 0.3745515648562951,
        "bleurt": 0.14694,
        "bertscore": {
            "precision": 0.90653,
            "recall": 0.91275,
            "f1": 0.90773
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "ByT5-base (Baseline)/e2e_nlg_test",
        "N": 1187,
        "total_length": 27455,
        "mean_pred_length": 23.129738837405224,
        "std_pred_length": 2.9883260958486844,
        "median_pred_length": 24.0,
        "min_pred_length": 14,
        "max_pred_length": 30,
        "distinct-1": 0.011291203788016754,
        "vocab_size-1": 310,
        "unique-1": 62,
        "entropy-1": 6.084866710878411,
        "distinct-2": 0.04446474798233592,
        "vocab_size-2": 1168,
        "unique-2": 323,
        "entropy-2": 8.064733507602659,
        "cond_entropy-2": 2.0458367926891903,
        "distinct-3": 0.08755631753119891,
        "vocab_size-3": 2196,
        "unique-3": 703,
        "entropy-3": 9.25456191499028,
        "cond_entropy-3": 1.2650414513468284,
        "total_length-nopunct": 25867,
        "mean_pred_length-nopunct": 21.79191238416175,
        "std_pred_length-nopunct": 3.0355382222892366,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.011868403757683535,
        "vocab_size-1-nopunct": 307,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 6.081860386729672,
        "distinct-2-nopunct": 0.04598865478119935,
        "vocab_size-2-nopunct": 1135,
        "unique-2-nopunct": 316,
        "entropy-2-nopunct": 8.044206649375564,
        "cond_entropy-2-nopunct": 2.0741113151327957,
        "distinct-3-nopunct": 0.09011194823990125,
        "vocab_size-3-nopunct": 2117,
        "unique-3-nopunct": 680,
        "entropy-3-nopunct": 9.257211466126586,
        "cond_entropy-3-nopunct": 1.2742962495082535,
        "msttr-100": 0.29839,
        "msttr-100_nopunct": 0.28806,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6646734324335706
        },
        "nist": 4.599631342335861,
        "bleu": 26.03576,
        "rouge1": {
            "precision": 0.68038,
            "recall": 0.67624,
            "fmeasure": 0.66869
        },
        "rouge2": {
            "precision": 0.37979,
            "recall": 0.37734,
            "fmeasure": 0.37299
        },
        "rougeL": {
            "precision": 0.48128,
            "recall": 0.47813,
            "fmeasure": 0.47291
        },
        "rougeLsum": {
            "precision": 0.48128,
            "recall": 0.47813,
            "fmeasure": 0.47291
        },
        "nubia": {
            "semantic_relation": 3.9643,
            "contradiction": 2.94462,
            "irrelevancy": 46.76707,
            "logical_agreement": 50.28831,
            "grammar_ref": 4.92209,
            "grammar_hyp": 4.78002,
            "nubia_score": 0.66859
        },
        "meteor": 0.3303480031954091,
        "bleurt": -0.05456,
        "bertscore": {
            "precision": 0.89486,
            "recall": 0.89513,
            "f1": 0.89462
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 19,
        "total_length": 236,
        "mean_pred_length": 12.421052631578947,
        "std_pred_length": 1.5326547135327409,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.423728813559322,
        "vocab_size-1": 100,
        "unique-1": 55,
        "entropy-1": 5.976347843206361,
        "distinct-2": 0.6082949308755761,
        "vocab_size-2": 132,
        "unique-2": 87,
        "entropy-2": 6.794787610420696,
        "cond_entropy-2": 0.9403970087571351,
        "distinct-3": 0.7121212121212122,
        "vocab_size-3": 141,
        "unique-3": 110,
        "entropy-3": 6.934665332091552,
        "cond_entropy-3": 0.20358287983393814,
        "total_length-nopunct": 210,
        "mean_pred_length-nopunct": 11.052631578947368,
        "std_pred_length-nopunct": 1.4317337377616255,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.4523809523809524,
        "vocab_size-1-nopunct": 95,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 5.994364346726769,
        "distinct-2-nopunct": 0.6335078534031413,
        "vocab_size-2-nopunct": 121,
        "unique-2-nopunct": 84,
        "entropy-2-nopunct": 6.671497841245179,
        "cond_entropy-2-nopunct": 0.7971484408308885,
        "distinct-3-nopunct": 0.7383720930232558,
        "vocab_size-3-nopunct": 127,
        "unique-3-nopunct": 103,
        "entropy-3-nopunct": 6.790891426125659,
        "cond_entropy-3-nopunct": 0.1860087084087387,
        "msttr-100": 0.53,
        "msttr-100_nopunct": 0.545,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.08135593220338982,
            "2": 0.22556390977443608,
            "3": 0.40594059405940597
        },
        "nist": 0.02035977247245544,
        "bleu": 7.55059,
        "rouge1": {
            "precision": 0.65789,
            "recall": 0.37354,
            "fmeasure": 0.45706
        },
        "rouge2": {
            "precision": 0.38596,
            "recall": 0.17817,
            "fmeasure": 0.22003
        },
        "rougeL": {
            "precision": 0.65789,
            "recall": 0.37354,
            "fmeasure": 0.45706
        },
        "rougeLsum": {
            "precision": 0.65789,
            "recall": 0.37354,
            "fmeasure": 0.45706
        },
        "nubia": {
            "semantic_relation": 3.0551,
            "contradiction": 20.51522,
            "irrelevancy": 24.05775,
            "logical_agreement": 55.42704,
            "grammar_ref": 2.51721,
            "grammar_hyp": 2.69705,
            "nubia_score": 0.56478
        },
        "meteor": 0.3043141317409734,
        "bleurt": 0.03275,
        "bertscore": {
            "precision": 0.94833,
            "recall": 0.85867,
            "f1": 0.90042
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_125": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 6,
        "total_length": 110,
        "mean_pred_length": 18.333333333333332,
        "std_pred_length": 8.439325934114775,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.7,
        "vocab_size-1": 77,
        "unique-1": 64,
        "entropy-1": 5.934293605436176,
        "distinct-2": 0.9711538461538461,
        "vocab_size-2": 101,
        "unique-2": 98,
        "entropy-2": 6.642747410448791,
        "cond_entropy-2": 0.6584026922143584,
        "distinct-3": 1.0,
        "vocab_size-3": 98,
        "unique-3": 98,
        "entropy-3": 6.614709844115218,
        "cond_entropy-3": -0.024505384229965385,
        "total_length-nopunct": 91,
        "mean_pred_length-nopunct": 15.166666666666666,
        "std_pred_length-nopunct": 6.066758241067098,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7802197802197802,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 63,
        "entropy-1-nopunct": 5.8933314867822855,
        "distinct-2-nopunct": 0.9882352941176471,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 83,
        "entropy-2-nopunct": 6.385861524373001,
        "cond_entropy-2-nopunct": 0.5241392013612842,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 79,
        "unique-3-nopunct": 79,
        "entropy-3-nopunct": 6.303780748177105,
        "cond_entropy-3-nopunct": -0.08029373226439625,
        "msttr-100": 0.68,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.25,
            "3": 0.7777777777777778
        },
        "nist": 4.792427435191352,
        "bleu": 42.8973,
        "rouge1": {
            "precision": 0.79532,
            "recall": 0.71587,
            "fmeasure": 0.73975
        },
        "rouge2": {
            "precision": 0.58586,
            "recall": 0.53553,
            "fmeasure": 0.54756
        },
        "rougeL": {
            "precision": 0.6904,
            "recall": 0.62132,
            "fmeasure": 0.63883
        },
        "rougeLsum": {
            "precision": 0.6904,
            "recall": 0.62132,
            "fmeasure": 0.63883
        },
        "nubia": {
            "semantic_relation": 4.14228,
            "contradiction": 1.641,
            "irrelevancy": 22.15767,
            "logical_agreement": 76.20132,
            "grammar_ref": 5.04309,
            "grammar_hyp": 5.28484,
            "nubia_score": 0.66779
        },
        "meteor": 0.3653660537478257,
        "bleurt": 0.22635,
        "bertscore": {
            "precision": 0.9368,
            "recall": 0.91874,
            "f1": 0.92703
        }
    },
    "totto_validation": {
        "predictions_file": "ByT5-base (Baseline)/totto_validation",
        "N": 7700,
        "total_length": 125754,
        "mean_pred_length": 16.33168831168831,
        "std_pred_length": 5.483491967951686,
        "median_pred_length": 16.0,
        "min_pred_length": 4,
        "max_pred_length": 38,
        "distinct-1": 0.172575027434515,
        "vocab_size-1": 21702,
        "unique-1": 14910,
        "entropy-1": 10.083215100274007,
        "distinct-2": 0.5542124790350179,
        "vocab_size-2": 65427,
        "unique-2": 54860,
        "entropy-2": 14.653326284335122,
        "cond_entropy-2": 4.24559947106337,
        "distinct-3": 0.7917610598618989,
        "vocab_size-3": 87374,
        "unique-3": 79949,
        "entropy-3": 15.954820328800746,
        "cond_entropy-3": 1.2991937202098214,
        "total_length-nopunct": 109861,
        "mean_pred_length-nopunct": 14.267662337662337,
        "std_pred_length-nopunct": 4.8812834686758935,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.1973220706165063,
        "vocab_size-1-nopunct": 21678,
        "unique-1-nopunct": 14907,
        "entropy-1-nopunct": 10.617647041566245,
        "distinct-2-nopunct": 0.5981147404586877,
        "vocab_size-2-nopunct": 61104,
        "unique-2-nopunct": 52394,
        "entropy-2-nopunct": 14.65450007286771,
        "cond_entropy-2-nopunct": 4.220065255572779,
        "distinct-3-nopunct": 0.8174908163157282,
        "vocab_size-3-nopunct": 77221,
        "unique-3-nopunct": 71519,
        "entropy-3-nopunct": 15.833812539427718,
        "cond_entropy-3-nopunct": 1.258229654204117,
        "msttr-100": 0.72792,
        "msttr-100_nopunct": 0.77886,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_validation.json",
        "local_recall": {
            "1": 0.22756015438942268,
            "2": 0.4668535691179642,
            "3": 0.7653213377272671
        },
        "nist": 10.73695263702773,
        "bleu": 46.72054,
        "rouge1": {
            "precision": 0.75051,
            "recall": 0.73363,
            "fmeasure": 0.73097
        },
        "rouge2": {
            "precision": 0.53088,
            "recall": 0.52075,
            "fmeasure": 0.5177
        },
        "rougeL": {
            "precision": 0.65583,
            "recall": 0.6444,
            "fmeasure": 0.64021
        },
        "rougeLsum": {
            "precision": 0.65583,
            "recall": 0.6444,
            "fmeasure": 0.64021
        },
        "nubia": {
            "semantic_relation": 4.15163,
            "contradiction": 8.79503,
            "irrelevancy": 30.80852,
            "logical_agreement": 60.39646,
            "grammar_ref": 4.66172,
            "grammar_hyp": 4.64748,
            "nubia_score": 0.71858
        },
        "meteor": 0.3907261698187715,
        "bleurt": 0.25636,
        "bertscore": {
            "precision": 0.92714,
            "recall": 0.92498,
            "f1": 0.92445
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 12,
        "total_length": 149,
        "mean_pred_length": 12.416666666666666,
        "std_pred_length": 2.782634642844,
        "median_pred_length": 12.5,
        "min_pred_length": 8,
        "max_pred_length": 19,
        "distinct-1": 0.5167785234899329,
        "vocab_size-1": 77,
        "unique-1": 46,
        "entropy-1": 5.729230900410304,
        "distinct-2": 0.7226277372262774,
        "vocab_size-2": 99,
        "unique-2": 74,
        "entropy-2": 6.443356283896934,
        "cond_entropy-2": 0.8227330582357064,
        "distinct-3": 0.816,
        "vocab_size-3": 102,
        "unique-3": 85,
        "entropy-3": 6.5615496845582495,
        "cond_entropy-3": 0.18104227737140172,
        "total_length-nopunct": 130,
        "mean_pred_length-nopunct": 10.833333333333334,
        "std_pred_length-nopunct": 2.034425935955617,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.5692307692307692,
        "vocab_size-1-nopunct": 74,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.802041205709721,
        "distinct-2-nopunct": 0.7542372881355932,
        "vocab_size-2-nopunct": 89,
        "unique-2-nopunct": 70,
        "entropy-2-nopunct": 6.294287778470136,
        "cond_entropy-2-nopunct": 0.5909238548606318,
        "distinct-3-nopunct": 0.8301886792452831,
        "vocab_size-3-nopunct": 88,
        "unique-3-nopunct": 74,
        "entropy-3-nopunct": 6.359811492217399,
        "cond_entropy-3-nopunct": 0.13212997082934563,
        "msttr-100": 0.57,
        "msttr-100_nopunct": 0.61,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.1781609195402299,
            "3": 0.31645569620253167
        },
        "nist": 0.005810512869059576,
        "bleu": 4.64033,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.32014,
            "fmeasure": 0.38218
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.16944,
            "fmeasure": 0.20556
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.32014,
            "fmeasure": 0.38218
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.32014,
            "fmeasure": 0.38218
        },
        "nubia": {
            "semantic_relation": 2.89253,
            "contradiction": 27.33739,
            "irrelevancy": 28.35768,
            "logical_agreement": 44.30493,
            "grammar_ref": 2.55511,
            "grammar_hyp": 2.69012,
            "nubia_score": 0.64259
        },
        "meteor": 0.2550673345026731,
        "bleurt": -0.04601,
        "bertscore": {
            "precision": 0.93554,
            "recall": 0.84819,
            "f1": 0.88951
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_60": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 114,
        "total_length": 1946,
        "mean_pred_length": 17.07017543859649,
        "std_pred_length": 5.757861594781512,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.4635149023638232,
        "vocab_size-1": 902,
        "unique-1": 712,
        "entropy-1": 8.347508571270586,
        "distinct-2": 0.87117903930131,
        "vocab_size-2": 1596,
        "unique-2": 1471,
        "entropy-2": 10.476701292522499,
        "cond_entropy-2": 1.917869282780775,
        "distinct-3": 0.9726426076833528,
        "vocab_size-3": 1671,
        "unique-3": 1630,
        "entropy-3": 10.6888777961039,
        "cond_entropy-3": 0.2168683673703753,
        "total_length-nopunct": 1708,
        "mean_pred_length-nopunct": 14.982456140350877,
        "std_pred_length-nopunct": 5.316281605382229,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5216627634660421,
        "vocab_size-1-nopunct": 891,
        "unique-1-nopunct": 708,
        "entropy-1-nopunct": 8.617184378297404,
        "distinct-2-nopunct": 0.882685069008783,
        "vocab_size-2-nopunct": 1407,
        "unique-2-nopunct": 1314,
        "entropy-2-nopunct": 10.293516962065313,
        "cond_entropy-2-nopunct": 1.7700175597989452,
        "distinct-3-nopunct": 0.9756756756756757,
        "vocab_size-3-nopunct": 1444,
        "unique-3-nopunct": 1414,
        "entropy-3-nopunct": 10.479341224024129,
        "cond_entropy-3-nopunct": 0.19972012210523854,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.77647,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25866666666666666,
            "2": 0.5517241379310345,
            "3": 0.7767936226749336
        },
        "nist": 7.547835681315057,
        "bleu": 42.43533,
        "rouge1": {
            "precision": 0.73435,
            "recall": 0.73968,
            "fmeasure": 0.72483
        },
        "rouge2": {
            "precision": 0.49433,
            "recall": 0.49879,
            "fmeasure": 0.48826
        },
        "rougeL": {
            "precision": 0.61393,
            "recall": 0.62673,
            "fmeasure": 0.60976
        },
        "rougeLsum": {
            "precision": 0.61393,
            "recall": 0.62673,
            "fmeasure": 0.60976
        },
        "nubia": {
            "semantic_relation": 4.16281,
            "contradiction": 10.54668,
            "irrelevancy": 29.0981,
            "logical_agreement": 60.35522,
            "grammar_ref": 4.84845,
            "grammar_hyp": 4.73266,
            "nubia_score": 0.70898
        },
        "meteor": 0.3861428899100278,
        "bleurt": 0.24529,
        "bertscore": {
            "precision": 0.92303,
            "recall": 0.92287,
            "f1": 0.92141
        }
    },
    "schema_guided_dialog_challenge_test_nopunc": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_challenge_test_nopunc",
        "N": 500,
        "total_length": 6108,
        "mean_pred_length": 12.216,
        "std_pred_length": 6.422876614103684,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 31,
        "distinct-1": 0.17468893254747872,
        "vocab_size-1": 1067,
        "unique-1": 607,
        "entropy-1": 8.066386279463236,
        "distinct-2": 0.520506419400856,
        "vocab_size-2": 2919,
        "unique-2": 2104,
        "entropy-2": 10.799376096937271,
        "cond_entropy-2": 2.7107452732630484,
        "distinct-3": 0.7423649177760376,
        "vocab_size-3": 3792,
        "unique-3": 3202,
        "entropy-3": 11.57988306395892,
        "cond_entropy-3": 0.8273611540494508,
        "total_length-nopunct": 5571,
        "mean_pred_length-nopunct": 11.142,
        "std_pred_length-nopunct": 5.956327391942119,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.1890145395799677,
        "vocab_size-1-nopunct": 1053,
        "unique-1-nopunct": 604,
        "entropy-1-nopunct": 8.139895895924399,
        "distinct-2-nopunct": 0.5350029579964504,
        "vocab_size-2-nopunct": 2713,
        "unique-2-nopunct": 2004,
        "entropy-2-nopunct": 10.68670430451677,
        "cond_entropy-2-nopunct": 2.6859879014123744,
        "distinct-3-nopunct": 0.7536644060380661,
        "vocab_size-3-nopunct": 3445,
        "unique-3-nopunct": 2951,
        "entropy-3-nopunct": 11.44681832580685,
        "cond_entropy-3-nopunct": 0.7940594695671815,
        "msttr-100": 0.72033,
        "msttr-100_nopunct": 0.73164,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_nopunc.json",
        "local_recall": {
            "1": 0.5372050816696915
        },
        "nist": 5.731234404966404,
        "bleu": 28.42186,
        "rouge1": {
            "precision": 0.57721,
            "recall": 0.51873,
            "fmeasure": 0.53369
        },
        "rouge2": {
            "precision": 0.35098,
            "recall": 0.31469,
            "fmeasure": 0.32392
        },
        "rougeL": {
            "precision": 0.51047,
            "recall": 0.4596,
            "fmeasure": 0.47257
        },
        "rougeLsum": {
            "precision": 0.51047,
            "recall": 0.4596,
            "fmeasure": 0.47257
        },
        "nubia": {
            "semantic_relation": 3.60782,
            "contradiction": 7.09947,
            "irrelevancy": 20.41234,
            "logical_agreement": 72.48819,
            "grammar_ref": 4.79983,
            "grammar_hyp": 4.99537,
            "nubia_score": 0.60772
        },
        "meteor": 0.2986243860912931,
        "bleurt": -0.16439,
        "bertscore": {
            "precision": 0.86677,
            "recall": 0.84746,
            "f1": 0.85652
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 1099,
        "total_length": 12470,
        "mean_pred_length": 11.346678798908098,
        "std_pred_length": 2.8481297245327633,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 21,
        "distinct-1": 0.20609462710505214,
        "vocab_size-1": 2570,
        "unique-1": 1330,
        "entropy-1": 9.140254072110078,
        "distinct-2": 0.491601442265412,
        "vocab_size-2": 5590,
        "unique-2": 3811,
        "entropy-2": 11.72644355242347,
        "cond_entropy-2": 2.645753110419002,
        "distinct-3": 0.6884735202492211,
        "vocab_size-3": 7072,
        "unique-3": 5551,
        "entropy-3": 12.474463543340486,
        "cond_entropy-3": 0.8642515517982035,
        "total_length-nopunct": 10587,
        "mean_pred_length-nopunct": 9.633303002729754,
        "std_pred_length-nopunct": 2.478519383612107,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.24199489940493057,
        "vocab_size-1-nopunct": 2562,
        "unique-1-nopunct": 1330,
        "entropy-1-nopunct": 9.686533813922383,
        "distinct-2-nopunct": 0.5425801011804384,
        "vocab_size-2-nopunct": 5148,
        "unique-2-nopunct": 3691,
        "entropy-2-nopunct": 11.696933283967333,
        "cond_entropy-2-nopunct": 2.2225029945614256,
        "distinct-3-nopunct": 0.72142090833234,
        "vocab_size-3-nopunct": 6052,
        "unique-3-nopunct": 4921,
        "entropy-3-nopunct": 12.270108197957676,
        "cond_entropy-3-nopunct": 0.7062851362273125,
        "msttr-100": 0.66823,
        "msttr-100_nopunct": 0.71419,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.16509231429798196,
            "2": 0.35851137146795314,
            "3": 0.5034702682423561,
            "4": 0.7012987012987013,
            "5": 0.7567567567567568,
            "6": 0.8461538461538461,
            "7": 1.0
        },
        "nist": 1.7613951606628915,
        "bleu": 22.61828,
        "rouge1": {
            "precision": 0.28725,
            "recall": 0.23543,
            "fmeasure": 0.25008
        },
        "rouge2": {
            "precision": 0.13372,
            "recall": 0.10473,
            "fmeasure": 0.11223
        },
        "rougeL": {
            "precision": 0.27994,
            "recall": 0.22912,
            "fmeasure": 0.24339
        },
        "rougeLsum": {
            "precision": 0.27994,
            "recall": 0.22912,
            "fmeasure": 0.24339
        },
        "nubia": {
            "semantic_relation": 3.60792,
            "contradiction": 21.64909,
            "irrelevancy": 22.538,
            "logical_agreement": 55.81292,
            "grammar_ref": 2.65247,
            "grammar_hyp": 2.72919,
            "nubia_score": 0.70018
        },
        "meteor": 0.4038946467650558,
        "bleurt": 0.10415,
        "bertscore": {
            "precision": 0.95105,
            "recall": 0.91458,
            "f1": 0.93158
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_77": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 30,
        "total_length": 516,
        "mean_pred_length": 17.2,
        "std_pred_length": 4.826316746063537,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.5891472868217055,
        "vocab_size-1": 304,
        "unique-1": 246,
        "entropy-1": 7.4553798940036025,
        "distinct-2": 0.9176954732510288,
        "vocab_size-2": 446,
        "unique-2": 421,
        "entropy-2": 8.722794377129686,
        "cond_entropy-2": 1.0992940269206535,
        "distinct-3": 0.9758771929824561,
        "vocab_size-3": 445,
        "unique-3": 435,
        "entropy-3": 8.782988945081103,
        "cond_entropy-3": 0.07348523416690102,
        "total_length-nopunct": 459,
        "mean_pred_length-nopunct": 15.3,
        "std_pred_length-nopunct": 4.488132499529547,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6470588235294118,
        "vocab_size-1-nopunct": 297,
        "unique-1-nopunct": 245,
        "entropy-1-nopunct": 7.591377336756441,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 390,
        "unique-2-nopunct": 366,
        "entropy-2-nopunct": 8.520636146433416,
        "cond_entropy-2-nopunct": 1.0027534255271733,
        "distinct-3-nopunct": 0.974937343358396,
        "vocab_size-3-nopunct": 389,
        "unique-3-nopunct": 380,
        "entropy-3-nopunct": 8.588227674312138,
        "cond_entropy-3-nopunct": 0.08444849713187427,
        "msttr-100": 0.726,
        "msttr-100_nopunct": 0.7875,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24489795918367346,
            "2": 0.38317757009345793,
            "3": 0.808955223880597
        },
        "nist": 6.627149922232443,
        "bleu": 47.85626,
        "rouge1": {
            "precision": 0.75089,
            "recall": 0.73769,
            "fmeasure": 0.73596
        },
        "rouge2": {
            "precision": 0.53532,
            "recall": 0.53013,
            "fmeasure": 0.52662
        },
        "rougeL": {
            "precision": 0.62825,
            "recall": 0.61618,
            "fmeasure": 0.61577
        },
        "rougeLsum": {
            "precision": 0.62825,
            "recall": 0.61618,
            "fmeasure": 0.61577
        },
        "nubia": {
            "semantic_relation": 4.04135,
            "contradiction": 12.18084,
            "irrelevancy": 32.16157,
            "logical_agreement": 55.65759,
            "grammar_ref": 4.79957,
            "grammar_hyp": 4.72801,
            "nubia_score": 0.68533
        },
        "meteor": 0.4057891816802011,
        "bleurt": 0.23303,
        "bertscore": {
            "precision": 0.93092,
            "recall": 0.92727,
            "f1": 0.92713
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_61": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 60,
        "mean_pred_length": 15.0,
        "std_pred_length": 5.431390245600108,
        "median_pred_length": 13.5,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.75,
        "vocab_size-1": 45,
        "unique-1": 37,
        "entropy-1": 5.288233670962455,
        "distinct-2": 0.9821428571428571,
        "vocab_size-2": 55,
        "unique-2": 54,
        "entropy-2": 5.7716406363433235,
        "cond_entropy-2": 0.44268804031694764,
        "distinct-3": 1.0,
        "vocab_size-3": 52,
        "unique-3": 52,
        "entropy-3": 5.700439718141095,
        "cond_entropy-3": -0.06845366545497374,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.431390245600108,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7678571428571429,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.229416922475459,
        "distinct-2-nopunct": 0.9807692307692307,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.661978179679556,
        "cond_entropy-2-nopunct": 0.4577872571719547,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.5849625007211605,
        "cond_entropy-3-nopunct": -0.07381055075326928,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.47368421052631576,
            "2": 0.7428571428571429,
            "3": 0.5
        },
        "nist": 4.491820924593481,
        "bleu": 43.90082,
        "rouge1": {
            "precision": 0.64451,
            "recall": 0.84044,
            "fmeasure": 0.70165
        },
        "rouge2": {
            "precision": 0.41689,
            "recall": 0.58295,
            "fmeasure": 0.46818
        },
        "rougeL": {
            "precision": 0.58059,
            "recall": 0.80045,
            "fmeasure": 0.65559
        },
        "rougeLsum": {
            "precision": 0.58059,
            "recall": 0.80045,
            "fmeasure": 0.65559
        },
        "nubia": {
            "semantic_relation": 3.86692,
            "contradiction": 1.98884,
            "irrelevancy": 71.70282,
            "logical_agreement": 26.30834,
            "grammar_ref": 5.36601,
            "grammar_hyp": 4.82684,
            "nubia_score": 0.61387
        },
        "meteor": 0.4186009213238684,
        "bleurt": 0.03038,
        "bertscore": {
            "precision": 0.88838,
            "recall": 0.91791,
            "f1": 0.89712
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_78": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 66,
        "total_length": 1066,
        "mean_pred_length": 16.151515151515152,
        "std_pred_length": 5.193942929881049,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.5084427767354597,
        "vocab_size-1": 542,
        "unique-1": 449,
        "entropy-1": 7.876141968192681,
        "distinct-2": 0.869,
        "vocab_size-2": 869,
        "unique-2": 805,
        "entropy-2": 9.59065713570406,
        "cond_entropy-2": 1.4871349434075993,
        "distinct-3": 0.9678800856531049,
        "vocab_size-3": 904,
        "unique-3": 887,
        "entropy-3": 9.775088465260383,
        "cond_entropy-3": 0.13854578404327234,
        "total_length-nopunct": 924,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.489043901713944,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5768398268398268,
        "vocab_size-1-nopunct": 533,
        "unique-1-nopunct": 446,
        "entropy-1-nopunct": 8.133625123858685,
        "distinct-2-nopunct": 0.8974358974358975,
        "vocab_size-2-nopunct": 770,
        "unique-2-nopunct": 723,
        "entropy-2-nopunct": 9.457140803519783,
        "cond_entropy-2-nopunct": 1.3633021960116698,
        "distinct-3-nopunct": 0.9797979797979798,
        "vocab_size-3-nopunct": 776,
        "unique-3-nopunct": 762,
        "entropy-3-nopunct": 9.58642732715021,
        "cond_entropy-3-nopunct": 0.08620827098779725,
        "msttr-100": 0.739,
        "msttr-100_nopunct": 0.79,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2537313432835821,
            "2": 0.4489795918367347,
            "3": 0.7341954022988506
        },
        "nist": 6.768243605024444,
        "bleu": 40.53655,
        "rouge1": {
            "precision": 0.74761,
            "recall": 0.72761,
            "fmeasure": 0.72599
        },
        "rouge2": {
            "precision": 0.52315,
            "recall": 0.51031,
            "fmeasure": 0.50836
        },
        "rougeL": {
            "precision": 0.64849,
            "recall": 0.63538,
            "fmeasure": 0.63177
        },
        "rougeLsum": {
            "precision": 0.64849,
            "recall": 0.63538,
            "fmeasure": 0.63177
        },
        "nubia": {
            "semantic_relation": 4.21349,
            "contradiction": 6.26535,
            "irrelevancy": 31.81995,
            "logical_agreement": 61.91471,
            "grammar_ref": 4.35949,
            "grammar_hyp": 4.25536,
            "nubia_score": 0.75716
        },
        "meteor": 0.3828893585094004,
        "bleurt": 0.27009,
        "bertscore": {
            "precision": 0.92367,
            "recall": 0.92272,
            "f1": 0.92129
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 136,
        "total_length": 2179,
        "mean_pred_length": 16.022058823529413,
        "std_pred_length": 4.583324813874855,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.38044974759063793,
        "vocab_size-1": 829,
        "unique-1": 653,
        "entropy-1": 7.775586833888953,
        "distinct-2": 0.7209985315712188,
        "vocab_size-2": 1473,
        "unique-2": 1352,
        "entropy-2": 9.873998789496635,
        "cond_entropy-2": 1.8952102037331424,
        "distinct-3": 0.8238070267435763,
        "vocab_size-3": 1571,
        "unique-3": 1502,
        "entropy-3": 10.212623608630413,
        "cond_entropy-3": 0.38561108619762985,
        "total_length-nopunct": 1909,
        "mean_pred_length-nopunct": 14.036764705882353,
        "std_pred_length-nopunct": 4.217275549722088,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.429544264012572,
        "vocab_size-1-nopunct": 820,
        "unique-1-nopunct": 652,
        "entropy-1-nopunct": 8.006399984964377,
        "distinct-2-nopunct": 0.7281443880428652,
        "vocab_size-2-nopunct": 1291,
        "unique-2-nopunct": 1200,
        "entropy-2-nopunct": 9.672103507682518,
        "cond_entropy-2-nopunct": 1.8020224789272785,
        "distinct-3-nopunct": 0.8289554062309102,
        "vocab_size-3-nopunct": 1357,
        "unique-3-nopunct": 1307,
        "entropy-3-nopunct": 10.001962021664681,
        "cond_entropy-3-nopunct": 0.39415916805429835,
        "msttr-100": 0.66571,
        "msttr-100_nopunct": 0.69632,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2961038961038961,
            "2": 0.4675324675324675,
            "3": 0.7836706210746686
        },
        "nist": 7.8814097189415016,
        "bleu": 51.6967,
        "rouge1": {
            "precision": 0.76375,
            "recall": 0.75344,
            "fmeasure": 0.74979
        },
        "rouge2": {
            "precision": 0.55304,
            "recall": 0.54475,
            "fmeasure": 0.54231
        },
        "rougeL": {
            "precision": 0.67291,
            "recall": 0.66649,
            "fmeasure": 0.66149
        },
        "rougeLsum": {
            "precision": 0.67291,
            "recall": 0.66649,
            "fmeasure": 0.66149
        },
        "nubia": {
            "semantic_relation": 4.18637,
            "contradiction": 8.63004,
            "irrelevancy": 29.37797,
            "logical_agreement": 61.99199,
            "grammar_ref": 4.4992,
            "grammar_hyp": 4.50689,
            "nubia_score": 0.73566
        },
        "meteor": 0.40059876342634027,
        "bleurt": 0.31283,
        "bertscore": {
            "precision": 0.93101,
            "recall": 0.93038,
            "f1": 0.92943
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_63": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 39,
        "total_length": 676,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 5.4928080406054764,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.5680473372781065,
        "vocab_size-1": 384,
        "unique-1": 318,
        "entropy-1": 7.581644309598292,
        "distinct-2": 0.9089481946624803,
        "vocab_size-2": 579,
        "unique-2": 543,
        "entropy-2": 9.078598638727179,
        "cond_entropy-2": 1.3336520266769931,
        "distinct-3": 0.9648829431438127,
        "vocab_size-3": 577,
        "unique-3": 556,
        "entropy-3": 9.153767560485594,
        "cond_entropy-3": 0.08056271108578653,
        "total_length-nopunct": 566,
        "mean_pred_length-nopunct": 14.512820512820513,
        "std_pred_length-nopunct": 3.822147301377248,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6678445229681979,
        "vocab_size-1-nopunct": 378,
        "unique-1-nopunct": 316,
        "entropy-1-nopunct": 7.903753866013619,
        "distinct-2-nopunct": 0.9278937381404174,
        "vocab_size-2-nopunct": 489,
        "unique-2-nopunct": 465,
        "entropy-2-nopunct": 8.853474781079782,
        "cond_entropy-2-nopunct": 1.0192472588872847,
        "distinct-3-nopunct": 0.9672131147540983,
        "vocab_size-3-nopunct": 472,
        "unique-3-nopunct": 456,
        "entropy-3-nopunct": 8.865163567071184,
        "cond_entropy-3-nopunct": 0.02262975003176589,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.816,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11278195488721804,
            "2": 0.5502645502645502,
            "3": 0.7096774193548387
        },
        "nist": 6.369023497203312,
        "bleu": 45.06657,
        "rouge1": {
            "precision": 0.75715,
            "recall": 0.66451,
            "fmeasure": 0.69778
        },
        "rouge2": {
            "precision": 0.51905,
            "recall": 0.4592,
            "fmeasure": 0.48028
        },
        "rougeL": {
            "precision": 0.61869,
            "recall": 0.55684,
            "fmeasure": 0.5776
        },
        "rougeLsum": {
            "precision": 0.61869,
            "recall": 0.55684,
            "fmeasure": 0.5776
        },
        "nubia": {
            "semantic_relation": 4.09208,
            "contradiction": 6.62436,
            "irrelevancy": 33.49736,
            "logical_agreement": 59.87828,
            "grammar_ref": 4.28467,
            "grammar_hyp": 4.36506,
            "nubia_score": 0.69129
        },
        "meteor": 0.37628563010519867,
        "bleurt": 0.27682,
        "bertscore": {
            "precision": 0.93343,
            "recall": 0.92154,
            "f1": 0.92649
        }
    },
    "totto_test": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 7700,
        "total_length": 125061,
        "mean_pred_length": 16.24168831168831,
        "std_pred_length": 5.469576042498045,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 36,
        "distinct-1": 0.1728996249830083,
        "vocab_size-1": 21623,
        "unique-1": 14925,
        "entropy-1": 10.076191405899703,
        "distinct-2": 0.5538551989161646,
        "vocab_size-2": 65001,
        "unique-2": 54498,
        "entropy-2": 14.64350845676657,
        "cond_entropy-2": 4.241095894331624,
        "distinct-3": 0.7904359799746491,
        "vocab_size-3": 86680,
        "unique-3": 79245,
        "entropy-3": 15.94426946759422,
        "cond_entropy-3": 1.2982356632097125,
        "total_length-nopunct": 109327,
        "mean_pred_length-nopunct": 14.198311688311689,
        "std_pred_length-nopunct": 4.910923129185843,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.19759986096755605,
        "vocab_size-1-nopunct": 21603,
        "unique-1-nopunct": 14922,
        "entropy-1-nopunct": 10.611177124027513,
        "distinct-2-nopunct": 0.5973904572603738,
        "vocab_size-2-nopunct": 60711,
        "unique-2-nopunct": 51983,
        "entropy-2-nopunct": 14.645604339643086,
        "cond_entropy-2-nopunct": 4.220476904639044,
        "distinct-3-nopunct": 0.8165703152448178,
        "vocab_size-3-nopunct": 76698,
        "unique-3-nopunct": 70953,
        "entropy-3-nopunct": 15.825275655294702,
        "cond_entropy-3-nopunct": 1.2590445541523083,
        "msttr-100": 0.72797,
        "msttr-100_nopunct": 0.77907,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2251003283473185,
            "2": 0.4694480660582355,
            "3": 0.767048451510813
        },
        "nist": 10.760305819821411,
        "bleu": 46.52521,
        "rouge1": {
            "precision": 0.75461,
            "recall": 0.73326,
            "fmeasure": 0.73226
        },
        "rouge2": {
            "precision": 0.53187,
            "recall": 0.51789,
            "fmeasure": 0.51638
        },
        "rougeL": {
            "precision": 0.65716,
            "recall": 0.64286,
            "fmeasure": 0.63957
        },
        "rougeLsum": {
            "precision": 0.65716,
            "recall": 0.64286,
            "fmeasure": 0.63957
        },
        "nubia": {
            "semantic_relation": 4.15974,
            "contradiction": 8.92779,
            "irrelevancy": 30.41751,
            "logical_agreement": 60.6547,
            "grammar_ref": 4.66736,
            "grammar_hyp": 4.66707,
            "nubia_score": 0.7188
        },
        "meteor": 0.39091881192644923,
        "bleurt": 0.26096,
        "bertscore": {
            "precision": 0.92797,
            "recall": 0.92531,
            "f1": 0.925
        }
    },
    "schema_guided_dialog_challenge_test_scramble": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_challenge_test_scramble",
        "N": 500,
        "total_length": 6465,
        "mean_pred_length": 12.93,
        "std_pred_length": 6.558742257475895,
        "median_pred_length": 12.0,
        "min_pred_length": 3,
        "max_pred_length": 31,
        "distinct-1": 0.15962877030162412,
        "vocab_size-1": 1032,
        "unique-1": 564,
        "entropy-1": 7.836328156117909,
        "distinct-2": 0.49958088851634536,
        "vocab_size-2": 2980,
        "unique-2": 2073,
        "entropy-2": 10.815906517948019,
        "cond_entropy-2": 2.7556898169352166,
        "distinct-3": 0.7348581884720952,
        "vocab_size-3": 4016,
        "unique-3": 3327,
        "entropy-3": 11.647262980358022,
        "cond_entropy-3": 0.8633583252072735,
        "total_length-nopunct": 5691,
        "mean_pred_length-nopunct": 11.382,
        "std_pred_length-nopunct": 6.123077330885182,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.17940607977508347,
        "vocab_size-1-nopunct": 1021,
        "unique-1-nopunct": 562,
        "entropy-1-nopunct": 8.024029289842298,
        "distinct-2-nopunct": 0.5162781737622809,
        "vocab_size-2-nopunct": 2680,
        "unique-2-nopunct": 1903,
        "entropy-2-nopunct": 10.656450183119007,
        "cond_entropy-2-nopunct": 2.7765312771621153,
        "distinct-3-nopunct": 0.7439778298870177,
        "vocab_size-3-nopunct": 3490,
        "unique-3-nopunct": 2922,
        "entropy-3-nopunct": 11.438510888224432,
        "cond_entropy-3-nopunct": 0.8387519665221698,
        "msttr-100": 0.69063,
        "msttr-100_nopunct": 0.72107,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.5494751333677508
        },
        "nist": 5.96453299018076,
        "bleu": 29.22998,
        "rouge1": {
            "precision": 0.57071,
            "recall": 0.54083,
            "fmeasure": 0.5449
        },
        "rouge2": {
            "precision": 0.34343,
            "recall": 0.3236,
            "fmeasure": 0.32599
        },
        "rougeL": {
            "precision": 0.49516,
            "recall": 0.47179,
            "fmeasure": 0.47411
        },
        "rougeLsum": {
            "precision": 0.49516,
            "recall": 0.47179,
            "fmeasure": 0.47411
        },
        "nubia": {
            "semantic_relation": 3.5412,
            "contradiction": 7.36988,
            "irrelevancy": 23.6558,
            "logical_agreement": 68.97432,
            "grammar_ref": 4.7801,
            "grammar_hyp": 4.70197,
            "nubia_score": 0.61186
        },
        "meteor": 0.3026034872141447,
        "bleurt": -0.15043,
        "bertscore": {
            "precision": 0.8668,
            "recall": 0.85925,
            "f1": 0.86255
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_16": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 111,
        "total_length": 1853,
        "mean_pred_length": 16.693693693693692,
        "std_pred_length": 5.4322904976004915,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 36,
        "distinct-1": 0.4117647058823529,
        "vocab_size-1": 763,
        "unique-1": 629,
        "entropy-1": 7.784633749058909,
        "distinct-2": 0.7445464982778416,
        "vocab_size-2": 1297,
        "unique-2": 1201,
        "entropy-2": 9.775873490856767,
        "cond_entropy-2": 1.802649832789642,
        "distinct-3": 0.8405885959534029,
        "vocab_size-3": 1371,
        "unique-3": 1316,
        "entropy-3": 10.06854475701875,
        "cond_entropy-3": 0.32967501287882867,
        "total_length-nopunct": 1597,
        "mean_pred_length-nopunct": 14.387387387387387,
        "std_pred_length-nopunct": 4.696502764749573,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4715090795241077,
        "vocab_size-1-nopunct": 753,
        "unique-1-nopunct": 625,
        "entropy-1-nopunct": 8.024705066292142,
        "distinct-2-nopunct": 0.7550471063257066,
        "vocab_size-2-nopunct": 1122,
        "unique-2-nopunct": 1057,
        "entropy-2-nopunct": 9.5493937167467,
        "cond_entropy-2-nopunct": 1.659081440847696,
        "distinct-3-nopunct": 0.8465454545454546,
        "vocab_size-3-nopunct": 1164,
        "unique-3-nopunct": 1124,
        "entropy-3-nopunct": 9.834227841069538,
        "cond_entropy-3-nopunct": 0.33966688304043746,
        "msttr-100": 0.67389,
        "msttr-100_nopunct": 0.70933,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22424242424242424,
            "2": 0.44814814814814813,
            "3": 0.7741420590582602
        },
        "nist": 7.61343750577275,
        "bleu": 50.87845,
        "rouge1": {
            "precision": 0.77769,
            "recall": 0.75027,
            "fmeasure": 0.75375
        },
        "rouge2": {
            "precision": 0.57572,
            "recall": 0.55302,
            "fmeasure": 0.55701
        },
        "rougeL": {
            "precision": 0.70282,
            "recall": 0.67687,
            "fmeasure": 0.68075
        },
        "rougeLsum": {
            "precision": 0.70282,
            "recall": 0.67687,
            "fmeasure": 0.68075
        },
        "nubia": {
            "semantic_relation": 4.25722,
            "contradiction": 4.29032,
            "irrelevancy": 26.3525,
            "logical_agreement": 69.35718,
            "grammar_ref": 4.48776,
            "grammar_hyp": 4.52554,
            "nubia_score": 0.75565
        },
        "meteor": 0.4005337802292072,
        "bleurt": 0.35036,
        "bertscore": {
            "precision": 0.93528,
            "recall": 0.93281,
            "f1": 0.93212
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_99": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 14,
        "total_length": 274,
        "mean_pred_length": 19.571428571428573,
        "std_pred_length": 5.407855208785056,
        "median_pred_length": 19.0,
        "min_pred_length": 12,
        "max_pred_length": 30,
        "distinct-1": 0.6532846715328468,
        "vocab_size-1": 179,
        "unique-1": 149,
        "entropy-1": 6.950808591222575,
        "distinct-2": 0.9615384615384616,
        "vocab_size-2": 250,
        "unique-2": 241,
        "entropy-2": 7.942541322635517,
        "cond_entropy-2": 0.9437781309181037,
        "distinct-3": 0.991869918699187,
        "vocab_size-3": 244,
        "unique-3": 242,
        "entropy-3": 7.9262543427376535,
        "cond_entropy-3": -0.011744008899932169,
        "total_length-nopunct": 246,
        "mean_pred_length-nopunct": 17.571428571428573,
        "std_pred_length-nopunct": 4.99591670001306,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7073170731707317,
        "vocab_size-1-nopunct": 174,
        "unique-1-nopunct": 147,
        "entropy-1-nopunct": 7.027040713513727,
        "distinct-2-nopunct": 0.9655172413793104,
        "vocab_size-2-nopunct": 224,
        "unique-2-nopunct": 217,
        "entropy-2-nopunct": 7.785761652445813,
        "cond_entropy-2-nopunct": 0.8053443574043628,
        "distinct-3-nopunct": 0.9954128440366973,
        "vocab_size-3-nopunct": 217,
        "unique-3-nopunct": 216,
        "entropy-3-nopunct": 7.759010012850308,
        "cond_entropy-3-nopunct": -0.02211370015723539,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.785,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3050847457627119,
            "2": 0.3695652173913043,
            "3": 0.703030303030303
        },
        "nist": 5.4899456996598515,
        "bleu": 36.84551,
        "rouge1": {
            "precision": 0.63728,
            "recall": 0.66714,
            "fmeasure": 0.63752
        },
        "rouge2": {
            "precision": 0.39016,
            "recall": 0.41153,
            "fmeasure": 0.39054
        },
        "rougeL": {
            "precision": 0.51996,
            "recall": 0.55658,
            "fmeasure": 0.52517
        },
        "rougeLsum": {
            "precision": 0.51996,
            "recall": 0.55658,
            "fmeasure": 0.52517
        },
        "nubia": {
            "semantic_relation": 3.85391,
            "contradiction": 5.76217,
            "irrelevancy": 41.87178,
            "logical_agreement": 52.36606,
            "grammar_ref": 4.70274,
            "grammar_hyp": 4.42801,
            "nubia_score": 0.62632
        },
        "meteor": 0.34347006454533385,
        "bleurt": 0.00791,
        "bertscore": {
            "precision": 0.88797,
            "recall": 0.9059,
            "f1": 0.89548
        }
    },
    "totto_challenge_train_sample": {
        "predictions_file": "ByT5-base (Baseline)/totto_challenge_train_sample",
        "N": 500
    },
    "totto_test_contrast_challenge_table_size-table_size_79": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185188,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.4,
            "3": 0.5714285714285714
        },
        "nist": 3.7910361962801384,
        "bleu": 55.26779,
        "rouge1": {
            "precision": 0.75439,
            "recall": 0.5119,
            "fmeasure": 0.60993
        },
        "rouge2": {
            "precision": 0.53704,
            "recall": 0.38827,
            "fmeasure": 0.44873
        },
        "rougeL": {
            "precision": 0.54386,
            "recall": 0.44841,
            "fmeasure": 0.48936
        },
        "rougeLsum": {
            "precision": 0.54386,
            "recall": 0.44841,
            "fmeasure": 0.48936
        },
        "nubia": {
            "semantic_relation": 3.96925,
            "contradiction": 0.12407,
            "irrelevancy": 62.48621,
            "logical_agreement": 37.38972,
            "grammar_ref": 3.5675,
            "grammar_hyp": 4.06162,
            "nubia_score": 0.65221
        },
        "meteor": 0.2768183560656726,
        "bleurt": -0.03043,
        "bertscore": {
            "precision": 0.92781,
            "recall": 0.88847,
            "f1": 0.90771
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_126": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 57,
        "total_length": 938,
        "mean_pred_length": 16.45614035087719,
        "std_pred_length": 4.783268263284763,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.5181236673773987,
        "vocab_size-1": 486,
        "unique-1": 393,
        "entropy-1": 7.788037180121109,
        "distinct-2": 0.8762769580022701,
        "vocab_size-2": 772,
        "unique-2": 720,
        "entropy-2": 9.43246885779378,
        "cond_entropy-2": 1.4487160167258648,
        "distinct-3": 0.9550970873786407,
        "vocab_size-3": 787,
        "unique-3": 761,
        "entropy-3": 9.584832520495356,
        "cond_entropy-3": 0.1584075619908077,
        "total_length-nopunct": 829,
        "mean_pred_length-nopunct": 14.543859649122806,
        "std_pred_length-nopunct": 4.4448676314377895,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.5778045838359469,
        "vocab_size-1-nopunct": 479,
        "unique-1-nopunct": 390,
        "entropy-1-nopunct": 7.9705900181363525,
        "distinct-2-nopunct": 0.8808290155440415,
        "vocab_size-2-nopunct": 680,
        "unique-2-nopunct": 639,
        "entropy-2-nopunct": 9.244721505705764,
        "cond_entropy-2-nopunct": 1.3673497927231173,
        "distinct-3-nopunct": 0.9552447552447553,
        "vocab_size-3-nopunct": 683,
        "unique-3-nopunct": 663,
        "entropy-3-nopunct": 9.37687698410132,
        "cond_entropy-3-nopunct": 0.1484505837067563,
        "msttr-100": 0.72667,
        "msttr-100_nopunct": 0.765,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24423963133640553,
            "2": 0.5414634146341464,
            "3": 0.7798861480075902
        },
        "nist": 7.255006384734669,
        "bleu": 47.47875,
        "rouge1": {
            "precision": 0.75363,
            "recall": 0.76271,
            "fmeasure": 0.74725
        },
        "rouge2": {
            "precision": 0.53495,
            "recall": 0.54794,
            "fmeasure": 0.53214
        },
        "rougeL": {
            "precision": 0.62954,
            "recall": 0.64275,
            "fmeasure": 0.62525
        },
        "rougeLsum": {
            "precision": 0.62954,
            "recall": 0.64275,
            "fmeasure": 0.62525
        },
        "nubia": {
            "semantic_relation": 4.2109,
            "contradiction": 5.36541,
            "irrelevancy": 36.91992,
            "logical_agreement": 57.71467,
            "grammar_ref": 4.80748,
            "grammar_hyp": 4.72604,
            "nubia_score": 0.73034
        },
        "meteor": 0.40102432058396664,
        "bleurt": 0.23676,
        "bertscore": {
            "precision": 0.92664,
            "recall": 0.93211,
            "f1": 0.92785
        }
    },
    "xsum_validation": {
        "predictions_file": "ByT5-base (Baseline)/xsum_validation",
        "N": 1117,
        "total_length": 24056,
        "mean_pred_length": 21.536257833482544,
        "std_pred_length": 3.4062165452095683,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.20090621882274692,
        "vocab_size-1": 4833,
        "unique-1": 2846,
        "entropy-1": 9.331115867751347,
        "distinct-2": 0.6488513012773006,
        "vocab_size-2": 14884,
        "unique-2": 12463,
        "entropy-2": 13.121945765792082,
        "cond_entropy-2": 3.715209687687861,
        "distinct-3": 0.8845660342773348,
        "vocab_size-3": 19303,
        "unique-3": 18054,
        "entropy-3": 14.081250068121093,
        "cond_entropy-3": 0.9825362681811385,
        "total_length-nopunct": 22846,
        "mean_pred_length-nopunct": 20.45299910474485,
        "std_pred_length-nopunct": 3.5562725868143237,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.21093408036417755,
        "vocab_size-1-nopunct": 4819,
        "unique-1-nopunct": 2842,
        "entropy-1-nopunct": 9.432485218864093,
        "distinct-2-nopunct": 0.6579686133738322,
        "vocab_size-2-nopunct": 14297,
        "unique-2-nopunct": 12047,
        "entropy-2-nopunct": 13.077891688767235,
        "cond_entropy-2-nopunct": 3.768538718017411,
        "distinct-3-nopunct": 0.8936056666019794,
        "vocab_size-3-nopunct": 18419,
        "unique-3-nopunct": 17301,
        "entropy-3-nopunct": 14.032915909336108,
        "cond_entropy-3-nopunct": 0.9792074636172176,
        "msttr-100": 0.74112,
        "msttr-100_nopunct": 0.74789,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_validation.json",
        "local_recall": {
            "1": 0.3511474521142031
        },
        "nist": 3.688282064096275,
        "bleu": 9.37321,
        "rouge1": {
            "precision": 0.38682,
            "recall": 0.37729,
            "fmeasure": 0.37563
        },
        "rouge2": {
            "precision": 0.14371,
            "recall": 0.13992,
            "fmeasure": 0.13932
        },
        "rougeL": {
            "precision": 0.30002,
            "recall": 0.29259,
            "fmeasure": 0.2912
        },
        "rougeLsum": {
            "precision": 0.30002,
            "recall": 0.29259,
            "fmeasure": 0.2912
        },
        "nubia": {
            "semantic_relation": 2.74404,
            "contradiction": 25.21142,
            "irrelevancy": 63.88677,
            "logical_agreement": 10.9018,
            "grammar_ref": 3.8151,
            "grammar_hyp": 4.1118,
            "nubia_score": 0.35678
        },
        "meteor": 0.16509448893825496,
        "bleurt": -0.44641,
        "bertscore": {
            "precision": 0.82487,
            "recall": 0.81919,
            "f1": 0.82174
        }
    },
    "xsum_test": {
        "predictions_file": "ByT5-base (Baseline)/xsum_test",
        "N": 1166,
        "total_length": 24999,
        "mean_pred_length": 21.439965694682677,
        "std_pred_length": 3.4025640617574644,
        "median_pred_length": 22.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.1996879875195008,
        "vocab_size-1": 4992,
        "unique-1": 2917,
        "entropy-1": 9.372497662223678,
        "distinct-2": 0.6461209247681786,
        "vocab_size-2": 15399,
        "unique-2": 12812,
        "entropy-2": 13.170268649886205,
        "cond_entropy-2": 3.7219766675508783,
        "distinct-3": 0.883619358538845,
        "vocab_size-3": 20029,
        "unique-3": 18680,
        "entropy-3": 14.135995373423356,
        "cond_entropy-3": 0.9900449842137865,
        "total_length-nopunct": 23771,
        "mean_pred_length-nopunct": 20.38679245283019,
        "std_pred_length-nopunct": 3.5456538036269984,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.2094989693323798,
        "vocab_size-1-nopunct": 4980,
        "unique-1-nopunct": 2915,
        "entropy-1-nopunct": 9.475053756801104,
        "distinct-2-nopunct": 0.653085600530856,
        "vocab_size-2-nopunct": 14763,
        "unique-2-nopunct": 12347,
        "entropy-2-nopunct": 13.121503935758701,
        "cond_entropy-2-nopunct": 3.7765607115517033,
        "distinct-3-nopunct": 0.8914128457484024,
        "vocab_size-3-nopunct": 19111,
        "unique-3-nopunct": 17892,
        "entropy-3-nopunct": 14.088643455697204,
        "cond_entropy-3-nopunct": 0.9928271841223403,
        "msttr-100": 0.74233,
        "msttr-100_nopunct": 0.75148,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.343620608699364
        },
        "nist": 3.625654518839486,
        "bleu": 8.90064,
        "rouge1": {
            "precision": 0.38576,
            "recall": 0.37289,
            "fmeasure": 0.37314
        },
        "rouge2": {
            "precision": 0.14493,
            "recall": 0.13974,
            "fmeasure": 0.13984
        },
        "rougeL": {
            "precision": 0.29937,
            "recall": 0.28953,
            "fmeasure": 0.28958
        },
        "rougeLsum": {
            "precision": 0.29937,
            "recall": 0.28953,
            "fmeasure": 0.28958
        },
        "nubia": {
            "semantic_relation": 2.69709,
            "contradiction": 27.76293,
            "irrelevancy": 61.93746,
            "logical_agreement": 10.29961,
            "grammar_ref": 3.76542,
            "grammar_hyp": 4.10215,
            "nubia_score": 0.34523
        },
        "meteor": 0.1605265376008837,
        "bleurt": -0.45386,
        "bertscore": {
            "precision": 0.82457,
            "recall": 0.81812,
            "f1": 0.82104
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_17": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 48,
        "total_length": 699,
        "mean_pred_length": 14.5625,
        "std_pred_length": 3.610783906116048,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.3319027181688126,
        "vocab_size-1": 232,
        "unique-1": 186,
        "entropy-1": 6.30388903384602,
        "distinct-2": 0.5929339477726574,
        "vocab_size-2": 386,
        "unique-2": 335,
        "entropy-2": 7.909658450919338,
        "cond_entropy-2": 1.445187810585372,
        "distinct-3": 0.7114427860696517,
        "vocab_size-3": 429,
        "unique-3": 387,
        "entropy-3": 8.28866242097615,
        "cond_entropy-3": 0.4310096302115795,
        "total_length-nopunct": 603,
        "mean_pred_length-nopunct": 12.5625,
        "std_pred_length-nopunct": 3.2717620762111252,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.37645107794361526,
        "vocab_size-1-nopunct": 227,
        "unique-1-nopunct": 184,
        "entropy-1-nopunct": 6.429213339979604,
        "distinct-2-nopunct": 0.5981981981981982,
        "vocab_size-2-nopunct": 332,
        "unique-2-nopunct": 288,
        "entropy-2-nopunct": 7.710742922990381,
        "cond_entropy-2-nopunct": 1.4017004127397144,
        "distinct-3-nopunct": 0.7140039447731755,
        "vocab_size-3-nopunct": 362,
        "unique-3-nopunct": 327,
        "entropy-3-nopunct": 8.047244225204867,
        "cond_entropy-3-nopunct": 0.4429294577006384,
        "msttr-100": 0.52333,
        "msttr-100_nopunct": 0.56333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21621621621621623,
            "2": 0.6125,
            "3": 0.8165680473372781
        },
        "nist": 7.400054142803229,
        "bleu": 65.29917,
        "rouge1": {
            "precision": 0.84695,
            "recall": 0.80811,
            "fmeasure": 0.81743
        },
        "rouge2": {
            "precision": 0.69127,
            "recall": 0.65805,
            "fmeasure": 0.66739
        },
        "rougeL": {
            "precision": 0.7924,
            "recall": 0.75826,
            "fmeasure": 0.76693
        },
        "rougeLsum": {
            "precision": 0.7924,
            "recall": 0.75826,
            "fmeasure": 0.76693
        },
        "nubia": {
            "semantic_relation": 4.44639,
            "contradiction": 2.00078,
            "irrelevancy": 12.67151,
            "logical_agreement": 85.32771,
            "grammar_ref": 4.06325,
            "grammar_hyp": 4.1444,
            "nubia_score": 0.83879
        },
        "meteor": 0.45623736338723664,
        "bleurt": 0.58862,
        "bertscore": {
            "precision": 0.9593,
            "recall": 0.95182,
            "f1": 0.95484
        }
    },
    "xsum_challenge_train_sample": {
        "predictions_file": "ByT5-base (Baseline)/xsum_challenge_train_sample",
        "N": 500
    },
    "totto_test_contrast_challenge_table_size-table_size_80": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 83,
        "total_length": 1470,
        "mean_pred_length": 17.710843373493976,
        "std_pred_length": 5.5418019784397945,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.49387755102040815,
        "vocab_size-1": 726,
        "unique-1": 582,
        "entropy-1": 8.17335234222608,
        "distinct-2": 0.8759913482335977,
        "vocab_size-2": 1215,
        "unique-2": 1120,
        "entropy-2": 10.088784415532196,
        "cond_entropy-2": 1.7377179312717106,
        "distinct-3": 0.9700920245398773,
        "vocab_size-3": 1265,
        "unique-3": 1234,
        "entropy-3": 10.283153173399624,
        "cond_entropy-3": 0.19010111254568682,
        "total_length-nopunct": 1273,
        "mean_pred_length-nopunct": 15.337349397590362,
        "std_pred_length-nopunct": 4.96318278282723,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5640219952867243,
        "vocab_size-1-nopunct": 718,
        "unique-1-nopunct": 580,
        "entropy-1-nopunct": 8.44416341698464,
        "distinct-2-nopunct": 0.892436974789916,
        "vocab_size-2-nopunct": 1062,
        "unique-2-nopunct": 994,
        "entropy-2-nopunct": 9.902784083425832,
        "cond_entropy-2-nopunct": 1.5534098085608359,
        "distinct-3-nopunct": 0.974706413730804,
        "vocab_size-3-nopunct": 1079,
        "unique-3-nopunct": 1058,
        "entropy-3-nopunct": 10.055750358179694,
        "cond_entropy-3-nopunct": 0.17146118424364826,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.78667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20161290322580644,
            "2": 0.556910569105691,
            "3": 0.7905982905982906
        },
        "nist": 7.7217764126287305,
        "bleu": 50.38547,
        "rouge1": {
            "precision": 0.76967,
            "recall": 0.75284,
            "fmeasure": 0.75071
        },
        "rouge2": {
            "precision": 0.54145,
            "recall": 0.53152,
            "fmeasure": 0.52881
        },
        "rougeL": {
            "precision": 0.66923,
            "recall": 0.66016,
            "fmeasure": 0.65555
        },
        "rougeLsum": {
            "precision": 0.66923,
            "recall": 0.66016,
            "fmeasure": 0.65555
        },
        "nubia": {
            "semantic_relation": 4.33896,
            "contradiction": 9.44626,
            "irrelevancy": 25.28096,
            "logical_agreement": 65.27279,
            "grammar_ref": 4.65999,
            "grammar_hyp": 4.66385,
            "nubia_score": 0.76091
        },
        "meteor": 0.4081578482937641,
        "bleurt": 0.32231,
        "bertscore": {
            "precision": 0.93366,
            "recall": 0.93404,
            "f1": 0.93252
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_127": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "nist": 2.415947705372627,
        "bleu": 25.21194,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.55556,
            "fmeasure": 0.55556
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "nubia": {
            "semantic_relation": 3.9393,
            "contradiction": 0.50698,
            "irrelevancy": 97.97126,
            "logical_agreement": 1.52176,
            "grammar_ref": 6.33221,
            "grammar_hyp": 5.93182,
            "nubia_score": 0.68311
        },
        "meteor": 0.4235494540099438,
        "bleurt": 0.64341,
        "bertscore": {
            "precision": 0.93993,
            "recall": 0.96605,
            "f1": 0.95235
        }
    },
    "xsum_challenge_validation_sample": {
        "predictions_file": "ByT5-base (Baseline)/xsum_challenge_validation_sample",
        "N": 500
    },
    "totto_test_contrast_challenge_table_size-table_size_64": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 36,
        "total_length": 657,
        "mean_pred_length": 18.25,
        "std_pred_length": 5.697830971323893,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.5449010654490106,
        "vocab_size-1": 358,
        "unique-1": 290,
        "entropy-1": 7.477770126182032,
        "distinct-2": 0.9194847020933977,
        "vocab_size-2": 571,
        "unique-2": 542,
        "entropy-2": 9.053369848702205,
        "cond_entropy-2": 1.4452601330414203,
        "distinct-3": 0.9863247863247864,
        "vocab_size-3": 577,
        "unique-3": 571,
        "entropy-3": 9.162361575147084,
        "cond_entropy-3": 0.11300536480468949,
        "total_length-nopunct": 576,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 5.369667897862337,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.609375,
        "vocab_size-1-nopunct": 351,
        "unique-1-nopunct": 288,
        "entropy-1-nopunct": 7.625977655127619,
        "distinct-2-nopunct": 0.924074074074074,
        "vocab_size-2-nopunct": 499,
        "unique-2-nopunct": 477,
        "entropy-2-nopunct": 8.854103259075792,
        "cond_entropy-2-nopunct": 1.312578982733169,
        "distinct-3-nopunct": 0.9861111111111112,
        "vocab_size-3-nopunct": 497,
        "unique-3-nopunct": 492,
        "entropy-3-nopunct": 8.946506560396026,
        "cond_entropy-3-nopunct": 0.1063271984771863,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.742,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26495726495726496,
            "2": 0.4485294117647059,
            "3": 0.7487437185929648
        },
        "nist": 6.616392877686005,
        "bleu": 41.70802,
        "rouge1": {
            "precision": 0.74969,
            "recall": 0.68557,
            "fmeasure": 0.70345
        },
        "rouge2": {
            "precision": 0.46989,
            "recall": 0.43127,
            "fmeasure": 0.44235
        },
        "rougeL": {
            "precision": 0.62174,
            "recall": 0.5779,
            "fmeasure": 0.5889
        },
        "rougeLsum": {
            "precision": 0.62174,
            "recall": 0.5779,
            "fmeasure": 0.5889
        },
        "nubia": {
            "semantic_relation": 4.08725,
            "contradiction": 5.96943,
            "irrelevancy": 34.17792,
            "logical_agreement": 59.85265,
            "grammar_ref": 4.71629,
            "grammar_hyp": 4.91392,
            "nubia_score": 0.67819
        },
        "meteor": 0.36042887279043306,
        "bleurt": 0.15748,
        "bertscore": {
            "precision": 0.92493,
            "recall": 0.91772,
            "f1": 0.92002
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "ByT5-base (Baseline)/e2e_nlg_test",
        "N": 1406,
        "total_length": 33686,
        "mean_pred_length": 23.958748221906117,
        "std_pred_length": 2.4659281917752307,
        "median_pred_length": 24.0,
        "min_pred_length": 17,
        "max_pred_length": 32,
        "distinct-1": 0.010122899720952325,
        "vocab_size-1": 341,
        "unique-1": 56,
        "entropy-1": 5.999278531055609,
        "distinct-2": 0.040923172242874846,
        "vocab_size-2": 1321,
        "unique-2": 306,
        "entropy-2": 8.083274611849472,
        "cond_entropy-2": 2.1739078939092558,
        "distinct-3": 0.0875493943123664,
        "vocab_size-3": 2703,
        "unique-3": 720,
        "entropy-3": 9.454469558621568,
        "cond_entropy-3": 1.4737696293658045,
        "total_length-nopunct": 31670,
        "mean_pred_length-nopunct": 22.524893314367,
        "std_pred_length-nopunct": 2.529573127842288,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.010704136406694032,
        "vocab_size-1-nopunct": 339,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.985991126219897,
        "distinct-2-nopunct": 0.04345096484271742,
        "vocab_size-2-nopunct": 1315,
        "unique-2-nopunct": 310,
        "entropy-2-nopunct": 8.056341650069736,
        "cond_entropy-2-nopunct": 2.1948624993211303,
        "distinct-3-nopunct": 0.09106660198211934,
        "vocab_size-3-nopunct": 2628,
        "unique-3-nopunct": 711,
        "entropy-3-nopunct": 9.445843001343134,
        "cond_entropy-3-nopunct": 1.48757959992577,
        "msttr-100": 0.31238,
        "msttr-100_nopunct": 0.30247,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6428810109663112
        },
        "nist": 4.620997863016883,
        "bleu": 27.3846,
        "rouge1": {
            "precision": 0.77152,
            "recall": 0.66083,
            "fmeasure": 0.70503
        },
        "rouge2": {
            "precision": 0.4657,
            "recall": 0.39831,
            "fmeasure": 0.4251
        },
        "rougeL": {
            "precision": 0.53906,
            "recall": 0.46354,
            "fmeasure": 0.49367
        },
        "rougeLsum": {
            "precision": 0.53906,
            "recall": 0.46354,
            "fmeasure": 0.49367
        },
        "nubia": {
            "semantic_relation": 4.16381,
            "contradiction": 3.17798,
            "irrelevancy": 13.08668,
            "logical_agreement": 83.73534,
            "grammar_ref": 4.68084,
            "grammar_hyp": 4.77797,
            "nubia_score": 0.69114
        },
        "meteor": 0.3305298775371911,
        "bleurt": 0.01188,
        "bertscore": {
            "precision": 0.91482,
            "recall": 0.89121,
            "f1": 0.90265
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_100": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 48,
        "total_length": 776,
        "mean_pred_length": 16.166666666666668,
        "std_pred_length": 4.9805175991613115,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.5347938144329897,
        "vocab_size-1": 415,
        "unique-1": 341,
        "entropy-1": 7.646839765046016,
        "distinct-2": 0.9065934065934066,
        "vocab_size-2": 660,
        "unique-2": 619,
        "entropy-2": 9.27207675170057,
        "cond_entropy-2": 1.4373011530072561,
        "distinct-3": 0.9838235294117647,
        "vocab_size-3": 669,
        "unique-3": 659,
        "entropy-3": 9.375927866281694,
        "cond_entropy-3": 0.1057841420044203,
        "total_length-nopunct": 692,
        "mean_pred_length-nopunct": 14.416666666666666,
        "std_pred_length-nopunct": 4.898270669895198,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5924855491329479,
        "vocab_size-1-nopunct": 410,
        "unique-1-nopunct": 340,
        "entropy-1-nopunct": 7.827246710969283,
        "distinct-2-nopunct": 0.9099378881987578,
        "vocab_size-2-nopunct": 586,
        "unique-2-nopunct": 552,
        "entropy-2-nopunct": 9.099786854318817,
        "cond_entropy-2-nopunct": 1.3630866689033707,
        "distinct-3-nopunct": 0.9848993288590604,
        "vocab_size-3-nopunct": 587,
        "unique-3-nopunct": 579,
        "entropy-3-nopunct": 9.187700588411463,
        "cond_entropy-3-nopunct": 0.10149467560646765,
        "msttr-100": 0.73286,
        "msttr-100_nopunct": 0.78333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18791946308724833,
            "2": 0.4,
            "3": 0.7702970297029703
        },
        "nist": 6.959831747043253,
        "bleu": 46.25384,
        "rouge1": {
            "precision": 0.75066,
            "recall": 0.74704,
            "fmeasure": 0.73799
        },
        "rouge2": {
            "precision": 0.51779,
            "recall": 0.52536,
            "fmeasure": 0.51385
        },
        "rougeL": {
            "precision": 0.64857,
            "recall": 0.64679,
            "fmeasure": 0.63826
        },
        "rougeLsum": {
            "precision": 0.64857,
            "recall": 0.64679,
            "fmeasure": 0.63826
        },
        "nubia": {
            "semantic_relation": 4.25138,
            "contradiction": 10.01992,
            "irrelevancy": 25.68462,
            "logical_agreement": 64.29546,
            "grammar_ref": 4.77611,
            "grammar_hyp": 4.89288,
            "nubia_score": 0.73057
        },
        "meteor": 0.39201765730275034,
        "bleurt": 0.27836,
        "bertscore": {
            "precision": 0.93047,
            "recall": 0.93401,
            "f1": 0.9306
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_81": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 12,
        "total_length": 184,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 6.1553951042064625,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.6793478260869565,
        "vocab_size-1": 125,
        "unique-1": 103,
        "entropy-1": 6.587394328945441,
        "distinct-2": 0.9593023255813954,
        "vocab_size-2": 165,
        "unique-2": 159,
        "entropy-2": 7.340480525038328,
        "cond_entropy-2": 0.6252648622351659,
        "distinct-3": 1.0,
        "vocab_size-3": 160,
        "unique-3": 160,
        "entropy-3": 7.321928094887368,
        "cond_entropy-3": -0.012118612926214203,
        "total_length-nopunct": 159,
        "mean_pred_length-nopunct": 13.25,
        "std_pred_length-nopunct": 5.0518148554092255,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7547169811320755,
        "vocab_size-1-nopunct": 120,
        "unique-1-nopunct": 102,
        "entropy-1-nopunct": 6.649198757577851,
        "distinct-2-nopunct": 0.9727891156462585,
        "vocab_size-2-nopunct": 143,
        "unique-2-nopunct": 140,
        "entropy-2-nopunct": 7.140115286998507,
        "cond_entropy-2-nopunct": 0.5207073312693286,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 135,
        "unique-3-nopunct": 135,
        "entropy-3-nopunct": 7.076815597050856,
        "cond_entropy-3-nopunct": -0.06541313665839688,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.74,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19642857142857142,
            "2": 0.45,
            "3": 0.6846153846153846
        },
        "nist": 4.618245699559715,
        "bleu": 31.0392,
        "rouge1": {
            "precision": 0.77494,
            "recall": 0.66199,
            "fmeasure": 0.7003
        },
        "rouge2": {
            "precision": 0.51891,
            "recall": 0.44327,
            "fmeasure": 0.46955
        },
        "rougeL": {
            "precision": 0.65997,
            "recall": 0.5688,
            "fmeasure": 0.60124
        },
        "rougeLsum": {
            "precision": 0.65997,
            "recall": 0.5688,
            "fmeasure": 0.60124
        },
        "nubia": {
            "semantic_relation": 4.08434,
            "contradiction": 7.16166,
            "irrelevancy": 32.81694,
            "logical_agreement": 60.0214,
            "grammar_ref": 4.67736,
            "grammar_hyp": 4.60348,
            "nubia_score": 0.69694
        },
        "meteor": 0.31283590820410107,
        "bleurt": 0.12404,
        "bertscore": {
            "precision": 0.92798,
            "recall": 0.91586,
            "f1": 0.92126
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_34": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 7,
        "total_length": 115,
        "mean_pred_length": 16.428571428571427,
        "std_pred_length": 4.370588154508101,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 25,
        "distinct-1": 0.7217391304347827,
        "vocab_size-1": 83,
        "unique-1": 68,
        "entropy-1": 6.1255423333837635,
        "distinct-2": 0.9722222222222222,
        "vocab_size-2": 105,
        "unique-2": 102,
        "entropy-2": 6.699331946607902,
        "cond_entropy-2": 0.47684386339635515,
        "distinct-3": 0.9900990099009901,
        "vocab_size-3": 100,
        "unique-3": 99,
        "entropy-3": 6.638409502553759,
        "cond_entropy-3": -0.05707205901563419,
        "total_length-nopunct": 101,
        "mean_pred_length-nopunct": 14.428571428571429,
        "std_pred_length-nopunct": 4.337778985911136,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7722772277227723,
        "vocab_size-1-nopunct": 78,
        "unique-1-nopunct": 66,
        "entropy-1-nopunct": 6.086187348981315,
        "distinct-2-nopunct": 0.9787234042553191,
        "vocab_size-2-nopunct": 92,
        "unique-2-nopunct": 90,
        "entropy-2-nopunct": 6.512035660188261,
        "cond_entropy-2-nopunct": 0.46844585308347403,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 87,
        "unique-3-nopunct": 87,
        "entropy-3-nopunct": 6.442943495848723,
        "cond_entropy-3-nopunct": -0.06566834433465614,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2413793103448276,
            "2": 0.6956521739130435,
            "3": 0.45614035087719296
        },
        "nist": 3.549107082888948,
        "bleu": 17.87181,
        "rouge1": {
            "precision": 0.54846,
            "recall": 0.59509,
            "fmeasure": 0.56007
        },
        "rouge2": {
            "precision": 0.2637,
            "recall": 0.30513,
            "fmeasure": 0.27582
        },
        "rougeL": {
            "precision": 0.45462,
            "recall": 0.50174,
            "fmeasure": 0.46742
        },
        "rougeLsum": {
            "precision": 0.45462,
            "recall": 0.50174,
            "fmeasure": 0.46742
        },
        "nubia": {
            "semantic_relation": 3.89461,
            "contradiction": 1.5491,
            "irrelevancy": 51.28986,
            "logical_agreement": 47.16104,
            "grammar_ref": 4.83605,
            "grammar_hyp": 4.48979,
            "nubia_score": 0.67988
        },
        "meteor": 0.2843948561960924,
        "bleurt": -0.01258,
        "bertscore": {
            "precision": 0.88522,
            "recall": 0.91396,
            "f1": 0.89862
        }
    },
    "xsum_challenge_test_backtranslation": {
        "predictions_file": "ByT5-base (Baseline)/xsum_challenge_test_backtranslation",
        "N": 500,
        "total_length": 10817,
        "mean_pred_length": 21.634,
        "std_pred_length": 3.481959792990149,
        "median_pred_length": 22.0,
        "min_pred_length": 4,
        "max_pred_length": 29,
        "distinct-1": 0.2733659979661644,
        "vocab_size-1": 2957,
        "unique-1": 1880,
        "entropy-1": 9.127863331388955,
        "distinct-2": 0.731608025588834,
        "vocab_size-2": 7548,
        "unique-2": 6556,
        "entropy-2": 12.384036529336203,
        "cond_entropy-2": 3.2118433987382136,
        "distinct-3": 0.9276764795762453,
        "vocab_size-3": 9107,
        "unique-3": 8715,
        "entropy-3": 13.06607414542808,
        "cond_entropy-3": 0.7080931736803032,
        "total_length-nopunct": 10306,
        "mean_pred_length-nopunct": 20.612,
        "std_pred_length-nopunct": 3.5779122403994204,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.2859499320784009,
        "vocab_size-1-nopunct": 2947,
        "unique-1-nopunct": 1879,
        "entropy-1-nopunct": 9.206412381796742,
        "distinct-2-nopunct": 0.7369977564756272,
        "vocab_size-2-nopunct": 7227,
        "unique-2-nopunct": 6309,
        "entropy-2-nopunct": 12.3245052801522,
        "cond_entropy-2-nopunct": 3.2312496589057966,
        "distinct-3-nopunct": 0.932194283258113,
        "vocab_size-3-nopunct": 8675,
        "unique-3-nopunct": 8316,
        "entropy-3-nopunct": 13.009762751325567,
        "cond_entropy-3-nopunct": 0.7117303491221987,
        "msttr-100": 0.74315,
        "msttr-100_nopunct": 0.75165,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_backtranslation.json",
        "local_recall": {
            "1": 0.30031335287577077
        },
        "nist": 2.8607259359504025,
        "bleu": 6.09267,
        "rouge1": {
            "precision": 0.33829,
            "recall": 0.33182,
            "fmeasure": 0.32899
        },
        "rouge2": {
            "precision": 0.10687,
            "recall": 0.10436,
            "fmeasure": 0.1034
        },
        "rougeL": {
            "precision": 0.25516,
            "recall": 0.25071,
            "fmeasure": 0.24826
        },
        "rougeLsum": {
            "precision": 0.25516,
            "recall": 0.25071,
            "fmeasure": 0.24826
        },
        "nubia": {
            "semantic_relation": 2.29446,
            "contradiction": 29.89927,
            "irrelevancy": 62.11991,
            "logical_agreement": 7.98082,
            "grammar_ref": 3.78538,
            "grammar_hyp": 4.30439,
            "nubia_score": 0.2673
        },
        "meteor": 0.13577350516203407,
        "bleurt": -0.58885,
        "bertscore": {
            "precision": 0.80443,
            "recall": 0.8006,
            "f1": 0.80224
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 214,
        "total_length": 2688,
        "mean_pred_length": 12.560747663551401,
        "std_pred_length": 2.50113084738995,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 19,
        "distinct-1": 0.38950892857142855,
        "vocab_size-1": 1047,
        "unique-1": 682,
        "entropy-1": 8.598058316026234,
        "distinct-2": 0.719482619240097,
        "vocab_size-2": 1780,
        "unique-2": 1398,
        "entropy-2": 10.519004957467018,
        "cond_entropy-2": 2.0432449629917993,
        "distinct-3": 0.8721238938053097,
        "vocab_size-3": 1971,
        "unique-3": 1745,
        "entropy-3": 10.86074459071768,
        "cond_entropy-3": 0.39508257187858914,
        "total_length-nopunct": 2304,
        "mean_pred_length-nopunct": 10.766355140186915,
        "std_pred_length-nopunct": 2.0715222595971032,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.4509548611111111,
        "vocab_size-1-nopunct": 1039,
        "unique-1-nopunct": 680,
        "entropy-1-nopunct": 9.03098412437082,
        "distinct-2-nopunct": 0.7688995215311005,
        "vocab_size-2-nopunct": 1607,
        "unique-2-nopunct": 1324,
        "entropy-2-nopunct": 10.437422589793742,
        "cond_entropy-2-nopunct": 1.5306973202948015,
        "distinct-3-nopunct": 0.8923240938166311,
        "vocab_size-3-nopunct": 1674,
        "unique-3-nopunct": 1519,
        "entropy-3-nopunct": 10.635005546709776,
        "cond_entropy-3-nopunct": 0.2521737307732368,
        "msttr-100": 0.78346,
        "msttr-100_nopunct": 0.84739,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.16586627262652381,
            "2": 0.3995451099317665,
            "3": 0.5662544169611308,
            "4": 0.45454545454545453
        },
        "nist": 3.043541072618895,
        "bleu": 26.51435,
        "rouge1": {
            "precision": 0.29712,
            "recall": 0.23788,
            "fmeasure": 0.25517
        },
        "rouge2": {
            "precision": 0.12189,
            "recall": 0.08458,
            "fmeasure": 0.09609
        },
        "rougeL": {
            "precision": 0.28933,
            "recall": 0.23247,
            "fmeasure": 0.249
        },
        "rougeLsum": {
            "precision": 0.28933,
            "recall": 0.23247,
            "fmeasure": 0.249
        },
        "nubia": {
            "semantic_relation": 3.48395,
            "contradiction": 21.91657,
            "irrelevancy": 23.08743,
            "logical_agreement": 54.99599,
            "grammar_ref": 2.61878,
            "grammar_hyp": 2.68952,
            "nubia_score": 0.67711
        },
        "meteor": 0.4260942660310865,
        "bleurt": -0.01208,
        "bertscore": {
            "precision": 0.94751,
            "recall": 0.90964,
            "f1": 0.92748
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_82": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.1625371587496606,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.10689059560851855,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.75,
            "2": 0.75,
            "3": 0.5
        },
        "nist": 4.667215901249649,
        "bleu": 44.81502,
        "rouge1": {
            "precision": 0.77083,
            "recall": 0.64286,
            "fmeasure": 0.6961
        },
        "rouge2": {
            "precision": 0.57778,
            "recall": 0.46923,
            "fmeasure": 0.51429
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.52381,
            "fmeasure": 0.56577
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.52381,
            "fmeasure": 0.56577
        },
        "nubia": {
            "semantic_relation": 3.5979,
            "contradiction": 0.1839,
            "irrelevancy": 67.02161,
            "logical_agreement": 32.79449,
            "grammar_ref": 5.89248,
            "grammar_hyp": 4.91769,
            "nubia_score": 0.59206
        },
        "meteor": 0.34186750544575256,
        "bleurt": 0.07627,
        "bertscore": {
            "precision": 0.96748,
            "recall": 0.93074,
            "f1": 0.94876
        }
    },
    "xsum_challenge_test_bfp_02": {
        "predictions_file": "ByT5-base (Baseline)/xsum_challenge_test_bfp_02",
        "N": 500,
        "total_length": 10735,
        "mean_pred_length": 21.47,
        "std_pred_length": 3.379511799062107,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.28113646949231486,
        "vocab_size-1": 3018,
        "unique-1": 2029,
        "entropy-1": 9.141059961571969,
        "distinct-2": 0.7283829995114802,
        "vocab_size-2": 7455,
        "unique-2": 6457,
        "entropy-2": 12.360448698517743,
        "cond_entropy-2": 3.143508781201773,
        "distinct-3": 0.9227529532614278,
        "vocab_size-3": 8983,
        "unique-3": 8526,
        "entropy-3": 13.047157034910674,
        "cond_entropy-3": 0.7013847724198803,
        "total_length-nopunct": 10200,
        "mean_pred_length-nopunct": 20.4,
        "std_pred_length-nopunct": 3.5355339059327378,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.295,
        "vocab_size-1-nopunct": 3009,
        "unique-1-nopunct": 2027,
        "entropy-1-nopunct": 9.238385994360693,
        "distinct-2-nopunct": 0.7370103092783505,
        "vocab_size-2-nopunct": 7149,
        "unique-2-nopunct": 6224,
        "entropy-2-nopunct": 12.314074463178153,
        "cond_entropy-2-nopunct": 3.1880194759648712,
        "distinct-3-nopunct": 0.9281521739130435,
        "vocab_size-3-nopunct": 8539,
        "unique-3-nopunct": 8122,
        "entropy-3-nopunct": 12.987877550227038,
        "cond_entropy-3-nopunct": 0.6934473270665132,
        "msttr-100": 0.74813,
        "msttr-100_nopunct": 0.75363,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_02.json",
        "local_recall": {
            "1": 0.33102218700475433
        },
        "nist": 3.272581768141724,
        "bleu": 7.58787,
        "rouge1": {
            "precision": 0.37513,
            "recall": 0.36238,
            "fmeasure": 0.36328
        },
        "rouge2": {
            "precision": 0.12641,
            "recall": 0.12309,
            "fmeasure": 0.12272
        },
        "rougeL": {
            "precision": 0.28917,
            "recall": 0.28113,
            "fmeasure": 0.28087
        },
        "rougeLsum": {
            "precision": 0.28917,
            "recall": 0.28113,
            "fmeasure": 0.28087
        },
        "nubia": {
            "semantic_relation": 2.61493,
            "contradiction": 25.72758,
            "irrelevancy": 62.54999,
            "logical_agreement": 11.72243,
            "grammar_ref": 3.74155,
            "grammar_hyp": 4.35413,
            "nubia_score": 0.31493
        },
        "meteor": 0.15307369134317927,
        "bleurt": -0.55865,
        "bertscore": {
            "precision": 0.81536,
            "recall": 0.8136,
            "f1": 0.81422
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_65": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 62,
        "total_length": 1055,
        "mean_pred_length": 17.016129032258064,
        "std_pred_length": 6.176155854950634,
        "median_pred_length": 15.5,
        "min_pred_length": 6,
        "max_pred_length": 34,
        "distinct-1": 0.46824644549763034,
        "vocab_size-1": 494,
        "unique-1": 377,
        "entropy-1": 7.824205194375104,
        "distinct-2": 0.8338368580060423,
        "vocab_size-2": 828,
        "unique-2": 742,
        "entropy-2": 9.520858586655129,
        "cond_entropy-2": 1.5133776851169076,
        "distinct-3": 0.9334049409237379,
        "vocab_size-3": 869,
        "unique-3": 830,
        "entropy-3": 9.704963901576448,
        "cond_entropy-3": 0.18995632124772358,
        "total_length-nopunct": 903,
        "mean_pred_length-nopunct": 14.564516129032258,
        "std_pred_length-nopunct": 5.043747223661339,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5370985603543743,
        "vocab_size-1-nopunct": 485,
        "unique-1-nopunct": 374,
        "entropy-1-nopunct": 8.094453584212458,
        "distinct-2-nopunct": 0.8537455410225921,
        "vocab_size-2-nopunct": 718,
        "unique-2-nopunct": 658,
        "entropy-2-nopunct": 9.322123159560475,
        "cond_entropy-2-nopunct": 1.3057304935218579,
        "distinct-3-nopunct": 0.9460847240051348,
        "vocab_size-3-nopunct": 737,
        "unique-3-nopunct": 710,
        "entropy-3-nopunct": 9.4799667613083,
        "cond_entropy-3-nopunct": 0.15782937256934992,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.77333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1569767441860465,
            "2": 0.4463276836158192,
            "3": 0.8104956268221575
        },
        "nist": 7.495427007332176,
        "bleu": 51.13872,
        "rouge1": {
            "precision": 0.76858,
            "recall": 0.7543,
            "fmeasure": 0.75358
        },
        "rouge2": {
            "precision": 0.56103,
            "recall": 0.55382,
            "fmeasure": 0.552
        },
        "rougeL": {
            "precision": 0.65693,
            "recall": 0.65194,
            "fmeasure": 0.64678
        },
        "rougeLsum": {
            "precision": 0.65693,
            "recall": 0.65194,
            "fmeasure": 0.64678
        },
        "nubia": {
            "semantic_relation": 4.25001,
            "contradiction": 6.53615,
            "irrelevancy": 29.6674,
            "logical_agreement": 63.79646,
            "grammar_ref": 4.56742,
            "grammar_hyp": 4.49558,
            "nubia_score": 0.75303
        },
        "meteor": 0.4027158359466755,
        "bleurt": 0.26189,
        "bertscore": {
            "precision": 0.93063,
            "recall": 0.92783,
            "f1": 0.92641
        }
    },
    "xsum_challenge_test_bfp_05": {
        "predictions_file": "ByT5-base (Baseline)/xsum_challenge_test_bfp_05",
        "N": 500,
        "total_length": 10821,
        "mean_pred_length": 21.642,
        "std_pred_length": 3.377844875064573,
        "median_pred_length": 22.0,
        "min_pred_length": 4,
        "max_pred_length": 29,
        "distinct-1": 0.2921171795582663,
        "vocab_size-1": 3161,
        "unique-1": 2173,
        "entropy-1": 9.192907795464205,
        "distinct-2": 0.7400445693246779,
        "vocab_size-2": 7638,
        "unique-2": 6693,
        "entropy-2": 12.395172757778429,
        "cond_entropy-2": 3.1209592596662015,
        "distinct-3": 0.9289278077588841,
        "vocab_size-3": 9123,
        "unique-3": 8713,
        "entropy-3": 13.076956817200326,
        "cond_entropy-3": 0.7023468125095496,
        "total_length-nopunct": 10299,
        "mean_pred_length-nopunct": 20.598,
        "std_pred_length-nopunct": 3.518578690323694,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.30595203417807554,
        "vocab_size-1-nopunct": 3151,
        "unique-1-nopunct": 2173,
        "entropy-1-nopunct": 9.280594439309066,
        "distinct-2-nopunct": 0.743647310950097,
        "vocab_size-2-nopunct": 7287,
        "unique-2-nopunct": 6404,
        "entropy-2-nopunct": 12.328126094682329,
        "cond_entropy-2-nopunct": 3.163395114009722,
        "distinct-3-nopunct": 0.9322507796537262,
        "vocab_size-3-nopunct": 8669,
        "unique-3-nopunct": 8289,
        "entropy-3-nopunct": 13.011658686774485,
        "cond_entropy-3-nopunct": 0.7071694357125095,
        "msttr-100": 0.74426,
        "msttr-100_nopunct": 0.75373,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_05.json",
        "local_recall": {
            "1": 0.31272401433691754
        },
        "nist": 3.0587341213572716,
        "bleu": 7.13056,
        "rouge1": {
            "precision": 0.3489,
            "recall": 0.34036,
            "fmeasure": 0.33904
        },
        "rouge2": {
            "precision": 0.11513,
            "recall": 0.11203,
            "fmeasure": 0.11158
        },
        "rougeL": {
            "precision": 0.27173,
            "recall": 0.26497,
            "fmeasure": 0.26388
        },
        "rougeLsum": {
            "precision": 0.27173,
            "recall": 0.26497,
            "fmeasure": 0.26388
        },
        "nubia": {
            "semantic_relation": 2.43247,
            "contradiction": 32.18757,
            "irrelevancy": 58.08522,
            "logical_agreement": 9.7272,
            "grammar_ref": 3.79385,
            "grammar_hyp": 4.61103,
            "nubia_score": 0.26827
        },
        "meteor": 0.14294214589387147,
        "bleurt": -0.65512,
        "bertscore": {
            "precision": 0.80803,
            "recall": 0.80751,
            "f1": 0.80749
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_35": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 103,
        "total_length": 1850,
        "mean_pred_length": 17.961165048543688,
        "std_pred_length": 5.639531637402509,
        "median_pred_length": 18.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.43729729729729727,
        "vocab_size-1": 809,
        "unique-1": 632,
        "entropy-1": 8.12276562505216,
        "distinct-2": 0.8168288494562106,
        "vocab_size-2": 1427,
        "unique-2": 1305,
        "entropy-2": 10.196602307960516,
        "cond_entropy-2": 1.875965040708938,
        "distinct-3": 0.9124087591240876,
        "vocab_size-3": 1500,
        "unique-3": 1436,
        "entropy-3": 10.431501955303887,
        "cond_entropy-3": 0.22981716546717856,
        "total_length-nopunct": 1619,
        "mean_pred_length-nopunct": 15.718446601941748,
        "std_pred_length-nopunct": 5.492125829826169,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4947498455836936,
        "vocab_size-1-nopunct": 801,
        "unique-1-nopunct": 630,
        "entropy-1-nopunct": 8.361861133796623,
        "distinct-2-nopunct": 0.8225593667546174,
        "vocab_size-2-nopunct": 1247,
        "unique-2-nopunct": 1152,
        "entropy-2-nopunct": 9.994331999252921,
        "cond_entropy-2-nopunct": 1.734672192432994,
        "distinct-3-nopunct": 0.9087048832271762,
        "vocab_size-3-nopunct": 1284,
        "unique-3-nopunct": 1233,
        "entropy-3-nopunct": 10.194585466503508,
        "cond_entropy-3-nopunct": 0.2361469173617236,
        "msttr-100": 0.70722,
        "msttr-100_nopunct": 0.75062,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21341463414634146,
            "2": 0.531986531986532,
            "3": 0.8247330960854092
        },
        "nist": 7.868928694295414,
        "bleu": 52.22933,
        "rouge1": {
            "precision": 0.76135,
            "recall": 0.77225,
            "fmeasure": 0.75679
        },
        "rouge2": {
            "precision": 0.54467,
            "recall": 0.55419,
            "fmeasure": 0.54314
        },
        "rougeL": {
            "precision": 0.66317,
            "recall": 0.67863,
            "fmeasure": 0.66223
        },
        "rougeLsum": {
            "precision": 0.66317,
            "recall": 0.67863,
            "fmeasure": 0.66223
        },
        "nubia": {
            "semantic_relation": 4.25497,
            "contradiction": 8.96633,
            "irrelevancy": 34.75725,
            "logical_agreement": 56.27641,
            "grammar_ref": 4.60982,
            "grammar_hyp": 4.49556,
            "nubia_score": 0.75502
        },
        "meteor": 0.4225644013281695,
        "bleurt": 0.30515,
        "bertscore": {
            "precision": 0.93137,
            "recall": 0.93525,
            "f1": 0.9324
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_36": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 131,
        "total_length": 2135,
        "mean_pred_length": 16.297709923664122,
        "std_pred_length": 6.011051725542996,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 30,
        "distinct-1": 0.4674473067915691,
        "vocab_size-1": 998,
        "unique-1": 800,
        "entropy-1": 8.41234079506773,
        "distinct-2": 0.8717564870259481,
        "vocab_size-2": 1747,
        "unique-2": 1623,
        "entropy-2": 10.593820684134535,
        "cond_entropy-2": 1.938707553639787,
        "distinct-3": 0.9690336358782702,
        "vocab_size-3": 1815,
        "unique-3": 1777,
        "entropy-3": 10.799638439450032,
        "cond_entropy-3": 0.2106684175026686,
        "total_length-nopunct": 1860,
        "mean_pred_length-nopunct": 14.198473282442748,
        "std_pred_length-nopunct": 5.4652543676137615,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5306451612903226,
        "vocab_size-1-nopunct": 987,
        "unique-1-nopunct": 798,
        "entropy-1-nopunct": 8.706375917765719,
        "distinct-2-nopunct": 0.8866396761133604,
        "vocab_size-2-nopunct": 1533,
        "unique-2-nopunct": 1442,
        "entropy-2-nopunct": 10.410793522869428,
        "cond_entropy-2-nopunct": 1.8072562891091768,
        "distinct-3-nopunct": 0.9793491864831039,
        "vocab_size-3-nopunct": 1565,
        "unique-3-nopunct": 1543,
        "entropy-3-nopunct": 10.59494017070339,
        "cond_entropy-3-nopunct": 0.2035557377148086,
        "msttr-100": 0.74429,
        "msttr-100_nopunct": 0.79056,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23342175066312998,
            "2": 0.47836538461538464,
            "3": 0.7237026647966339
        },
        "nist": 7.482468489649266,
        "bleu": 41.83406,
        "rouge1": {
            "precision": 0.75958,
            "recall": 0.70259,
            "fmeasure": 0.7176
        },
        "rouge2": {
            "precision": 0.51204,
            "recall": 0.47278,
            "fmeasure": 0.48308
        },
        "rougeL": {
            "precision": 0.65861,
            "recall": 0.60912,
            "fmeasure": 0.62134
        },
        "rougeLsum": {
            "precision": 0.65861,
            "recall": 0.60912,
            "fmeasure": 0.62134
        },
        "nubia": {
            "semantic_relation": 4.14417,
            "contradiction": 10.72622,
            "irrelevancy": 26.71243,
            "logical_agreement": 62.56135,
            "grammar_ref": 4.61481,
            "grammar_hyp": 4.74263,
            "nubia_score": 0.68852
        },
        "meteor": 0.3693550098077485,
        "bleurt": 0.22494,
        "bertscore": {
            "precision": 0.9231,
            "recall": 0.9171,
            "f1": 0.91877
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_183": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.3333333333333333,
            "3": 0.8333333333333334
        },
        "nist": 2.9615503233922893,
        "bleu": 15.6197,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.75,
            "fmeasure": 0.70588
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.34524,
            "fmeasure": 0.33889
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.625,
            "fmeasure": 0.58824
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.625,
            "fmeasure": 0.58824
        },
        "nubia": {
            "semantic_relation": 4.36063,
            "contradiction": 0.18928,
            "irrelevancy": 1.93774,
            "logical_agreement": 97.87298,
            "grammar_ref": 4.0172,
            "grammar_hyp": 3.90331,
            "nubia_score": 0.90233
        },
        "meteor": 0.3848849075287803,
        "bleurt": 0.23697,
        "bertscore": {
            "precision": 0.94088,
            "recall": 0.95363,
            "f1": 0.94721
        }
    },
    "totto_challenge_validation_sample": {
        "predictions_file": "ByT5-base (Baseline)/totto_challenge_validation_sample",
        "N": 500
    },
    "totto_challenge_test_scramble": {
        "predictions_file": "ByT5-base (Baseline)/totto_challenge_test_scramble",
        "N": 378
    },
    "totto_test_contrast_challenge_table_size-table_size_212": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 15,
        "total_length": 258,
        "mean_pred_length": 17.2,
        "std_pred_length": 5.912698199637793,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 30,
        "distinct-1": 0.5581395348837209,
        "vocab_size-1": 144,
        "unique-1": 111,
        "entropy-1": 6.519731648372593,
        "distinct-2": 0.8930041152263375,
        "vocab_size-2": 217,
        "unique-2": 197,
        "entropy-2": 7.690164149660686,
        "cond_entropy-2": 1.0645342205058919,
        "distinct-3": 0.9517543859649122,
        "vocab_size-3": 217,
        "unique-3": 206,
        "entropy-3": 7.736398786094599,
        "cond_entropy-3": 0.061672028140776075,
        "total_length-nopunct": 235,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 5.884065110297661,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.5957446808510638,
        "vocab_size-1-nopunct": 140,
        "unique-1-nopunct": 109,
        "entropy-1-nopunct": 6.545878009189536,
        "distinct-2-nopunct": 0.8863636363636364,
        "vocab_size-2-nopunct": 195,
        "unique-2-nopunct": 176,
        "entropy-2-nopunct": 7.531270849848948,
        "cond_entropy-2-nopunct": 1.0689138477499214,
        "distinct-3-nopunct": 0.9512195121951219,
        "vocab_size-3-nopunct": 195,
        "unique-3-nopunct": 185,
        "entropy-3-nopunct": 7.581919123895676,
        "cond_entropy-3-nopunct": 0.06894745919373228,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.665,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24285714285714285,
            "2": 0.2875,
            "3": 0.7192982456140351
        },
        "nist": 5.383066253992834,
        "bleu": 41.69968,
        "rouge1": {
            "precision": 0.72348,
            "recall": 0.65214,
            "fmeasure": 0.67991
        },
        "rouge2": {
            "precision": 0.46964,
            "recall": 0.4182,
            "fmeasure": 0.43911
        },
        "rougeL": {
            "precision": 0.63606,
            "recall": 0.57517,
            "fmeasure": 0.59939
        },
        "rougeLsum": {
            "precision": 0.63606,
            "recall": 0.57517,
            "fmeasure": 0.59939
        },
        "nubia": {
            "semantic_relation": 4.08215,
            "contradiction": 12.54248,
            "irrelevancy": 32.43665,
            "logical_agreement": 55.02086,
            "grammar_ref": 4.73267,
            "grammar_hyp": 4.84277,
            "nubia_score": 0.68119
        },
        "meteor": 0.35073348629720585,
        "bleurt": 0.18002,
        "bertscore": {
            "precision": 0.9104,
            "recall": 0.90855,
            "f1": 0.90738
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_215": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 6,
        "total_length": 87,
        "mean_pred_length": 14.5,
        "std_pred_length": 4.9916597106239795,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.7586206896551724,
        "vocab_size-1": 66,
        "unique-1": 59,
        "entropy-1": 5.760367886822815,
        "distinct-2": 1.0,
        "vocab_size-2": 81,
        "unique-2": 81,
        "entropy-2": 6.339850002884614,
        "cond_entropy-2": 0.47047768582167937,
        "distinct-3": 1.0,
        "vocab_size-3": 75,
        "unique-3": 75,
        "entropy-3": 6.228818690495891,
        "cond_entropy-3": -0.111031312388744,
        "total_length-nopunct": 78,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 5.066228051190222,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8076923076923077,
        "vocab_size-1-nopunct": 63,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.748552180645238,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 72,
        "unique-2-nopunct": 72,
        "entropy-2-nopunct": 6.1699250014423175,
        "cond_entropy-2-nopunct": 0.4661103239818315,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 66,
        "unique-3-nopunct": 66,
        "entropy-3-nopunct": 6.044394119358462,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.5974025974025974
        },
        "nist": 3.285118358082432,
        "bleu": 29.5739,
        "rouge1": {
            "precision": 0.75788,
            "recall": 0.53214,
            "fmeasure": 0.61806
        },
        "rouge2": {
            "precision": 0.42987,
            "recall": 0.31928,
            "fmeasure": 0.35984
        },
        "rougeL": {
            "precision": 0.6312,
            "recall": 0.49457,
            "fmeasure": 0.54556
        },
        "rougeLsum": {
            "precision": 0.6312,
            "recall": 0.49457,
            "fmeasure": 0.54556
        },
        "nubia": {
            "semantic_relation": 3.83125,
            "contradiction": 5.77166,
            "irrelevancy": 26.54032,
            "logical_agreement": 67.68801,
            "grammar_ref": 4.85958,
            "grammar_hyp": 4.98046,
            "nubia_score": 0.5953
        },
        "meteor": 0.26422073020616543,
        "bleurt": -0.01762,
        "bertscore": {
            "precision": 0.90733,
            "recall": 0.8526,
            "f1": 0.87334
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_102": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 24,
        "total_length": 425,
        "mean_pred_length": 17.708333333333332,
        "std_pred_length": 4.7123876349704314,
        "median_pred_length": 17.5,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.5952941176470589,
        "vocab_size-1": 253,
        "unique-1": 214,
        "entropy-1": 7.1732371025088355,
        "distinct-2": 0.9251870324189526,
        "vocab_size-2": 371,
        "unique-2": 355,
        "entropy-2": 8.450055644669133,
        "cond_entropy-2": 1.1466077675599025,
        "distinct-3": 0.986737400530504,
        "vocab_size-3": 372,
        "unique-3": 367,
        "entropy-3": 8.531895514329664,
        "cond_entropy-3": 0.09440662499961015,
        "total_length-nopunct": 371,
        "mean_pred_length-nopunct": 15.458333333333334,
        "std_pred_length-nopunct": 3.9684082311285582,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6657681940700808,
        "vocab_size-1-nopunct": 247,
        "unique-1-nopunct": 213,
        "entropy-1-nopunct": 7.318449244011959,
        "distinct-2-nopunct": 0.9221902017291066,
        "vocab_size-2-nopunct": 320,
        "unique-2-nopunct": 307,
        "entropy-2-nopunct": 8.227960395817258,
        "cond_entropy-2-nopunct": 0.9672457402236003,
        "distinct-3-nopunct": 0.9876160990712074,
        "vocab_size-3-nopunct": 319,
        "unique-3-nopunct": 315,
        "entropy-3-nopunct": 8.31062255283636,
        "cond_entropy-3-nopunct": 0.09832765225829986,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.40860215053763443,
            "3": 0.823045267489712
        },
        "nist": 6.318596784238443,
        "bleu": 45.16211,
        "rouge1": {
            "precision": 0.728,
            "recall": 0.73961,
            "fmeasure": 0.72365
        },
        "rouge2": {
            "precision": 0.49115,
            "recall": 0.49616,
            "fmeasure": 0.48778
        },
        "rougeL": {
            "precision": 0.61593,
            "recall": 0.61648,
            "fmeasure": 0.60892
        },
        "rougeLsum": {
            "precision": 0.61593,
            "recall": 0.61648,
            "fmeasure": 0.60892
        },
        "nubia": {
            "semantic_relation": 4.13001,
            "contradiction": 6.61944,
            "irrelevancy": 39.0058,
            "logical_agreement": 54.37477,
            "grammar_ref": 4.72162,
            "grammar_hyp": 4.56868,
            "nubia_score": 0.71501
        },
        "meteor": 0.3919551015322908,
        "bleurt": 0.11263,
        "bertscore": {
            "precision": 0.91859,
            "recall": 0.91585,
            "f1": 0.91529
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_153": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 11,
        "total_length": 163,
        "mean_pred_length": 14.818181818181818,
        "std_pred_length": 3.432946834272583,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 25,
        "distinct-1": 0.588957055214724,
        "vocab_size-1": 96,
        "unique-1": 71,
        "entropy-1": 6.11827973622647,
        "distinct-2": 0.8355263157894737,
        "vocab_size-2": 127,
        "unique-2": 108,
        "entropy-2": 6.885956789702427,
        "cond_entropy-2": 0.6063690586933518,
        "distinct-3": 0.8794326241134752,
        "vocab_size-3": 124,
        "unique-3": 110,
        "entropy-3": 6.882355164409483,
        "cond_entropy-3": 0.02463722549537453,
        "total_length-nopunct": 145,
        "mean_pred_length-nopunct": 13.181818181818182,
        "std_pred_length-nopunct": 2.690663379445226,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6344827586206897,
        "vocab_size-1-nopunct": 92,
        "unique-1-nopunct": 71,
        "entropy-1-nopunct": 6.119533525686815,
        "distinct-2-nopunct": 0.8208955223880597,
        "vocab_size-2-nopunct": 110,
        "unique-2-nopunct": 92,
        "entropy-2-nopunct": 6.670420906811106,
        "cond_entropy-2-nopunct": 0.6142769796777818,
        "distinct-3-nopunct": 0.8699186991869918,
        "vocab_size-3-nopunct": 107,
        "unique-3-nopunct": 94,
        "entropy-3-nopunct": 6.663940013416543,
        "cond_entropy-3-nopunct": 0.01601820107205517,
        "msttr-100": 0.59,
        "msttr-100_nopunct": 0.64,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35555555555555557,
            "2": 0.20689655172413793,
            "3": 0.7311827956989247
        },
        "nist": 4.621205053875439,
        "bleu": 31.7871,
        "rouge1": {
            "precision": 0.62295,
            "recall": 0.68756,
            "fmeasure": 0.64794
        },
        "rouge2": {
            "precision": 0.39633,
            "recall": 0.4506,
            "fmeasure": 0.4158
        },
        "rougeL": {
            "precision": 0.5414,
            "recall": 0.61565,
            "fmeasure": 0.56934
        },
        "rougeLsum": {
            "precision": 0.5414,
            "recall": 0.61565,
            "fmeasure": 0.56934
        },
        "nubia": {
            "semantic_relation": 4.1554,
            "contradiction": 12.61831,
            "irrelevancy": 59.29144,
            "logical_agreement": 28.09025,
            "grammar_ref": 5.00152,
            "grammar_hyp": 4.79202,
            "nubia_score": 0.70688
        },
        "meteor": 0.37087380824195965,
        "bleurt": 0.24238,
        "bertscore": {
            "precision": 0.90363,
            "recall": 0.92527,
            "f1": 0.91323
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_128": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 20,
        "total_length": 312,
        "mean_pred_length": 15.6,
        "std_pred_length": 4.726520919238589,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.6378205128205128,
        "vocab_size-1": 199,
        "unique-1": 165,
        "entropy-1": 6.992380930007378,
        "distinct-2": 0.952054794520548,
        "vocab_size-2": 278,
        "unique-2": 269,
        "entropy-2": 8.07247982426879,
        "cond_entropy-2": 0.9022417712104012,
        "distinct-3": 0.9852941176470589,
        "vocab_size-3": 268,
        "unique-3": 264,
        "entropy-3": 8.058051076544471,
        "cond_entropy-3": -0.00580045841463943,
        "total_length-nopunct": 272,
        "mean_pred_length-nopunct": 13.6,
        "std_pred_length-nopunct": 4.662617290749907,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7095588235294118,
        "vocab_size-1-nopunct": 193,
        "unique-1-nopunct": 164,
        "entropy-1-nopunct": 7.1124273900953945,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 240,
        "unique-2-nopunct": 233,
        "entropy-2-nopunct": 7.857182056410679,
        "cond_entropy-2-nopunct": 0.8118806445786885,
        "distinct-3-nopunct": 0.9913793103448276,
        "vocab_size-3-nopunct": 230,
        "unique-3-nopunct": 228,
        "entropy-3-nopunct": 7.840739615817207,
        "cond_entropy-3-nopunct": -0.010399521016782456,
        "msttr-100": 0.73667,
        "msttr-100_nopunct": 0.775,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.47540983606557374,
            "3": 0.7382198952879581
        },
        "nist": 5.6103668880719475,
        "bleu": 42.0288,
        "rouge1": {
            "precision": 0.72831,
            "recall": 0.73387,
            "fmeasure": 0.71121
        },
        "rouge2": {
            "precision": 0.48398,
            "recall": 0.47576,
            "fmeasure": 0.46932
        },
        "rougeL": {
            "precision": 0.59865,
            "recall": 0.60628,
            "fmeasure": 0.58724
        },
        "rougeLsum": {
            "precision": 0.59865,
            "recall": 0.60628,
            "fmeasure": 0.58724
        },
        "nubia": {
            "semantic_relation": 4.22258,
            "contradiction": 1.25008,
            "irrelevancy": 31.99174,
            "logical_agreement": 66.75817,
            "grammar_ref": 4.72495,
            "grammar_hyp": 4.77738,
            "nubia_score": 0.7249
        },
        "meteor": 0.38271191370279817,
        "bleurt": 0.22666,
        "bertscore": {
            "precision": 0.91594,
            "recall": 0.92157,
            "f1": 0.91731
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_18": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 123,
        "total_length": 1874,
        "mean_pred_length": 15.235772357723578,
        "std_pred_length": 5.322266924579383,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.4023479188900747,
        "vocab_size-1": 754,
        "unique-1": 621,
        "entropy-1": 7.68599635455991,
        "distinct-2": 0.7355796687607081,
        "vocab_size-2": 1288,
        "unique-2": 1194,
        "entropy-2": 9.71338904054465,
        "cond_entropy-2": 1.7949323232875387,
        "distinct-3": 0.8341523341523341,
        "vocab_size-3": 1358,
        "unique-3": 1314,
        "entropy-3": 10.000612258093689,
        "cond_entropy-3": 0.3278953277308066,
        "total_length-nopunct": 1628,
        "mean_pred_length-nopunct": 13.235772357723578,
        "std_pred_length-nopunct": 4.664484915337895,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.45884520884520885,
        "vocab_size-1-nopunct": 747,
        "unique-1-nopunct": 620,
        "entropy-1-nopunct": 7.942343196805814,
        "distinct-2-nopunct": 0.7428571428571429,
        "vocab_size-2-nopunct": 1118,
        "unique-2-nopunct": 1047,
        "entropy-2-nopunct": 9.505363500326267,
        "cond_entropy-2-nopunct": 1.704808835880139,
        "distinct-3-nopunct": 0.8408104196816208,
        "vocab_size-3-nopunct": 1162,
        "unique-3-nopunct": 1132,
        "entropy-3-nopunct": 9.77777392051637,
        "cond_entropy-3-nopunct": 0.34554929708416077,
        "msttr-100": 0.65278,
        "msttr-100_nopunct": 0.6925,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23674911660777384,
            "2": 0.451505016722408,
            "3": 0.7421093148575828
        },
        "nist": 7.445877858397707,
        "bleu": 50.27057,
        "rouge1": {
            "precision": 0.77429,
            "recall": 0.73795,
            "fmeasure": 0.74503
        },
        "rouge2": {
            "precision": 0.56394,
            "recall": 0.53588,
            "fmeasure": 0.54196
        },
        "rougeL": {
            "precision": 0.67839,
            "recall": 0.64338,
            "fmeasure": 0.65095
        },
        "rougeLsum": {
            "precision": 0.67839,
            "recall": 0.64338,
            "fmeasure": 0.65095
        },
        "nubia": {
            "semantic_relation": 4.27883,
            "contradiction": 9.58126,
            "irrelevancy": 22.80786,
            "logical_agreement": 67.61088,
            "grammar_ref": 4.71387,
            "grammar_hyp": 4.69355,
            "nubia_score": 0.76128
        },
        "meteor": 0.3937621565621431,
        "bleurt": 0.35883,
        "bertscore": {
            "precision": 0.93093,
            "recall": 0.92509,
            "f1": 0.92652
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_130": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 31,
        "total_length": 602,
        "mean_pred_length": 19.419354838709676,
        "std_pred_length": 6.089516075631939,
        "median_pred_length": 20.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.5598006644518272,
        "vocab_size-1": 337,
        "unique-1": 271,
        "entropy-1": 7.574184696197659,
        "distinct-2": 0.8984238178633975,
        "vocab_size-2": 513,
        "unique-2": 474,
        "entropy-2": 8.920642004546606,
        "cond_entropy-2": 1.2580643729117047,
        "distinct-3": 0.9703703703703703,
        "vocab_size-3": 524,
        "unique-3": 510,
        "entropy-3": 9.014760458153866,
        "cond_entropy-3": 0.1040033663023306,
        "total_length-nopunct": 519,
        "mean_pred_length-nopunct": 16.741935483870968,
        "std_pred_length-nopunct": 5.351923030544248,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6377649325626205,
        "vocab_size-1-nopunct": 331,
        "unique-1-nopunct": 270,
        "entropy-1-nopunct": 7.7682338648734754,
        "distinct-2-nopunct": 0.9159836065573771,
        "vocab_size-2-nopunct": 447,
        "unique-2-nopunct": 420,
        "entropy-2-nopunct": 8.732184360125324,
        "cond_entropy-2-nopunct": 1.0253945687065493,
        "distinct-3-nopunct": 0.975929978118162,
        "vocab_size-3-nopunct": 446,
        "unique-3-nopunct": 436,
        "entropy-3-nopunct": 8.786258478685756,
        "cond_entropy-3-nopunct": 0.06754270127509074,
        "msttr-100": 0.74167,
        "msttr-100_nopunct": 0.79,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21495327102803738,
            "2": 0.379746835443038,
            "3": 0.7715617715617715
        },
        "nist": 6.844785753952808,
        "bleu": 47.74968,
        "rouge1": {
            "precision": 0.79673,
            "recall": 0.74824,
            "fmeasure": 0.76209
        },
        "rouge2": {
            "precision": 0.57719,
            "recall": 0.53808,
            "fmeasure": 0.5501
        },
        "rougeL": {
            "precision": 0.67262,
            "recall": 0.63024,
            "fmeasure": 0.64254
        },
        "rougeLsum": {
            "precision": 0.67262,
            "recall": 0.63024,
            "fmeasure": 0.64254
        },
        "nubia": {
            "semantic_relation": 4.17459,
            "contradiction": 3.64817,
            "irrelevancy": 20.52093,
            "logical_agreement": 75.83089,
            "grammar_ref": 4.57329,
            "grammar_hyp": 4.76668,
            "nubia_score": 0.71729
        },
        "meteor": 0.4025016766404045,
        "bleurt": 0.26143,
        "bertscore": {
            "precision": 0.93643,
            "recall": 0.93147,
            "f1": 0.933
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_132": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 43,
        "total_length": 701,
        "mean_pred_length": 16.302325581395348,
        "std_pred_length": 4.401558306089303,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.5121255349500713,
        "vocab_size-1": 359,
        "unique-1": 287,
        "entropy-1": 7.3643090997410745,
        "distinct-2": 0.8860182370820668,
        "vocab_size-2": 583,
        "unique-2": 537,
        "entropy-2": 9.057413802168668,
        "cond_entropy-2": 1.5018294247011734,
        "distinct-3": 0.9723577235772358,
        "vocab_size-3": 598,
        "unique-3": 582,
        "entropy-3": 9.207930588027981,
        "cond_entropy-3": 0.1620530277737588,
        "total_length-nopunct": 621,
        "mean_pred_length-nopunct": 14.44186046511628,
        "std_pred_length-nopunct": 4.400329404061808,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5700483091787439,
        "vocab_size-1-nopunct": 354,
        "unique-1-nopunct": 286,
        "entropy-1-nopunct": 7.513416385637039,
        "distinct-2-nopunct": 0.8875432525951558,
        "vocab_size-2-nopunct": 513,
        "unique-2-nopunct": 477,
        "entropy-2-nopunct": 8.862848310025253,
        "cond_entropy-2-nopunct": 1.4497288268404946,
        "distinct-3-nopunct": 0.9757009345794393,
        "vocab_size-3-nopunct": 522,
        "unique-3-nopunct": 510,
        "entropy-3-nopunct": 9.01338594577045,
        "cond_entropy-3-nopunct": 0.16891962549428394,
        "msttr-100": 0.69286,
        "msttr-100_nopunct": 0.73333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2558139534883721,
            "2": 0.6120689655172413,
            "3": 0.8165938864628821
        },
        "nist": 7.6045409501706045,
        "bleu": 51.96699,
        "rouge1": {
            "precision": 0.82219,
            "recall": 0.77922,
            "fmeasure": 0.78948
        },
        "rouge2": {
            "precision": 0.59867,
            "recall": 0.57408,
            "fmeasure": 0.57908
        },
        "rougeL": {
            "precision": 0.70818,
            "recall": 0.66937,
            "fmeasure": 0.681
        },
        "rougeLsum": {
            "precision": 0.70818,
            "recall": 0.66937,
            "fmeasure": 0.681
        },
        "nubia": {
            "semantic_relation": 4.517,
            "contradiction": 1.78647,
            "irrelevancy": 16.67077,
            "logical_agreement": 81.54276,
            "grammar_ref": 4.66047,
            "grammar_hyp": 4.67364,
            "nubia_score": 0.82072
        },
        "meteor": 0.42910146580808367,
        "bleurt": 0.3931,
        "bertscore": {
            "precision": 0.94826,
            "recall": 0.94065,
            "f1": 0.94332
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "ByT5-base (Baseline)/e2e_nlg_test",
        "N": 774,
        "total_length": 19530,
        "mean_pred_length": 25.232558139534884,
        "std_pred_length": 1.82508345881297,
        "median_pred_length": 25.0,
        "min_pred_length": 20,
        "max_pred_length": 30,
        "distinct-1": 0.0134152585765489,
        "vocab_size-1": 262,
        "unique-1": 26,
        "entropy-1": 6.097745987249566,
        "distinct-2": 0.05033056088718277,
        "vocab_size-2": 944,
        "unique-2": 159,
        "entropy-2": 8.128465444412495,
        "cond_entropy-2": 2.138852742915352,
        "distinct-3": 0.10126793460126793,
        "vocab_size-3": 1821,
        "unique-3": 362,
        "entropy-3": 9.422741446133287,
        "cond_entropy-3": 1.390816022039544,
        "total_length-nopunct": 18407,
        "mean_pred_length-nopunct": 23.781653746770026,
        "std_pred_length-nopunct": 1.5978423287354988,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.014125061118052914,
        "vocab_size-1-nopunct": 260,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 6.081789550543979,
        "distinct-2-nopunct": 0.05319571258435887,
        "vocab_size-2-nopunct": 938,
        "unique-2-nopunct": 160,
        "entropy-2-nopunct": 8.140282618488396,
        "cond_entropy-2-nopunct": 2.1732909502459283,
        "distinct-3-nopunct": 0.10492911797852779,
        "vocab_size-3-nopunct": 1769,
        "unique-3-nopunct": 356,
        "entropy-3-nopunct": 9.434532631876554,
        "cond_entropy-3-nopunct": 1.4013162510091044,
        "msttr-100": 0.31903,
        "msttr-100_nopunct": 0.30859,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.5718477805207508
        },
        "nist": 3.5794377669743085,
        "bleu": 22.43546,
        "rouge1": {
            "precision": 0.77132,
            "recall": 0.58126,
            "fmeasure": 0.65887
        },
        "rouge2": {
            "precision": 0.44733,
            "recall": 0.33387,
            "fmeasure": 0.37985
        },
        "rougeL": {
            "precision": 0.53055,
            "recall": 0.40068,
            "fmeasure": 0.4537
        },
        "rougeLsum": {
            "precision": 0.53055,
            "recall": 0.40068,
            "fmeasure": 0.4537
        },
        "nubia": {
            "semantic_relation": 3.66121,
            "contradiction": 3.62115,
            "irrelevancy": 11.60996,
            "logical_agreement": 84.76889,
            "grammar_ref": 4.52626,
            "grammar_hyp": 4.66927,
            "nubia_score": 0.55166
        },
        "meteor": 0.29099286078386366,
        "bleurt": -0.14214,
        "bertscore": {
            "precision": 0.91017,
            "recall": 0.86794,
            "f1": 0.88838
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_216": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 35,
        "total_length": 586,
        "mean_pred_length": 16.742857142857144,
        "std_pred_length": 5.958632907173337,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.5597269624573379,
        "vocab_size-1": 328,
        "unique-1": 264,
        "entropy-1": 7.441870010513961,
        "distinct-2": 0.911070780399274,
        "vocab_size-2": 502,
        "unique-2": 471,
        "entropy-2": 8.869828862859915,
        "cond_entropy-2": 1.2847669204574894,
        "distinct-3": 0.9689922480620154,
        "vocab_size-3": 500,
        "unique-3": 484,
        "entropy-3": 8.949211751547246,
        "cond_entropy-3": 0.08764410496618835,
        "total_length-nopunct": 519,
        "mean_pred_length-nopunct": 14.82857142857143,
        "std_pred_length-nopunct": 5.37978074054385,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6184971098265896,
        "vocab_size-1-nopunct": 321,
        "unique-1-nopunct": 262,
        "entropy-1-nopunct": 7.572056880536204,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 440,
        "unique-2-nopunct": 414,
        "entropy-2-nopunct": 8.670764301764581,
        "cond_entropy-2-nopunct": 1.1719199542515613,
        "distinct-3-nopunct": 0.9688195991091314,
        "vocab_size-3-nopunct": 435,
        "unique-3-nopunct": 421,
        "entropy-3-nopunct": 8.748210832959437,
        "cond_entropy-3-nopunct": 0.09233174888497435,
        "msttr-100": 0.722,
        "msttr-100_nopunct": 0.772,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19072164948453607,
            "2": 0.44144144144144143,
            "3": 0.7318435754189944
        },
        "nist": 6.4016798076742525,
        "bleu": 40.39525,
        "rouge1": {
            "precision": 0.72675,
            "recall": 0.70197,
            "fmeasure": 0.70306
        },
        "rouge2": {
            "precision": 0.49052,
            "recall": 0.46729,
            "fmeasure": 0.47285
        },
        "rougeL": {
            "precision": 0.62838,
            "recall": 0.6131,
            "fmeasure": 0.61182
        },
        "rougeLsum": {
            "precision": 0.62838,
            "recall": 0.6131,
            "fmeasure": 0.61182
        },
        "nubia": {
            "semantic_relation": 4.03857,
            "contradiction": 10.12218,
            "irrelevancy": 35.61271,
            "logical_agreement": 54.26511,
            "grammar_ref": 4.80535,
            "grammar_hyp": 4.84146,
            "nubia_score": 0.6621
        },
        "meteor": 0.3512673712736548,
        "bleurt": 0.1907,
        "bertscore": {
            "precision": 0.92497,
            "recall": 0.91934,
            "f1": 0.92091
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_217": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 63,
        "mean_pred_length": 21.0,
        "std_pred_length": 2.449489742783178,
        "median_pred_length": 21.0,
        "min_pred_length": 18,
        "max_pred_length": 24,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 49,
        "unique-1": 40,
        "entropy-1": 5.443793566762825,
        "distinct-2": 0.95,
        "vocab_size-2": 57,
        "unique-2": 54,
        "entropy-2": 5.806890595608517,
        "cond_entropy-2": 0.3564380133492155,
        "distinct-3": 1.0,
        "vocab_size-3": 57,
        "unique-3": 57,
        "entropy-3": 5.832890014164737,
        "cond_entropy-3": 0.03126257645096006,
        "total_length-nopunct": 57,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 3.559026084010437,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8245614035087719,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.418685795314969,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.643776391052356,
        "cond_entropy-2-nopunct": 0.248101941229038,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 51,
        "unique-3-nopunct": 51,
        "entropy-3-nopunct": 5.6724253419715005,
        "cond_entropy-3-nopunct": 0.03518489863155645,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.6,
            "3": 0.6666666666666666
        },
        "nist": 2.9643927584689385,
        "bleu": 12.36523,
        "rouge1": {
            "precision": 0.55592,
            "recall": 0.64897,
            "fmeasure": 0.59061
        },
        "rouge2": {
            "precision": 0.27887,
            "recall": 0.31771,
            "fmeasure": 0.2931
        },
        "rougeL": {
            "precision": 0.44224,
            "recall": 0.51957,
            "fmeasure": 0.47099
        },
        "rougeLsum": {
            "precision": 0.44224,
            "recall": 0.51957,
            "fmeasure": 0.47099
        },
        "nubia": {
            "semantic_relation": 3.77024,
            "contradiction": 1.89951,
            "irrelevancy": 72.72674,
            "logical_agreement": 25.37375,
            "grammar_ref": 4.57112,
            "grammar_hyp": 4.24795,
            "nubia_score": 0.60093
        },
        "meteor": 0.35390667221448546,
        "bleurt": 0.00622,
        "bertscore": {
            "precision": 0.86359,
            "recall": 0.9091,
            "f1": 0.88437
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_104": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 29,
        "total_length": 497,
        "mean_pred_length": 17.137931034482758,
        "std_pred_length": 5.888177154446044,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 34,
        "distinct-1": 0.579476861167002,
        "vocab_size-1": 288,
        "unique-1": 243,
        "entropy-1": 7.311939274466928,
        "distinct-2": 0.9188034188034188,
        "vocab_size-2": 430,
        "unique-2": 406,
        "entropy-2": 8.672652486649676,
        "cond_entropy-2": 1.196560134146931,
        "distinct-3": 0.9840546697038725,
        "vocab_size-3": 432,
        "unique-3": 426,
        "entropy-3": 8.744466907434692,
        "cond_entropy-3": 0.07404395894660941,
        "total_length-nopunct": 429,
        "mean_pred_length-nopunct": 14.793103448275861,
        "std_pred_length-nopunct": 4.641486907601527,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6573426573426573,
        "vocab_size-1-nopunct": 282,
        "unique-1-nopunct": 241,
        "entropy-1-nopunct": 7.480131416102711,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 375,
        "unique-2-nopunct": 360,
        "entropy-2-nopunct": 8.486307314753109,
        "cond_entropy-2-nopunct": 1.0762123789572469,
        "distinct-3-nopunct": 0.9946091644204852,
        "vocab_size-3-nopunct": 369,
        "unique-3-nopunct": 367,
        "entropy-3-nopunct": 8.524493705461705,
        "cond_entropy-3-nopunct": 0.03768512352125475,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.775,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14563106796116504,
            "2": 0.47674418604651164,
            "3": 0.7880794701986755
        },
        "nist": 6.427545740843112,
        "bleu": 46.29085,
        "rouge1": {
            "precision": 0.73742,
            "recall": 0.74787,
            "fmeasure": 0.72906
        },
        "rouge2": {
            "precision": 0.51831,
            "recall": 0.5233,
            "fmeasure": 0.51088
        },
        "rougeL": {
            "precision": 0.64456,
            "recall": 0.65856,
            "fmeasure": 0.6397
        },
        "rougeLsum": {
            "precision": 0.64456,
            "recall": 0.65856,
            "fmeasure": 0.6397
        },
        "nubia": {
            "semantic_relation": 4.31943,
            "contradiction": 7.10709,
            "irrelevancy": 33.61317,
            "logical_agreement": 59.27974,
            "grammar_ref": 4.69384,
            "grammar_hyp": 4.35885,
            "nubia_score": 0.78534
        },
        "meteor": 0.3850043477799275,
        "bleurt": 0.29323,
        "bertscore": {
            "precision": 0.92664,
            "recall": 0.9313,
            "f1": 0.92746
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "ByT5-base (Baseline)/e2e_nlg_test",
        "N": 73,
        "total_length": 1807,
        "mean_pred_length": 24.753424657534246,
        "std_pred_length": 1.8190831795678082,
        "median_pred_length": 25.0,
        "min_pred_length": 20,
        "max_pred_length": 28,
        "distinct-1": 0.08024349750968456,
        "vocab_size-1": 145,
        "unique-1": 36,
        "entropy-1": 5.980421753746166,
        "distinct-2": 0.2422145328719723,
        "vocab_size-2": 420,
        "unique-2": 161,
        "entropy-2": 7.852741631415563,
        "cond_entropy-2": 1.9621281276961462,
        "distinct-3": 0.4214328717639976,
        "vocab_size-3": 700,
        "unique-3": 372,
        "entropy-3": 8.860418508207308,
        "cond_entropy-3": 1.078337219881079,
        "total_length-nopunct": 1710,
        "mean_pred_length-nopunct": 23.424657534246574,
        "std_pred_length-nopunct": 1.6295037333384002,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.08362573099415205,
        "vocab_size-1-nopunct": 143,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.950093892554501,
        "distinct-2-nopunct": 0.24862553451435554,
        "vocab_size-2-nopunct": 407,
        "unique-2-nopunct": 164,
        "entropy-2-nopunct": 7.830146120656728,
        "cond_entropy-2-nopunct": 1.9786825231972034,
        "distinct-3-nopunct": 0.43414322250639387,
        "vocab_size-3-nopunct": 679,
        "unique-3-nopunct": 370,
        "entropy-3-nopunct": 8.853385286535865,
        "cond_entropy-3-nopunct": 1.0944048712079077,
        "msttr-100": 0.40667,
        "msttr-100_nopunct": 0.41235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.630589430894309
        },
        "nist": 4.279763543472865,
        "bleu": 31.95332,
        "rouge1": {
            "precision": 0.8217,
            "recall": 0.63469,
            "fmeasure": 0.71251
        },
        "rouge2": {
            "precision": 0.56215,
            "recall": 0.4319,
            "fmeasure": 0.48568
        },
        "rougeL": {
            "precision": 0.61691,
            "recall": 0.47669,
            "fmeasure": 0.53497
        },
        "rougeLsum": {
            "precision": 0.61691,
            "recall": 0.47669,
            "fmeasure": 0.53497
        },
        "nubia": {
            "semantic_relation": 3.76324,
            "contradiction": 5.88894,
            "irrelevancy": 8.8765,
            "logical_agreement": 85.23456,
            "grammar_ref": 4.71083,
            "grammar_hyp": 4.94596,
            "nubia_score": 0.5608
        },
        "meteor": 0.3313898035416707,
        "bleurt": -0.10976,
        "bertscore": {
            "precision": 0.92625,
            "recall": 0.88367,
            "f1": 0.90429
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_154": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 17,
        "total_length": 245,
        "mean_pred_length": 14.411764705882353,
        "std_pred_length": 4.994806991847948,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 22,
        "distinct-1": 0.6163265306122448,
        "vocab_size-1": 151,
        "unique-1": 122,
        "entropy-1": 6.633808880873757,
        "distinct-2": 0.9692982456140351,
        "vocab_size-2": 221,
        "unique-2": 215,
        "entropy-2": 7.768175595295637,
        "cond_entropy-2": 0.9508057231419986,
        "distinct-3": 0.995260663507109,
        "vocab_size-3": 210,
        "unique-3": 209,
        "entropy-3": 7.71162051572143,
        "cond_entropy-3": -0.06081979464161614,
        "total_length-nopunct": 215,
        "mean_pred_length-nopunct": 12.647058823529411,
        "std_pred_length-nopunct": 4.714697625767972,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6930232558139535,
        "vocab_size-1-nopunct": 149,
        "unique-1-nopunct": 122,
        "entropy-1-nopunct": 6.8091688945533635,
        "distinct-2-nopunct": 0.9797979797979798,
        "vocab_size-2-nopunct": 194,
        "unique-2-nopunct": 191,
        "entropy-2-nopunct": 7.5851400165333125,
        "cond_entropy-2-nopunct": 0.8233370044794045,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 181,
        "unique-3-nopunct": 181,
        "entropy-3-nopunct": 7.499845887083174,
        "cond_entropy-3-nopunct": -0.08114118878555639,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.5245901639344263,
            "3": 0.7080745341614907
        },
        "nist": 5.582725230585707,
        "bleu": 40.56012,
        "rouge1": {
            "precision": 0.74204,
            "recall": 0.67722,
            "fmeasure": 0.69798
        },
        "rouge2": {
            "precision": 0.46739,
            "recall": 0.45297,
            "fmeasure": 0.45618
        },
        "rougeL": {
            "precision": 0.61755,
            "recall": 0.56624,
            "fmeasure": 0.58207
        },
        "rougeLsum": {
            "precision": 0.61755,
            "recall": 0.56624,
            "fmeasure": 0.58207
        },
        "nubia": {
            "semantic_relation": 4.01053,
            "contradiction": 6.5549,
            "irrelevancy": 33.7159,
            "logical_agreement": 59.72921,
            "grammar_ref": 4.51289,
            "grammar_hyp": 4.792,
            "nubia_score": 0.67017
        },
        "meteor": 0.3648491663708827,
        "bleurt": 0.18909,
        "bertscore": {
            "precision": 0.92644,
            "recall": 0.91936,
            "f1": 0.92189
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_19": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 29,
        "total_length": 451,
        "mean_pred_length": 15.551724137931034,
        "std_pred_length": 4.57569445942024,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.3303769401330377,
        "vocab_size-1": 149,
        "unique-1": 115,
        "entropy-1": 5.835768847772031,
        "distinct-2": 0.5521327014218009,
        "vocab_size-2": 233,
        "unique-2": 195,
        "entropy-2": 7.048152614116191,
        "cond_entropy-2": 1.1421440121845607,
        "distinct-3": 0.6513994910941476,
        "vocab_size-3": 256,
        "unique-3": 226,
        "entropy-3": 7.340101252222931,
        "cond_entropy-3": 0.41030856345817396,
        "total_length-nopunct": 390,
        "mean_pred_length-nopunct": 13.448275862068966,
        "std_pred_length-nopunct": 3.9003643233593706,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.3641025641025641,
        "vocab_size-1-nopunct": 142,
        "unique-1-nopunct": 113,
        "entropy-1-nopunct": 5.791765206704116,
        "distinct-2-nopunct": 0.5346260387811634,
        "vocab_size-2-nopunct": 193,
        "unique-2-nopunct": 160,
        "entropy-2-nopunct": 6.748970794086365,
        "cond_entropy-2-nopunct": 1.1507423000104053,
        "distinct-3-nopunct": 0.641566265060241,
        "vocab_size-3-nopunct": 213,
        "unique-3-nopunct": 188,
        "entropy-3-nopunct": 7.062502228545984,
        "cond_entropy-3-nopunct": 0.4510604788910517,
        "msttr-100": 0.4925,
        "msttr-100_nopunct": 0.48333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.45614035087719296,
            "3": 0.8284023668639053
        },
        "nist": 6.595270127648317,
        "bleu": 64.58129,
        "rouge1": {
            "precision": 0.87965,
            "recall": 0.83539,
            "fmeasure": 0.84931
        },
        "rouge2": {
            "precision": 0.76373,
            "recall": 0.71845,
            "fmeasure": 0.73301
        },
        "rougeL": {
            "precision": 0.84029,
            "recall": 0.79254,
            "fmeasure": 0.8083
        },
        "rougeLsum": {
            "precision": 0.84029,
            "recall": 0.79254,
            "fmeasure": 0.8083
        },
        "nubia": {
            "semantic_relation": 4.33853,
            "contradiction": 1.41163,
            "irrelevancy": 14.41869,
            "logical_agreement": 84.16968,
            "grammar_ref": 4.31347,
            "grammar_hyp": 4.23824,
            "nubia_score": 0.81235
        },
        "meteor": 0.41086742186304276,
        "bleurt": 0.52437,
        "bertscore": {
            "precision": 0.96013,
            "recall": 0.9495,
            "f1": 0.95312
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_37": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 10,
        "total_length": 148,
        "mean_pred_length": 14.8,
        "std_pred_length": 5.3814496188294845,
        "median_pred_length": 13.0,
        "min_pred_length": 5,
        "max_pred_length": 25,
        "distinct-1": 0.6216216216216216,
        "vocab_size-1": 92,
        "unique-1": 69,
        "entropy-1": 6.156833730634611,
        "distinct-2": 0.855072463768116,
        "vocab_size-2": 118,
        "unique-2": 106,
        "entropy-2": 6.774907789986082,
        "cond_entropy-2": 0.4536314173302395,
        "distinct-3": 0.90625,
        "vocab_size-3": 116,
        "unique-3": 110,
        "entropy-3": 6.777114648336088,
        "cond_entropy-3": 0.012645660443135101,
        "total_length-nopunct": 135,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 4.944694126030447,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 90,
        "unique-1-nopunct": 69,
        "entropy-1-nopunct": 6.204122726472136,
        "distinct-2-nopunct": 0.848,
        "vocab_size-2-nopunct": 106,
        "unique-2-nopunct": 95,
        "entropy-2-nopunct": 6.613471484523634,
        "cond_entropy-2-nopunct": 0.46316418769779466,
        "distinct-3-nopunct": 0.8956521739130435,
        "vocab_size-3-nopunct": 103,
        "unique-3-nopunct": 97,
        "entropy-3-nopunct": 6.597408963874986,
        "cond_entropy-3-nopunct": 0.014573375015565947,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.45454545454545453,
            "3": 0.9056603773584906
        },
        "nist": 6.011867868638018,
        "bleu": 69.85484,
        "rouge1": {
            "precision": 0.83178,
            "recall": 0.89689,
            "fmeasure": 0.85938
        },
        "rouge2": {
            "precision": 0.7158,
            "recall": 0.75616,
            "fmeasure": 0.73279
        },
        "rougeL": {
            "precision": 0.79296,
            "recall": 0.85325,
            "fmeasure": 0.81875
        },
        "rougeLsum": {
            "precision": 0.79296,
            "recall": 0.85325,
            "fmeasure": 0.81875
        },
        "nubia": {
            "semantic_relation": 4.76144,
            "contradiction": 0.481,
            "irrelevancy": 27.07092,
            "logical_agreement": 72.44808,
            "grammar_ref": 5.03704,
            "grammar_hyp": 4.85413,
            "nubia_score": 0.92113
        },
        "meteor": 0.5348578221574135,
        "bleurt": 0.71083,
        "bertscore": {
            "precision": 0.9674,
            "recall": 0.97156,
            "f1": 0.96714
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "ByT5-base (Baseline)/e2e_nlg_test",
        "N": 2,
        "total_length": 52,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.46153846153846156,
        "vocab_size-1": 24,
        "unique-1": 0,
        "entropy-1": 4.546593564294937,
        "distinct-2": 0.5,
        "vocab_size-2": 25,
        "unique-2": 0,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.10341647163363238,
        "distinct-3": 0.5,
        "vocab_size-3": 24,
        "unique-3": 0,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.46,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 4.4838561897747224,
        "distinct-2-nopunct": 0.5,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.1077729776130983,
        "distinct-3-nopunct": 0.5,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.061400544664143256,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6428571428571429
        },
        "nist": 2.142603282278024,
        "bleu": 43.41299,
        "rouge1": {
            "precision": 0.98,
            "recall": 0.61466,
            "fmeasure": 0.75503
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.51945,
            "fmeasure": 0.6396
        },
        "rougeL": {
            "precision": 0.86,
            "recall": 0.54323,
            "fmeasure": 0.66548
        },
        "rougeLsum": {
            "precision": 0.86,
            "recall": 0.54323,
            "fmeasure": 0.66548
        },
        "nubia": {
            "semantic_relation": 3.54838,
            "contradiction": 0.818,
            "irrelevancy": 0.91752,
            "logical_agreement": 98.26448,
            "grammar_ref": 4.16331,
            "grammar_hyp": 4.89053,
            "nubia_score": 0.45208
        },
        "meteor": 0.3474533266129814,
        "bleurt": -0.03258,
        "bertscore": {
            "precision": 0.96415,
            "recall": 0.88509,
            "f1": 0.92293
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_184": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 18,
        "total_length": 327,
        "mean_pred_length": 18.166666666666668,
        "std_pred_length": 5.823801736552049,
        "median_pred_length": 16.5,
        "min_pred_length": 9,
        "max_pred_length": 30,
        "distinct-1": 0.5657492354740061,
        "vocab_size-1": 185,
        "unique-1": 149,
        "entropy-1": 6.778058247483854,
        "distinct-2": 0.8737864077669902,
        "vocab_size-2": 270,
        "unique-2": 250,
        "entropy-2": 7.935623424309484,
        "cond_entropy-2": 1.0489124498846454,
        "distinct-3": 0.9553264604810997,
        "vocab_size-3": 278,
        "unique-3": 268,
        "entropy-3": 8.086061296509097,
        "cond_entropy-3": 0.15201914492807633,
        "total_length-nopunct": 286,
        "mean_pred_length-nopunct": 15.88888888888889,
        "std_pred_length-nopunct": 4.976487928124154,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6223776223776224,
        "vocab_size-1-nopunct": 178,
        "unique-1-nopunct": 147,
        "entropy-1-nopunct": 6.789199853635873,
        "distinct-2-nopunct": 0.8768656716417911,
        "vocab_size-2-nopunct": 235,
        "unique-2-nopunct": 220,
        "entropy-2-nopunct": 7.726464003858286,
        "cond_entropy-2-nopunct": 1.00453366703886,
        "distinct-3-nopunct": 0.948,
        "vocab_size-3-nopunct": 237,
        "unique-3-nopunct": 227,
        "entropy-3-nopunct": 7.8507647346534455,
        "cond_entropy-3-nopunct": 0.14875374423027687,
        "msttr-100": 0.70667,
        "msttr-100_nopunct": 0.73,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.30303030303030304,
            "2": 0.29411764705882354,
            "3": 0.8078602620087336
        },
        "nist": 6.477926314979681,
        "bleu": 57.85688,
        "rouge1": {
            "precision": 0.77262,
            "recall": 0.77484,
            "fmeasure": 0.76494
        },
        "rouge2": {
            "precision": 0.61621,
            "recall": 0.60562,
            "fmeasure": 0.603
        },
        "rougeL": {
            "precision": 0.73183,
            "recall": 0.73221,
            "fmeasure": 0.72287
        },
        "rougeLsum": {
            "precision": 0.73183,
            "recall": 0.73221,
            "fmeasure": 0.72287
        },
        "nubia": {
            "semantic_relation": 4.3722,
            "contradiction": 0.58714,
            "irrelevancy": 19.56249,
            "logical_agreement": 79.85037,
            "grammar_ref": 4.5077,
            "grammar_hyp": 4.30597,
            "nubia_score": 0.80651
        },
        "meteor": 0.4179175809257229,
        "bleurt": 0.44649,
        "bertscore": {
            "precision": 0.93911,
            "recall": 0.94452,
            "f1": 0.9405
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_20": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 112,
        "total_length": 1806,
        "mean_pred_length": 16.125,
        "std_pred_length": 5.048205126577168,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.44130675526024365,
        "vocab_size-1": 797,
        "unique-1": 665,
        "entropy-1": 8.001614211802798,
        "distinct-2": 0.8057851239669421,
        "vocab_size-2": 1365,
        "unique-2": 1257,
        "entropy-2": 10.085702135780425,
        "cond_entropy-2": 1.849426650026528,
        "distinct-3": 0.9051833122629582,
        "vocab_size-3": 1432,
        "unique-3": 1375,
        "entropy-3": 10.34659989428047,
        "cond_entropy-3": 0.27747678481697263,
        "total_length-nopunct": 1574,
        "mean_pred_length-nopunct": 14.053571428571429,
        "std_pred_length-nopunct": 4.401378204840027,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5,
        "vocab_size-1-nopunct": 787,
        "unique-1-nopunct": 661,
        "entropy-1-nopunct": 8.260131642894828,
        "distinct-2-nopunct": 0.8173734610123119,
        "vocab_size-2-nopunct": 1195,
        "unique-2-nopunct": 1115,
        "entropy-2-nopunct": 9.890440018717648,
        "cond_entropy-2-nopunct": 1.7379279067162334,
        "distinct-3-nopunct": 0.9088888888888889,
        "vocab_size-3-nopunct": 1227,
        "unique-3-nopunct": 1182,
        "entropy-3-nopunct": 10.12825972159083,
        "cond_entropy-3-nopunct": 0.2738039909932409,
        "msttr-100": 0.70556,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24629080118694363,
            "2": 0.4391025641025641,
            "3": 0.8013998250218722
        },
        "nist": 7.599485197625915,
        "bleu": 46.6986,
        "rouge1": {
            "precision": 0.76199,
            "recall": 0.73636,
            "fmeasure": 0.73663
        },
        "rouge2": {
            "precision": 0.54032,
            "recall": 0.51863,
            "fmeasure": 0.52125
        },
        "rougeL": {
            "precision": 0.64876,
            "recall": 0.63517,
            "fmeasure": 0.63105
        },
        "rougeLsum": {
            "precision": 0.64876,
            "recall": 0.63517,
            "fmeasure": 0.63105
        },
        "nubia": {
            "semantic_relation": 4.19368,
            "contradiction": 6.25018,
            "irrelevancy": 25.46958,
            "logical_agreement": 68.28024,
            "grammar_ref": 4.71051,
            "grammar_hyp": 4.65434,
            "nubia_score": 0.74393
        },
        "meteor": 0.3888436716561185,
        "bleurt": 0.29092,
        "bertscore": {
            "precision": 0.92868,
            "recall": 0.92809,
            "f1": 0.92691
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_21": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 91,
        "total_length": 1445,
        "mean_pred_length": 15.87912087912088,
        "std_pred_length": 5.412308245640468,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.413840830449827,
        "vocab_size-1": 598,
        "unique-1": 478,
        "entropy-1": 7.717474302967937,
        "distinct-2": 0.7592319054652881,
        "vocab_size-2": 1028,
        "unique-2": 931,
        "entropy-2": 9.62449383488717,
        "cond_entropy-2": 1.681827866390662,
        "distinct-3": 0.8709422011084719,
        "vocab_size-3": 1100,
        "unique-3": 1045,
        "entropy-3": 9.911336487885636,
        "cond_entropy-3": 0.29869605932470167,
        "total_length-nopunct": 1253,
        "mean_pred_length-nopunct": 13.76923076923077,
        "std_pred_length-nopunct": 4.99907007413241,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.47166799680766164,
        "vocab_size-1-nopunct": 591,
        "unique-1-nopunct": 476,
        "entropy-1-nopunct": 7.960543288169895,
        "distinct-2-nopunct": 0.7736660929432013,
        "vocab_size-2-nopunct": 899,
        "unique-2-nopunct": 824,
        "entropy-2-nopunct": 9.439630159972667,
        "cond_entropy-2-nopunct": 1.5892567233524961,
        "distinct-3-nopunct": 0.8748832866479925,
        "vocab_size-3-nopunct": 937,
        "unique-3-nopunct": 893,
        "entropy-3-nopunct": 9.685754374243713,
        "cond_entropy-3-nopunct": 0.2866672736556133,
        "msttr-100": 0.69857,
        "msttr-100_nopunct": 0.75417,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23873873873873874,
            "2": 0.5112781954887218,
            "3": 0.7741596638655462
        },
        "nist": 7.506174600041334,
        "bleu": 50.27294,
        "rouge1": {
            "precision": 0.78688,
            "recall": 0.75093,
            "fmeasure": 0.758
        },
        "rouge2": {
            "precision": 0.5852,
            "recall": 0.55348,
            "fmeasure": 0.56005
        },
        "rougeL": {
            "precision": 0.71425,
            "recall": 0.68486,
            "fmeasure": 0.68972
        },
        "rougeLsum": {
            "precision": 0.71425,
            "recall": 0.68486,
            "fmeasure": 0.68972
        },
        "nubia": {
            "semantic_relation": 4.19604,
            "contradiction": 5.47545,
            "irrelevancy": 26.66555,
            "logical_agreement": 67.85901,
            "grammar_ref": 4.3909,
            "grammar_hyp": 4.45675,
            "nubia_score": 0.74683
        },
        "meteor": 0.40477619235828355,
        "bleurt": 0.32075,
        "bertscore": {
            "precision": 0.93725,
            "recall": 0.92897,
            "f1": 0.93168
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_133": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 11,
        "total_length": 155,
        "mean_pred_length": 14.090909090909092,
        "std_pred_length": 4.6211872825959395,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.7032258064516129,
        "vocab_size-1": 109,
        "unique-1": 92,
        "entropy-1": 6.397060899541794,
        "distinct-2": 0.9722222222222222,
        "vocab_size-2": 140,
        "unique-2": 136,
        "entropy-2": 7.1143694458867754,
        "cond_entropy-2": 0.553769779776807,
        "distinct-3": 1.0,
        "vocab_size-3": 133,
        "unique-3": 133,
        "entropy-3": 7.055282435501199,
        "cond_entropy-3": -0.054492190001273,
        "total_length-nopunct": 139,
        "mean_pred_length-nopunct": 12.636363636363637,
        "std_pred_length-nopunct": 4.291063171347616,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7697841726618705,
        "vocab_size-1-nopunct": 107,
        "unique-1-nopunct": 92,
        "entropy-1-nopunct": 6.489259148728337,
        "distinct-2-nopunct": 0.96875,
        "vocab_size-2-nopunct": 124,
        "unique-2-nopunct": 120,
        "entropy-2-nopunct": 6.9375,
        "cond_entropy-2-nopunct": 0.48672914161501096,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 117,
        "unique-3-nopunct": 117,
        "entropy-3-nopunct": 6.8703647195833835,
        "cond_entropy-3-nopunct": -0.06980622058753588,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.79,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.027777777777777776,
            "2": 0.4090909090909091,
            "3": 0.6587301587301587
        },
        "nist": 4.49049161445023,
        "bleu": 32.06017,
        "rouge1": {
            "precision": 0.76088,
            "recall": 0.66396,
            "fmeasure": 0.69949
        },
        "rouge2": {
            "precision": 0.50509,
            "recall": 0.45136,
            "fmeasure": 0.4696
        },
        "rougeL": {
            "precision": 0.6174,
            "recall": 0.55306,
            "fmeasure": 0.57308
        },
        "rougeLsum": {
            "precision": 0.6174,
            "recall": 0.55306,
            "fmeasure": 0.57308
        },
        "nubia": {
            "semantic_relation": 4.18249,
            "contradiction": 4.81475,
            "irrelevancy": 39.67991,
            "logical_agreement": 55.50535,
            "grammar_ref": 4.38413,
            "grammar_hyp": 5.11159,
            "nubia_score": 0.64339
        },
        "meteor": 0.3609916395329997,
        "bleurt": 0.08208,
        "bertscore": {
            "precision": 0.91565,
            "recall": 0.90574,
            "f1": 0.90983
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_185": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 8,
        "total_length": 104,
        "mean_pred_length": 13.0,
        "std_pred_length": 1.8708286933869707,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 16,
        "distinct-1": 0.6826923076923077,
        "vocab_size-1": 71,
        "unique-1": 58,
        "entropy-1": 5.800193055588787,
        "distinct-2": 0.9375,
        "vocab_size-2": 90,
        "unique-2": 84,
        "entropy-2": 6.45996250072116,
        "cond_entropy-2": 0.484790000345068,
        "distinct-3": 0.9545454545454546,
        "vocab_size-3": 84,
        "unique-3": 80,
        "entropy-3": 6.368522527728215,
        "cond_entropy-3": -0.08007633662931363,
        "total_length-nopunct": 92,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 2.1213203435596424,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.85371790273702,
        "distinct-2-nopunct": 0.9404761904761905,
        "vocab_size-2-nopunct": 79,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.273269803731141,
        "cond_entropy-2-nopunct": 0.48334657273889364,
        "distinct-3-nopunct": 0.9605263157894737,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 70,
        "entropy-3-nopunct": 6.168980145022539,
        "cond_entropy-3-nopunct": -0.0917583303878064,
        "msttr-100": 0.68,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.1,
            "3": 0.7619047619047619
        },
        "nist": 5.034826085446333,
        "bleu": 43.84024,
        "rouge1": {
            "precision": 0.73996,
            "recall": 0.71483,
            "fmeasure": 0.71818
        },
        "rouge2": {
            "precision": 0.49496,
            "recall": 0.50101,
            "fmeasure": 0.49129
        },
        "rougeL": {
            "precision": 0.63223,
            "recall": 0.63923,
            "fmeasure": 0.62676
        },
        "rougeLsum": {
            "precision": 0.63223,
            "recall": 0.63923,
            "fmeasure": 0.62676
        },
        "nubia": {
            "semantic_relation": 3.81567,
            "contradiction": 42.18806,
            "irrelevancy": 10.55608,
            "logical_agreement": 47.25585,
            "grammar_ref": 5.14697,
            "grammar_hyp": 5.24638,
            "nubia_score": 0.59966
        },
        "meteor": 0.38405421625731445,
        "bleurt": 0.25418,
        "bertscore": {
            "precision": 0.92922,
            "recall": 0.91901,
            "f1": 0.92212
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_105": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 36,
        "total_length": 586,
        "mean_pred_length": 16.27777777777778,
        "std_pred_length": 4.362791608280637,
        "median_pred_length": 15.5,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.5716723549488054,
        "vocab_size-1": 335,
        "unique-1": 280,
        "entropy-1": 7.441899083078527,
        "distinct-2": 0.9327272727272727,
        "vocab_size-2": 513,
        "unique-2": 493,
        "entropy-2": 8.92329922939433,
        "cond_entropy-2": 1.3034053822584277,
        "distinct-3": 0.9844357976653697,
        "vocab_size-3": 506,
        "unique-3": 499,
        "entropy-3": 8.973027491796703,
        "cond_entropy-3": 0.05455236521284353,
        "total_length-nopunct": 513,
        "mean_pred_length-nopunct": 14.25,
        "std_pred_length-nopunct": 4.225419111362406,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6374269005847953,
        "vocab_size-1-nopunct": 327,
        "unique-1-nopunct": 277,
        "entropy-1-nopunct": 7.591282844103137,
        "distinct-2-nopunct": 0.9287211740041929,
        "vocab_size-2-nopunct": 443,
        "unique-2-nopunct": 426,
        "entropy-2-nopunct": 8.70289007139404,
        "cond_entropy-2-nopunct": 1.1859789425345562,
        "distinct-3-nopunct": 0.981859410430839,
        "vocab_size-3-nopunct": 433,
        "unique-3-nopunct": 426,
        "entropy-3-nopunct": 8.746641903375789,
        "cond_entropy-3-nopunct": 0.057398983560008277,
        "msttr-100": 0.718,
        "msttr-100_nopunct": 0.756,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14814814814814814,
            "2": 0.6101694915254238,
            "3": 0.796923076923077
        },
        "nist": 6.632453186683324,
        "bleu": 47.96527,
        "rouge1": {
            "precision": 0.73264,
            "recall": 0.77206,
            "fmeasure": 0.74219
        },
        "rouge2": {
            "precision": 0.51541,
            "recall": 0.56149,
            "fmeasure": 0.52841
        },
        "rougeL": {
            "precision": 0.62497,
            "recall": 0.67207,
            "fmeasure": 0.63776
        },
        "rougeLsum": {
            "precision": 0.62497,
            "recall": 0.67207,
            "fmeasure": 0.63776
        },
        "nubia": {
            "semantic_relation": 4.18085,
            "contradiction": 4.88122,
            "irrelevancy": 50.28751,
            "logical_agreement": 44.83127,
            "grammar_ref": 4.61474,
            "grammar_hyp": 4.45999,
            "nubia_score": 0.7247
        },
        "meteor": 0.415803391941241,
        "bleurt": 0.20433,
        "bertscore": {
            "precision": 0.9207,
            "recall": 0.93382,
            "f1": 0.92467
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_84": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 80,
        "total_length": 1312,
        "mean_pred_length": 16.4,
        "std_pred_length": 5.80430874437258,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.5076219512195121,
        "vocab_size-1": 666,
        "unique-1": 540,
        "entropy-1": 8.086863031802528,
        "distinct-2": 0.9099025974025974,
        "vocab_size-2": 1121,
        "unique-2": 1059,
        "entropy-2": 10.012995785720546,
        "cond_entropy-2": 1.7135481582255312,
        "distinct-3": 0.9878472222222222,
        "vocab_size-3": 1138,
        "unique-3": 1125,
        "entropy-3": 10.144964161596606,
        "cond_entropy-3": 0.13293075211111502,
        "total_length-nopunct": 1136,
        "mean_pred_length-nopunct": 14.2,
        "std_pred_length-nopunct": 5.247380298777667,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5801056338028169,
        "vocab_size-1-nopunct": 659,
        "unique-1-nopunct": 538,
        "entropy-1-nopunct": 8.38696366337979,
        "distinct-2-nopunct": 0.9232954545454546,
        "vocab_size-2-nopunct": 975,
        "unique-2-nopunct": 931,
        "entropy-2-nopunct": 9.81624866086737,
        "cond_entropy-2-nopunct": 1.517130179848729,
        "distinct-3-nopunct": 0.9907786885245902,
        "vocab_size-3-nopunct": 967,
        "unique-3-nopunct": 958,
        "entropy-3-nopunct": 9.912294714612063,
        "cond_entropy-3-nopunct": 0.11209797400948708,
        "msttr-100": 0.72692,
        "msttr-100_nopunct": 0.78455,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23728813559322035,
            "2": 0.40375586854460094,
            "3": 0.7369589345172031
        },
        "nist": 7.130591645455012,
        "bleu": 40.88266,
        "rouge1": {
            "precision": 0.74896,
            "recall": 0.69764,
            "fmeasure": 0.71065
        },
        "rouge2": {
            "precision": 0.49013,
            "recall": 0.45223,
            "fmeasure": 0.46248
        },
        "rougeL": {
            "precision": 0.64171,
            "recall": 0.59995,
            "fmeasure": 0.60871
        },
        "rougeLsum": {
            "precision": 0.64171,
            "recall": 0.59995,
            "fmeasure": 0.60871
        },
        "nubia": {
            "semantic_relation": 4.1502,
            "contradiction": 9.16597,
            "irrelevancy": 25.78287,
            "logical_agreement": 65.05116,
            "grammar_ref": 4.79239,
            "grammar_hyp": 4.80497,
            "nubia_score": 0.71096
        },
        "meteor": 0.3719488828282331,
        "bleurt": 0.24355,
        "bertscore": {
            "precision": 0.92664,
            "recall": 0.91654,
            "f1": 0.91909
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_155": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 17,
        "total_length": 288,
        "mean_pred_length": 16.941176470588236,
        "std_pred_length": 6.338218233906343,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 31,
        "distinct-1": 0.6006944444444444,
        "vocab_size-1": 173,
        "unique-1": 140,
        "entropy-1": 6.817136440235041,
        "distinct-2": 0.9040590405904059,
        "vocab_size-2": 245,
        "unique-2": 228,
        "entropy-2": 7.850890611600862,
        "cond_entropy-2": 0.902366889470617,
        "distinct-3": 0.952755905511811,
        "vocab_size-3": 242,
        "unique-3": 232,
        "entropy-3": 7.888252501715726,
        "cond_entropy-3": 0.044965800767625616,
        "total_length-nopunct": 242,
        "mean_pred_length-nopunct": 14.235294117647058,
        "std_pred_length-nopunct": 4.634009974407324,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6942148760330579,
        "vocab_size-1-nopunct": 168,
        "unique-1-nopunct": 139,
        "entropy-1-nopunct": 6.969702998494617,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 210,
        "unique-2-nopunct": 201,
        "entropy-2-nopunct": 7.643086204743364,
        "cond_entropy-2-nopunct": 0.7406530909566119,
        "distinct-3-nopunct": 0.9711538461538461,
        "vocab_size-3-nopunct": 202,
        "unique-3-nopunct": 196,
        "entropy-3-nopunct": 7.64274741044876,
        "cond_entropy-3-nopunct": 0.01361223825370243,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.795,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1702127659574468,
            "2": 0.23684210526315788,
            "3": 0.7972350230414746
        },
        "nist": 6.42549606565757,
        "bleu": 56.88056,
        "rouge1": {
            "precision": 0.80255,
            "recall": 0.75309,
            "fmeasure": 0.76566
        },
        "rouge2": {
            "precision": 0.59954,
            "recall": 0.55358,
            "fmeasure": 0.56662
        },
        "rougeL": {
            "precision": 0.70841,
            "recall": 0.66392,
            "fmeasure": 0.67469
        },
        "rougeLsum": {
            "precision": 0.70841,
            "recall": 0.66392,
            "fmeasure": 0.67469
        },
        "nubia": {
            "semantic_relation": 4.35703,
            "contradiction": 4.41957,
            "irrelevancy": 20.57857,
            "logical_agreement": 75.00186,
            "grammar_ref": 4.52442,
            "grammar_hyp": 4.63835,
            "nubia_score": 0.77162
        },
        "meteor": 0.4350478128133857,
        "bleurt": 0.37274,
        "bertscore": {
            "precision": 0.93843,
            "recall": 0.93109,
            "f1": 0.93079
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_106": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 5.0,
        "median_pred_length": 18.0,
        "min_pred_length": 13,
        "max_pred_length": 23,
        "distinct-1": 0.8611111111111112,
        "vocab_size-1": 31,
        "unique-1": 27,
        "entropy-1": 4.871178126382214,
        "distinct-2": 0.9705882352941176,
        "vocab_size-2": 33,
        "unique-2": 32,
        "entropy-2": 5.028639311838574,
        "cond_entropy-2": 0.17503453104812905,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.024962841250339374,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.90625,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.8125,
        "distinct-2-nopunct": 0.9666666666666667,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.840223928941852,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.028107102122342936,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "nist": 3.4579476507107794,
        "bleu": 34.55824,
        "rouge1": {
            "precision": 0.68939,
            "recall": 0.67949,
            "fmeasure": 0.675
        },
        "rouge2": {
            "precision": 0.50476,
            "recall": 0.47386,
            "fmeasure": 0.48086
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.55983,
            "fmeasure": 0.56429
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.55983,
            "fmeasure": 0.56429
        },
        "nubia": {
            "semantic_relation": 4.22658,
            "contradiction": 11.29115,
            "irrelevancy": 38.92138,
            "logical_agreement": 49.78747,
            "grammar_ref": 4.99819,
            "grammar_hyp": 5.27362,
            "nubia_score": 0.71876
        },
        "meteor": 0.3171520804273202,
        "bleurt": 0.22751,
        "bertscore": {
            "precision": 0.88097,
            "recall": 0.89649,
            "f1": 0.88832
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_134": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.546593564294939,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.277613436819116,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.75
        },
        "nist": 2.6357432697300314,
        "bleu": 23.68477,
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.725,
            "fmeasure": 0.72464
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.24747,
            "fmeasure": 0.24812
        },
        "rougeL": {
            "precision": 0.40909,
            "recall": 0.41667,
            "fmeasure": 0.41201
        },
        "rougeLsum": {
            "precision": 0.40909,
            "recall": 0.41667,
            "fmeasure": 0.41201
        },
        "nubia": {
            "semantic_relation": 4.72525,
            "contradiction": 1.72286,
            "irrelevancy": 0.6434,
            "logical_agreement": 97.63374,
            "grammar_ref": 5.93899,
            "grammar_hyp": 6.41759,
            "nubia_score": 0.68169
        },
        "meteor": 0.331961373853206,
        "bleurt": -0.11809,
        "bertscore": {
            "precision": 0.87608,
            "recall": 0.88076,
            "f1": 0.8732
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_219": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 2.5,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 16,
        "distinct-1": 0.8518518518518519,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.430632409490749,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.15916418769779478,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.303508854797679,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.18150945892357132,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 5.016137706633773,
        "bleu": 100.0,
        "rouge1": {
            "precision": 0.98333,
            "recall": 1.0,
            "fmeasure": 0.99123
        },
        "rouge2": {
            "precision": 0.96296,
            "recall": 0.97917,
            "fmeasure": 0.97059
        },
        "rougeL": {
            "precision": 0.98333,
            "recall": 1.0,
            "fmeasure": 0.99123
        },
        "rougeLsum": {
            "precision": 0.98333,
            "recall": 1.0,
            "fmeasure": 0.99123
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.56394,
            "irrelevancy": 0.56148,
            "logical_agreement": 98.87458,
            "grammar_ref": 4.84371,
            "grammar_hyp": 4.6994,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.95532,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_220": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 16,
        "total_length": 282,
        "mean_pred_length": 17.625,
        "std_pred_length": 5.23061898822692,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 29,
        "distinct-1": 0.6276595744680851,
        "vocab_size-1": 177,
        "unique-1": 146,
        "entropy-1": 6.9073215121273295,
        "distinct-2": 0.9323308270676691,
        "vocab_size-2": 248,
        "unique-2": 234,
        "entropy-2": 7.906749446763169,
        "cond_entropy-2": 0.8532336433208337,
        "distinct-3": 1.0,
        "vocab_size-3": 250,
        "unique-3": 250,
        "entropy-3": 7.9657842846621,
        "cond_entropy-3": 0.06854094917820526,
        "total_length-nopunct": 249,
        "mean_pred_length-nopunct": 15.5625,
        "std_pred_length-nopunct": 4.358450842902785,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6867469879518072,
        "vocab_size-1-nopunct": 171,
        "unique-1-nopunct": 145,
        "entropy-1-nopunct": 6.960618976224211,
        "distinct-2-nopunct": 0.9399141630901288,
        "vocab_size-2-nopunct": 219,
        "unique-2-nopunct": 209,
        "entropy-2-nopunct": 7.728951058798835,
        "cond_entropy-2-nopunct": 0.8301568241745075,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 217,
        "unique-3-nopunct": 217,
        "entropy-3-nopunct": 7.761551232444494,
        "cond_entropy-3-nopunct": 0.04257142421566904,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.795,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.425,
            "3": 0.839572192513369
        },
        "nist": 6.3687143196763385,
        "bleu": 51.06597,
        "rouge1": {
            "precision": 0.78456,
            "recall": 0.79768,
            "fmeasure": 0.7835
        },
        "rouge2": {
            "precision": 0.54758,
            "recall": 0.57811,
            "fmeasure": 0.55512
        },
        "rougeL": {
            "precision": 0.67915,
            "recall": 0.71007,
            "fmeasure": 0.68642
        },
        "rougeLsum": {
            "precision": 0.67915,
            "recall": 0.71007,
            "fmeasure": 0.68642
        },
        "nubia": {
            "semantic_relation": 4.38976,
            "contradiction": 4.54605,
            "irrelevancy": 29.29137,
            "logical_agreement": 66.16258,
            "grammar_ref": 4.78068,
            "grammar_hyp": 4.74189,
            "nubia_score": 0.77929
        },
        "meteor": 0.4176140038643694,
        "bleurt": 0.36327,
        "bertscore": {
            "precision": 0.93267,
            "recall": 0.93522,
            "f1": 0.931
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_22": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 17,
        "total_length": 275,
        "mean_pred_length": 16.176470588235293,
        "std_pred_length": 6.002306361799575,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.5890909090909091,
        "vocab_size-1": 162,
        "unique-1": 136,
        "entropy-1": 6.584689008076213,
        "distinct-2": 0.9224806201550387,
        "vocab_size-2": 238,
        "unique-2": 227,
        "entropy-2": 7.812927800156827,
        "cond_entropy-2": 1.135377327332167,
        "distinct-3": 0.983402489626556,
        "vocab_size-3": 237,
        "unique-3": 234,
        "entropy-3": 7.876562002196121,
        "cond_entropy-3": 0.07762213041901707,
        "total_length-nopunct": 240,
        "mean_pred_length-nopunct": 14.117647058823529,
        "std_pred_length-nopunct": 5.54003984845699,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.65,
        "vocab_size-1-nopunct": 156,
        "unique-1-nopunct": 133,
        "entropy-1-nopunct": 6.667155303701327,
        "distinct-2-nopunct": 0.9237668161434978,
        "vocab_size-2-nopunct": 206,
        "unique-2-nopunct": 197,
        "entropy-2-nopunct": 7.601768187110599,
        "cond_entropy-2-nopunct": 1.008561481892258,
        "distinct-3-nopunct": 0.9805825242718447,
        "vocab_size-3-nopunct": 202,
        "unique-3-nopunct": 199,
        "entropy-3-nopunct": 7.64400107328922,
        "cond_entropy-3-nopunct": 0.058666085779434135,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.71,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13157894736842105,
            "2": 0.375,
            "3": 0.695906432748538
        },
        "nist": 4.843115123667946,
        "bleu": 37.37926,
        "rouge1": {
            "precision": 0.66981,
            "recall": 0.59373,
            "fmeasure": 0.61134
        },
        "rouge2": {
            "precision": 0.43193,
            "recall": 0.36263,
            "fmeasure": 0.38385
        },
        "rougeL": {
            "precision": 0.57158,
            "recall": 0.5062,
            "fmeasure": 0.52145
        },
        "rougeLsum": {
            "precision": 0.57158,
            "recall": 0.5062,
            "fmeasure": 0.52145
        },
        "nubia": {
            "semantic_relation": 3.78992,
            "contradiction": 13.90225,
            "irrelevancy": 23.14442,
            "logical_agreement": 62.95333,
            "grammar_ref": 4.31337,
            "grammar_hyp": 4.33244,
            "nubia_score": 0.62951
        },
        "meteor": 0.316748512157699,
        "bleurt": 0.09178,
        "bertscore": {
            "precision": 0.89263,
            "recall": 0.87774,
            "f1": 0.8833
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_186": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 14,
        "total_length": 236,
        "mean_pred_length": 16.857142857142858,
        "std_pred_length": 5.6550501179684245,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.6228813559322034,
        "vocab_size-1": 147,
        "unique-1": 118,
        "entropy-1": 6.571096351869913,
        "distinct-2": 0.9234234234234234,
        "vocab_size-2": 205,
        "unique-2": 195,
        "entropy-2": 7.60919327410341,
        "cond_entropy-2": 0.9377498206981584,
        "distinct-3": 0.9903846153846154,
        "vocab_size-3": 206,
        "unique-3": 204,
        "entropy-3": 7.681208948910298,
        "cond_entropy-3": 0.07967488774658142,
        "total_length-nopunct": 215,
        "mean_pred_length-nopunct": 15.357142857142858,
        "std_pred_length-nopunct": 5.575547927681867,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6604651162790698,
        "vocab_size-1-nopunct": 142,
        "unique-1-nopunct": 115,
        "entropy-1-nopunct": 6.576938020060712,
        "distinct-2-nopunct": 0.9154228855721394,
        "vocab_size-2-nopunct": 184,
        "unique-2-nopunct": 174,
        "entropy-2-nopunct": 7.446477484816931,
        "cond_entropy-2-nopunct": 0.9204232588455468,
        "distinct-3-nopunct": 0.9893048128342246,
        "vocab_size-3-nopunct": 185,
        "unique-3-nopunct": 183,
        "entropy-3-nopunct": 7.525504085556064,
        "cond_entropy-3-nopunct": 0.08364712955771189,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.71,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16216216216216217,
            "2": 0.4423076923076923,
            "3": 0.8095238095238095
        },
        "nist": 5.55679728070718,
        "bleu": 47.32385,
        "rouge1": {
            "precision": 0.68104,
            "recall": 0.7357,
            "fmeasure": 0.69974
        },
        "rouge2": {
            "precision": 0.46838,
            "recall": 0.51577,
            "fmeasure": 0.48661
        },
        "rougeL": {
            "precision": 0.62534,
            "recall": 0.6726,
            "fmeasure": 0.64133
        },
        "rougeLsum": {
            "precision": 0.62534,
            "recall": 0.6726,
            "fmeasure": 0.64133
        },
        "nubia": {
            "semantic_relation": 3.88125,
            "contradiction": 17.33692,
            "irrelevancy": 41.2575,
            "logical_agreement": 41.40558,
            "grammar_ref": 4.72137,
            "grammar_hyp": 4.61264,
            "nubia_score": 0.6609
        },
        "meteor": 0.40118409092497437,
        "bleurt": 0.08785,
        "bertscore": {
            "precision": 0.91077,
            "recall": 0.91649,
            "f1": 0.91282
        }
    },
    "xsum_challenge_test_nopunc": {
        "predictions_file": "ByT5-base (Baseline)/xsum_challenge_test_nopunc",
        "N": 500,
        "total_length": 10675,
        "mean_pred_length": 21.35,
        "std_pred_length": 3.4356222143885375,
        "median_pred_length": 22.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.27672131147540985,
        "vocab_size-1": 2954,
        "unique-1": 1901,
        "entropy-1": 9.144107463507984,
        "distinct-2": 0.7402457002457002,
        "vocab_size-2": 7532,
        "unique-2": 6570,
        "entropy-2": 12.408917683886582,
        "cond_entropy-2": 3.1925273309857998,
        "distinct-3": 0.9329198966408269,
        "vocab_size-3": 9026,
        "unique-3": 8634,
        "entropy-3": 13.06801510774337,
        "cond_entropy-3": 0.682510574708162,
        "total_length-nopunct": 10169,
        "mean_pred_length-nopunct": 20.338,
        "std_pred_length-nopunct": 3.5619876473676886,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.2895073261874324,
        "vocab_size-1-nopunct": 2944,
        "unique-1-nopunct": 1900,
        "entropy-1-nopunct": 9.234595057867349,
        "distinct-2-nopunct": 0.7436136105078085,
        "vocab_size-2-nopunct": 7190,
        "unique-2-nopunct": 6286,
        "entropy-2-nopunct": 12.3441463616043,
        "cond_entropy-2-nopunct": 3.2251451795744828,
        "distinct-3-nopunct": 0.9358708692332861,
        "vocab_size-3-nopunct": 8581,
        "unique-3-nopunct": 8216,
        "entropy-3-nopunct": 13.003818947316923,
        "cond_entropy-3-nopunct": 0.6828059106529394,
        "msttr-100": 0.74292,
        "msttr-100_nopunct": 0.75287,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_nopunc.json",
        "local_recall": {
            "1": 0.3455202892728003
        },
        "nist": 3.513164055023838,
        "bleu": 9.11715,
        "rouge1": {
            "precision": 0.38338,
            "recall": 0.37028,
            "fmeasure": 0.3713
        },
        "rouge2": {
            "precision": 0.14659,
            "recall": 0.13997,
            "fmeasure": 0.14105
        },
        "rougeL": {
            "precision": 0.29995,
            "recall": 0.28982,
            "fmeasure": 0.29042
        },
        "rougeLsum": {
            "precision": 0.29995,
            "recall": 0.28982,
            "fmeasure": 0.29042
        },
        "nubia": {
            "semantic_relation": 2.66964,
            "contradiction": 27.43806,
            "irrelevancy": 63.26672,
            "logical_agreement": 9.29522,
            "grammar_ref": 3.78318,
            "grammar_hyp": 4.13771,
            "nubia_score": 0.33841
        },
        "meteor": 0.1617494820231736,
        "bleurt": -0.46755,
        "bertscore": {
            "precision": 0.82419,
            "recall": 0.81801,
            "f1": 0.82084
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_85": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 25,
        "total_length": 422,
        "mean_pred_length": 16.88,
        "std_pred_length": 5.4429403818156965,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.566350710900474,
        "vocab_size-1": 239,
        "unique-1": 192,
        "entropy-1": 7.16436455378856,
        "distinct-2": 0.9143576826196473,
        "vocab_size-2": 363,
        "unique-2": 339,
        "entropy-2": 8.438991292839063,
        "cond_entropy-2": 1.119463018243691,
        "distinct-3": 0.9758064516129032,
        "vocab_size-3": 363,
        "unique-3": 355,
        "entropy-3": 8.488742446854946,
        "cond_entropy-3": 0.038595502423380765,
        "total_length-nopunct": 355,
        "mean_pred_length-nopunct": 14.2,
        "std_pred_length-nopunct": 4.560701700396552,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6563380281690141,
        "vocab_size-1-nopunct": 233,
        "unique-1-nopunct": 191,
        "entropy-1-nopunct": 7.361585150783939,
        "distinct-2-nopunct": 0.9393939393939394,
        "vocab_size-2-nopunct": 310,
        "unique-2-nopunct": 296,
        "entropy-2-nopunct": 8.228413805141837,
        "cond_entropy-2-nopunct": 0.94006286371996,
        "distinct-3-nopunct": 0.9836065573770492,
        "vocab_size-3-nopunct": 300,
        "unique-3-nopunct": 295,
        "entropy-3-nopunct": 8.219878547204301,
        "cond_entropy-3-nopunct": 0.002768710021898031,
        "msttr-100": 0.7125,
        "msttr-100_nopunct": 0.76667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15942028985507245,
            "2": 0.36231884057971014,
            "3": 0.7632508833922261
        },
        "nist": 6.597791819697449,
        "bleu": 51.912,
        "rouge1": {
            "precision": 0.76944,
            "recall": 0.72584,
            "fmeasure": 0.73583
        },
        "rouge2": {
            "precision": 0.56928,
            "recall": 0.53646,
            "fmeasure": 0.54523
        },
        "rougeL": {
            "precision": 0.68232,
            "recall": 0.66004,
            "fmeasure": 0.6619
        },
        "rougeLsum": {
            "precision": 0.68232,
            "recall": 0.66004,
            "fmeasure": 0.6619
        },
        "nubia": {
            "semantic_relation": 3.90735,
            "contradiction": 14.58845,
            "irrelevancy": 25.61624,
            "logical_agreement": 59.7953,
            "grammar_ref": 4.78896,
            "grammar_hyp": 4.93273,
            "nubia_score": 0.63412
        },
        "meteor": 0.40730786903165417,
        "bleurt": 0.15249,
        "bertscore": {
            "precision": 0.9311,
            "recall": 0.92716,
            "f1": 0.92803
        }
    },
    "xsum_challenge_test_covid": {
        "predictions_file": "ByT5-base (Baseline)/xsum_challenge_test_covid",
        "N": 401,
        "total_length": 8781,
        "mean_pred_length": 21.897755610972567,
        "std_pred_length": 3.0713899718574686,
        "median_pred_length": 22.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.22377861291424667,
        "vocab_size-1": 1965,
        "unique-1": 1199,
        "entropy-1": 8.578591113795742,
        "distinct-2": 0.6466587112171838,
        "vocab_size-2": 5419,
        "unique-2": 4509,
        "entropy-2": 11.764764546661937,
        "cond_entropy-2": 3.1627573709906467,
        "distinct-3": 0.878806868028575,
        "vocab_size-3": 7012,
        "unique-3": 6544,
        "entropy-3": 12.615834555865657,
        "cond_entropy-3": 0.8652082418101676,
        "total_length-nopunct": 8308,
        "mean_pred_length-nopunct": 20.718204488778056,
        "std_pred_length-nopunct": 3.1493011167986347,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.23531535869041886,
        "vocab_size-1-nopunct": 1955,
        "unique-1-nopunct": 1197,
        "entropy-1-nopunct": 8.65324073444883,
        "distinct-2-nopunct": 0.6628304034399899,
        "vocab_size-2-nopunct": 5241,
        "unique-2-nopunct": 4413,
        "entropy-2-nopunct": 11.736098469245487,
        "cond_entropy-2-nopunct": 3.172426820399936,
        "distinct-3-nopunct": 0.8930189181987743,
        "vocab_size-3-nopunct": 6703,
        "unique-3-nopunct": 6300,
        "entropy-3-nopunct": 12.57070488409185,
        "cond_entropy-3-nopunct": 0.8418173746326338,
        "msttr-100": 0.72851,
        "msttr-100_nopunct": 0.73807,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_covid.json",
        "local_recall": {
            "1": 0.2689812590100913
        },
        "nist": 2.4342654753817086,
        "bleu": 5.36018,
        "rouge1": {
            "precision": 0.30389,
            "recall": 0.28811,
            "fmeasure": 0.28935
        },
        "rouge2": {
            "precision": 0.09101,
            "recall": 0.08692,
            "fmeasure": 0.08713
        },
        "rougeL": {
            "precision": 0.22986,
            "recall": 0.21877,
            "fmeasure": 0.21902
        },
        "rougeLsum": {
            "precision": 0.22986,
            "recall": 0.21877,
            "fmeasure": 0.21902
        },
        "nubia": {
            "semantic_relation": 2.11178,
            "contradiction": 23.0753,
            "irrelevancy": 68.07685,
            "logical_agreement": 8.84785,
            "grammar_ref": 4.04957,
            "grammar_hyp": 4.52979,
            "nubia_score": 0.23261
        },
        "meteor": 0.12229698507269447,
        "bleurt": -0.70319,
        "bertscore": {
            "precision": 0.78917,
            "recall": 0.78208,
            "f1": 0.78535
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_23": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 7,
        "total_length": 112,
        "mean_pred_length": 16.0,
        "std_pred_length": 5.477225575051661,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.625,
        "vocab_size-1": 70,
        "unique-1": 53,
        "entropy-1": 5.766771552022023,
        "distinct-2": 0.9047619047619048,
        "vocab_size-2": 95,
        "unique-2": 87,
        "entropy-2": 6.509390517624905,
        "cond_entropy-2": 0.6396603568905114,
        "distinct-3": 0.9591836734693877,
        "vocab_size-3": 94,
        "unique-3": 91,
        "entropy-3": 6.525374257358448,
        "cond_entropy-3": 0.03061623973646835,
        "total_length-nopunct": 97,
        "mean_pred_length-nopunct": 13.857142857142858,
        "std_pred_length-nopunct": 5.3566666455007645,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6804123711340206,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.760901728937093,
        "distinct-2-nopunct": 0.9222222222222223,
        "vocab_size-2-nopunct": 83,
        "unique-2-nopunct": 77,
        "entropy-2-nopunct": 6.32790990186118,
        "cond_entropy-2-nopunct": 0.6035427872799864,
        "distinct-3-nopunct": 0.9759036144578314,
        "vocab_size-3-nopunct": 81,
        "unique-3-nopunct": 79,
        "entropy-3-nopunct": 6.326846660262595,
        "cond_entropy-3-nopunct": 0.012763292874641419,
        "msttr-100": 0.65,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3076923076923077,
            "3": 0.64
        },
        "nist": 4.0493030817663085,
        "bleu": 24.63431,
        "rouge1": {
            "precision": 0.64533,
            "recall": 0.64142,
            "fmeasure": 0.63208
        },
        "rouge2": {
            "precision": 0.3961,
            "recall": 0.39243,
            "fmeasure": 0.38698
        },
        "rougeL": {
            "precision": 0.54423,
            "recall": 0.52047,
            "fmeasure": 0.52478
        },
        "rougeLsum": {
            "precision": 0.54423,
            "recall": 0.52047,
            "fmeasure": 0.52478
        },
        "nubia": {
            "semantic_relation": 4.04845,
            "contradiction": 1.01824,
            "irrelevancy": 42.74782,
            "logical_agreement": 56.23394,
            "grammar_ref": 4.51794,
            "grammar_hyp": 4.34319,
            "nubia_score": 0.69036
        },
        "meteor": 0.29354166228531564,
        "bleurt": 0.17333,
        "bertscore": {
            "precision": 0.90153,
            "recall": 0.89435,
            "f1": 0.89416
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_221": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 62,
        "mean_pred_length": 12.4,
        "std_pred_length": 5.713142742834281,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.5806451612903226,
        "vocab_size-1": 36,
        "unique-1": 24,
        "entropy-1": 4.885828069136431,
        "distinct-2": 0.8421052631578947,
        "vocab_size-2": 48,
        "unique-2": 41,
        "entropy-2": 5.490613259702861,
        "cond_entropy-2": 0.49482379989652847,
        "distinct-3": 0.9423076923076923,
        "vocab_size-3": 49,
        "unique-3": 46,
        "entropy-3": 5.585055102756479,
        "cond_entropy-3": 0.08889153098263752,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 10.8,
        "std_pred_length-nopunct": 4.955804677345546,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6296296296296297,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.831289298812965,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.29818382361874,
        "cond_entropy-2-nopunct": 0.4286524415490989,
        "distinct-3-nopunct": 0.9545454545454546,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.368522527728205,
        "cond_entropy-3-nopunct": 0.03426382004219399,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.7142857142857143
        },
        "nist": 3.357249176963539,
        "bleu": 29.37357,
        "rouge1": {
            "precision": 0.80812,
            "recall": 0.69516,
            "fmeasure": 0.74006
        },
        "rouge2": {
            "precision": 0.6035,
            "recall": 0.52384,
            "fmeasure": 0.5556
        },
        "rougeL": {
            "precision": 0.65641,
            "recall": 0.57006,
            "fmeasure": 0.60506
        },
        "rougeLsum": {
            "precision": 0.65641,
            "recall": 0.57006,
            "fmeasure": 0.60506
        },
        "nubia": {
            "semantic_relation": 4.33197,
            "contradiction": 5.09531,
            "irrelevancy": 4.32738,
            "logical_agreement": 90.57731,
            "grammar_ref": 3.91039,
            "grammar_hyp": 4.14609,
            "nubia_score": 0.78663
        },
        "meteor": 0.3463920029633669,
        "bleurt": 0.28666,
        "bertscore": {
            "precision": 0.94037,
            "recall": 0.92803,
            "f1": 0.93404
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_24": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 169,
        "total_length": 2804,
        "mean_pred_length": 16.59171597633136,
        "std_pred_length": 5.52285643569262,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.40192582025677603,
        "vocab_size-1": 1127,
        "unique-1": 866,
        "entropy-1": 8.37135143614052,
        "distinct-2": 0.7844402277039848,
        "vocab_size-2": 2067,
        "unique-2": 1854,
        "entropy-2": 10.662501605523424,
        "cond_entropy-2": 2.0638943856096197,
        "distinct-3": 0.9087591240875912,
        "vocab_size-3": 2241,
        "unique-3": 2141,
        "entropy-3": 11.002754034447449,
        "cond_entropy-3": 0.35145770881885197,
        "total_length-nopunct": 2441,
        "mean_pred_length-nopunct": 14.44378698224852,
        "std_pred_length-nopunct": 4.982642045485508,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.45759934453092993,
        "vocab_size-1-nopunct": 1117,
        "unique-1-nopunct": 864,
        "entropy-1-nopunct": 8.669931026717704,
        "distinct-2-nopunct": 0.8028169014084507,
        "vocab_size-2-nopunct": 1824,
        "unique-2-nopunct": 1662,
        "entropy-2-nopunct": 10.487615226323792,
        "cond_entropy-2-nopunct": 1.933777297367864,
        "distinct-3-nopunct": 0.912981455064194,
        "vocab_size-3-nopunct": 1920,
        "unique-3-nopunct": 1839,
        "entropy-3-nopunct": 10.785951257986767,
        "cond_entropy-3-nopunct": 0.3319846063473947,
        "msttr-100": 0.70929,
        "msttr-100_nopunct": 0.75583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22594142259414227,
            "2": 0.42247191011235957,
            "3": 0.7927350427350427
        },
        "nist": 8.114770997431204,
        "bleu": 49.04124,
        "rouge1": {
            "precision": 0.77961,
            "recall": 0.75387,
            "fmeasure": 0.75545
        },
        "rouge2": {
            "precision": 0.56862,
            "recall": 0.54677,
            "fmeasure": 0.54922
        },
        "rougeL": {
            "precision": 0.69346,
            "recall": 0.67637,
            "fmeasure": 0.67475
        },
        "rougeLsum": {
            "precision": 0.69346,
            "recall": 0.67637,
            "fmeasure": 0.67475
        },
        "nubia": {
            "semantic_relation": 4.19618,
            "contradiction": 6.68891,
            "irrelevancy": 29.97849,
            "logical_agreement": 63.33261,
            "grammar_ref": 4.66226,
            "grammar_hyp": 4.68765,
            "nubia_score": 0.72883
        },
        "meteor": 0.40228387018780215,
        "bleurt": 0.2912,
        "bertscore": {
            "precision": 0.9326,
            "recall": 0.92895,
            "f1": 0.92935
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_135": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 23,
        "total_length": 386,
        "mean_pred_length": 16.782608695652176,
        "std_pred_length": 4.323409702489061,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.572538860103627,
        "vocab_size-1": 221,
        "unique-1": 175,
        "entropy-1": 7.041241236287364,
        "distinct-2": 0.8980716253443526,
        "vocab_size-2": 326,
        "unique-2": 297,
        "entropy-2": 8.276472225563323,
        "cond_entropy-2": 1.0469005166402303,
        "distinct-3": 0.95,
        "vocab_size-3": 323,
        "unique-3": 306,
        "entropy-3": 8.309390936137682,
        "cond_entropy-3": 0.03065144818012966,
        "total_length-nopunct": 342,
        "mean_pred_length-nopunct": 14.869565217391305,
        "std_pred_length-nopunct": 3.6866899001217526,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6286549707602339,
        "vocab_size-1-nopunct": 215,
        "unique-1-nopunct": 173,
        "entropy-1-nopunct": 7.1397475942745565,
        "distinct-2-nopunct": 0.9028213166144201,
        "vocab_size-2-nopunct": 288,
        "unique-2-nopunct": 265,
        "entropy-2-nopunct": 8.096317551028312,
        "cond_entropy-2-nopunct": 1.0108633660860087,
        "distinct-3-nopunct": 0.9594594594594594,
        "vocab_size-3-nopunct": 284,
        "unique-3-nopunct": 272,
        "entropy-3-nopunct": 8.12837228454783,
        "cond_entropy-3-nopunct": 0.03176845460576416,
        "msttr-100": 0.76333,
        "msttr-100_nopunct": 0.79667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.5072463768115942,
            "3": 0.8596491228070176
        },
        "nist": 6.288458502350013,
        "bleu": 46.93312,
        "rouge1": {
            "precision": 0.75778,
            "recall": 0.76041,
            "fmeasure": 0.75416
        },
        "rouge2": {
            "precision": 0.54355,
            "recall": 0.54822,
            "fmeasure": 0.54194
        },
        "rougeL": {
            "precision": 0.65364,
            "recall": 0.65239,
            "fmeasure": 0.64821
        },
        "rougeLsum": {
            "precision": 0.65364,
            "recall": 0.65239,
            "fmeasure": 0.64821
        },
        "nubia": {
            "semantic_relation": 4.24411,
            "contradiction": 10.842,
            "irrelevancy": 37.99909,
            "logical_agreement": 51.15891,
            "grammar_ref": 4.82223,
            "grammar_hyp": 4.72637,
            "nubia_score": 0.74692
        },
        "meteor": 0.41716985025814474,
        "bleurt": 0.27917,
        "bertscore": {
            "precision": 0.9272,
            "recall": 0.93477,
            "f1": 0.92994
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_136": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 23,
        "total_length": 406,
        "mean_pred_length": 17.652173913043477,
        "std_pred_length": 5.752947793747162,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 30,
        "distinct-1": 0.583743842364532,
        "vocab_size-1": 237,
        "unique-1": 191,
        "entropy-1": 7.166545175677458,
        "distinct-2": 0.9295039164490861,
        "vocab_size-2": 356,
        "unique-2": 334,
        "entropy-2": 8.429073525772205,
        "cond_entropy-2": 1.1418013639308942,
        "distinct-3": 0.9833333333333333,
        "vocab_size-3": 354,
        "unique-3": 348,
        "entropy-3": 8.45851976299632,
        "cond_entropy-3": 0.03916546581163538,
        "total_length-nopunct": 354,
        "mean_pred_length-nopunct": 15.391304347826088,
        "std_pred_length-nopunct": 4.9584283137053635,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.652542372881356,
        "vocab_size-1-nopunct": 231,
        "unique-1-nopunct": 191,
        "entropy-1-nopunct": 7.290938311637542,
        "distinct-2-nopunct": 0.9365558912386707,
        "vocab_size-2-nopunct": 310,
        "unique-2-nopunct": 293,
        "entropy-2-nopunct": 8.233195639422497,
        "cond_entropy-2-nopunct": 1.0101678534149592,
        "distinct-3-nopunct": 0.987012987012987,
        "vocab_size-3-nopunct": 304,
        "unique-3-nopunct": 300,
        "entropy-3-nopunct": 8.240812514720833,
        "cond_entropy-3-nopunct": 0.011390611174459463,
        "msttr-100": 0.6975,
        "msttr-100_nopunct": 0.74667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2619047619047619,
            "2": 0.3493975903614458,
            "3": 0.6995884773662552
        },
        "nist": 5.836564254715127,
        "bleu": 41.73907,
        "rouge1": {
            "precision": 0.7026,
            "recall": 0.68762,
            "fmeasure": 0.6803
        },
        "rouge2": {
            "precision": 0.47127,
            "recall": 0.47344,
            "fmeasure": 0.46076
        },
        "rougeL": {
            "precision": 0.63469,
            "recall": 0.63172,
            "fmeasure": 0.61956
        },
        "rougeLsum": {
            "precision": 0.63469,
            "recall": 0.63172,
            "fmeasure": 0.61956
        },
        "nubia": {
            "semantic_relation": 4.01177,
            "contradiction": 6.22402,
            "irrelevancy": 43.58618,
            "logical_agreement": 50.18979,
            "grammar_ref": 4.55066,
            "grammar_hyp": 4.40419,
            "nubia_score": 0.6678
        },
        "meteor": 0.3578021859919517,
        "bleurt": 0.16354,
        "bertscore": {
            "precision": 0.91376,
            "recall": 0.91057,
            "f1": 0.91081
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_138": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 19,
        "total_length": 293,
        "mean_pred_length": 15.421052631578947,
        "std_pred_length": 4.782817815931087,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.5631399317406144,
        "vocab_size-1": 165,
        "unique-1": 127,
        "entropy-1": 6.7467328383718765,
        "distinct-2": 0.9087591240875912,
        "vocab_size-2": 249,
        "unique-2": 229,
        "entropy-2": 7.899985869433149,
        "cond_entropy-2": 1.020086813196225,
        "distinct-3": 0.9764705882352941,
        "vocab_size-3": 249,
        "unique-3": 244,
        "entropy-3": 7.944334270183719,
        "cond_entropy-3": 0.0512616480329468,
        "total_length-nopunct": 258,
        "mean_pred_length-nopunct": 13.578947368421053,
        "std_pred_length-nopunct": 4.934473677193357,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6201550387596899,
        "vocab_size-1-nopunct": 160,
        "unique-1-nopunct": 126,
        "entropy-1-nopunct": 6.805600295136823,
        "distinct-2-nopunct": 0.9079497907949791,
        "vocab_size-2-nopunct": 217,
        "unique-2-nopunct": 200,
        "entropy-2-nopunct": 7.698922613392966,
        "cond_entropy-2-nopunct": 0.9710837582165565,
        "distinct-3-nopunct": 0.9772727272727273,
        "vocab_size-3-nopunct": 215,
        "unique-3-nopunct": 211,
        "entropy-3-nopunct": 7.732473861242084,
        "cond_entropy-3-nopunct": 0.05099188283630624,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.74,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2077922077922078,
            "2": 0.23529411764705882,
            "3": 0.6724137931034483
        },
        "nist": 5.1942868555768085,
        "bleu": 44.03198,
        "rouge1": {
            "precision": 0.76549,
            "recall": 0.65997,
            "fmeasure": 0.69724
        },
        "rouge2": {
            "precision": 0.56203,
            "recall": 0.497,
            "fmeasure": 0.51843
        },
        "rougeL": {
            "precision": 0.68882,
            "recall": 0.60185,
            "fmeasure": 0.6337
        },
        "rougeLsum": {
            "precision": 0.68882,
            "recall": 0.60185,
            "fmeasure": 0.6337
        },
        "nubia": {
            "semantic_relation": 3.97961,
            "contradiction": 11.80314,
            "irrelevancy": 28.51444,
            "logical_agreement": 59.68242,
            "grammar_ref": 4.44575,
            "grammar_hyp": 4.48319,
            "nubia_score": 0.66296
        },
        "meteor": 0.36941802450043193,
        "bleurt": 0.14908,
        "bertscore": {
            "precision": 0.91877,
            "recall": 0.90005,
            "f1": 0.90838
        }
    },
    "web_nlg_ru_challenge_test_scramble_parent": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 500,
        "total_length": 5616,
        "mean_pred_length": 11.232,
        "std_pred_length": 2.8993406146915546,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 21,
        "distinct-1": 0.2980769230769231,
        "vocab_size-1": 1674,
        "unique-1": 1022,
        "entropy-1": 8.904066502428902,
        "distinct-2": 0.6180609851446442,
        "vocab_size-2": 3162,
        "unique-2": 2399,
        "entropy-2": 11.152859945742989,
        "cond_entropy-2": 2.2762269547233145,
        "distinct-3": 0.8028596187175043,
        "vocab_size-3": 3706,
        "unique-3": 3170,
        "entropy-3": 11.688921980025812,
        "cond_entropy-3": 0.6139569222381864,
        "total_length-nopunct": 4776,
        "mean_pred_length-nopunct": 9.552,
        "std_pred_length-nopunct": 2.552507786471963,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.34882747068676717,
        "vocab_size-1-nopunct": 1666,
        "unique-1-nopunct": 1021,
        "entropy-1-nopunct": 9.405583133022715,
        "distinct-2-nopunct": 0.6580916744621141,
        "vocab_size-2-nopunct": 2814,
        "unique-2-nopunct": 2215,
        "entropy-2-nopunct": 11.048052276407653,
        "cond_entropy-2-nopunct": 1.8231221307596517,
        "distinct-3-nopunct": 0.8188559322033898,
        "vocab_size-3-nopunct": 3092,
        "unique-3-nopunct": 2694,
        "entropy-3-nopunct": 11.43541130882946,
        "cond_entropy-3-nopunct": 0.47882573422110625,
        "msttr-100": 0.67411,
        "msttr-100_nopunct": 0.72532,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.17226205997392438,
            "2": 0.3463636363636364,
            "3": 0.5114116652578191,
            "4": 0.6666666666666666,
            "5": 0.6,
            "6": 1.0
        },
        "nist": 1.6297882066282396,
        "bleu": 22.15211,
        "rouge1": {
            "precision": 0.28172,
            "recall": 0.22994,
            "fmeasure": 0.24446
        },
        "rouge2": {
            "precision": 0.13254,
            "recall": 0.10285,
            "fmeasure": 0.10991
        },
        "rougeL": {
            "precision": 0.27471,
            "recall": 0.22364,
            "fmeasure": 0.23788
        },
        "rougeLsum": {
            "precision": 0.27471,
            "recall": 0.22364,
            "fmeasure": 0.23788
        },
        "nubia": {
            "semantic_relation": 3.60778,
            "contradiction": 21.47452,
            "irrelevancy": 21.8507,
            "logical_agreement": 56.67478,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.72763,
            "nubia_score": 0.70373
        },
        "meteor": 0.4006704204950873,
        "bleurt": 0.11959,
        "bertscore": {
            "precision": 0.95179,
            "recall": 0.91532,
            "f1": 0.93233
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_25": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 56,
        "total_length": 927,
        "mean_pred_length": 16.553571428571427,
        "std_pred_length": 5.545009477182236,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.5275080906148867,
        "vocab_size-1": 489,
        "unique-1": 400,
        "entropy-1": 7.894053860632535,
        "distinct-2": 0.9024110218140069,
        "vocab_size-2": 786,
        "unique-2": 738,
        "entropy-2": 9.525929432720632,
        "cond_entropy-2": 1.444251445759623,
        "distinct-3": 0.9693251533742331,
        "vocab_size-3": 790,
        "unique-3": 771,
        "entropy-3": 9.603147598801284,
        "cond_entropy-3": 0.07705120923968342,
        "total_length-nopunct": 811,
        "mean_pred_length-nopunct": 14.482142857142858,
        "std_pred_length-nopunct": 5.130410285140707,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.593094944512947,
        "vocab_size-1-nopunct": 481,
        "unique-1-nopunct": 399,
        "entropy-1-nopunct": 8.10902236907043,
        "distinct-2-nopunct": 0.9125827814569536,
        "vocab_size-2-nopunct": 689,
        "unique-2-nopunct": 652,
        "entropy-2-nopunct": 9.343527747445398,
        "cond_entropy-2-nopunct": 1.3210243634644379,
        "distinct-3-nopunct": 0.9699570815450643,
        "vocab_size-3-nopunct": 678,
        "unique-3-nopunct": 662,
        "entropy-3-nopunct": 9.38296171761237,
        "cond_entropy-3-nopunct": 0.05453571889095025,
        "msttr-100": 0.74889,
        "msttr-100_nopunct": 0.8025,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20634920634920634,
            "2": 0.43670886075949367,
            "3": 0.7523364485981309
        },
        "nist": 6.9240650716833345,
        "bleu": 45.6088,
        "rouge1": {
            "precision": 0.76261,
            "recall": 0.70588,
            "fmeasure": 0.7201
        },
        "rouge2": {
            "precision": 0.53885,
            "recall": 0.49535,
            "fmeasure": 0.50643
        },
        "rougeL": {
            "precision": 0.66822,
            "recall": 0.61276,
            "fmeasure": 0.6277
        },
        "rougeLsum": {
            "precision": 0.66822,
            "recall": 0.61276,
            "fmeasure": 0.6277
        },
        "nubia": {
            "semantic_relation": 4.21188,
            "contradiction": 6.57343,
            "irrelevancy": 33.7506,
            "logical_agreement": 59.67597,
            "grammar_ref": 4.75668,
            "grammar_hyp": 4.96252,
            "nubia_score": 0.70993
        },
        "meteor": 0.3924111525301927,
        "bleurt": 0.22366,
        "bertscore": {
            "precision": 0.92544,
            "recall": 0.91879,
            "f1": 0.92085
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_156": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 32,
        "total_length": 615,
        "mean_pred_length": 19.21875,
        "std_pred_length": 5.856270010638171,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 32,
        "distinct-1": 0.5382113821138211,
        "vocab_size-1": 331,
        "unique-1": 261,
        "entropy-1": 7.4471941775237065,
        "distinct-2": 0.8576329331046312,
        "vocab_size-2": 500,
        "unique-2": 447,
        "entropy-2": 8.819210938652985,
        "cond_entropy-2": 1.2802978709207684,
        "distinct-3": 0.9346642468239564,
        "vocab_size-3": 515,
        "unique-3": 481,
        "entropy-3": 8.972496938690298,
        "cond_entropy-3": 0.1595304034905293,
        "total_length-nopunct": 557,
        "mean_pred_length-nopunct": 17.40625,
        "std_pred_length-nopunct": 5.413290213677815,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5834829443447038,
        "vocab_size-1-nopunct": 325,
        "unique-1-nopunct": 261,
        "entropy-1-nopunct": 7.524655268982754,
        "distinct-2-nopunct": 0.8590476190476191,
        "vocab_size-2-nopunct": 451,
        "unique-2-nopunct": 404,
        "entropy-2-nopunct": 8.665961005058676,
        "cond_entropy-2-nopunct": 1.2097752079870037,
        "distinct-3-nopunct": 0.9371196754563894,
        "vocab_size-3-nopunct": 462,
        "unique-3-nopunct": 431,
        "entropy-3-nopunct": 8.81968318729072,
        "cond_entropy-3-nopunct": 0.16083567804731458,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.748,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23469387755102042,
            "2": 0.3855421686746988,
            "3": 0.826530612244898
        },
        "nist": 6.798170416436569,
        "bleu": 49.02705,
        "rouge1": {
            "precision": 0.76474,
            "recall": 0.76311,
            "fmeasure": 0.75486
        },
        "rouge2": {
            "precision": 0.56062,
            "recall": 0.56589,
            "fmeasure": 0.55584
        },
        "rougeL": {
            "precision": 0.66472,
            "recall": 0.66697,
            "fmeasure": 0.65777
        },
        "rougeLsum": {
            "precision": 0.66472,
            "recall": 0.66697,
            "fmeasure": 0.65777
        },
        "nubia": {
            "semantic_relation": 4.29421,
            "contradiction": 11.02267,
            "irrelevancy": 27.54524,
            "logical_agreement": 61.43209,
            "grammar_ref": 4.40347,
            "grammar_hyp": 4.38048,
            "nubia_score": 0.75972
        },
        "meteor": 0.39737349106705244,
        "bleurt": 0.27637,
        "bertscore": {
            "precision": 0.93227,
            "recall": 0.92848,
            "f1": 0.92965
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_159": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 43,
        "mean_pred_length": 21.5,
        "std_pred_length": 4.5,
        "median_pred_length": 21.5,
        "min_pred_length": 17,
        "max_pred_length": 26,
        "distinct-1": 0.813953488372093,
        "vocab_size-1": 35,
        "unique-1": 29,
        "entropy-1": 5.0076601035393065,
        "distinct-2": 1.0,
        "vocab_size-2": 41,
        "unique-2": 41,
        "entropy-2": 5.357552004618081,
        "cond_entropy-2": 0.3459213962574491,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.07214978575583503,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.825,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.921928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.247927513443589,
        "cond_entropy-2-nopunct": 0.3207362606614863,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.0780025120012732,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.6363636363636364,
            "3": 0.34615384615384615
        },
        "nist": 2.1371390745720427,
        "bleu": 10.0599,
        "rouge1": {
            "precision": 0.46923,
            "recall": 0.49538,
            "fmeasure": 0.47658
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.29722,
            "fmeasure": 0.26972
        },
        "rougeL": {
            "precision": 0.40923,
            "recall": 0.44699,
            "fmeasure": 0.42301
        },
        "rougeLsum": {
            "precision": 0.40923,
            "recall": 0.44699,
            "fmeasure": 0.42301
        },
        "nubia": {
            "semantic_relation": 3.16547,
            "contradiction": 35.78048,
            "irrelevancy": 55.59348,
            "logical_agreement": 8.62605,
            "grammar_ref": 4.83168,
            "grammar_hyp": 4.84325,
            "nubia_score": 0.38734
        },
        "meteor": 0.1978611859747151,
        "bleurt": -0.51802,
        "bertscore": {
            "precision": 0.83954,
            "recall": 0.83965,
            "f1": 0.83827
        }
    },
    "web_nlg_en_challenge_test_scramble_parent": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 500,
        "total_length": 9383,
        "mean_pred_length": 18.766,
        "std_pred_length": 6.567742686798867,
        "median_pred_length": 20.5,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.13481828839390386,
        "vocab_size-1": 1265,
        "unique-1": 504,
        "entropy-1": 8.05074354966074,
        "distinct-2": 0.38264099966227627,
        "vocab_size-2": 3399,
        "unique-2": 2013,
        "entropy-2": 10.852158506313275,
        "cond_entropy-2": 2.7398176446710307,
        "distinct-3": 0.5785518310867231,
        "vocab_size-3": 4850,
        "unique-3": 3473,
        "entropy-3": 11.753717947145752,
        "cond_entropy-3": 0.984639328335534,
        "total_length-nopunct": 8527,
        "mean_pred_length-nopunct": 17.054,
        "std_pred_length-nopunct": 6.259958785806821,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.1472968218599742,
        "vocab_size-1-nopunct": 1256,
        "unique-1-nopunct": 502,
        "entropy-1-nopunct": 8.22262125723075,
        "distinct-2-nopunct": 0.38694406378472657,
        "vocab_size-2-nopunct": 3106,
        "unique-2-nopunct": 1874,
        "entropy-2-nopunct": 10.718700224411082,
        "cond_entropy-2-nopunct": 2.667062626638181,
        "distinct-3-nopunct": 0.5785837651122625,
        "vocab_size-3-nopunct": 4355,
        "unique-3-nopunct": 3150,
        "entropy-3-nopunct": 11.585509765226846,
        "cond_entropy-3-nopunct": 0.9476044741019527,
        "msttr-100": 0.52548,
        "msttr-100_nopunct": 0.52824,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.18798181458786323,
            "2": 0.5188327112317611,
            "3": 0.7543006731488406,
            "4": 0.2,
            "5": 0.7222222222222222
        },
        "nist": 6.825858554898038,
        "bleu": 41.00032,
        "rouge1": {
            "precision": 0.79022,
            "recall": 0.68556,
            "fmeasure": 0.72202
        },
        "rouge2": {
            "precision": 0.53985,
            "recall": 0.46713,
            "fmeasure": 0.49162
        },
        "rougeL": {
            "precision": 0.65953,
            "recall": 0.57403,
            "fmeasure": 0.60321
        },
        "rougeLsum": {
            "precision": 0.65953,
            "recall": 0.57403,
            "fmeasure": 0.60321
        },
        "nubia": {
            "semantic_relation": 4.14462,
            "contradiction": 8.98328,
            "irrelevancy": 9.72356,
            "logical_agreement": 81.29315,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.82282,
            "nubia_score": 0.67602
        },
        "meteor": 0.33220078923487606,
        "bleurt": 0.06529,
        "bertscore": {
            "precision": 0.92347,
            "recall": 0.90332,
            "f1": 0.91174
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_222": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 11,
        "total_length": 187,
        "mean_pred_length": 17.0,
        "std_pred_length": 4.880387465988926,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.6737967914438503,
        "vocab_size-1": 126,
        "unique-1": 108,
        "entropy-1": 6.473012904720787,
        "distinct-2": 0.9431818181818182,
        "vocab_size-2": 166,
        "unique-2": 162,
        "entropy-2": 7.309633164224804,
        "cond_entropy-2": 0.7476305997192064,
        "distinct-3": 1.0,
        "vocab_size-3": 165,
        "unique-3": 165,
        "entropy-3": 7.366322214245809,
        "cond_entropy-3": 0.052603322164354385,
        "total_length-nopunct": 164,
        "mean_pred_length-nopunct": 14.909090909090908,
        "std_pred_length-nopunct": 4.756900164345866,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7378048780487805,
        "vocab_size-1-nopunct": 121,
        "unique-1-nopunct": 107,
        "entropy-1-nopunct": 6.49455421009947,
        "distinct-2-nopunct": 0.934640522875817,
        "vocab_size-2-nopunct": 143,
        "unique-2-nopunct": 139,
        "entropy-2-nopunct": 7.085070666374984,
        "cond_entropy-2-nopunct": 0.6218402211223679,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 142,
        "unique-3-nopunct": 142,
        "entropy-3-nopunct": 7.149747119504689,
        "cond_entropy-3-nopunct": 0.061673360486065074,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.10810810810810811,
            "2": 0.65,
            "3": 0.5966386554621849
        },
        "nist": 4.250185123181625,
        "bleu": 30.68105,
        "rouge1": {
            "precision": 0.71019,
            "recall": 0.67118,
            "fmeasure": 0.66544
        },
        "rouge2": {
            "precision": 0.44308,
            "recall": 0.41551,
            "fmeasure": 0.41325
        },
        "rougeL": {
            "precision": 0.57329,
            "recall": 0.5455,
            "fmeasure": 0.53489
        },
        "rougeLsum": {
            "precision": 0.57329,
            "recall": 0.5455,
            "fmeasure": 0.53489
        },
        "nubia": {
            "semantic_relation": 3.66996,
            "contradiction": 5.99209,
            "irrelevancy": 42.63292,
            "logical_agreement": 51.37499,
            "grammar_ref": 4.70623,
            "grammar_hyp": 5.15563,
            "nubia_score": 0.54644
        },
        "meteor": 0.3035703143704133,
        "bleurt": -0.01927,
        "bertscore": {
            "precision": 0.90507,
            "recall": 0.90129,
            "f1": 0.9015
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_140": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 42,
        "total_length": 689,
        "mean_pred_length": 16.404761904761905,
        "std_pred_length": 5.066507784834328,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.5384615384615384,
        "vocab_size-1": 371,
        "unique-1": 287,
        "entropy-1": 7.569423276940529,
        "distinct-2": 0.8918083462132921,
        "vocab_size-2": 577,
        "unique-2": 528,
        "entropy-2": 9.06778081787505,
        "cond_entropy-2": 1.2939911887455304,
        "distinct-3": 0.9735537190082645,
        "vocab_size-3": 589,
        "unique-3": 574,
        "entropy-3": 9.186651022240998,
        "cond_entropy-3": 0.13099140359389094,
        "total_length-nopunct": 614,
        "mean_pred_length-nopunct": 14.619047619047619,
        "std_pred_length-nopunct": 4.830224193517024,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5944625407166124,
        "vocab_size-1-nopunct": 365,
        "unique-1-nopunct": 286,
        "entropy-1-nopunct": 7.753758107987743,
        "distinct-2-nopunct": 0.8951048951048951,
        "vocab_size-2-nopunct": 512,
        "unique-2-nopunct": 472,
        "entropy-2-nopunct": 8.890933759992096,
        "cond_entropy-2-nopunct": 1.2266515575438635,
        "distinct-3-nopunct": 0.9830188679245283,
        "vocab_size-3-nopunct": 521,
        "unique-3-nopunct": 512,
        "entropy-3-nopunct": 9.015886285299631,
        "cond_entropy-3-nopunct": 0.13950047950437366,
        "msttr-100": 0.71167,
        "msttr-100_nopunct": 0.76167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.5,
            "3": 0.8
        },
        "nist": 6.639443749982467,
        "bleu": 40.87616,
        "rouge1": {
            "precision": 0.76196,
            "recall": 0.76965,
            "fmeasure": 0.75943
        },
        "rouge2": {
            "precision": 0.50418,
            "recall": 0.51659,
            "fmeasure": 0.50631
        },
        "rougeL": {
            "precision": 0.63213,
            "recall": 0.64983,
            "fmeasure": 0.63501
        },
        "rougeLsum": {
            "precision": 0.63213,
            "recall": 0.64983,
            "fmeasure": 0.63501
        },
        "nubia": {
            "semantic_relation": 4.34803,
            "contradiction": 5.74413,
            "irrelevancy": 25.55003,
            "logical_agreement": 68.70584,
            "grammar_ref": 4.66791,
            "grammar_hyp": 4.53019,
            "nubia_score": 0.79381
        },
        "meteor": 0.3994492468058015,
        "bleurt": 0.29707,
        "bertscore": {
            "precision": 0.92958,
            "recall": 0.92828,
            "f1": 0.92729
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_86": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9565217391304348,
        "vocab_size-1": 22,
        "unique-1": 21,
        "entropy-1": 4.436605434317882,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.026778753489375355,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.021369002496408336,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9230769230769231
        },
        "nist": 2.608695652173913,
        "bleu": 48.06216,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.92308,
            "fmeasure": 0.72727
        },
        "rouge2": {
            "precision": 0.47368,
            "recall": 0.75,
            "fmeasure": 0.58065
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.92308,
            "fmeasure": 0.72727
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.92308,
            "fmeasure": 0.72727
        },
        "nubia": {
            "semantic_relation": 3.83104,
            "contradiction": 0.17281,
            "irrelevancy": 99.71393,
            "logical_agreement": 0.11326,
            "grammar_ref": 3.82301,
            "grammar_hyp": 3.48,
            "nubia_score": 0.7756
        },
        "meteor": 0.5194825265249872,
        "bleurt": 0.47867,
        "bertscore": {
            "precision": 0.91266,
            "recall": 0.97795,
            "f1": 0.94418
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_160": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 29,
        "total_length": 451,
        "mean_pred_length": 15.551724137931034,
        "std_pred_length": 4.839394425613471,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.5853658536585366,
        "vocab_size-1": 264,
        "unique-1": 218,
        "entropy-1": 7.261322410106509,
        "distinct-2": 0.9265402843601895,
        "vocab_size-2": 391,
        "unique-2": 368,
        "entropy-2": 8.549520108241367,
        "cond_entropy-2": 1.0946379351228093,
        "distinct-3": 0.9847328244274809,
        "vocab_size-3": 387,
        "unique-3": 381,
        "entropy-3": 8.587851151113615,
        "cond_entropy-3": 0.05099209461138784,
        "total_length-nopunct": 391,
        "mean_pred_length-nopunct": 13.482758620689655,
        "std_pred_length-nopunct": 4.239556659118257,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.659846547314578,
        "vocab_size-1-nopunct": 258,
        "unique-1-nopunct": 217,
        "entropy-1-nopunct": 7.441332087667652,
        "distinct-2-nopunct": 0.925414364640884,
        "vocab_size-2-nopunct": 335,
        "unique-2-nopunct": 315,
        "entropy-2-nopunct": 8.32401305709865,
        "cond_entropy-2-nopunct": 0.940004625724186,
        "distinct-3-nopunct": 0.987987987987988,
        "vocab_size-3-nopunct": 329,
        "unique-3-nopunct": 325,
        "entropy-3-nopunct": 8.355354343047267,
        "cond_entropy-3-nopunct": 0.03764504591719517,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.81,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26153846153846155,
            "2": 0.4897959183673469,
            "3": 0.8328358208955224
        },
        "nist": 7.51317494684517,
        "bleu": 60.6361,
        "rouge1": {
            "precision": 0.84704,
            "recall": 0.81361,
            "fmeasure": 0.82173
        },
        "rouge2": {
            "precision": 0.64779,
            "recall": 0.63235,
            "fmeasure": 0.63213
        },
        "rougeL": {
            "precision": 0.72871,
            "recall": 0.70874,
            "fmeasure": 0.71054
        },
        "rougeLsum": {
            "precision": 0.72871,
            "recall": 0.70874,
            "fmeasure": 0.71054
        },
        "nubia": {
            "semantic_relation": 4.5313,
            "contradiction": 6.34521,
            "irrelevancy": 19.80998,
            "logical_agreement": 73.84481,
            "grammar_ref": 4.52589,
            "grammar_hyp": 4.56006,
            "nubia_score": 0.83762
        },
        "meteor": 0.45419465711940993,
        "bleurt": 0.47015,
        "bertscore": {
            "precision": 0.95374,
            "recall": 0.94997,
            "f1": 0.95063
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_38": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 6,
        "total_length": 81,
        "mean_pred_length": 13.5,
        "std_pred_length": 2.565800719723442,
        "median_pred_length": 14.5,
        "min_pred_length": 10,
        "max_pred_length": 16,
        "distinct-1": 0.7037037037037037,
        "vocab_size-1": 57,
        "unique-1": 47,
        "entropy-1": 5.4734202563737036,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 70,
        "unique-2": 66,
        "entropy-2": 6.085420190467043,
        "cond_entropy-2": 0.45672592004958895,
        "distinct-3": 0.9710144927536232,
        "vocab_size-3": 67,
        "unique-3": 65,
        "entropy-3": 6.050553442285411,
        "cond_entropy-3": -0.022397313396502062,
        "total_length-nopunct": 73,
        "mean_pred_length-nopunct": 12.166666666666666,
        "std_pred_length-nopunct": 2.4776781245530843,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7534246575342466,
        "vocab_size-1-nopunct": 55,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.497642024455629,
        "distinct-2-nopunct": 0.9253731343283582,
        "vocab_size-2-nopunct": 62,
        "unique-2-nopunct": 58,
        "entropy-2-nopunct": 5.905568481470254,
        "cond_entropy-2-nopunct": 0.44006220636607407,
        "distinct-3-nopunct": 0.9672131147540983,
        "vocab_size-3-nopunct": 59,
        "unique-3-nopunct": 57,
        "entropy-3-nopunct": 5.865163567071079,
        "cond_entropy-3-nopunct": -0.04100943482663273,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.7333333333333333,
            "3": 0.8787878787878788
        },
        "nist": 4.110784697219382,
        "bleu": 43.34775,
        "rouge1": {
            "precision": 0.63706,
            "recall": 0.83743,
            "fmeasure": 0.71412
        },
        "rouge2": {
            "precision": 0.45647,
            "recall": 0.57461,
            "fmeasure": 0.50281
        },
        "rougeL": {
            "precision": 0.61276,
            "recall": 0.79616,
            "fmeasure": 0.68364
        },
        "rougeLsum": {
            "precision": 0.61276,
            "recall": 0.79616,
            "fmeasure": 0.68364
        },
        "nubia": {
            "semantic_relation": 4.18804,
            "contradiction": 3.8838,
            "irrelevancy": 45.3605,
            "logical_agreement": 50.7557,
            "grammar_ref": 5.1808,
            "grammar_hyp": 4.53503,
            "nubia_score": 0.67936
        },
        "meteor": 0.44308015731060574,
        "bleurt": 0.16655,
        "bertscore": {
            "precision": 0.91461,
            "recall": 0.94395,
            "f1": 0.92878
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_141": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 81,
        "mean_pred_length": 16.2,
        "std_pred_length": 5.706137047074842,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 63,
        "unique-1": 55,
        "entropy-1": 5.7482926329970425,
        "distinct-2": 1.0,
        "vocab_size-2": 76,
        "unique-2": 76,
        "entropy-2": 6.247927513443591,
        "cond_entropy-2": 0.4332899705707193,
        "distinct-3": 1.0,
        "vocab_size-3": 71,
        "unique-3": 71,
        "entropy-3": 6.149747119504677,
        "cond_entropy-3": -0.09818039393890347,
        "total_length-nopunct": 74,
        "mean_pred_length-nopunct": 14.8,
        "std_pred_length-nopunct": 5.344155686354955,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8243243243243243,
        "vocab_size-1-nopunct": 61,
        "unique-1-nopunct": 55,
        "entropy-1-nopunct": 5.734301210781249,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 69,
        "unique-2-nopunct": 69,
        "entropy-2-nopunct": 6.108524456778164,
        "cond_entropy-2-nopunct": 0.40865456156559854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 64,
        "unique-3-nopunct": 64,
        "entropy-3-nopunct": 6.0,
        "cond_entropy-3-nopunct": -0.10852445677816912,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.0,
            "3": 0.7083333333333334
        },
        "nist": 3.9949534224424794,
        "bleu": 35.75266,
        "rouge1": {
            "precision": 0.77388,
            "recall": 0.65399,
            "fmeasure": 0.70502
        },
        "rouge2": {
            "precision": 0.53265,
            "recall": 0.44948,
            "fmeasure": 0.48442
        },
        "rougeL": {
            "precision": 0.63085,
            "recall": 0.53951,
            "fmeasure": 0.57831
        },
        "rougeLsum": {
            "precision": 0.63085,
            "recall": 0.53951,
            "fmeasure": 0.57831
        },
        "nubia": {
            "semantic_relation": 4.26639,
            "contradiction": 0.51763,
            "irrelevancy": 22.53467,
            "logical_agreement": 76.94771,
            "grammar_ref": 4.6156,
            "grammar_hyp": 4.82275,
            "nubia_score": 0.74336
        },
        "meteor": 0.33548712591666446,
        "bleurt": 0.31418,
        "bertscore": {
            "precision": 0.93675,
            "recall": 0.90848,
            "f1": 0.92219
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_246": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 69,
        "mean_pred_length": 13.8,
        "std_pred_length": 4.749736834815167,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.7971014492753623,
        "vocab_size-1": 55,
        "unique-1": 46,
        "entropy-1": 5.628532928100429,
        "distinct-2": 1.0,
        "vocab_size-2": 64,
        "unique-2": 64,
        "entropy-2": 6.0,
        "cond_entropy-2": 0.22756577766443967,
        "distinct-3": 1.0,
        "vocab_size-3": 59,
        "unique-3": 59,
        "entropy-3": 5.882643049361836,
        "cond_entropy-3": -0.11735695063815871,
        "total_length-nopunct": 60,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.8987177379235853,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 51,
        "unique-1-nopunct": 44,
        "entropy-1-nopunct": 5.581727678869735,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 55,
        "unique-2-nopunct": 55,
        "entropy-2-nopunct": 5.7813597135246555,
        "cond_entropy-2-nopunct": 0.22919229981299444,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.643856189774728,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.75,
            "3": 0.7551020408163265
        },
        "nist": 5.508597892839826,
        "bleu": 60.25583,
        "rouge1": {
            "precision": 0.76572,
            "recall": 0.74011,
            "fmeasure": 0.74827
        },
        "rouge2": {
            "precision": 0.58136,
            "recall": 0.58,
            "fmeasure": 0.57572
        },
        "rougeL": {
            "precision": 0.71698,
            "recall": 0.69929,
            "fmeasure": 0.70389
        },
        "rougeLsum": {
            "precision": 0.71698,
            "recall": 0.69929,
            "fmeasure": 0.70389
        },
        "nubia": {
            "semantic_relation": 4.01552,
            "contradiction": 39.66231,
            "irrelevancy": 25.48432,
            "logical_agreement": 34.85336,
            "grammar_ref": 5.41078,
            "grammar_hyp": 5.27139,
            "nubia_score": 0.64929
        },
        "meteor": 0.43219811219076504,
        "bleurt": 0.37307,
        "bertscore": {
            "precision": 0.92557,
            "recall": 0.93182,
            "f1": 0.92688
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_161": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 9,
        "total_length": 142,
        "mean_pred_length": 15.777777777777779,
        "std_pred_length": 5.050363634383783,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.6830985915492958,
        "vocab_size-1": 97,
        "unique-1": 82,
        "entropy-1": 6.17684406347819,
        "distinct-2": 0.9323308270676691,
        "vocab_size-2": 124,
        "unique-2": 117,
        "entropy-2": 6.9085923978746795,
        "cond_entropy-2": 0.6069116990032523,
        "distinct-3": 0.9838709677419355,
        "vocab_size-3": 122,
        "unique-3": 120,
        "entropy-3": 6.921938245870732,
        "cond_entropy-3": 0.007863673307677125,
        "total_length-nopunct": 126,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.374838498865699,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7380952380952381,
        "vocab_size-1-nopunct": 93,
        "unique-1-nopunct": 80,
        "entropy-1-nopunct": 6.19939684041782,
        "distinct-2-nopunct": 0.9316239316239316,
        "vocab_size-2-nopunct": 109,
        "unique-2-nopunct": 103,
        "entropy-2-nopunct": 6.7207085229652055,
        "cond_entropy-2-nopunct": 0.5455084581567827,
        "distinct-3-nopunct": 0.9814814814814815,
        "vocab_size-3-nopunct": 106,
        "unique-3-nopunct": 104,
        "entropy-3-nopunct": 6.71785046512642,
        "cond_entropy-3-nopunct": 0.009613291879387635,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1891891891891892,
            "2": 0.5681818181818182,
            "3": 0.8208955223880597
        },
        "nist": 5.077526344569107,
        "bleu": 38.09965,
        "rouge1": {
            "precision": 0.73833,
            "recall": 0.7252,
            "fmeasure": 0.7252
        },
        "rouge2": {
            "precision": 0.51115,
            "recall": 0.49854,
            "fmeasure": 0.49948
        },
        "rougeL": {
            "precision": 0.59093,
            "recall": 0.59426,
            "fmeasure": 0.58479
        },
        "rougeLsum": {
            "precision": 0.59093,
            "recall": 0.59426,
            "fmeasure": 0.58479
        },
        "nubia": {
            "semantic_relation": 4.32948,
            "contradiction": 1.05896,
            "irrelevancy": 31.42811,
            "logical_agreement": 67.51294,
            "grammar_ref": 5.14381,
            "grammar_hyp": 4.82181,
            "nubia_score": 0.78089
        },
        "meteor": 0.36308175735031434,
        "bleurt": 0.2892,
        "bertscore": {
            "precision": 0.91452,
            "recall": 0.92535,
            "f1": 0.91816
        }
    },
    "web_nlg_en_challenge_test_numbers_parent": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_en_test",
        "N": 500,
        "total_length": 9618,
        "mean_pred_length": 19.236,
        "std_pred_length": 6.36932523898725,
        "median_pred_length": 21.0,
        "min_pred_length": 4,
        "max_pred_length": 31,
        "distinct-1": 0.13100436681222707,
        "vocab_size-1": 1260,
        "unique-1": 493,
        "entropy-1": 8.050417725134535,
        "distinct-2": 0.3703663084009651,
        "vocab_size-2": 3377,
        "unique-2": 1989,
        "entropy-2": 10.82738221005171,
        "cond_entropy-2": 2.720265938070403,
        "distinct-3": 0.5641680204223718,
        "vocab_size-3": 4862,
        "unique-3": 3447,
        "entropy-3": 11.733702412364876,
        "cond_entropy-3": 0.991894809578628,
        "total_length-nopunct": 8723,
        "mean_pred_length-nopunct": 17.446,
        "std_pred_length-nopunct": 6.103694291164983,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.143528602544996,
        "vocab_size-1-nopunct": 1252,
        "unique-1-nopunct": 493,
        "entropy-1-nopunct": 8.220795778693677,
        "distinct-2-nopunct": 0.3749239936762739,
        "vocab_size-2-nopunct": 3083,
        "unique-2-nopunct": 1857,
        "entropy-2-nopunct": 10.69605136888026,
        "cond_entropy-2-nopunct": 2.63936215214922,
        "distinct-3-nopunct": 0.5670076395183219,
        "vocab_size-3-nopunct": 4379,
        "unique-3-nopunct": 3159,
        "entropy-3-nopunct": 11.565608127266428,
        "cond_entropy-3-nopunct": 0.9440251714034319,
        "msttr-100": 0.66656,
        "msttr-100_nopunct": 0.69011,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.19192975120217437,
            "2": 0.5163398692810458,
            "3": 0.7560494712314034,
            "4": 0.8888888888888888,
            "5": 0.9090909090909091
        },
        "nist": 6.8036126294275014,
        "bleu": 41.5641,
        "rouge1": {
            "precision": 0.7967,
            "recall": 0.68621,
            "fmeasure": 0.72479
        },
        "rouge2": {
            "precision": 0.54247,
            "recall": 0.46467,
            "fmeasure": 0.49088
        },
        "rougeL": {
            "precision": 0.66186,
            "recall": 0.57077,
            "fmeasure": 0.60179
        },
        "rougeLsum": {
            "precision": 0.66186,
            "recall": 0.57077,
            "fmeasure": 0.60179
        },
        "nubia": {
            "semantic_relation": 4.17236,
            "contradiction": 7.73131,
            "irrelevancy": 9.73652,
            "logical_agreement": 82.53217,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.75248,
            "nubia_score": 0.68198
        },
        "meteor": 0.3343820426157199,
        "bleurt": 0.07543,
        "bertscore": {
            "precision": 0.92633,
            "recall": 0.90439,
            "f1": 0.91348
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_108": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 51,
        "total_length": 881,
        "mean_pred_length": 17.274509803921568,
        "std_pred_length": 4.777719660242182,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.5482406356413166,
        "vocab_size-1": 483,
        "unique-1": 411,
        "entropy-1": 7.745835763954353,
        "distinct-2": 0.9012048192771084,
        "vocab_size-2": 748,
        "unique-2": 700,
        "entropy-2": 9.419431732428881,
        "cond_entropy-2": 1.4954815969915942,
        "distinct-3": 0.982028241335045,
        "vocab_size-3": 765,
        "unique-3": 751,
        "entropy-3": 9.569536000731683,
        "cond_entropy-3": 0.15415346661382784,
        "total_length-nopunct": 768,
        "mean_pred_length-nopunct": 15.058823529411764,
        "std_pred_length-nopunct": 4.3087315121005085,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6197916666666666,
        "vocab_size-1-nopunct": 476,
        "unique-1-nopunct": 408,
        "entropy-1-nopunct": 7.984033120471173,
        "distinct-2-nopunct": 0.9065550906555091,
        "vocab_size-2-nopunct": 650,
        "unique-2-nopunct": 614,
        "entropy-2-nopunct": 9.210236810296722,
        "cond_entropy-2-nopunct": 1.3192616896709715,
        "distinct-3-nopunct": 0.984984984984985,
        "vocab_size-3-nopunct": 656,
        "unique-3-nopunct": 646,
        "entropy-3-nopunct": 9.349348337041377,
        "cond_entropy-3-nopunct": 0.15721245379950233,
        "msttr-100": 0.7175,
        "msttr-100_nopunct": 0.77429,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2864583333333333,
            "2": 0.45652173913043476,
            "3": 0.7938517179023508
        },
        "nist": 7.399856854707431,
        "bleu": 50.92136,
        "rouge1": {
            "precision": 0.77379,
            "recall": 0.77625,
            "fmeasure": 0.76205
        },
        "rouge2": {
            "precision": 0.56019,
            "recall": 0.57092,
            "fmeasure": 0.55649
        },
        "rougeL": {
            "precision": 0.67195,
            "recall": 0.68688,
            "fmeasure": 0.66804
        },
        "rougeLsum": {
            "precision": 0.67195,
            "recall": 0.68688,
            "fmeasure": 0.66804
        },
        "nubia": {
            "semantic_relation": 4.2733,
            "contradiction": 5.11755,
            "irrelevancy": 30.76707,
            "logical_agreement": 64.11539,
            "grammar_ref": 4.80362,
            "grammar_hyp": 4.79739,
            "nubia_score": 0.73216
        },
        "meteor": 0.407378596019169,
        "bleurt": 0.29596,
        "bertscore": {
            "precision": 0.93424,
            "recall": 0.9372,
            "f1": 0.93399
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_26": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 12,
        "total_length": 243,
        "mean_pred_length": 20.25,
        "std_pred_length": 5.959935681979575,
        "median_pred_length": 19.0,
        "min_pred_length": 12,
        "max_pred_length": 34,
        "distinct-1": 0.5267489711934157,
        "vocab_size-1": 128,
        "unique-1": 94,
        "entropy-1": 6.36606246364929,
        "distinct-2": 0.8484848484848485,
        "vocab_size-2": 196,
        "unique-2": 177,
        "entropy-2": 7.468505210191003,
        "cond_entropy-2": 1.0512551944486508,
        "distinct-3": 0.9223744292237442,
        "vocab_size-3": 202,
        "unique-3": 189,
        "entropy-3": 7.603509548165898,
        "cond_entropy-3": 0.15143778991412885,
        "total_length-nopunct": 208,
        "mean_pred_length-nopunct": 17.333333333333332,
        "std_pred_length-nopunct": 4.801620096962645,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5865384615384616,
        "vocab_size-1-nopunct": 122,
        "unique-1-nopunct": 93,
        "entropy-1-nopunct": 6.356123640192264,
        "distinct-2-nopunct": 0.8622448979591837,
        "vocab_size-2-nopunct": 169,
        "unique-2-nopunct": 154,
        "entropy-2-nopunct": 7.262569282846553,
        "cond_entropy-2-nopunct": 0.955153961198498,
        "distinct-3-nopunct": 0.9293478260869565,
        "vocab_size-3-nopunct": 171,
        "unique-3-nopunct": 161,
        "entropy-3-nopunct": 7.367285393545269,
        "cond_entropy-3-nopunct": 0.12768179947707822,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.69,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2972972972972973,
            "2": 0.6666666666666666,
            "3": 0.7913669064748201
        },
        "nist": 6.005093083530155,
        "bleu": 57.1806,
        "rouge1": {
            "precision": 0.7495,
            "recall": 0.76775,
            "fmeasure": 0.74435
        },
        "rouge2": {
            "precision": 0.61289,
            "recall": 0.60916,
            "fmeasure": 0.60032
        },
        "rougeL": {
            "precision": 0.70124,
            "recall": 0.71806,
            "fmeasure": 0.69506
        },
        "rougeLsum": {
            "precision": 0.70124,
            "recall": 0.71806,
            "fmeasure": 0.69506
        },
        "nubia": {
            "semantic_relation": 3.98581,
            "contradiction": 14.75803,
            "irrelevancy": 31.29396,
            "logical_agreement": 53.94801,
            "grammar_ref": 4.07585,
            "grammar_hyp": 3.90214,
            "nubia_score": 0.69739
        },
        "meteor": 0.42318517476809264,
        "bleurt": 0.31173,
        "bertscore": {
            "precision": 0.93916,
            "recall": 0.94275,
            "f1": 0.94026
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_247": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 74,
        "mean_pred_length": 18.5,
        "std_pred_length": 3.840572873934304,
        "median_pred_length": 18.0,
        "min_pred_length": 14,
        "max_pred_length": 24,
        "distinct-1": 0.6486486486486487,
        "vocab_size-1": 48,
        "unique-1": 30,
        "entropy-1": 5.411891879025523,
        "distinct-2": 0.8142857142857143,
        "vocab_size-2": 57,
        "unique-2": 46,
        "entropy-2": 5.736286231168871,
        "cond_entropy-2": 0.30204232991835206,
        "distinct-3": 0.9090909090909091,
        "vocab_size-3": 60,
        "unique-3": 55,
        "entropy-3": 5.85113824811356,
        "cond_entropy-3": 0.06662625392863819,
        "total_length-nopunct": 67,
        "mean_pred_length-nopunct": 16.75,
        "std_pred_length-nopunct": 4.548351349665063,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6865671641791045,
        "vocab_size-1-nopunct": 46,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.375571839614629,
        "distinct-2-nopunct": 0.8412698412698413,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.64783726473542,
        "cond_entropy-2-nopunct": 0.24063339180664373,
        "distinct-3-nopunct": 0.9322033898305084,
        "vocab_size-3-nopunct": 55,
        "unique-3-nopunct": 51,
        "entropy-3-nopunct": 5.7470498290228536,
        "cond_entropy-3-nopunct": 0.040956346200907844,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.625,
            "3": 0.6379310344827587
        },
        "nist": 4.052978541205391,
        "bleu": 36.32121,
        "rouge1": {
            "precision": 0.73725,
            "recall": 0.70647,
            "fmeasure": 0.71745
        },
        "rouge2": {
            "precision": 0.50591,
            "recall": 0.51996,
            "fmeasure": 0.50716
        },
        "rougeL": {
            "precision": 0.62887,
            "recall": 0.61306,
            "fmeasure": 0.61748
        },
        "rougeLsum": {
            "precision": 0.62887,
            "recall": 0.61306,
            "fmeasure": 0.61748
        },
        "nubia": {
            "semantic_relation": 4.37597,
            "contradiction": 1.04976,
            "irrelevancy": 47.07764,
            "logical_agreement": 51.8726,
            "grammar_ref": 3.32258,
            "grammar_hyp": 2.79625,
            "nubia_score": 0.84283
        },
        "meteor": 0.33276728818188955,
        "bleurt": 0.21625,
        "bertscore": {
            "precision": 0.90784,
            "recall": 0.90539,
            "f1": 0.90443
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_248": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 8,
        "total_length": 140,
        "mean_pred_length": 17.5,
        "std_pred_length": 6.164414002968976,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.7357142857142858,
        "vocab_size-1": 103,
        "unique-1": 91,
        "entropy-1": 6.306131986619251,
        "distinct-2": 0.9621212121212122,
        "vocab_size-2": 127,
        "unique-2": 125,
        "entropy-2": 6.941290782430891,
        "cond_entropy-2": 0.5241645631410643,
        "distinct-3": 1.0,
        "vocab_size-3": 124,
        "unique-3": 124,
        "entropy-3": 6.954196310386861,
        "cond_entropy-3": 0.0195573561448478,
        "total_length-nopunct": 128,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 5.70087712549569,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7734375,
        "vocab_size-1-nopunct": 99,
        "unique-1-nopunct": 89,
        "entropy-1-nopunct": 6.290353341491916,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 115,
        "unique-2-nopunct": 113,
        "entropy-2-nopunct": 6.793476924988228,
        "cond_entropy-2-nopunct": 0.5288920065574914,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 112,
        "unique-3-nopunct": 112,
        "entropy-3-nopunct": 6.807354922057591,
        "cond_entropy-3-nopunct": 0.0219789735422714,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.4583333333333333,
            "3": 0.7763157894736842
        },
        "nist": 4.601705734900376,
        "bleu": 37.86301,
        "rouge1": {
            "precision": 0.66261,
            "recall": 0.67773,
            "fmeasure": 0.64705
        },
        "rouge2": {
            "precision": 0.47137,
            "recall": 0.44022,
            "fmeasure": 0.43495
        },
        "rougeL": {
            "precision": 0.54441,
            "recall": 0.58395,
            "fmeasure": 0.54242
        },
        "rougeLsum": {
            "precision": 0.54441,
            "recall": 0.58395,
            "fmeasure": 0.54242
        },
        "nubia": {
            "semantic_relation": 3.76281,
            "contradiction": 8.49758,
            "irrelevancy": 60.14615,
            "logical_agreement": 31.35627,
            "grammar_ref": 4.75129,
            "grammar_hyp": 4.71978,
            "nubia_score": 0.61603
        },
        "meteor": 0.34478282653257936,
        "bleurt": 5e-05,
        "bertscore": {
            "precision": 0.87844,
            "recall": 0.88851,
            "f1": 0.87857
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_162": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 26,
        "total_length": 453,
        "mean_pred_length": 17.423076923076923,
        "std_pred_length": 5.450286350438401,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.5916114790286976,
        "vocab_size-1": 268,
        "unique-1": 222,
        "entropy-1": 7.317030047617189,
        "distinct-2": 0.9133489461358314,
        "vocab_size-2": 390,
        "unique-2": 365,
        "entropy-2": 8.530763629613515,
        "cond_entropy-2": 1.0866286759200192,
        "distinct-3": 0.9875311720698254,
        "vocab_size-3": 396,
        "unique-3": 391,
        "entropy-3": 8.622520770594491,
        "cond_entropy-3": 0.0893897952885349,
        "total_length-nopunct": 402,
        "mean_pred_length-nopunct": 15.461538461538462,
        "std_pred_length-nopunct": 4.837599287240038,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6492537313432836,
        "vocab_size-1-nopunct": 261,
        "unique-1-nopunct": 220,
        "entropy-1-nopunct": 7.396551001303682,
        "distinct-2-nopunct": 0.9202127659574468,
        "vocab_size-2-nopunct": 346,
        "unique-2-nopunct": 327,
        "entropy-2-nopunct": 8.358380241276475,
        "cond_entropy-2-nopunct": 1.0119944804903458,
        "distinct-3-nopunct": 0.9857142857142858,
        "vocab_size-3-nopunct": 345,
        "unique-3-nopunct": 340,
        "entropy-3-nopunct": 8.422639683260924,
        "cond_entropy-3-nopunct": 0.0743064744692524,
        "msttr-100": 0.7475,
        "msttr-100_nopunct": 0.7725,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21176470588235294,
            "2": 0.5671641791044776,
            "3": 0.7401574803149606
        },
        "nist": 6.304561477939811,
        "bleu": 46.21098,
        "rouge1": {
            "precision": 0.74431,
            "recall": 0.71362,
            "fmeasure": 0.71942
        },
        "rouge2": {
            "precision": 0.50153,
            "recall": 0.49007,
            "fmeasure": 0.48903
        },
        "rougeL": {
            "precision": 0.64374,
            "recall": 0.62275,
            "fmeasure": 0.62545
        },
        "rougeLsum": {
            "precision": 0.64374,
            "recall": 0.62275,
            "fmeasure": 0.62545
        },
        "nubia": {
            "semantic_relation": 4.06562,
            "contradiction": 15.39019,
            "irrelevancy": 41.75153,
            "logical_agreement": 42.85828,
            "grammar_ref": 4.52061,
            "grammar_hyp": 4.7367,
            "nubia_score": 0.66148
        },
        "meteor": 0.38557170875609476,
        "bleurt": 0.13095,
        "bertscore": {
            "precision": 0.92103,
            "recall": 0.92331,
            "f1": 0.92139
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_279": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 41,
        "mean_pred_length": 20.5,
        "std_pred_length": 2.5,
        "median_pred_length": 20.5,
        "min_pred_length": 18,
        "max_pred_length": 23,
        "distinct-1": 0.7560975609756098,
        "vocab_size-1": 31,
        "unique-1": 26,
        "entropy-1": 4.683125554510687,
        "distinct-2": 0.9487179487179487,
        "vocab_size-2": 37,
        "unique-2": 35,
        "entropy-2": 5.182838116298145,
        "cond_entropy-2": 0.5342985335878375,
        "distinct-3": 1.0,
        "vocab_size-3": 37,
        "unique-3": 37,
        "entropy-3": 5.209453365628954,
        "cond_entropy-3": 0.032159254874809355,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7435897435897436,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.576389796954472,
        "distinct-2-nopunct": 0.9459459459459459,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.101345257520845,
        "cond_entropy-2-nopunct": 0.5632804563451672,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": 0.03411536560173101,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.16666666666666666,
            "3": 0.7777777777777778
        },
        "nist": 4.326370452328609,
        "bleu": 25.2148,
        "rouge1": {
            "precision": 0.79412,
            "recall": 0.7268,
            "fmeasure": 0.74567
        },
        "rouge2": {
            "precision": 0.50893,
            "recall": 0.47708,
            "fmeasure": 0.48313
        },
        "rougeL": {
            "precision": 0.51471,
            "recall": 0.48769,
            "fmeasure": 0.49228
        },
        "rougeLsum": {
            "precision": 0.51471,
            "recall": 0.48769,
            "fmeasure": 0.49228
        },
        "nubia": {
            "semantic_relation": 3.92664,
            "contradiction": 0.1885,
            "irrelevancy": 43.41376,
            "logical_agreement": 56.39774,
            "grammar_ref": 3.10743,
            "grammar_hyp": 3.44522,
            "nubia_score": 0.73299
        },
        "meteor": 0.38006847462102356,
        "bleurt": 0.07905,
        "bertscore": {
            "precision": 0.91392,
            "recall": 0.93257,
            "f1": 0.92091
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_187": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.8,
        "vocab_size-1": 20,
        "unique-1": 16,
        "entropy-1": 4.213660689688184,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.3892266235365761,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.061400544664143256,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7727272727272727,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.970573095811683,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.44502330424448566,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.6363636363636364
        },
        "nist": 1.5968626779648138,
        "bleu": 13.30844,
        "rouge1": {
            "precision": 0.45833,
            "recall": 0.67402,
            "fmeasure": 0.54553
        },
        "rouge2": {
            "precision": 0.26087,
            "recall": 0.41905,
            "fmeasure": 0.32148
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.52222,
            "fmeasure": 0.40684
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.52222,
            "fmeasure": 0.40684
        },
        "nubia": {
            "semantic_relation": 3.39192,
            "contradiction": 96.54884,
            "irrelevancy": 2.28923,
            "logical_agreement": 1.16193,
            "grammar_ref": 5.18542,
            "grammar_hyp": 4.92635,
            "nubia_score": 0.51764
        },
        "meteor": 0.2783893681640193,
        "bleurt": -0.23725,
        "bertscore": {
            "precision": 0.82257,
            "recall": 0.91534,
            "f1": 0.86605
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_164": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 12,
        "total_length": 160,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 6.368324391514267,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.6125,
        "vocab_size-1": 98,
        "unique-1": 81,
        "entropy-1": 6.048912422302888,
        "distinct-2": 0.9391891891891891,
        "vocab_size-2": 139,
        "unique-2": 131,
        "entropy-2": 7.082731152776491,
        "cond_entropy-2": 0.8705863018457761,
        "distinct-3": 0.9926470588235294,
        "vocab_size-3": 135,
        "unique-3": 134,
        "entropy-3": 7.072756958897386,
        "cond_entropy-3": -0.01349870450976122,
        "total_length-nopunct": 137,
        "mean_pred_length-nopunct": 11.416666666666666,
        "std_pred_length-nopunct": 5.8659800734593555,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.7007299270072993,
        "vocab_size-1-nopunct": 96,
        "unique-1-nopunct": 81,
        "entropy-1-nopunct": 6.20307434719517,
        "distinct-2-nopunct": 0.952,
        "vocab_size-2-nopunct": 119,
        "unique-2-nopunct": 114,
        "entropy-2-nopunct": 6.863745184644788,
        "cond_entropy-2-nopunct": 0.7052273800715296,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 113,
        "unique-3-nopunct": 113,
        "entropy-3-nopunct": 6.8201789624152065,
        "cond_entropy-3-nopunct": -0.0327302116082845,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.74,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.5,
            "3": 0.6915887850467289
        },
        "nist": 5.265095841142869,
        "bleu": 40.25143,
        "rouge1": {
            "precision": 0.82392,
            "recall": 0.67845,
            "fmeasure": 0.72912
        },
        "rouge2": {
            "precision": 0.49792,
            "recall": 0.41271,
            "fmeasure": 0.44126
        },
        "rougeL": {
            "precision": 0.68829,
            "recall": 0.5667,
            "fmeasure": 0.60957
        },
        "rougeLsum": {
            "precision": 0.68829,
            "recall": 0.5667,
            "fmeasure": 0.60957
        },
        "nubia": {
            "semantic_relation": 4.16218,
            "contradiction": 5.10754,
            "irrelevancy": 15.07419,
            "logical_agreement": 79.81827,
            "grammar_ref": 4.9625,
            "grammar_hyp": 5.30095,
            "nubia_score": 0.70364
        },
        "meteor": 0.3728110387806076,
        "bleurt": 0.16272,
        "bertscore": {
            "precision": 0.92441,
            "recall": 0.91091,
            "f1": 0.9145
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_305": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.625
        },
        "nist": 2.0818734482105152,
        "bleu": 15.44788,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.625,
            "fmeasure": 0.71429
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.28571,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.5,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.5,
            "fmeasure": 0.57143
        },
        "nubia": {
            "semantic_relation": 4.89215,
            "contradiction": 0.31878,
            "irrelevancy": 0.49621,
            "logical_agreement": 99.18501,
            "grammar_ref": 5.02153,
            "grammar_hyp": 4.92558,
            "nubia_score": 0.97134
        },
        "meteor": 0.35772595517358696,
        "bleurt": 0.71323,
        "bertscore": {
            "precision": 0.97848,
            "recall": 0.92917,
            "f1": 0.95319
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_280": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 25,
        "total_length": 445,
        "mean_pred_length": 17.8,
        "std_pred_length": 5.789645930452052,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.5955056179775281,
        "vocab_size-1": 265,
        "unique-1": 222,
        "entropy-1": 7.306119056507241,
        "distinct-2": 0.9666666666666667,
        "vocab_size-2": 406,
        "unique-2": 397,
        "entropy-2": 8.63538976652622,
        "cond_entropy-2": 1.1669717200595904,
        "distinct-3": 1.0,
        "vocab_size-3": 395,
        "unique-3": 395,
        "entropy-3": 8.62570884306451,
        "cond_entropy-3": -0.004690053136432591,
        "total_length-nopunct": 391,
        "mean_pred_length-nopunct": 15.64,
        "std_pred_length-nopunct": 5.050782117652671,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6624040920716112,
        "vocab_size-1-nopunct": 259,
        "unique-1-nopunct": 222,
        "entropy-1-nopunct": 7.420807968856205,
        "distinct-2-nopunct": 0.9644808743169399,
        "vocab_size-2-nopunct": 353,
        "unique-2-nopunct": 345,
        "entropy-2-nopunct": 8.430674112932175,
        "cond_entropy-2-nopunct": 1.0857006268937768,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 341,
        "unique-3-nopunct": 341,
        "entropy-3-nopunct": 8.413627929024182,
        "cond_entropy-3-nopunct": -0.010812626330943846,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.77333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17391304347826086,
            "2": 0.484375,
            "3": 0.8064516129032258
        },
        "nist": 6.553600269399545,
        "bleu": 46.87572,
        "rouge1": {
            "precision": 0.76111,
            "recall": 0.79245,
            "fmeasure": 0.76797
        },
        "rouge2": {
            "precision": 0.54936,
            "recall": 0.55734,
            "fmeasure": 0.54615
        },
        "rougeL": {
            "precision": 0.64987,
            "recall": 0.66492,
            "fmeasure": 0.65025
        },
        "rougeLsum": {
            "precision": 0.64987,
            "recall": 0.66492,
            "fmeasure": 0.65025
        },
        "nubia": {
            "semantic_relation": 4.14385,
            "contradiction": 10.70083,
            "irrelevancy": 23.43036,
            "logical_agreement": 65.86881,
            "grammar_ref": 4.76367,
            "grammar_hyp": 4.57626,
            "nubia_score": 0.743
        },
        "meteor": 0.42006493127437516,
        "bleurt": 0.32582,
        "bertscore": {
            "precision": 0.93789,
            "recall": 0.94097,
            "f1": 0.93834
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_110": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 31,
        "total_length": 566,
        "mean_pred_length": 18.258064516129032,
        "std_pred_length": 5.471142723921127,
        "median_pred_length": 19.0,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.5706713780918727,
        "vocab_size-1": 323,
        "unique-1": 253,
        "entropy-1": 7.5769692753100255,
        "distinct-2": 0.9271028037383178,
        "vocab_size-2": 496,
        "unique-2": 463,
        "entropy-2": 8.908218352300374,
        "cond_entropy-2": 1.2347356779269199,
        "distinct-3": 0.9682539682539683,
        "vocab_size-3": 488,
        "unique-3": 473,
        "entropy-3": 8.912290067344763,
        "cond_entropy-3": 0.008487421587933468,
        "total_length-nopunct": 505,
        "mean_pred_length-nopunct": 16.29032258064516,
        "std_pred_length-nopunct": 5.219031849330758,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6316831683168317,
        "vocab_size-1-nopunct": 319,
        "unique-1-nopunct": 253,
        "entropy-1-nopunct": 7.7250800007001645,
        "distinct-2-nopunct": 0.930379746835443,
        "vocab_size-2-nopunct": 441,
        "unique-2-nopunct": 413,
        "entropy-2-nopunct": 8.740505564285366,
        "cond_entropy-2-nopunct": 1.0697228671372268,
        "distinct-3-nopunct": 0.963882618510158,
        "vocab_size-3-nopunct": 427,
        "unique-3-nopunct": 412,
        "entropy-3-nopunct": 8.717224090581757,
        "cond_entropy-3-nopunct": -0.018743311802370124,
        "msttr-100": 0.768,
        "msttr-100_nopunct": 0.8,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2972972972972973,
            "2": 0.43373493975903615,
            "3": 0.7413333333333333
        },
        "nist": 6.636125674778884,
        "bleu": 46.67564,
        "rouge1": {
            "precision": 0.73086,
            "recall": 0.72938,
            "fmeasure": 0.71528
        },
        "rouge2": {
            "precision": 0.51507,
            "recall": 0.50007,
            "fmeasure": 0.49722
        },
        "rougeL": {
            "precision": 0.6379,
            "recall": 0.63092,
            "fmeasure": 0.62333
        },
        "rougeLsum": {
            "precision": 0.6379,
            "recall": 0.63092,
            "fmeasure": 0.62333
        },
        "nubia": {
            "semantic_relation": 4.18254,
            "contradiction": 13.69815,
            "irrelevancy": 32.07656,
            "logical_agreement": 54.22528,
            "grammar_ref": 4.88113,
            "grammar_hyp": 4.66678,
            "nubia_score": 0.72901
        },
        "meteor": 0.3822373775268821,
        "bleurt": 0.2182,
        "bertscore": {
            "precision": 0.92255,
            "recall": 0.92001,
            "f1": 0.91995
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_224": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 18,
        "total_length": 286,
        "mean_pred_length": 15.88888888888889,
        "std_pred_length": 4.99876527964533,
        "median_pred_length": 14.5,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.6398601398601399,
        "vocab_size-1": 183,
        "unique-1": 152,
        "entropy-1": 6.936847571263283,
        "distinct-2": 0.9589552238805971,
        "vocab_size-2": 257,
        "unique-2": 248,
        "entropy-2": 7.978366149396818,
        "cond_entropy-2": 0.9210389470532513,
        "distinct-3": 0.992,
        "vocab_size-3": 248,
        "unique-3": 246,
        "entropy-3": 7.9497842846621,
        "cond_entropy-3": -0.02226580577837778,
        "total_length-nopunct": 253,
        "mean_pred_length-nopunct": 14.055555555555555,
        "std_pred_length-nopunct": 4.49038753861107,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7035573122529645,
        "vocab_size-1-nopunct": 178,
        "unique-1-nopunct": 151,
        "entropy-1-nopunct": 7.018754432340361,
        "distinct-2-nopunct": 0.9531914893617022,
        "vocab_size-2-nopunct": 224,
        "unique-2-nopunct": 215,
        "entropy-2-nopunct": 7.776475350801889,
        "cond_entropy-2-nopunct": 0.8188115761737376,
        "distinct-3-nopunct": 0.9907834101382489,
        "vocab_size-3-nopunct": 215,
        "unique-3-nopunct": 213,
        "entropy-3-nopunct": 7.743118052720991,
        "cond_entropy-3-nopunct": -0.02505891686555761,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23333333333333334,
            "2": 0.18,
            "3": 0.702020202020202
        },
        "nist": 5.595622559323526,
        "bleu": 40.16972,
        "rouge1": {
            "precision": 0.7195,
            "recall": 0.70018,
            "fmeasure": 0.69239
        },
        "rouge2": {
            "precision": 0.53246,
            "recall": 0.51893,
            "fmeasure": 0.51095
        },
        "rougeL": {
            "precision": 0.62992,
            "recall": 0.61587,
            "fmeasure": 0.60676
        },
        "rougeLsum": {
            "precision": 0.62992,
            "recall": 0.61587,
            "fmeasure": 0.60676
        },
        "nubia": {
            "semantic_relation": 3.87623,
            "contradiction": 20.67447,
            "irrelevancy": 21.71742,
            "logical_agreement": 57.60811,
            "grammar_ref": 4.41455,
            "grammar_hyp": 4.50389,
            "nubia_score": 0.62461
        },
        "meteor": 0.37786670318837356,
        "bleurt": 0.09814,
        "bertscore": {
            "precision": 0.91811,
            "recall": 0.91686,
            "f1": 0.91295
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_282": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548847,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983795,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6153846153846154
        },
        "nist": 2.0136660282620062,
        "bleu": 11.26871,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.76413,
            "fmeasure": 0.73054
        },
        "rouge2": {
            "precision": 0.36842,
            "recall": 0.40414,
            "fmeasure": 0.38539
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.54581,
            "fmeasure": 0.52182
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.54581,
            "fmeasure": 0.52182
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.08355,
            "irrelevancy": 0.8285,
            "logical_agreement": 99.08795,
            "grammar_ref": 4.92793,
            "grammar_hyp": 4.73732,
            "nubia_score": 0.98668
        },
        "meteor": 0.34239561133117297,
        "bleurt": 0.48542,
        "bertscore": {
            "precision": 0.90249,
            "recall": 0.90328,
            "f1": 0.90288
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_225": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 17,
        "total_length": 318,
        "mean_pred_length": 18.705882352941178,
        "std_pred_length": 4.59878124369225,
        "median_pred_length": 19.0,
        "min_pred_length": 11,
        "max_pred_length": 29,
        "distinct-1": 0.5849056603773585,
        "vocab_size-1": 186,
        "unique-1": 141,
        "entropy-1": 6.948182154695266,
        "distinct-2": 0.9102990033222591,
        "vocab_size-2": 274,
        "unique-2": 252,
        "entropy-2": 8.040049369429138,
        "cond_entropy-2": 1.0014096372564807,
        "distinct-3": 0.9753521126760564,
        "vocab_size-3": 277,
        "unique-3": 270,
        "entropy-3": 8.100451344856817,
        "cond_entropy-3": 0.06846780368332611,
        "total_length-nopunct": 279,
        "mean_pred_length-nopunct": 16.41176470588235,
        "std_pred_length-nopunct": 4.1024931233323985,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6451612903225806,
        "vocab_size-1-nopunct": 180,
        "unique-1-nopunct": 140,
        "entropy-1-nopunct": 7.021596309158905,
        "distinct-2-nopunct": 0.9045801526717557,
        "vocab_size-2-nopunct": 237,
        "unique-2-nopunct": 217,
        "entropy-2-nopunct": 7.826305969069958,
        "cond_entropy-2-nopunct": 0.8559348391114381,
        "distinct-3-nopunct": 0.9714285714285714,
        "vocab_size-3-nopunct": 238,
        "unique-3-nopunct": 231,
        "entropy-3-nopunct": 7.879495081859742,
        "cond_entropy-3-nopunct": 0.055315600756918146,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22,
            "2": 0.5476190476190477,
            "3": 0.7641509433962265
        },
        "nist": 5.796451894254354,
        "bleu": 38.55624,
        "rouge1": {
            "precision": 0.73035,
            "recall": 0.75112,
            "fmeasure": 0.72723
        },
        "rouge2": {
            "precision": 0.46565,
            "recall": 0.47643,
            "fmeasure": 0.46286
        },
        "rougeL": {
            "precision": 0.61742,
            "recall": 0.62236,
            "fmeasure": 0.60947
        },
        "rougeLsum": {
            "precision": 0.61742,
            "recall": 0.62236,
            "fmeasure": 0.60947
        },
        "nubia": {
            "semantic_relation": 4.05913,
            "contradiction": 8.61844,
            "irrelevancy": 46.27388,
            "logical_agreement": 45.10768,
            "grammar_ref": 4.59976,
            "grammar_hyp": 4.69904,
            "nubia_score": 0.65137
        },
        "meteor": 0.38688845795754173,
        "bleurt": 0.08011,
        "bertscore": {
            "precision": 0.91338,
            "recall": 0.92579,
            "f1": 0.9168
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_165": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 19,
        "total_length": 354,
        "mean_pred_length": 18.63157894736842,
        "std_pred_length": 6.191764703095892,
        "median_pred_length": 19.0,
        "min_pred_length": 7,
        "max_pred_length": 31,
        "distinct-1": 0.5847457627118644,
        "vocab_size-1": 207,
        "unique-1": 167,
        "entropy-1": 7.032914323655839,
        "distinct-2": 0.9104477611940298,
        "vocab_size-2": 305,
        "unique-2": 278,
        "entropy-2": 8.200689262950645,
        "cond_entropy-2": 1.0700410088533039,
        "distinct-3": 0.9588607594936709,
        "vocab_size-3": 303,
        "unique-3": 290,
        "entropy-3": 8.221502267164468,
        "cond_entropy-3": 0.025747284041346203,
        "total_length-nopunct": 307,
        "mean_pred_length-nopunct": 16.157894736842106,
        "std_pred_length-nopunct": 5.039456506772979,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6579804560260586,
        "vocab_size-1-nopunct": 202,
        "unique-1-nopunct": 166,
        "entropy-1-nopunct": 7.142217014358457,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 264,
        "unique-2-nopunct": 243,
        "entropy-2-nopunct": 7.9936927531708815,
        "cond_entropy-2-nopunct": 0.9074054394644336,
        "distinct-3-nopunct": 0.9591078066914498,
        "vocab_size-3-nopunct": 258,
        "unique-3-nopunct": 247,
        "entropy-3-nopunct": 7.989677975939495,
        "cond_entropy-3-nopunct": -0.0027195626694673752,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.76667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.29508196721311475,
            "2": 0.4067796610169492,
            "3": 0.7439613526570048
        },
        "nist": 5.546681405605829,
        "bleu": 37.34822,
        "rouge1": {
            "precision": 0.70407,
            "recall": 0.73123,
            "fmeasure": 0.71043
        },
        "rouge2": {
            "precision": 0.44798,
            "recall": 0.46751,
            "fmeasure": 0.45184
        },
        "rougeL": {
            "precision": 0.63452,
            "recall": 0.65487,
            "fmeasure": 0.63787
        },
        "rougeLsum": {
            "precision": 0.63452,
            "recall": 0.65487,
            "fmeasure": 0.63787
        },
        "nubia": {
            "semantic_relation": 3.97358,
            "contradiction": 4.20113,
            "irrelevancy": 50.92244,
            "logical_agreement": 44.87643,
            "grammar_ref": 4.52561,
            "grammar_hyp": 4.25462,
            "nubia_score": 0.70988
        },
        "meteor": 0.36138950463299796,
        "bleurt": 0.13121,
        "bertscore": {
            "precision": 0.90647,
            "recall": 0.91956,
            "f1": 0.91142
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_87": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 41,
        "mean_pred_length": 13.666666666666666,
        "std_pred_length": 5.90668171555645,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 22,
        "distinct-1": 0.8780487804878049,
        "vocab_size-1": 36,
        "unique-1": 32,
        "entropy-1": 5.095237675297021,
        "distinct-2": 1.0,
        "vocab_size-2": 38,
        "unique-2": 38,
        "entropy-2": 5.247927513443589,
        "cond_entropy-2": 0.04827024566760739,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": -0.11864449649861893,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 5.436502143433364,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.918918918918919,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.047291203466791,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.087462841250338,
        "cond_entropy-2-nopunct": 0.054480063856683886,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.13326653086346418,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.36363636363636365,
            "3": 0.625
        },
        "nist": 2.5512161809928164,
        "bleu": 25.19507,
        "rouge1": {
            "precision": 0.71746,
            "recall": 0.71402,
            "fmeasure": 0.69534
        },
        "rouge2": {
            "precision": 0.44153,
            "recall": 0.48148,
            "fmeasure": 0.44467
        },
        "rougeL": {
            "precision": 0.68571,
            "recall": 0.69021,
            "fmeasure": 0.66813
        },
        "rougeLsum": {
            "precision": 0.68571,
            "recall": 0.69021,
            "fmeasure": 0.66813
        },
        "nubia": {
            "semantic_relation": 4.19251,
            "contradiction": 23.40868,
            "irrelevancy": 23.6506,
            "logical_agreement": 52.94072,
            "grammar_ref": 5.04645,
            "grammar_hyp": 4.95176,
            "nubia_score": 0.68922
        },
        "meteor": 0.3005737499726081,
        "bleurt": 0.3246,
        "bertscore": {
            "precision": 0.93977,
            "recall": 0.92174,
            "f1": 0.93003
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_39": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 26,
        "total_length": 392,
        "mean_pred_length": 15.076923076923077,
        "std_pred_length": 4.882646483864107,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.5739795918367347,
        "vocab_size-1": 225,
        "unique-1": 181,
        "entropy-1": 7.005891220414094,
        "distinct-2": 0.9426229508196722,
        "vocab_size-2": 345,
        "unique-2": 329,
        "entropy-2": 8.386958265937643,
        "cond_entropy-2": 1.1754191752281486,
        "distinct-3": 0.9941176470588236,
        "vocab_size-3": 338,
        "unique-3": 336,
        "entropy-3": 8.397626230255328,
        "cond_entropy-3": 0.014630555144141147,
        "total_length-nopunct": 343,
        "mean_pred_length-nopunct": 13.192307692307692,
        "std_pred_length-nopunct": 4.323631226440169,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6384839650145773,
        "vocab_size-1-nopunct": 219,
        "unique-1-nopunct": 181,
        "entropy-1-nopunct": 7.109557136714628,
        "distinct-2-nopunct": 0.9558359621451105,
        "vocab_size-2-nopunct": 303,
        "unique-2-nopunct": 294,
        "entropy-2-nopunct": 8.203861378786886,
        "cond_entropy-2-nopunct": 1.1717182353377742,
        "distinct-3-nopunct": 0.9965635738831615,
        "vocab_size-3-nopunct": 290,
        "unique-3-nopunct": 289,
        "entropy-3-nopunct": 8.178002490674606,
        "cond_entropy-3-nopunct": -0.0199605412559901,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.73333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2988505747126437,
            "2": 0.44086021505376344,
            "3": 0.6995708154506438
        },
        "nist": 5.595321574021313,
        "bleu": 38.15917,
        "rouge1": {
            "precision": 0.70587,
            "recall": 0.68396,
            "fmeasure": 0.68016
        },
        "rouge2": {
            "precision": 0.44661,
            "recall": 0.42343,
            "fmeasure": 0.42473
        },
        "rougeL": {
            "precision": 0.63096,
            "recall": 0.60814,
            "fmeasure": 0.60559
        },
        "rougeLsum": {
            "precision": 0.63096,
            "recall": 0.60814,
            "fmeasure": 0.60559
        },
        "nubia": {
            "semantic_relation": 3.71473,
            "contradiction": 16.4851,
            "irrelevancy": 42.16058,
            "logical_agreement": 41.35432,
            "grammar_ref": 4.64456,
            "grammar_hyp": 4.86704,
            "nubia_score": 0.58594
        },
        "meteor": 0.33913211191093984,
        "bleurt": -0.02419,
        "bertscore": {
            "precision": 0.90121,
            "recall": 0.89918,
            "f1": 0.89889
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_284": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.7391304347826086,
        "vocab_size-1": 17,
        "unique-1": 11,
        "entropy-1": 4.001822825622231,
        "distinct-2": 0.8181818181818182,
        "vocab_size-2": 18,
        "unique-2": 14,
        "entropy-2": 4.095795255000932,
        "cond_entropy-2": 0.11768784439846627,
        "distinct-3": 0.8571428571428571,
        "vocab_size-3": 18,
        "unique-3": 15,
        "entropy-3": 4.106603137064474,
        "cond_entropy-3": 0.02812389937955851,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7272727272727273,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.9139770731827515,
        "distinct-2-nopunct": 0.8095238095238095,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 4.011365041826379,
        "cond_entropy-2-nopunct": 0.12336199461765374,
        "distinct-3-nopunct": 0.85,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 4.021928094887363,
        "cond_entropy-3-nopunct": 0.029610672108602014,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.4117647058823529
        },
        "nist": 1.897944351952884,
        "bleu": 22.08029,
        "rouge1": {
            "precision": 0.45238,
            "recall": 0.47483,
            "fmeasure": 0.4633
        },
        "rouge2": {
            "precision": 0.2963,
            "recall": 0.32,
            "fmeasure": 0.30769
        },
        "rougeL": {
            "precision": 0.39286,
            "recall": 0.42308,
            "fmeasure": 0.40741
        },
        "rougeLsum": {
            "precision": 0.39286,
            "recall": 0.42308,
            "fmeasure": 0.40741
        },
        "nubia": {
            "semantic_relation": 3.06329,
            "contradiction": 1.91886,
            "irrelevancy": 57.07206,
            "logical_agreement": 41.00908,
            "grammar_ref": 4.71547,
            "grammar_hyp": 4.21128,
            "nubia_score": 0.45232
        },
        "meteor": 0.2577379973972488,
        "bleurt": -0.59784,
        "bertscore": {
            "precision": 0.86427,
            "recall": 0.84388,
            "f1": 0.85343
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_88": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 35,
        "total_length": 618,
        "mean_pred_length": 17.65714285714286,
        "std_pred_length": 5.502949116573025,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 30,
        "distinct-1": 0.5566343042071198,
        "vocab_size-1": 344,
        "unique-1": 281,
        "entropy-1": 7.51321310356638,
        "distinct-2": 0.8953687821612349,
        "vocab_size-2": 522,
        "unique-2": 483,
        "entropy-2": 8.936657428400563,
        "cond_entropy-2": 1.3046649594704702,
        "distinct-3": 0.9616788321167883,
        "vocab_size-3": 527,
        "unique-3": 513,
        "entropy-3": 9.010852452466414,
        "cond_entropy-3": 0.08838172583230026,
        "total_length-nopunct": 538,
        "mean_pred_length-nopunct": 15.371428571428572,
        "std_pred_length-nopunct": 5.377655964588046,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6263940520446096,
        "vocab_size-1-nopunct": 337,
        "unique-1-nopunct": 280,
        "entropy-1-nopunct": 7.654868709163841,
        "distinct-2-nopunct": 0.9105367793240556,
        "vocab_size-2-nopunct": 458,
        "unique-2-nopunct": 430,
        "entropy-2-nopunct": 8.756919380230432,
        "cond_entropy-2-nopunct": 1.1737039892727115,
        "distinct-3-nopunct": 0.9700854700854701,
        "vocab_size-3-nopunct": 454,
        "unique-3-nopunct": 445,
        "entropy-3-nopunct": 8.80247062233807,
        "cond_entropy-3-nopunct": 0.05754340521685165,
        "msttr-100": 0.70833,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24468085106382978,
            "2": 0.4690265486725664,
            "3": 0.72544080604534
        },
        "nist": 6.285856297720851,
        "bleu": 38.62147,
        "rouge1": {
            "precision": 0.73874,
            "recall": 0.71271,
            "fmeasure": 0.71788
        },
        "rouge2": {
            "precision": 0.48296,
            "recall": 0.47063,
            "fmeasure": 0.4711
        },
        "rougeL": {
            "precision": 0.61598,
            "recall": 0.6097,
            "fmeasure": 0.60519
        },
        "rougeLsum": {
            "precision": 0.61598,
            "recall": 0.6097,
            "fmeasure": 0.60519
        },
        "nubia": {
            "semantic_relation": 4.07456,
            "contradiction": 12.10903,
            "irrelevancy": 32.20294,
            "logical_agreement": 55.68803,
            "grammar_ref": 4.59802,
            "grammar_hyp": 4.51886,
            "nubia_score": 0.6952
        },
        "meteor": 0.3694419682010793,
        "bleurt": 0.19401,
        "bertscore": {
            "precision": 0.9201,
            "recall": 0.91773,
            "f1": 0.91577
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_90": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 78,
        "total_length": 1289,
        "mean_pred_length": 16.525641025641026,
        "std_pred_length": 5.941432873397302,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 28,
        "distinct-1": 0.48176881303335917,
        "vocab_size-1": 621,
        "unique-1": 474,
        "entropy-1": 8.053824333737452,
        "distinct-2": 0.8678777869529315,
        "vocab_size-2": 1051,
        "unique-2": 950,
        "entropy-2": 9.893145815880972,
        "cond_entropy-2": 1.6159242506295914,
        "distinct-3": 0.9691085613415711,
        "vocab_size-3": 1098,
        "unique-3": 1063,
        "entropy-3": 10.084149268503602,
        "cond_entropy-3": 0.1950631803924649,
        "total_length-nopunct": 1128,
        "mean_pred_length-nopunct": 14.461538461538462,
        "std_pred_length-nopunct": 5.295601241118043,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5416666666666666,
        "vocab_size-1-nopunct": 611,
        "unique-1-nopunct": 472,
        "entropy-1-nopunct": 8.2788292435213,
        "distinct-2-nopunct": 0.878095238095238,
        "vocab_size-2-nopunct": 922,
        "unique-2-nopunct": 844,
        "entropy-2-nopunct": 9.703832595608075,
        "cond_entropy-2-nopunct": 1.5017682118210147,
        "distinct-3-nopunct": 0.9711934156378601,
        "vocab_size-3-nopunct": 944,
        "unique-3-nopunct": 916,
        "entropy-3-nopunct": 9.867199334881434,
        "cond_entropy-3-nopunct": 0.18489204721769867,
        "msttr-100": 0.72917,
        "msttr-100_nopunct": 0.77727,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23605150214592274,
            "2": 0.5361702127659574,
            "3": 0.7883211678832117
        },
        "nist": 7.6702253280406705,
        "bleu": 50.26377,
        "rouge1": {
            "precision": 0.78308,
            "recall": 0.74312,
            "fmeasure": 0.75275
        },
        "rouge2": {
            "precision": 0.55576,
            "recall": 0.5305,
            "fmeasure": 0.53431
        },
        "rougeL": {
            "precision": 0.70205,
            "recall": 0.67103,
            "fmeasure": 0.67624
        },
        "rougeLsum": {
            "precision": 0.70205,
            "recall": 0.67103,
            "fmeasure": 0.67624
        },
        "nubia": {
            "semantic_relation": 4.33268,
            "contradiction": 5.36371,
            "irrelevancy": 30.25825,
            "logical_agreement": 64.37804,
            "grammar_ref": 4.66269,
            "grammar_hyp": 4.76292,
            "nubia_score": 0.75712
        },
        "meteor": 0.4140939003589695,
        "bleurt": 0.35242,
        "bertscore": {
            "precision": 0.93579,
            "recall": 0.93342,
            "f1": 0.93307
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_66": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 48,
        "total_length": 821,
        "mean_pred_length": 17.104166666666668,
        "std_pred_length": 5.598510156481117,
        "median_pred_length": 17.5,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.5237515225334958,
        "vocab_size-1": 430,
        "unique-1": 346,
        "entropy-1": 7.67550175048349,
        "distinct-2": 0.9003880983182406,
        "vocab_size-2": 696,
        "unique-2": 648,
        "entropy-2": 9.337324325341308,
        "cond_entropy-2": 1.475681676120069,
        "distinct-3": 0.9806896551724138,
        "vocab_size-3": 711,
        "unique-3": 697,
        "entropy-3": 9.463216495247009,
        "cond_entropy-3": 0.11861820148870418,
        "total_length-nopunct": 716,
        "mean_pred_length-nopunct": 14.916666666666666,
        "std_pred_length-nopunct": 5.227464862520732,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5921787709497207,
        "vocab_size-1-nopunct": 424,
        "unique-1-nopunct": 344,
        "entropy-1-nopunct": 7.894637462530162,
        "distinct-2-nopunct": 0.905688622754491,
        "vocab_size-2-nopunct": 605,
        "unique-2-nopunct": 567,
        "entropy-2-nopunct": 9.13475715569487,
        "cond_entropy-2-nopunct": 1.3096765238538335,
        "distinct-3-nopunct": 0.9838709677419355,
        "vocab_size-3-nopunct": 610,
        "unique-3-nopunct": 600,
        "entropy-3-nopunct": 9.243866340758133,
        "cond_entropy-3-nopunct": 0.125156705330021,
        "msttr-100": 0.71375,
        "msttr-100_nopunct": 0.76286,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22807017543859648,
            "2": 0.5833333333333334,
            "3": 0.6853281853281853
        },
        "nist": 6.454718268644235,
        "bleu": 36.97273,
        "rouge1": {
            "precision": 0.74506,
            "recall": 0.67708,
            "fmeasure": 0.69746
        },
        "rouge2": {
            "precision": 0.47839,
            "recall": 0.43784,
            "fmeasure": 0.44922
        },
        "rougeL": {
            "precision": 0.61592,
            "recall": 0.56791,
            "fmeasure": 0.58006
        },
        "rougeLsum": {
            "precision": 0.61592,
            "recall": 0.56791,
            "fmeasure": 0.58006
        },
        "nubia": {
            "semantic_relation": 4.0082,
            "contradiction": 13.06736,
            "irrelevancy": 29.80204,
            "logical_agreement": 57.13059,
            "grammar_ref": 4.63301,
            "grammar_hyp": 4.70155,
            "nubia_score": 0.67647
        },
        "meteor": 0.35526667117955096,
        "bleurt": 0.15071,
        "bertscore": {
            "precision": 0.9199,
            "recall": 0.90829,
            "f1": 0.91211
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_285": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 7,
        "total_length": 137,
        "mean_pred_length": 19.571428571428573,
        "std_pred_length": 4.370588154508101,
        "median_pred_length": 18.0,
        "min_pred_length": 13,
        "max_pred_length": 25,
        "distinct-1": 0.7372262773722628,
        "vocab_size-1": 101,
        "unique-1": 88,
        "entropy-1": 6.343878934494748,
        "distinct-2": 0.9923076923076923,
        "vocab_size-2": 129,
        "unique-2": 128,
        "entropy-2": 7.00698319764384,
        "cond_entropy-2": 0.5741422824330396,
        "distinct-3": 1.0,
        "vocab_size-3": 123,
        "unique-3": 123,
        "entropy-3": 6.942514505339227,
        "cond_entropy-3": -0.06359314508758866,
        "total_length-nopunct": 120,
        "mean_pred_length-nopunct": 17.142857142857142,
        "std_pred_length-nopunct": 3.398679215248663,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 96,
        "unique-1-nopunct": 85,
        "entropy-1-nopunct": 6.3734238253501685,
        "distinct-2-nopunct": 0.9911504424778761,
        "vocab_size-2-nopunct": 112,
        "unique-2-nopunct": 111,
        "entropy-2-nopunct": 6.802479847370959,
        "cond_entropy-2-nopunct": 0.4532530785854615,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 106,
        "unique-3-nopunct": 106,
        "entropy-3-nopunct": 6.727920454563184,
        "cond_entropy-3-nopunct": -0.07339058332368639,
        "msttr-100": 0.79,
        "msttr-100_nopunct": 0.84,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.8387096774193549,
            "3": 0.7037037037037037
        },
        "nist": 5.584739728804183,
        "bleu": 46.42416,
        "rouge1": {
            "precision": 0.77311,
            "recall": 0.74957,
            "fmeasure": 0.75898
        },
        "rouge2": {
            "precision": 0.48269,
            "recall": 0.47248,
            "fmeasure": 0.47588
        },
        "rougeL": {
            "precision": 0.65263,
            "recall": 0.6381,
            "fmeasure": 0.64346
        },
        "rougeLsum": {
            "precision": 0.65263,
            "recall": 0.6381,
            "fmeasure": 0.64346
        },
        "nubia": {
            "semantic_relation": 4.44333,
            "contradiction": 0.87547,
            "irrelevancy": 33.5263,
            "logical_agreement": 65.59823,
            "grammar_ref": 4.72263,
            "grammar_hyp": 4.61661,
            "nubia_score": 0.80071
        },
        "meteor": 0.37726555024289715,
        "bleurt": 0.22649,
        "bertscore": {
            "precision": 0.92644,
            "recall": 0.92248,
            "f1": 0.92357
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_306": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 12,
        "total_length": 189,
        "mean_pred_length": 15.75,
        "std_pred_length": 4.45580146176495,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 126,
        "unique-1": 106,
        "entropy-1": 6.474534533862971,
        "distinct-2": 0.9717514124293786,
        "vocab_size-2": 172,
        "unique-2": 167,
        "entropy-2": 7.411108374941765,
        "cond_entropy-2": 0.7953238234476412,
        "distinct-3": 0.9939393939393939,
        "vocab_size-3": 164,
        "unique-3": 163,
        "entropy-3": 7.354201002124597,
        "cond_entropy-3": -0.052798487352333376,
        "total_length-nopunct": 162,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 3.9895697345286076,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7469135802469136,
        "vocab_size-1-nopunct": 121,
        "unique-1-nopunct": 104,
        "entropy-1-nopunct": 6.5836555987857315,
        "distinct-2-nopunct": 0.9733333333333334,
        "vocab_size-2-nopunct": 146,
        "unique-2-nopunct": 142,
        "entropy-2-nopunct": 7.175485357162531,
        "cond_entropy-2-nopunct": 0.6523253107047094,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 138,
        "unique-3-nopunct": 138,
        "entropy-3-nopunct": 7.108524456778167,
        "cond_entropy-3-nopunct": -0.06232321922495815,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.84,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19736842105263158,
            "2": 0.45161290322580644,
            "3": 0.5961538461538461
        },
        "nist": 4.328031457899823,
        "bleu": 27.19517,
        "rouge1": {
            "precision": 0.60783,
            "recall": 0.61371,
            "fmeasure": 0.6014
        },
        "rouge2": {
            "precision": 0.40945,
            "recall": 0.40849,
            "fmeasure": 0.40056
        },
        "rougeL": {
            "precision": 0.53891,
            "recall": 0.54456,
            "fmeasure": 0.53206
        },
        "rougeLsum": {
            "precision": 0.53891,
            "recall": 0.54456,
            "fmeasure": 0.53206
        },
        "nubia": {
            "semantic_relation": 3.77902,
            "contradiction": 12.25489,
            "irrelevancy": 49.95576,
            "logical_agreement": 37.78935,
            "grammar_ref": 4.84087,
            "grammar_hyp": 4.53139,
            "nubia_score": 0.62871
        },
        "meteor": 0.32297846882726555,
        "bleurt": 0.07032,
        "bertscore": {
            "precision": 0.89079,
            "recall": 0.89794,
            "f1": 0.89283
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_286": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 44,
        "mean_pred_length": 11.0,
        "std_pred_length": 4.301162633521313,
        "median_pred_length": 9.5,
        "min_pred_length": 7,
        "max_pred_length": 18,
        "distinct-1": 0.6590909090909091,
        "vocab_size-1": 29,
        "unique-1": 21,
        "entropy-1": 4.646376220664175,
        "distinct-2": 0.875,
        "vocab_size-2": 35,
        "unique-2": 32,
        "entropy-2": 5.03418371977919,
        "cond_entropy-2": 0.26911303891232496,
        "distinct-3": 0.9166666666666666,
        "vocab_size-3": 33,
        "unique-3": 31,
        "entropy-3": 4.982289237493325,
        "cond_entropy-3": -0.15200309344504975,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 9.25,
        "std_pred_length-nopunct": 3.491060010942235,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7297297297297297,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.587303365395064,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.839700558686835,
        "cond_entropy-2-nopunct": 0.18372181446668367,
        "distinct-3-nopunct": 0.9655172413793104,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.789015477886192,
        "cond_entropy-3-nopunct": -0.18641312423088147,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.42857142857142855,
            "3": 0.7096774193548387
        },
        "nist": 3.727910825194825,
        "bleu": 52.67606,
        "rouge1": {
            "precision": 0.85894,
            "recall": 0.71949,
            "fmeasure": 0.76439
        },
        "rouge2": {
            "precision": 0.69577,
            "recall": 0.59599,
            "fmeasure": 0.62561
        },
        "rougeL": {
            "precision": 0.85894,
            "recall": 0.71949,
            "fmeasure": 0.76439
        },
        "rougeLsum": {
            "precision": 0.85894,
            "recall": 0.71949,
            "fmeasure": 0.76439
        },
        "nubia": {
            "semantic_relation": 4.29518,
            "contradiction": 0.37637,
            "irrelevancy": 22.47804,
            "logical_agreement": 77.14558,
            "grammar_ref": 4.09757,
            "grammar_hyp": 4.06587,
            "nubia_score": 0.86785
        },
        "meteor": 0.4110449905242251,
        "bleurt": 0.46454,
        "bertscore": {
            "precision": 0.9612,
            "recall": 0.94657,
            "f1": 0.95332
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_111": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.029610672108601997,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.75,
            "3": 1.0
        },
        "nist": 3.514930358482146,
        "bleu": 50.1772,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.90278,
            "fmeasure": 0.86601
        },
        "rouge2": {
            "precision": 0.64706,
            "recall": 0.70458,
            "fmeasure": 0.67402
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.84259,
            "fmeasure": 0.80828
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.84259,
            "fmeasure": 0.80828
        },
        "nubia": {
            "semantic_relation": 4.40543,
            "contradiction": 0.08407,
            "irrelevancy": 0.75833,
            "logical_agreement": 99.15759,
            "grammar_ref": 3.66146,
            "grammar_hyp": 2.72425,
            "nubia_score": 0.95353
        },
        "meteor": 0.5002614954558539,
        "bleurt": 0.44243,
        "bertscore": {
            "precision": 0.93671,
            "recall": 0.96035,
            "f1": 0.94838
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_308": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 8,
        "total_length": 149,
        "mean_pred_length": 18.625,
        "std_pred_length": 4.948168853222372,
        "median_pred_length": 18.0,
        "min_pred_length": 13,
        "max_pred_length": 29,
        "distinct-1": 0.6577181208053692,
        "vocab_size-1": 98,
        "unique-1": 79,
        "entropy-1": 6.203449937065426,
        "distinct-2": 0.9645390070921985,
        "vocab_size-2": 136,
        "unique-2": 131,
        "entropy-2": 7.06862936658317,
        "cond_entropy-2": 0.776344423934583,
        "distinct-3": 1.0,
        "vocab_size-3": 133,
        "unique-3": 133,
        "entropy-3": 7.055282435501199,
        "cond_entropy-3": -0.009080946972791968,
        "total_length-nopunct": 133,
        "mean_pred_length-nopunct": 16.625,
        "std_pred_length-nopunct": 4.414110895752394,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.706766917293233,
        "vocab_size-1-nopunct": 94,
        "unique-1-nopunct": 79,
        "entropy-1-nopunct": 6.176066668812867,
        "distinct-2-nopunct": 0.976,
        "vocab_size-2-nopunct": 122,
        "unique-2-nopunct": 119,
        "entropy-2-nopunct": 6.917784284662096,
        "cond_entropy-2-nopunct": 0.7659874249172786,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 117,
        "unique-3-nopunct": 117,
        "entropy-3-nopunct": 6.8703647195833835,
        "cond_entropy-3-nopunct": -0.04413751379663118,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.72,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.6,
            "3": 0.7684210526315789
        },
        "nist": 5.821721156185527,
        "bleu": 49.64442,
        "rouge1": {
            "precision": 0.80065,
            "recall": 0.75457,
            "fmeasure": 0.76143
        },
        "rouge2": {
            "precision": 0.57783,
            "recall": 0.55663,
            "fmeasure": 0.55497
        },
        "rougeL": {
            "precision": 0.70596,
            "recall": 0.6837,
            "fmeasure": 0.68169
        },
        "rougeLsum": {
            "precision": 0.70596,
            "recall": 0.6837,
            "fmeasure": 0.68169
        },
        "nubia": {
            "semantic_relation": 4.15984,
            "contradiction": 0.89174,
            "irrelevancy": 37.31271,
            "logical_agreement": 61.79555,
            "grammar_ref": 4.94279,
            "grammar_hyp": 4.97067,
            "nubia_score": 0.70597
        },
        "meteor": 0.36836607345192707,
        "bleurt": 0.12864,
        "bertscore": {
            "precision": 0.93902,
            "recall": 0.9349,
            "f1": 0.93658
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_143": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 10,
        "total_length": 157,
        "mean_pred_length": 15.7,
        "std_pred_length": 6.679071791798618,
        "median_pred_length": 13.5,
        "min_pred_length": 4,
        "max_pred_length": 26,
        "distinct-1": 0.6050955414012739,
        "vocab_size-1": 95,
        "unique-1": 70,
        "entropy-1": 6.110339478879542,
        "distinct-2": 0.8843537414965986,
        "vocab_size-2": 130,
        "unique-2": 117,
        "entropy-2": 6.930898365215084,
        "cond_entropy-2": 0.7378569319146027,
        "distinct-3": 0.9562043795620438,
        "vocab_size-3": 131,
        "unique-3": 125,
        "entropy-3": 7.010440842084599,
        "cond_entropy-3": 0.0991610155280087,
        "total_length-nopunct": 143,
        "mean_pred_length-nopunct": 14.3,
        "std_pred_length-nopunct": 6.649060083951716,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6503496503496503,
        "vocab_size-1-nopunct": 93,
        "unique-1-nopunct": 70,
        "entropy-1-nopunct": 6.135938578823358,
        "distinct-2-nopunct": 0.8872180451127819,
        "vocab_size-2-nopunct": 118,
        "unique-2-nopunct": 107,
        "entropy-2-nopunct": 6.788291645994979,
        "cond_entropy-2-nopunct": 0.697987673022056,
        "distinct-3-nopunct": 0.959349593495935,
        "vocab_size-3-nopunct": 118,
        "unique-3-nopunct": 113,
        "entropy-3-nopunct": 6.8612136923310985,
        "cond_entropy-3-nopunct": 0.08649853328786239,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13559322033898305,
            "2": 0.15384615384615385,
            "3": 0.5196078431372549
        },
        "nist": 3.1306229519942264,
        "bleu": 8.54103,
        "rouge1": {
            "precision": 0.5477,
            "recall": 0.53381,
            "fmeasure": 0.50529
        },
        "rouge2": {
            "precision": 0.26245,
            "recall": 0.26505,
            "fmeasure": 0.25573
        },
        "rougeL": {
            "precision": 0.39405,
            "recall": 0.39854,
            "fmeasure": 0.36871
        },
        "rougeLsum": {
            "precision": 0.39405,
            "recall": 0.39854,
            "fmeasure": 0.36871
        },
        "nubia": {
            "semantic_relation": 3.54838,
            "contradiction": 10.85682,
            "irrelevancy": 48.20466,
            "logical_agreement": 40.93851,
            "grammar_ref": 4.73444,
            "grammar_hyp": 4.88549,
            "nubia_score": 0.52179
        },
        "meteor": 0.23902466770357111,
        "bleurt": -0.1114,
        "bertscore": {
            "precision": 0.86218,
            "recall": 0.86226,
            "f1": 0.85948
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_228": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 11,
        "total_length": 186,
        "mean_pred_length": 16.90909090909091,
        "std_pred_length": 4.999173485406371,
        "median_pred_length": 18.0,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.6827956989247311,
        "vocab_size-1": 127,
        "unique-1": 107,
        "entropy-1": 6.544148496622524,
        "distinct-2": 0.9828571428571429,
        "vocab_size-2": 172,
        "unique-2": 170,
        "entropy-2": 7.412611754677087,
        "cond_entropy-2": 0.7354680152572675,
        "distinct-3": 1.0,
        "vocab_size-3": 164,
        "unique-3": 164,
        "entropy-3": 7.357552004618105,
        "cond_entropy-3": -0.052470768786419306,
        "total_length-nopunct": 163,
        "mean_pred_length-nopunct": 14.818181818181818,
        "std_pred_length-nopunct": 4.4887370529558215,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.754601226993865,
        "vocab_size-1-nopunct": 123,
        "unique-1-nopunct": 107,
        "entropy-1-nopunct": 6.616683292068812,
        "distinct-2-nopunct": 0.9802631578947368,
        "vocab_size-2-nopunct": 149,
        "unique-2-nopunct": 147,
        "entropy-2-nopunct": 7.203487464087228,
        "cond_entropy-2-nopunct": 0.6266232080959846,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 141,
        "unique-3-nopunct": 141,
        "entropy-3-nopunct": 7.139551352398772,
        "cond_entropy-3-nopunct": -0.06046915748334867,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.8,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1875,
            "2": 0.3684210526315789,
            "3": 0.8285714285714286
        },
        "nist": 5.970989614644914,
        "bleu": 54.48105,
        "rouge1": {
            "precision": 0.8063,
            "recall": 0.80143,
            "fmeasure": 0.792
        },
        "rouge2": {
            "precision": 0.60033,
            "recall": 0.59082,
            "fmeasure": 0.58694
        },
        "rougeL": {
            "precision": 0.74123,
            "recall": 0.73142,
            "fmeasure": 0.72662
        },
        "rougeLsum": {
            "precision": 0.74123,
            "recall": 0.73142,
            "fmeasure": 0.72662
        },
        "nubia": {
            "semantic_relation": 4.20417,
            "contradiction": 9.0898,
            "irrelevancy": 26.62737,
            "logical_agreement": 64.28282,
            "grammar_ref": 4.46209,
            "grammar_hyp": 4.35358,
            "nubia_score": 0.7416
        },
        "meteor": 0.4514734686780682,
        "bleurt": 0.34807,
        "bertscore": {
            "precision": 0.93514,
            "recall": 0.93225,
            "f1": 0.93177
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_287": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 58,
        "mean_pred_length": 14.5,
        "std_pred_length": 2.29128784747792,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 17,
        "distinct-1": 0.8275862068965517,
        "vocab_size-1": 48,
        "unique-1": 42,
        "entropy-1": 5.444187891679295,
        "distinct-2": 1.0,
        "vocab_size-2": 54,
        "unique-2": 54,
        "entropy-2": 5.7548875021634665,
        "cond_entropy-2": 0.1932028033321929,
        "distinct-3": 1.0,
        "vocab_size-3": 50,
        "unique-3": 50,
        "entropy-3": 5.643856189774728,
        "cond_entropy-3": -0.11103131238874385,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 1.8027756377319946,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.92,
        "vocab_size-1-nopunct": 46,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.483856189774727,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.5235619560570095,
        "cond_entropy-2-nopunct": 0.05361880976054911,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.3923174227787625,
        "cond_entropy-3-nopunct": -0.1312445332782525,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.2,
            "3": 0.7321428571428571
        },
        "nist": 4.0303989764379295,
        "bleu": 52.84027,
        "rouge1": {
            "precision": 0.84977,
            "recall": 0.72841,
            "fmeasure": 0.76961
        },
        "rouge2": {
            "precision": 0.68829,
            "recall": 0.61597,
            "fmeasure": 0.63959
        },
        "rougeL": {
            "precision": 0.75594,
            "recall": 0.6867,
            "fmeasure": 0.70944
        },
        "rougeLsum": {
            "precision": 0.75594,
            "recall": 0.6867,
            "fmeasure": 0.70944
        },
        "nubia": {
            "semantic_relation": 4.59561,
            "contradiction": 0.26011,
            "irrelevancy": 0.82891,
            "logical_agreement": 98.91098,
            "grammar_ref": 4.68915,
            "grammar_hyp": 4.96259,
            "nubia_score": 0.82152
        },
        "meteor": 0.39355476538132506,
        "bleurt": 0.51492,
        "bertscore": {
            "precision": 0.9593,
            "recall": 0.93242,
            "f1": 0.94521
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_40": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 110,
        "total_length": 1758,
        "mean_pred_length": 15.981818181818182,
        "std_pred_length": 5.508640845702518,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.48293515358361777,
        "vocab_size-1": 849,
        "unique-1": 697,
        "entropy-1": 8.27617188226381,
        "distinct-2": 0.866504854368932,
        "vocab_size-2": 1428,
        "unique-2": 1323,
        "entropy-2": 10.302334650055103,
        "cond_entropy-2": 1.784339504731591,
        "distinct-3": 0.9570871261378413,
        "vocab_size-3": 1472,
        "unique-3": 1430,
        "entropy-3": 10.485438457026897,
        "cond_entropy-3": 0.19318401437208177,
        "total_length-nopunct": 1558,
        "mean_pred_length-nopunct": 14.163636363636364,
        "std_pred_length-nopunct": 5.177797483183319,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.5397946084724005,
        "vocab_size-1-nopunct": 841,
        "unique-1-nopunct": 696,
        "entropy-1-nopunct": 8.509218111488074,
        "distinct-2-nopunct": 0.8667127071823204,
        "vocab_size-2-nopunct": 1255,
        "unique-2-nopunct": 1169,
        "entropy-2-nopunct": 10.105097551100464,
        "cond_entropy-2-nopunct": 1.7191631270416072,
        "distinct-3-nopunct": 0.9581464872944694,
        "vocab_size-3-nopunct": 1282,
        "unique-3-nopunct": 1247,
        "entropy-3-nopunct": 10.286310562468106,
        "cond_entropy-3-nopunct": 0.206812706402291,
        "msttr-100": 0.73471,
        "msttr-100_nopunct": 0.772,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24867724867724866,
            "2": 0.5464190981432361,
            "3": 0.7924528301886793
        },
        "nist": 7.915990538433853,
        "bleu": 48.10996,
        "rouge1": {
            "precision": 0.75794,
            "recall": 0.7344,
            "fmeasure": 0.73657
        },
        "rouge2": {
            "precision": 0.53634,
            "recall": 0.52492,
            "fmeasure": 0.52312
        },
        "rougeL": {
            "precision": 0.65925,
            "recall": 0.64427,
            "fmeasure": 0.64267
        },
        "rougeLsum": {
            "precision": 0.65925,
            "recall": 0.64427,
            "fmeasure": 0.64267
        },
        "nubia": {
            "semantic_relation": 4.24365,
            "contradiction": 9.35964,
            "irrelevancy": 27.05588,
            "logical_agreement": 63.58448,
            "grammar_ref": 4.79734,
            "grammar_hyp": 4.75949,
            "nubia_score": 0.74368
        },
        "meteor": 0.40209202169873487,
        "bleurt": 0.2841,
        "bertscore": {
            "precision": 0.93491,
            "recall": 0.9304,
            "f1": 0.93153
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_250": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 16,
        "total_length": 254,
        "mean_pred_length": 15.875,
        "std_pred_length": 5.956876278721928,
        "median_pred_length": 14.5,
        "min_pred_length": 9,
        "max_pred_length": 35,
        "distinct-1": 0.6535433070866141,
        "vocab_size-1": 166,
        "unique-1": 139,
        "entropy-1": 6.862475899070478,
        "distinct-2": 0.9537815126050421,
        "vocab_size-2": 227,
        "unique-2": 219,
        "entropy-2": 7.787214231902791,
        "cond_entropy-2": 0.7764877937331663,
        "distinct-3": 0.9864864864864865,
        "vocab_size-3": 219,
        "unique-3": 216,
        "entropy-3": 7.767388839323067,
        "cond_entropy-3": -0.012070183109023015,
        "total_length-nopunct": 211,
        "mean_pred_length-nopunct": 13.1875,
        "std_pred_length-nopunct": 3.503904072602445,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7630331753554502,
        "vocab_size-1-nopunct": 161,
        "unique-1-nopunct": 138,
        "entropy-1-nopunct": 7.062381440960487,
        "distinct-2-nopunct": 0.9743589743589743,
        "vocab_size-2-nopunct": 190,
        "unique-2-nopunct": 185,
        "entropy-2-nopunct": 7.556048262467597,
        "cond_entropy-2-nopunct": 0.5477154572196447,
        "distinct-3-nopunct": 0.994413407821229,
        "vocab_size-3-nopunct": 178,
        "unique-3-nopunct": 177,
        "entropy-3-nopunct": 7.472642592906706,
        "cond_entropy-3-nopunct": -0.07882179905518687,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.835,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.12962962962962962,
            "2": 0.21951219512195122,
            "3": 0.7567567567567568
        },
        "nist": 5.893948373399762,
        "bleu": 47.45899,
        "rouge1": {
            "precision": 0.759,
            "recall": 0.70553,
            "fmeasure": 0.7258
        },
        "rouge2": {
            "precision": 0.52183,
            "recall": 0.49526,
            "fmeasure": 0.50345
        },
        "rougeL": {
            "precision": 0.64795,
            "recall": 0.60346,
            "fmeasure": 0.62024
        },
        "rougeLsum": {
            "precision": 0.64795,
            "recall": 0.60346,
            "fmeasure": 0.62024
        },
        "nubia": {
            "semantic_relation": 4.29076,
            "contradiction": 5.7554,
            "irrelevancy": 40.52063,
            "logical_agreement": 53.72397,
            "grammar_ref": 4.44923,
            "grammar_hyp": 4.60554,
            "nubia_score": 0.74365
        },
        "meteor": 0.39918300362715725,
        "bleurt": 0.33137,
        "bertscore": {
            "precision": 0.93607,
            "recall": 0.93111,
            "f1": 0.93201
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_41": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.875
        },
        "nist": 3.6770863059767853,
        "bleu": 79.10665,
        "rouge1": {
            "precision": 0.92857,
            "recall": 0.92857,
            "fmeasure": 0.92857
        },
        "rouge2": {
            "precision": 0.84615,
            "recall": 0.84615,
            "fmeasure": 0.84615
        },
        "rougeL": {
            "precision": 0.92857,
            "recall": 0.92857,
            "fmeasure": 0.92857
        },
        "rougeLsum": {
            "precision": 0.92857,
            "recall": 0.92857,
            "fmeasure": 0.92857
        },
        "nubia": {
            "semantic_relation": 4.63219,
            "contradiction": 0.25219,
            "irrelevancy": 33.52138,
            "logical_agreement": 66.22643,
            "grammar_ref": 4.76643,
            "grammar_hyp": 4.02495,
            "nubia_score": 0.94701
        },
        "meteor": 0.9515151515151515,
        "bleurt": 0.59769,
        "bertscore": {
            "precision": 0.98984,
            "recall": 0.98984,
            "f1": 0.98984
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_230": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 10,
        "total_length": 171,
        "mean_pred_length": 17.1,
        "std_pred_length": 5.575840743780259,
        "median_pred_length": 16.5,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.7485380116959064,
        "vocab_size-1": 128,
        "unique-1": 113,
        "entropy-1": 6.652975394888987,
        "distinct-2": 0.9813664596273292,
        "vocab_size-2": 158,
        "unique-2": 155,
        "entropy-2": 7.29364979736926,
        "cond_entropy-2": 0.5204804347782307,
        "distinct-3": 1.0,
        "vocab_size-3": 151,
        "unique-3": 151,
        "entropy-3": 7.238404739325059,
        "cond_entropy-3": -0.052777039451789916,
        "total_length-nopunct": 147,
        "mean_pred_length-nopunct": 14.7,
        "std_pred_length-nopunct": 4.473253849269009,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8299319727891157,
        "vocab_size-1-nopunct": 122,
        "unique-1-nopunct": 111,
        "entropy-1-nopunct": 6.713211290385153,
        "distinct-2-nopunct": 0.9927007299270073,
        "vocab_size-2-nopunct": 136,
        "unique-2-nopunct": 135,
        "entropy-2-nopunct": 7.083433542814526,
        "cond_entropy-2-nopunct": 0.3838325483747235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 127,
        "unique-3-nopunct": 127,
        "entropy-3-nopunct": 6.988684686772147,
        "cond_entropy-3-nopunct": -0.09359936469229793,
        "msttr-100": 0.79,
        "msttr-100_nopunct": 0.87,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21212121212121213,
            "2": 0.5526315789473685,
            "3": 0.7623762376237624
        },
        "nist": 5.454010816476286,
        "bleu": 46.91331,
        "rouge1": {
            "precision": 0.71236,
            "recall": 0.67987,
            "fmeasure": 0.69139
        },
        "rouge2": {
            "precision": 0.44468,
            "recall": 0.41788,
            "fmeasure": 0.42831
        },
        "rougeL": {
            "precision": 0.58621,
            "recall": 0.55134,
            "fmeasure": 0.56488
        },
        "rougeLsum": {
            "precision": 0.58621,
            "recall": 0.55134,
            "fmeasure": 0.56488
        },
        "nubia": {
            "semantic_relation": 4.00989,
            "contradiction": 19.95126,
            "irrelevancy": 34.21974,
            "logical_agreement": 45.82899,
            "grammar_ref": 5.06465,
            "grammar_hyp": 4.98519,
            "nubia_score": 0.66888
        },
        "meteor": 0.38237454528059817,
        "bleurt": 0.20124,
        "bertscore": {
            "precision": 0.9144,
            "recall": 0.90673,
            "f1": 0.90975
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_67": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.4677201004745006,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.2588453731729854,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.334679141051595,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.28076340776035313,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.1111111111111111,
            "3": 0.5
        },
        "nist": 1.4879525257381083,
        "bleu": 12.57119,
        "rouge1": {
            "precision": 0.38095,
            "recall": 0.47037,
            "fmeasure": 0.4075
        },
        "rouge2": {
            "precision": 0.23077,
            "recall": 0.30263,
            "fmeasure": 0.25298
        },
        "rougeL": {
            "precision": 0.38095,
            "recall": 0.47037,
            "fmeasure": 0.4075
        },
        "rougeLsum": {
            "precision": 0.38095,
            "recall": 0.47037,
            "fmeasure": 0.4075
        },
        "nubia": {
            "semantic_relation": 2.82375,
            "contradiction": 92.5183,
            "irrelevancy": 5.69143,
            "logical_agreement": 1.79026,
            "grammar_ref": 4.8547,
            "grammar_hyp": 4.89203,
            "nubia_score": 0.25938
        },
        "meteor": 0.20450259717837463,
        "bleurt": -0.68207,
        "bertscore": {
            "precision": 0.86971,
            "recall": 0.89623,
            "f1": 0.87962
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_252": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 19,
        "total_length": 360,
        "mean_pred_length": 18.94736842105263,
        "std_pred_length": 5.670548884697107,
        "median_pred_length": 17.0,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.5833333333333334,
        "vocab_size-1": 210,
        "unique-1": 171,
        "entropy-1": 6.948631141867319,
        "distinct-2": 0.9325513196480938,
        "vocab_size-2": 318,
        "unique-2": 305,
        "entropy-2": 8.241279248868274,
        "cond_entropy-2": 1.1909507965457473,
        "distinct-3": 0.9906832298136646,
        "vocab_size-3": 319,
        "unique-3": 316,
        "entropy-3": 8.312283337741993,
        "cond_entropy-3": 0.08117373149158381,
        "total_length-nopunct": 318,
        "mean_pred_length-nopunct": 16.736842105263158,
        "std_pred_length-nopunct": 4.908018200789375,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6446540880503144,
        "vocab_size-1-nopunct": 205,
        "unique-1-nopunct": 170,
        "entropy-1-nopunct": 7.043240294660724,
        "distinct-2-nopunct": 0.9297658862876255,
        "vocab_size-2-nopunct": 278,
        "unique-2-nopunct": 267,
        "entropy-2-nopunct": 8.040821406863055,
        "cond_entropy-2-nopunct": 1.0715717829443523,
        "distinct-3-nopunct": 0.9892857142857143,
        "vocab_size-3-nopunct": 277,
        "unique-3-nopunct": 274,
        "entropy-3-nopunct": 8.107854445516407,
        "cond_entropy-3-nopunct": 0.0738025478627395,
        "msttr-100": 0.70667,
        "msttr-100_nopunct": 0.74667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22058823529411764,
            "2": 0.5274725274725275,
            "3": 0.7341040462427746
        },
        "nist": 5.206684450572574,
        "bleu": 37.27672,
        "rouge1": {
            "precision": 0.65372,
            "recall": 0.6863,
            "fmeasure": 0.6564
        },
        "rouge2": {
            "precision": 0.42604,
            "recall": 0.44095,
            "fmeasure": 0.4248
        },
        "rougeL": {
            "precision": 0.56665,
            "recall": 0.59184,
            "fmeasure": 0.56834
        },
        "rougeLsum": {
            "precision": 0.56665,
            "recall": 0.59184,
            "fmeasure": 0.56834
        },
        "nubia": {
            "semantic_relation": 3.89299,
            "contradiction": 9.51668,
            "irrelevancy": 44.75268,
            "logical_agreement": 45.73063,
            "grammar_ref": 4.62734,
            "grammar_hyp": 4.62316,
            "nubia_score": 0.61652
        },
        "meteor": 0.3519092390211977,
        "bleurt": 0.06574,
        "bertscore": {
            "precision": 0.89299,
            "recall": 0.9182,
            "f1": 0.90289
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_112": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 47,
        "total_length": 832,
        "mean_pred_length": 17.70212765957447,
        "std_pred_length": 5.1111679708513025,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 33,
        "distinct-1": 0.5360576923076923,
        "vocab_size-1": 446,
        "unique-1": 363,
        "entropy-1": 7.734212327132988,
        "distinct-2": 0.9006369426751593,
        "vocab_size-2": 707,
        "unique-2": 653,
        "entropy-2": 9.378627625982167,
        "cond_entropy-2": 1.4613108456455581,
        "distinct-3": 0.9566395663956639,
        "vocab_size-3": 706,
        "unique-3": 676,
        "entropy-3": 9.438710373263117,
        "cond_entropy-3": 0.06981485735753296,
        "total_length-nopunct": 729,
        "mean_pred_length-nopunct": 15.51063829787234,
        "std_pred_length-nopunct": 4.43329923936647,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.6049382716049383,
        "vocab_size-1-nopunct": 441,
        "unique-1-nopunct": 363,
        "entropy-1-nopunct": 7.979551055417168,
        "distinct-2-nopunct": 0.9046920821114369,
        "vocab_size-2-nopunct": 617,
        "unique-2-nopunct": 573,
        "entropy-2-nopunct": 9.181218114560771,
        "cond_entropy-2-nopunct": 1.2814482183729257,
        "distinct-3-nopunct": 0.9622047244094488,
        "vocab_size-3-nopunct": 611,
        "unique-3-nopunct": 588,
        "entropy-3-nopunct": 9.233833431262356,
        "cond_entropy-3-nopunct": 0.06509289352016603,
        "msttr-100": 0.7125,
        "msttr-100_nopunct": 0.77429,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.32558139534883723,
            "3": 0.7836363636363637
        },
        "nist": 6.790903337673816,
        "bleu": 46.06884,
        "rouge1": {
            "precision": 0.74527,
            "recall": 0.74097,
            "fmeasure": 0.73266
        },
        "rouge2": {
            "precision": 0.53388,
            "recall": 0.53079,
            "fmeasure": 0.52416
        },
        "rougeL": {
            "precision": 0.66057,
            "recall": 0.6586,
            "fmeasure": 0.65039
        },
        "rougeLsum": {
            "precision": 0.66057,
            "recall": 0.6586,
            "fmeasure": 0.65039
        },
        "nubia": {
            "semantic_relation": 4.1222,
            "contradiction": 9.96204,
            "irrelevancy": 32.59535,
            "logical_agreement": 57.44261,
            "grammar_ref": 4.39993,
            "grammar_hyp": 4.37464,
            "nubia_score": 0.70754
        },
        "meteor": 0.3967626601115795,
        "bleurt": 0.22655,
        "bertscore": {
            "precision": 0.92187,
            "recall": 0.92261,
            "f1": 0.92079
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_144": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 46,
        "total_length": 762,
        "mean_pred_length": 16.565217391304348,
        "std_pred_length": 6.060033627087945,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 30,
        "distinct-1": 0.541994750656168,
        "vocab_size-1": 413,
        "unique-1": 334,
        "entropy-1": 7.695677454919179,
        "distinct-2": 0.9036312849162011,
        "vocab_size-2": 647,
        "unique-2": 602,
        "entropy-2": 9.234010464641278,
        "cond_entropy-2": 1.373242838194364,
        "distinct-3": 0.9671641791044776,
        "vocab_size-3": 648,
        "unique-3": 626,
        "entropy-3": 9.32234564355413,
        "cond_entropy-3": 0.0875755436599808,
        "total_length-nopunct": 669,
        "mean_pred_length-nopunct": 14.543478260869565,
        "std_pred_length-nopunct": 5.448200826835168,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6083707025411061,
        "vocab_size-1-nopunct": 407,
        "unique-1-nopunct": 332,
        "entropy-1-nopunct": 7.89577368891316,
        "distinct-2-nopunct": 0.9069020866773676,
        "vocab_size-2-nopunct": 565,
        "unique-2-nopunct": 529,
        "entropy-2-nopunct": 9.034515955210109,
        "cond_entropy-2-nopunct": 1.2138453052012923,
        "distinct-3-nopunct": 0.9688041594454073,
        "vocab_size-3-nopunct": 559,
        "unique-3-nopunct": 541,
        "entropy-3-nopunct": 9.110035827536164,
        "cond_entropy-3-nopunct": 0.09013742917087121,
        "msttr-100": 0.72143,
        "msttr-100_nopunct": 0.76667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23636363636363636,
            "2": 0.40145985401459855,
            "3": 0.7193675889328063
        },
        "nist": 6.247734696117084,
        "bleu": 38.60091,
        "rouge1": {
            "precision": 0.74497,
            "recall": 0.71085,
            "fmeasure": 0.71649
        },
        "rouge2": {
            "precision": 0.48446,
            "recall": 0.47596,
            "fmeasure": 0.4706
        },
        "rougeL": {
            "precision": 0.64363,
            "recall": 0.62494,
            "fmeasure": 0.62249
        },
        "rougeLsum": {
            "precision": 0.64363,
            "recall": 0.62494,
            "fmeasure": 0.62249
        },
        "nubia": {
            "semantic_relation": 4.18974,
            "contradiction": 12.03415,
            "irrelevancy": 32.1008,
            "logical_agreement": 55.86506,
            "grammar_ref": 4.63942,
            "grammar_hyp": 4.76263,
            "nubia_score": 0.70917
        },
        "meteor": 0.35285667783103314,
        "bleurt": 0.26081,
        "bertscore": {
            "precision": 0.92,
            "recall": 0.9129,
            "f1": 0.91481
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_168": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 44,
        "total_length": 693,
        "mean_pred_length": 15.75,
        "std_pred_length": 4.583195590216701,
        "median_pred_length": 14.5,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.5223665223665224,
        "vocab_size-1": 362,
        "unique-1": 288,
        "entropy-1": 7.519994854606086,
        "distinct-2": 0.8751926040061633,
        "vocab_size-2": 568,
        "unique-2": 522,
        "entropy-2": 9.033007738166665,
        "cond_entropy-2": 1.3279125671063075,
        "distinct-3": 0.9487603305785124,
        "vocab_size-3": 574,
        "unique-3": 553,
        "entropy-3": 9.125834513944351,
        "cond_entropy-3": 0.09422191199338745,
        "total_length-nopunct": 615,
        "mean_pred_length-nopunct": 13.977272727272727,
        "std_pred_length-nopunct": 4.644100051598393,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5788617886178862,
        "vocab_size-1-nopunct": 356,
        "unique-1-nopunct": 286,
        "entropy-1-nopunct": 7.685518697492076,
        "distinct-2-nopunct": 0.8791593695271454,
        "vocab_size-2-nopunct": 502,
        "unique-2-nopunct": 464,
        "entropy-2-nopunct": 8.854238945070437,
        "cond_entropy-2-nopunct": 1.2582234516170674,
        "distinct-3-nopunct": 0.9506641366223909,
        "vocab_size-3-nopunct": 501,
        "unique-3-nopunct": 483,
        "entropy-3-nopunct": 8.931528032059791,
        "cond_entropy-3-nopunct": 0.09167592583318335,
        "msttr-100": 0.71833,
        "msttr-100_nopunct": 0.77667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.29285714285714287,
            "2": 0.5448717948717948,
            "3": 0.7367149758454107
        },
        "nist": 6.5094292066757635,
        "bleu": 43.24545,
        "rouge1": {
            "precision": 0.74255,
            "recall": 0.7248,
            "fmeasure": 0.72362
        },
        "rouge2": {
            "precision": 0.50545,
            "recall": 0.49363,
            "fmeasure": 0.49236
        },
        "rougeL": {
            "precision": 0.66096,
            "recall": 0.64102,
            "fmeasure": 0.64234
        },
        "rougeLsum": {
            "precision": 0.66096,
            "recall": 0.64102,
            "fmeasure": 0.64234
        },
        "nubia": {
            "semantic_relation": 4.15414,
            "contradiction": 12.29363,
            "irrelevancy": 29.06083,
            "logical_agreement": 58.64555,
            "grammar_ref": 4.41204,
            "grammar_hyp": 4.47234,
            "nubia_score": 0.72259
        },
        "meteor": 0.38585049335765176,
        "bleurt": 0.21388,
        "bertscore": {
            "precision": 0.92384,
            "recall": 0.92074,
            "f1": 0.91947
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_169": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 51,
        "mean_pred_length": 17.0,
        "std_pred_length": 7.118052168020874,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.7843137254901961,
        "vocab_size-1": 40,
        "unique-1": 33,
        "entropy-1": 5.1722336752199904,
        "distinct-2": 0.9583333333333334,
        "vocab_size-2": 46,
        "unique-2": 44,
        "entropy-2": 5.501629167387827,
        "cond_entropy-2": 0.3189908046731386,
        "distinct-3": 1.0,
        "vocab_size-3": 45,
        "unique-3": 45,
        "entropy-3": 5.491853096329673,
        "cond_entropy-3": -0.0042205155025928556,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 6.944222218666553,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8085106382978723,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.096934064351533,
        "distinct-2-nopunct": 0.9772727272727273,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.413977073182751,
        "cond_entropy-2-nopunct": 0.34824674433072633,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.05309912621433558,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15,
            "2": 0.2727272727272727,
            "3": 0.6875
        },
        "nist": 3.511464736549499,
        "bleu": 24.21384,
        "rouge1": {
            "precision": 0.58436,
            "recall": 0.57769,
            "fmeasure": 0.57976
        },
        "rouge2": {
            "precision": 0.34042,
            "recall": 0.4042,
            "fmeasure": 0.36085
        },
        "rougeL": {
            "precision": 0.43129,
            "recall": 0.48527,
            "fmeasure": 0.44833
        },
        "rougeLsum": {
            "precision": 0.43129,
            "recall": 0.48527,
            "fmeasure": 0.44833
        },
        "nubia": {
            "semantic_relation": 4.20462,
            "contradiction": 0.26008,
            "irrelevancy": 22.8991,
            "logical_agreement": 76.84082,
            "grammar_ref": 4.07664,
            "grammar_hyp": 4.3328,
            "nubia_score": 0.76201
        },
        "meteor": 0.30882958192076176,
        "bleurt": 0.17188,
        "bertscore": {
            "precision": 0.90287,
            "recall": 0.90957,
            "f1": 0.89694
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_253": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 4.0,
        "median_pred_length": 18.0,
        "min_pred_length": 14,
        "max_pred_length": 22,
        "distinct-1": 0.8055555555555556,
        "vocab_size-1": 29,
        "unique-1": 22,
        "entropy-1": 4.781036112553422,
        "distinct-2": 0.9117647058823529,
        "vocab_size-2": 31,
        "unique-2": 28,
        "entropy-2": 4.910992253015044,
        "cond_entropy-2": 0.09400842804332116,
        "distinct-3": 0.9375,
        "vocab_size-3": 30,
        "unique-3": 28,
        "entropy-3": 4.875,
        "cond_entropy-3": -0.02496284125033942,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8387096774193549,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.631615665225586,
        "distinct-2-nopunct": 0.896551724137931,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.651084443403434,
        "cond_entropy-2-nopunct": 0.0072329606027659935,
        "distinct-3-nopunct": 0.9259259259259259,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.606739354015322,
        "cond_entropy-3-nopunct": -0.06605645592706638,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.34210526315789475
        },
        "nist": 1.462842959488487,
        "bleu": 26.27641,
        "rouge1": {
            "precision": 0.69414,
            "recall": 0.57349,
            "fmeasure": 0.60797
        },
        "rouge2": {
            "precision": 0.55833,
            "recall": 0.47545,
            "fmeasure": 0.49697
        },
        "rougeL": {
            "precision": 0.69414,
            "recall": 0.57349,
            "fmeasure": 0.60797
        },
        "rougeLsum": {
            "precision": 0.69414,
            "recall": 0.57349,
            "fmeasure": 0.60797
        },
        "nubia": {
            "semantic_relation": 3.29992,
            "contradiction": 30.26892,
            "irrelevancy": 13.60683,
            "logical_agreement": 56.12425,
            "grammar_ref": 4.45404,
            "grammar_hyp": 3.8227,
            "nubia_score": 0.54886
        },
        "meteor": 0.2225241303828783,
        "bleurt": -0.16368,
        "bertscore": {
            "precision": 0.92971,
            "recall": 0.84549,
            "f1": 0.88219
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_170": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 15,
        "total_length": 261,
        "mean_pred_length": 17.4,
        "std_pred_length": 4.97728172131469,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 25,
        "distinct-1": 0.6091954022988506,
        "vocab_size-1": 159,
        "unique-1": 131,
        "entropy-1": 6.69915095055543,
        "distinct-2": 0.9471544715447154,
        "vocab_size-2": 233,
        "unique-2": 222,
        "entropy-2": 7.830686151663151,
        "cond_entropy-2": 1.0409159038871934,
        "distinct-3": 0.987012987012987,
        "vocab_size-3": 228,
        "unique-3": 225,
        "entropy-3": 7.825775015442002,
        "cond_entropy-3": -0.004510864340473179,
        "total_length-nopunct": 235,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 5.094659513211413,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6553191489361702,
        "vocab_size-1-nopunct": 154,
        "unique-1-nopunct": 129,
        "entropy-1-nopunct": 6.733123025715003,
        "distinct-2-nopunct": 0.95,
        "vocab_size-2-nopunct": 209,
        "unique-2-nopunct": 200,
        "entropy-2-nopunct": 7.6744970998686135,
        "cond_entropy-2-nopunct": 0.9931741710199191,
        "distinct-3-nopunct": 0.9951219512195122,
        "vocab_size-3-nopunct": 204,
        "unique-3-nopunct": 203,
        "entropy-3-nopunct": 7.669724001944456,
        "cond_entropy-3-nopunct": -0.004685406684551317,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22857142857142856,
            "2": 0.4230769230769231,
            "3": 0.78125
        },
        "nist": 6.1228806981078865,
        "bleu": 47.90305,
        "rouge1": {
            "precision": 0.80347,
            "recall": 0.74983,
            "fmeasure": 0.76529
        },
        "rouge2": {
            "precision": 0.58916,
            "recall": 0.54721,
            "fmeasure": 0.55932
        },
        "rougeL": {
            "precision": 0.75603,
            "recall": 0.7013,
            "fmeasure": 0.71672
        },
        "rougeLsum": {
            "precision": 0.75603,
            "recall": 0.7013,
            "fmeasure": 0.71672
        },
        "nubia": {
            "semantic_relation": 4.15042,
            "contradiction": 7.25152,
            "irrelevancy": 31.53426,
            "logical_agreement": 61.21422,
            "grammar_ref": 4.2734,
            "grammar_hyp": 4.49276,
            "nubia_score": 0.6939
        },
        "meteor": 0.39433570236406634,
        "bleurt": 0.28102,
        "bertscore": {
            "precision": 0.93184,
            "recall": 0.92578,
            "f1": 0.92744
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_145": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 17,
        "total_length": 272,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.86282416128009,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.5992647058823529,
        "vocab_size-1": 163,
        "unique-1": 133,
        "entropy-1": 6.664391706716296,
        "distinct-2": 0.9058823529411765,
        "vocab_size-2": 231,
        "unique-2": 211,
        "entropy-2": 7.784511181939941,
        "cond_entropy-2": 0.9640104920357108,
        "distinct-3": 0.9537815126050421,
        "vocab_size-3": 227,
        "unique-3": 216,
        "entropy-3": 7.802380788518074,
        "cond_entropy-3": 0.024454977727770257,
        "total_length-nopunct": 231,
        "mean_pred_length-nopunct": 13.588235294117647,
        "std_pred_length-nopunct": 4.229571296999423,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6883116883116883,
        "vocab_size-1-nopunct": 159,
        "unique-1-nopunct": 133,
        "entropy-1-nopunct": 6.79568807930013,
        "distinct-2-nopunct": 0.9158878504672897,
        "vocab_size-2-nopunct": 196,
        "unique-2-nopunct": 182,
        "entropy-2-nopunct": 7.5474960751659435,
        "cond_entropy-2-nopunct": 0.812336203136709,
        "distinct-3-nopunct": 0.9644670050761421,
        "vocab_size-3-nopunct": 190,
        "unique-3-nopunct": 183,
        "entropy-3-nopunct": 7.550985829608622,
        "cond_entropy-3-nopunct": 0.0151522188639956,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.785,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1076923076923077,
            "2": 0.5263157894736842,
            "3": 0.813953488372093
        },
        "nist": 6.084818876230943,
        "bleu": 41.41648,
        "rouge1": {
            "precision": 0.80227,
            "recall": 0.74965,
            "fmeasure": 0.76572
        },
        "rouge2": {
            "precision": 0.53377,
            "recall": 0.52192,
            "fmeasure": 0.52266
        },
        "rougeL": {
            "precision": 0.63914,
            "recall": 0.61348,
            "fmeasure": 0.62093
        },
        "rougeLsum": {
            "precision": 0.63914,
            "recall": 0.61348,
            "fmeasure": 0.62093
        },
        "nubia": {
            "semantic_relation": 4.23136,
            "contradiction": 10.19879,
            "irrelevancy": 16.63779,
            "logical_agreement": 73.16342,
            "grammar_ref": 4.90086,
            "grammar_hyp": 4.99416,
            "nubia_score": 0.71555
        },
        "meteor": 0.39273117381061706,
        "bleurt": 0.27143,
        "bertscore": {
            "precision": 0.93536,
            "recall": 0.93205,
            "f1": 0.9322
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_288": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 12,
        "total_length": 200,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 6.182412330330469,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.605,
        "vocab_size-1": 121,
        "unique-1": 95,
        "entropy-1": 6.329505659036221,
        "distinct-2": 0.9095744680851063,
        "vocab_size-2": 171,
        "unique-2": 158,
        "entropy-2": 7.355068771867405,
        "cond_entropy-2": 0.9523869498305441,
        "distinct-3": 0.9715909090909091,
        "vocab_size-3": 171,
        "unique-3": 166,
        "entropy-3": 7.402613436819128,
        "cond_entropy-3": 0.06114830675697171,
        "total_length-nopunct": 179,
        "mean_pred_length-nopunct": 14.916666666666666,
        "std_pred_length-nopunct": 5.453719423985392,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.659217877094972,
        "vocab_size-1-nopunct": 118,
        "unique-1-nopunct": 94,
        "entropy-1-nopunct": 6.38724017207033,
        "distinct-2-nopunct": 0.9161676646706587,
        "vocab_size-2-nopunct": 153,
        "unique-2-nopunct": 141,
        "entropy-2-nopunct": 7.206999052927161,
        "cond_entropy-2-nopunct": 0.8691721543102505,
        "distinct-3-nopunct": 0.9741935483870968,
        "vocab_size-3-nopunct": 151,
        "unique-3-nopunct": 147,
        "entropy-3-nopunct": 7.2245115020484505,
        "cond_entropy-3-nopunct": 0.018289628957133375,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.45161290322580644,
            "3": 0.7404580152671756
        },
        "nist": 5.366061305917174,
        "bleu": 45.34976,
        "rouge1": {
            "precision": 0.76168,
            "recall": 0.73819,
            "fmeasure": 0.73902
        },
        "rouge2": {
            "precision": 0.59255,
            "recall": 0.57043,
            "fmeasure": 0.57348
        },
        "rougeL": {
            "precision": 0.63946,
            "recall": 0.62689,
            "fmeasure": 0.62487
        },
        "rougeLsum": {
            "precision": 0.63946,
            "recall": 0.62689,
            "fmeasure": 0.62487
        },
        "nubia": {
            "semantic_relation": 4.20921,
            "contradiction": 9.7428,
            "irrelevancy": 31.82216,
            "logical_agreement": 58.43505,
            "grammar_ref": 4.5489,
            "grammar_hyp": 4.87427,
            "nubia_score": 0.67885
        },
        "meteor": 0.38464125091793144,
        "bleurt": 0.19755,
        "bertscore": {
            "precision": 0.93198,
            "recall": 0.9284,
            "f1": 0.92994
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_289": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.7,
        "vocab_size-1": 14,
        "unique-1": 8,
        "entropy-1": 3.721928094887362,
        "distinct-2": 0.7894736842105263,
        "vocab_size-2": 15,
        "unique-2": 11,
        "entropy-2": 3.826874881864636,
        "cond_entropy-2": 0.08389415539832848,
        "distinct-3": 0.8888888888888888,
        "vocab_size-3": 16,
        "unique-3": 14,
        "entropy-3": 3.94770277922009,
        "cond_entropy-3": 0.08866415466539351,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.5032583347756456,
        "distinct-2-nopunct": 0.7647058823529411,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.6168746059562227,
        "cond_entropy-2-nopunct": 0.09400842804332114,
        "distinct-3-nopunct": 0.875,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.75,
        "cond_entropy-3-nopunct": 0.10003715874966063,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2,
            "3": 0.6666666666666666
        },
        "nist": 2.2460115665330793,
        "bleu": 28.3393,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.53571,
            "fmeasure": 0.61224
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.2963,
            "fmeasure": 0.34043
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.5,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.5,
            "fmeasure": 0.57143
        },
        "nubia": {
            "semantic_relation": 3.62121,
            "contradiction": 56.40931,
            "irrelevancy": 15.68625,
            "logical_agreement": 27.90444,
            "grammar_ref": 3.99891,
            "grammar_hyp": 4.20733,
            "nubia_score": 0.50891
        },
        "meteor": 0.29338635671236885,
        "bleurt": -0.19316,
        "bertscore": {
            "precision": 0.8882,
            "recall": 0.93351,
            "f1": 0.91029
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_146": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.046930949929641655,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6
        },
        "nist": 2.1279098100202685,
        "bleu": 22.71871,
        "rouge1": {
            "precision": 0.58974,
            "recall": 0.71818,
            "fmeasure": 0.64734
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.48148,
            "fmeasure": 0.43001
        },
        "rougeL": {
            "precision": 0.58974,
            "recall": 0.71818,
            "fmeasure": 0.64734
        },
        "rougeLsum": {
            "precision": 0.58974,
            "recall": 0.71818,
            "fmeasure": 0.64734
        },
        "nubia": {
            "semantic_relation": 3.88144,
            "contradiction": 0.5302,
            "irrelevancy": 89.95724,
            "logical_agreement": 9.51257,
            "grammar_ref": 5.00001,
            "grammar_hyp": 4.5907,
            "nubia_score": 0.59017
        },
        "meteor": 0.3951686358072344,
        "bleurt": 0.17654,
        "bertscore": {
            "precision": 0.89942,
            "recall": 0.9298,
            "f1": 0.91436
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_42": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 54,
        "total_length": 917,
        "mean_pred_length": 16.98148148148148,
        "std_pred_length": 5.539390061158094,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 28,
        "distinct-1": 0.5223555070883316,
        "vocab_size-1": 479,
        "unique-1": 382,
        "entropy-1": 7.857512544898443,
        "distinct-2": 0.9061413673232909,
        "vocab_size-2": 782,
        "unique-2": 734,
        "entropy-2": 9.514787295652944,
        "cond_entropy-2": 1.5003030426735964,
        "distinct-3": 0.9814585908529048,
        "vocab_size-3": 794,
        "unique-3": 780,
        "entropy-3": 9.621979962266526,
        "cond_entropy-3": 0.1156910479366785,
        "total_length-nopunct": 819,
        "mean_pred_length-nopunct": 15.166666666666666,
        "std_pred_length-nopunct": 5.173830159419472,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.575091575091575,
        "vocab_size-1-nopunct": 471,
        "unique-1-nopunct": 380,
        "entropy-1-nopunct": 8.04014932615754,
        "distinct-2-nopunct": 0.9084967320261438,
        "vocab_size-2-nopunct": 695,
        "unique-2-nopunct": 656,
        "entropy-2-nopunct": 9.341074312235653,
        "cond_entropy-2-nopunct": 1.368967827150711,
        "distinct-3-nopunct": 0.9817158931082982,
        "vocab_size-3-nopunct": 698,
        "unique-3-nopunct": 686,
        "entropy-3-nopunct": 9.436075809391253,
        "cond_entropy-3-nopunct": 0.11028285829308096,
        "msttr-100": 0.75667,
        "msttr-100_nopunct": 0.80125,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22905027932960895,
            "2": 0.3942857142857143,
            "3": 0.7419354838709677
        },
        "nist": 6.673036529944166,
        "bleu": 41.04119,
        "rouge1": {
            "precision": 0.73902,
            "recall": 0.71787,
            "fmeasure": 0.71472
        },
        "rouge2": {
            "precision": 0.49404,
            "recall": 0.48549,
            "fmeasure": 0.48166
        },
        "rougeL": {
            "precision": 0.61362,
            "recall": 0.59275,
            "fmeasure": 0.59158
        },
        "rougeLsum": {
            "precision": 0.61362,
            "recall": 0.59275,
            "fmeasure": 0.59158
        },
        "nubia": {
            "semantic_relation": 4.16858,
            "contradiction": 11.23192,
            "irrelevancy": 30.10591,
            "logical_agreement": 58.66218,
            "grammar_ref": 4.68502,
            "grammar_hyp": 4.66663,
            "nubia_score": 0.71372
        },
        "meteor": 0.3715714545077482,
        "bleurt": 0.19356,
        "bertscore": {
            "precision": 0.92212,
            "recall": 0.92024,
            "f1": 0.9201
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_91": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 18,
        "total_length": 270,
        "mean_pred_length": 15.0,
        "std_pred_length": 5.185449728701348,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.6148148148148148,
        "vocab_size-1": 166,
        "unique-1": 135,
        "entropy-1": 6.719457609279481,
        "distinct-2": 0.9285714285714286,
        "vocab_size-2": 234,
        "unique-2": 222,
        "entropy-2": 7.811112054527992,
        "cond_entropy-2": 0.9346403332639224,
        "distinct-3": 0.9786324786324786,
        "vocab_size-3": 229,
        "unique-3": 225,
        "entropy-3": 7.824403661881837,
        "cond_entropy-3": 0.026073751120939827,
        "total_length-nopunct": 237,
        "mean_pred_length-nopunct": 13.166666666666666,
        "std_pred_length-nopunct": 5.145116346811044,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6751054852320675,
        "vocab_size-1-nopunct": 160,
        "unique-1-nopunct": 133,
        "entropy-1-nopunct": 6.789870215593406,
        "distinct-2-nopunct": 0.9269406392694064,
        "vocab_size-2-nopunct": 203,
        "unique-2-nopunct": 192,
        "entropy-2-nopunct": 7.605292011752946,
        "cond_entropy-2-nopunct": 0.8756718057429689,
        "distinct-3-nopunct": 0.9850746268656716,
        "vocab_size-3-nopunct": 198,
        "unique-3-nopunct": 195,
        "entropy-3-nopunct": 7.621200944910282,
        "cond_entropy-3-nopunct": 0.021137345402450408,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20408163265306123,
            "2": 0.5178571428571429,
            "3": 0.7588235294117647
        },
        "nist": 5.7729428935244105,
        "bleu": 41.7088,
        "rouge1": {
            "precision": 0.75502,
            "recall": 0.7036,
            "fmeasure": 0.71945
        },
        "rouge2": {
            "precision": 0.50599,
            "recall": 0.46787,
            "fmeasure": 0.4787
        },
        "rougeL": {
            "precision": 0.65894,
            "recall": 0.61545,
            "fmeasure": 0.62843
        },
        "rougeLsum": {
            "precision": 0.65894,
            "recall": 0.61545,
            "fmeasure": 0.62843
        },
        "nubia": {
            "semantic_relation": 4.18004,
            "contradiction": 2.43579,
            "irrelevancy": 38.46416,
            "logical_agreement": 59.10005,
            "grammar_ref": 4.90853,
            "grammar_hyp": 4.99779,
            "nubia_score": 0.71344
        },
        "meteor": 0.36611372001677067,
        "bleurt": 0.2542,
        "bertscore": {
            "precision": 0.92676,
            "recall": 0.92108,
            "f1": 0.92247
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_114": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 28,
        "total_length": 487,
        "mean_pred_length": 17.392857142857142,
        "std_pred_length": 5.446750575961295,
        "median_pred_length": 17.5,
        "min_pred_length": 9,
        "max_pred_length": 34,
        "distinct-1": 0.5749486652977412,
        "vocab_size-1": 280,
        "unique-1": 226,
        "entropy-1": 7.30390584883132,
        "distinct-2": 0.8997821350762527,
        "vocab_size-2": 413,
        "unique-2": 387,
        "entropy-2": 8.577562345025285,
        "cond_entropy-2": 1.1308009823675482,
        "distinct-3": 0.9721577726218097,
        "vocab_size-3": 419,
        "unique-3": 407,
        "entropy-3": 8.695859604332702,
        "cond_entropy-3": 0.1354992638432116,
        "total_length-nopunct": 429,
        "mean_pred_length-nopunct": 15.321428571428571,
        "std_pred_length-nopunct": 4.140855427743087,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6433566433566433,
        "vocab_size-1-nopunct": 276,
        "unique-1-nopunct": 226,
        "entropy-1-nopunct": 7.447807003172982,
        "distinct-2-nopunct": 0.9177057356608479,
        "vocab_size-2-nopunct": 368,
        "unique-2-nopunct": 349,
        "entropy-2-nopunct": 8.425081460659898,
        "cond_entropy-2-nopunct": 1.0478897975397494,
        "distinct-3-nopunct": 0.9812332439678284,
        "vocab_size-3-nopunct": 366,
        "unique-3-nopunct": 359,
        "entropy-3-nopunct": 8.505498308190928,
        "cond_entropy-3-nopunct": 0.09174809429300942,
        "msttr-100": 0.7525,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14102564102564102,
            "2": 0.49333333333333335,
            "3": 0.7222222222222222
        },
        "nist": 6.320119333866146,
        "bleu": 46.47082,
        "rouge1": {
            "precision": 0.76173,
            "recall": 0.69309,
            "fmeasure": 0.71733
        },
        "rouge2": {
            "precision": 0.52713,
            "recall": 0.48946,
            "fmeasure": 0.50117
        },
        "rougeL": {
            "precision": 0.66458,
            "recall": 0.61446,
            "fmeasure": 0.63015
        },
        "rougeLsum": {
            "precision": 0.66458,
            "recall": 0.61446,
            "fmeasure": 0.63015
        },
        "nubia": {
            "semantic_relation": 4.08454,
            "contradiction": 8.21719,
            "irrelevancy": 31.78382,
            "logical_agreement": 59.99899,
            "grammar_ref": 4.55489,
            "grammar_hyp": 4.60466,
            "nubia_score": 0.70015
        },
        "meteor": 0.3691372109000027,
        "bleurt": 0.22609,
        "bertscore": {
            "precision": 0.92748,
            "recall": 0.91601,
            "f1": 0.9193
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_231": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 16,
        "total_length": 245,
        "mean_pred_length": 15.3125,
        "std_pred_length": 3.9799301187332423,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.5918367346938775,
        "vocab_size-1": 145,
        "unique-1": 113,
        "entropy-1": 6.595367349178355,
        "distinct-2": 0.9213973799126638,
        "vocab_size-2": 211,
        "unique-2": 196,
        "entropy-2": 7.669968471493615,
        "cond_entropy-2": 0.9080376747303813,
        "distinct-3": 0.9577464788732394,
        "vocab_size-3": 204,
        "unique-3": 195,
        "entropy-3": 7.650202577972357,
        "cond_entropy-3": -0.007053381475971983,
        "total_length-nopunct": 212,
        "mean_pred_length-nopunct": 13.25,
        "std_pred_length-nopunct": 3.6314597615834874,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.660377358490566,
        "vocab_size-1-nopunct": 140,
        "unique-1-nopunct": 112,
        "entropy-1-nopunct": 6.6786543566223004,
        "distinct-2-nopunct": 0.9183673469387755,
        "vocab_size-2-nopunct": 180,
        "unique-2-nopunct": 167,
        "entropy-2-nopunct": 7.43738898951232,
        "cond_entropy-2-nopunct": 0.813776763334194,
        "distinct-3-nopunct": 0.9611111111111111,
        "vocab_size-3-nopunct": 173,
        "unique-3-nopunct": 166,
        "entropy-3-nopunct": 7.414075318551882,
        "cond_entropy-3-nopunct": -0.01310737277351436,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3170731707317073,
            "2": 0.5217391304347826,
            "3": 0.8109756097560976
        },
        "nist": 6.341971439235355,
        "bleu": 53.60782,
        "rouge1": {
            "precision": 0.7824,
            "recall": 0.79992,
            "fmeasure": 0.78587
        },
        "rouge2": {
            "precision": 0.57428,
            "recall": 0.58238,
            "fmeasure": 0.57489
        },
        "rougeL": {
            "precision": 0.7127,
            "recall": 0.73089,
            "fmeasure": 0.71724
        },
        "rougeLsum": {
            "precision": 0.7127,
            "recall": 0.73089,
            "fmeasure": 0.71724
        },
        "nubia": {
            "semantic_relation": 4.52505,
            "contradiction": 5.74707,
            "irrelevancy": 20.67056,
            "logical_agreement": 73.58237,
            "grammar_ref": 4.58203,
            "grammar_hyp": 4.55935,
            "nubia_score": 0.81126
        },
        "meteor": 0.4429767464571547,
        "bleurt": 0.45086,
        "bertscore": {
            "precision": 0.93816,
            "recall": 0.94246,
            "f1": 0.93949
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_147": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 17,
        "total_length": 259,
        "mean_pred_length": 15.235294117647058,
        "std_pred_length": 3.4561013697807956,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 22,
        "distinct-1": 0.6293436293436293,
        "vocab_size-1": 163,
        "unique-1": 130,
        "entropy-1": 6.793309061964762,
        "distinct-2": 0.9504132231404959,
        "vocab_size-2": 230,
        "unique-2": 218,
        "entropy-2": 7.8196896835555885,
        "cond_entropy-2": 0.8283564616006286,
        "distinct-3": 0.9822222222222222,
        "vocab_size-3": 221,
        "unique-3": 217,
        "entropy-3": 7.778225635661439,
        "cond_entropy-3": -0.042859823835335514,
        "total_length-nopunct": 228,
        "mean_pred_length-nopunct": 13.411764705882353,
        "std_pred_length-nopunct": 3.866276876507055,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6929824561403509,
        "vocab_size-1-nopunct": 158,
        "unique-1-nopunct": 129,
        "entropy-1-nopunct": 6.890477267902912,
        "distinct-2-nopunct": 0.95260663507109,
        "vocab_size-2-nopunct": 201,
        "unique-2-nopunct": 191,
        "entropy-2-nopunct": 7.62631245884939,
        "cond_entropy-2-nopunct": 0.7605140321561201,
        "distinct-3-nopunct": 0.9845360824742269,
        "vocab_size-3-nopunct": 191,
        "unique-3-nopunct": 188,
        "entropy-3-nopunct": 7.5689850071355576,
        "cond_entropy-3-nopunct": -0.049021398066448986,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.8,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22727272727272727,
            "2": 0.42857142857142855,
            "3": 0.7849462365591398
        },
        "nist": 6.460779509346244,
        "bleu": 55.64765,
        "rouge1": {
            "precision": 0.79117,
            "recall": 0.76117,
            "fmeasure": 0.76532
        },
        "rouge2": {
            "precision": 0.60393,
            "recall": 0.58693,
            "fmeasure": 0.58718
        },
        "rougeL": {
            "precision": 0.69989,
            "recall": 0.69186,
            "fmeasure": 0.68818
        },
        "rougeLsum": {
            "precision": 0.69989,
            "recall": 0.69186,
            "fmeasure": 0.68818
        },
        "nubia": {
            "semantic_relation": 4.26673,
            "contradiction": 14.04917,
            "irrelevancy": 22.53286,
            "logical_agreement": 63.41797,
            "grammar_ref": 4.21928,
            "grammar_hyp": 4.16565,
            "nubia_score": 0.75467
        },
        "meteor": 0.41516632320986324,
        "bleurt": 0.33964,
        "bertscore": {
            "precision": 0.94433,
            "recall": 0.93802,
            "f1": 0.93892
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_92": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 22,
        "total_length": 335,
        "mean_pred_length": 15.227272727272727,
        "std_pred_length": 4.689754967254959,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.5940298507462687,
        "vocab_size-1": 199,
        "unique-1": 163,
        "entropy-1": 6.858301537611767,
        "distinct-2": 0.9297124600638977,
        "vocab_size-2": 291,
        "unique-2": 277,
        "entropy-2": 8.113465732143956,
        "cond_entropy-2": 1.0865226116325224,
        "distinct-3": 0.9828178694158075,
        "vocab_size-3": 286,
        "unique-3": 281,
        "entropy-3": 8.150511081739898,
        "cond_entropy-3": 0.05039300775862077,
        "total_length-nopunct": 293,
        "mean_pred_length-nopunct": 13.318181818181818,
        "std_pred_length-nopunct": 4.289377615759484,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6552901023890785,
        "vocab_size-1-nopunct": 192,
        "unique-1-nopunct": 160,
        "entropy-1-nopunct": 6.937416505436698,
        "distinct-2-nopunct": 0.922509225092251,
        "vocab_size-2-nopunct": 250,
        "unique-2-nopunct": 237,
        "entropy-2-nopunct": 7.885613525011254,
        "cond_entropy-2-nopunct": 1.0391988191232684,
        "distinct-3-nopunct": 0.9839357429718876,
        "vocab_size-3-nopunct": 245,
        "unique-3-nopunct": 241,
        "entropy-3-nopunct": 7.927873418011858,
        "cond_entropy-3-nopunct": 0.059624476773807764,
        "msttr-100": 0.70333,
        "msttr-100_nopunct": 0.785,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.43636363636363634,
            "3": 0.8152173913043478
        },
        "nist": 5.623175546865243,
        "bleu": 40.21269,
        "rouge1": {
            "precision": 0.70151,
            "recall": 0.75878,
            "fmeasure": 0.71556
        },
        "rouge2": {
            "precision": 0.45666,
            "recall": 0.47584,
            "fmeasure": 0.45758
        },
        "rougeL": {
            "precision": 0.61494,
            "recall": 0.66695,
            "fmeasure": 0.62808
        },
        "rougeLsum": {
            "precision": 0.61494,
            "recall": 0.66695,
            "fmeasure": 0.62808
        },
        "nubia": {
            "semantic_relation": 4.20609,
            "contradiction": 6.98815,
            "irrelevancy": 32.05318,
            "logical_agreement": 60.95866,
            "grammar_ref": 5.03776,
            "grammar_hyp": 4.94577,
            "nubia_score": 0.73001
        },
        "meteor": 0.3896446210005598,
        "bleurt": 0.21471,
        "bertscore": {
            "precision": 0.91212,
            "recall": 0.92498,
            "f1": 0.91742
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_255": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 6,
        "total_length": 92,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 4.307615994440028,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.7717391304347826,
        "vocab_size-1": 71,
        "unique-1": 64,
        "entropy-1": 5.8834113800833165,
        "distinct-2": 1.0,
        "vocab_size-2": 86,
        "unique-2": 86,
        "entropy-2": 6.426264754702099,
        "cond_entropy-2": 0.4071688217294358,
        "distinct-3": 1.0,
        "vocab_size-3": 80,
        "unique-3": 80,
        "entropy-3": 6.321928094887356,
        "cond_entropy-3": -0.10433665981473575,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 13.833333333333334,
        "std_pred_length-nopunct": 3.6247605284885913,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8313253012048193,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 64,
        "entropy-1-nopunct": 5.909627497815717,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 77,
        "unique-2-nopunct": 77,
        "entropy-2-nopunct": 6.266786540694905,
        "cond_entropy-2-nopunct": 0.380437894842661,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 71,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 6.149747119504677,
        "cond_entropy-3-nopunct": -0.11703942119021936,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.3333333333333333,
            "3": 0.7428571428571429
        },
        "nist": 4.8633648670297704,
        "bleu": 33.42686,
        "rouge1": {
            "precision": 0.77357,
            "recall": 0.7368,
            "fmeasure": 0.74494
        },
        "rouge2": {
            "precision": 0.47842,
            "recall": 0.45811,
            "fmeasure": 0.46178
        },
        "rougeL": {
            "precision": 0.54474,
            "recall": 0.53094,
            "fmeasure": 0.52948
        },
        "rougeLsum": {
            "precision": 0.54474,
            "recall": 0.53094,
            "fmeasure": 0.52948
        },
        "nubia": {
            "semantic_relation": 4.19139,
            "contradiction": 18.47496,
            "irrelevancy": 27.80607,
            "logical_agreement": 53.71897,
            "grammar_ref": 5.40206,
            "grammar_hyp": 5.12766,
            "nubia_score": 0.74222
        },
        "meteor": 0.3728938492396249,
        "bleurt": 0.30194,
        "bertscore": {
            "precision": 0.93172,
            "recall": 0.91833,
            "f1": 0.92309
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_290": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 13,
        "total_length": 205,
        "mean_pred_length": 15.76923076923077,
        "std_pred_length": 4.838210828774273,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.5853658536585366,
        "vocab_size-1": 120,
        "unique-1": 96,
        "entropy-1": 6.293154139025499,
        "distinct-2": 0.921875,
        "vocab_size-2": 177,
        "unique-2": 168,
        "entropy-2": 7.384929313447392,
        "cond_entropy-2": 0.94768131203409,
        "distinct-3": 0.9888268156424581,
        "vocab_size-3": 177,
        "unique-3": 175,
        "entropy-3": 7.461469408549164,
        "cond_entropy-3": 0.09106764501553984,
        "total_length-nopunct": 174,
        "mean_pred_length-nopunct": 13.384615384615385,
        "std_pred_length-nopunct": 4.32414440694006,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6724137931034483,
        "vocab_size-1-nopunct": 117,
        "unique-1-nopunct": 95,
        "entropy-1-nopunct": 6.48378342119595,
        "distinct-2-nopunct": 0.9192546583850931,
        "vocab_size-2-nopunct": 148,
        "unique-2-nopunct": 141,
        "entropy-2-nopunct": 7.1172127044713305,
        "cond_entropy-2-nopunct": 0.698454630918153,
        "distinct-3-nopunct": 0.9932432432432432,
        "vocab_size-3-nopunct": 147,
        "unique-3-nopunct": 146,
        "entropy-3-nopunct": 7.1959398521154325,
        "cond_entropy-3-nopunct": 0.0974984601938375,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.73,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.11764705882352941,
            "3": 0.8169934640522876
        },
        "nist": 5.6235221071139465,
        "bleu": 47.01637,
        "rouge1": {
            "precision": 0.765,
            "recall": 0.7579,
            "fmeasure": 0.75695
        },
        "rouge2": {
            "precision": 0.56168,
            "recall": 0.55723,
            "fmeasure": 0.55581
        },
        "rougeL": {
            "precision": 0.62523,
            "recall": 0.61586,
            "fmeasure": 0.61669
        },
        "rougeLsum": {
            "precision": 0.62523,
            "recall": 0.61586,
            "fmeasure": 0.61669
        },
        "nubia": {
            "semantic_relation": 4.43466,
            "contradiction": 1.11595,
            "irrelevancy": 22.86846,
            "logical_agreement": 76.01559,
            "grammar_ref": 4.72277,
            "grammar_hyp": 4.61326,
            "nubia_score": 0.82633
        },
        "meteor": 0.418004699009308,
        "bleurt": 0.46496,
        "bertscore": {
            "precision": 0.93891,
            "recall": 0.93491,
            "f1": 0.93663
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_232": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 9,
        "total_length": 161,
        "mean_pred_length": 17.88888888888889,
        "std_pred_length": 5.704665623552638,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 30,
        "distinct-1": 0.6645962732919255,
        "vocab_size-1": 107,
        "unique-1": 89,
        "entropy-1": 6.243119189234064,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 144,
        "unique-2": 137,
        "entropy-2": 7.137697990403019,
        "cond_entropy-2": 0.8569498814031569,
        "distinct-3": 0.986013986013986,
        "vocab_size-3": 141,
        "unique-3": 139,
        "entropy-3": 7.131899308806369,
        "cond_entropy-3": 0.0011388408324506062,
        "total_length-nopunct": 143,
        "mean_pred_length-nopunct": 15.88888888888889,
        "std_pred_length-nopunct": 5.020943790086669,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7132867132867133,
        "vocab_size-1-nopunct": 102,
        "unique-1-nopunct": 88,
        "entropy-1-nopunct": 6.20900302593198,
        "distinct-2-nopunct": 0.9552238805970149,
        "vocab_size-2-nopunct": 128,
        "unique-2-nopunct": 123,
        "entropy-2-nopunct": 6.970903462829694,
        "cond_entropy-2-nopunct": 0.8257647264321716,
        "distinct-3-nopunct": 0.992,
        "vocab_size-3-nopunct": 124,
        "unique-3-nopunct": 123,
        "entropy-3-nopunct": 6.949784284662096,
        "cond_entropy-3-nopunct": -0.014265805778377745,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3181818181818182,
            "2": 0.1875,
            "3": 0.7217391304347827
        },
        "nist": 4.993204136887871,
        "bleu": 31.39976,
        "rouge1": {
            "precision": 0.73776,
            "recall": 0.69953,
            "fmeasure": 0.70766
        },
        "rouge2": {
            "precision": 0.45106,
            "recall": 0.43288,
            "fmeasure": 0.43523
        },
        "rougeL": {
            "precision": 0.583,
            "recall": 0.57173,
            "fmeasure": 0.56739
        },
        "rougeLsum": {
            "precision": 0.583,
            "recall": 0.57173,
            "fmeasure": 0.56739
        },
        "nubia": {
            "semantic_relation": 4.30599,
            "contradiction": 1.53456,
            "irrelevancy": 26.37581,
            "logical_agreement": 72.08963,
            "grammar_ref": 4.7133,
            "grammar_hyp": 4.67319,
            "nubia_score": 0.75762
        },
        "meteor": 0.3354886569808657,
        "bleurt": 0.18041,
        "bertscore": {
            "precision": 0.91708,
            "recall": 0.91221,
            "f1": 0.91446
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_43": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 6,
        "total_length": 75,
        "mean_pred_length": 12.5,
        "std_pred_length": 5.377421934967226,
        "median_pred_length": 9.5,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 50,
        "unique-1": 41,
        "entropy-1": 5.315094356989477,
        "distinct-2": 0.8115942028985508,
        "vocab_size-2": 56,
        "unique-2": 51,
        "entropy-2": 5.622875543671977,
        "cond_entropy-2": 0.16245612866383807,
        "distinct-3": 0.8571428571428571,
        "vocab_size-3": 54,
        "unique-3": 50,
        "entropy-3": 5.623872582127056,
        "cond_entropy-3": -0.07973481109037095,
        "total_length-nopunct": 67,
        "mean_pred_length-nopunct": 11.166666666666666,
        "std_pred_length-nopunct": 4.946940693218609,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7164179104477612,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.304603369433083,
        "distinct-2-nopunct": 0.8360655737704918,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.512544304705066,
        "cond_entropy-2-nopunct": 0.15169363897932575,
        "distinct-3-nopunct": 0.8909090909090909,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.522002213406648,
        "cond_entropy-3-nopunct": -0.09037557862301694,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7162162162162162
        },
        "nist": 4.310604416112145,
        "bleu": 54.81206,
        "rouge1": {
            "precision": 0.89034,
            "recall": 0.85652,
            "fmeasure": 0.87137
        },
        "rouge2": {
            "precision": 0.7868,
            "recall": 0.76667,
            "fmeasure": 0.77542
        },
        "rougeL": {
            "precision": 0.84638,
            "recall": 0.81956,
            "fmeasure": 0.83134
        },
        "rougeLsum": {
            "precision": 0.84638,
            "recall": 0.81956,
            "fmeasure": 0.83134
        },
        "nubia": {
            "semantic_relation": 4.56819,
            "contradiction": 15.56736,
            "irrelevancy": 15.26228,
            "logical_agreement": 69.17035,
            "grammar_ref": 5.92578,
            "grammar_hyp": 6.14882,
            "nubia_score": 0.82472
        },
        "meteor": 0.4178528282643783,
        "bleurt": 0.73368,
        "bertscore": {
            "precision": 0.96945,
            "recall": 0.95805,
            "f1": 0.96352
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_68": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 36,
        "total_length": 618,
        "mean_pred_length": 17.166666666666668,
        "std_pred_length": 5.899623340142619,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.5485436893203883,
        "vocab_size-1": 339,
        "unique-1": 281,
        "entropy-1": 7.341251551224071,
        "distinct-2": 0.8969072164948454,
        "vocab_size-2": 522,
        "unique-2": 494,
        "entropy-2": 8.891387059688851,
        "cond_entropy-2": 1.407453321518616,
        "distinct-3": 0.9652014652014652,
        "vocab_size-3": 527,
        "unique-3": 516,
        "entropy-3": 9.01209944858047,
        "cond_entropy-3": 0.11426205071330643,
        "total_length-nopunct": 539,
        "mean_pred_length-nopunct": 14.972222222222221,
        "std_pred_length-nopunct": 5.619836450324428,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6159554730983302,
        "vocab_size-1-nopunct": 332,
        "unique-1-nopunct": 281,
        "entropy-1-nopunct": 7.481037901822838,
        "distinct-2-nopunct": 0.904572564612326,
        "vocab_size-2-nopunct": 455,
        "unique-2-nopunct": 435,
        "entropy-2-nopunct": 8.689523126924025,
        "cond_entropy-2-nopunct": 1.2965069201238917,
        "distinct-3-nopunct": 0.9721627408993576,
        "vocab_size-3-nopunct": 454,
        "unique-3-nopunct": 447,
        "entropy-3-nopunct": 8.80190545274405,
        "cond_entropy-3-nopunct": 0.1255913832556324,
        "msttr-100": 0.70833,
        "msttr-100_nopunct": 0.736,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.28378378378378377,
            "2": 0.3707865168539326,
            "3": 0.7699757869249395
        },
        "nist": 6.985449682298999,
        "bleu": 49.36823,
        "rouge1": {
            "precision": 0.80399,
            "recall": 0.7345,
            "fmeasure": 0.75672
        },
        "rouge2": {
            "precision": 0.58597,
            "recall": 0.52942,
            "fmeasure": 0.54783
        },
        "rougeL": {
            "precision": 0.70741,
            "recall": 0.65117,
            "fmeasure": 0.66772
        },
        "rougeLsum": {
            "precision": 0.70741,
            "recall": 0.65117,
            "fmeasure": 0.66772
        },
        "nubia": {
            "semantic_relation": 4.22806,
            "contradiction": 2.30399,
            "irrelevancy": 28.08199,
            "logical_agreement": 69.61402,
            "grammar_ref": 4.82696,
            "grammar_hyp": 4.89715,
            "nubia_score": 0.72831
        },
        "meteor": 0.39096741575703925,
        "bleurt": 0.28768,
        "bertscore": {
            "precision": 0.93944,
            "recall": 0.92773,
            "f1": 0.93219
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_234": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 14,
        "total_length": 177,
        "mean_pred_length": 12.642857142857142,
        "std_pred_length": 3.175962010773673,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 19,
        "distinct-1": 0.615819209039548,
        "vocab_size-1": 109,
        "unique-1": 91,
        "entropy-1": 6.1755765579861395,
        "distinct-2": 0.9325153374233128,
        "vocab_size-2": 152,
        "unique-2": 144,
        "entropy-2": 7.199865194068583,
        "cond_entropy-2": 0.8082483721594191,
        "distinct-3": 0.9865771812080537,
        "vocab_size-3": 147,
        "unique-3": 145,
        "entropy-3": 7.192322882878277,
        "cond_entropy-3": -0.006978006208577526,
        "total_length-nopunct": 159,
        "mean_pred_length-nopunct": 11.357142857142858,
        "std_pred_length-nopunct": 2.868726518289029,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.6729559748427673,
        "vocab_size-1-nopunct": 107,
        "unique-1-nopunct": 91,
        "entropy-1-nopunct": 6.2601397936973,
        "distinct-2-nopunct": 0.9310344827586207,
        "vocab_size-2-nopunct": 135,
        "unique-2-nopunct": 128,
        "entropy-2-nopunct": 7.0263596934184696,
        "cond_entropy-2-nopunct": 0.8333813084260848,
        "distinct-3-nopunct": 0.9923664122137404,
        "vocab_size-3-nopunct": 130,
        "unique-3-nopunct": 129,
        "entropy-3-nopunct": 7.018155825964931,
        "cond_entropy-3-nopunct": -0.007061183847786362,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.72,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21621621621621623,
            "2": 0.3333333333333333,
            "3": 0.75
        },
        "nist": 5.398167803138904,
        "bleu": 47.02776,
        "rouge1": {
            "precision": 0.73723,
            "recall": 0.71933,
            "fmeasure": 0.71688
        },
        "rouge2": {
            "precision": 0.49841,
            "recall": 0.50216,
            "fmeasure": 0.49247
        },
        "rougeL": {
            "precision": 0.67806,
            "recall": 0.67652,
            "fmeasure": 0.66611
        },
        "rougeLsum": {
            "precision": 0.67806,
            "recall": 0.67652,
            "fmeasure": 0.66611
        },
        "nubia": {
            "semantic_relation": 4.19658,
            "contradiction": 11.76816,
            "irrelevancy": 29.24093,
            "logical_agreement": 58.9909,
            "grammar_ref": 4.23107,
            "grammar_hyp": 4.39752,
            "nubia_score": 0.73958
        },
        "meteor": 0.4146768540872547,
        "bleurt": 0.27214,
        "bertscore": {
            "precision": 0.93477,
            "recall": 0.92696,
            "f1": 0.92952
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_44": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 47,
        "total_length": 753,
        "mean_pred_length": 16.02127659574468,
        "std_pred_length": 5.582988453546269,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 32,
        "distinct-1": 0.5099601593625498,
        "vocab_size-1": 384,
        "unique-1": 307,
        "entropy-1": 7.464307185906811,
        "distinct-2": 0.8711048158640227,
        "vocab_size-2": 615,
        "unique-2": 563,
        "entropy-2": 9.138727513018576,
        "cond_entropy-2": 1.472038394550639,
        "distinct-3": 0.9544764795144158,
        "vocab_size-3": 629,
        "unique-3": 607,
        "entropy-3": 9.260394855346942,
        "cond_entropy-3": 0.12114505394829676,
        "total_length-nopunct": 650,
        "mean_pred_length-nopunct": 13.829787234042554,
        "std_pred_length-nopunct": 4.9133736251441915,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5769230769230769,
        "vocab_size-1-nopunct": 375,
        "unique-1-nopunct": 304,
        "entropy-1-nopunct": 7.639839687174711,
        "distinct-2-nopunct": 0.8822553897180763,
        "vocab_size-2-nopunct": 532,
        "unique-2-nopunct": 492,
        "entropy-2-nopunct": 8.935131471572644,
        "cond_entropy-2-nopunct": 1.40576871520816,
        "distinct-3-nopunct": 0.9622302158273381,
        "vocab_size-3-nopunct": 535,
        "unique-3-nopunct": 519,
        "entropy-3-nopunct": 9.033312222949274,
        "cond_entropy-3-nopunct": 0.10997306316565278,
        "msttr-100": 0.69286,
        "msttr-100_nopunct": 0.73667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.168141592920354,
            "2": 0.40588235294117647,
            "3": 0.7291666666666666
        },
        "nist": 6.380415575566592,
        "bleu": 41.69808,
        "rouge1": {
            "precision": 0.74109,
            "recall": 0.6788,
            "fmeasure": 0.70015
        },
        "rouge2": {
            "precision": 0.50411,
            "recall": 0.47324,
            "fmeasure": 0.48348
        },
        "rougeL": {
            "precision": 0.64228,
            "recall": 0.59714,
            "fmeasure": 0.61249
        },
        "rougeLsum": {
            "precision": 0.64228,
            "recall": 0.59714,
            "fmeasure": 0.61249
        },
        "nubia": {
            "semantic_relation": 4.12038,
            "contradiction": 8.54622,
            "irrelevancy": 28.04323,
            "logical_agreement": 63.41054,
            "grammar_ref": 4.69178,
            "grammar_hyp": 4.82364,
            "nubia_score": 0.68922
        },
        "meteor": 0.36283675524076403,
        "bleurt": 0.22826,
        "bertscore": {
            "precision": 0.92579,
            "recall": 0.90946,
            "f1": 0.91667
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_148": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 10,
        "total_length": 148,
        "mean_pred_length": 14.8,
        "std_pred_length": 3.0919249667480613,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 22,
        "distinct-1": 0.6418918918918919,
        "vocab_size-1": 95,
        "unique-1": 79,
        "entropy-1": 6.049338886818619,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 132,
        "unique-2": 128,
        "entropy-2": 7.007075181415848,
        "cond_entropy-2": 0.8010831340119362,
        "distinct-3": 1.0,
        "vocab_size-3": 128,
        "unique-3": 128,
        "entropy-3": 7.0,
        "cond_entropy-3": -0.01477445677816911,
        "total_length-nopunct": 128,
        "mean_pred_length-nopunct": 12.8,
        "std_pred_length-nopunct": 2.821347195933177,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7109375,
        "vocab_size-1-nopunct": 91,
        "unique-1-nopunct": 79,
        "entropy-1-nopunct": 6.054938383509937,
        "distinct-2-nopunct": 0.9576271186440678,
        "vocab_size-2-nopunct": 113,
        "unique-2-nopunct": 110,
        "entropy-2-nopunct": 6.780948134107596,
        "cond_entropy-2-nopunct": 0.789150565554451,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 108,
        "unique-3-nopunct": 108,
        "entropy-3-nopunct": 6.754887502163458,
        "cond_entropy-3-nopunct": -0.02590369534652069,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.37037037037037035,
            "2": 0.47058823529411764,
            "3": 0.7641509433962265
        },
        "nist": 5.618232110521855,
        "bleu": 40.98566,
        "rouge1": {
            "precision": 0.75989,
            "recall": 0.72585,
            "fmeasure": 0.73075
        },
        "rouge2": {
            "precision": 0.46219,
            "recall": 0.42258,
            "fmeasure": 0.43303
        },
        "rougeL": {
            "precision": 0.66457,
            "recall": 0.62037,
            "fmeasure": 0.63125
        },
        "rougeLsum": {
            "precision": 0.66457,
            "recall": 0.62037,
            "fmeasure": 0.63125
        },
        "nubia": {
            "semantic_relation": 4.52305,
            "contradiction": 5.2664,
            "irrelevancy": 24.58143,
            "logical_agreement": 70.15216,
            "grammar_ref": 5.26168,
            "grammar_hyp": 5.23285,
            "nubia_score": 0.7867
        },
        "meteor": 0.3796812895764877,
        "bleurt": 0.2646,
        "bertscore": {
            "precision": 0.92518,
            "recall": 0.92147,
            "f1": 0.92295
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_69": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 6,
        "total_length": 82,
        "mean_pred_length": 13.666666666666666,
        "std_pred_length": 6.871842709362768,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.6829268292682927,
        "vocab_size-1": 56,
        "unique-1": 45,
        "entropy-1": 5.496220413360882,
        "distinct-2": 0.9736842105263158,
        "vocab_size-2": 74,
        "unique-2": 72,
        "entropy-2": 6.195295934496223,
        "cond_entropy-2": 0.5629993967039726,
        "distinct-3": 1.0,
        "vocab_size-3": 70,
        "unique-3": 70,
        "entropy-3": 6.129283016944973,
        "cond_entropy-3": -0.061501639355761785,
        "total_length-nopunct": 70,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 6.420453428086074,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7571428571428571,
        "vocab_size-1-nopunct": 53,
        "unique-1-nopunct": 44,
        "entropy-1-nopunct": 5.507714802597441,
        "distinct-2-nopunct": 0.984375,
        "vocab_size-2-nopunct": 63,
        "unique-2-nopunct": 62,
        "entropy-2-nopunct": 5.96875,
        "cond_entropy-2-nopunct": 0.48805721749764136,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.85798099512757,
        "cond_entropy-3-nopunct": -0.1075362462517382,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22727272727272727,
            "2": 0.38461538461538464,
            "3": 0.5689655172413793
        },
        "nist": 3.7105482030274906,
        "bleu": 26.76713,
        "rouge1": {
            "precision": 0.72869,
            "recall": 0.52405,
            "fmeasure": 0.59397
        },
        "rouge2": {
            "precision": 0.33523,
            "recall": 0.24322,
            "fmeasure": 0.27436
        },
        "rougeL": {
            "precision": 0.59759,
            "recall": 0.41275,
            "fmeasure": 0.47708
        },
        "rougeLsum": {
            "precision": 0.59759,
            "recall": 0.41275,
            "fmeasure": 0.47708
        },
        "nubia": {
            "semantic_relation": 3.68106,
            "contradiction": 16.27402,
            "irrelevancy": 30.15464,
            "logical_agreement": 53.57134,
            "grammar_ref": 3.92533,
            "grammar_hyp": 4.57266,
            "nubia_score": 0.61273
        },
        "meteor": 0.2890587969877915,
        "bleurt": 0.03593,
        "bertscore": {
            "precision": 0.91716,
            "recall": 0.87749,
            "f1": 0.89624
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_171": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 6,
        "total_length": 98,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 3.590109871423003,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.7448979591836735,
        "vocab_size-1": 73,
        "unique-1": 60,
        "entropy-1": 5.9679335381432335,
        "distinct-2": 1.0,
        "vocab_size-2": 92,
        "unique-2": 92,
        "entropy-2": 6.523561956057027,
        "cond_entropy-2": 0.4292249704301434,
        "distinct-3": 1.0,
        "vocab_size-3": 86,
        "unique-3": 86,
        "entropy-3": 6.426264754702099,
        "cond_entropy-3": -0.09729720135491499,
        "total_length-nopunct": 85,
        "mean_pred_length-nopunct": 14.166666666666666,
        "std_pred_length-nopunct": 2.967415635794142,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8117647058823529,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 5.9491625187404855,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 79,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.303780748177105,
        "cond_entropy-2-nopunct": 0.38957228645413255,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 73,
        "entropy-3-nopunct": 6.189824558880028,
        "cond_entropy-3-nopunct": -0.11395618929708562,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "nist": 5.560224337329097,
        "bleu": 57.34316,
        "rouge1": {
            "precision": 0.78692,
            "recall": 0.82094,
            "fmeasure": 0.79494
        },
        "rouge2": {
            "precision": 0.61949,
            "recall": 0.65167,
            "fmeasure": 0.62729
        },
        "rougeL": {
            "precision": 0.69375,
            "recall": 0.73682,
            "fmeasure": 0.70717
        },
        "rougeLsum": {
            "precision": 0.69375,
            "recall": 0.73682,
            "fmeasure": 0.70717
        },
        "nubia": {
            "semantic_relation": 4.49984,
            "contradiction": 0.33969,
            "irrelevancy": 28.56595,
            "logical_agreement": 71.09436,
            "grammar_ref": 4.66241,
            "grammar_hyp": 4.86154,
            "nubia_score": 0.79344
        },
        "meteor": 0.4745506352593268,
        "bleurt": 0.4762,
        "bertscore": {
            "precision": 0.9538,
            "recall": 0.96007,
            "f1": 0.9518
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_150": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 37,
        "total_length": 633,
        "mean_pred_length": 17.10810810810811,
        "std_pred_length": 4.689169717227271,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.5797788309636651,
        "vocab_size-1": 367,
        "unique-1": 314,
        "entropy-1": 7.571876101630118,
        "distinct-2": 0.9278523489932886,
        "vocab_size-2": 553,
        "unique-2": 528,
        "entropy-2": 9.037894862714914,
        "cond_entropy-2": 1.2907816820689018,
        "distinct-3": 0.9910554561717353,
        "vocab_size-3": 554,
        "unique-3": 550,
        "entropy-3": 9.107464960316952,
        "cond_entropy-3": 0.07336645330128368,
        "total_length-nopunct": 561,
        "mean_pred_length-nopunct": 15.162162162162161,
        "std_pred_length-nopunct": 4.505333257095108,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6452762923351159,
        "vocab_size-1-nopunct": 362,
        "unique-1-nopunct": 313,
        "entropy-1-nopunct": 7.753667126443975,
        "distinct-2-nopunct": 0.9274809160305344,
        "vocab_size-2-nopunct": 486,
        "unique-2-nopunct": 466,
        "entropy-2-nopunct": 8.846325482420475,
        "cond_entropy-2-nopunct": 1.16250703239125,
        "distinct-3-nopunct": 0.9938398357289527,
        "vocab_size-3-nopunct": 484,
        "unique-3-nopunct": 482,
        "entropy-3-nopunct": 8.913907556533752,
        "cond_entropy-3-nopunct": 0.0764889441474035,
        "msttr-100": 0.73167,
        "msttr-100_nopunct": 0.784,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2426470588235294,
            "2": 0.4387755102040816,
            "3": 0.7077294685990339
        },
        "nist": 6.239714312685515,
        "bleu": 40.47848,
        "rouge1": {
            "precision": 0.70886,
            "recall": 0.70388,
            "fmeasure": 0.69056
        },
        "rouge2": {
            "precision": 0.47461,
            "recall": 0.47119,
            "fmeasure": 0.46089
        },
        "rougeL": {
            "precision": 0.61017,
            "recall": 0.60219,
            "fmeasure": 0.59197
        },
        "rougeLsum": {
            "precision": 0.61017,
            "recall": 0.60219,
            "fmeasure": 0.59197
        },
        "nubia": {
            "semantic_relation": 4.00657,
            "contradiction": 9.80644,
            "irrelevancy": 41.07267,
            "logical_agreement": 49.12089,
            "grammar_ref": 4.9523,
            "grammar_hyp": 4.76698,
            "nubia_score": 0.66595
        },
        "meteor": 0.36834763604642634,
        "bleurt": 0.12856,
        "bertscore": {
            "precision": 0.91042,
            "recall": 0.91235,
            "f1": 0.90954
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_172": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 10,
        "total_length": 173,
        "mean_pred_length": 17.3,
        "std_pred_length": 4.172529209005013,
        "median_pred_length": 18.0,
        "min_pred_length": 11,
        "max_pred_length": 24,
        "distinct-1": 0.6242774566473989,
        "vocab_size-1": 108,
        "unique-1": 88,
        "entropy-1": 6.235182435730159,
        "distinct-2": 0.9570552147239264,
        "vocab_size-2": 156,
        "unique-2": 150,
        "entropy-2": 7.258207372009238,
        "cond_entropy-2": 0.941031426509286,
        "distinct-3": 0.9869281045751634,
        "vocab_size-3": 151,
        "unique-3": 149,
        "entropy-3": 7.231244051842959,
        "cond_entropy-3": -0.021046929171344306,
        "total_length-nopunct": 156,
        "mean_pred_length-nopunct": 15.6,
        "std_pred_length-nopunct": 4.409081537009721,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6794871794871795,
        "vocab_size-1-nopunct": 106,
        "unique-1-nopunct": 88,
        "entropy-1-nopunct": 6.291974033049087,
        "distinct-2-nopunct": 0.952054794520548,
        "vocab_size-2-nopunct": 139,
        "unique-2-nopunct": 133,
        "entropy-2-nopunct": 7.088763685577532,
        "cond_entropy-2-nopunct": 0.8579833638855214,
        "distinct-3-nopunct": 0.9852941176470589,
        "vocab_size-3-nopunct": 134,
        "unique-3-nopunct": 132,
        "entropy-3-nopunct": 7.058051076544447,
        "cond_entropy-3-nopunct": -0.023281662466710998,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.41935483870967744,
            "2": 0.325,
            "3": 0.6666666666666666
        },
        "nist": 5.042460915434714,
        "bleu": 37.04539,
        "rouge1": {
            "precision": 0.70555,
            "recall": 0.71043,
            "fmeasure": 0.69712
        },
        "rouge2": {
            "precision": 0.47468,
            "recall": 0.47224,
            "fmeasure": 0.46753
        },
        "rougeL": {
            "precision": 0.62025,
            "recall": 0.63152,
            "fmeasure": 0.61724
        },
        "rougeLsum": {
            "precision": 0.62025,
            "recall": 0.63152,
            "fmeasure": 0.61724
        },
        "nubia": {
            "semantic_relation": 4.10003,
            "contradiction": 12.22131,
            "irrelevancy": 31.70529,
            "logical_agreement": 56.0734,
            "grammar_ref": 4.7085,
            "grammar_hyp": 4.62127,
            "nubia_score": 0.70707
        },
        "meteor": 0.31974178756651844,
        "bleurt": 0.13176,
        "bertscore": {
            "precision": 0.91575,
            "recall": 0.91444,
            "f1": 0.91221
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_188": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 5.656854249492381,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 24,
        "distinct-1": 0.7083333333333334,
        "vocab_size-1": 34,
        "unique-1": 28,
        "entropy-1": 4.8375811886185085,
        "distinct-2": 0.9777777777777777,
        "vocab_size-2": 44,
        "unique-2": 43,
        "entropy-2": 5.447408651885229,
        "cond_entropy-2": 0.5539887173588242,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.051916625931866765,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 4.714045207910316,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.775,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.7439427079182686,
        "distinct-2-nopunct": 0.972972972972973,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.1553993115749,
        "cond_entropy-2-nopunct": 0.43129325665412094,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.09257875967272791,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.16666666666666666,
            "3": 0.9090909090909091
        },
        "nist": 4.901015980260178,
        "bleu": 57.88118,
        "rouge1": {
            "precision": 0.89495,
            "recall": 0.85608,
            "fmeasure": 0.87282
        },
        "rouge2": {
            "precision": 0.71781,
            "recall": 0.68718,
            "fmeasure": 0.70028
        },
        "rougeL": {
            "precision": 0.72525,
            "recall": 0.6977,
            "fmeasure": 0.7095
        },
        "rougeLsum": {
            "precision": 0.72525,
            "recall": 0.6977,
            "fmeasure": 0.7095
        },
        "nubia": {
            "semantic_relation": 4.96462,
            "contradiction": 0.40703,
            "irrelevancy": 1.17125,
            "logical_agreement": 98.42172,
            "grammar_ref": 5.15044,
            "grammar_hyp": 5.18654,
            "nubia_score": 0.9777
        },
        "meteor": 0.4978637218834755,
        "bleurt": 0.64539,
        "bertscore": {
            "precision": 0.97568,
            "recall": 0.97407,
            "f1": 0.97487
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_93": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 81,
        "mean_pred_length": 16.2,
        "std_pred_length": 5.844655678480984,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 63,
        "unique-1": 53,
        "entropy-1": 5.798191941391688,
        "distinct-2": 0.9736842105263158,
        "vocab_size-2": 74,
        "unique-2": 72,
        "entropy-2": 6.195295934496223,
        "cond_entropy-2": 0.3274762339922139,
        "distinct-3": 1.0,
        "vocab_size-3": 71,
        "unique-3": 71,
        "entropy-3": 6.149747119504677,
        "cond_entropy-3": -0.07001137985439647,
        "total_length-nopunct": 70,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.253570214625479,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8428571428571429,
        "vocab_size-1-nopunct": 59,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.782644981137965,
        "distinct-2-nopunct": 0.9846153846153847,
        "vocab_size-2-nopunct": 64,
        "unique-2-nopunct": 63,
        "entropy-2-nopunct": 5.991598582259227,
        "cond_entropy-2-nopunct": 0.18946421926026333,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 60,
        "unique-3-nopunct": 60,
        "entropy-3-nopunct": 5.906890595608517,
        "cond_entropy-3-nopunct": -0.08214388408660254,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.09523809523809523,
            "2": 0.75,
            "3": 0.8695652173913043
        },
        "nist": 5.4423974252530405,
        "bleu": 60.82311,
        "rouge1": {
            "precision": 0.80754,
            "recall": 0.87707,
            "fmeasure": 0.83136
        },
        "rouge2": {
            "precision": 0.63905,
            "recall": 0.70409,
            "fmeasure": 0.66114
        },
        "rougeL": {
            "precision": 0.7377,
            "recall": 0.80613,
            "fmeasure": 0.76135
        },
        "rougeLsum": {
            "precision": 0.7377,
            "recall": 0.80613,
            "fmeasure": 0.76135
        },
        "nubia": {
            "semantic_relation": 4.43687,
            "contradiction": 17.23925,
            "irrelevancy": 15.94413,
            "logical_agreement": 66.81662,
            "grammar_ref": 4.96303,
            "grammar_hyp": 4.68766,
            "nubia_score": 0.83018
        },
        "meteor": 0.4264994823622506,
        "bleurt": 0.43596,
        "bertscore": {
            "precision": 0.94838,
            "recall": 0.95501,
            "f1": 0.95121
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_70": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 81,
        "total_length": 1420,
        "mean_pred_length": 17.530864197530864,
        "std_pred_length": 5.812048829702108,
        "median_pred_length": 17.0,
        "min_pred_length": 4,
        "max_pred_length": 35,
        "distinct-1": 0.47394366197183097,
        "vocab_size-1": 673,
        "unique-1": 520,
        "entropy-1": 8.128956493306886,
        "distinct-2": 0.8633308439133682,
        "vocab_size-2": 1156,
        "unique-2": 1051,
        "entropy-2": 10.034755471643683,
        "cond_entropy-2": 1.7309091536762244,
        "distinct-3": 0.9403815580286169,
        "vocab_size-3": 1183,
        "unique-3": 1124,
        "entropy-3": 10.167688524025422,
        "cond_entropy-3": 0.1377161936088014,
        "total_length-nopunct": 1220,
        "mean_pred_length-nopunct": 15.061728395061728,
        "std_pred_length-nopunct": 4.9823036939823595,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5426229508196722,
        "vocab_size-1-nopunct": 662,
        "unique-1-nopunct": 515,
        "entropy-1-nopunct": 8.405804187400621,
        "distinct-2-nopunct": 0.8762071992976295,
        "vocab_size-2-nopunct": 998,
        "unique-2-nopunct": 922,
        "entropy-2-nopunct": 9.823720423038754,
        "cond_entropy-2-nopunct": 1.5224693399793758,
        "distinct-3-nopunct": 0.9480151228733459,
        "vocab_size-3-nopunct": 1003,
        "unique-3-nopunct": 960,
        "entropy-3-nopunct": 9.934592106796376,
        "cond_entropy-3-nopunct": 0.13234272374085027,
        "msttr-100": 0.74214,
        "msttr-100_nopunct": 0.7975,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2525597269624573,
            "2": 0.4844961240310077,
            "3": 0.8044496487119438
        },
        "nist": 7.734988316601862,
        "bleu": 50.83283,
        "rouge1": {
            "precision": 0.76412,
            "recall": 0.75022,
            "fmeasure": 0.74369
        },
        "rouge2": {
            "precision": 0.55948,
            "recall": 0.54301,
            "fmeasure": 0.5398
        },
        "rougeL": {
            "precision": 0.65776,
            "recall": 0.64083,
            "fmeasure": 0.63683
        },
        "rougeLsum": {
            "precision": 0.65776,
            "recall": 0.64083,
            "fmeasure": 0.63683
        },
        "nubia": {
            "semantic_relation": 4.21102,
            "contradiction": 5.75356,
            "irrelevancy": 35.97472,
            "logical_agreement": 58.27172,
            "grammar_ref": 4.67017,
            "grammar_hyp": 4.66108,
            "nubia_score": 0.72782
        },
        "meteor": 0.407362073247569,
        "bleurt": 0.21779,
        "bertscore": {
            "precision": 0.93227,
            "recall": 0.92956,
            "f1": 0.92896
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_291": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.5555555555555556
        },
        "nist": 0.6432068335983285,
        "bleu": 22.99092,
        "rouge1": {
            "precision": 0.80556,
            "recall": 0.42857,
            "fmeasure": 0.55789
        },
        "rouge2": {
            "precision": 0.42424,
            "recall": 0.21795,
            "fmeasure": 0.28713
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.30864,
            "fmeasure": 0.40249
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.30864,
            "fmeasure": 0.40249
        },
        "nubia": {
            "semantic_relation": 3.17287,
            "contradiction": 0.2138,
            "irrelevancy": 8.53689,
            "logical_agreement": 91.24931,
            "grammar_ref": 3.87789,
            "grammar_hyp": 4.04892,
            "nubia_score": 0.39856
        },
        "meteor": 0.25558584806646634,
        "bleurt": -0.19667,
        "bertscore": {
            "precision": 0.90467,
            "recall": 0.82504,
            "f1": 0.86302
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_256": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 10,
        "total_length": 158,
        "mean_pred_length": 15.8,
        "std_pred_length": 4.237924020083418,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 21,
        "distinct-1": 0.7025316455696202,
        "vocab_size-1": 111,
        "unique-1": 95,
        "entropy-1": 6.373896132698454,
        "distinct-2": 0.9797297297297297,
        "vocab_size-2": 145,
        "unique-2": 142,
        "entropy-2": 7.168912825088406,
        "cond_entropy-2": 0.6650810244291939,
        "distinct-3": 1.0,
        "vocab_size-3": 138,
        "unique-3": 138,
        "entropy-3": 7.108524456778167,
        "cond_entropy-3": -0.05745064798121528,
        "total_length-nopunct": 139,
        "mean_pred_length-nopunct": 13.9,
        "std_pred_length-nopunct": 3.8845849199110063,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.762589928057554,
        "vocab_size-1-nopunct": 106,
        "unique-1-nopunct": 94,
        "entropy-1-nopunct": 6.379496441369486,
        "distinct-2-nopunct": 0.9767441860465116,
        "vocab_size-2-nopunct": 126,
        "unique-2-nopunct": 123,
        "entropy-2-nopunct": 6.964715627516259,
        "cond_entropy-2-nopunct": 0.6347885374145587,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 119,
        "unique-3-nopunct": 119,
        "entropy-3-nopunct": 6.894817763307943,
        "cond_entropy-3-nopunct": -0.06598932404808368,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.74,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4117647058823529,
            "2": 0.41935483870967744,
            "3": 0.7857142857142857
        },
        "nist": 5.841626290251629,
        "bleu": 46.63972,
        "rouge1": {
            "precision": 0.73667,
            "recall": 0.71349,
            "fmeasure": 0.71708
        },
        "rouge2": {
            "precision": 0.47192,
            "recall": 0.45115,
            "fmeasure": 0.45692
        },
        "rougeL": {
            "precision": 0.61831,
            "recall": 0.60089,
            "fmeasure": 0.60441
        },
        "rougeLsum": {
            "precision": 0.61831,
            "recall": 0.60089,
            "fmeasure": 0.60441
        },
        "nubia": {
            "semantic_relation": 3.98432,
            "contradiction": 15.78232,
            "irrelevancy": 48.8847,
            "logical_agreement": 35.33298,
            "grammar_ref": 4.57625,
            "grammar_hyp": 4.60021,
            "nubia_score": 0.67696
        },
        "meteor": 0.410216916784443,
        "bleurt": 0.18178,
        "bertscore": {
            "precision": 0.91663,
            "recall": 0.91614,
            "f1": 0.91556
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_115": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 20,
        "total_length": 357,
        "mean_pred_length": 17.85,
        "std_pred_length": 5.9856077385675714,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.5826330532212886,
        "vocab_size-1": 208,
        "unique-1": 170,
        "entropy-1": 6.968819717101252,
        "distinct-2": 0.887240356083086,
        "vocab_size-2": 299,
        "unique-2": 275,
        "entropy-2": 8.134279475561936,
        "cond_entropy-2": 1.0264703249669502,
        "distinct-3": 0.9463722397476341,
        "vocab_size-3": 300,
        "unique-3": 287,
        "entropy-3": 8.191558115285654,
        "cond_entropy-3": 0.052520338809570445,
        "total_length-nopunct": 308,
        "mean_pred_length-nopunct": 15.4,
        "std_pred_length-nopunct": 5.033885179461287,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6590909090909091,
        "vocab_size-1-nopunct": 203,
        "unique-1-nopunct": 170,
        "entropy-1-nopunct": 7.123987491633903,
        "distinct-2-nopunct": 0.90625,
        "vocab_size-2-nopunct": 261,
        "unique-2-nopunct": 244,
        "entropy-2-nopunct": 7.949841397326819,
        "cond_entropy-2-nopunct": 0.8670205063221541,
        "distinct-3-nopunct": 0.9552238805970149,
        "vocab_size-3-nopunct": 256,
        "unique-3-nopunct": 247,
        "entropy-3-nopunct": 7.968086718418598,
        "cond_entropy-3-nopunct": 0.023475440801892074,
        "msttr-100": 0.72667,
        "msttr-100_nopunct": 0.77667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19607843137254902,
            "2": 0.46296296296296297,
            "3": 0.8311111111111111
        },
        "nist": 6.182855866306614,
        "bleu": 54.63091,
        "rouge1": {
            "precision": 0.75444,
            "recall": 0.78902,
            "fmeasure": 0.76523
        },
        "rouge2": {
            "precision": 0.57401,
            "recall": 0.59413,
            "fmeasure": 0.57863
        },
        "rougeL": {
            "precision": 0.65564,
            "recall": 0.66346,
            "fmeasure": 0.65448
        },
        "rougeLsum": {
            "precision": 0.65564,
            "recall": 0.66346,
            "fmeasure": 0.65448
        },
        "nubia": {
            "semantic_relation": 4.29207,
            "contradiction": 1.98028,
            "irrelevancy": 31.93159,
            "logical_agreement": 66.08813,
            "grammar_ref": 4.56897,
            "grammar_hyp": 4.48675,
            "nubia_score": 0.77756
        },
        "meteor": 0.41274266168081264,
        "bleurt": 0.39395,
        "bertscore": {
            "precision": 0.93132,
            "recall": 0.93599,
            "f1": 0.9322
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_235": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 7,
        "total_length": 110,
        "mean_pred_length": 15.714285714285714,
        "std_pred_length": 5.5217565971679115,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.7090909090909091,
        "vocab_size-1": 78,
        "unique-1": 67,
        "entropy-1": 5.96719628282911,
        "distinct-2": 0.9805825242718447,
        "vocab_size-2": 101,
        "unique-2": 99,
        "entropy-2": 6.647665575726924,
        "cond_entropy-2": 0.6005428409127993,
        "distinct-3": 1.0,
        "vocab_size-3": 96,
        "unique-3": 96,
        "entropy-3": 6.5849625007211605,
        "cond_entropy-3": -0.059871359795395464,
        "total_length-nopunct": 98,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.1269595556932455,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7551020408163265,
        "vocab_size-1-nopunct": 74,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 5.937784370363812,
        "distinct-2-nopunct": 0.978021978021978,
        "vocab_size-2-nopunct": 89,
        "unique-2-nopunct": 87,
        "entropy-2-nopunct": 6.463838596242657,
        "cond_entropy-2-nopunct": 0.5306317008389818,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 84,
        "entropy-3-nopunct": 6.39231742277876,
        "cond_entropy-3-nopunct": -0.07976293170565009,
        "msttr-100": 0.75,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17142857142857143,
            "2": 0.65,
            "3": 0.7846153846153846
        },
        "nist": 5.039559597941632,
        "bleu": 46.62015,
        "rouge1": {
            "precision": 0.73877,
            "recall": 0.79968,
            "fmeasure": 0.75578
        },
        "rouge2": {
            "precision": 0.55946,
            "recall": 0.59701,
            "fmeasure": 0.56762
        },
        "rougeL": {
            "precision": 0.69902,
            "recall": 0.72734,
            "fmeasure": 0.70014
        },
        "rougeLsum": {
            "precision": 0.69902,
            "recall": 0.72734,
            "fmeasure": 0.70014
        },
        "nubia": {
            "semantic_relation": 4.30924,
            "contradiction": 0.99218,
            "irrelevancy": 49.93656,
            "logical_agreement": 49.07127,
            "grammar_ref": 5.24762,
            "grammar_hyp": 5.20046,
            "nubia_score": 0.70857
        },
        "meteor": 0.3869715706086223,
        "bleurt": 0.20657,
        "bertscore": {
            "precision": 0.92206,
            "recall": 0.93593,
            "f1": 0.92714
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_292": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 1.0,
        "median_pred_length": 19.0,
        "min_pred_length": 18,
        "max_pred_length": 20,
        "distinct-1": 0.7631578947368421,
        "vocab_size-1": 29,
        "unique-1": 22,
        "entropy-1": 4.734512381750772,
        "distinct-2": 0.9166666666666666,
        "vocab_size-2": 33,
        "unique-2": 30,
        "entropy-2": 5.003258334775643,
        "cond_entropy-2": 0.24171346034114163,
        "distinct-3": 0.9705882352941176,
        "vocab_size-3": 33,
        "unique-3": 32,
        "entropy-3": 5.028639311838574,
        "cond_entropy-3": 0.03518489863155644,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.78125,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.515319531114783,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.773557262275185,
        "cond_entropy-2-nopunct": 0.29054976241941644,
        "distinct-3-nopunct": 0.9642857142857143,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.735926350629034,
        "cond_entropy-3-nopunct": -0.028107102122342936,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.2,
            "3": 0.7368421052631579
        },
        "nist": 3.4278048476455916,
        "bleu": 29.96516,
        "rouge1": {
            "precision": 0.53064,
            "recall": 0.73333,
            "fmeasure": 0.60367
        },
        "rouge2": {
            "precision": 0.27431,
            "recall": 0.36052,
            "fmeasure": 0.30592
        },
        "rougeL": {
            "precision": 0.43015,
            "recall": 0.56969,
            "fmeasure": 0.47758
        },
        "rougeLsum": {
            "precision": 0.43015,
            "recall": 0.56969,
            "fmeasure": 0.47758
        },
        "nubia": {
            "semantic_relation": 3.55967,
            "contradiction": 37.90604,
            "irrelevancy": 54.73305,
            "logical_agreement": 7.36091,
            "grammar_ref": 4.97036,
            "grammar_hyp": 4.19589,
            "nubia_score": 0.54797
        },
        "meteor": 0.34213333527759165,
        "bleurt": -0.35146,
        "bertscore": {
            "precision": 0.8833,
            "recall": 0.91245,
            "f1": 0.8971
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_294": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 8,
        "total_length": 125,
        "mean_pred_length": 15.625,
        "std_pred_length": 4.922842166878804,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.728,
        "vocab_size-1": 91,
        "unique-1": 78,
        "entropy-1": 6.174633460745445,
        "distinct-2": 0.9829059829059829,
        "vocab_size-2": 115,
        "unique-2": 113,
        "entropy-2": 6.836176685395349,
        "cond_entropy-2": 0.5105108023536343,
        "distinct-3": 1.0,
        "vocab_size-3": 109,
        "unique-3": 109,
        "entropy-3": 6.7681843247769145,
        "cond_entropy-3": -0.06548314710005627,
        "total_length-nopunct": 111,
        "mean_pred_length-nopunct": 13.875,
        "std_pred_length-nopunct": 4.2260353760942415,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7837837837837838,
        "vocab_size-1-nopunct": 87,
        "unique-1-nopunct": 76,
        "entropy-1-nopunct": 6.191768542119656,
        "distinct-2-nopunct": 0.9805825242718447,
        "vocab_size-2-nopunct": 101,
        "unique-2-nopunct": 99,
        "entropy-2-nopunct": 6.647665575726925,
        "cond_entropy-2-nopunct": 0.4929958549067147,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 95,
        "unique-3-nopunct": 95,
        "entropy-3-nopunct": 6.569855608330948,
        "cond_entropy-3-nopunct": -0.07453965569437589,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.81,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.6041666666666666,
            "3": 0.6338028169014085
        },
        "nist": 4.036974571277236,
        "bleu": 36.70568,
        "rouge1": {
            "precision": 0.76914,
            "recall": 0.68832,
            "fmeasure": 0.71465
        },
        "rouge2": {
            "precision": 0.52694,
            "recall": 0.48286,
            "fmeasure": 0.49545
        },
        "rougeL": {
            "precision": 0.72748,
            "recall": 0.65862,
            "fmeasure": 0.68074
        },
        "rougeLsum": {
            "precision": 0.72748,
            "recall": 0.65862,
            "fmeasure": 0.68074
        },
        "nubia": {
            "semantic_relation": 4.10966,
            "contradiction": 13.41568,
            "irrelevancy": 43.21617,
            "logical_agreement": 43.36815,
            "grammar_ref": 4.54831,
            "grammar_hyp": 4.59229,
            "nubia_score": 0.68738
        },
        "meteor": 0.3299168424763535,
        "bleurt": 0.31421,
        "bertscore": {
            "precision": 0.93009,
            "recall": 0.92517,
            "f1": 0.92639
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_174": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 11,
        "total_length": 186,
        "mean_pred_length": 16.90909090909091,
        "std_pred_length": 4.813891743590446,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.6290322580645161,
        "vocab_size-1": 117,
        "unique-1": 99,
        "entropy-1": 6.314950242669048,
        "distinct-2": 0.9257142857142857,
        "vocab_size-2": 162,
        "unique-2": 156,
        "entropy-2": 7.261957309096516,
        "cond_entropy-2": 0.8552183192266328,
        "distinct-3": 0.9817073170731707,
        "vocab_size-3": 161,
        "unique-3": 159,
        "entropy-3": 7.316363666190279,
        "cond_entropy-3": 0.06710020971624427,
        "total_length-nopunct": 168,
        "mean_pred_length-nopunct": 15.272727272727273,
        "std_pred_length-nopunct": 4.350358586911054,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6785714285714286,
        "vocab_size-1-nopunct": 114,
        "unique-1-nopunct": 98,
        "entropy-1-nopunct": 6.349618204227158,
        "distinct-2-nopunct": 0.9363057324840764,
        "vocab_size-2-nopunct": 147,
        "unique-2-nopunct": 142,
        "entropy-2-nopunct": 7.134624471956823,
        "cond_entropy-2-nopunct": 0.851692200239672,
        "distinct-3-nopunct": 0.9794520547945206,
        "vocab_size-3-nopunct": 143,
        "unique-3-nopunct": 141,
        "entropy-3-nopunct": 7.143558206125476,
        "cond_entropy-3-nopunct": 0.020988248184282802,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.30303030303030304,
            "2": 0.2619047619047619,
            "3": 0.6377952755905512
        },
        "nist": 4.677540659704889,
        "bleu": 30.09065,
        "rouge1": {
            "precision": 0.65073,
            "recall": 0.68431,
            "fmeasure": 0.65312
        },
        "rouge2": {
            "precision": 0.38338,
            "recall": 0.4242,
            "fmeasure": 0.39287
        },
        "rougeL": {
            "precision": 0.52362,
            "recall": 0.57664,
            "fmeasure": 0.53558
        },
        "rougeLsum": {
            "precision": 0.52362,
            "recall": 0.57664,
            "fmeasure": 0.53558
        },
        "nubia": {
            "semantic_relation": 3.85033,
            "contradiction": 6.60499,
            "irrelevancy": 59.38844,
            "logical_agreement": 34.00656,
            "grammar_ref": 4.8345,
            "grammar_hyp": 4.38196,
            "nubia_score": 0.64125
        },
        "meteor": 0.3151347739828184,
        "bleurt": 0.10491,
        "bertscore": {
            "precision": 0.90285,
            "recall": 0.91071,
            "f1": 0.90311
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_295": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 11,
        "total_length": 177,
        "mean_pred_length": 16.09090909090909,
        "std_pred_length": 6.244336276754326,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 26,
        "distinct-1": 0.632768361581921,
        "vocab_size-1": 112,
        "unique-1": 88,
        "entropy-1": 6.367603768374497,
        "distinct-2": 0.9096385542168675,
        "vocab_size-2": 151,
        "unique-2": 137,
        "entropy-2": 7.189769024707373,
        "cond_entropy-2": 0.7231935369703212,
        "distinct-3": 0.9612903225806452,
        "vocab_size-3": 149,
        "unique-3": 143,
        "entropy-3": 7.198705050435546,
        "cond_entropy-3": 0.022084248134819243,
        "total_length-nopunct": 156,
        "mean_pred_length-nopunct": 14.181818181818182,
        "std_pred_length-nopunct": 5.874725244146732,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6858974358974359,
        "vocab_size-1-nopunct": 107,
        "unique-1-nopunct": 85,
        "entropy-1-nopunct": 6.403083851320955,
        "distinct-2-nopunct": 0.896551724137931,
        "vocab_size-2-nopunct": 130,
        "unique-2-nopunct": 116,
        "entropy-2-nopunct": 6.96780641758624,
        "cond_entropy-2-nopunct": 0.6109674079408269,
        "distinct-3-nopunct": 0.9552238805970149,
        "vocab_size-3-nopunct": 128,
        "unique-3-nopunct": 122,
        "entropy-3-nopunct": 6.976536951651809,
        "cond_entropy-3-nopunct": 0.011216574339580423,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.8,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21875,
            "2": 0.5,
            "3": 0.8861788617886179
        },
        "nist": 6.249987359799164,
        "bleu": 61.87593,
        "rouge1": {
            "precision": 0.86199,
            "recall": 0.87785,
            "fmeasure": 0.86747
        },
        "rouge2": {
            "precision": 0.67111,
            "recall": 0.68642,
            "fmeasure": 0.67643
        },
        "rougeL": {
            "precision": 0.74356,
            "recall": 0.76689,
            "fmeasure": 0.7528
        },
        "rougeLsum": {
            "precision": 0.74356,
            "recall": 0.76689,
            "fmeasure": 0.7528
        },
        "nubia": {
            "semantic_relation": 4.67361,
            "contradiction": 6.53438,
            "irrelevancy": 6.91381,
            "logical_agreement": 86.55181,
            "grammar_ref": 4.24853,
            "grammar_hyp": 4.34292,
            "nubia_score": 0.8957
        },
        "meteor": 0.48363269711911017,
        "bleurt": 0.53739,
        "bertscore": {
            "precision": 0.95691,
            "recall": 0.9546,
            "f1": 0.9554
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_116": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 17,
        "total_length": 281,
        "mean_pred_length": 16.529411764705884,
        "std_pred_length": 6.598731135237721,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 35,
        "distinct-1": 0.5871886120996441,
        "vocab_size-1": 165,
        "unique-1": 127,
        "entropy-1": 6.720774435342504,
        "distinct-2": 0.9242424242424242,
        "vocab_size-2": 244,
        "unique-2": 226,
        "entropy-2": 7.885303210267552,
        "cond_entropy-2": 1.033576968519005,
        "distinct-3": 0.97165991902834,
        "vocab_size-3": 240,
        "unique-3": 233,
        "entropy-3": 7.891687069641388,
        "cond_entropy-3": 0.009236270120961138,
        "total_length-nopunct": 241,
        "mean_pred_length-nopunct": 14.176470588235293,
        "std_pred_length-nopunct": 5.327346697688282,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6680497925311203,
        "vocab_size-1-nopunct": 161,
        "unique-1-nopunct": 127,
        "entropy-1-nopunct": 6.847286926131606,
        "distinct-2-nopunct": 0.9464285714285714,
        "vocab_size-2-nopunct": 212,
        "unique-2-nopunct": 202,
        "entropy-2-nopunct": 7.691283493486141,
        "cond_entropy-2-nopunct": 0.9070110359781234,
        "distinct-3-nopunct": 0.9855072463768116,
        "vocab_size-3-nopunct": 204,
        "unique-3-nopunct": 201,
        "entropy-3-nopunct": 7.664501450252921,
        "cond_entropy-3-nopunct": -0.026911442819148215,
        "msttr-100": 0.675,
        "msttr-100_nopunct": 0.725,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.4583333333333333,
            "3": 0.7799043062200957
        },
        "nist": 6.001185042659408,
        "bleu": 44.80029,
        "rouge1": {
            "precision": 0.84315,
            "recall": 0.74719,
            "fmeasure": 0.78212
        },
        "rouge2": {
            "precision": 0.57753,
            "recall": 0.49937,
            "fmeasure": 0.52827
        },
        "rougeL": {
            "precision": 0.74851,
            "recall": 0.65555,
            "fmeasure": 0.68771
        },
        "rougeLsum": {
            "precision": 0.74851,
            "recall": 0.65555,
            "fmeasure": 0.68771
        },
        "nubia": {
            "semantic_relation": 4.17302,
            "contradiction": 9.44369,
            "irrelevancy": 21.60127,
            "logical_agreement": 68.95503,
            "grammar_ref": 4.34644,
            "grammar_hyp": 4.8289,
            "nubia_score": 0.68738
        },
        "meteor": 0.3966849359996431,
        "bleurt": 0.25369,
        "bertscore": {
            "precision": 0.94461,
            "recall": 0.92145,
            "f1": 0.93119
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_72": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 76,
        "total_length": 1215,
        "mean_pred_length": 15.986842105263158,
        "std_pred_length": 5.361886502883672,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.5242798353909465,
        "vocab_size-1": 637,
        "unique-1": 529,
        "entropy-1": 8.051048683324282,
        "distinct-2": 0.9104477611940298,
        "vocab_size-2": 1037,
        "unique-2": 981,
        "entropy-2": 9.912324343514417,
        "cond_entropy-2": 1.6185786581937323,
        "distinct-3": 0.9840075258701787,
        "vocab_size-3": 1046,
        "unique-3": 1033,
        "entropy-3": 10.016757701846887,
        "cond_entropy-3": 0.10403676077883554,
        "total_length-nopunct": 1056,
        "mean_pred_length-nopunct": 13.894736842105264,
        "std_pred_length-nopunct": 4.71442061900009,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.5965909090909091,
        "vocab_size-1-nopunct": 630,
        "unique-1-nopunct": 528,
        "entropy-1-nopunct": 8.329481326237284,
        "distinct-2-nopunct": 0.9214285714285714,
        "vocab_size-2-nopunct": 903,
        "unique-2-nopunct": 862,
        "entropy-2-nopunct": 9.71940933301111,
        "cond_entropy-2-nopunct": 1.4848068301711592,
        "distinct-3-nopunct": 0.9889380530973452,
        "vocab_size-3-nopunct": 894,
        "unique-3-nopunct": 884,
        "entropy-3-nopunct": 9.798055068609738,
        "cond_entropy-3-nopunct": 0.09137734406706735,
        "msttr-100": 0.73333,
        "msttr-100_nopunct": 0.788,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.45528455284552843,
            "3": 0.7576177285318559
        },
        "nist": 7.136595545329052,
        "bleu": 42.72365,
        "rouge1": {
            "precision": 0.71993,
            "recall": 0.70036,
            "fmeasure": 0.69536
        },
        "rouge2": {
            "precision": 0.48161,
            "recall": 0.46452,
            "fmeasure": 0.46122
        },
        "rougeL": {
            "precision": 0.6308,
            "recall": 0.61902,
            "fmeasure": 0.61047
        },
        "rougeLsum": {
            "precision": 0.6308,
            "recall": 0.61902,
            "fmeasure": 0.61047
        },
        "nubia": {
            "semantic_relation": 4.11666,
            "contradiction": 6.9289,
            "irrelevancy": 31.9871,
            "logical_agreement": 61.084,
            "grammar_ref": 4.73156,
            "grammar_hyp": 4.69302,
            "nubia_score": 0.69707
        },
        "meteor": 0.37939791667851763,
        "bleurt": 0.19266,
        "bertscore": {
            "precision": 0.92486,
            "recall": 0.91954,
            "f1": 0.91998
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_94": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 43,
        "mean_pred_length": 21.5,
        "std_pred_length": 11.5,
        "median_pred_length": 21.5,
        "min_pred_length": 10,
        "max_pred_length": 33,
        "distinct-1": 0.6744186046511628,
        "vocab_size-1": 29,
        "unique-1": 22,
        "entropy-1": 4.6180115569773665,
        "distinct-2": 0.8292682926829268,
        "vocab_size-2": 34,
        "unique-2": 29,
        "entropy-2": 4.967308102179057,
        "cond_entropy-2": 0.38872353045655816,
        "distinct-3": 0.8974358974358975,
        "vocab_size-3": 35,
        "unique-3": 31,
        "entropy-3": 5.0802740137340425,
        "cond_entropy-3": 0.1329784193723701,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 6.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.548394345536403,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.28456745152635227,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.6666666666666666
        },
        "nist": 4.764167676331368,
        "bleu": 79.49064,
        "rouge1": {
            "precision": 0.88095,
            "recall": 0.75037,
            "fmeasure": 0.80948
        },
        "rouge2": {
            "precision": 0.74583,
            "recall": 0.63012,
            "fmeasure": 0.68237
        },
        "rougeL": {
            "precision": 0.84921,
            "recall": 0.72656,
            "fmeasure": 0.78227
        },
        "rougeLsum": {
            "precision": 0.84921,
            "recall": 0.72656,
            "fmeasure": 0.78227
        },
        "nubia": {
            "semantic_relation": 3.95767,
            "contradiction": 2.99153,
            "irrelevancy": 22.25901,
            "logical_agreement": 74.74946,
            "grammar_ref": 4.15024,
            "grammar_hyp": 4.62308,
            "nubia_score": 0.66348
        },
        "meteor": 0.41954632790577445,
        "bleurt": 0.06533,
        "bertscore": {
            "precision": 0.95921,
            "recall": 0.91011,
            "f1": 0.93377
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_117": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 8,
        "total_length": 156,
        "mean_pred_length": 19.5,
        "std_pred_length": 7.158910531638177,
        "median_pred_length": 19.5,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.6730769230769231,
        "vocab_size-1": 105,
        "unique-1": 81,
        "entropy-1": 6.364622312859416,
        "distinct-2": 0.9662162162162162,
        "vocab_size-2": 143,
        "unique-2": 138,
        "entropy-2": 7.14188579806138,
        "cond_entropy-2": 0.7154828381999242,
        "distinct-3": 1.0,
        "vocab_size-3": 140,
        "unique-3": 140,
        "entropy-3": 7.129283016944978,
        "cond_entropy-3": -0.008741777255411962,
        "total_length-nopunct": 136,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 6.123724356957945,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7426470588235294,
        "vocab_size-1-nopunct": 101,
        "unique-1-nopunct": 81,
        "entropy-1-nopunct": 6.418987772255901,
        "distinct-2-nopunct": 0.9765625,
        "vocab_size-2-nopunct": 125,
        "unique-2-nopunct": 122,
        "entropy-2-nopunct": 6.953125,
        "cond_entropy-2-nopunct": 0.5681044195562474,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 120,
        "unique-3-nopunct": 120,
        "entropy-3-nopunct": 6.906890595608536,
        "cond_entropy-3-nopunct": -0.043109404391481636,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.5128205128205128,
            "3": 0.6666666666666666
        },
        "nist": 4.6368655738766416,
        "bleu": 28.35179,
        "rouge1": {
            "precision": 0.67748,
            "recall": 0.63574,
            "fmeasure": 0.64316
        },
        "rouge2": {
            "precision": 0.4567,
            "recall": 0.41062,
            "fmeasure": 0.42252
        },
        "rougeL": {
            "precision": 0.57827,
            "recall": 0.54509,
            "fmeasure": 0.55101
        },
        "rougeLsum": {
            "precision": 0.57827,
            "recall": 0.54509,
            "fmeasure": 0.55101
        },
        "nubia": {
            "semantic_relation": 3.82283,
            "contradiction": 12.29382,
            "irrelevancy": 52.58521,
            "logical_agreement": 35.12097,
            "grammar_ref": 4.12019,
            "grammar_hyp": 4.48341,
            "nubia_score": 0.58522
        },
        "meteor": 0.32188842524493705,
        "bleurt": -0.04964,
        "bertscore": {
            "precision": 0.90007,
            "recall": 0.89733,
            "f1": 0.89735
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_238": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 9,
        "total_length": 125,
        "mean_pred_length": 13.88888888888889,
        "std_pred_length": 4.121608220220313,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.664,
        "vocab_size-1": 83,
        "unique-1": 62,
        "entropy-1": 6.070477060676213,
        "distinct-2": 0.8793103448275862,
        "vocab_size-2": 102,
        "unique-2": 88,
        "entropy-2": 6.61660168478273,
        "cond_entropy-2": 0.36964565861422777,
        "distinct-3": 0.8878504672897196,
        "vocab_size-3": 95,
        "unique-3": 83,
        "entropy-3": 6.5171679209805795,
        "cond_entropy-3": -0.07913083115633171,
        "total_length-nopunct": 111,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 4.2946995755750415,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7297297297297297,
        "vocab_size-1-nopunct": 81,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 6.147799312198611,
        "distinct-2-nopunct": 0.8725490196078431,
        "vocab_size-2-nopunct": 89,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 6.417523381187186,
        "cond_entropy-2-nopunct": 0.31697454925685403,
        "distinct-3-nopunct": 0.8817204301075269,
        "vocab_size-3-nopunct": 82,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 6.302599671323093,
        "cond_entropy-3-nopunct": -0.10100846634733521,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.74,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3783783783783784,
            "2": 0.6,
            "3": 0.8705882352941177
        },
        "nist": 5.958164383011969,
        "bleu": 57.22301,
        "rouge1": {
            "precision": 0.87404,
            "recall": 0.8181,
            "fmeasure": 0.83723
        },
        "rouge2": {
            "precision": 0.67554,
            "recall": 0.63994,
            "fmeasure": 0.65064
        },
        "rougeL": {
            "precision": 0.78364,
            "recall": 0.75894,
            "fmeasure": 0.76719
        },
        "rougeLsum": {
            "precision": 0.78364,
            "recall": 0.75894,
            "fmeasure": 0.76719
        },
        "nubia": {
            "semantic_relation": 4.17901,
            "contradiction": 11.82739,
            "irrelevancy": 23.79673,
            "logical_agreement": 64.37588,
            "grammar_ref": 4.78166,
            "grammar_hyp": 5.1614,
            "nubia_score": 0.69255
        },
        "meteor": 0.4341099095684707,
        "bleurt": 0.28918,
        "bertscore": {
            "precision": 0.96441,
            "recall": 0.94934,
            "f1": 0.95648
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_95": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 31,
        "total_length": 557,
        "mean_pred_length": 17.967741935483872,
        "std_pred_length": 5.5094281125132305,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.5888689407540395,
        "vocab_size-1": 328,
        "unique-1": 274,
        "entropy-1": 7.5816456307277305,
        "distinct-2": 0.908745247148289,
        "vocab_size-2": 478,
        "unique-2": 449,
        "entropy-2": 8.820679469293303,
        "cond_entropy-2": 1.093539912214157,
        "distinct-3": 0.9737373737373738,
        "vocab_size-3": 482,
        "unique-3": 472,
        "entropy-3": 8.893194033144448,
        "cond_entropy-3": 0.07051564994768847,
        "total_length-nopunct": 480,
        "mean_pred_length-nopunct": 15.483870967741936,
        "std_pred_length-nopunct": 4.627205439236414,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.66875,
        "vocab_size-1-nopunct": 321,
        "unique-1-nopunct": 271,
        "entropy-1-nopunct": 7.800677236336233,
        "distinct-2-nopunct": 0.9265033407572383,
        "vocab_size-2-nopunct": 416,
        "unique-2-nopunct": 396,
        "entropy-2-nopunct": 8.63399209684553,
        "cond_entropy-2-nopunct": 0.8790558997860778,
        "distinct-3-nopunct": 0.9880382775119617,
        "vocab_size-3-nopunct": 413,
        "unique-3-nopunct": 408,
        "entropy-3-nopunct": 8.68343568710475,
        "cond_entropy-3-nopunct": 0.06014685742381377,
        "msttr-100": 0.734,
        "msttr-100_nopunct": 0.7925,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22123893805309736,
            "2": 0.5,
            "3": 0.8319559228650137
        },
        "nist": 7.550913916309123,
        "bleu": 62.93321,
        "rouge1": {
            "precision": 0.82196,
            "recall": 0.80396,
            "fmeasure": 0.80113
        },
        "rouge2": {
            "precision": 0.66329,
            "recall": 0.64155,
            "fmeasure": 0.64307
        },
        "rougeL": {
            "precision": 0.75375,
            "recall": 0.74126,
            "fmeasure": 0.73519
        },
        "rougeLsum": {
            "precision": 0.75375,
            "recall": 0.74126,
            "fmeasure": 0.73519
        },
        "nubia": {
            "semantic_relation": 4.2555,
            "contradiction": 8.50283,
            "irrelevancy": 21.64051,
            "logical_agreement": 69.85667,
            "grammar_ref": 4.87083,
            "grammar_hyp": 4.81734,
            "nubia_score": 0.74378
        },
        "meteor": 0.46727196019637635,
        "bleurt": 0.38053,
        "bertscore": {
            "precision": 0.94728,
            "recall": 0.94291,
            "f1": 0.94419
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_189": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 18,
        "total_length": 283,
        "mean_pred_length": 15.722222222222221,
        "std_pred_length": 5.140315117400181,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.5901060070671378,
        "vocab_size-1": 167,
        "unique-1": 132,
        "entropy-1": 6.721093905104251,
        "distinct-2": 0.9283018867924528,
        "vocab_size-2": 246,
        "unique-2": 234,
        "entropy-2": 7.865867841895182,
        "cond_entropy-2": 0.9529304003272303,
        "distinct-3": 0.9838056680161943,
        "vocab_size-3": 243,
        "unique-3": 239,
        "entropy-3": 7.915978567617097,
        "cond_entropy-3": 0.06351822667728799,
        "total_length-nopunct": 251,
        "mean_pred_length-nopunct": 13.944444444444445,
        "std_pred_length-nopunct": 4.754789657951025,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6573705179282868,
        "vocab_size-1-nopunct": 165,
        "unique-1-nopunct": 132,
        "entropy-1-nopunct": 6.8797014484302395,
        "distinct-2-nopunct": 0.9227467811158798,
        "vocab_size-2-nopunct": 215,
        "unique-2-nopunct": 204,
        "entropy-2-nopunct": 7.663521391426147,
        "cond_entropy-2-nopunct": 0.8502715863346109,
        "distinct-3-nopunct": 0.986046511627907,
        "vocab_size-3-nopunct": 212,
        "unique-3-nopunct": 209,
        "entropy-3-nopunct": 7.720285872845248,
        "cond_entropy-3-nopunct": 0.07356432122431202,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.775,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19318181818181818,
            "2": 0.423728813559322,
            "3": 0.7888198757763976
        },
        "nist": 5.987075631910278,
        "bleu": 40.60968,
        "rouge1": {
            "precision": 0.70716,
            "recall": 0.71072,
            "fmeasure": 0.69938
        },
        "rouge2": {
            "precision": 0.45307,
            "recall": 0.45886,
            "fmeasure": 0.44878
        },
        "rougeL": {
            "precision": 0.59017,
            "recall": 0.58487,
            "fmeasure": 0.57835
        },
        "rougeLsum": {
            "precision": 0.59017,
            "recall": 0.58487,
            "fmeasure": 0.57835
        },
        "nubia": {
            "semantic_relation": 4.22195,
            "contradiction": 15.54758,
            "irrelevancy": 26.07163,
            "logical_agreement": 58.38079,
            "grammar_ref": 4.82101,
            "grammar_hyp": 4.59803,
            "nubia_score": 0.73791
        },
        "meteor": 0.38400149663880945,
        "bleurt": 0.28909,
        "bertscore": {
            "precision": 0.9199,
            "recall": 0.92269,
            "f1": 0.91832
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_258": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 9,
        "total_length": 148,
        "mean_pred_length": 16.444444444444443,
        "std_pred_length": 4.969039949999533,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.6418918918918919,
        "vocab_size-1": 95,
        "unique-1": 77,
        "entropy-1": 6.104567936759544,
        "distinct-2": 0.9496402877697842,
        "vocab_size-2": 132,
        "unique-2": 127,
        "entropy-2": 7.007359957584479,
        "cond_entropy-2": 0.8016694946366073,
        "distinct-3": 0.9923076923076923,
        "vocab_size-3": 129,
        "unique-3": 128,
        "entropy-3": 7.00698319764384,
        "cond_entropy-3": 0.007348086492077362,
        "total_length-nopunct": 130,
        "mean_pred_length-nopunct": 14.444444444444445,
        "std_pred_length-nopunct": 4.94662873101157,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7,
        "vocab_size-1-nopunct": 91,
        "unique-1-nopunct": 77,
        "entropy-1-nopunct": 6.083804209425804,
        "distinct-2-nopunct": 0.9504132231404959,
        "vocab_size-2-nopunct": 115,
        "unique-2-nopunct": 111,
        "entropy-2-nopunct": 6.807212204180992,
        "cond_entropy-2-nopunct": 0.7766895851057913,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 112,
        "unique-3-nopunct": 112,
        "entropy-3-nopunct": 6.807354922057591,
        "cond_entropy-3-nopunct": 0.0091146758930716,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.71,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.06896551724137931,
            "2": 0.4642857142857143,
            "3": 0.6623376623376623
        },
        "nist": 3.7969821340235423,
        "bleu": 27.10797,
        "rouge1": {
            "precision": 0.61973,
            "recall": 0.68356,
            "fmeasure": 0.63214
        },
        "rouge2": {
            "precision": 0.37241,
            "recall": 0.44648,
            "fmeasure": 0.39315
        },
        "rougeL": {
            "precision": 0.55959,
            "recall": 0.63361,
            "fmeasure": 0.57775
        },
        "rougeLsum": {
            "precision": 0.55959,
            "recall": 0.63361,
            "fmeasure": 0.57775
        },
        "nubia": {
            "semantic_relation": 3.85228,
            "contradiction": 29.39429,
            "irrelevancy": 39.66097,
            "logical_agreement": 30.94474,
            "grammar_ref": 5.16318,
            "grammar_hyp": 4.7645,
            "nubia_score": 0.62938
        },
        "meteor": 0.32037993228745854,
        "bleurt": 0.15487,
        "bertscore": {
            "precision": 0.88749,
            "recall": 0.89815,
            "f1": 0.89156
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_342": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 64,
        "mean_pred_length": 12.8,
        "std_pred_length": 6.8527366796047255,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 26,
        "distinct-1": 0.734375,
        "vocab_size-1": 47,
        "unique-1": 36,
        "entropy-1": 5.36930425036562,
        "distinct-2": 1.0,
        "vocab_size-2": 59,
        "unique-2": 59,
        "entropy-2": 5.882643049361836,
        "cond_entropy-2": 0.3700140239747816,
        "distinct-3": 1.0,
        "vocab_size-3": 54,
        "unique-3": 54,
        "entropy-3": 5.7548875021634665,
        "cond_entropy-3": -0.12775554719837257,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 5.761944116355173,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 45,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.403998122576231,
        "distinct-2-nopunct": 0.98,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.603856189774728,
        "cond_entropy-2-nopunct": 0.2175942262933343,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 45,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.491853096329673,
        "cond_entropy-3-nopunct": -0.10755864900060558,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.625,
            "3": 0.7631578947368421
        },
        "nist": 3.5993063095427096,
        "bleu": 28.81495,
        "rouge1": {
            "precision": 0.72835,
            "recall": 0.76328,
            "fmeasure": 0.73705
        },
        "rouge2": {
            "precision": 0.44357,
            "recall": 0.43388,
            "fmeasure": 0.43418
        },
        "rougeL": {
            "precision": 0.69199,
            "recall": 0.71302,
            "fmeasure": 0.6957
        },
        "rougeLsum": {
            "precision": 0.69199,
            "recall": 0.71302,
            "fmeasure": 0.6957
        },
        "nubia": {
            "semantic_relation": 4.15018,
            "contradiction": 31.10511,
            "irrelevancy": 26.69201,
            "logical_agreement": 42.20288,
            "grammar_ref": 5.90284,
            "grammar_hyp": 5.34335,
            "nubia_score": 0.75595
        },
        "meteor": 0.3916724758045998,
        "bleurt": 0.21559,
        "bertscore": {
            "precision": 0.92347,
            "recall": 0.92084,
            "f1": 0.92198
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_119": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 7,
        "total_length": 94,
        "mean_pred_length": 13.428571428571429,
        "std_pred_length": 2.3211538298959886,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 17,
        "distinct-1": 0.7127659574468085,
        "vocab_size-1": 67,
        "unique-1": 52,
        "entropy-1": 5.832076649965996,
        "distinct-2": 0.9770114942528736,
        "vocab_size-2": 85,
        "unique-2": 83,
        "entropy-2": 6.396966484354469,
        "cond_entropy-2": 0.39714386838362453,
        "distinct-3": 0.9875,
        "vocab_size-3": 79,
        "unique-3": 78,
        "entropy-3": 6.296928094887356,
        "cond_entropy-3": -0.09601540096136618,
        "total_length-nopunct": 81,
        "mean_pred_length-nopunct": 11.571428571428571,
        "std_pred_length-nopunct": 2.381904571504724,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7654320987654321,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.8026922867818165,
        "distinct-2-nopunct": 0.9864864864864865,
        "vocab_size-2-nopunct": 73,
        "unique-2-nopunct": 72,
        "entropy-2-nopunct": 6.182426338601928,
        "cond_entropy-2-nopunct": 0.417032754694689,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 67,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 6.066089190457767,
        "cond_entropy-3-nopunct": -0.11351342890252035,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.2777777777777778,
            "3": 0.7619047619047619
        },
        "nist": 5.061998640872223,
        "bleu": 47.49256,
        "rouge1": {
            "precision": 0.73559,
            "recall": 0.67478,
            "fmeasure": 0.7008
        },
        "rouge2": {
            "precision": 0.52262,
            "recall": 0.49075,
            "fmeasure": 0.50314
        },
        "rougeL": {
            "precision": 0.64226,
            "recall": 0.60521,
            "fmeasure": 0.61977
        },
        "rougeLsum": {
            "precision": 0.64226,
            "recall": 0.60521,
            "fmeasure": 0.61977
        },
        "nubia": {
            "semantic_relation": 4.21031,
            "contradiction": 11.36256,
            "irrelevancy": 15.03528,
            "logical_agreement": 73.60217,
            "grammar_ref": 4.57228,
            "grammar_hyp": 4.4844,
            "nubia_score": 0.74121
        },
        "meteor": 0.36235275155699775,
        "bleurt": 0.19166,
        "bertscore": {
            "precision": 0.9365,
            "recall": 0.91899,
            "f1": 0.9272
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_175": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 21,
        "total_length": 342,
        "mean_pred_length": 16.285714285714285,
        "std_pred_length": 3.730732816343028,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 23,
        "distinct-1": 0.6081871345029239,
        "vocab_size-1": 208,
        "unique-1": 172,
        "entropy-1": 6.979736549156984,
        "distinct-2": 0.940809968847352,
        "vocab_size-2": 302,
        "unique-2": 290,
        "entropy-2": 8.179509675724344,
        "cond_entropy-2": 1.0424205176106391,
        "distinct-3": 0.9833333333333333,
        "vocab_size-3": 295,
        "unique-3": 290,
        "entropy-3": 8.195485357162605,
        "cond_entropy-3": 0.026260068236011527,
        "total_length-nopunct": 299,
        "mean_pred_length-nopunct": 14.238095238095237,
        "std_pred_length-nopunct": 3.24997819633363,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6789297658862876,
        "vocab_size-1-nopunct": 203,
        "unique-1-nopunct": 171,
        "entropy-1-nopunct": 7.113204369120227,
        "distinct-2-nopunct": 0.9424460431654677,
        "vocab_size-2-nopunct": 262,
        "unique-2-nopunct": 252,
        "entropy-2-nopunct": 7.973594411009192,
        "cond_entropy-2-nopunct": 0.9292994606126918,
        "distinct-3-nopunct": 0.9844357976653697,
        "vocab_size-3-nopunct": 253,
        "unique-3-nopunct": 249,
        "entropy-3-nopunct": 7.974496144524645,
        "cond_entropy-3-nopunct": 0.012778308986194385,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24242424242424243,
            "2": 0.48936170212765956,
            "3": 0.7422680412371134
        },
        "nist": 5.984918357245965,
        "bleu": 38.40647,
        "rouge1": {
            "precision": 0.72165,
            "recall": 0.70091,
            "fmeasure": 0.70649
        },
        "rouge2": {
            "precision": 0.45578,
            "recall": 0.45558,
            "fmeasure": 0.45367
        },
        "rougeL": {
            "precision": 0.61521,
            "recall": 0.60828,
            "fmeasure": 0.60912
        },
        "rougeLsum": {
            "precision": 0.61521,
            "recall": 0.60828,
            "fmeasure": 0.60912
        },
        "nubia": {
            "semantic_relation": 4.24572,
            "contradiction": 4.39619,
            "irrelevancy": 44.62047,
            "logical_agreement": 50.98334,
            "grammar_ref": 4.90831,
            "grammar_hyp": 4.5694,
            "nubia_score": 0.74144
        },
        "meteor": 0.3718060751548824,
        "bleurt": 0.25543,
        "bertscore": {
            "precision": 0.92885,
            "recall": 0.92261,
            "f1": 0.92429
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_240": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 31,
        "total_length": 535,
        "mean_pred_length": 17.258064516129032,
        "std_pred_length": 5.945818492371321,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 33,
        "distinct-1": 0.5644859813084112,
        "vocab_size-1": 302,
        "unique-1": 239,
        "entropy-1": 7.4767672179244515,
        "distinct-2": 0.8948412698412699,
        "vocab_size-2": 451,
        "unique-2": 413,
        "entropy-2": 8.729193490087834,
        "cond_entropy-2": 1.089337980905224,
        "distinct-3": 0.9513742071881607,
        "vocab_size-3": 450,
        "unique-3": 428,
        "entropy-3": 8.786848831051575,
        "cond_entropy-3": 0.07391470552128439,
        "total_length-nopunct": 460,
        "mean_pred_length-nopunct": 14.838709677419354,
        "std_pred_length-nopunct": 4.600818820486046,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6456521739130435,
        "vocab_size-1-nopunct": 297,
        "unique-1-nopunct": 239,
        "entropy-1-nopunct": 7.700274058557955,
        "distinct-2-nopunct": 0.9184149184149184,
        "vocab_size-2-nopunct": 394,
        "unique-2-nopunct": 369,
        "entropy-2-nopunct": 8.549225103325004,
        "cond_entropy-2-nopunct": 0.9177195663614014,
        "distinct-3-nopunct": 0.9673366834170855,
        "vocab_size-3-nopunct": 385,
        "unique-3-nopunct": 372,
        "entropy-3-nopunct": 8.571297987377841,
        "cond_entropy-3-nopunct": 0.03479617741820764,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.8175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26851851851851855,
            "2": 0.3625,
            "3": 0.8351351351351352
        },
        "nist": 7.54054854640818,
        "bleu": 62.86565,
        "rouge1": {
            "precision": 0.81955,
            "recall": 0.80522,
            "fmeasure": 0.80458
        },
        "rouge2": {
            "precision": 0.64343,
            "recall": 0.62588,
            "fmeasure": 0.62801
        },
        "rougeL": {
            "precision": 0.75365,
            "recall": 0.73179,
            "fmeasure": 0.73519
        },
        "rougeLsum": {
            "precision": 0.75365,
            "recall": 0.73179,
            "fmeasure": 0.73519
        },
        "nubia": {
            "semantic_relation": 4.42656,
            "contradiction": 8.12848,
            "irrelevancy": 18.14498,
            "logical_agreement": 73.72654,
            "grammar_ref": 4.66938,
            "grammar_hyp": 4.72935,
            "nubia_score": 0.78341
        },
        "meteor": 0.4546554016077678,
        "bleurt": 0.40219,
        "bertscore": {
            "precision": 0.95267,
            "recall": 0.94893,
            "f1": 0.94903
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_343": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 6,
        "total_length": 108,
        "mean_pred_length": 18.0,
        "std_pred_length": 7.094598884597588,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.6944444444444444,
        "vocab_size-1": 75,
        "unique-1": 58,
        "entropy-1": 5.9299469102208615,
        "distinct-2": 0.9607843137254902,
        "vocab_size-2": 98,
        "unique-2": 94,
        "entropy-2": 6.59399396942248,
        "cond_entropy-2": 0.5987529717233613,
        "distinct-3": 0.9895833333333334,
        "vocab_size-3": 95,
        "unique-3": 94,
        "entropy-3": 6.5641291673878275,
        "cond_entropy-3": -0.024962841250339422,
        "total_length-nopunct": 98,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 6.79869268479038,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.7244897959183674,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.872576620102962,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 88,
        "unique-2-nopunct": 84,
        "entropy-2-nopunct": 6.436605434317896,
        "cond_entropy-2-nopunct": 0.6124288070852889,
        "distinct-3-nopunct": 0.9883720930232558,
        "vocab_size-3-nopunct": 85,
        "unique-3-nopunct": 84,
        "entropy-3-nopunct": 6.40300894074861,
        "cond_entropy-3-nopunct": -0.02752975949445001,
        "msttr-100": 0.72,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.5833333333333334,
            "3": 0.7291666666666666
        },
        "nist": 3.824276557643631,
        "bleu": 33.07193,
        "rouge1": {
            "precision": 0.61648,
            "recall": 0.72195,
            "fmeasure": 0.63727
        },
        "rouge2": {
            "precision": 0.38034,
            "recall": 0.46375,
            "fmeasure": 0.39847
        },
        "rougeL": {
            "precision": 0.49539,
            "recall": 0.58407,
            "fmeasure": 0.51317
        },
        "rougeLsum": {
            "precision": 0.49539,
            "recall": 0.58407,
            "fmeasure": 0.51317
        },
        "nubia": {
            "semantic_relation": 3.8281,
            "contradiction": 0.87195,
            "irrelevancy": 56.85827,
            "logical_agreement": 42.26978,
            "grammar_ref": 4.25456,
            "grammar_hyp": 4.63958,
            "nubia_score": 0.5545
        },
        "meteor": 0.3804553172458454,
        "bleurt": -0.05727,
        "bertscore": {
            "precision": 0.8738,
            "recall": 0.89193,
            "f1": 0.8817
        }
    },
    "wiki_lingua_russian_ru_test": {
        "predictions_file": "ByT5-base (Baseline)/wiki_lingua_russian_ru_test",
        "N": 10580,
        "total_length": 248704,
        "mean_pred_length": 23.506994328922495,
        "std_pred_length": 6.168877940850927,
        "median_pred_length": 25.0,
        "min_pred_length": 2,
        "max_pred_length": 44,
        "distinct-1": 0.04196957025218734,
        "vocab_size-1": 10438,
        "unique-1": 4023,
        "entropy-1": 8.744834465040483,
        "distinct-2": 0.23851858695469588,
        "vocab_size-2": 56797,
        "unique-2": 35848,
        "entropy-2": 13.55435807351279,
        "cond_entropy-2": 4.791402271296809,
        "distinct-3": 0.5355843265478325,
        "vocab_size-3": 121869,
        "unique-3": 94844,
        "entropy-3": 15.838337685061546,
        "cond_entropy-3": 2.342503326958222,
        "total_length-nopunct": 210313,
        "mean_pred_length-nopunct": 19.87835538752363,
        "std_pred_length-nopunct": 5.624047437796413,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.049516672768682865,
        "vocab_size-1-nopunct": 10414,
        "unique-1-nopunct": 4022,
        "entropy-1-nopunct": 9.557711514525316,
        "distinct-2-nopunct": 0.35695653697686414,
        "vocab_size-2-nopunct": 71296,
        "unique-2-nopunct": 50238,
        "entropy-2-nopunct": 14.333712438098441,
        "cond_entropy-2-nopunct": 4.929513699393592,
        "distinct-3-nopunct": 0.6733189889879835,
        "vocab_size-3-nopunct": 127363,
        "unique-3-nopunct": 105995,
        "entropy-3-nopunct": 16.351122885654103,
        "cond_entropy-3-nopunct": 2.0965376301648853,
        "msttr-100": 0.56228,
        "msttr-100_nopunct": 0.63619,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_test.json",
        "local_recall": {
            "1": 0.23215210586760546
        },
        "nist": 1.556092885833661,
        "bleu": 6.70987,
        "rouge1": {
            "precision": 0.4146,
            "recall": 0.27885,
            "fmeasure": 0.3136
        },
        "rouge2": {
            "precision": 0.14641,
            "recall": 0.09754,
            "fmeasure": 0.10986
        },
        "rougeL": {
            "precision": 0.3446,
            "recall": 0.2346,
            "fmeasure": 0.26231
        },
        "rougeLsum": {
            "precision": 0.3446,
            "recall": 0.2346,
            "fmeasure": 0.26231
        },
        "sari": 68.17267,
        "nubia": {
            "semantic_relation": 2.70149,
            "contradiction": 18.26337,
            "irrelevancy": 41.06026,
            "logical_agreement": 40.67636,
            "grammar_ref": 3.95647,
            "grammar_hyp": 3.88532,
            "nubia_score": 0.34728
        },
        "meteor": 0.12853203568338523,
        "bleurt": -0.51117,
        "bertscore": {
            "precision": 0.85184,
            "recall": 0.81877,
            "f1": 0.83442
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_176": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 23,
        "total_length": 383,
        "mean_pred_length": 16.652173913043477,
        "std_pred_length": 6.189814183150264,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.5822454308093995,
        "vocab_size-1": 223,
        "unique-1": 191,
        "entropy-1": 6.93284403572535,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 336,
        "unique-2": 321,
        "entropy-2": 8.323089519934756,
        "cond_entropy-2": 1.2246811038421495,
        "distinct-3": 0.9940652818991098,
        "vocab_size-3": 335,
        "unique-3": 333,
        "entropy-3": 8.384735344980063,
        "cond_entropy-3": 0.06426173678738713,
        "total_length-nopunct": 329,
        "mean_pred_length-nopunct": 14.304347826086957,
        "std_pred_length-nopunct": 5.392706689987358,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6595744680851063,
        "vocab_size-1-nopunct": 217,
        "unique-1-nopunct": 189,
        "entropy-1-nopunct": 7.088865064679386,
        "distinct-2-nopunct": 0.9477124183006536,
        "vocab_size-2-nopunct": 290,
        "unique-2-nopunct": 283,
        "entropy-2-nopunct": 8.111130040398036,
        "cond_entropy-2-nopunct": 1.0798435123542998,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 283,
        "unique-3-nopunct": 283,
        "entropy-3-nopunct": 8.14465824283186,
        "cond_entropy-3-nopunct": 0.03981430473796681,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.75333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.136986301369863,
            "2": 0.37209302325581395,
            "3": 0.8076923076923077
        },
        "nist": 6.510339973327841,
        "bleu": 53.08302,
        "rouge1": {
            "precision": 0.76485,
            "recall": 0.74831,
            "fmeasure": 0.74673
        },
        "rouge2": {
            "precision": 0.5869,
            "recall": 0.5552,
            "fmeasure": 0.56064
        },
        "rougeL": {
            "precision": 0.67853,
            "recall": 0.67261,
            "fmeasure": 0.66698
        },
        "rougeLsum": {
            "precision": 0.67853,
            "recall": 0.67261,
            "fmeasure": 0.66698
        },
        "nubia": {
            "semantic_relation": 4.38882,
            "contradiction": 0.37738,
            "irrelevancy": 22.0573,
            "logical_agreement": 77.56532,
            "grammar_ref": 4.50686,
            "grammar_hyp": 4.48376,
            "nubia_score": 0.79721
        },
        "meteor": 0.41729145324641786,
        "bleurt": 0.38853,
        "bertscore": {
            "precision": 0.94223,
            "recall": 0.93318,
            "f1": 0.93418
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_120": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 75,
        "total_length": 1227,
        "mean_pred_length": 16.36,
        "std_pred_length": 5.823263689719023,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.4873675631621842,
        "vocab_size-1": 598,
        "unique-1": 466,
        "entropy-1": 7.988686434566475,
        "distinct-2": 0.8489583333333334,
        "vocab_size-2": 978,
        "unique-2": 896,
        "entropy-2": 9.740984937108838,
        "cond_entropy-2": 1.5357208008395815,
        "distinct-3": 0.9387186629526463,
        "vocab_size-3": 1011,
        "unique-3": 975,
        "entropy-3": 9.924438833541997,
        "cond_entropy-3": 0.17232041952173804,
        "total_length-nopunct": 1072,
        "mean_pred_length-nopunct": 14.293333333333333,
        "std_pred_length-nopunct": 5.240288372048071,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5494402985074627,
        "vocab_size-1-nopunct": 589,
        "unique-1-nopunct": 464,
        "entropy-1-nopunct": 8.21523534369936,
        "distinct-2-nopunct": 0.8625877632898696,
        "vocab_size-2-nopunct": 860,
        "unique-2-nopunct": 799,
        "entropy-2-nopunct": 9.557524887831757,
        "cond_entropy-2-nopunct": 1.4327294179702632,
        "distinct-3-nopunct": 0.9436008676789588,
        "vocab_size-3-nopunct": 870,
        "unique-3-nopunct": 844,
        "entropy-3-nopunct": 9.709492863450095,
        "cond_entropy-3-nopunct": 0.16800331779651917,
        "msttr-100": 0.7275,
        "msttr-100_nopunct": 0.773,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2037735849056604,
            "2": 0.49074074074074076,
            "3": 0.7757961783439491
        },
        "nist": 7.4806270811142035,
        "bleu": 45.99603,
        "rouge1": {
            "precision": 0.76964,
            "recall": 0.73921,
            "fmeasure": 0.74042
        },
        "rouge2": {
            "precision": 0.5555,
            "recall": 0.53845,
            "fmeasure": 0.53606
        },
        "rougeL": {
            "precision": 0.66496,
            "recall": 0.64347,
            "fmeasure": 0.64122
        },
        "rougeLsum": {
            "precision": 0.66496,
            "recall": 0.64347,
            "fmeasure": 0.64122
        },
        "nubia": {
            "semantic_relation": 4.13371,
            "contradiction": 7.41128,
            "irrelevancy": 34.89365,
            "logical_agreement": 57.69506,
            "grammar_ref": 4.90125,
            "grammar_hyp": 5.0274,
            "nubia_score": 0.68398
        },
        "meteor": 0.3932741568022686,
        "bleurt": 0.22596,
        "bertscore": {
            "precision": 0.93219,
            "recall": 0.92363,
            "f1": 0.92568
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_259": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 75,
        "mean_pred_length": 15.0,
        "std_pred_length": 2.8284271247461903,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 19,
        "distinct-1": 0.72,
        "vocab_size-1": 54,
        "unique-1": 43,
        "entropy-1": 5.510494650750188,
        "distinct-2": 0.9714285714285714,
        "vocab_size-2": 68,
        "unique-2": 66,
        "entropy-2": 6.072140159802114,
        "cond_entropy-2": 0.44710236225609146,
        "distinct-3": 1.0,
        "vocab_size-3": 65,
        "unique-3": 65,
        "entropy-3": 6.022367813028458,
        "cond_entropy-3": -0.045376742378050665,
        "total_length-nopunct": 67,
        "mean_pred_length-nopunct": 13.4,
        "std_pred_length-nopunct": 2.727636339397171,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7761194029850746,
        "vocab_size-1-nopunct": 52,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.506241802333487,
        "distinct-2-nopunct": 0.967741935483871,
        "vocab_size-2-nopunct": 60,
        "unique-2-nopunct": 58,
        "entropy-2-nopunct": 5.889680181354615,
        "cond_entropy-2-nopunct": 0.41245832967631185,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 57,
        "unique-3-nopunct": 57,
        "entropy-3-nopunct": 5.832890014164737,
        "cond_entropy-3-nopunct": -0.0686747172747651,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.3333333333333333,
            "3": 0.84
        },
        "nist": 5.174237957853003,
        "bleu": 47.59855,
        "rouge1": {
            "precision": 0.77628,
            "recall": 0.832,
            "fmeasure": 0.79378
        },
        "rouge2": {
            "precision": 0.50815,
            "recall": 0.55221,
            "fmeasure": 0.52419
        },
        "rougeL": {
            "precision": 0.67813,
            "recall": 0.73578,
            "fmeasure": 0.70019
        },
        "rougeLsum": {
            "precision": 0.67813,
            "recall": 0.73578,
            "fmeasure": 0.70019
        },
        "nubia": {
            "semantic_relation": 4.73567,
            "contradiction": 0.64949,
            "irrelevancy": 19.7554,
            "logical_agreement": 79.5951,
            "grammar_ref": 4.84964,
            "grammar_hyp": 4.76276,
            "nubia_score": 0.85973
        },
        "meteor": 0.4430401427943344,
        "bleurt": 0.55063,
        "bertscore": {
            "precision": 0.95363,
            "recall": 0.95001,
            "f1": 0.95137
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_177": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 43,
        "mean_pred_length": 14.333333333333334,
        "std_pred_length": 2.494438257849294,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 17,
        "distinct-1": 0.8372093023255814,
        "vocab_size-1": 36,
        "unique-1": 32,
        "entropy-1": 5.036616208140156,
        "distinct-2": 1.0,
        "vocab_size-2": 40,
        "unique-2": 40,
        "entropy-2": 5.3219280948873635,
        "cond_entropy-2": 0.19566334018526424,
        "distinct-3": 1.0,
        "vocab_size-3": 37,
        "unique-3": 37,
        "entropy-3": 5.209453365628954,
        "cond_entropy-3": -0.11247472925841272,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 2.0548046676563256,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 4.984769618706745,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.129283016944964,
        "cond_entropy-2-nopunct": 0.16706978921566668,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.12928301694496638,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.5714285714285714,
            "3": 0.8571428571428571
        },
        "nist": 5.234108233735735,
        "bleu": 47.99063,
        "rouge1": {
            "precision": 0.83579,
            "recall": 0.80271,
            "fmeasure": 0.81506
        },
        "rouge2": {
            "precision": 0.58095,
            "recall": 0.53263,
            "fmeasure": 0.55106
        },
        "rougeL": {
            "precision": 0.72028,
            "recall": 0.69862,
            "fmeasure": 0.70383
        },
        "rougeLsum": {
            "precision": 0.72028,
            "recall": 0.69862,
            "fmeasure": 0.70383
        },
        "nubia": {
            "semantic_relation": 4.56399,
            "contradiction": 0.34492,
            "irrelevancy": 35.45134,
            "logical_agreement": 64.20374,
            "grammar_ref": 5.80868,
            "grammar_hyp": 5.76131,
            "nubia_score": 0.83518
        },
        "meteor": 0.4321946872460301,
        "bleurt": 0.35238,
        "bertscore": {
            "precision": 0.95071,
            "recall": 0.95236,
            "f1": 0.95082
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_296": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 7,
        "total_length": 109,
        "mean_pred_length": 15.571428571428571,
        "std_pred_length": 6.758214955722783,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.6513761467889908,
        "vocab_size-1": 71,
        "unique-1": 55,
        "entropy-1": 5.809968985567064,
        "distinct-2": 0.9509803921568627,
        "vocab_size-2": 97,
        "unique-2": 93,
        "entropy-2": 6.566985268420877,
        "cond_entropy-2": 0.6707195413846094,
        "distinct-3": 0.9789473684210527,
        "vocab_size-3": 93,
        "unique-3": 91,
        "entropy-3": 6.527750345173053,
        "cond_entropy-3": -0.03146565467040612,
        "total_length-nopunct": 92,
        "mean_pred_length-nopunct": 13.142857142857142,
        "std_pred_length-nopunct": 5.591538797365979,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.717391304347826,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 54,
        "entropy-1-nopunct": 5.768932369478536,
        "distinct-2-nopunct": 0.9411764705882353,
        "vocab_size-2-nopunct": 80,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 6.2828628478769595,
        "cond_entropy-2-nopunct": 0.5574298266964062,
        "distinct-3-nopunct": 0.9743589743589743,
        "vocab_size-3-nopunct": 76,
        "unique-3-nopunct": 74,
        "entropy-3-nopunct": 6.234120167580205,
        "cond_entropy-3-nopunct": -0.05770762751337231,
        "msttr-100": 0.69,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.5882352941176471,
            "3": 0.5942028985507246
        },
        "nist": 3.9502425033348745,
        "bleu": 22.14654,
        "rouge1": {
            "precision": 0.63691,
            "recall": 0.60431,
            "fmeasure": 0.61089
        },
        "rouge2": {
            "precision": 0.34949,
            "recall": 0.34349,
            "fmeasure": 0.3409
        },
        "rougeL": {
            "precision": 0.56705,
            "recall": 0.55216,
            "fmeasure": 0.55134
        },
        "rougeLsum": {
            "precision": 0.56705,
            "recall": 0.55216,
            "fmeasure": 0.55134
        },
        "nubia": {
            "semantic_relation": 3.78392,
            "contradiction": 21.97438,
            "irrelevancy": 38.3069,
            "logical_agreement": 39.71873,
            "grammar_ref": 4.06397,
            "grammar_hyp": 4.44516,
            "nubia_score": 0.64662
        },
        "meteor": 0.3194263700299461,
        "bleurt": 0.05869,
        "bertscore": {
            "precision": 0.89694,
            "recall": 0.8929,
            "f1": 0.89296
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_243": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 1.0,
        "median_pred_length": 20.0,
        "min_pred_length": 19,
        "max_pred_length": 21,
        "distinct-1": 0.625,
        "vocab_size-1": 25,
        "unique-1": 16,
        "entropy-1": 4.384183719779189,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 36,
        "unique-2": 34,
        "entropy-2": 5.142664355548852,
        "cond_entropy-2": 0.7552040239332484,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": 0.03310859910983796,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.210764573772789,
        "distinct-2-nopunct": 0.967741935483871,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.889680181354619,
        "cond_entropy-2-nopunct": 0.7004400943938068,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.02724979801792366,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9473684210526315
        },
        "nist": 2.893520068931775,
        "bleu": 40.32356,
        "rouge1": {
            "precision": 0.62281,
            "recall": 0.92857,
            "fmeasure": 0.7125
        },
        "rouge2": {
            "precision": 0.47222,
            "recall": 0.67892,
            "fmeasure": 0.53284
        },
        "rougeL": {
            "precision": 0.60526,
            "recall": 0.91931,
            "fmeasure": 0.69874
        },
        "rougeLsum": {
            "precision": 0.60526,
            "recall": 0.91931,
            "fmeasure": 0.69874
        },
        "nubia": {
            "semantic_relation": 3.92811,
            "contradiction": 0.11285,
            "irrelevancy": 50.04987,
            "logical_agreement": 49.83727,
            "grammar_ref": 5.56806,
            "grammar_hyp": 4.14986,
            "nubia_score": 0.60974
        },
        "meteor": 0.47523214599267444,
        "bleurt": 0.41236,
        "bertscore": {
            "precision": 0.92067,
            "recall": 0.96393,
            "f1": 0.94146
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_260": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 22,
        "total_length": 327,
        "mean_pred_length": 14.863636363636363,
        "std_pred_length": 4.434323301304932,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.5932721712538226,
        "vocab_size-1": 194,
        "unique-1": 152,
        "entropy-1": 6.99370494335296,
        "distinct-2": 0.898360655737705,
        "vocab_size-2": 274,
        "unique-2": 251,
        "entropy-2": 8.027979120932232,
        "cond_entropy-2": 0.8299104252148205,
        "distinct-3": 0.9540636042402827,
        "vocab_size-3": 270,
        "unique-3": 260,
        "entropy-3": 8.044783110300093,
        "cond_entropy-3": 0.010401909336852762,
        "total_length-nopunct": 285,
        "mean_pred_length-nopunct": 12.954545454545455,
        "std_pred_length-nopunct": 3.819534392462858,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6596491228070176,
        "vocab_size-1-nopunct": 188,
        "unique-1-nopunct": 151,
        "entropy-1-nopunct": 7.110012829858746,
        "distinct-2-nopunct": 0.9049429657794676,
        "vocab_size-2-nopunct": 238,
        "unique-2-nopunct": 219,
        "entropy-2-nopunct": 7.829719179373492,
        "cond_entropy-2-nopunct": 0.7639872093602388,
        "distinct-3-nopunct": 0.9626556016597511,
        "vocab_size-3-nopunct": 232,
        "unique-3-nopunct": 224,
        "entropy-3-nopunct": 7.835068226262511,
        "cond_entropy-3-nopunct": 0.0005669237190990111,
        "msttr-100": 0.72667,
        "msttr-100_nopunct": 0.765,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11904761904761904,
            "2": 0.2777777777777778,
            "3": 0.8735177865612648
        },
        "nist": 6.933702709920098,
        "bleu": 64.32249,
        "rouge1": {
            "precision": 0.85762,
            "recall": 0.84954,
            "fmeasure": 0.84546
        },
        "rouge2": {
            "precision": 0.69549,
            "recall": 0.68834,
            "fmeasure": 0.68612
        },
        "rougeL": {
            "precision": 0.79548,
            "recall": 0.78545,
            "fmeasure": 0.78276
        },
        "rougeLsum": {
            "precision": 0.79548,
            "recall": 0.78545,
            "fmeasure": 0.78276
        },
        "nubia": {
            "semantic_relation": 4.51576,
            "contradiction": 2.33553,
            "irrelevancy": 24.50657,
            "logical_agreement": 73.1579,
            "grammar_ref": 4.36588,
            "grammar_hyp": 4.41707,
            "nubia_score": 0.84411
        },
        "meteor": 0.48498938891843496,
        "bleurt": 0.49471,
        "bertscore": {
            "precision": 0.95996,
            "recall": 0.95807,
            "f1": 0.95828
        }
    },
    "dart_validation": {
        "predictions_file": "ByT5-base (Baseline)/dart_validation",
        "N": 2768,
        "total_length": 55391,
        "mean_pred_length": 20.01119942196532,
        "std_pred_length": 6.105427700441434,
        "median_pred_length": 22.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.06804354498023145,
        "vocab_size-1": 3769,
        "unique-1": 1799,
        "entropy-1": 7.836826772905315,
        "distinct-2": 0.22917735590901317,
        "vocab_size-2": 12060,
        "unique-2": 7747,
        "entropy-2": 10.920384352293034,
        "cond_entropy-2": 3.035052716026466,
        "distinct-3": 0.37378397352321735,
        "vocab_size-3": 18635,
        "unique-3": 13756,
        "entropy-3": 12.355960400362084,
        "cond_entropy-3": 1.54026872508697,
        "total_length-nopunct": 50627,
        "mean_pred_length-nopunct": 18.290101156069365,
        "std_pred_length-nopunct": 5.890193696447933,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.07415015703083334,
        "vocab_size-1-nopunct": 3754,
        "unique-1-nopunct": 1796,
        "entropy-1-nopunct": 7.981728623870223,
        "distinct-2-nopunct": 0.23491924193986502,
        "vocab_size-2-nopunct": 11243,
        "unique-2-nopunct": 7380,
        "entropy-2-nopunct": 10.813707112759742,
        "cond_entropy-2-nopunct": 3.003361494283911,
        "distinct-3-nopunct": 0.3764609345545674,
        "vocab_size-3-nopunct": 16975,
        "unique-3-nopunct": 12608,
        "entropy-3-nopunct": 12.249661934534528,
        "cond_entropy-3-nopunct": 1.544140673022228,
        "msttr-100": 0.47573,
        "msttr-100_nopunct": 0.4803,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/dart_validation.json",
        "local_recall": {
            "1": 0.021273986880019618,
            "2": 0.016928778924171092,
            "3": 0.01471004243281471,
            "4": 0.028218369605311693,
            "5": 0.04548436474961732,
            "6": 0.06507413509060955,
            "7": 0.08590604026845637,
            "8": 0.09314516129032258,
            "9": 0.10484780157835401,
            "10": 0.10646108663729809,
            "11": 0.1141602634467618,
            "12": 0.12168486739469579,
            "13": 0.09409190371991247,
            "14": 0.06086956521739131,
            "15": 0.08018867924528301,
            "16": 0.09027777777777778,
            "17": 0.0,
            "18": 0.06666666666666667,
            "19": 0.08333333333333333,
            "20": 0.08823529411764706,
            "21": 0.13043478260869565,
            "22": 0.0,
            "23": 0.06666666666666667,
            "24": 0.1,
            "25": 0.3333333333333333,
            "26": 0.5,
            "27": 0,
            "28": 0.0,
            "29": 0.0,
            "30": 0.0,
            "31": 0.0,
            "32": 0,
            "33": 0,
            "34": 0,
            "35": 0,
            "36": 0,
            "37": 0.0,
            "38": 0,
            "39": 0,
            "40": 0,
            "41": 0,
            "42": 0,
            "43": 0,
            "44": 0,
            "45": 0,
            "46": 0,
            "47": 0,
            "48": 0,
            "49": 0,
            "50": 0,
            "51": 0,
            "52": 0,
            "53": 0,
            "54": 0,
            "55": 0,
            "56": 0,
            "57": 0,
            "58": 0,
            "59": 0,
            "60": 0,
            "61": 0,
            "62": 0,
            "63": 0,
            "64": 0,
            "65": 0,
            "66": 0,
            "67": 0,
            "68": 0,
            "69": 0,
            "70": 0,
            "71": 0,
            "72": 0
        },
        "nist": 0.6137482316097256,
        "bleu": 0.00594,
        "rouge1": {
            "precision": 0.03944,
            "recall": 0.7276,
            "fmeasure": 0.0743
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.03944,
            "recall": 0.7276,
            "fmeasure": 0.0743
        },
        "rougeLsum": {
            "precision": 0.03944,
            "recall": 0.7276,
            "fmeasure": 0.0743
        },
        "nubia": {
            "semantic_relation": 4.08181,
            "contradiction": 6.95049,
            "irrelevancy": 19.8226,
            "logical_agreement": 73.22691,
            "grammar_ref": 4.89251,
            "grammar_hyp": 4.84676,
            "nubia_score": 0.68318
        },
        "meteor": 0.08265432904095381,
        "bleurt": 0.049,
        "bertscore": {
            "precision": 0.90366,
            "recall": 0.89104,
            "f1": 0.89695
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_244": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 6,
        "total_length": 106,
        "mean_pred_length": 17.666666666666668,
        "std_pred_length": 5.9907335852038095,
        "median_pred_length": 15.5,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.7264150943396226,
        "vocab_size-1": 77,
        "unique-1": 66,
        "entropy-1": 5.953966680815002,
        "distinct-2": 1.0,
        "vocab_size-2": 100,
        "unique-2": 100,
        "entropy-2": 6.6438561897747395,
        "cond_entropy-2": 0.5812289853413334,
        "distinct-3": 1.0,
        "vocab_size-3": 94,
        "unique-3": 94,
        "entropy-3": 6.554588851677623,
        "cond_entropy-3": -0.08926733809708727,
        "total_length-nopunct": 91,
        "mean_pred_length-nopunct": 15.166666666666666,
        "std_pred_length-nopunct": 4.4503433076062295,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8021978021978022,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 66,
        "entropy-1-nopunct": 5.933457689577926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 85,
        "unique-2-nopunct": 85,
        "entropy-2-nopunct": 6.409390936137707,
        "cond_entropy-2-nopunct": 0.5164746783683051,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 79,
        "unique-3-nopunct": 79,
        "entropy-3-nopunct": 6.303780748177105,
        "cond_entropy-3-nopunct": -0.10561018796059891,
        "msttr-100": 0.72,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.3333333333333333,
            "3": 0.8333333333333334
        },
        "nist": 5.86969605284093,
        "bleu": 51.30498,
        "rouge1": {
            "precision": 0.79453,
            "recall": 0.79519,
            "fmeasure": 0.78844
        },
        "rouge2": {
            "precision": 0.57116,
            "recall": 0.57929,
            "fmeasure": 0.56814
        },
        "rougeL": {
            "precision": 0.65485,
            "recall": 0.66364,
            "fmeasure": 0.65119
        },
        "rougeLsum": {
            "precision": 0.65485,
            "recall": 0.66364,
            "fmeasure": 0.65119
        },
        "nubia": {
            "semantic_relation": 4.11633,
            "contradiction": 28.90096,
            "irrelevancy": 14.06307,
            "logical_agreement": 57.03597,
            "grammar_ref": 4.74863,
            "grammar_hyp": 5.08893,
            "nubia_score": 0.61362
        },
        "meteor": 0.4231271845420522,
        "bleurt": 0.2824,
        "bertscore": {
            "precision": 0.94845,
            "recall": 0.94727,
            "f1": 0.94688
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_190": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 13,
        "total_length": 191,
        "mean_pred_length": 14.692307692307692,
        "std_pred_length": 3.472631797014065,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 19,
        "distinct-1": 0.6387434554973822,
        "vocab_size-1": 122,
        "unique-1": 101,
        "entropy-1": 6.441463047452926,
        "distinct-2": 0.9438202247191011,
        "vocab_size-2": 168,
        "unique-2": 160,
        "entropy-2": 7.352137925348396,
        "cond_entropy-2": 0.7233818375120269,
        "distinct-3": 0.9939393939393939,
        "vocab_size-3": 164,
        "unique-3": 163,
        "entropy-3": 7.354201002124596,
        "cond_entropy-3": -0.0003203076296729472,
        "total_length-nopunct": 166,
        "mean_pred_length-nopunct": 12.76923076923077,
        "std_pred_length-nopunct": 3.190221746665803,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7168674698795181,
        "vocab_size-1-nopunct": 119,
        "unique-1-nopunct": 100,
        "entropy-1-nopunct": 6.587027383452485,
        "distinct-2-nopunct": 0.9477124183006536,
        "vocab_size-2-nopunct": 145,
        "unique-2-nopunct": 139,
        "entropy-2-nopunct": 7.139740783869104,
        "cond_entropy-2-nopunct": 0.606596777035105,
        "distinct-3-nopunct": 0.9928571428571429,
        "vocab_size-3-nopunct": 139,
        "unique-3-nopunct": 138,
        "entropy-3-nopunct": 7.114997302659264,
        "cond_entropy-3-nopunct": -0.013819111461970887,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.8,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18518518518518517,
            "2": 0.09090909090909091,
            "3": 0.9144736842105263
        },
        "nist": 6.785650181754762,
        "bleu": 66.40646,
        "rouge1": {
            "precision": 0.88786,
            "recall": 0.87334,
            "fmeasure": 0.87925
        },
        "rouge2": {
            "precision": 0.69021,
            "recall": 0.68841,
            "fmeasure": 0.68837
        },
        "rougeL": {
            "precision": 0.8079,
            "recall": 0.79423,
            "fmeasure": 0.79948
        },
        "rougeLsum": {
            "precision": 0.8079,
            "recall": 0.79423,
            "fmeasure": 0.79948
        },
        "nubia": {
            "semantic_relation": 4.78569,
            "contradiction": 0.68559,
            "irrelevancy": 6.66369,
            "logical_agreement": 92.65072,
            "grammar_ref": 5.1809,
            "grammar_hyp": 5.16124,
            "nubia_score": 0.91191
        },
        "meteor": 0.5000231972818153,
        "bleurt": 0.674,
        "bertscore": {
            "precision": 0.97212,
            "recall": 0.96981,
            "f1": 0.97092
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_297": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 1.5,
        "median_pred_length": 12.5,
        "min_pred_length": 11,
        "max_pred_length": 14,
        "distinct-1": 0.96,
        "vocab_size-1": 24,
        "unique-1": 23,
        "entropy-1": 4.5638561897747225,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": -0.12029423371771175,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.459431618637295,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "nist": 2.947931098999345,
        "bleu": 50.34604,
        "rouge1": {
            "precision": 0.59524,
            "recall": 0.85859,
            "fmeasure": 0.67874
        },
        "rouge2": {
            "precision": 0.47902,
            "recall": 0.68788,
            "fmeasure": 0.54185
        },
        "rougeL": {
            "precision": 0.59524,
            "recall": 0.85859,
            "fmeasure": 0.67874
        },
        "rougeLsum": {
            "precision": 0.59524,
            "recall": 0.85859,
            "fmeasure": 0.67874
        },
        "nubia": {
            "semantic_relation": 4.04628,
            "contradiction": 0.56934,
            "irrelevancy": 46.87521,
            "logical_agreement": 52.55546,
            "grammar_ref": 3.61093,
            "grammar_hyp": 3.55185,
            "nubia_score": 0.72038
        },
        "meteor": 0.5784080721762755,
        "bleurt": 0.38245,
        "bertscore": {
            "precision": 0.90497,
            "recall": 0.96292,
            "f1": 0.93221
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_376": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 8,
        "total_length": 153,
        "mean_pred_length": 19.125,
        "std_pred_length": 3.822221212855164,
        "median_pred_length": 19.0,
        "min_pred_length": 13,
        "max_pred_length": 26,
        "distinct-1": 0.7450980392156863,
        "vocab_size-1": 114,
        "unique-1": 102,
        "entropy-1": 6.466579225309036,
        "distinct-2": 0.9793103448275862,
        "vocab_size-2": 142,
        "unique-2": 140,
        "entropy-2": 7.133323658965553,
        "cond_entropy-2": 0.5655476677190234,
        "distinct-3": 1.0,
        "vocab_size-3": 137,
        "unique-3": 137,
        "entropy-3": 7.098032082960511,
        "cond_entropy-3": -0.03257125886343344,
        "total_length-nopunct": 137,
        "mean_pred_length-nopunct": 17.125,
        "std_pred_length-nopunct": 3.4437443284889775,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8029197080291971,
        "vocab_size-1-nopunct": 110,
        "unique-1-nopunct": 100,
        "entropy-1-nopunct": 6.503258773067346,
        "distinct-2-nopunct": 0.9767441860465116,
        "vocab_size-2-nopunct": 126,
        "unique-2-nopunct": 124,
        "entropy-2-nopunct": 6.958863786414216,
        "cond_entropy-2-nopunct": 0.48473824186738373,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 121,
        "unique-3-nopunct": 121,
        "entropy-3-nopunct": 6.918863237274603,
        "cond_entropy-3-nopunct": -0.036538501601854165,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.82,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.5666666666666667,
            "3": 0.7671232876712328
        },
        "nist": 4.265992881513589,
        "bleu": 33.49505,
        "rouge1": {
            "precision": 0.60091,
            "recall": 0.72114,
            "fmeasure": 0.6476
        },
        "rouge2": {
            "precision": 0.38874,
            "recall": 0.45935,
            "fmeasure": 0.41422
        },
        "rougeL": {
            "precision": 0.54023,
            "recall": 0.63565,
            "fmeasure": 0.57627
        },
        "rougeLsum": {
            "precision": 0.54023,
            "recall": 0.63565,
            "fmeasure": 0.57627
        },
        "nubia": {
            "semantic_relation": 3.99841,
            "contradiction": 11.72316,
            "irrelevancy": 53.41381,
            "logical_agreement": 34.86303,
            "grammar_ref": 4.8199,
            "grammar_hyp": 4.58197,
            "nubia_score": 0.6778
        },
        "meteor": 0.37524649793218295,
        "bleurt": -0.0624,
        "bertscore": {
            "precision": 0.87658,
            "recall": 0.91599,
            "f1": 0.89312
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_180": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 42,
        "total_length": 772,
        "mean_pred_length": 18.38095238095238,
        "std_pred_length": 4.659615664471649,
        "median_pred_length": 18.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.5582901554404145,
        "vocab_size-1": 431,
        "unique-1": 348,
        "entropy-1": 7.81406238647642,
        "distinct-2": 0.910958904109589,
        "vocab_size-2": 665,
        "unique-2": 617,
        "entropy-2": 9.299995019770098,
        "cond_entropy-2": 1.2954312451774177,
        "distinct-3": 0.9767441860465116,
        "vocab_size-3": 672,
        "unique-3": 657,
        "entropy-3": 9.378655906588463,
        "cond_entropy-3": 0.08031631287318372,
        "total_length-nopunct": 683,
        "mean_pred_length-nopunct": 16.261904761904763,
        "std_pred_length-nopunct": 4.094476673401004,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.623718887262079,
        "vocab_size-1-nopunct": 426,
        "unique-1-nopunct": 348,
        "entropy-1-nopunct": 8.003619997420598,
        "distinct-2-nopunct": 0.9141965678627145,
        "vocab_size-2-nopunct": 586,
        "unique-2-nopunct": 547,
        "entropy-2-nopunct": 9.115400226313305,
        "cond_entropy-2-nopunct": 1.1854160946021368,
        "distinct-3-nopunct": 0.9799666110183639,
        "vocab_size-3-nopunct": 587,
        "unique-3-nopunct": 576,
        "entropy-3-nopunct": 9.185085168578306,
        "cond_entropy-3-nopunct": 0.08265451397248884,
        "msttr-100": 0.72857,
        "msttr-100_nopunct": 0.78667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23478260869565218,
            "2": 0.5591397849462365,
            "3": 0.7995867768595041
        },
        "nist": 6.627201135130569,
        "bleu": 44.71681,
        "rouge1": {
            "precision": 0.73516,
            "recall": 0.79522,
            "fmeasure": 0.75277
        },
        "rouge2": {
            "precision": 0.52237,
            "recall": 0.56026,
            "fmeasure": 0.53279
        },
        "rougeL": {
            "precision": 0.61659,
            "recall": 0.66394,
            "fmeasure": 0.62999
        },
        "rougeLsum": {
            "precision": 0.61659,
            "recall": 0.66394,
            "fmeasure": 0.62999
        },
        "nubia": {
            "semantic_relation": 4.30326,
            "contradiction": 9.47632,
            "irrelevancy": 39.59538,
            "logical_agreement": 50.9283,
            "grammar_ref": 4.60727,
            "grammar_hyp": 4.51092,
            "nubia_score": 0.74607
        },
        "meteor": 0.4165562805948002,
        "bleurt": 0.32875,
        "bertscore": {
            "precision": 0.92745,
            "recall": 0.93893,
            "f1": 0.93222
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_378": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 7,
        "total_length": 125,
        "mean_pred_length": 17.857142857142858,
        "std_pred_length": 4.763809143009448,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 25,
        "distinct-1": 0.616,
        "vocab_size-1": 77,
        "unique-1": 60,
        "entropy-1": 5.817169954440637,
        "distinct-2": 0.8983050847457628,
        "vocab_size-2": 106,
        "unique-2": 95,
        "entropy-2": 6.672855867140108,
        "cond_entropy-2": 0.8254372672512927,
        "distinct-3": 0.9459459459459459,
        "vocab_size-3": 105,
        "unique-3": 99,
        "entropy-3": 6.686307758242012,
        "cond_entropy-3": 0.0266817134041518,
        "total_length-nopunct": 115,
        "mean_pred_length-nopunct": 16.428571428571427,
        "std_pred_length-nopunct": 4.8064582403602065,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6434782608695652,
        "vocab_size-1-nopunct": 74,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 5.767514826568338,
        "distinct-2-nopunct": 0.8888888888888888,
        "vocab_size-2-nopunct": 96,
        "unique-2-nopunct": 85,
        "entropy-2-nopunct": 6.52567558084713,
        "cond_entropy-2-nopunct": 0.8280295188217012,
        "distinct-3-nopunct": 0.9405940594059405,
        "vocab_size-3-nopunct": 95,
        "unique-3-nopunct": 89,
        "entropy-3-nopunct": 6.539399601563661,
        "cond_entropy-3-nopunct": 0.0296099954612317,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.68,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.5714285714285714,
            "3": 0.6777777777777778
        },
        "nist": 5.328153190191445,
        "bleu": 39.07773,
        "rouge1": {
            "precision": 0.74578,
            "recall": 0.71843,
            "fmeasure": 0.72813
        },
        "rouge2": {
            "precision": 0.53428,
            "recall": 0.51708,
            "fmeasure": 0.52296
        },
        "rougeL": {
            "precision": 0.64187,
            "recall": 0.62598,
            "fmeasure": 0.63121
        },
        "rougeLsum": {
            "precision": 0.64187,
            "recall": 0.62598,
            "fmeasure": 0.63121
        },
        "nubia": {
            "semantic_relation": 4.02563,
            "contradiction": 14.90899,
            "irrelevancy": 26.59707,
            "logical_agreement": 58.49394,
            "grammar_ref": 4.76973,
            "grammar_hyp": 4.76668,
            "nubia_score": 0.67558
        },
        "meteor": 0.37017910103723034,
        "bleurt": 0.12281,
        "bertscore": {
            "precision": 0.9269,
            "recall": 0.91683,
            "f1": 0.92132
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_299": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.625
        },
        "nist": 1.9931568569324174,
        "bleu": 41.11336,
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.67879,
            "fmeasure": 0.65657
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.64444,
            "fmeasure": 0.62105
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.67879,
            "fmeasure": 0.65657
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.67879,
            "fmeasure": 0.65657
        },
        "nubia": {
            "semantic_relation": 3.96063,
            "contradiction": 0.32181,
            "irrelevancy": 97.44349,
            "logical_agreement": 2.23469,
            "grammar_ref": 3.16175,
            "grammar_hyp": 3.21507,
            "nubia_score": 0.83237
        },
        "meteor": 0.3828573091235029,
        "bleurt": 0.09221,
        "bertscore": {
            "precision": 0.90096,
            "recall": 0.93977,
            "f1": 0.91996
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_45": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 79,
        "total_length": 1281,
        "mean_pred_length": 16.21518987341772,
        "std_pred_length": 5.875654310078412,
        "median_pred_length": 16.0,
        "min_pred_length": 4,
        "max_pred_length": 28,
        "distinct-1": 0.4972677595628415,
        "vocab_size-1": 637,
        "unique-1": 510,
        "entropy-1": 8.025689205194329,
        "distinct-2": 0.891846921797005,
        "vocab_size-2": 1072,
        "unique-2": 1004,
        "entropy-2": 9.934569933434522,
        "cond_entropy-2": 1.6938642131591282,
        "distinct-3": 0.9777382012466608,
        "vocab_size-3": 1098,
        "unique-3": 1076,
        "entropy-3": 10.086601996455668,
        "cond_entropy-3": 0.130550600494682,
        "total_length-nopunct": 1101,
        "mean_pred_length-nopunct": 13.936708860759493,
        "std_pred_length-nopunct": 5.3209444582607865,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5722070844686649,
        "vocab_size-1-nopunct": 630,
        "unique-1-nopunct": 508,
        "entropy-1-nopunct": 8.326886229691832,
        "distinct-2-nopunct": 0.9099804305283757,
        "vocab_size-2-nopunct": 930,
        "unique-2-nopunct": 884,
        "entropy-2-nopunct": 9.743924888702223,
        "cond_entropy-2-nopunct": 1.5124874775989847,
        "distinct-3-nopunct": 0.9809119830328739,
        "vocab_size-3-nopunct": 925,
        "unique-3-nopunct": 910,
        "entropy-3-nopunct": 9.840536375832594,
        "cond_entropy-3-nopunct": 0.11358615604524,
        "msttr-100": 0.72917,
        "msttr-100_nopunct": 0.79273,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24115755627009647,
            "2": 0.4828767123287671,
            "3": 0.7127799736495388
        },
        "nist": 6.910207345882438,
        "bleu": 40.80342,
        "rouge1": {
            "precision": 0.72051,
            "recall": 0.67307,
            "fmeasure": 0.67655
        },
        "rouge2": {
            "precision": 0.48025,
            "recall": 0.44704,
            "fmeasure": 0.44756
        },
        "rougeL": {
            "precision": 0.62236,
            "recall": 0.58693,
            "fmeasure": 0.58656
        },
        "rougeLsum": {
            "precision": 0.62236,
            "recall": 0.58693,
            "fmeasure": 0.58656
        },
        "nubia": {
            "semantic_relation": 4.02099,
            "contradiction": 11.97518,
            "irrelevancy": 37.05385,
            "logical_agreement": 50.97097,
            "grammar_ref": 4.80224,
            "grammar_hyp": 4.90222,
            "nubia_score": 0.65755
        },
        "meteor": 0.3596430996713814,
        "bleurt": 0.12491,
        "bertscore": {
            "precision": 0.91903,
            "recall": 0.91304,
            "f1": 0.91447
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_300": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 29,
        "total_length": 515,
        "mean_pred_length": 17.75862068965517,
        "std_pred_length": 4.606256408136978,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.5495145631067961,
        "vocab_size-1": 283,
        "unique-1": 220,
        "entropy-1": 7.369123747817186,
        "distinct-2": 0.9094650205761317,
        "vocab_size-2": 442,
        "unique-2": 414,
        "entropy-2": 8.705788898721272,
        "cond_entropy-2": 1.1830199012779108,
        "distinct-3": 0.9715536105032823,
        "vocab_size-3": 444,
        "unique-3": 433,
        "entropy-3": 8.77585391084732,
        "cond_entropy-3": 0.07355909755159719,
        "total_length-nopunct": 441,
        "mean_pred_length-nopunct": 15.206896551724139,
        "std_pred_length-nopunct": 3.8896796281940897,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6281179138321995,
        "vocab_size-1-nopunct": 277,
        "unique-1-nopunct": 219,
        "entropy-1-nopunct": 7.565476988391068,
        "distinct-2-nopunct": 0.9247572815533981,
        "vocab_size-2-nopunct": 381,
        "unique-2-nopunct": 361,
        "entropy-2-nopunct": 8.500405783340819,
        "cond_entropy-2-nopunct": 0.9922120239684084,
        "distinct-3-nopunct": 0.9869451697127938,
        "vocab_size-3-nopunct": 378,
        "unique-3-nopunct": 373,
        "entropy-3-nopunct": 8.555090921350507,
        "cond_entropy-3-nopunct": 0.06355393062439416,
        "msttr-100": 0.742,
        "msttr-100_nopunct": 0.7925,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.47761194029850745,
            "3": 0.8466076696165191
        },
        "nist": 6.885135322148131,
        "bleu": 55.8659,
        "rouge1": {
            "precision": 0.80235,
            "recall": 0.82094,
            "fmeasure": 0.8036
        },
        "rouge2": {
            "precision": 0.62581,
            "recall": 0.63572,
            "fmeasure": 0.62503
        },
        "rougeL": {
            "precision": 0.72956,
            "recall": 0.7393,
            "fmeasure": 0.72767
        },
        "rougeLsum": {
            "precision": 0.72956,
            "recall": 0.7393,
            "fmeasure": 0.72767
        },
        "nubia": {
            "semantic_relation": 4.34032,
            "contradiction": 7.22891,
            "irrelevancy": 29.57186,
            "logical_agreement": 63.19923,
            "grammar_ref": 4.69712,
            "grammar_hyp": 4.73425,
            "nubia_score": 0.77658
        },
        "meteor": 0.4452225866604356,
        "bleurt": 0.44236,
        "bertscore": {
            "precision": 0.94485,
            "recall": 0.95013,
            "f1": 0.94626
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_192": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 31,
        "total_length": 537,
        "mean_pred_length": 17.322580645161292,
        "std_pred_length": 6.171668341256204,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.5735567970204841,
        "vocab_size-1": 308,
        "unique-1": 251,
        "entropy-1": 7.37202699685471,
        "distinct-2": 0.9268774703557312,
        "vocab_size-2": 469,
        "unique-2": 440,
        "entropy-2": 8.817234082637128,
        "cond_entropy-2": 1.3076336807298727,
        "distinct-3": 0.9789473684210527,
        "vocab_size-3": 465,
        "unique-3": 455,
        "entropy-3": 8.849678440060346,
        "cond_entropy-3": 0.03905181901016246,
        "total_length-nopunct": 476,
        "mean_pred_length-nopunct": 15.35483870967742,
        "std_pred_length-nopunct": 5.845033111177354,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6302521008403361,
        "vocab_size-1-nopunct": 300,
        "unique-1-nopunct": 249,
        "entropy-1-nopunct": 7.498079106687884,
        "distinct-2-nopunct": 0.9235955056179775,
        "vocab_size-2-nopunct": 411,
        "unique-2-nopunct": 385,
        "entropy-2-nopunct": 8.622663092188732,
        "cond_entropy-2-nopunct": 1.2128961166362489,
        "distinct-3-nopunct": 0.9758454106280193,
        "vocab_size-3-nopunct": 404,
        "unique-3-nopunct": 394,
        "entropy-3-nopunct": 8.64517777875539,
        "cond_entropy-3-nopunct": 0.03320297507775659,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.7875,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21518987341772153,
            "2": 0.4888888888888889,
            "3": 0.676056338028169
        },
        "nist": 5.973845689990195,
        "bleu": 39.396,
        "rouge1": {
            "precision": 0.72857,
            "recall": 0.68107,
            "fmeasure": 0.69459
        },
        "rouge2": {
            "precision": 0.47922,
            "recall": 0.4454,
            "fmeasure": 0.45706
        },
        "rougeL": {
            "precision": 0.58022,
            "recall": 0.55482,
            "fmeasure": 0.56001
        },
        "rougeLsum": {
            "precision": 0.58022,
            "recall": 0.55482,
            "fmeasure": 0.56001
        },
        "nubia": {
            "semantic_relation": 4.01581,
            "contradiction": 11.49008,
            "irrelevancy": 38.96153,
            "logical_agreement": 49.54839,
            "grammar_ref": 4.61479,
            "grammar_hyp": 4.73716,
            "nubia_score": 0.66498
        },
        "meteor": 0.36047931664293614,
        "bleurt": 0.16689,
        "bertscore": {
            "precision": 0.9077,
            "recall": 0.8995,
            "f1": 0.90243
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_309": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 1.0
        },
        "nist": 3.6962282398857416,
        "bleu": 48.54918,
        "rouge1": {
            "precision": 0.80769,
            "recall": 0.95833,
            "fmeasure": 0.87478
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.61616,
            "fmeasure": 0.55072
        },
        "rougeL": {
            "precision": 0.65385,
            "recall": 0.78333,
            "fmeasure": 0.7113
        },
        "rougeLsum": {
            "precision": 0.65385,
            "recall": 0.78333,
            "fmeasure": 0.7113
        },
        "nubia": {
            "semantic_relation": 4.38432,
            "contradiction": 0.27322,
            "irrelevancy": 75.25094,
            "logical_agreement": 24.47585,
            "grammar_ref": 4.59758,
            "grammar_hyp": 3.82605,
            "nubia_score": 0.8622
        },
        "meteor": 0.4921814572635894,
        "bleurt": 0.57296,
        "bertscore": {
            "precision": 0.89241,
            "recall": 0.95665,
            "f1": 0.92341
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_301": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 1.0,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 15,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 24,
        "unique-1": 21,
        "entropy-1": 4.49468036840891,
        "distinct-2": 0.9615384615384616,
        "vocab_size-2": 25,
        "unique-2": 24,
        "entropy-2": 4.623516641218013,
        "cond_entropy-2": 0.07596508462823659,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.03214388408660255,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8846153846153846,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.440636352673264,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.501629167387823,
        "cond_entropy-2-nopunct": 0.08264309517020864,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.03462179117476821,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.375,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "nist": 4.618255147566651,
        "bleu": 58.18749,
        "rouge1": {
            "precision": 0.77381,
            "recall": 0.68029,
            "fmeasure": 0.71771
        },
        "rouge2": {
            "precision": 0.62821,
            "recall": 0.54683,
            "fmeasure": 0.58003
        },
        "rougeL": {
            "precision": 0.77381,
            "recall": 0.68029,
            "fmeasure": 0.71771
        },
        "rougeLsum": {
            "precision": 0.77381,
            "recall": 0.68029,
            "fmeasure": 0.71771
        },
        "nubia": {
            "semantic_relation": 3.50875,
            "contradiction": 50.24092,
            "irrelevancy": 5.63453,
            "logical_agreement": 44.12455,
            "grammar_ref": 4.37461,
            "grammar_hyp": 4.2538,
            "nubia_score": 0.51908
        },
        "meteor": 0.41020055124920374,
        "bleurt": 0.12861,
        "bertscore": {
            "precision": 0.92942,
            "recall": 0.9338,
            "f1": 0.9231
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_182": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 14,
        "total_length": 239,
        "mean_pred_length": 17.071428571428573,
        "std_pred_length": 5.284266210909052,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.6192468619246861,
        "vocab_size-1": 148,
        "unique-1": 119,
        "entropy-1": 6.670738333555136,
        "distinct-2": 0.9377777777777778,
        "vocab_size-2": 211,
        "unique-2": 201,
        "entropy-2": 7.6737377467533205,
        "cond_entropy-2": 0.888342740457378,
        "distinct-3": 1.0,
        "vocab_size-3": 211,
        "unique-3": 211,
        "entropy-3": 7.721099188707212,
        "cond_entropy-3": 0.05665342405093912,
        "total_length-nopunct": 211,
        "mean_pred_length-nopunct": 15.071428571428571,
        "std_pred_length-nopunct": 4.772903963510889,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6824644549763034,
        "vocab_size-1-nopunct": 144,
        "unique-1-nopunct": 119,
        "entropy-1-nopunct": 6.734122414177,
        "distinct-2-nopunct": 0.9390862944162437,
        "vocab_size-2-nopunct": 185,
        "unique-2-nopunct": 177,
        "entropy-2-nopunct": 7.482408291515594,
        "cond_entropy-2-nopunct": 0.8031979323814027,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 183,
        "unique-3-nopunct": 183,
        "entropy-3-nopunct": 7.5156998382840365,
        "cond_entropy-3-nopunct": 0.03851017732125579,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.74,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2786885245901639,
            "2": 0.5142857142857142,
            "3": 0.6918238993710691
        },
        "nist": 5.6898379096050355,
        "bleu": 43.69737,
        "rouge1": {
            "precision": 0.73313,
            "recall": 0.72376,
            "fmeasure": 0.71707
        },
        "rouge2": {
            "precision": 0.49624,
            "recall": 0.48521,
            "fmeasure": 0.48453
        },
        "rougeL": {
            "precision": 0.61803,
            "recall": 0.6148,
            "fmeasure": 0.60609
        },
        "rougeLsum": {
            "precision": 0.61803,
            "recall": 0.6148,
            "fmeasure": 0.60609
        },
        "nubia": {
            "semantic_relation": 4.02063,
            "contradiction": 8.37946,
            "irrelevancy": 44.50587,
            "logical_agreement": 47.11466,
            "grammar_ref": 4.54419,
            "grammar_hyp": 4.51636,
            "nubia_score": 0.68965
        },
        "meteor": 0.3801618617844258,
        "bleurt": 0.09733,
        "bertscore": {
            "precision": 0.92063,
            "recall": 0.91581,
            "f1": 0.9153
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_302": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 1.0
        },
        "nist": 3.7574673462380614,
        "bleu": 65.8037,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.7,
            "fmeasure": 0.65385
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "nubia": {
            "semantic_relation": 4.11383,
            "contradiction": 0.4147,
            "irrelevancy": 35.64603,
            "logical_agreement": 63.93928,
            "grammar_ref": 4.09688,
            "grammar_hyp": 3.81746,
            "nubia_score": 0.76218
        },
        "meteor": 0.9555555555555555,
        "bleurt": 0.34708,
        "bertscore": {
            "precision": 0.97544,
            "recall": 0.97544,
            "f1": 0.97544
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_46": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 50,
        "mean_pred_length": 12.5,
        "std_pred_length": 4.031128874149275,
        "median_pred_length": 12.5,
        "min_pred_length": 8,
        "max_pred_length": 17,
        "distinct-1": 0.78,
        "vocab_size-1": 39,
        "unique-1": 34,
        "entropy-1": 5.093660689688188,
        "distinct-2": 1.0,
        "vocab_size-2": 46,
        "unique-2": 46,
        "entropy-2": 5.5235619560570095,
        "cond_entropy-2": 0.30383130985461293,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.1312445332782525,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 3.640054944640259,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.041010577489155,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.247927513443589,
        "cond_entropy-2-nopunct": 0.24389660387965334,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.16046467219324617,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3076923076923077,
            "2": 0.0,
            "3": 0.8
        },
        "nist": 4.741620287585599,
        "bleu": 49.89194,
        "rouge1": {
            "precision": 0.74589,
            "recall": 0.73838,
            "fmeasure": 0.73592
        },
        "rouge2": {
            "precision": 0.57738,
            "recall": 0.57369,
            "fmeasure": 0.57062
        },
        "rougeL": {
            "precision": 0.68221,
            "recall": 0.70177,
            "fmeasure": 0.68505
        },
        "rougeLsum": {
            "precision": 0.68221,
            "recall": 0.70177,
            "fmeasure": 0.68505
        },
        "nubia": {
            "semantic_relation": 4.13872,
            "contradiction": 1.07215,
            "irrelevancy": 63.85932,
            "logical_agreement": 35.06853,
            "grammar_ref": 6.02061,
            "grammar_hyp": 5.86437,
            "nubia_score": 0.69733
        },
        "meteor": 0.43536669401972933,
        "bleurt": 0.27287,
        "bertscore": {
            "precision": 0.9422,
            "recall": 0.95402,
            "f1": 0.9475
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_304": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 6,
        "total_length": 117,
        "mean_pred_length": 19.5,
        "std_pred_length": 4.890466917040404,
        "median_pred_length": 18.0,
        "min_pred_length": 15,
        "max_pred_length": 30,
        "distinct-1": 0.6495726495726496,
        "vocab_size-1": 76,
        "unique-1": 57,
        "entropy-1": 5.922196369416321,
        "distinct-2": 0.8828828828828829,
        "vocab_size-2": 98,
        "unique-2": 86,
        "entropy-2": 6.553380843808107,
        "cond_entropy-2": 0.5427091149023505,
        "distinct-3": 0.9047619047619048,
        "vocab_size-3": 95,
        "unique-3": 85,
        "entropy-3": 6.523769327189923,
        "cond_entropy-3": -0.034885705806236164,
        "total_length-nopunct": 105,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 4.536885862938733,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6857142857142857,
        "vocab_size-1-nopunct": 72,
        "unique-1-nopunct": 55,
        "entropy-1-nopunct": 5.881617689425921,
        "distinct-2-nopunct": 0.8888888888888888,
        "vocab_size-2-nopunct": 88,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.39950927157292,
        "cond_entropy-2-nopunct": 0.5481518545655794,
        "distinct-3-nopunct": 0.9139784946236559,
        "vocab_size-3-nopunct": 85,
        "unique-3-nopunct": 77,
        "entropy-3-nopunct": 6.367115800355352,
        "cond_entropy-3-nopunct": -0.039069986367669965,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.72,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5263157894736842,
            "2": 0.625,
            "3": 0.875
        },
        "nist": 5.678749960768879,
        "bleu": 57.45176,
        "rouge1": {
            "precision": 0.7444,
            "recall": 0.8316,
            "fmeasure": 0.78166
        },
        "rouge2": {
            "precision": 0.57984,
            "recall": 0.64918,
            "fmeasure": 0.60841
        },
        "rougeL": {
            "precision": 0.67744,
            "recall": 0.75853,
            "fmeasure": 0.71199
        },
        "rougeLsum": {
            "precision": 0.67744,
            "recall": 0.75853,
            "fmeasure": 0.71199
        },
        "nubia": {
            "semantic_relation": 4.05533,
            "contradiction": 31.08629,
            "irrelevancy": 21.12771,
            "logical_agreement": 47.78599,
            "grammar_ref": 4.63046,
            "grammar_hyp": 4.17722,
            "nubia_score": 0.73389
        },
        "meteor": 0.46235751849569795,
        "bleurt": 0.22761,
        "bertscore": {
            "precision": 0.91576,
            "recall": 0.94303,
            "f1": 0.92674
        }
    },
    "web_nlg_ru_validation": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_validation",
        "N": 790,
        "total_length": 8700,
        "mean_pred_length": 11.012658227848101,
        "std_pred_length": 3.1101860861991413,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 21,
        "distinct-1": 0.17264367816091955,
        "vocab_size-1": 1502,
        "unique-1": 758,
        "entropy-1": 8.483795688716263,
        "distinct-2": 0.37825537294563844,
        "vocab_size-2": 2992,
        "unique-2": 1881,
        "entropy-2": 10.519331106051313,
        "cond_entropy-2": 2.114983074862231,
        "distinct-3": 0.515308988764045,
        "vocab_size-3": 3669,
        "unique-3": 2586,
        "entropy-3": 11.154356036928538,
        "cond_entropy-3": 0.8016935468163486,
        "total_length-nopunct": 7431,
        "mean_pred_length-nopunct": 9.40632911392405,
        "std_pred_length-nopunct": 2.6942433602199136,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.2013187996232001,
        "vocab_size-1-nopunct": 1496,
        "unique-1-nopunct": 757,
        "entropy-1-nopunct": 8.8976392899885,
        "distinct-2-nopunct": 0.4124378858605632,
        "vocab_size-2-nopunct": 2739,
        "unique-2-nopunct": 1796,
        "entropy-2-nopunct": 10.480063216871983,
        "cond_entropy-2-nopunct": 1.817663822064679,
        "distinct-3-nopunct": 0.5399077080840882,
        "vocab_size-3-nopunct": 3159,
        "unique-3-nopunct": 2284,
        "entropy-3-nopunct": 10.963503603726998,
        "cond_entropy-3-nopunct": 0.6669684462643797,
        "msttr-100": 0.5092,
        "msttr-100_nopunct": 0.54203,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_validation.json",
        "local_recall": {
            "1": 0.14543726235741444,
            "2": 0.3880985774393909,
            "3": 0.5246800731261426,
            "4": 0.7878787878787878,
            "5": 0.6538461538461539,
            "6": 1.0,
            "7": 0.875,
            "8": 0,
            "9": 1.0
        },
        "nist": 1.9310791046345235,
        "bleu": 24.28509,
        "rouge1": {
            "precision": 0.24121,
            "recall": 0.19618,
            "fmeasure": 0.20885
        },
        "rouge2": {
            "precision": 0.08772,
            "recall": 0.06154,
            "fmeasure": 0.06863
        },
        "rougeL": {
            "precision": 0.23466,
            "recall": 0.19179,
            "fmeasure": 0.20367
        },
        "rougeLsum": {
            "precision": 0.23466,
            "recall": 0.19179,
            "fmeasure": 0.20367
        },
        "nubia": {
            "semantic_relation": 3.65066,
            "contradiction": 21.66391,
            "irrelevancy": 21.90186,
            "logical_agreement": 56.43423,
            "grammar_ref": 2.60252,
            "grammar_hyp": 2.69555,
            "nubia_score": 0.71164
        },
        "meteor": 0.408151400241165,
        "bleurt": 0.10102,
        "bertscore": {
            "precision": 0.95115,
            "recall": 0.91784,
            "f1": 0.93314
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_344": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 7,
        "total_length": 120,
        "mean_pred_length": 17.142857142857142,
        "std_pred_length": 5.462301226944332,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.6916666666666667,
        "vocab_size-1": 83,
        "unique-1": 67,
        "entropy-1": 6.0430176545856265,
        "distinct-2": 0.9823008849557522,
        "vocab_size-2": 111,
        "unique-2": 109,
        "entropy-2": 6.78478073232671,
        "cond_entropy-2": 0.6213703886504296,
        "distinct-3": 1.0,
        "vocab_size-3": 106,
        "unique-3": 106,
        "entropy-3": 6.727920454563184,
        "cond_entropy-3": -0.054522658795384496,
        "total_length-nopunct": 104,
        "mean_pred_length-nopunct": 14.857142857142858,
        "std_pred_length-nopunct": 4.257046978786097,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 78,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 6.023481756661213,
        "distinct-2-nopunct": 0.9896907216494846,
        "vocab_size-2-nopunct": 96,
        "unique-2-nopunct": 95,
        "entropy-2-nopunct": 6.57929428548611,
        "cond_entropy-2-nopunct": 0.5943558868698304,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 90,
        "unique-3-nopunct": 90,
        "entropy-3-nopunct": 6.491853096329662,
        "cond_entropy-3-nopunct": -0.08583752363523099,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.38461538461538464,
            "2": 0.6296296296296297,
            "3": 0.5384615384615384
        },
        "nist": 3.8728233770868714,
        "bleu": 24.9979,
        "rouge1": {
            "precision": 0.60686,
            "recall": 0.62095,
            "fmeasure": 0.59861
        },
        "rouge2": {
            "precision": 0.3676,
            "recall": 0.39031,
            "fmeasure": 0.36481
        },
        "rougeL": {
            "precision": 0.5387,
            "recall": 0.58002,
            "fmeasure": 0.5435
        },
        "rougeLsum": {
            "precision": 0.5387,
            "recall": 0.58002,
            "fmeasure": 0.5435
        },
        "nubia": {
            "semantic_relation": 3.98451,
            "contradiction": 20.61486,
            "irrelevancy": 37.09425,
            "logical_agreement": 42.2909,
            "grammar_ref": 4.57813,
            "grammar_hyp": 4.42232,
            "nubia_score": 0.65076
        },
        "meteor": 0.31238298497582223,
        "bleurt": 0.10025,
        "bertscore": {
            "precision": 0.8988,
            "recall": 0.91029,
            "f1": 0.90277
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_245": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 20,
        "total_length": 313,
        "mean_pred_length": 15.65,
        "std_pred_length": 4.089926649709014,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.65814696485623,
        "vocab_size-1": 206,
        "unique-1": 175,
        "entropy-1": 7.1486810107336725,
        "distinct-2": 0.9658703071672355,
        "vocab_size-2": 283,
        "unique-2": 275,
        "entropy-2": 8.119671530190212,
        "cond_entropy-2": 0.7538853823446323,
        "distinct-3": 0.989010989010989,
        "vocab_size-3": 270,
        "unique-3": 267,
        "entropy-3": 8.070779118941795,
        "cond_entropy-3": -0.043391654894336724,
        "total_length-nopunct": 270,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 3.4713109915419564,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.737037037037037,
        "vocab_size-1-nopunct": 199,
        "unique-1-nopunct": 174,
        "entropy-1-nopunct": 7.2709604122966125,
        "distinct-2-nopunct": 0.964,
        "vocab_size-2-nopunct": 241,
        "unique-2-nopunct": 234,
        "entropy-2-nopunct": 7.8857842846621,
        "cond_entropy-2-nopunct": 0.6752922871458258,
        "distinct-3-nopunct": 0.9869565217391304,
        "vocab_size-3-nopunct": 227,
        "unique-3-nopunct": 224,
        "entropy-3-nopunct": 7.819403094422624,
        "cond_entropy-3-nopunct": -0.059424668500320195,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.835,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22727272727272727,
            "2": 0.48484848484848486,
            "3": 0.8106796116504854
        },
        "nist": 6.426918651804533,
        "bleu": 52.83183,
        "rouge1": {
            "precision": 0.80868,
            "recall": 0.7614,
            "fmeasure": 0.76667
        },
        "rouge2": {
            "precision": 0.62522,
            "recall": 0.58835,
            "fmeasure": 0.58989
        },
        "rougeL": {
            "precision": 0.70889,
            "recall": 0.67377,
            "fmeasure": 0.67103
        },
        "rougeLsum": {
            "precision": 0.70889,
            "recall": 0.67377,
            "fmeasure": 0.67103
        },
        "nubia": {
            "semantic_relation": 4.31965,
            "contradiction": 10.64931,
            "irrelevancy": 23.22184,
            "logical_agreement": 66.12885,
            "grammar_ref": 4.67668,
            "grammar_hyp": 4.68639,
            "nubia_score": 0.75756
        },
        "meteor": 0.4292474700736585,
        "bleurt": 0.36605,
        "bertscore": {
            "precision": 0.94322,
            "recall": 0.93748,
            "f1": 0.93619
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_380": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 8,
        "total_length": 134,
        "mean_pred_length": 16.75,
        "std_pred_length": 5.3091901453988255,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 28,
        "distinct-1": 0.7164179104477612,
        "vocab_size-1": 96,
        "unique-1": 82,
        "entropy-1": 6.244782381142022,
        "distinct-2": 0.9603174603174603,
        "vocab_size-2": 121,
        "unique-2": 117,
        "entropy-2": 6.891923673482755,
        "cond_entropy-2": 0.5433235940877361,
        "distinct-3": 1.0,
        "vocab_size-3": 118,
        "unique-3": 118,
        "entropy-3": 6.882643049361832,
        "cond_entropy-3": -0.020442912255333918,
        "total_length-nopunct": 115,
        "mean_pred_length-nopunct": 14.375,
        "std_pred_length-nopunct": 4.270172713134681,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7913043478260869,
        "vocab_size-1-nopunct": 91,
        "unique-1-nopunct": 79,
        "entropy-1-nopunct": 6.307452633718932,
        "distinct-2-nopunct": 0.9719626168224299,
        "vocab_size-2-nopunct": 104,
        "unique-2-nopunct": 102,
        "entropy-2-nopunct": 6.6783371966612926,
        "cond_entropy-2-nopunct": 0.3924200707723209,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 99,
        "unique-3-nopunct": 99,
        "entropy-3-nopunct": 6.62935662007962,
        "cond_entropy-3-nopunct": -0.04387917943099727,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.81,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11538461538461539,
            "2": 0.5,
            "3": 0.8645833333333334
        },
        "nist": 6.115257195475066,
        "bleu": 65.43138,
        "rouge1": {
            "precision": 0.89392,
            "recall": 0.83918,
            "fmeasure": 0.86275
        },
        "rouge2": {
            "precision": 0.75399,
            "recall": 0.71516,
            "fmeasure": 0.73168
        },
        "rougeL": {
            "precision": 0.77961,
            "recall": 0.73844,
            "fmeasure": 0.75602
        },
        "rougeLsum": {
            "precision": 0.77961,
            "recall": 0.73844,
            "fmeasure": 0.75602
        },
        "nubia": {
            "semantic_relation": 4.3604,
            "contradiction": 4.38346,
            "irrelevancy": 6.15039,
            "logical_agreement": 89.46614,
            "grammar_ref": 4.87577,
            "grammar_hyp": 5.11422,
            "nubia_score": 0.75417
        },
        "meteor": 0.47766776198871036,
        "bleurt": 0.41011,
        "bertscore": {
            "precision": 0.95619,
            "recall": 0.95835,
            "f1": 0.95719
        }
    },
    "web_nlg_ru_test": {
        "predictions_file": "ByT5-base (Baseline)/web_nlg_ru_test",
        "N": 1102,
        "total_length": 12506,
        "mean_pred_length": 11.348457350272232,
        "std_pred_length": 2.851145593537696,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 21,
        "distinct-1": 0.2056612825843595,
        "vocab_size-1": 2572,
        "unique-1": 1331,
        "entropy-1": 9.138715529434501,
        "distinct-2": 0.4909680813749562,
        "vocab_size-2": 5599,
        "unique-2": 3817,
        "entropy-2": 11.7273116300896,
        "cond_entropy-2": 2.6481035457550606,
        "distinct-3": 0.6877305377596583,
        "vocab_size-3": 7085,
        "unique-3": 5558,
        "entropy-3": 12.476429248272863,
        "cond_entropy-3": 0.8655010413290141,
        "total_length-nopunct": 10618,
        "mean_pred_length-nopunct": 9.635208711433757,
        "std_pred_length-nopunct": 2.4806609355064437,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.2414767376153701,
        "vocab_size-1-nopunct": 2564,
        "unique-1-nopunct": 1331,
        "entropy-1-nopunct": 9.684760081195833,
        "distinct-2-nopunct": 0.5420344682639765,
        "vocab_size-2-nopunct": 5158,
        "unique-2-nopunct": 3698,
        "entropy-2-nopunct": 11.698609225215433,
        "cond_entropy-2-nopunct": 2.2258100660527513,
        "distinct-3-nopunct": 0.7207035892560019,
        "vocab_size-3-nopunct": 6064,
        "unique-3-nopunct": 4927,
        "entropy-3-nopunct": 12.272495045481174,
        "cond_entropy-3-nopunct": 0.7070456839169372,
        "msttr-100": 0.77656,
        "msttr-100_nopunct": 0.85047,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.16494183141817143,
            "2": 0.3583321865969451,
            "3": 0.5030789326366859,
            "4": 0.7012987012987013,
            "5": 0.7567567567567568,
            "6": 0.8461538461538461,
            "7": 1.0
        },
        "nist": 1.7599464245830725,
        "bleu": 22.57755,
        "rouge1": {
            "precision": 0.28647,
            "recall": 0.23479,
            "fmeasure": 0.2494
        },
        "rouge2": {
            "precision": 0.13336,
            "recall": 0.10444,
            "fmeasure": 0.11193
        },
        "rougeL": {
            "precision": 0.27918,
            "recall": 0.2285,
            "fmeasure": 0.24273
        },
        "rougeLsum": {
            "precision": 0.27918,
            "recall": 0.2285,
            "fmeasure": 0.24273
        },
        "nubia": {
            "semantic_relation": 3.60761,
            "contradiction": 21.64157,
            "irrelevancy": 22.54,
            "logical_agreement": 55.81843,
            "grammar_ref": 2.65213,
            "grammar_hyp": 2.72938,
            "nubia_score": 0.70003
        },
        "meteor": 0.40365395426991457,
        "bleurt": 0.10381,
        "bertscore": {
            "precision": 0.95101,
            "recall": 0.91453,
            "f1": 0.93153
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_194": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.2776134368191165,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.04089198233393867,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5
        },
        "nist": 1.414491628691261,
        "bleu": 4.67255,
        "rouge1": {
            "precision": 0.4,
            "recall": 0.33333,
            "fmeasure": 0.36364
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.3,
            "recall": 0.25,
            "fmeasure": 0.27273
        },
        "rougeLsum": {
            "precision": 0.3,
            "recall": 0.25,
            "fmeasure": 0.27273
        },
        "nubia": {
            "semantic_relation": 2.76826,
            "contradiction": 2.2626,
            "irrelevancy": 97.6269,
            "logical_agreement": 0.1105,
            "grammar_ref": 3.85254,
            "grammar_hyp": 5.2443,
            "nubia_score": 0.20035
        },
        "meteor": 0.2483341037027653,
        "bleurt": -0.68525,
        "bertscore": {
            "precision": 0.84894,
            "recall": 0.85245,
            "f1": 0.85069
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_413": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666
        },
        "nist": 1.623963756721793,
        "bleu": 10.55267,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.47222,
            "fmeasure": 0.45752
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.13393,
            "fmeasure": 0.12917
        },
        "rougeL": {
            "precision": 0.38889,
            "recall": 0.41667,
            "fmeasure": 0.40196
        },
        "rougeLsum": {
            "precision": 0.38889,
            "recall": 0.41667,
            "fmeasure": 0.40196
        },
        "nubia": {
            "semantic_relation": 3.91139,
            "contradiction": 64.52236,
            "irrelevancy": 23.44226,
            "logical_agreement": 12.03538,
            "grammar_ref": 6.12307,
            "grammar_hyp": 6.22463,
            "nubia_score": 0.43118
        },
        "meteor": 0.23932831540551672,
        "bleurt": 0.08011,
        "bertscore": {
            "precision": 0.81319,
            "recall": 0.80802,
            "f1": 0.81059
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_152": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 24,
        "total_length": 353,
        "mean_pred_length": 14.708333333333334,
        "std_pred_length": 5.02061721526569,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.6005665722379604,
        "vocab_size-1": 212,
        "unique-1": 179,
        "entropy-1": 6.988402132300843,
        "distinct-2": 0.9361702127659575,
        "vocab_size-2": 308,
        "unique-2": 292,
        "entropy-2": 8.218723665897071,
        "cond_entropy-2": 1.0034638854684634,
        "distinct-3": 0.9868852459016394,
        "vocab_size-3": 301,
        "unique-3": 297,
        "entropy-3": 8.226435924253481,
        "cond_entropy-3": 0.012424660284724354,
        "total_length-nopunct": 306,
        "mean_pred_length-nopunct": 12.75,
        "std_pred_length-nopunct": 4.4464405239847,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6797385620915033,
        "vocab_size-1-nopunct": 208,
        "unique-1-nopunct": 179,
        "entropy-1-nopunct": 7.148387667004761,
        "distinct-2-nopunct": 0.9397163120567376,
        "vocab_size-2-nopunct": 265,
        "unique-2-nopunct": 253,
        "entropy-2-nopunct": 8.000830020913853,
        "cond_entropy-2-nopunct": 0.9208610635602291,
        "distinct-3-nopunct": 0.9844961240310077,
        "vocab_size-3-nopunct": 254,
        "unique-3-nopunct": 250,
        "entropy-3-nopunct": 7.980219503485237,
        "cond_entropy-3-nopunct": -0.015458145507462833,
        "msttr-100": 0.71333,
        "msttr-100_nopunct": 0.76333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1276595744680851,
            "2": 0.3023255813953488,
            "3": 0.7552742616033755
        },
        "nist": 5.7027731662930226,
        "bleu": 40.63466,
        "rouge1": {
            "precision": 0.7474,
            "recall": 0.69052,
            "fmeasure": 0.70884
        },
        "rouge2": {
            "precision": 0.48317,
            "recall": 0.44954,
            "fmeasure": 0.45964
        },
        "rougeL": {
            "precision": 0.68482,
            "recall": 0.63026,
            "fmeasure": 0.6485
        },
        "rougeLsum": {
            "precision": 0.68482,
            "recall": 0.63026,
            "fmeasure": 0.6485
        },
        "nubia": {
            "semantic_relation": 4.24501,
            "contradiction": 9.36363,
            "irrelevancy": 27.21851,
            "logical_agreement": 63.41786,
            "grammar_ref": 4.6818,
            "grammar_hyp": 4.85297,
            "nubia_score": 0.72717
        },
        "meteor": 0.36096792625209606,
        "bleurt": 0.23425,
        "bertscore": {
            "precision": 0.92671,
            "recall": 0.91709,
            "f1": 0.92037
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_570": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.25,
            "3": 0.8888888888888888
        },
        "nist": 5.009956335533093,
        "bleu": 62.38986,
        "rouge1": {
            "precision": 0.86111,
            "recall": 0.7381,
            "fmeasure": 0.79487
        },
        "rouge2": {
            "precision": 0.63636,
            "recall": 0.53846,
            "fmeasure": 0.58333
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.61905,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.61905,
            "fmeasure": 0.66667
        },
        "nubia": {
            "semantic_relation": 4.49643,
            "contradiction": 0.15683,
            "irrelevancy": 0.59311,
            "logical_agreement": 99.25006,
            "grammar_ref": 5.70189,
            "grammar_hyp": 5.07596,
            "nubia_score": 0.89535
        },
        "meteor": 0.408268404006417,
        "bleurt": 0.40705,
        "bertscore": {
            "precision": 0.95272,
            "recall": 0.93435,
            "f1": 0.94345
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_195": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 15,
        "total_length": 224,
        "mean_pred_length": 14.933333333333334,
        "std_pred_length": 5.234076380370806,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.6473214285714286,
        "vocab_size-1": 145,
        "unique-1": 120,
        "entropy-1": 6.623345483812913,
        "distinct-2": 0.937799043062201,
        "vocab_size-2": 196,
        "unique-2": 185,
        "entropy-2": 7.575733414356848,
        "cond_entropy-2": 0.8071937929258874,
        "distinct-3": 0.9742268041237113,
        "vocab_size-3": 189,
        "unique-3": 185,
        "entropy-3": 7.544475277742961,
        "cond_entropy-3": -0.05589989814117771,
        "total_length-nopunct": 196,
        "mean_pred_length-nopunct": 13.066666666666666,
        "std_pred_length-nopunct": 4.753478258660237,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7244897959183674,
        "vocab_size-1-nopunct": 142,
        "unique-1-nopunct": 120,
        "entropy-1-nopunct": 6.7507406588082866,
        "distinct-2-nopunct": 0.9558011049723757,
        "vocab_size-2-nopunct": 173,
        "unique-2-nopunct": 166,
        "entropy-2-nopunct": 7.407277447844704,
        "cond_entropy-2-nopunct": 0.6843529507822801,
        "distinct-3-nopunct": 0.9819277108433735,
        "vocab_size-3-nopunct": 163,
        "unique-3-nopunct": 160,
        "entropy-3-nopunct": 7.338894853033655,
        "cond_entropy-3-nopunct": -0.0886618774230276,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.82,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.09615384615384616,
            "2": 0.3409090909090909,
            "3": 0.7070063694267515
        },
        "nist": 5.018773824210335,
        "bleu": 39.83736,
        "rouge1": {
            "precision": 0.73678,
            "recall": 0.67236,
            "fmeasure": 0.69186
        },
        "rouge2": {
            "precision": 0.46074,
            "recall": 0.44245,
            "fmeasure": 0.44654
        },
        "rougeL": {
            "precision": 0.63781,
            "recall": 0.58082,
            "fmeasure": 0.59892
        },
        "rougeLsum": {
            "precision": 0.63781,
            "recall": 0.58082,
            "fmeasure": 0.59892
        },
        "nubia": {
            "semantic_relation": 4.27607,
            "contradiction": 0.76291,
            "irrelevancy": 44.18288,
            "logical_agreement": 55.0542,
            "grammar_ref": 4.60593,
            "grammar_hyp": 4.87382,
            "nubia_score": 0.71641
        },
        "meteor": 0.34885276255753783,
        "bleurt": 0.20949,
        "bertscore": {
            "precision": 0.91387,
            "recall": 0.90862,
            "f1": 0.91082
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_382": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.04978793508525296,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.1986532337201607,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20913,
            "irrelevancy": 0.49456,
            "logical_agreement": 99.29631,
            "grammar_ref": 4.69221,
            "grammar_hyp": 4.84818,
            "nubia_score": 0.99204
        },
        "meteor": 1.0,
        "bleurt": 0.99035,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_310": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 14,
        "total_length": 216,
        "mean_pred_length": 15.428571428571429,
        "std_pred_length": 4.254649317667266,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.6203703703703703,
        "vocab_size-1": 134,
        "unique-1": 107,
        "entropy-1": 6.541682856763099,
        "distinct-2": 0.9108910891089109,
        "vocab_size-2": 184,
        "unique-2": 169,
        "entropy-2": 7.466355604028186,
        "cond_entropy-2": 0.7448801538334213,
        "distinct-3": 0.9627659574468085,
        "vocab_size-3": 181,
        "unique-3": 174,
        "entropy-3": 7.480120766571275,
        "cond_entropy-3": 0.028052302447988814,
        "total_length-nopunct": 186,
        "mean_pred_length-nopunct": 13.285714285714286,
        "std_pred_length-nopunct": 3.4934340744678525,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6989247311827957,
        "vocab_size-1-nopunct": 130,
        "unique-1-nopunct": 106,
        "entropy-1-nopunct": 6.673702913329252,
        "distinct-2-nopunct": 0.9127906976744186,
        "vocab_size-2-nopunct": 157,
        "unique-2-nopunct": 145,
        "entropy-2-nopunct": 7.235829362247629,
        "cond_entropy-2-nopunct": 0.6209426266446003,
        "distinct-3-nopunct": 0.9683544303797469,
        "vocab_size-3-nopunct": 153,
        "unique-3-nopunct": 148,
        "entropy-3-nopunct": 7.240489608936612,
        "cond_entropy-3-nopunct": 0.01520515488110283,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.79,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.4375,
            "3": 0.8525641025641025
        },
        "nist": 6.101593767690059,
        "bleu": 58.3781,
        "rouge1": {
            "precision": 0.81568,
            "recall": 0.82213,
            "fmeasure": 0.81125
        },
        "rouge2": {
            "precision": 0.64559,
            "recall": 0.64556,
            "fmeasure": 0.64095
        },
        "rougeL": {
            "precision": 0.67631,
            "recall": 0.67626,
            "fmeasure": 0.66972
        },
        "rougeLsum": {
            "precision": 0.67631,
            "recall": 0.67626,
            "fmeasure": 0.66972
        },
        "nubia": {
            "semantic_relation": 4.34501,
            "contradiction": 5.65885,
            "irrelevancy": 23.66601,
            "logical_agreement": 70.67514,
            "grammar_ref": 4.89936,
            "grammar_hyp": 4.98775,
            "nubia_score": 0.74604
        },
        "meteor": 0.4509060135627331,
        "bleurt": 0.40522,
        "bertscore": {
            "precision": 0.94491,
            "recall": 0.93334,
            "f1": 0.93806
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_345": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 8,
        "total_length": 108,
        "mean_pred_length": 13.5,
        "std_pred_length": 4.06201920231798,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.5370370370370371,
        "vocab_size-1": 58,
        "unique-1": 39,
        "entropy-1": 5.472447747867002,
        "distinct-2": 0.76,
        "vocab_size-2": 76,
        "unique-2": 65,
        "entropy-2": 6.027759785030367,
        "cond_entropy-2": 0.41790721750706716,
        "distinct-3": 0.8043478260869565,
        "vocab_size-3": 74,
        "unique-3": 66,
        "entropy-3": 6.023561956057024,
        "cond_entropy-3": 0.027636641004427503,
        "total_length-nopunct": 97,
        "mean_pred_length-nopunct": 12.125,
        "std_pred_length-nopunct": 3.6206870894900596,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.5773195876288659,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.468483914745334,
        "distinct-2-nopunct": 0.7415730337078652,
        "vocab_size-2-nopunct": 66,
        "unique-2-nopunct": 56,
        "entropy-2-nopunct": 5.805962189680599,
        "cond_entropy-2-nopunct": 0.3906187617290483,
        "distinct-3-nopunct": 0.7901234567901234,
        "vocab_size-3-nopunct": 64,
        "unique-3-nopunct": 57,
        "entropy-3-nopunct": 5.796640126341408,
        "cond_entropy-3-nopunct": 0.03213682468905184,
        "msttr-100": 0.57,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.9012345679012346
        },
        "nist": 5.305916316310318,
        "bleu": 64.91642,
        "rouge1": {
            "precision": 0.83835,
            "recall": 0.8568,
            "fmeasure": 0.84043
        },
        "rouge2": {
            "precision": 0.73408,
            "recall": 0.73016,
            "fmeasure": 0.72768
        },
        "rougeL": {
            "precision": 0.79092,
            "recall": 0.8082,
            "fmeasure": 0.79266
        },
        "rougeLsum": {
            "precision": 0.79092,
            "recall": 0.8082,
            "fmeasure": 0.79266
        },
        "nubia": {
            "semantic_relation": 4.48829,
            "contradiction": 0.88635,
            "irrelevancy": 20.30102,
            "logical_agreement": 78.81263,
            "grammar_ref": 5.07225,
            "grammar_hyp": 5.04283,
            "nubia_score": 0.85744
        },
        "meteor": 0.4855161019039483,
        "bleurt": 0.59248,
        "bertscore": {
            "precision": 0.94876,
            "recall": 0.95692,
            "f1": 0.95228
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_196": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 18,
        "total_length": 277,
        "mean_pred_length": 15.38888888888889,
        "std_pred_length": 4.8090064680634965,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.5992779783393501,
        "vocab_size-1": 166,
        "unique-1": 131,
        "entropy-1": 6.774099434449056,
        "distinct-2": 0.9034749034749034,
        "vocab_size-2": 234,
        "unique-2": 218,
        "entropy-2": 7.778771668171453,
        "cond_entropy-2": 0.8217637428635534,
        "distinct-3": 0.9543568464730291,
        "vocab_size-3": 230,
        "unique-3": 221,
        "entropy-3": 7.813304273989328,
        "cond_entropy-3": 0.04816189690192746,
        "total_length-nopunct": 243,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 4.362084109434134,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6625514403292181,
        "vocab_size-1-nopunct": 161,
        "unique-1-nopunct": 130,
        "entropy-1-nopunct": 6.877180329353373,
        "distinct-2-nopunct": 0.8933333333333333,
        "vocab_size-2-nopunct": 201,
        "unique-2-nopunct": 186,
        "entropy-2-nopunct": 7.548663482530764,
        "cond_entropy-2-nopunct": 0.7375159493398323,
        "distinct-3-nopunct": 0.9516908212560387,
        "vocab_size-3-nopunct": 197,
        "unique-3-nopunct": 189,
        "entropy-3-nopunct": 7.587206764262586,
        "cond_entropy-3-nopunct": 0.05676607765621706,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.79,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2692307692307692,
            "2": 0.4482758620689655,
            "3": 0.7663043478260869
        },
        "nist": 5.393152270455767,
        "bleu": 31.66371,
        "rouge1": {
            "precision": 0.7411,
            "recall": 0.73796,
            "fmeasure": 0.72903
        },
        "rouge2": {
            "precision": 0.45866,
            "recall": 0.47482,
            "fmeasure": 0.45908
        },
        "rougeL": {
            "precision": 0.62391,
            "recall": 0.64271,
            "fmeasure": 0.62239
        },
        "rougeLsum": {
            "precision": 0.62391,
            "recall": 0.64271,
            "fmeasure": 0.62239
        },
        "nubia": {
            "semantic_relation": 4.23383,
            "contradiction": 3.91629,
            "irrelevancy": 26.9169,
            "logical_agreement": 69.16681,
            "grammar_ref": 4.68102,
            "grammar_hyp": 4.5903,
            "nubia_score": 0.73149
        },
        "meteor": 0.37393816869581875,
        "bleurt": 0.25045,
        "bertscore": {
            "precision": 0.91372,
            "recall": 0.91936,
            "f1": 0.91573
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_348": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 42,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.08248290463863,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 19,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 36,
        "unique-1": 33,
        "entropy-1": 5.052682601195657,
        "distinct-2": 1.0,
        "vocab_size-2": 39,
        "unique-2": 39,
        "entropy-2": 5.285402218862247,
        "cond_entropy-2": 0.13692518080981989,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.1154772174199358,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.7416573867739413,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.03784479304888,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.018556617981700586,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.13750352374993471,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.625,
            "3": 0.9333333333333333
        },
        "nist": 4.110991091151693,
        "bleu": 44.76184,
        "rouge1": {
            "precision": 0.68687,
            "recall": 0.67287,
            "fmeasure": 0.67411
        },
        "rouge2": {
            "precision": 0.36569,
            "recall": 0.39444,
            "fmeasure": 0.37917
        },
        "rougeL": {
            "precision": 0.62626,
            "recall": 0.61227,
            "fmeasure": 0.6135
        },
        "rougeLsum": {
            "precision": 0.62626,
            "recall": 0.61227,
            "fmeasure": 0.6135
        },
        "nubia": {
            "semantic_relation": 4.01353,
            "contradiction": 0.15912,
            "irrelevancy": 43.85892,
            "logical_agreement": 55.98197,
            "grammar_ref": 4.86076,
            "grammar_hyp": 5.28069,
            "nubia_score": 0.65041
        },
        "meteor": 0.411943810975762,
        "bleurt": 0.3542,
        "bertscore": {
            "precision": 0.91894,
            "recall": 0.92131,
            "f1": 0.9199
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_312": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 14,
        "total_length": 233,
        "mean_pred_length": 16.642857142857142,
        "std_pred_length": 3.791101288490171,
        "median_pred_length": 16.5,
        "min_pred_length": 11,
        "max_pred_length": 26,
        "distinct-1": 0.6523605150214592,
        "vocab_size-1": 152,
        "unique-1": 131,
        "entropy-1": 6.633216480166987,
        "distinct-2": 0.958904109589041,
        "vocab_size-2": 210,
        "unique-2": 202,
        "entropy-2": 7.689148303883541,
        "cond_entropy-2": 0.8943076091546077,
        "distinct-3": 1.0,
        "vocab_size-3": 205,
        "unique-3": 205,
        "entropy-3": 7.679480099505431,
        "cond_entropy-3": -0.003819703987612974,
        "total_length-nopunct": 209,
        "mean_pred_length-nopunct": 14.928571428571429,
        "std_pred_length-nopunct": 3.899895341348199,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7081339712918661,
        "vocab_size-1-nopunct": 148,
        "unique-1-nopunct": 129,
        "entropy-1-nopunct": 6.7017089384123345,
        "distinct-2-nopunct": 0.958974358974359,
        "vocab_size-2-nopunct": 187,
        "unique-2-nopunct": 180,
        "entropy-2-nopunct": 7.521407813738552,
        "cond_entropy-2-nopunct": 0.8605736356060995,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 181,
        "unique-3-nopunct": 181,
        "entropy-3-nopunct": 7.499845887083174,
        "cond_entropy-3-nopunct": -0.01491598742793322,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.8,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.10344827586206896,
            "2": 0.3953488372093023,
            "3": 0.8175182481751825
        },
        "nist": 5.749516471252879,
        "bleu": 45.02036,
        "rouge1": {
            "precision": 0.71168,
            "recall": 0.70956,
            "fmeasure": 0.70218
        },
        "rouge2": {
            "precision": 0.47413,
            "recall": 0.50191,
            "fmeasure": 0.48266
        },
        "rougeL": {
            "precision": 0.62892,
            "recall": 0.63717,
            "fmeasure": 0.62644
        },
        "rougeLsum": {
            "precision": 0.62892,
            "recall": 0.63717,
            "fmeasure": 0.62644
        },
        "nubia": {
            "semantic_relation": 4.02157,
            "contradiction": 12.07244,
            "irrelevancy": 19.71761,
            "logical_agreement": 68.20995,
            "grammar_ref": 4.5978,
            "grammar_hyp": 4.34328,
            "nubia_score": 0.71945
        },
        "meteor": 0.3828454766055982,
        "bleurt": 0.24143,
        "bertscore": {
            "precision": 0.9202,
            "recall": 0.9164,
            "f1": 0.91651
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_198": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 18,
        "total_length": 298,
        "mean_pred_length": 16.555555555555557,
        "std_pred_length": 6.238075043385867,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.6308724832214765,
        "vocab_size-1": 188,
        "unique-1": 158,
        "entropy-1": 6.948923226639135,
        "distinct-2": 0.9607142857142857,
        "vocab_size-2": 269,
        "unique-2": 259,
        "entropy-2": 8.04801556158011,
        "cond_entropy-2": 0.9680691880358167,
        "distinct-3": 0.9847328244274809,
        "vocab_size-3": 258,
        "unique-3": 254,
        "entropy-3": 8.002888650392444,
        "cond_entropy-3": -0.03954365089544176,
        "total_length-nopunct": 272,
        "mean_pred_length-nopunct": 15.11111111111111,
        "std_pred_length-nopunct": 6.288339198591566,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6727941176470589,
        "vocab_size-1-nopunct": 183,
        "unique-1-nopunct": 155,
        "entropy-1-nopunct": 6.996651063171419,
        "distinct-2-nopunct": 0.9566929133858267,
        "vocab_size-2-nopunct": 243,
        "unique-2-nopunct": 233,
        "entropy-2-nopunct": 7.89909851550377,
        "cond_entropy-2-nopunct": 0.9512139267102555,
        "distinct-3-nopunct": 0.9830508474576272,
        "vocab_size-3-nopunct": 232,
        "unique-3-nopunct": 228,
        "entropy-3-nopunct": 7.848744744277071,
        "cond_entropy-3-nopunct": -0.0435209276553946,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.735,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22058823529411764,
            "2": 0.5774647887323944,
            "3": 0.6881720430107527
        },
        "nist": 5.647472019327342,
        "bleu": 34.88363,
        "rouge1": {
            "precision": 0.72246,
            "recall": 0.66888,
            "fmeasure": 0.68554
        },
        "rouge2": {
            "precision": 0.44662,
            "recall": 0.41883,
            "fmeasure": 0.42559
        },
        "rougeL": {
            "precision": 0.6122,
            "recall": 0.57733,
            "fmeasure": 0.58656
        },
        "rougeLsum": {
            "precision": 0.6122,
            "recall": 0.57733,
            "fmeasure": 0.58656
        },
        "nubia": {
            "semantic_relation": 3.83788,
            "contradiction": 14.07884,
            "irrelevancy": 37.20402,
            "logical_agreement": 48.71715,
            "grammar_ref": 4.71491,
            "grammar_hyp": 4.73014,
            "nubia_score": 0.60746
        },
        "meteor": 0.350442949198747,
        "bleurt": 0.02915,
        "bertscore": {
            "precision": 0.91208,
            "recall": 0.90722,
            "f1": 0.90703
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_315": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 13,
        "total_length": 229,
        "mean_pred_length": 17.615384615384617,
        "std_pred_length": 5.181898397876704,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.6157205240174672,
        "vocab_size-1": 141,
        "unique-1": 111,
        "entropy-1": 6.608922071246458,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 204,
        "unique-2": 194,
        "entropy-2": 7.634517131793093,
        "cond_entropy-2": 0.9004752101318374,
        "distinct-3": 0.9802955665024631,
        "vocab_size-3": 199,
        "unique-3": 195,
        "entropy-3": 7.625927050190108,
        "cond_entropy-3": -0.020586067736913082,
        "total_length-nopunct": 204,
        "mean_pred_length-nopunct": 15.692307692307692,
        "std_pred_length-nopunct": 4.905014943670726,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6715686274509803,
        "vocab_size-1-nopunct": 137,
        "unique-1-nopunct": 109,
        "entropy-1-nopunct": 6.688791933417097,
        "distinct-2-nopunct": 0.9476439790575916,
        "vocab_size-2-nopunct": 181,
        "unique-2-nopunct": 173,
        "entropy-2-nopunct": 7.46224558196245,
        "cond_entropy-2-nopunct": 0.8037533046249732,
        "distinct-3-nopunct": 0.9831460674157303,
        "vocab_size-3-nopunct": 175,
        "unique-3-nopunct": 172,
        "entropy-3-nopunct": 7.442025565797832,
        "cond_entropy-3-nopunct": -0.039897644260362,
        "msttr-100": 0.685,
        "msttr-100_nopunct": 0.735,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16901408450704225,
            "2": 0.49056603773584906,
            "3": 0.746031746031746
        },
        "nist": 5.185703904396265,
        "bleu": 37.25142,
        "rouge1": {
            "precision": 0.67018,
            "recall": 0.68712,
            "fmeasure": 0.66776
        },
        "rouge2": {
            "precision": 0.38543,
            "recall": 0.41431,
            "fmeasure": 0.39204
        },
        "rougeL": {
            "precision": 0.52422,
            "recall": 0.55816,
            "fmeasure": 0.53234
        },
        "rougeLsum": {
            "precision": 0.52422,
            "recall": 0.55816,
            "fmeasure": 0.53234
        },
        "nubia": {
            "semantic_relation": 3.62318,
            "contradiction": 36.47046,
            "irrelevancy": 51.89994,
            "logical_agreement": 11.6296,
            "grammar_ref": 4.70766,
            "grammar_hyp": 4.34252,
            "nubia_score": 0.56937
        },
        "meteor": 0.35443710475605716,
        "bleurt": 0.00766,
        "bertscore": {
            "precision": 0.89755,
            "recall": 0.90259,
            "f1": 0.89772
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_574": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.1365257343456969,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966058,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "nist": 2.44757307218722,
        "bleu": 26.97857,
        "rouge1": {
            "precision": 0.52941,
            "recall": 0.73077,
            "fmeasure": 0.61379
        },
        "rouge2": {
            "precision": 0.35417,
            "recall": 0.50253,
            "fmeasure": 0.41534
        },
        "rougeL": {
            "precision": 0.52941,
            "recall": 0.73077,
            "fmeasure": 0.61379
        },
        "rougeLsum": {
            "precision": 0.52941,
            "recall": 0.73077,
            "fmeasure": 0.61379
        },
        "nubia": {
            "semantic_relation": 4.86055,
            "contradiction": 0.25033,
            "irrelevancy": 66.45772,
            "logical_agreement": 33.29194,
            "grammar_ref": 5.03839,
            "grammar_hyp": 4.79097,
            "nubia_score": 0.89927
        },
        "meteor": 0.40594071194398795,
        "bleurt": 0.40042,
        "bertscore": {
            "precision": 0.91173,
            "recall": 0.93527,
            "f1": 0.92335
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_384": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 9,
        "total_length": 167,
        "mean_pred_length": 18.555555555555557,
        "std_pred_length": 6.5508457657705215,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.6766467065868264,
        "vocab_size-1": 113,
        "unique-1": 96,
        "entropy-1": 6.371634940639197,
        "distinct-2": 0.9683544303797469,
        "vocab_size-2": 153,
        "unique-2": 148,
        "entropy-2": 7.2404896089366115,
        "cond_entropy-2": 0.745938840155189,
        "distinct-3": 0.9932885906040269,
        "vocab_size-3": 148,
        "unique-3": 147,
        "entropy-3": 7.2057457016702235,
        "cond_entropy-3": -0.03092095254715614,
        "total_length-nopunct": 153,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 6.411794687223781,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7254901960784313,
        "vocab_size-1-nopunct": 111,
        "unique-1-nopunct": 96,
        "entropy-1-nopunct": 6.415057017405048,
        "distinct-2-nopunct": 0.9652777777777778,
        "vocab_size-2-nopunct": 139,
        "unique-2-nopunct": 134,
        "entropy-2-nopunct": 7.100480556997886,
        "cond_entropy-2-nopunct": 0.7311247717288347,
        "distinct-3-nopunct": 0.9925925925925926,
        "vocab_size-3-nopunct": 134,
        "unique-3-nopunct": 133,
        "entropy-3-nopunct": 7.0620007822360416,
        "cond_entropy-3-nopunct": -0.03385014513222259,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.73,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18867924528301888,
            "2": 0.40816326530612246,
            "3": 0.7464788732394366
        },
        "nist": 4.51475475911875,
        "bleu": 31.2982,
        "rouge1": {
            "precision": 0.60588,
            "recall": 0.58924,
            "fmeasure": 0.58998
        },
        "rouge2": {
            "precision": 0.35058,
            "recall": 0.35849,
            "fmeasure": 0.34687
        },
        "rougeL": {
            "precision": 0.52121,
            "recall": 0.51664,
            "fmeasure": 0.50986
        },
        "rougeLsum": {
            "precision": 0.52121,
            "recall": 0.51664,
            "fmeasure": 0.50986
        },
        "nubia": {
            "semantic_relation": 3.57398,
            "contradiction": 15.04198,
            "irrelevancy": 36.08462,
            "logical_agreement": 48.87341,
            "grammar_ref": 4.84583,
            "grammar_hyp": 5.10268,
            "nubia_score": 0.53139
        },
        "meteor": 0.33043612325150595,
        "bleurt": 0.02158,
        "bertscore": {
            "precision": 0.89652,
            "recall": 0.88757,
            "f1": 0.88992
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_350": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 7,
        "total_length": 100,
        "mean_pred_length": 14.285714285714286,
        "std_pred_length": 4.3985155195259,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.78,
        "vocab_size-1": 78,
        "unique-1": 69,
        "entropy-1": 6.051014064623293,
        "distinct-2": 0.989247311827957,
        "vocab_size-2": 92,
        "unique-2": 91,
        "entropy-2": 6.51765343476395,
        "cond_entropy-2": 0.31669482574294294,
        "distinct-3": 1.0,
        "vocab_size-3": 86,
        "unique-3": 86,
        "entropy-3": 6.426264754702099,
        "cond_entropy-3": -0.08963824245244507,
        "total_length-nopunct": 87,
        "mean_pred_length-nopunct": 12.428571428571429,
        "std_pred_length-nopunct": 3.5799897388976194,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8620689655172413,
        "vocab_size-1-nopunct": 75,
        "unique-1-nopunct": 68,
        "entropy-1-nopunct": 6.1180623176132025,
        "distinct-2-nopunct": 0.9875,
        "vocab_size-2-nopunct": 79,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.296928094887357,
        "cond_entropy-2-nopunct": 0.2072928803697639,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 73,
        "entropy-3-nopunct": 6.189824558880028,
        "cond_entropy-3-nopunct": -0.10470627573337266,
        "msttr-100": 0.78,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3157894736842105,
            "2": 0.4375,
            "3": 0.7721518987341772
        },
        "nist": 5.39095284436679,
        "bleu": 51.92071,
        "rouge1": {
            "precision": 0.80526,
            "recall": 0.78081,
            "fmeasure": 0.76613
        },
        "rouge2": {
            "precision": 0.63106,
            "recall": 0.62895,
            "fmeasure": 0.60925
        },
        "rougeL": {
            "precision": 0.70779,
            "recall": 0.71755,
            "fmeasure": 0.69367
        },
        "rougeLsum": {
            "precision": 0.70779,
            "recall": 0.71755,
            "fmeasure": 0.69367
        },
        "nubia": {
            "semantic_relation": 4.03828,
            "contradiction": 11.76618,
            "irrelevancy": 29.88417,
            "logical_agreement": 58.34966,
            "grammar_ref": 4.69419,
            "grammar_hyp": 4.65808,
            "nubia_score": 0.66854
        },
        "meteor": 0.4113298547083687,
        "bleurt": 0.3428,
        "bertscore": {
            "precision": 0.95006,
            "recall": 0.93721,
            "f1": 0.94097
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_200": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 25,
        "total_length": 414,
        "mean_pred_length": 16.56,
        "std_pred_length": 5.810886335147161,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.6135265700483091,
        "vocab_size-1": 254,
        "unique-1": 220,
        "entropy-1": 7.232449168240027,
        "distinct-2": 0.9151670951156813,
        "vocab_size-2": 356,
        "unique-2": 338,
        "entropy-2": 8.382081847640816,
        "cond_entropy-2": 1.0213226095645787,
        "distinct-3": 0.9807692307692307,
        "vocab_size-3": 357,
        "unique-3": 351,
        "entropy-3": 8.467259234972971,
        "cond_entropy-3": 0.10039335555651659,
        "total_length-nopunct": 367,
        "mean_pred_length-nopunct": 14.68,
        "std_pred_length-nopunct": 5.497053756331659,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6784741144414169,
        "vocab_size-1-nopunct": 249,
        "unique-1-nopunct": 220,
        "entropy-1-nopunct": 7.35040527103618,
        "distinct-2-nopunct": 0.9239766081871345,
        "vocab_size-2-nopunct": 316,
        "unique-2-nopunct": 304,
        "entropy-2-nopunct": 8.209004789841385,
        "cond_entropy-2-nopunct": 0.9411456432062607,
        "distinct-3-nopunct": 0.9873817034700315,
        "vocab_size-3-nopunct": 313,
        "unique-3-nopunct": 310,
        "entropy-3-nopunct": 8.280721088492253,
        "cond_entropy-3-nopunct": 0.08818693942719108,
        "msttr-100": 0.7275,
        "msttr-100_nopunct": 0.78667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17857142857142858,
            "2": 0.32558139534883723,
            "3": 0.8603896103896104
        },
        "nist": 7.11591182993978,
        "bleu": 61.78134,
        "rouge1": {
            "precision": 0.84124,
            "recall": 0.81323,
            "fmeasure": 0.81929
        },
        "rouge2": {
            "precision": 0.67382,
            "recall": 0.66528,
            "fmeasure": 0.66481
        },
        "rougeL": {
            "precision": 0.75427,
            "recall": 0.72892,
            "fmeasure": 0.73417
        },
        "rougeLsum": {
            "precision": 0.75427,
            "recall": 0.72892,
            "fmeasure": 0.73417
        },
        "nubia": {
            "semantic_relation": 4.2932,
            "contradiction": 8.75101,
            "irrelevancy": 19.48859,
            "logical_agreement": 71.76041,
            "grammar_ref": 4.85173,
            "grammar_hyp": 5.09456,
            "nubia_score": 0.73246
        },
        "meteor": 0.46554560739575485,
        "bleurt": 0.39112,
        "bertscore": {
            "precision": 0.95218,
            "recall": 0.94787,
            "f1": 0.94956
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_575": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.11251249881411754,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.9130434782608695,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.349648912578752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.1176878443984663,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.6956521739130435
        },
        "nist": 1.5673665619371575,
        "bleu": 20.19635,
        "rouge1": {
            "precision": 0.7971,
            "recall": 0.49733,
            "fmeasure": 0.61171
        },
        "rouge2": {
            "precision": 0.37879,
            "recall": 0.2451,
            "fmeasure": 0.29762
        },
        "rougeL": {
            "precision": 0.57971,
            "recall": 0.38095,
            "fmeasure": 0.45977
        },
        "rougeLsum": {
            "precision": 0.57971,
            "recall": 0.38095,
            "fmeasure": 0.45977
        },
        "nubia": {
            "semantic_relation": 3.73002,
            "contradiction": 0.65691,
            "irrelevancy": 88.07441,
            "logical_agreement": 11.26868,
            "grammar_ref": 5.19058,
            "grammar_hyp": 6.07062,
            "nubia_score": 0.40277
        },
        "meteor": 0.3101509650077615,
        "bleurt": -0.08412,
        "bertscore": {
            "precision": 0.92488,
            "recall": 0.88602,
            "f1": 0.9031
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_576": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 69,
        "mean_pred_length": 23.0,
        "std_pred_length": 4.320493798938574,
        "median_pred_length": 21.0,
        "min_pred_length": 19,
        "max_pred_length": 29,
        "distinct-1": 0.7391304347826086,
        "vocab_size-1": 51,
        "unique-1": 41,
        "entropy-1": 5.463171920358154,
        "distinct-2": 0.9848484848484849,
        "vocab_size-2": 65,
        "unique-2": 64,
        "entropy-2": 6.014091089055431,
        "cond_entropy-2": 0.5499503445951455,
        "distinct-3": 1.0,
        "vocab_size-3": 63,
        "unique-3": 63,
        "entropy-3": 5.97727992349992,
        "cond_entropy-3": -0.03536816411250496,
        "total_length-nopunct": 58,
        "mean_pred_length-nopunct": 19.333333333333332,
        "std_pred_length-nopunct": 2.494438257849294,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8103448275862069,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.370659227774289,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 55,
        "unique-2-nopunct": 55,
        "entropy-2-nopunct": 5.7813597135246555,
        "cond_entropy-2-nopunct": 0.4372816730605492,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 52,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 5.700439718141095,
        "cond_entropy-3-nopunct": -0.08091999538356742,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 0.625,
            "3": 0.8928571428571429
        },
        "nist": 4.340355061861203,
        "bleu": 46.65994,
        "rouge1": {
            "precision": 0.72348,
            "recall": 0.78894,
            "fmeasure": 0.75117
        },
        "rouge2": {
            "precision": 0.55929,
            "recall": 0.6318,
            "fmeasure": 0.59118
        },
        "rougeL": {
            "precision": 0.67247,
            "recall": 0.7415,
            "fmeasure": 0.70196
        },
        "rougeLsum": {
            "precision": 0.67247,
            "recall": 0.7415,
            "fmeasure": 0.70196
        },
        "nubia": {
            "semantic_relation": 3.83567,
            "contradiction": 16.33303,
            "irrelevancy": 40.73469,
            "logical_agreement": 42.93228,
            "grammar_ref": 4.44265,
            "grammar_hyp": 4.06973,
            "nubia_score": 0.66529
        },
        "meteor": 0.42032025369587167,
        "bleurt": 0.29652,
        "bertscore": {
            "precision": 0.92132,
            "recall": 0.94504,
            "f1": 0.9303
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_580": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 73,
        "mean_pred_length": 14.6,
        "std_pred_length": 5.425863986500215,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.7671232876712328,
        "vocab_size-1": 56,
        "unique-1": 45,
        "entropy-1": 5.625176874648879,
        "distinct-2": 0.9264705882352942,
        "vocab_size-2": 63,
        "unique-2": 58,
        "entropy-2": 5.940404017720933,
        "cond_entropy-2": 0.18601534817086335,
        "distinct-3": 0.9523809523809523,
        "vocab_size-3": 60,
        "unique-3": 57,
        "entropy-3": 5.8820418282618245,
        "cond_entropy-3": -0.046690854258359324,
        "total_length-nopunct": 66,
        "mean_pred_length-nopunct": 13.2,
        "std_pred_length-nopunct": 5.035871324805669,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 54,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.626066233382144,
        "distinct-2-nopunct": 0.9180327868852459,
        "vocab_size-2-nopunct": 56,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 5.7668029113333725,
        "cond_entropy-2-nopunct": 0.15863240630995404,
        "distinct-3-nopunct": 0.9464285714285714,
        "vocab_size-3-nopunct": 53,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.7002120649147505,
        "cond_entropy-3-nopunct": -0.06981098693385336,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.75,
            "3": 0.8444444444444444
        },
        "nist": 4.163458287062195,
        "bleu": 41.67151,
        "rouge1": {
            "precision": 0.70778,
            "recall": 0.80347,
            "fmeasure": 0.7409
        },
        "rouge2": {
            "precision": 0.5446,
            "recall": 0.62015,
            "fmeasure": 0.56902
        },
        "rougeL": {
            "precision": 0.63778,
            "recall": 0.73109,
            "fmeasure": 0.67023
        },
        "rougeLsum": {
            "precision": 0.63778,
            "recall": 0.73109,
            "fmeasure": 0.67023
        },
        "nubia": {
            "semantic_relation": 4.15492,
            "contradiction": 34.55685,
            "irrelevancy": 34.11715,
            "logical_agreement": 31.326,
            "grammar_ref": 5.55931,
            "grammar_hyp": 5.02904,
            "nubia_score": 0.72027
        },
        "meteor": 0.44414892963723673,
        "bleurt": 0.47771,
        "bertscore": {
            "precision": 0.9409,
            "recall": 0.96079,
            "f1": 0.94605
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_385": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 2.5,
        "median_pred_length": 17.5,
        "min_pred_length": 15,
        "max_pred_length": 20,
        "distinct-1": 0.7714285714285715,
        "vocab_size-1": 27,
        "unique-1": 22,
        "entropy-1": 4.569007574818198,
        "distinct-2": 0.9696969696969697,
        "vocab_size-2": 32,
        "unique-2": 31,
        "entropy-2": 4.9837880587523955,
        "cond_entropy-2": 0.3881305107297537,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.025681679939320107,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7878787878787878,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.510768650436127,
        "distinct-2-nopunct": 0.967741935483871,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.889680181354619,
        "cond_entropy-2-nopunct": 0.4133389805263835,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.02724979801792366,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.3333333333333333,
            "3": 0.9473684210526315
        },
        "nist": 4.985264613907984,
        "bleu": 62.97184,
        "rouge1": {
            "precision": 0.81498,
            "recall": 0.89825,
            "fmeasure": 0.85184
        },
        "rouge2": {
            "precision": 0.69589,
            "recall": 0.7556,
            "fmeasure": 0.72213
        },
        "rougeL": {
            "precision": 0.79324,
            "recall": 0.87096,
            "fmeasure": 0.82764
        },
        "rougeLsum": {
            "precision": 0.79324,
            "recall": 0.87096,
            "fmeasure": 0.82764
        },
        "nubia": {
            "semantic_relation": 4.90152,
            "contradiction": 0.36397,
            "irrelevancy": 28.4496,
            "logical_agreement": 71.18643,
            "grammar_ref": 3.86772,
            "grammar_hyp": 3.70671,
            "nubia_score": 0.93785
        },
        "meteor": 0.5183732512519792,
        "bleurt": 0.66307,
        "bertscore": {
            "precision": 0.96198,
            "recall": 0.9794,
            "f1": 0.97053
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_581": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.277613436819116,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.2252432046274455,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9697,
            "fmeasure": 0.98413
        },
        "rouge2": {
            "precision": 0.96296,
            "recall": 0.93333,
            "fmeasure": 0.94737
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9697,
            "fmeasure": 0.98413
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9697,
            "fmeasure": 0.98413
        },
        "nubia": {
            "semantic_relation": 4.85528,
            "contradiction": 0.45187,
            "irrelevancy": 0.4652,
            "logical_agreement": 99.08293,
            "grammar_ref": 4.19474,
            "grammar_hyp": 4.01239,
            "nubia_score": 0.98066
        },
        "meteor": 1.0,
        "bleurt": 0.70774,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_203": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 83,
        "mean_pred_length": 16.6,
        "std_pred_length": 4.409081537009721,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 24,
        "distinct-1": 0.7590361445783133,
        "vocab_size-1": 63,
        "unique-1": 53,
        "entropy-1": 5.7603460577486905,
        "distinct-2": 0.9871794871794872,
        "vocab_size-2": 77,
        "unique-2": 76,
        "entropy-2": 6.259761193221231,
        "cond_entropy-2": 0.43625445429293697,
        "distinct-3": 1.0,
        "vocab_size-3": 73,
        "unique-3": 73,
        "entropy-3": 6.189824558880028,
        "cond_entropy-3": -0.06818039970825861,
        "total_length-nopunct": 73,
        "mean_pred_length-nopunct": 14.6,
        "std_pred_length-nopunct": 3.2,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8082191780821918,
        "vocab_size-1-nopunct": 59,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 5.693048360160979,
        "distinct-2-nopunct": 0.9852941176470589,
        "vocab_size-2-nopunct": 67,
        "unique-2-nopunct": 66,
        "entropy-2-nopunct": 6.058051076544463,
        "cond_entropy-2-nopunct": 0.40153037805400504,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 63,
        "unique-3-nopunct": 63,
        "entropy-3-nopunct": 5.97727992349992,
        "cond_entropy-3-nopunct": -0.07843688600439114,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25925925925925924,
            "2": 0.28125,
            "3": 0.825
        },
        "nist": 4.430715319046585,
        "bleu": 28.62987,
        "rouge1": {
            "precision": 0.64553,
            "recall": 0.74886,
            "fmeasure": 0.67712
        },
        "rouge2": {
            "precision": 0.38394,
            "recall": 0.46327,
            "fmeasure": 0.4091
        },
        "rougeL": {
            "precision": 0.52539,
            "recall": 0.6169,
            "fmeasure": 0.55651
        },
        "rougeLsum": {
            "precision": 0.52539,
            "recall": 0.6169,
            "fmeasure": 0.55651
        },
        "nubia": {
            "semantic_relation": 3.64449,
            "contradiction": 16.92875,
            "irrelevancy": 31.81895,
            "logical_agreement": 51.2523,
            "grammar_ref": 4.63083,
            "grammar_hyp": 4.2613,
            "nubia_score": 0.55146
        },
        "meteor": 0.3654520125509644,
        "bleurt": 0.00345,
        "bertscore": {
            "precision": 0.91051,
            "recall": 0.92114,
            "f1": 0.90569
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_261": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 2.0,
        "median_pred_length": 20.0,
        "min_pred_length": 18,
        "max_pred_length": 22,
        "distinct-1": 0.85,
        "vocab_size-1": 34,
        "unique-1": 29,
        "entropy-1": 5.003055907333277,
        "distinct-2": 1.0,
        "vocab_size-2": 38,
        "unique-2": 38,
        "entropy-2": 5.247927513443589,
        "cond_entropy-2": 0.20902277387631443,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.0780025120012732,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 18.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8648648648648649,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.918780730435346,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.129283016944964,
        "cond_entropy-2-nopunct": 0.1985407228064013,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.08488889758651327,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.8235294117647058
        },
        "nist": 2.398549071911337,
        "bleu": 28.83374,
        "rouge1": {
            "precision": 0.52063,
            "recall": 0.66688,
            "fmeasure": 0.57622
        },
        "rouge2": {
            "precision": 0.34643,
            "recall": 0.43946,
            "fmeasure": 0.37902
        },
        "rougeL": {
            "precision": 0.46349,
            "recall": 0.59817,
            "fmeasure": 0.51197
        },
        "rougeLsum": {
            "precision": 0.46349,
            "recall": 0.59817,
            "fmeasure": 0.51197
        },
        "nubia": {
            "semantic_relation": 3.19876,
            "contradiction": 34.9693,
            "irrelevancy": 38.17364,
            "logical_agreement": 26.85706,
            "grammar_ref": 5.15434,
            "grammar_hyp": 4.22038,
            "nubia_score": 0.48206
        },
        "meteor": 0.34973269128293794,
        "bleurt": -0.11641,
        "bertscore": {
            "precision": 0.81529,
            "recall": 0.85904,
            "f1": 0.83632
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_264": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 6,
        "total_length": 115,
        "mean_pred_length": 19.166666666666668,
        "std_pred_length": 6.568020165079344,
        "median_pred_length": 22.5,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.6347826086956522,
        "vocab_size-1": 73,
        "unique-1": 60,
        "entropy-1": 5.759116546536655,
        "distinct-2": 0.9174311926605505,
        "vocab_size-2": 100,
        "unique-2": 93,
        "entropy-2": 6.589195563269329,
        "cond_entropy-2": 0.8164848977092646,
        "distinct-3": 0.9805825242718447,
        "vocab_size-3": 101,
        "unique-3": 99,
        "entropy-3": 6.647665575726925,
        "cond_entropy-3": 0.06889654225412677,
        "total_length-nopunct": 93,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 4.856267428111155,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7419354838709677,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 5.782130553109024,
        "distinct-2-nopunct": 0.9310344827586207,
        "vocab_size-2-nopunct": 81,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 6.296335593525004,
        "cond_entropy-2-nopunct": 0.5664138857952329,
        "distinct-3-nopunct": 0.9876543209876543,
        "vocab_size-3-nopunct": 80,
        "unique-3-nopunct": 79,
        "entropy-3-nopunct": 6.315158644859922,
        "cond_entropy-3-nopunct": 0.029682895951494953,
        "msttr-100": 0.65,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.2978723404255319,
            "3": 0.6935483870967742
        },
        "nist": 4.000177347756656,
        "bleu": 37.72589,
        "rouge1": {
            "precision": 0.72157,
            "recall": 0.59857,
            "fmeasure": 0.63869
        },
        "rouge2": {
            "precision": 0.42682,
            "recall": 0.38766,
            "fmeasure": 0.3996
        },
        "rougeL": {
            "precision": 0.61509,
            "recall": 0.52081,
            "fmeasure": 0.55221
        },
        "rougeLsum": {
            "precision": 0.61509,
            "recall": 0.52081,
            "fmeasure": 0.55221
        },
        "nubia": {
            "semantic_relation": 3.68098,
            "contradiction": 7.58081,
            "irrelevancy": 29.73462,
            "logical_agreement": 62.68456,
            "grammar_ref": 4.79112,
            "grammar_hyp": 4.66187,
            "nubia_score": 0.57904
        },
        "meteor": 0.3331300277613004,
        "bleurt": -0.04049,
        "bertscore": {
            "precision": 0.91096,
            "recall": 0.88285,
            "f1": 0.89645
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_387": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 69,
        "mean_pred_length": 17.25,
        "std_pred_length": 5.673402858955108,
        "median_pred_length": 18.5,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.7391304347826086,
        "vocab_size-1": 51,
        "unique-1": 39,
        "entropy-1": 5.4945457904506245,
        "distinct-2": 0.9538461538461539,
        "vocab_size-2": 62,
        "unique-2": 59,
        "entropy-2": 5.930060120720766,
        "cond_entropy-2": 0.35022070973644354,
        "distinct-3": 0.9672131147540983,
        "vocab_size-3": 59,
        "unique-3": 57,
        "entropy-3": 5.865163567071081,
        "cond_entropy-3": -0.05884359021966683,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.949747468305833,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8214285714285714,
        "vocab_size-1-nopunct": 46,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.385754199299808,
        "distinct-2-nopunct": 0.9423076923076923,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.5850551027564785,
        "cond_entropy-2-nopunct": 0.23173172828419572,
        "distinct-3-nopunct": 0.9583333333333334,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.501629167387826,
        "cond_entropy-3-nopunct": -0.07381055075326926,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.037037037037037035,
            "2": 0.4666666666666667,
            "3": 0.6923076923076923
        },
        "nist": 4.2164858121929,
        "bleu": 34.18498,
        "rouge1": {
            "precision": 0.68159,
            "recall": 0.73636,
            "fmeasure": 0.69978
        },
        "rouge2": {
            "precision": 0.36367,
            "recall": 0.39981,
            "fmeasure": 0.37502
        },
        "rougeL": {
            "precision": 0.5641,
            "recall": 0.61095,
            "fmeasure": 0.58185
        },
        "rougeLsum": {
            "precision": 0.5641,
            "recall": 0.61095,
            "fmeasure": 0.58185
        },
        "nubia": {
            "semantic_relation": 3.98022,
            "contradiction": 14.84827,
            "irrelevancy": 53.33043,
            "logical_agreement": 31.8213,
            "grammar_ref": 4.83213,
            "grammar_hyp": 4.48573,
            "nubia_score": 0.67084
        },
        "meteor": 0.3715802416345226,
        "bleurt": 0.21012,
        "bertscore": {
            "precision": 0.92269,
            "recall": 0.9316,
            "f1": 0.92598
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_318": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 79,
        "mean_pred_length": 15.8,
        "std_pred_length": 6.013318551349164,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.6708860759493671,
        "vocab_size-1": 53,
        "unique-1": 42,
        "entropy-1": 5.412887831625156,
        "distinct-2": 0.9324324324324325,
        "vocab_size-2": 69,
        "unique-2": 66,
        "entropy-2": 6.047291203466792,
        "cond_entropy-2": 0.5729772175546008,
        "distinct-3": 0.9855072463768116,
        "vocab_size-3": 68,
        "unique-3": 67,
        "entropy-3": 6.079538949531787,
        "cond_entropy-3": 0.04399862738110349,
        "total_length-nopunct": 70,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 6.099180272790763,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7285714285714285,
        "vocab_size-1-nopunct": 51,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.403984446471153,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 60,
        "unique-2-nopunct": 57,
        "entropy-2-nopunct": 5.837752428413074,
        "cond_entropy-2-nopunct": 0.4587909489014414,
        "distinct-3-nopunct": 0.9833333333333333,
        "vocab_size-3-nopunct": 59,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.873557262275184,
        "cond_entropy-3-nopunct": 0.05118944924673077,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.3333333333333333,
            "3": 0.7321428571428571
        },
        "nist": 5.066638158666016,
        "bleu": 44.84852,
        "rouge1": {
            "precision": 0.80707,
            "recall": 0.69013,
            "fmeasure": 0.73579
        },
        "rouge2": {
            "precision": 0.56669,
            "recall": 0.50075,
            "fmeasure": 0.52375
        },
        "rougeL": {
            "precision": 0.67374,
            "recall": 0.5812,
            "fmeasure": 0.61765
        },
        "rougeLsum": {
            "precision": 0.67374,
            "recall": 0.5812,
            "fmeasure": 0.61765
        },
        "nubia": {
            "semantic_relation": 3.90189,
            "contradiction": 5.63751,
            "irrelevancy": 59.58999,
            "logical_agreement": 34.7725,
            "grammar_ref": 4.74509,
            "grammar_hyp": 4.53535,
            "nubia_score": 0.68516
        },
        "meteor": 0.3674180861857611,
        "bleurt": 0.14321,
        "bertscore": {
            "precision": 0.92912,
            "recall": 0.90114,
            "f1": 0.91427
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_265": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 6,
        "total_length": 97,
        "mean_pred_length": 16.166666666666668,
        "std_pred_length": 4.524623986832743,
        "median_pred_length": 15.5,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.711340206185567,
        "vocab_size-1": 69,
        "unique-1": 53,
        "entropy-1": 5.879559203208504,
        "distinct-2": 0.967032967032967,
        "vocab_size-2": 88,
        "unique-2": 85,
        "entropy-2": 6.441860574264635,
        "cond_entropy-2": 0.521885127472307,
        "distinct-3": 0.9882352941176471,
        "vocab_size-3": 84,
        "unique-3": 83,
        "entropy-3": 6.385861524373001,
        "cond_entropy-3": -0.07487429229628861,
        "total_length-nopunct": 88,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 5.055250296034367,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 5.847223630217675,
        "distinct-2-nopunct": 0.975609756097561,
        "vocab_size-2-nopunct": 80,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.308771516813209,
        "cond_entropy-2-nopunct": 0.48195334916282595,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 76,
        "unique-3-nopunct": 76,
        "entropy-3-nopunct": 6.247927513443591,
        "cond_entropy-3-nopunct": -0.0833087017008138,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.16666666666666666,
            "3": 0.7564102564102564
        },
        "nist": 4.920492310707959,
        "bleu": 50.32767,
        "rouge1": {
            "precision": 0.82523,
            "recall": 0.70987,
            "fmeasure": 0.74645
        },
        "rouge2": {
            "precision": 0.61063,
            "recall": 0.51316,
            "fmeasure": 0.54318
        },
        "rougeL": {
            "precision": 0.67253,
            "recall": 0.56236,
            "fmeasure": 0.59737
        },
        "rougeLsum": {
            "precision": 0.67253,
            "recall": 0.56236,
            "fmeasure": 0.59737
        },
        "nubia": {
            "semantic_relation": 3.82699,
            "contradiction": 15.29253,
            "irrelevancy": 43.66844,
            "logical_agreement": 41.03903,
            "grammar_ref": 4.20009,
            "grammar_hyp": 4.07467,
            "nubia_score": 0.64542
        },
        "meteor": 0.3703504465280372,
        "bleurt": 0.11713,
        "bertscore": {
            "precision": 0.92662,
            "recall": 0.90465,
            "f1": 0.91404
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_390": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 8,
        "total_length": 133,
        "mean_pred_length": 16.625,
        "std_pred_length": 5.786568499551353,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.6917293233082706,
        "vocab_size-1": 92,
        "unique-1": 72,
        "entropy-1": 6.233649823773048,
        "distinct-2": 0.928,
        "vocab_size-2": 116,
        "unique-2": 107,
        "entropy-2": 6.821784284662096,
        "cond_entropy-2": 0.4835070724044191,
        "distinct-3": 0.9401709401709402,
        "vocab_size-3": 110,
        "unique-3": 103,
        "entropy-3": 6.750706599925268,
        "cond_entropy-3": -0.06123153089064832,
        "total_length-nopunct": 121,
        "mean_pred_length-nopunct": 15.125,
        "std_pred_length-nopunct": 5.18260311040697,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7355371900826446,
        "vocab_size-1-nopunct": 89,
        "unique-1-nopunct": 71,
        "entropy-1-nopunct": 6.244271064502366,
        "distinct-2-nopunct": 0.9203539823008849,
        "vocab_size-2-nopunct": 104,
        "unique-2-nopunct": 95,
        "entropy-2-nopunct": 6.660886927016974,
        "cond_entropy-2-nopunct": 0.46437460040997713,
        "distinct-3-nopunct": 0.9333333333333333,
        "vocab_size-3-nopunct": 98,
        "unique-3-nopunct": 91,
        "entropy-3-nopunct": 6.580912184332781,
        "cond_entropy-3-nopunct": -0.06783820665382725,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17391304347826086,
            "2": 0.38461538461538464,
            "3": 0.7692307692307693
        },
        "nist": 4.943962951294086,
        "bleu": 42.62005,
        "rouge1": {
            "precision": 0.86115,
            "recall": 0.74122,
            "fmeasure": 0.79452
        },
        "rouge2": {
            "precision": 0.5962,
            "recall": 0.50116,
            "fmeasure": 0.54309
        },
        "rougeL": {
            "precision": 0.63194,
            "recall": 0.54221,
            "fmeasure": 0.58219
        },
        "rougeLsum": {
            "precision": 0.63194,
            "recall": 0.54221,
            "fmeasure": 0.58219
        },
        "nubia": {
            "semantic_relation": 4.31884,
            "contradiction": 1.0285,
            "irrelevancy": 9.00887,
            "logical_agreement": 89.96262,
            "grammar_ref": 4.47406,
            "grammar_hyp": 4.66054,
            "nubia_score": 0.75772
        },
        "meteor": 0.38966483402707147,
        "bleurt": 0.36734,
        "bertscore": {
            "precision": 0.94712,
            "recall": 0.9265,
            "f1": 0.93602
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_320": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 14,
        "total_length": 237,
        "mean_pred_length": 16.928571428571427,
        "std_pred_length": 5.035081013879174,
        "median_pred_length": 14.5,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.6160337552742616,
        "vocab_size-1": 146,
        "unique-1": 116,
        "entropy-1": 6.638233633720418,
        "distinct-2": 0.9417040358744395,
        "vocab_size-2": 210,
        "unique-2": 201,
        "entropy-2": 7.668569070304498,
        "cond_entropy-2": 0.953711303965783,
        "distinct-3": 1.0,
        "vocab_size-3": 209,
        "unique-3": 209,
        "entropy-3": 7.707359132080901,
        "cond_entropy-3": 0.04765432787506109,
        "total_length-nopunct": 212,
        "mean_pred_length-nopunct": 15.142857142857142,
        "std_pred_length-nopunct": 5.068912856917192,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6698113207547169,
        "vocab_size-1-nopunct": 142,
        "unique-1-nopunct": 114,
        "entropy-1-nopunct": 6.712366298980708,
        "distinct-2-nopunct": 0.9393939393939394,
        "vocab_size-2-nopunct": 186,
        "unique-2-nopunct": 178,
        "entropy-2-nopunct": 7.490418362481982,
        "cond_entropy-2-nopunct": 0.8448084179364195,
        "distinct-3-nopunct": 0.9945652173913043,
        "vocab_size-3-nopunct": 183,
        "unique-3-nopunct": 182,
        "entropy-3-nopunct": 7.512692390839634,
        "cond_entropy-3-nopunct": 0.03284541752265847,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3939393939393939,
            "2": 0.6136363636363636,
            "3": 0.8142857142857143
        },
        "nist": 6.161092534962991,
        "bleu": 56.97837,
        "rouge1": {
            "precision": 0.78953,
            "recall": 0.81983,
            "fmeasure": 0.79983
        },
        "rouge2": {
            "precision": 0.65183,
            "recall": 0.67144,
            "fmeasure": 0.65772
        },
        "rougeL": {
            "precision": 0.69944,
            "recall": 0.73274,
            "fmeasure": 0.71108
        },
        "rougeLsum": {
            "precision": 0.69944,
            "recall": 0.73274,
            "fmeasure": 0.71108
        },
        "nubia": {
            "semantic_relation": 4.30416,
            "contradiction": 5.51507,
            "irrelevancy": 31.53355,
            "logical_agreement": 62.95138,
            "grammar_ref": 4.83858,
            "grammar_hyp": 4.84822,
            "nubia_score": 0.77579
        },
        "meteor": 0.4361219798666884,
        "bleurt": 0.3402,
        "bertscore": {
            "precision": 0.94183,
            "recall": 0.94544,
            "f1": 0.9432
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_322": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 4.0,
        "median_pred_length": 17.0,
        "min_pred_length": 13,
        "max_pred_length": 21,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 30,
        "unique-1": 26,
        "entropy-1": 4.852168723603279,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.10003715874966054,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.09310940439148141,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.773557262275186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.043321469306228474,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7931034482758621
        },
        "nist": 4.212934730182593,
        "bleu": 53.01556,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.79481,
            "fmeasure": 0.81031
        },
        "rouge2": {
            "precision": 0.68571,
            "recall": 0.66082,
            "fmeasure": 0.66876
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.79865,
            "fmeasure": 0.80381
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.79865,
            "fmeasure": 0.80381
        },
        "nubia": {
            "semantic_relation": 4.92165,
            "contradiction": 0.38246,
            "irrelevancy": 2.88517,
            "logical_agreement": 96.73236,
            "grammar_ref": 4.49155,
            "grammar_hyp": 4.68741,
            "nubia_score": 0.94029
        },
        "meteor": 0.49634852707969274,
        "bleurt": 0.58578,
        "bertscore": {
            "precision": 0.97254,
            "recall": 0.96993,
            "f1": 0.97116
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_324": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 11,
        "total_length": 198,
        "mean_pred_length": 18.0,
        "std_pred_length": 5.134553180524705,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 26,
        "distinct-1": 0.6515151515151515,
        "vocab_size-1": 129,
        "unique-1": 109,
        "entropy-1": 6.467305720585078,
        "distinct-2": 0.9732620320855615,
        "vocab_size-2": 182,
        "unique-2": 177,
        "entropy-2": 7.4934185240587405,
        "cond_entropy-2": 0.9114779315248293,
        "distinct-3": 1.0,
        "vocab_size-3": 176,
        "unique-3": 176,
        "entropy-3": 7.459431618637307,
        "cond_entropy-3": -0.030644659432157488,
        "total_length-nopunct": 171,
        "mean_pred_length-nopunct": 15.545454545454545,
        "std_pred_length-nopunct": 4.997520046139909,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7251461988304093,
        "vocab_size-1-nopunct": 124,
        "unique-1-nopunct": 108,
        "entropy-1-nopunct": 6.516462215483313,
        "distinct-2-nopunct": 0.975,
        "vocab_size-2-nopunct": 156,
        "unique-2-nopunct": 152,
        "entropy-2-nopunct": 7.271928094887367,
        "cond_entropy-2-nopunct": 0.8049364624879732,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 149,
        "unique-3-nopunct": 149,
        "entropy-3-nopunct": 7.21916852046217,
        "cond_entropy-3-nopunct": -0.04906829925741543,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.81,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.56,
            "3": 0.7730496453900709
        },
        "nist": 5.841763578849132,
        "bleu": 42.63804,
        "rouge1": {
            "precision": 0.75575,
            "recall": 0.73775,
            "fmeasure": 0.73808
        },
        "rouge2": {
            "precision": 0.47102,
            "recall": 0.42766,
            "fmeasure": 0.44577
        },
        "rougeL": {
            "precision": 0.60327,
            "recall": 0.56048,
            "fmeasure": 0.57491
        },
        "rougeLsum": {
            "precision": 0.60327,
            "recall": 0.56048,
            "fmeasure": 0.57491
        },
        "nubia": {
            "semantic_relation": 4.4247,
            "contradiction": 1.33999,
            "irrelevancy": 29.21993,
            "logical_agreement": 69.44009,
            "grammar_ref": 4.70918,
            "grammar_hyp": 4.79947,
            "nubia_score": 0.77691
        },
        "meteor": 0.3888089810060307,
        "bleurt": 0.23575,
        "bertscore": {
            "precision": 0.92668,
            "recall": 0.92804,
            "f1": 0.92667
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_529": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "nist": 2.268023386349885,
        "bleu": 22.45923,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.7,
            "fmeasure": 0.76863
        },
        "rouge2": {
            "precision": 0.27778,
            "recall": 0.22751,
            "fmeasure": 0.24957
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.58333,
            "fmeasure": 0.64052
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.58333,
            "fmeasure": 0.64052
        },
        "nubia": {
            "semantic_relation": 4.47459,
            "contradiction": 0.466,
            "irrelevancy": 0.50815,
            "logical_agreement": 99.02586,
            "grammar_ref": 5.68329,
            "grammar_hyp": 6.38664,
            "nubia_score": 0.76827
        },
        "meteor": 0.37906975887049504,
        "bleurt": 0.46909,
        "bertscore": {
            "precision": 0.95745,
            "recall": 0.93578,
            "f1": 0.94649
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_486": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 63,
        "mean_pred_length": 15.75,
        "std_pred_length": 6.94172168845741,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.7619047619047619,
        "vocab_size-1": 48,
        "unique-1": 37,
        "entropy-1": 5.445378732955048,
        "distinct-2": 1.0,
        "vocab_size-2": 59,
        "unique-2": 59,
        "entropy-2": 5.882643049361836,
        "cond_entropy-2": 0.3377321937318731,
        "distinct-3": 1.0,
        "vocab_size-3": 55,
        "unique-3": 55,
        "entropy-3": 5.7813597135246555,
        "cond_entropy-3": -0.10128333583718159,
        "total_length-nopunct": 53,
        "mean_pred_length-nopunct": 13.25,
        "std_pred_length-nopunct": 4.9180788932265,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8113207547169812,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.322075643160802,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.614709844115208,
        "cond_entropy-2-nopunct": 0.32576438964031396,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 45,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.491853096329673,
        "cond_entropy-3-nopunct": -0.12285674778553377,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.21052631578947367,
            "3": 0.85
        },
        "nist": 3.8489223717955814,
        "bleu": 35.00925,
        "rouge1": {
            "precision": 0.50621,
            "recall": 0.48818,
            "fmeasure": 0.48253
        },
        "rouge2": {
            "precision": 0.25065,
            "recall": 0.24401,
            "fmeasure": 0.23796
        },
        "rougeL": {
            "precision": 0.48641,
            "recall": 0.49165,
            "fmeasure": 0.47246
        },
        "rougeLsum": {
            "precision": 0.48641,
            "recall": 0.49165,
            "fmeasure": 0.47246
        },
        "nubia": {
            "semantic_relation": 3.06317,
            "contradiction": 46.15591,
            "irrelevancy": 36.3435,
            "logical_agreement": 17.50058,
            "grammar_ref": 4.83501,
            "grammar_hyp": 4.69299,
            "nubia_score": 0.40622
        },
        "meteor": 0.32155604367331286,
        "bleurt": -0.25744,
        "bertscore": {
            "precision": 0.83622,
            "recall": 0.83691,
            "f1": 0.83001
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_204": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 12,
        "total_length": 226,
        "mean_pred_length": 18.833333333333332,
        "std_pred_length": 5.398044913567215,
        "median_pred_length": 18.0,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.6106194690265486,
        "vocab_size-1": 138,
        "unique-1": 112,
        "entropy-1": 6.498668905545262,
        "distinct-2": 0.9532710280373832,
        "vocab_size-2": 204,
        "unique-2": 197,
        "entropy-2": 7.631141563623372,
        "cond_entropy-2": 1.0498969369074025,
        "distinct-3": 1.0,
        "vocab_size-3": 202,
        "unique-3": 202,
        "entropy-3": 7.658211482751764,
        "cond_entropy-3": 0.022129211100892564,
        "total_length-nopunct": 202,
        "mean_pred_length-nopunct": 16.833333333333332,
        "std_pred_length-nopunct": 5.624845676895402,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6633663366336634,
        "vocab_size-1-nopunct": 134,
        "unique-1-nopunct": 112,
        "entropy-1-nopunct": 6.52911148258041,
        "distinct-2-nopunct": 0.9578947368421052,
        "vocab_size-2-nopunct": 182,
        "unique-2-nopunct": 177,
        "entropy-2-nopunct": 7.466646974254975,
        "cond_entropy-2-nopunct": 0.9667418074748312,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 178,
        "unique-3-nopunct": 178,
        "entropy-3-nopunct": 7.47573343096637,
        "cond_entropy-3-nopunct": 0.0029998022958401937,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.72,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.19230769230769232,
            "3": 0.6823529411764706
        },
        "nist": 4.7239080765884065,
        "bleu": 26.25397,
        "rouge1": {
            "precision": 0.75688,
            "recall": 0.69127,
            "fmeasure": 0.712
        },
        "rouge2": {
            "precision": 0.48789,
            "recall": 0.44996,
            "fmeasure": 0.46064
        },
        "rougeL": {
            "precision": 0.65801,
            "recall": 0.60768,
            "fmeasure": 0.6233
        },
        "rougeLsum": {
            "precision": 0.65801,
            "recall": 0.60768,
            "fmeasure": 0.6233
        },
        "nubia": {
            "semantic_relation": 4.10033,
            "contradiction": 18.37087,
            "irrelevancy": 28.62528,
            "logical_agreement": 53.00386,
            "grammar_ref": 4.36261,
            "grammar_hyp": 4.30292,
            "nubia_score": 0.72009
        },
        "meteor": 0.31592345045607373,
        "bleurt": 0.16005,
        "bertscore": {
            "precision": 0.91824,
            "recall": 0.90668,
            "f1": 0.91095
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_351": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 10,
        "unique-1": 8,
        "entropy-1": 3.180832987205441,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.44743007442701976,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.0220552088742,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.48854979993100167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.8
        },
        "nist": 2.210473320391313,
        "bleu": 34.38931,
        "rouge1": {
            "precision": 0.69444,
            "recall": 0.93939,
            "fmeasure": 0.7942
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.93333,
            "fmeasure": 0.77249
        },
        "rougeL": {
            "precision": 0.69444,
            "recall": 0.93939,
            "fmeasure": 0.7942
        },
        "rougeLsum": {
            "precision": 0.69444,
            "recall": 0.93939,
            "fmeasure": 0.7942
        },
        "nubia": {
            "semantic_relation": 4.97174,
            "contradiction": 0.18493,
            "irrelevancy": 28.82608,
            "logical_agreement": 70.98899,
            "grammar_ref": 3.38649,
            "grammar_hyp": 2.7485,
            "nubia_score": 0.90007
        },
        "meteor": 0.5228493300640051,
        "bleurt": 0.72139,
        "bertscore": {
            "precision": 0.95642,
            "recall": 0.96183,
            "f1": 0.95427
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_582": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 54,
        "mean_pred_length": 13.5,
        "std_pred_length": 3.774917217635375,
        "median_pred_length": 11.5,
        "min_pred_length": 11,
        "max_pred_length": 20,
        "distinct-1": 0.7407407407407407,
        "vocab_size-1": 40,
        "unique-1": 30,
        "entropy-1": 5.1713731502314895,
        "distinct-2": 0.84,
        "vocab_size-2": 42,
        "unique-2": 35,
        "entropy-2": 5.308758439731456,
        "cond_entropy-2": 0.024066437654525413,
        "distinct-3": 0.8913043478260869,
        "vocab_size-3": 41,
        "unique-3": 36,
        "entropy-3": 5.306170651709183,
        "cond_entropy-3": 0.026551146764102772,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.9154759474226504,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7708333333333334,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 5.095175521464346,
        "distinct-2-nopunct": 0.8181818181818182,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 5.078638720860853,
        "cond_entropy-2-nopunct": 0.027989288419856123,
        "distinct-3-nopunct": 0.875,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 5.071928094887363,
        "cond_entropy-3-nopunct": 0.0313686638041517,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8780487804878049
        },
        "nist": 5.194860450654667,
        "bleu": 70.7629,
        "rouge1": {
            "precision": 0.95,
            "recall": 0.90143,
            "fmeasure": 0.92307
        },
        "rouge2": {
            "precision": 0.86647,
            "recall": 0.83813,
            "fmeasure": 0.85134
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.86339,
            "fmeasure": 0.88641
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.86339,
            "fmeasure": 0.88641
        },
        "nubia": {
            "semantic_relation": 4.62432,
            "contradiction": 17.45325,
            "irrelevancy": 10.09123,
            "logical_agreement": 72.45551,
            "grammar_ref": 5.18336,
            "grammar_hyp": 5.10741,
            "nubia_score": 0.82759
        },
        "meteor": 0.5218966298762977,
        "bleurt": 0.66442,
        "bertscore": {
            "precision": 0.98124,
            "recall": 0.97711,
            "f1": 0.97789
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_488": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9285714285714286
        },
        "nist": 3.7683039530523845,
        "bleu": 56.05302,
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.86667,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.64286,
            "recall": 0.64286,
            "fmeasure": 0.64286
        },
        "rougeL": {
            "precision": 0.86667,
            "recall": 0.83268,
            "fmeasure": 0.84861
        },
        "rougeLsum": {
            "precision": 0.86667,
            "recall": 0.83268,
            "fmeasure": 0.84861
        },
        "nubia": {
            "semantic_relation": 4.71564,
            "contradiction": 0.61817,
            "irrelevancy": 3.88139,
            "logical_agreement": 95.50044,
            "grammar_ref": 4.24096,
            "grammar_hyp": 4.09782,
            "nubia_score": 0.90645
        },
        "meteor": 0.47375793339493116,
        "bleurt": 0.69449,
        "bertscore": {
            "precision": 0.96886,
            "recall": 0.96772,
            "f1": 0.96829
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_392": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 13,
        "total_length": 184,
        "mean_pred_length": 14.153846153846153,
        "std_pred_length": 4.365003372034187,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.625,
        "vocab_size-1": 115,
        "unique-1": 89,
        "entropy-1": 6.372847992789223,
        "distinct-2": 0.9122807017543859,
        "vocab_size-2": 156,
        "unique-2": 141,
        "entropy-2": 7.242413918394661,
        "cond_entropy-2": 0.6757271255273667,
        "distinct-3": 0.9493670886075949,
        "vocab_size-3": 150,
        "unique-3": 142,
        "entropy-3": 7.2025149253923075,
        "cond_entropy-3": -0.05078062746828853,
        "total_length-nopunct": 162,
        "mean_pred_length-nopunct": 12.461538461538462,
        "std_pred_length-nopunct": 3.733741876772799,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6851851851851852,
        "vocab_size-1-nopunct": 111,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.451120568001665,
        "distinct-2-nopunct": 0.9060402684563759,
        "vocab_size-2-nopunct": 135,
        "unique-2-nopunct": 121,
        "entropy-2-nopunct": 7.031249057374921,
        "cond_entropy-2-nopunct": 0.6174001850341609,
        "distinct-3-nopunct": 0.9485294117647058,
        "vocab_size-3-nopunct": 129,
        "unique-3-nopunct": 122,
        "entropy-3-nopunct": 6.984521664779739,
        "cond_entropy-3-nopunct": -0.06552920862358699,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.73,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08823529411764706,
            "2": 0.5098039215686274,
            "3": 0.7886178861788617
        },
        "nist": 5.417469442390628,
        "bleu": 44.82167,
        "rouge1": {
            "precision": 0.82724,
            "recall": 0.71948,
            "fmeasure": 0.75795
        },
        "rouge2": {
            "precision": 0.56775,
            "recall": 0.5068,
            "fmeasure": 0.52686
        },
        "rougeL": {
            "precision": 0.67915,
            "recall": 0.58858,
            "fmeasure": 0.6212
        },
        "rougeLsum": {
            "precision": 0.67915,
            "recall": 0.58858,
            "fmeasure": 0.6212
        },
        "nubia": {
            "semantic_relation": 4.13831,
            "contradiction": 16.54264,
            "irrelevancy": 19.18641,
            "logical_agreement": 64.27095,
            "grammar_ref": 4.86507,
            "grammar_hyp": 5.1164,
            "nubia_score": 0.67345
        },
        "meteor": 0.4013140638615047,
        "bleurt": 0.16091,
        "bertscore": {
            "precision": 0.93092,
            "recall": 0.91462,
            "f1": 0.92123
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_448": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 54,
        "mean_pred_length": 13.5,
        "std_pred_length": 0.5,
        "median_pred_length": 13.5,
        "min_pred_length": 13,
        "max_pred_length": 14,
        "distinct-1": 0.8148148148148148,
        "vocab_size-1": 44,
        "unique-1": 36,
        "entropy-1": 5.347480094756062,
        "distinct-2": 0.94,
        "vocab_size-2": 47,
        "unique-2": 44,
        "entropy-2": 5.523856189774728,
        "cond_entropy-2": 0.04896868761125601,
        "distinct-3": 0.9565217391304348,
        "vocab_size-3": 44,
        "unique-3": 42,
        "entropy-3": 5.43660543431788,
        "cond_entropy-3": -0.07681597284814654,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 12.25,
        "std_pred_length-nopunct": 0.82915619758885,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.328995558400923,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.358519762996339,
        "cond_entropy-2-nopunct": 0.05492102999224414,
        "distinct-3-nopunct": 0.9512195121951219,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.259991029008325,
        "cond_entropy-3-nopunct": -0.08552060390671316,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.8478260869565217
        },
        "nist": 5.1892432691312145,
        "bleu": 70.56072,
        "rouge1": {
            "precision": 0.87108,
            "recall": 0.80231,
            "fmeasure": 0.83376
        },
        "rouge2": {
            "precision": 0.67992,
            "recall": 0.63475,
            "fmeasure": 0.65548
        },
        "rougeL": {
            "precision": 0.80627,
            "recall": 0.75117,
            "fmeasure": 0.77662
        },
        "rougeLsum": {
            "precision": 0.80627,
            "recall": 0.75117,
            "fmeasure": 0.77662
        },
        "nubia": {
            "semantic_relation": 4.76314,
            "contradiction": 3.01298,
            "irrelevancy": 1.68808,
            "logical_agreement": 95.29893,
            "grammar_ref": 4.9146,
            "grammar_hyp": 4.88342,
            "nubia_score": 0.88985
        },
        "meteor": 0.4845363109375299,
        "bleurt": 0.52601,
        "bertscore": {
            "precision": 0.97349,
            "recall": 0.96144,
            "f1": 0.96521
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_530": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 85,
        "mean_pred_length": 17.0,
        "std_pred_length": 4.604345773288535,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 21,
        "distinct-1": 0.6352941176470588,
        "vocab_size-1": 54,
        "unique-1": 38,
        "entropy-1": 5.457970166687388,
        "distinct-2": 0.8125,
        "vocab_size-2": 65,
        "unique-2": 51,
        "entropy-2": 5.937492001110315,
        "cond_entropy-2": 0.3938651265831175,
        "distinct-3": 0.88,
        "vocab_size-3": 66,
        "unique-3": 57,
        "entropy-3": 5.9888186904958856,
        "cond_entropy-3": 0.050289095637364806,
        "total_length-nopunct": 74,
        "mean_pred_length-nopunct": 14.8,
        "std_pred_length-nopunct": 3.9698866482558417,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6891891891891891,
        "vocab_size-1-nopunct": 51,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.408627353077061,
        "distinct-2-nopunct": 0.8260869565217391,
        "vocab_size-2-nopunct": 57,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.749757971239565,
        "cond_entropy-2-nopunct": 0.3701759813909088,
        "distinct-3-nopunct": 0.90625,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 5.8125,
        "cond_entropy-3-nopunct": 0.05952066044313513,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.0,
            "3": 0.890625
        },
        "nist": 5.812084895214275,
        "bleu": 79.06436,
        "rouge1": {
            "precision": 0.86433,
            "recall": 0.83733,
            "fmeasure": 0.84753
        },
        "rouge2": {
            "precision": 0.76407,
            "recall": 0.72574,
            "fmeasure": 0.74287
        },
        "rougeL": {
            "precision": 0.82222,
            "recall": 0.80352,
            "fmeasure": 0.81003
        },
        "rougeLsum": {
            "precision": 0.82222,
            "recall": 0.80352,
            "fmeasure": 0.81003
        },
        "nubia": {
            "semantic_relation": 4.56346,
            "contradiction": 0.16796,
            "irrelevancy": 20.43457,
            "logical_agreement": 79.39748,
            "grammar_ref": 3.93665,
            "grammar_hyp": 3.93758,
            "nubia_score": 0.87047
        },
        "meteor": 0.5351345793834232,
        "bleurt": 0.60867,
        "bertscore": {
            "precision": 0.95848,
            "recall": 0.95975,
            "f1": 0.95842
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_584": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "nist": 3.0878882661357028,
        "bleu": 65.8037,
        "rouge1": {
            "precision": 0.85185,
            "recall": 0.88426,
            "fmeasure": 0.8671
        },
        "rouge2": {
            "precision": 0.70833,
            "recall": 0.7381,
            "fmeasure": 0.72222
        },
        "rougeL": {
            "precision": 0.85185,
            "recall": 0.88426,
            "fmeasure": 0.8671
        },
        "rougeLsum": {
            "precision": 0.85185,
            "recall": 0.88426,
            "fmeasure": 0.8671
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 2.51679,
            "irrelevancy": 0.90907,
            "logical_agreement": 96.57414,
            "grammar_ref": 5.94246,
            "grammar_hyp": 6.43289,
            "nubia_score": 0.86087
        },
        "meteor": 0.96,
        "bleurt": 0.74402,
        "bertscore": {
            "precision": 0.99641,
            "recall": 0.99641,
            "f1": 0.99641
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_450": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 47,
        "mean_pred_length": 11.75,
        "std_pred_length": 2.384848003542364,
        "median_pred_length": 11.5,
        "min_pred_length": 9,
        "max_pred_length": 15,
        "distinct-1": 0.8085106382978723,
        "vocab_size-1": 38,
        "unique-1": 33,
        "entropy-1": 5.08650374529466,
        "distinct-2": 1.0,
        "vocab_size-2": 43,
        "unique-2": 43,
        "entropy-2": 5.426264754702098,
        "cond_entropy-2": 0.1972572983732978,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.14086253583984967,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 2.0615528128088303,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.0589840894454285,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.247927513443589,
        "cond_entropy-2-nopunct": 0.22403114329640406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.16046467219324617,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24,
            "2": 0.6875,
            "3": 0.8095238095238095
        },
        "nist": 4.642192280396126,
        "bleu": 45.25868,
        "rouge1": {
            "precision": 0.76816,
            "recall": 0.81635,
            "fmeasure": 0.77425
        },
        "rouge2": {
            "precision": 0.60069,
            "recall": 0.64792,
            "fmeasure": 0.60784
        },
        "rougeL": {
            "precision": 0.74038,
            "recall": 0.78347,
            "fmeasure": 0.74272
        },
        "rougeLsum": {
            "precision": 0.74038,
            "recall": 0.78347,
            "fmeasure": 0.74272
        },
        "nubia": {
            "semantic_relation": 4.1428,
            "contradiction": 1.59889,
            "irrelevancy": 24.43911,
            "logical_agreement": 73.962,
            "grammar_ref": 4.75156,
            "grammar_hyp": 4.79586,
            "nubia_score": 0.69677
        },
        "meteor": 0.4116947490032879,
        "bleurt": 0.34956,
        "bertscore": {
            "precision": 0.93335,
            "recall": 0.92636,
            "f1": 0.929
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_490": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 78,
        "mean_pred_length": 15.6,
        "std_pred_length": 4.127953488110059,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 21,
        "distinct-1": 0.7051282051282052,
        "vocab_size-1": 55,
        "unique-1": 44,
        "entropy-1": 5.491605462953361,
        "distinct-2": 0.9863013698630136,
        "vocab_size-2": 72,
        "unique-2": 71,
        "entropy-2": 6.162427298606055,
        "cond_entropy-2": 0.5329068927657906,
        "distinct-3": 1.0,
        "vocab_size-3": 68,
        "unique-3": 68,
        "entropy-3": 6.087462841250345,
        "cond_entropy-3": -0.07294995292379533,
        "total_length-nopunct": 67,
        "mean_pred_length-nopunct": 13.4,
        "std_pred_length-nopunct": 3.4409301068170506,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7611940298507462,
        "vocab_size-1-nopunct": 51,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.465124078420599,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 62,
        "unique-2-nopunct": 62,
        "entropy-2-nopunct": 5.954196310386873,
        "cond_entropy-2-nopunct": 0.521408128098303,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 57,
        "unique-3-nopunct": 57,
        "entropy-3-nopunct": 5.832890014164737,
        "cond_entropy-3-nopunct": -0.12130629622213351,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.125,
            "3": 0.7142857142857143
        },
        "nist": 4.547584812169538,
        "bleu": 42.63127,
        "rouge1": {
            "precision": 0.74417,
            "recall": 0.74908,
            "fmeasure": 0.74293
        },
        "rouge2": {
            "precision": 0.54152,
            "recall": 0.56315,
            "fmeasure": 0.54939
        },
        "rougeL": {
            "precision": 0.65667,
            "recall": 0.67095,
            "fmeasure": 0.66078
        },
        "rougeLsum": {
            "precision": 0.65667,
            "recall": 0.67095,
            "fmeasure": 0.66078
        },
        "nubia": {
            "semantic_relation": 4.28426,
            "contradiction": 4.23776,
            "irrelevancy": 13.8159,
            "logical_agreement": 81.94633,
            "grammar_ref": 4.31899,
            "grammar_hyp": 4.34481,
            "nubia_score": 0.76914
        },
        "meteor": 0.3828393124396222,
        "bleurt": 0.2939,
        "bertscore": {
            "precision": 0.93448,
            "recall": 0.92396,
            "f1": 0.92858
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_531": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.03126257645096008,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185189,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "nist": 4.820497962650059,
        "bleu": 67.23344,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.79902,
            "fmeasure": 0.81566
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.725,
            "fmeasure": 0.68645
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.81439,
            "fmeasure": 0.70216
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.81439,
            "fmeasure": 0.70216
        },
        "nubia": {
            "semantic_relation": 4.26261,
            "contradiction": 0.27829,
            "irrelevancy": 62.55491,
            "logical_agreement": 37.1668,
            "grammar_ref": 5.72031,
            "grammar_hyp": 4.89117,
            "nubia_score": 0.79198
        },
        "meteor": 0.5577259071939104,
        "bleurt": 0.4181,
        "bertscore": {
            "precision": 0.93274,
            "recall": 0.97972,
            "f1": 0.94199
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_352": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 7.5,
        "median_pred_length": 18.5,
        "min_pred_length": 11,
        "max_pred_length": 26,
        "distinct-1": 0.8648648648648649,
        "vocab_size-1": 32,
        "unique-1": 27,
        "entropy-1": 4.939183095358682,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.20554393703030235,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.08488889758651327,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 6.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.90625,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.8125,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": 0.10689059560851857,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.09953567355091442,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.6470588235294118
        },
        "nist": 3.807345838421778,
        "bleu": 56.30582,
        "rouge1": {
            "precision": 0.67101,
            "recall": 0.5366,
            "fmeasure": 0.59607
        },
        "rouge2": {
            "precision": 0.50253,
            "recall": 0.37844,
            "fmeasure": 0.43156
        },
        "rougeL": {
            "precision": 0.67101,
            "recall": 0.51598,
            "fmeasure": 0.58299
        },
        "rougeLsum": {
            "precision": 0.67101,
            "recall": 0.51598,
            "fmeasure": 0.58299
        },
        "nubia": {
            "semantic_relation": 3.38959,
            "contradiction": 5.407,
            "irrelevancy": 23.03768,
            "logical_agreement": 71.55532,
            "grammar_ref": 4.82994,
            "grammar_hyp": 4.19911,
            "nubia_score": 0.52893
        },
        "meteor": 0.3936235630101921,
        "bleurt": 0.37756,
        "bertscore": {
            "precision": 0.93865,
            "recall": 0.89047,
            "f1": 0.91383
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_395": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.277613436819116,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.875
        },
        "nist": 2.8296710124237334,
        "bleu": 34.53156,
        "rouge1": {
            "precision": 0.76667,
            "recall": 0.85185,
            "fmeasure": 0.80702
        },
        "rouge2": {
            "precision": 0.59259,
            "recall": 0.66667,
            "fmeasure": 0.62745
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.74074,
            "fmeasure": 0.70175
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.74074,
            "fmeasure": 0.70175
        },
        "nubia": {
            "semantic_relation": 4.57202,
            "contradiction": 0.28796,
            "irrelevancy": 0.53489,
            "logical_agreement": 99.17714,
            "grammar_ref": 4.07798,
            "grammar_hyp": 4.47186,
            "nubia_score": 0.86077
        },
        "meteor": 0.3733732920052035,
        "bleurt": 0.45772,
        "bertscore": {
            "precision": 0.94116,
            "recall": 0.90575,
            "f1": 0.92004
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_585": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 6,
        "total_length": 83,
        "mean_pred_length": 13.833333333333334,
        "std_pred_length": 5.610010893235612,
        "median_pred_length": 12.5,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.5542168674698795,
        "vocab_size-1": 46,
        "unique-1": 34,
        "entropy-1": 5.080784274689553,
        "distinct-2": 0.7662337662337663,
        "vocab_size-2": 59,
        "unique-2": 49,
        "entropy-2": 5.720824202807793,
        "cond_entropy-2": 0.5901164276702798,
        "distinct-3": 0.8169014084507042,
        "vocab_size-3": 58,
        "unique-3": 51,
        "entropy-3": 5.719756626364102,
        "cond_entropy-3": -0.021900160596367544,
        "total_length-nopunct": 74,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 4.921607686744467,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.5540540540540541,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.914675831465099,
        "distinct-2-nopunct": 0.7647058823529411,
        "vocab_size-2-nopunct": 52,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.539165598380575,
        "cond_entropy-2-nopunct": 0.6688100272510562,
        "distinct-3-nopunct": 0.8225806451612904,
        "vocab_size-3-nopunct": 51,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.53847957634143,
        "cond_entropy-3-nopunct": -0.024316732441472744,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6923076923076923,
            "3": 0.8809523809523809
        },
        "nist": 5.02025643560413,
        "bleu": 61.39756,
        "rouge1": {
            "precision": 0.83365,
            "recall": 0.9007,
            "fmeasure": 0.85768
        },
        "rouge2": {
            "precision": 0.71014,
            "recall": 0.77999,
            "fmeasure": 0.73521
        },
        "rougeL": {
            "precision": 0.80587,
            "recall": 0.87955,
            "fmeasure": 0.83269
        },
        "rougeLsum": {
            "precision": 0.80587,
            "recall": 0.87955,
            "fmeasure": 0.83269
        },
        "nubia": {
            "semantic_relation": 4.09179,
            "contradiction": 18.69513,
            "irrelevancy": 24.50851,
            "logical_agreement": 56.79636,
            "grammar_ref": 4.0718,
            "grammar_hyp": 3.90415,
            "nubia_score": 0.7463
        },
        "meteor": 0.5031786499660648,
        "bleurt": 0.55628,
        "bertscore": {
            "precision": 0.95218,
            "recall": 0.96897,
            "f1": 0.96031
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_452": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.9057645846554525,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.19723710464117222,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.807763576417195,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.20971762763487736,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.5833333333333334
        },
        "nist": 2.586185595379058,
        "bleu": 8.32983,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.54167,
            "fmeasure": 0.61905
        },
        "rouge2": {
            "precision": 0.29412,
            "recall": 0.21739,
            "fmeasure": 0.25
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.59722,
            "fmeasure": 0.53016
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.59722,
            "fmeasure": 0.53016
        },
        "nubia": {
            "semantic_relation": 3.52823,
            "contradiction": 85.60185,
            "irrelevancy": 10.21482,
            "logical_agreement": 4.18333,
            "grammar_ref": 4.791,
            "grammar_hyp": 5.83005,
            "nubia_score": 0.37663
        },
        "meteor": 0.28460281007835175,
        "bleurt": -0.0213,
        "bertscore": {
            "precision": 0.90784,
            "recall": 0.89507,
            "f1": 0.89336
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_354": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "nist": 2.5092629064746266,
        "bleu": 26.91109,
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.7,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.44444,
            "fmeasure": 0.42105
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.7,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.7,
            "fmeasure": 0.66667
        },
        "nubia": {
            "semantic_relation": 4.89581,
            "contradiction": 0.24187,
            "irrelevancy": 0.44068,
            "logical_agreement": 99.31744,
            "grammar_ref": 5.11392,
            "grammar_hyp": 4.49466,
            "nubia_score": 1.0
        },
        "meteor": 0.40223127473947595,
        "bleurt": 0.73744,
        "bertscore": {
            "precision": 0.96402,
            "recall": 0.96871,
            "f1": 0.96636
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_455": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 6.0,
        "median_pred_length": 20.0,
        "min_pred_length": 14,
        "max_pred_length": 26,
        "distinct-1": 0.675,
        "vocab_size-1": 27,
        "unique-1": 21,
        "entropy-1": 4.472573883611434,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 36,
        "unique-2": 34,
        "entropy-2": 5.142664355548852,
        "cond_entropy-2": 0.6536899542443745,
        "distinct-3": 0.9722222222222222,
        "vocab_size-3": 35,
        "unique-3": 34,
        "entropy-3": 5.114369445886754,
        "cond_entropy-3": -0.050224734223495375,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 18.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6756756756756757,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.345286650736057,
        "distinct-2-nopunct": 0.9428571428571428,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 5.01499730265925,
        "cond_entropy-2-nopunct": 0.6527508043488662,
        "distinct-3-nopunct": 0.9696969696969697,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.9837880587523955,
        "cond_entropy-3-nopunct": -0.05458586728348292,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.8823529411764706
        },
        "nist": 2.934741527269918,
        "bleu": 32.2077,
        "rouge1": {
            "precision": 0.62019,
            "recall": 0.74818,
            "fmeasure": 0.64363
        },
        "rouge2": {
            "precision": 0.46014,
            "recall": 0.47724,
            "fmeasure": 0.44893
        },
        "rougeL": {
            "precision": 0.57265,
            "recall": 0.65925,
            "fmeasure": 0.58432
        },
        "rougeLsum": {
            "precision": 0.57265,
            "recall": 0.65925,
            "fmeasure": 0.58432
        },
        "nubia": {
            "semantic_relation": 3.62116,
            "contradiction": 9.69944,
            "irrelevancy": 40.65951,
            "logical_agreement": 49.64105,
            "grammar_ref": 5.06568,
            "grammar_hyp": 4.11,
            "nubia_score": 0.4501
        },
        "meteor": 0.3474090292580594,
        "bleurt": 0.01196,
        "bertscore": {
            "precision": 0.88954,
            "recall": 0.90734,
            "f1": 0.89783
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_355": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 65,
        "mean_pred_length": 16.25,
        "std_pred_length": 3.6996621467371855,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 50,
        "unique-1": 40,
        "entropy-1": 5.487677236072096,
        "distinct-2": 0.9508196721311475,
        "vocab_size-2": 58,
        "unique-2": 55,
        "entropy-2": 5.832376681825177,
        "cond_entropy-2": 0.24861358194694738,
        "distinct-3": 0.9824561403508771,
        "vocab_size-3": 56,
        "unique-3": 55,
        "entropy-3": 5.797802294866491,
        "cond_entropy-3": -0.027671884801653113,
        "total_length-nopunct": 57,
        "mean_pred_length-nopunct": 14.25,
        "std_pred_length-nopunct": 3.112474899497183,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.503856900091696,
        "distinct-2-nopunct": 0.9433962264150944,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.614712907393385,
        "cond_entropy-2-nopunct": 0.116820770627957,
        "distinct-3-nopunct": 0.9795918367346939,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.5738935175845965,
        "cond_entropy-3-nopunct": -0.03157795738676629,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.5,
            "3": 0.9361702127659575
        },
        "nist": 5.8345933893973285,
        "bleu": 72.6368,
        "rouge1": {
            "precision": 0.86504,
            "recall": 0.88396,
            "fmeasure": 0.86839
        },
        "rouge2": {
            "precision": 0.76007,
            "recall": 0.7452,
            "fmeasure": 0.74964
        },
        "rougeL": {
            "precision": 0.81959,
            "recall": 0.8423,
            "fmeasure": 0.82492
        },
        "rougeLsum": {
            "precision": 0.81959,
            "recall": 0.8423,
            "fmeasure": 0.82492
        },
        "nubia": {
            "semantic_relation": 4.78433,
            "contradiction": 0.26155,
            "irrelevancy": 25.46455,
            "logical_agreement": 74.2739,
            "grammar_ref": 4.25492,
            "grammar_hyp": 4.34339,
            "nubia_score": 0.92122
        },
        "meteor": 0.5630894343854947,
        "bleurt": 0.60034,
        "bertscore": {
            "precision": 0.97603,
            "recall": 0.98227,
            "f1": 0.97568
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_532": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 55,
        "mean_pred_length": 18.333333333333332,
        "std_pred_length": 1.247219128924647,
        "median_pred_length": 18.0,
        "min_pred_length": 17,
        "max_pred_length": 20,
        "distinct-1": 0.8545454545454545,
        "vocab_size-1": 47,
        "unique-1": 42,
        "entropy-1": 5.449274940679376,
        "distinct-2": 1.0,
        "vocab_size-2": 52,
        "unique-2": 52,
        "entropy-2": 5.700439718141095,
        "cond_entropy-2": 0.17888337008425823,
        "distinct-3": 1.0,
        "vocab_size-3": 49,
        "unique-3": 49,
        "entropy-3": 5.614709844115208,
        "cond_entropy-3": -0.08572987402588379,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 1.699673171197595,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9183673469387755,
        "vocab_size-1-nopunct": 45,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.436038670601668,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.5235619560570095,
        "cond_entropy-2-nopunct": 0.09917575329318432,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.426264754702098,
        "cond_entropy-3-nopunct": -0.09729720135491506,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.5,
            "3": 0.7169811320754716
        },
        "nist": 4.585169828906505,
        "bleu": 55.51081,
        "rouge1": {
            "precision": 0.86928,
            "recall": 0.78911,
            "fmeasure": 0.81967
        },
        "rouge2": {
            "precision": 0.71806,
            "recall": 0.71266,
            "fmeasure": 0.70904
        },
        "rougeL": {
            "precision": 0.80579,
            "recall": 0.74744,
            "fmeasure": 0.76935
        },
        "rougeLsum": {
            "precision": 0.80579,
            "recall": 0.74744,
            "fmeasure": 0.76935
        },
        "nubia": {
            "semantic_relation": 4.60198,
            "contradiction": 0.14371,
            "irrelevancy": 32.97522,
            "logical_agreement": 66.88107,
            "grammar_ref": 4.33326,
            "grammar_hyp": 4.38191,
            "nubia_score": 0.84529
        },
        "meteor": 0.42060163113702537,
        "bleurt": 0.56765,
        "bertscore": {
            "precision": 0.96445,
            "recall": 0.93761,
            "f1": 0.94993
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_492": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 39,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.943920288775949,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.7948717948717948,
        "vocab_size-1": 31,
        "unique-1": 27,
        "entropy-1": 4.797721449409584,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.2807634077603531,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.160246899469287,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8787878787878788,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.756219119227336,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": 0.17948897639429642,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.15200309344505,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.8571428571428571,
            "3": 0.5
        },
        "nist": 3.600404781887966,
        "bleu": 23.35641,
        "rouge1": {
            "precision": 0.7352,
            "recall": 0.60205,
            "fmeasure": 0.65281
        },
        "rouge2": {
            "precision": 0.4072,
            "recall": 0.34113,
            "fmeasure": 0.36521
        },
        "rougeL": {
            "precision": 0.52686,
            "recall": 0.44295,
            "fmeasure": 0.4733
        },
        "rougeLsum": {
            "precision": 0.52686,
            "recall": 0.44295,
            "fmeasure": 0.4733
        },
        "nubia": {
            "semantic_relation": 4.2312,
            "contradiction": 0.32242,
            "irrelevancy": 30.17787,
            "logical_agreement": 69.4997,
            "grammar_ref": 3.54742,
            "grammar_hyp": 4.01243,
            "nubia_score": 0.79561
        },
        "meteor": 0.34463321435259964,
        "bleurt": 0.28428,
        "bertscore": {
            "precision": 0.91067,
            "recall": 0.88477,
            "f1": 0.89693
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_456": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 1.5,
        "median_pred_length": 13.5,
        "min_pred_length": 12,
        "max_pred_length": 15,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 21,
        "unique-1": 18,
        "entropy-1": 4.1767526697769215,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.4333543065887285,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.0994705707972505,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.47142926517084527,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.75,
            "3": 0.8
        },
        "nist": 3.7320727454868776,
        "bleu": 29.01284,
        "rouge1": {
            "precision": 0.81169,
            "recall": 0.88462,
            "fmeasure": 0.84656
        },
        "rouge2": {
            "precision": 0.47949,
            "recall": 0.53889,
            "fmeasure": 0.50709
        },
        "rougeL": {
            "precision": 0.55628,
            "recall": 0.6204,
            "fmeasure": 0.58617
        },
        "rougeLsum": {
            "precision": 0.55628,
            "recall": 0.6204,
            "fmeasure": 0.58617
        },
        "nubia": {
            "semantic_relation": 4.57314,
            "contradiction": 0.15981,
            "irrelevancy": 51.73702,
            "logical_agreement": 48.10318,
            "grammar_ref": 3.96214,
            "grammar_hyp": 4.20662,
            "nubia_score": 0.86429
        },
        "meteor": 0.41618742829667965,
        "bleurt": 0.24681,
        "bertscore": {
            "precision": 0.93622,
            "recall": 0.93433,
            "f1": 0.93344
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_325": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 66,
        "mean_pred_length": 13.2,
        "std_pred_length": 5.114684741017769,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 20,
        "distinct-1": 0.7575757575757576,
        "vocab_size-1": 50,
        "unique-1": 42,
        "entropy-1": 5.440238013586835,
        "distinct-2": 0.9836065573770492,
        "vocab_size-2": 60,
        "unique-2": 59,
        "entropy-2": 5.897950452316981,
        "cond_entropy-2": 0.3169114560157508,
        "distinct-3": 1.0,
        "vocab_size-3": 56,
        "unique-3": 56,
        "entropy-3": 5.807354922057609,
        "cond_entropy-3": -0.08766812979099622,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 11.2,
        "std_pred_length-nopunct": 3.9698866482558417,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8214285714285714,
        "vocab_size-1-nopunct": 46,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.387537511266055,
        "distinct-2-nopunct": 0.9803921568627451,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.63320965569699,
        "cond_entropy-2-nopunct": 0.2868307141163801,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.5235619560570095,
        "cond_entropy-3-nopunct": -0.10538512504491752,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.5,
            "3": 0.8157894736842105
        },
        "nist": 4.481925873323747,
        "bleu": 44.4891,
        "rouge1": {
            "precision": 0.74806,
            "recall": 0.73882,
            "fmeasure": 0.73279
        },
        "rouge2": {
            "precision": 0.57365,
            "recall": 0.56497,
            "fmeasure": 0.55651
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.71595,
            "fmeasure": 0.68734
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.71595,
            "fmeasure": 0.68734
        },
        "nubia": {
            "semantic_relation": 4.06823,
            "contradiction": 11.98383,
            "irrelevancy": 28.71242,
            "logical_agreement": 59.30375,
            "grammar_ref": 5.12632,
            "grammar_hyp": 4.80777,
            "nubia_score": 0.68863
        },
        "meteor": 0.41938789211195177,
        "bleurt": 0.40967,
        "bertscore": {
            "precision": 0.9308,
            "recall": 0.92659,
            "f1": 0.92773
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_534": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 54,
        "mean_pred_length": 18.0,
        "std_pred_length": 4.242640687119285,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 24,
        "distinct-1": 0.8148148148148148,
        "vocab_size-1": 44,
        "unique-1": 38,
        "entropy-1": 5.3036925396338335,
        "distinct-2": 0.9607843137254902,
        "vocab_size-2": 49,
        "unique-2": 48,
        "entropy-2": 5.579192253693785,
        "cond_entropy-2": 0.2628249079342389,
        "distinct-3": 1.0,
        "vocab_size-3": 48,
        "unique-3": 48,
        "entropy-3": 5.5849625007211605,
        "cond_entropy-3": 0.01159731504473286,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 3.299831645537222,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8163265306122449,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.1582909058172435,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.420194836444761,
        "cond_entropy-2-nopunct": 0.2916703831252133,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.426264754702098,
        "cond_entropy-3-nopunct": 0.013281577765165604,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.7333333333333333,
            "3": 0.6363636363636364
        },
        "nist": 2.9752252464949165,
        "bleu": 21.74149,
        "rouge1": {
            "precision": 0.69949,
            "recall": 0.55773,
            "fmeasure": 0.61192
        },
        "rouge2": {
            "precision": 0.36386,
            "recall": 0.28151,
            "fmeasure": 0.31311
        },
        "rougeL": {
            "precision": 0.55592,
            "recall": 0.46579,
            "fmeasure": 0.50183
        },
        "rougeLsum": {
            "precision": 0.55592,
            "recall": 0.46579,
            "fmeasure": 0.50183
        },
        "nubia": {
            "semantic_relation": 3.73741,
            "contradiction": 6.09055,
            "irrelevancy": 49.57736,
            "logical_agreement": 44.33208,
            "grammar_ref": 3.79025,
            "grammar_hyp": 4.15539,
            "nubia_score": 0.56344
        },
        "meteor": 0.28701386686647123,
        "bleurt": 0.05896,
        "bertscore": {
            "precision": 0.8891,
            "recall": 0.88242,
            "f1": 0.88546
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_588": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 10,
        "unique-1": 6,
        "entropy-1": 3.2359263506290334,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 12,
        "unique-2": 11,
        "entropy-2": 3.5465935642949384,
        "cond_entropy-2": 0.35462325762194935,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": 0.05118944924673077,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 2.918295834054489,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.277613436819116,
        "cond_entropy-2-nopunct": 0.3290145724615955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": 0.06249647625006499,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.7
        },
        "nist": 3.16333702950726,
        "bleu": 61.15381,
        "rouge1": {
            "precision": 0.73077,
            "recall": 0.75962,
            "fmeasure": 0.74462
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.69697,
            "fmeasure": 0.68116
        },
        "rougeL": {
            "precision": 0.73077,
            "recall": 0.75962,
            "fmeasure": 0.74462
        },
        "rougeLsum": {
            "precision": 0.73077,
            "recall": 0.75962,
            "fmeasure": 0.74462
        },
        "nubia": {
            "semantic_relation": 4.92883,
            "contradiction": 20.1668,
            "irrelevancy": 3.38421,
            "logical_agreement": 76.44899,
            "grammar_ref": 3.96979,
            "grammar_hyp": 3.52993,
            "nubia_score": 0.86381
        },
        "meteor": 0.451369116507126,
        "bleurt": 0.77377,
        "bertscore": {
            "precision": 0.97782,
            "recall": 0.96474,
            "f1": 0.97123
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_357": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 8,
        "total_length": 122,
        "mean_pred_length": 15.25,
        "std_pred_length": 5.606915373001451,
        "median_pred_length": 12.5,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.6065573770491803,
        "vocab_size-1": 74,
        "unique-1": 57,
        "entropy-1": 5.829279989653509,
        "distinct-2": 0.868421052631579,
        "vocab_size-2": 99,
        "unique-2": 91,
        "entropy-2": 6.523379378066996,
        "cond_entropy-2": 0.5608683251088807,
        "distinct-3": 0.8867924528301887,
        "vocab_size-3": 94,
        "unique-3": 88,
        "entropy-3": 6.458775878969027,
        "cond_entropy-3": -0.041244205807547424,
        "total_length-nopunct": 102,
        "mean_pred_length-nopunct": 12.75,
        "std_pred_length-nopunct": 4.892596447695231,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6764705882352942,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.797343175636387,
        "distinct-2-nopunct": 0.8617021276595744,
        "vocab_size-2-nopunct": 81,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.229808798348042,
        "cond_entropy-2-nopunct": 0.496302402825297,
        "distinct-3-nopunct": 0.8837209302325582,
        "vocab_size-3-nopunct": 76,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 6.149817806901897,
        "cond_entropy-3-nopunct": -0.04977889346201078,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.68,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.125,
            "3": 0.7553191489361702
        },
        "nist": 5.4703204348546155,
        "bleu": 61.55164,
        "rouge1": {
            "precision": 0.87858,
            "recall": 0.82997,
            "fmeasure": 0.84919
        },
        "rouge2": {
            "precision": 0.76811,
            "recall": 0.73895,
            "fmeasure": 0.75057
        },
        "rougeL": {
            "precision": 0.84449,
            "recall": 0.80089,
            "fmeasure": 0.81829
        },
        "rougeLsum": {
            "precision": 0.84449,
            "recall": 0.80089,
            "fmeasure": 0.81829
        },
        "nubia": {
            "semantic_relation": 4.71657,
            "contradiction": 0.22215,
            "irrelevancy": 16.64886,
            "logical_agreement": 83.12899,
            "grammar_ref": 4.5568,
            "grammar_hyp": 4.45954,
            "nubia_score": 0.90463
        },
        "meteor": 0.4476527688433485,
        "bleurt": 0.69071,
        "bertscore": {
            "precision": 0.96335,
            "recall": 0.95323,
            "f1": 0.95806
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_328": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 6,
        "total_length": 105,
        "mean_pred_length": 17.5,
        "std_pred_length": 5.737304826019502,
        "median_pred_length": 18.0,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.780952380952381,
        "vocab_size-1": 82,
        "unique-1": 74,
        "entropy-1": 6.06278239391461,
        "distinct-2": 0.9797979797979798,
        "vocab_size-2": 97,
        "unique-2": 95,
        "entropy-2": 6.5889525796755795,
        "cond_entropy-2": 0.40898840533854924,
        "distinct-3": 1.0,
        "vocab_size-3": 93,
        "unique-3": 93,
        "entropy-3": 6.539158811108037,
        "cond_entropy-3": -0.04718705628340619,
        "total_length-nopunct": 94,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 4.818944098266987,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8191489361702128,
        "vocab_size-1-nopunct": 77,
        "unique-1-nopunct": 71,
        "entropy-1-nopunct": 6.01316488370336,
        "distinct-2-nopunct": 0.9772727272727273,
        "vocab_size-2-nopunct": 86,
        "unique-2-nopunct": 84,
        "entropy-2-nopunct": 6.41397707318276,
        "cond_entropy-2-nopunct": 0.4377274600230816,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 82,
        "unique-3-nopunct": 82,
        "entropy-3-nopunct": 6.357552004618087,
        "cond_entropy-3-nopunct": -0.053099126214335685,
        "msttr-100": 0.78,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.6363636363636364,
            "3": 0.8985507246376812
        },
        "nist": 5.783846888961601,
        "bleu": 62.4487,
        "rouge1": {
            "precision": 0.80639,
            "recall": 0.80694,
            "fmeasure": 0.80062
        },
        "rouge2": {
            "precision": 0.60194,
            "recall": 0.61217,
            "fmeasure": 0.60373
        },
        "rougeL": {
            "precision": 0.73385,
            "recall": 0.74329,
            "fmeasure": 0.73291
        },
        "rougeLsum": {
            "precision": 0.73385,
            "recall": 0.74329,
            "fmeasure": 0.73291
        },
        "nubia": {
            "semantic_relation": 4.66731,
            "contradiction": 3.82497,
            "irrelevancy": 34.62615,
            "logical_agreement": 61.54888,
            "grammar_ref": 4.71157,
            "grammar_hyp": 4.96191,
            "nubia_score": 0.81496
        },
        "meteor": 0.4796002765596578,
        "bleurt": 0.38973,
        "bertscore": {
            "precision": 0.94514,
            "recall": 0.93633,
            "f1": 0.93991
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_396": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 8,
        "total_length": 113,
        "mean_pred_length": 14.125,
        "std_pred_length": 2.4206145913796355,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 17,
        "distinct-1": 0.584070796460177,
        "vocab_size-1": 66,
        "unique-1": 44,
        "entropy-1": 5.6441271660472205,
        "distinct-2": 0.819047619047619,
        "vocab_size-2": 86,
        "unique-2": 69,
        "entropy-2": 6.333293136713734,
        "cond_entropy-2": 0.5501984884850407,
        "distinct-3": 0.8556701030927835,
        "vocab_size-3": 83,
        "unique-3": 69,
        "entropy-3": 6.311253048372705,
        "cond_entropy-3": -0.011239891973840177,
        "total_length-nopunct": 94,
        "mean_pred_length-nopunct": 11.75,
        "std_pred_length-nopunct": 2.7726341266023544,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.6702127659574468,
        "vocab_size-1-nopunct": 63,
        "unique-1-nopunct": 44,
        "entropy-1-nopunct": 5.720923660437205,
        "distinct-2-nopunct": 0.8255813953488372,
        "vocab_size-2-nopunct": 71,
        "unique-2-nopunct": 58,
        "entropy-2-nopunct": 6.054171731446285,
        "cond_entropy-2-nopunct": 0.3759146004267895,
        "distinct-3-nopunct": 0.8717948717948718,
        "vocab_size-3-nopunct": 68,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 6.028991962451998,
        "cond_entropy-3-nopunct": -0.01265740763472146,
        "msttr-100": 0.59,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.36585365853658536,
            "2": 0.7619047619047619,
            "3": 0.875
        },
        "nist": 5.8394942689066,
        "bleu": 62.2781,
        "rouge1": {
            "precision": 0.77357,
            "recall": 0.78431,
            "fmeasure": 0.77132
        },
        "rouge2": {
            "precision": 0.5876,
            "recall": 0.63643,
            "fmeasure": 0.60092
        },
        "rougeL": {
            "precision": 0.69266,
            "recall": 0.70907,
            "fmeasure": 0.69433
        },
        "rougeLsum": {
            "precision": 0.69266,
            "recall": 0.70907,
            "fmeasure": 0.69433
        },
        "nubia": {
            "semantic_relation": 4.02007,
            "contradiction": 24.66984,
            "irrelevancy": 23.73842,
            "logical_agreement": 51.59173,
            "grammar_ref": 5.12618,
            "grammar_hyp": 4.92859,
            "nubia_score": 0.6862
        },
        "meteor": 0.48087249742080523,
        "bleurt": 0.34643,
        "bertscore": {
            "precision": 0.96179,
            "recall": 0.95873,
            "f1": 0.95909
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_495": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 72,
        "mean_pred_length": 18.0,
        "std_pred_length": 4.06201920231798,
        "median_pred_length": 17.5,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.7638888888888888,
        "vocab_size-1": 55,
        "unique-1": 46,
        "entropy-1": 5.572431251322123,
        "distinct-2": 0.9852941176470589,
        "vocab_size-2": 67,
        "unique-2": 66,
        "entropy-2": 6.058051076544463,
        "cond_entropy-2": 0.41282754577522124,
        "distinct-3": 1.0,
        "vocab_size-3": 64,
        "unique-3": 64,
        "entropy-3": 6.0,
        "cond_entropy-3": -0.05621284125033941,
        "total_length-nopunct": 66,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 3.840572873934304,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7727272727272727,
        "vocab_size-1-nopunct": 51,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.464626505623757,
        "distinct-2-nopunct": 0.9838709677419355,
        "vocab_size-2-nopunct": 61,
        "unique-2-nopunct": 60,
        "entropy-2-nopunct": 5.921938245870744,
        "cond_entropy-2-nopunct": 0.45302315886340927,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.85798099512757,
        "cond_entropy-3-nopunct": -0.061732556638613253,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16,
            "2": 0.7333333333333333,
            "3": 0.8
        },
        "nist": 4.962614614462093,
        "bleu": 51.15845,
        "rouge1": {
            "precision": 0.80139,
            "recall": 0.72472,
            "fmeasure": 0.75876
        },
        "rouge2": {
            "precision": 0.58712,
            "recall": 0.53945,
            "fmeasure": 0.56005
        },
        "rougeL": {
            "precision": 0.69722,
            "recall": 0.62896,
            "fmeasure": 0.65936
        },
        "rougeLsum": {
            "precision": 0.69722,
            "recall": 0.62896,
            "fmeasure": 0.65936
        },
        "nubia": {
            "semantic_relation": 3.8976,
            "contradiction": 0.8373,
            "irrelevancy": 42.99263,
            "logical_agreement": 56.17007,
            "grammar_ref": 4.35502,
            "grammar_hyp": 4.54823,
            "nubia_score": 0.62707
        },
        "meteor": 0.4160409527506893,
        "bleurt": 0.23341,
        "bertscore": {
            "precision": 0.93776,
            "recall": 0.93179,
            "f1": 0.93004
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_399": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8181818181818182
        },
        "nist": 2.9200645816166895,
        "bleu": 40.01602,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.81818,
            "fmeasure": 0.78261
        },
        "rouge2": {
            "precision": 0.45455,
            "recall": 0.5,
            "fmeasure": 0.47619
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.81818,
            "fmeasure": 0.78261
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.81818,
            "fmeasure": 0.78261
        },
        "nubia": {
            "semantic_relation": 4.2091,
            "contradiction": 0.09211,
            "irrelevancy": 99.77518,
            "logical_agreement": 0.13271,
            "grammar_ref": 4.20968,
            "grammar_hyp": 4.04245,
            "nubia_score": 0.84814
        },
        "meteor": 0.3900874238333935,
        "bleurt": 0.10887,
        "bertscore": {
            "precision": 0.90149,
            "recall": 0.91854,
            "f1": 0.90994
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_205": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 12,
        "total_length": 181,
        "mean_pred_length": 15.083333333333334,
        "std_pred_length": 3.6846151615723572,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 23,
        "distinct-1": 0.6408839779005525,
        "vocab_size-1": 116,
        "unique-1": 93,
        "entropy-1": 6.381551643249935,
        "distinct-2": 0.9289940828402367,
        "vocab_size-2": 157,
        "unique-2": 147,
        "entropy-2": 7.249934022055392,
        "cond_entropy-2": 0.7226177818882203,
        "distinct-3": 0.9681528662420382,
        "vocab_size-3": 152,
        "unique-3": 147,
        "entropy-3": 7.230926481375701,
        "cond_entropy-3": -0.007470311566818905,
        "total_length-nopunct": 157,
        "mean_pred_length-nopunct": 13.083333333333334,
        "std_pred_length-nopunct": 3.5463204718255352,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7070063694267515,
        "vocab_size-1-nopunct": 111,
        "unique-1-nopunct": 92,
        "entropy-1-nopunct": 6.426101574822781,
        "distinct-2-nopunct": 0.9310344827586207,
        "vocab_size-2-nopunct": 135,
        "unique-2-nopunct": 127,
        "entropy-2-nopunct": 7.031565814123045,
        "cond_entropy-2-nopunct": 0.6635485847404203,
        "distinct-3-nopunct": 0.9774436090225563,
        "vocab_size-3-nopunct": 130,
        "unique-3-nopunct": 127,
        "entropy-3-nopunct": 7.01016965354631,
        "cond_entropy-3-nopunct": -0.015530601849632512,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.27586206896551724,
            "3": 0.7603305785123967
        },
        "nist": 5.285761212958927,
        "bleu": 39.60063,
        "rouge1": {
            "precision": 0.77046,
            "recall": 0.7132,
            "fmeasure": 0.7312
        },
        "rouge2": {
            "precision": 0.50136,
            "recall": 0.45916,
            "fmeasure": 0.47337
        },
        "rougeL": {
            "precision": 0.67044,
            "recall": 0.59685,
            "fmeasure": 0.62569
        },
        "rougeLsum": {
            "precision": 0.67044,
            "recall": 0.59685,
            "fmeasure": 0.62569
        },
        "nubia": {
            "semantic_relation": 4.43744,
            "contradiction": 6.78316,
            "irrelevancy": 5.95865,
            "logical_agreement": 87.25819,
            "grammar_ref": 4.24445,
            "grammar_hyp": 4.23166,
            "nubia_score": 0.82412
        },
        "meteor": 0.3580943044772803,
        "bleurt": 0.41347,
        "bertscore": {
            "precision": 0.94242,
            "recall": 0.93139,
            "f1": 0.93553
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_360": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 20,
        "total_length": 333,
        "mean_pred_length": 16.65,
        "std_pred_length": 5.703288525052892,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.5765765765765766,
        "vocab_size-1": 192,
        "unique-1": 146,
        "entropy-1": 6.954422686105294,
        "distinct-2": 0.9169329073482428,
        "vocab_size-2": 287,
        "unique-2": 267,
        "entropy-2": 8.103550706432264,
        "cond_entropy-2": 0.985244339532601,
        "distinct-3": 0.9795221843003413,
        "vocab_size-3": 287,
        "unique-3": 281,
        "entropy-3": 8.153801223022977,
        "cond_entropy-3": 0.05615277874082422,
        "total_length-nopunct": 292,
        "mean_pred_length-nopunct": 14.6,
        "std_pred_length-nopunct": 5.141984052872976,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6404109589041096,
        "vocab_size-1-nopunct": 187,
        "unique-1-nopunct": 145,
        "entropy-1-nopunct": 7.093688668935099,
        "distinct-2-nopunct": 0.9191176470588235,
        "vocab_size-2-nopunct": 250,
        "unique-2-nopunct": 236,
        "entropy-2-nopunct": 7.8967484920557665,
        "cond_entropy-2-nopunct": 0.852095688187515,
        "distinct-3-nopunct": 0.9841269841269841,
        "vocab_size-3-nopunct": 248,
        "unique-3-nopunct": 244,
        "entropy-3-nopunct": 7.945533891753895,
        "cond_entropy-3-nopunct": 0.05995320518976427,
        "msttr-100": 0.75333,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21621621621621623,
            "2": 0.5538461538461539,
            "3": 0.868421052631579
        },
        "nist": 6.450980268963633,
        "bleu": 55.78505,
        "rouge1": {
            "precision": 0.79537,
            "recall": 0.79889,
            "fmeasure": 0.79212
        },
        "rouge2": {
            "precision": 0.63032,
            "recall": 0.63723,
            "fmeasure": 0.6275
        },
        "rougeL": {
            "precision": 0.71342,
            "recall": 0.72404,
            "fmeasure": 0.71305
        },
        "rougeLsum": {
            "precision": 0.71342,
            "recall": 0.72404,
            "fmeasure": 0.71305
        },
        "nubia": {
            "semantic_relation": 4.31654,
            "contradiction": 6.3325,
            "irrelevancy": 10.44885,
            "logical_agreement": 83.21864,
            "grammar_ref": 4.44035,
            "grammar_hyp": 4.41012,
            "nubia_score": 0.7708
        },
        "meteor": 0.44812341560027363,
        "bleurt": 0.41837,
        "bertscore": {
            "precision": 0.94602,
            "recall": 0.94045,
            "f1": 0.94176
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_535": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8888888888888888
        },
        "nist": 2.2997963733835585,
        "bleu": 25.45094,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.88889,
            "fmeasure": 0.7619
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.5,
            "fmeasure": 0.42105
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.77778,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.77778,
            "fmeasure": 0.66667
        },
        "nubia": {
            "semantic_relation": 4.9615,
            "contradiction": 0.13809,
            "irrelevancy": 0.73786,
            "logical_agreement": 99.12406,
            "grammar_ref": 6.68645,
            "grammar_hyp": 5.21536,
            "nubia_score": 1.0
        },
        "meteor": 0.45933486691439784,
        "bleurt": 0.68493,
        "bertscore": {
            "precision": 0.90595,
            "recall": 0.94971,
            "f1": 0.92732
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_496": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 61,
        "mean_pred_length": 20.333333333333332,
        "std_pred_length": 4.988876515698588,
        "median_pred_length": 19.0,
        "min_pred_length": 15,
        "max_pred_length": 27,
        "distinct-1": 0.7704918032786885,
        "vocab_size-1": 47,
        "unique-1": 40,
        "entropy-1": 5.344271148860961,
        "distinct-2": 0.9827586206896551,
        "vocab_size-2": 57,
        "unique-2": 56,
        "entropy-2": 5.823498236506881,
        "cond_entropy-2": 0.47507878706153644,
        "distinct-3": 1.0,
        "vocab_size-3": 55,
        "unique-3": 55,
        "entropy-3": 5.7813597135246555,
        "cond_entropy-3": -0.04025764523927594,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 18.333333333333332,
        "std_pred_length-nopunct": 3.6817870057290873,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7818181818181819,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.203642667873432,
        "distinct-2-nopunct": 0.9807692307692307,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.661978179679556,
        "cond_entropy-2-nopunct": 0.49166534136292017,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.614709844115208,
        "cond_entropy-3-nopunct": -0.04491354749527154,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8095238095238095
        },
        "nist": 4.821492376983775,
        "bleu": 52.7508,
        "rouge1": {
            "precision": 0.76268,
            "recall": 0.77846,
            "fmeasure": 0.76975
        },
        "rouge2": {
            "precision": 0.53704,
            "recall": 0.54608,
            "fmeasure": 0.54102
        },
        "rougeL": {
            "precision": 0.65338,
            "recall": 0.6655,
            "fmeasure": 0.65878
        },
        "rougeLsum": {
            "precision": 0.65338,
            "recall": 0.6655,
            "fmeasure": 0.65878
        },
        "nubia": {
            "semantic_relation": 4.74295,
            "contradiction": 2.27437,
            "irrelevancy": 29.49121,
            "logical_agreement": 68.23442,
            "grammar_ref": 4.0888,
            "grammar_hyp": 4.25952,
            "nubia_score": 0.85224
        },
        "meteor": 0.4240380493646208,
        "bleurt": 0.51473,
        "bertscore": {
            "precision": 0.94862,
            "recall": 0.94703,
            "f1": 0.9478
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_590": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 3.559026084010437,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 21,
        "distinct-1": 0.7291666666666666,
        "vocab_size-1": 35,
        "unique-1": 28,
        "entropy-1": 4.938721875540869,
        "distinct-2": 0.9777777777777777,
        "vocab_size-2": 44,
        "unique-2": 43,
        "entropy-2": 5.447408651885229,
        "cond_entropy-2": 0.4461053179749718,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.051916625931866786,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 2.6246692913372702,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7674418604651163,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.8619702778069716,
        "distinct-2-nopunct": 0.975,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.271928094887364,
        "cond_entropy-2-nopunct": 0.4126558403294953,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.058420675204358556,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.8,
            "3": 0.7692307692307693
        },
        "nist": 3.8269430571811482,
        "bleu": 33.71921,
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.78212,
            "fmeasure": 0.68341
        },
        "rouge2": {
            "precision": 0.36676,
            "recall": 0.48679,
            "fmeasure": 0.41693
        },
        "rougeL": {
            "precision": 0.52991,
            "recall": 0.69681,
            "fmeasure": 0.59836
        },
        "rougeLsum": {
            "precision": 0.52991,
            "recall": 0.69681,
            "fmeasure": 0.59836
        },
        "nubia": {
            "semantic_relation": 4.05036,
            "contradiction": 4.53655,
            "irrelevancy": 42.10872,
            "logical_agreement": 53.35473,
            "grammar_ref": 4.63208,
            "grammar_hyp": 4.028,
            "nubia_score": 0.72849
        },
        "meteor": 0.41627957729280074,
        "bleurt": 0.27759,
        "bertscore": {
            "precision": 0.8974,
            "recall": 0.9311,
            "f1": 0.91393
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_498": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.2857142857142857
        },
        "nist": 0.6217195190750829,
        "bleu": 4.97419,
        "rouge1": {
            "precision": 0.53333,
            "recall": 0.25589,
            "fmeasure": 0.34524
        },
        "rouge2": {
            "precision": 0.18519,
            "recall": 0.0831,
            "fmeasure": 0.11453
        },
        "rougeL": {
            "precision": 0.2,
            "recall": 0.10582,
            "fmeasure": 0.13825
        },
        "rougeLsum": {
            "precision": 0.2,
            "recall": 0.10582,
            "fmeasure": 0.13825
        },
        "nubia": {
            "semantic_relation": 3.1321,
            "contradiction": 0.12006,
            "irrelevancy": 67.30597,
            "logical_agreement": 32.57397,
            "grammar_ref": 4.70322,
            "grammar_hyp": 7.00983,
            "nubia_score": 0.1835
        },
        "meteor": 0.1610407994576726,
        "bleurt": -0.89044,
        "bertscore": {
            "precision": 0.85106,
            "recall": 0.73403,
            "f1": 0.78823
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_329": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 6,
        "total_length": 120,
        "mean_pred_length": 20.0,
        "std_pred_length": 5.066228051190222,
        "median_pred_length": 22.5,
        "min_pred_length": 12,
        "max_pred_length": 25,
        "distinct-1": 0.7166666666666667,
        "vocab_size-1": 86,
        "unique-1": 72,
        "entropy-1": 6.121567004295799,
        "distinct-2": 0.9824561403508771,
        "vocab_size-2": 112,
        "unique-2": 111,
        "entropy-2": 6.791180474672092,
        "cond_entropy-2": 0.6091073394415492,
        "distinct-3": 1.0,
        "vocab_size-3": 108,
        "unique-3": 108,
        "entropy-3": 6.754887502163458,
        "cond_entropy-3": -0.03397577587012991,
        "total_length-nopunct": 114,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 5.196152422706632,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7368421052631579,
        "vocab_size-1-nopunct": 84,
        "unique-1-nopunct": 71,
        "entropy-1-nopunct": 6.108072553786761,
        "distinct-2-nopunct": 0.9814814814814815,
        "vocab_size-2-nopunct": 106,
        "unique-2-nopunct": 105,
        "entropy-2-nopunct": 6.710860766032314,
        "cond_entropy-2-nopunct": 0.643055848933239,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 102,
        "unique-3-nopunct": 102,
        "entropy-3-nopunct": 6.6724253419715,
        "cond_entropy-3-nopunct": -0.035845616053115446,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16981132075471697,
            "2": 0.7027027027027027,
            "3": 0.7142857142857143
        },
        "nist": 4.31635533063043,
        "bleu": 33.08924,
        "rouge1": {
            "precision": 0.59183,
            "recall": 0.62059,
            "fmeasure": 0.59953
        },
        "rouge2": {
            "precision": 0.3677,
            "recall": 0.37949,
            "fmeasure": 0.36855
        },
        "rougeL": {
            "precision": 0.45722,
            "recall": 0.51056,
            "fmeasure": 0.47786
        },
        "rougeLsum": {
            "precision": 0.45722,
            "recall": 0.51056,
            "fmeasure": 0.47786
        },
        "nubia": {
            "semantic_relation": 3.90816,
            "contradiction": 10.69894,
            "irrelevancy": 43.33784,
            "logical_agreement": 45.96322,
            "grammar_ref": 4.80564,
            "grammar_hyp": 4.38868,
            "nubia_score": 0.67752
        },
        "meteor": 0.33507441800827925,
        "bleurt": -0.0636,
        "bertscore": {
            "precision": 0.89329,
            "recall": 0.91075,
            "f1": 0.90157
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_207": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 38,
        "mean_pred_length": 12.666666666666666,
        "std_pred_length": 1.8856180831641267,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.868421052631579,
        "vocab_size-1": 33,
        "unique-1": 29,
        "entropy-1": 4.964904158123496,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.05278407492995249,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.12928301694496638,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 11.333333333333334,
        "std_pred_length-nopunct": 2.357022603955158,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9117647058823529,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.910992253015044,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.060281856233310095,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.14684138832927116,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.4444444444444444,
            "3": 0.8636363636363636
        },
        "nist": 3.86718369447706,
        "bleu": 56.6323,
        "rouge1": {
            "precision": 0.68849,
            "recall": 0.79783,
            "fmeasure": 0.71993
        },
        "rouge2": {
            "precision": 0.47863,
            "recall": 0.46389,
            "fmeasure": 0.4696
        },
        "rougeL": {
            "precision": 0.64881,
            "recall": 0.76159,
            "fmeasure": 0.68237
        },
        "rougeLsum": {
            "precision": 0.64881,
            "recall": 0.76159,
            "fmeasure": 0.68237
        },
        "nubia": {
            "semantic_relation": 4.07924,
            "contradiction": 0.59565,
            "irrelevancy": 44.18963,
            "logical_agreement": 55.21472,
            "grammar_ref": 5.944,
            "grammar_hyp": 5.79375,
            "nubia_score": 0.70165
        },
        "meteor": 0.399293385846686,
        "bleurt": 0.30665,
        "bertscore": {
            "precision": 0.90681,
            "recall": 0.92821,
            "f1": 0.91639
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_400": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 10,
        "total_length": 162,
        "mean_pred_length": 16.2,
        "std_pred_length": 5.36283507111677,
        "median_pred_length": 16.5,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 108,
        "unique-1": 88,
        "entropy-1": 6.345186867639134,
        "distinct-2": 0.9605263157894737,
        "vocab_size-2": 146,
        "unique-2": 140,
        "entropy-2": 7.1689801450225135,
        "cond_entropy-2": 0.7313369047021656,
        "distinct-3": 0.9859154929577465,
        "vocab_size-3": 140,
        "unique-3": 138,
        "entropy-3": 7.121578105420181,
        "cond_entropy-3": -0.04184236576988943,
        "total_length-nopunct": 145,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 5.181698563212646,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7172413793103448,
        "vocab_size-1-nopunct": 104,
        "unique-1-nopunct": 86,
        "entropy-1-nopunct": 6.369674997219335,
        "distinct-2-nopunct": 0.9555555555555556,
        "vocab_size-2-nopunct": 129,
        "unique-2-nopunct": 123,
        "entropy-2-nopunct": 6.987926708161966,
        "cond_entropy-2-nopunct": 0.670861643742296,
        "distinct-3-nopunct": 0.984,
        "vocab_size-3-nopunct": 123,
        "unique-3-nopunct": 121,
        "entropy-3-nopunct": 6.933784284662096,
        "cond_entropy-3-nopunct": -0.04703131238874401,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.30434782608695654,
            "2": 0.5925925925925926,
            "3": 0.8
        },
        "nist": 5.7976240231177,
        "bleu": 49.84127,
        "rouge1": {
            "precision": 0.73792,
            "recall": 0.75404,
            "fmeasure": 0.72657
        },
        "rouge2": {
            "precision": 0.48149,
            "recall": 0.44284,
            "fmeasure": 0.45166
        },
        "rougeL": {
            "precision": 0.59941,
            "recall": 0.57547,
            "fmeasure": 0.57677
        },
        "rougeLsum": {
            "precision": 0.59941,
            "recall": 0.57547,
            "fmeasure": 0.57677
        },
        "nubia": {
            "semantic_relation": 4.17236,
            "contradiction": 1.62994,
            "irrelevancy": 32.8712,
            "logical_agreement": 65.49886,
            "grammar_ref": 5.10223,
            "grammar_hyp": 5.21436,
            "nubia_score": 0.7053
        },
        "meteor": 0.3929206080075103,
        "bleurt": 0.21028,
        "bertscore": {
            "precision": 0.91073,
            "recall": 0.91214,
            "f1": 0.90915
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_459": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 6.0,
        "median_pred_length": 18.0,
        "min_pred_length": 12,
        "max_pred_length": 24,
        "distinct-1": 0.75,
        "vocab_size-1": 27,
        "unique-1": 20,
        "entropy-1": 4.614369445886755,
        "distinct-2": 0.9411764705882353,
        "vocab_size-2": 32,
        "unique-2": 30,
        "entropy-2": 4.969815782426808,
        "cond_entropy-2": 0.3293025456903801,
        "distinct-3": 0.96875,
        "vocab_size-3": 31,
        "unique-3": 30,
        "entropy-3": 4.9375,
        "cond_entropy-3": -0.02496284125033941,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 6.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.4375,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.773557262275186,
        "cond_entropy-2-nopunct": 0.3402239289418519,
        "distinct-3-nopunct": 0.9642857142857143,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.735926350629034,
        "cond_entropy-3-nopunct": -0.028107102122342933,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.9583333333333334
        },
        "nist": 5.733962710971957,
        "bleu": 95.99769,
        "rouge1": {
            "precision": 0.99167,
            "recall": 0.94621,
            "fmeasure": 0.96786
        },
        "rouge2": {
            "precision": 0.91813,
            "recall": 0.87368,
            "fmeasure": 0.89474
        },
        "rougeL": {
            "precision": 0.99167,
            "recall": 0.94621,
            "fmeasure": 0.96786
        },
        "rougeLsum": {
            "precision": 0.99167,
            "recall": 0.94621,
            "fmeasure": 0.96786
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.50686,
            "irrelevancy": 0.67443,
            "logical_agreement": 98.81871,
            "grammar_ref": 3.53925,
            "grammar_hyp": 3.48018,
            "nubia_score": 0.98386
        },
        "meteor": 0.6560757668682714,
        "bleurt": 0.79176,
        "bertscore": {
            "precision": 0.99581,
            "recall": 0.99056,
            "f1": 0.99317
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_414": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 0.5,
        "median_pred_length": 15.5,
        "min_pred_length": 15,
        "max_pred_length": 16,
        "distinct-1": 0.8709677419354839,
        "vocab_size-1": 27,
        "unique-1": 24,
        "entropy-1": 4.6717805845106355,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.13671183998771327,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8928571428571429,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.5661089398374815,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.15288816155131352,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.36363636363636365,
            "3": 0.4444444444444444
        },
        "nist": 2.5703694668638675,
        "bleu": 8.52161,
        "rouge1": {
            "precision": 0.42619,
            "recall": 0.47733,
            "fmeasure": 0.4447
        },
        "rouge2": {
            "precision": 0.16941,
            "recall": 0.1896,
            "fmeasure": 0.17785
        },
        "rougeL": {
            "precision": 0.40238,
            "recall": 0.46286,
            "fmeasure": 0.42657
        },
        "rougeLsum": {
            "precision": 0.40238,
            "recall": 0.46286,
            "fmeasure": 0.42657
        },
        "nubia": {
            "semantic_relation": 3.66827,
            "contradiction": 0.22574,
            "irrelevancy": 48.50012,
            "logical_agreement": 51.27414,
            "grammar_ref": 4.46073,
            "grammar_hyp": 4.38331,
            "nubia_score": 0.59351
        },
        "meteor": 0.23921263466079126,
        "bleurt": 0.10404,
        "bertscore": {
            "precision": 0.87354,
            "recall": 0.86201,
            "f1": 0.86198
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_330": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 7,
        "total_length": 119,
        "mean_pred_length": 17.0,
        "std_pred_length": 4.174754056057845,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 26,
        "distinct-1": 0.6638655462184874,
        "vocab_size-1": 79,
        "unique-1": 65,
        "entropy-1": 5.931764326886701,
        "distinct-2": 0.9464285714285714,
        "vocab_size-2": 106,
        "unique-2": 100,
        "entropy-2": 6.7002120649147345,
        "cond_entropy-2": 0.690158443837168,
        "distinct-3": 0.9809523809523809,
        "vocab_size-3": 103,
        "unique-3": 101,
        "entropy-3": 6.676150279570876,
        "cond_entropy-3": -0.016918928201005594,
        "total_length-nopunct": 108,
        "mean_pred_length-nopunct": 15.428571428571429,
        "std_pred_length-nopunct": 4.403152859263554,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7129629629629629,
        "vocab_size-1-nopunct": 77,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 5.944850988687869,
        "distinct-2-nopunct": 0.9405940594059405,
        "vocab_size-2-nopunct": 95,
        "unique-2-nopunct": 89,
        "entropy-2-nopunct": 6.5393996015636615,
        "cond_entropy-2-nopunct": 0.6209867870770795,
        "distinct-3-nopunct": 0.9787234042553191,
        "vocab_size-3-nopunct": 92,
        "unique-3-nopunct": 90,
        "entropy-3-nopunct": 6.512035660188261,
        "cond_entropy-3-nopunct": -0.03979284384011483,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.72,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.7142857142857143,
            "3": 0.7246376811594203
        },
        "nist": 4.898987163065689,
        "bleu": 46.94159,
        "rouge1": {
            "precision": 0.74075,
            "recall": 0.65344,
            "fmeasure": 0.68702
        },
        "rouge2": {
            "precision": 0.49787,
            "recall": 0.42725,
            "fmeasure": 0.45453
        },
        "rougeL": {
            "precision": 0.66002,
            "recall": 0.58986,
            "fmeasure": 0.61647
        },
        "rougeLsum": {
            "precision": 0.66002,
            "recall": 0.58986,
            "fmeasure": 0.61647
        },
        "nubia": {
            "semantic_relation": 3.73902,
            "contradiction": 28.75923,
            "irrelevancy": 15.3367,
            "logical_agreement": 55.90406,
            "grammar_ref": 5.20043,
            "grammar_hyp": 4.71912,
            "nubia_score": 0.58509
        },
        "meteor": 0.3602206617182558,
        "bleurt": -0.02902,
        "bertscore": {
            "precision": 0.9247,
            "recall": 0.90573,
            "f1": 0.91367
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_500": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 47,
        "mean_pred_length": 23.5,
        "std_pred_length": 3.5,
        "median_pred_length": 23.5,
        "min_pred_length": 20,
        "max_pred_length": 27,
        "distinct-1": 0.7659574468085106,
        "vocab_size-1": 36,
        "unique-1": 26,
        "entropy-1": 5.070442309078416,
        "distinct-2": 0.9777777777777777,
        "vocab_size-2": 44,
        "unique-2": 43,
        "entropy-2": 5.447408651885229,
        "cond_entropy-2": 0.3540395224778921,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.01907671372059984,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8205128205128205,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.907071770088826,
        "distinct-2-nopunct": 0.972972972972973,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.1553993115749,
        "cond_entropy-2-nopunct": 0.26877783601436245,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.023027491541126162,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7741935483870968
        },
        "nist": 3.997680196495234,
        "bleu": 44.466,
        "rouge1": {
            "precision": 0.6377,
            "recall": 0.63536,
            "fmeasure": 0.63498
        },
        "rouge2": {
            "precision": 0.41915,
            "recall": 0.39229,
            "fmeasure": 0.40367
        },
        "rougeL": {
            "precision": 0.6377,
            "recall": 0.63049,
            "fmeasure": 0.63218
        },
        "rougeLsum": {
            "precision": 0.6377,
            "recall": 0.63049,
            "fmeasure": 0.63218
        },
        "nubia": {
            "semantic_relation": 3.20321,
            "contradiction": 47.6425,
            "irrelevancy": 2.70475,
            "logical_agreement": 49.65276,
            "grammar_ref": 5.38335,
            "grammar_hyp": 5.19948,
            "nubia_score": 0.50314
        },
        "meteor": 0.3624814926198504,
        "bleurt": 0.04724,
        "bertscore": {
            "precision": 0.89305,
            "recall": 0.90448,
            "f1": 0.89744
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_402": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 62,
        "mean_pred_length": 20.666666666666668,
        "std_pred_length": 4.496912521077347,
        "median_pred_length": 21.0,
        "min_pred_length": 15,
        "max_pred_length": 26,
        "distinct-1": 0.8225806451612904,
        "vocab_size-1": 51,
        "unique-1": 47,
        "entropy-1": 5.443688496606177,
        "distinct-2": 0.9830508474576272,
        "vocab_size-2": 58,
        "unique-2": 57,
        "entropy-2": 5.848744744277091,
        "cond_entropy-2": 0.4310142721004442,
        "distinct-3": 1.0,
        "vocab_size-3": 56,
        "unique-3": 56,
        "entropy-3": 5.807354922057609,
        "cond_entropy-3": -0.03957384158995153,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 3.265986323710904,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9074074074074074,
        "vocab_size-1-nopunct": 49,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.532665279941245,
        "distinct-2-nopunct": 0.9803921568627451,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.63320965569699,
        "cond_entropy-2-nopunct": 0.11361627118057613,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.5849625007211605,
        "cond_entropy-3-nopunct": -0.04579617458367275,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6825396825396826
        },
        "nist": 4.036277037113842,
        "bleu": 40.77751,
        "rouge1": {
            "precision": 0.8177,
            "recall": 0.64091,
            "fmeasure": 0.71751
        },
        "rouge2": {
            "precision": 0.59542,
            "recall": 0.44747,
            "fmeasure": 0.5094
        },
        "rougeL": {
            "precision": 0.7874,
            "recall": 0.60431,
            "fmeasure": 0.68199
        },
        "rougeLsum": {
            "precision": 0.7874,
            "recall": 0.60431,
            "fmeasure": 0.68199
        },
        "nubia": {
            "semantic_relation": 4.49708,
            "contradiction": 38.15279,
            "irrelevancy": 18.2264,
            "logical_agreement": 43.62081,
            "grammar_ref": 3.87101,
            "grammar_hyp": 3.84503,
            "nubia_score": 0.79179
        },
        "meteor": 0.35295934415989627,
        "bleurt": 0.27079,
        "bertscore": {
            "precision": 0.93325,
            "recall": 0.89625,
            "f1": 0.91419
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_332": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "nist": 1.8012607652313612,
        "bleu": 22.64094,
        "rouge1": {
            "precision": 0.90476,
            "recall": 0.86111,
            "fmeasure": 0.861
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.53333,
            "fmeasure": 0.48485
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.66667,
            "fmeasure": 0.61538
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.66667,
            "fmeasure": 0.61538
        },
        "nubia": {
            "semantic_relation": 3.9837,
            "contradiction": 0.31096,
            "irrelevancy": 33.6074,
            "logical_agreement": 66.08165,
            "grammar_ref": 6.47099,
            "grammar_hyp": 7.23317,
            "nubia_score": 0.62051
        },
        "meteor": 0.4000024264613498,
        "bleurt": 0.11852,
        "bertscore": {
            "precision": 0.91451,
            "recall": 0.90549,
            "f1": 0.90998
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_208": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 23,
        "total_length": 388,
        "mean_pred_length": 16.869565217391305,
        "std_pred_length": 4.830198013999255,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.5541237113402062,
        "vocab_size-1": 215,
        "unique-1": 170,
        "entropy-1": 6.99564208047758,
        "distinct-2": 0.8849315068493151,
        "vocab_size-2": 323,
        "unique-2": 300,
        "entropy-2": 8.207442248798449,
        "cond_entropy-2": 1.0508417122329772,
        "distinct-3": 0.9766081871345029,
        "vocab_size-3": 334,
        "unique-3": 327,
        "entropy-3": 8.368861615756757,
        "cond_entropy-3": 0.16213355354347989,
        "total_length-nopunct": 344,
        "mean_pred_length-nopunct": 14.956521739130435,
        "std_pred_length-nopunct": 4.338686045031778,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6075581395348837,
        "vocab_size-1-nopunct": 209,
        "unique-1-nopunct": 167,
        "entropy-1-nopunct": 7.109803441818326,
        "distinct-2-nopunct": 0.8909657320872274,
        "vocab_size-2-nopunct": 286,
        "unique-2-nopunct": 267,
        "entropy-2-nopunct": 8.032602663721946,
        "cond_entropy-2-nopunct": 0.9555834047515205,
        "distinct-3-nopunct": 0.9832214765100671,
        "vocab_size-3-nopunct": 293,
        "unique-3-nopunct": 288,
        "entropy-3-nopunct": 8.185611473482265,
        "cond_entropy-3-nopunct": 0.14687811995321254,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.74333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.639344262295082,
            "3": 0.7372881355932204
        },
        "nist": 6.0375708395677705,
        "bleu": 40.64723,
        "rouge1": {
            "precision": 0.73331,
            "recall": 0.75981,
            "fmeasure": 0.73926
        },
        "rouge2": {
            "precision": 0.49064,
            "recall": 0.51199,
            "fmeasure": 0.49649
        },
        "rougeL": {
            "precision": 0.61513,
            "recall": 0.65249,
            "fmeasure": 0.62622
        },
        "rougeLsum": {
            "precision": 0.61513,
            "recall": 0.65249,
            "fmeasure": 0.62622
        },
        "nubia": {
            "semantic_relation": 4.30421,
            "contradiction": 7.1875,
            "irrelevancy": 34.14327,
            "logical_agreement": 58.66923,
            "grammar_ref": 4.22562,
            "grammar_hyp": 4.05812,
            "nubia_score": 0.77705
        },
        "meteor": 0.3965422837134498,
        "bleurt": 0.22641,
        "bertscore": {
            "precision": 0.91399,
            "recall": 0.91656,
            "f1": 0.913
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_460": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 55,
        "mean_pred_length": 13.75,
        "std_pred_length": 4.264680527307995,
        "median_pred_length": 13.5,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.7636363636363637,
        "vocab_size-1": 42,
        "unique-1": 34,
        "entropy-1": 5.231093122497558,
        "distinct-2": 0.8823529411764706,
        "vocab_size-2": 45,
        "unique-2": 40,
        "entropy-2": 5.4223295085957455,
        "cond_entropy-2": 0.07753180500226613,
        "distinct-3": 0.9361702127659575,
        "vocab_size-3": 44,
        "unique-3": 41,
        "entropy-3": 5.426929277209555,
        "cond_entropy-3": 0.025884520390471046,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.9370039370059056,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7916666666666666,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.121115365169276,
        "distinct-2-nopunct": 0.8636363636363636,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.169547811769943,
        "cond_entropy-2-nopunct": 0.05457849299809049,
        "distinct-3-nopunct": 0.925,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.171928094887363,
        "cond_entropy-3-nopunct": 0.0313686638041517,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9387755102040817
        },
        "nist": 5.568493488866189,
        "bleu": 88.72965,
        "rouge1": {
            "precision": 0.95833,
            "recall": 0.94231,
            "fmeasure": 0.95
        },
        "rouge2": {
            "precision": 0.90909,
            "recall": 0.89583,
            "fmeasure": 0.90217
        },
        "rougeL": {
            "precision": 0.95833,
            "recall": 0.94231,
            "fmeasure": 0.95
        },
        "rougeLsum": {
            "precision": 0.95833,
            "recall": 0.94231,
            "fmeasure": 0.95
        },
        "nubia": {
            "semantic_relation": 4.97356,
            "contradiction": 0.47127,
            "irrelevancy": 0.65888,
            "logical_agreement": 98.86985,
            "grammar_ref": 5.0449,
            "grammar_hyp": 5.09026,
            "nubia_score": 0.97561
        },
        "meteor": 0.6320486238977993,
        "bleurt": 0.92747,
        "bertscore": {
            "precision": 0.98953,
            "recall": 0.98667,
            "f1": 0.98809
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_209": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666
        },
        "nist": 1.0797518930990786,
        "bleu": 7.76856,
        "rouge1": {
            "precision": 0.36364,
            "recall": 0.66667,
            "fmeasure": 0.47059
        },
        "rouge2": {
            "precision": 0.1,
            "recall": 0.2,
            "fmeasure": 0.13333
        },
        "rougeL": {
            "precision": 0.18182,
            "recall": 0.33333,
            "fmeasure": 0.23529
        },
        "rougeLsum": {
            "precision": 0.18182,
            "recall": 0.33333,
            "fmeasure": 0.23529
        },
        "nubia": {
            "semantic_relation": 2.87306,
            "contradiction": 15.88307,
            "irrelevancy": 83.72316,
            "logical_agreement": 0.39377,
            "grammar_ref": 6.80479,
            "grammar_hyp": 6.45912,
            "nubia_score": 0.24377
        },
        "meteor": 0.2929047000066177,
        "bleurt": -0.92386,
        "bertscore": {
            "precision": 0.80713,
            "recall": 0.85805,
            "f1": 0.83181
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_333": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322734,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.875
        },
        "nist": 4.00193538757769,
        "bleu": 81.96501,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.96
        },
        "rouge2": {
            "precision": 0.90909,
            "recall": 0.83333,
            "fmeasure": 0.86957
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.96
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.96
        },
        "nubia": {
            "semantic_relation": 4.91472,
            "contradiction": 0.30946,
            "irrelevancy": 2.79721,
            "logical_agreement": 96.89333,
            "grammar_ref": 3.61542,
            "grammar_hyp": 3.03745,
            "nubia_score": 1.0
        },
        "meteor": 0.5249299242820813,
        "bleurt": 0.86304,
        "bertscore": {
            "precision": 0.99614,
            "recall": 0.98503,
            "f1": 0.99055
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_504": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 86,
        "mean_pred_length": 17.2,
        "std_pred_length": 4.445222154178573,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.7093023255813954,
        "vocab_size-1": 61,
        "unique-1": 51,
        "entropy-1": 5.585117121822595,
        "distinct-2": 0.9629629629629629,
        "vocab_size-2": 78,
        "unique-2": 75,
        "entropy-2": 6.26577592881054,
        "cond_entropy-2": 0.5892526056294475,
        "distinct-3": 0.9868421052631579,
        "vocab_size-3": 75,
        "unique-3": 74,
        "entropy-3": 6.221611723969907,
        "cond_entropy-3": -0.03929091049367099,
        "total_length-nopunct": 80,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 4.33589667773576,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7375,
        "vocab_size-1-nopunct": 59,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.562814895472351,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 72,
        "unique-2-nopunct": 69,
        "entropy-2-nopunct": 6.148818690495889,
        "cond_entropy-2-nopunct": 0.6232780083178595,
        "distinct-3-nopunct": 0.9857142857142858,
        "vocab_size-3-nopunct": 69,
        "unique-3-nopunct": 68,
        "entropy-3-nopunct": 6.100711588373543,
        "cond_entropy-3-nopunct": -0.05667853069377157,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.0,
            "3": 0.7428571428571429
        },
        "nist": 4.726191890704764,
        "bleu": 35.42925,
        "rouge1": {
            "precision": 0.77739,
            "recall": 0.73559,
            "fmeasure": 0.75363
        },
        "rouge2": {
            "precision": 0.52385,
            "recall": 0.48016,
            "fmeasure": 0.49926
        },
        "rougeL": {
            "precision": 0.61908,
            "recall": 0.57522,
            "fmeasure": 0.59344
        },
        "rougeLsum": {
            "precision": 0.61908,
            "recall": 0.57522,
            "fmeasure": 0.59344
        },
        "nubia": {
            "semantic_relation": 4.67365,
            "contradiction": 0.83844,
            "irrelevancy": 22.45957,
            "logical_agreement": 76.70199,
            "grammar_ref": 4.46418,
            "grammar_hyp": 4.8461,
            "nubia_score": 0.79994
        },
        "meteor": 0.3803635829657731,
        "bleurt": 0.28959,
        "bertscore": {
            "precision": 0.93405,
            "recall": 0.92153,
            "f1": 0.92764
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_335": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 55,
        "mean_pred_length": 13.75,
        "std_pred_length": 4.322904116447646,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 19,
        "distinct-1": 0.7090909090909091,
        "vocab_size-1": 39,
        "unique-1": 32,
        "entropy-1": 5.033733977547134,
        "distinct-2": 1.0,
        "vocab_size-2": 51,
        "unique-2": 51,
        "entropy-2": 5.6724253419715005,
        "cond_entropy-2": 0.5404659319520079,
        "distinct-3": 1.0,
        "vocab_size-3": 47,
        "unique-3": 47,
        "entropy-3": 5.55458885167764,
        "cond_entropy-3": -0.11783649029385802,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 4.123105625617661,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7708333333333334,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 4.994034834541985,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.4594316186372955,
        "cond_entropy-2-nopunct": 0.48309560600430307,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.13750352374993507,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.9230769230769231,
            "3": 0.875
        },
        "nist": 5.091601883613467,
        "bleu": 62.57922,
        "rouge1": {
            "precision": 0.83186,
            "recall": 0.89455,
            "fmeasure": 0.85533
        },
        "rouge2": {
            "precision": 0.67917,
            "recall": 0.73095,
            "fmeasure": 0.69788
        },
        "rougeL": {
            "precision": 0.80409,
            "recall": 0.87603,
            "fmeasure": 0.83191
        },
        "rougeLsum": {
            "precision": 0.80409,
            "recall": 0.87603,
            "fmeasure": 0.83191
        },
        "nubia": {
            "semantic_relation": 4.5325,
            "contradiction": 18.3196,
            "irrelevancy": 30.81608,
            "logical_agreement": 50.86432,
            "grammar_ref": 5.05046,
            "grammar_hyp": 5.25047,
            "nubia_score": 0.79137
        },
        "meteor": 0.4942854592268962,
        "bleurt": 0.57428,
        "bertscore": {
            "precision": 0.96107,
            "recall": 0.97134,
            "f1": 0.96601
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_364": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 51,
        "mean_pred_length": 12.75,
        "std_pred_length": 4.9180788932265,
        "median_pred_length": 10.5,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.803921568627451,
        "vocab_size-1": 41,
        "unique-1": 35,
        "entropy-1": 5.2114493614945,
        "distinct-2": 0.9574468085106383,
        "vocab_size-2": 45,
        "unique-2": 43,
        "entropy-2": 5.469482468698917,
        "cond_entropy-2": 0.12705233958543846,
        "distinct-3": 0.9767441860465116,
        "vocab_size-3": 42,
        "unique-3": 41,
        "entropy-3": 5.379753126795121,
        "cond_entropy-3": -0.08181246906856265,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 3.6742346141747673,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8409090909090909,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.1069367321753205,
        "distinct-2-nopunct": 0.95,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.221928094887364,
        "cond_entropy-2-nopunct": 0.15024085135823842,
        "distinct-3-nopunct": 0.9722222222222222,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.114369445886754,
        "cond_entropy-3-nopunct": -0.09644753788949416,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.5
        },
        "nist": 3.107525545812433,
        "bleu": 23.95923,
        "rouge1": {
            "precision": 0.69653,
            "recall": 0.55337,
            "fmeasure": 0.59422
        },
        "rouge2": {
            "precision": 0.4365,
            "recall": 0.34177,
            "fmeasure": 0.36587
        },
        "rougeL": {
            "precision": 0.6088,
            "recall": 0.49816,
            "fmeasure": 0.52771
        },
        "rougeLsum": {
            "precision": 0.6088,
            "recall": 0.49816,
            "fmeasure": 0.52771
        },
        "nubia": {
            "semantic_relation": 4.01496,
            "contradiction": 8.4212,
            "irrelevancy": 45.02767,
            "logical_agreement": 46.55113,
            "grammar_ref": 4.84918,
            "grammar_hyp": 5.161,
            "nubia_score": 0.62702
        },
        "meteor": 0.27954827119482945,
        "bleurt": 0.0806,
        "bertscore": {
            "precision": 0.92539,
            "recall": 0.89863,
            "f1": 0.90991
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_210": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 31,
        "total_length": 491,
        "mean_pred_length": 15.838709677419354,
        "std_pred_length": 4.89302844538285,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.5641547861507128,
        "vocab_size-1": 277,
        "unique-1": 215,
        "entropy-1": 7.372224006677519,
        "distinct-2": 0.9043478260869565,
        "vocab_size-2": 416,
        "unique-2": 391,
        "entropy-2": 8.604199358640725,
        "cond_entropy-2": 1.0257179608269764,
        "distinct-3": 0.9696969696969697,
        "vocab_size-3": 416,
        "unique-3": 406,
        "entropy-3": 8.678948843311957,
        "cond_entropy-3": 0.08110175497250599,
        "total_length-nopunct": 428,
        "mean_pred_length-nopunct": 13.806451612903226,
        "std_pred_length-nopunct": 4.161415351960154,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6355140186915887,
        "vocab_size-1-nopunct": 272,
        "unique-1-nopunct": 214,
        "entropy-1-nopunct": 7.552970803160609,
        "distinct-2-nopunct": 0.9118387909319899,
        "vocab_size-2-nopunct": 362,
        "unique-2-nopunct": 345,
        "entropy-2-nopunct": 8.400655572564816,
        "cond_entropy-2-nopunct": 0.8980920202385106,
        "distinct-3-nopunct": 0.9754098360655737,
        "vocab_size-3-nopunct": 357,
        "unique-3-nopunct": 351,
        "entropy-3-nopunct": 8.460331907938386,
        "cond_entropy-3-nopunct": 0.07229263554085436,
        "msttr-100": 0.7425,
        "msttr-100_nopunct": 0.8075,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19387755102040816,
            "2": 0.5051546391752577,
            "3": 0.7751677852348994
        },
        "nist": 6.050954533784631,
        "bleu": 41.55045,
        "rouge1": {
            "precision": 0.74401,
            "recall": 0.71627,
            "fmeasure": 0.71472
        },
        "rouge2": {
            "precision": 0.51061,
            "recall": 0.49553,
            "fmeasure": 0.48932
        },
        "rougeL": {
            "precision": 0.60832,
            "recall": 0.59089,
            "fmeasure": 0.58523
        },
        "rougeLsum": {
            "precision": 0.60832,
            "recall": 0.59089,
            "fmeasure": 0.58523
        },
        "nubia": {
            "semantic_relation": 4.11927,
            "contradiction": 1.76892,
            "irrelevancy": 36.24559,
            "logical_agreement": 61.98549,
            "grammar_ref": 4.50561,
            "grammar_hyp": 4.46159,
            "nubia_score": 0.71544
        },
        "meteor": 0.389662847679089,
        "bleurt": 0.23642,
        "bertscore": {
            "precision": 0.9188,
            "recall": 0.91809,
            "f1": 0.91731
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_416": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 4.496912521077347,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 22,
        "distinct-1": 0.7021276595744681,
        "vocab_size-1": 33,
        "unique-1": 24,
        "entropy-1": 4.839490118178984,
        "distinct-2": 0.9772727272727273,
        "vocab_size-2": 43,
        "unique-2": 42,
        "entropy-2": 5.413977073182751,
        "cond_entropy-2": 0.5777891413786783,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.053099126214335594,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 4.714045207910316,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7209302325581395,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.737668464598916,
        "distinct-2-nopunct": 0.975,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.271928094887364,
        "cond_entropy-2-nopunct": 0.5609043520461846,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.058420675204358584,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.6764705882352942
        },
        "nist": 3.689028753766541,
        "bleu": 25.41381,
        "rouge1": {
            "precision": 0.72407,
            "recall": 0.74131,
            "fmeasure": 0.73174
        },
        "rouge2": {
            "precision": 0.4662,
            "recall": 0.46108,
            "fmeasure": 0.4624
        },
        "rougeL": {
            "precision": 0.59935,
            "recall": 0.61028,
            "fmeasure": 0.60416
        },
        "rougeLsum": {
            "precision": 0.59935,
            "recall": 0.61028,
            "fmeasure": 0.60416
        },
        "nubia": {
            "semantic_relation": 4.81811,
            "contradiction": 0.79256,
            "irrelevancy": 1.03969,
            "logical_agreement": 98.16776,
            "grammar_ref": 4.67072,
            "grammar_hyp": 4.15369,
            "nubia_score": 0.95619
        },
        "meteor": 0.37176123317941945,
        "bleurt": 0.38586,
        "bertscore": {
            "precision": 0.91932,
            "recall": 0.93533,
            "f1": 0.92681
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_420": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 11,
        "total_length": 185,
        "mean_pred_length": 16.818181818181817,
        "std_pred_length": 5.653931565624077,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.654054054054054,
        "vocab_size-1": 121,
        "unique-1": 101,
        "entropy-1": 6.464538884428727,
        "distinct-2": 0.9310344827586207,
        "vocab_size-2": 162,
        "unique-2": 153,
        "entropy-2": 7.291997159604512,
        "cond_entropy-2": 0.676202646049089,
        "distinct-3": 1.0,
        "vocab_size-3": 163,
        "unique-3": 163,
        "entropy-3": 7.348728154231104,
        "cond_entropy-3": 0.05464761854486706,
        "total_length-nopunct": 168,
        "mean_pred_length-nopunct": 15.272727272727273,
        "std_pred_length-nopunct": 5.188990251938304,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7083333333333334,
        "vocab_size-1-nopunct": 119,
        "unique-1-nopunct": 101,
        "entropy-1-nopunct": 6.536351031309348,
        "distinct-2-nopunct": 0.9299363057324841,
        "vocab_size-2-nopunct": 146,
        "unique-2-nopunct": 138,
        "entropy-2-nopunct": 7.140068758404424,
        "cond_entropy-2-nopunct": 0.6408557385947345,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 146,
        "unique-3-nopunct": 146,
        "entropy-3-nopunct": 7.18982455888002,
        "cond_entropy-3-nopunct": 0.06140012852599587,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.631578947368421,
            "3": 0.8387096774193549
        },
        "nist": 5.650942648818549,
        "bleu": 50.61338,
        "rouge1": {
            "precision": 0.76076,
            "recall": 0.8067,
            "fmeasure": 0.77215
        },
        "rouge2": {
            "precision": 0.58711,
            "recall": 0.63135,
            "fmeasure": 0.59798
        },
        "rougeL": {
            "precision": 0.69957,
            "recall": 0.7382,
            "fmeasure": 0.70806
        },
        "rougeLsum": {
            "precision": 0.69957,
            "recall": 0.7382,
            "fmeasure": 0.70806
        },
        "nubia": {
            "semantic_relation": 4.61294,
            "contradiction": 3.59188,
            "irrelevancy": 27.41753,
            "logical_agreement": 68.99059,
            "grammar_ref": 4.45431,
            "grammar_hyp": 4.3141,
            "nubia_score": 0.86185
        },
        "meteor": 0.43099172096323135,
        "bleurt": 0.50473,
        "bertscore": {
            "precision": 0.9433,
            "recall": 0.9456,
            "f1": 0.94356
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_505": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 75,
        "mean_pred_length": 15.0,
        "std_pred_length": 5.830951894845301,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 50,
        "unique-1": 37,
        "entropy-1": 5.415224690380499,
        "distinct-2": 0.8142857142857143,
        "vocab_size-2": 57,
        "unique-2": 48,
        "entropy-2": 5.707714802597444,
        "cond_entropy-2": 0.2363182550823275,
        "distinct-3": 0.8923076923076924,
        "vocab_size-3": 58,
        "unique-3": 52,
        "entropy-3": 5.795369543764403,
        "cond_entropy-3": 0.1200830653475412,
        "total_length-nopunct": 70,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.830951894845301,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6857142857142857,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.3718608739642,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 52,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.5683712745003495,
        "cond_entropy-2-nopunct": 0.22400441153467154,
        "distinct-3-nopunct": 0.8833333333333333,
        "vocab_size-3-nopunct": 53,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.660975803905793,
        "cond_entropy-3-nopunct": 0.13043757428278852,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.7796610169491526
        },
        "nist": 4.377932780446793,
        "bleu": 48.16746,
        "rouge1": {
            "precision": 0.79838,
            "recall": 0.82277,
            "fmeasure": 0.8095
        },
        "rouge2": {
            "precision": 0.65,
            "recall": 0.6708,
            "fmeasure": 0.65971
        },
        "rougeL": {
            "precision": 0.77397,
            "recall": 0.80091,
            "fmeasure": 0.78656
        },
        "rougeLsum": {
            "precision": 0.77397,
            "recall": 0.80091,
            "fmeasure": 0.78656
        },
        "nubia": {
            "semantic_relation": 4.40334,
            "contradiction": 1.88504,
            "irrelevancy": 1.1104,
            "logical_agreement": 97.00457,
            "grammar_ref": 4.79762,
            "grammar_hyp": 4.7527,
            "nubia_score": 0.79057
        },
        "meteor": 0.40307007921358395,
        "bleurt": 0.65508,
        "bertscore": {
            "precision": 0.96531,
            "recall": 0.96026,
            "f1": 0.9625
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_403": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 6.5,
        "median_pred_length": 18.5,
        "min_pred_length": 12,
        "max_pred_length": 25,
        "distinct-1": 0.7027027027027027,
        "vocab_size-1": 26,
        "unique-1": 18,
        "entropy-1": 4.553651676264346,
        "distinct-2": 0.9714285714285714,
        "vocab_size-2": 34,
        "unique-2": 33,
        "entropy-2": 5.072140159802107,
        "cond_entropy-2": 0.4988200086443141,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.02428283698045265,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7419354838709677,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.389364858634393,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.4730872710967984,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.10309349296410335,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6428571428571429
        },
        "nist": 3.3854636546070664,
        "bleu": 30.36778,
        "rouge1": {
            "precision": 0.74242,
            "recall": 0.643,
            "fmeasure": 0.68422
        },
        "rouge2": {
            "precision": 0.54565,
            "recall": 0.44116,
            "fmeasure": 0.48274
        },
        "rougeL": {
            "precision": 0.63826,
            "recall": 0.52404,
            "fmeasure": 0.57033
        },
        "rougeLsum": {
            "precision": 0.63826,
            "recall": 0.52404,
            "fmeasure": 0.57033
        },
        "nubia": {
            "semantic_relation": 3.58773,
            "contradiction": 49.90233,
            "irrelevancy": 0.77045,
            "logical_agreement": 49.32722,
            "grammar_ref": 3.82725,
            "grammar_hyp": 4.65533,
            "nubia_score": 0.48661
        },
        "meteor": 0.3516428084637585,
        "bleurt": 0.04751,
        "bertscore": {
            "precision": 0.93146,
            "recall": 0.89698,
            "f1": 0.91224
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_336": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 17,
        "total_length": 274,
        "mean_pred_length": 16.11764705882353,
        "std_pred_length": 5.645220288945919,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.6204379562043796,
        "vocab_size-1": 170,
        "unique-1": 140,
        "entropy-1": 6.7765920310272865,
        "distinct-2": 0.9182879377431906,
        "vocab_size-2": 236,
        "unique-2": 221,
        "entropy-2": 7.809490806172242,
        "cond_entropy-2": 0.8769283699356802,
        "distinct-3": 0.975,
        "vocab_size-3": 234,
        "unique-3": 228,
        "entropy-3": 7.8568905956085615,
        "cond_entropy-3": 0.06129259623366863,
        "total_length-nopunct": 239,
        "mean_pred_length-nopunct": 14.058823529411764,
        "std_pred_length-nopunct": 4.607801418250856,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.694560669456067,
        "vocab_size-1-nopunct": 166,
        "unique-1-nopunct": 140,
        "entropy-1-nopunct": 6.886278526847901,
        "distinct-2-nopunct": 0.9144144144144144,
        "vocab_size-2-nopunct": 203,
        "unique-2-nopunct": 190,
        "entropy-2-nopunct": 7.585378154834029,
        "cond_entropy-2-nopunct": 0.7632798116765249,
        "distinct-3-nopunct": 0.975609756097561,
        "vocab_size-3-nopunct": 200,
        "unique-3-nopunct": 195,
        "entropy-3-nopunct": 7.630699611700555,
        "cond_entropy-3-nopunct": 0.05290019391907992,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.4588235294117647,
            "3": 0.6612021857923497
        },
        "nist": 5.226632152466533,
        "bleu": 39.2381,
        "rouge1": {
            "precision": 0.73491,
            "recall": 0.66164,
            "fmeasure": 0.68004
        },
        "rouge2": {
            "precision": 0.50895,
            "recall": 0.44951,
            "fmeasure": 0.46712
        },
        "rougeL": {
            "precision": 0.61021,
            "recall": 0.56818,
            "fmeasure": 0.57346
        },
        "rougeLsum": {
            "precision": 0.61021,
            "recall": 0.56818,
            "fmeasure": 0.57346
        },
        "nubia": {
            "semantic_relation": 3.86036,
            "contradiction": 13.0427,
            "irrelevancy": 34.28023,
            "logical_agreement": 52.67707,
            "grammar_ref": 4.33068,
            "grammar_hyp": 4.53806,
            "nubia_score": 0.61542
        },
        "meteor": 0.34575717163214764,
        "bleurt": 0.10866,
        "bertscore": {
            "precision": 0.91718,
            "recall": 0.90917,
            "f1": 0.91018
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_592": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 3.0193857123681083,
        "bleu": 66.06329,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.79365,
            "fmeasure": 0.75092
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "nubia": {
            "semantic_relation": 4.73051,
            "contradiction": 12.38492,
            "irrelevancy": 65.97277,
            "logical_agreement": 21.64232,
            "grammar_ref": 5.97194,
            "grammar_hyp": 6.43578,
            "nubia_score": 0.73889
        },
        "meteor": 0.5319853951676884,
        "bleurt": 0.4261,
        "bertscore": {
            "precision": 0.96679,
            "recall": 0.98719,
            "f1": 0.97688
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_404": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 5.0,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 20,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 28,
        "unique-1": 26,
        "entropy-1": 4.773557262275186,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": -0.02810710212234293,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9642857142857143,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.735926350629034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": -0.02999212699343526,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.375,
            "3": 1.0
        },
        "nist": 5.049387559436231,
        "bleu": 67.43842,
        "rouge1": {
            "precision": 0.90351,
            "recall": 0.88405,
            "fmeasure": 0.8906
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.72317,
            "fmeasure": 0.73352
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.82386,
            "fmeasure": 0.8247
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.82386,
            "fmeasure": 0.8247
        },
        "nubia": {
            "semantic_relation": 4.80572,
            "contradiction": 0.4117,
            "irrelevancy": 17.02437,
            "logical_agreement": 82.56393,
            "grammar_ref": 4.70227,
            "grammar_hyp": 4.78757,
            "nubia_score": 0.91094
        },
        "meteor": 0.5045942485863172,
        "bleurt": 0.57813,
        "bertscore": {
            "precision": 0.96749,
            "recall": 0.97661,
            "f1": 0.96986
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_121": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 47,
        "mean_pred_length": 11.75,
        "std_pred_length": 2.680951323690902,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.7659574468085106,
        "vocab_size-1": 36,
        "unique-1": 31,
        "entropy-1": 4.969274489883449,
        "distinct-2": 1.0,
        "vocab_size-2": 43,
        "unique-2": 43,
        "entropy-2": 5.426264754702098,
        "cond_entropy-2": 0.32539160079950546,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.14086253583984967,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 2.29128784747792,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8095238095238095,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.927798970294787,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.247927513443589,
        "cond_entropy-2-nopunct": 0.32731568286497736,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.16046467219324617,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.2857142857142857,
            "3": 0.6216216216216216
        },
        "nist": 3.490701241129032,
        "bleu": 32.60706,
        "rouge1": {
            "precision": 0.71245,
            "recall": 0.66827,
            "fmeasure": 0.68717
        },
        "rouge2": {
            "precision": 0.42949,
            "recall": 0.40253,
            "fmeasure": 0.41371
        },
        "rougeL": {
            "precision": 0.60855,
            "recall": 0.57601,
            "fmeasure": 0.58972
        },
        "rougeLsum": {
            "precision": 0.60855,
            "recall": 0.57601,
            "fmeasure": 0.58972
        },
        "nubia": {
            "semantic_relation": 3.40702,
            "contradiction": 28.07199,
            "irrelevancy": 33.28034,
            "logical_agreement": 38.64767,
            "grammar_ref": 5.13429,
            "grammar_hyp": 4.7889,
            "nubia_score": 0.53693
        },
        "meteor": 0.33715757158974674,
        "bleurt": 0.14752,
        "bertscore": {
            "precision": 0.91771,
            "recall": 0.90633,
            "f1": 0.90964
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_365": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 55,
        "mean_pred_length": 18.333333333333332,
        "std_pred_length": 4.189935029992178,
        "median_pred_length": 17.0,
        "min_pred_length": 14,
        "max_pred_length": 24,
        "distinct-1": 0.6363636363636364,
        "vocab_size-1": 35,
        "unique-1": 19,
        "entropy-1": 4.9539092589005325,
        "distinct-2": 0.75,
        "vocab_size-2": 39,
        "unique-2": 26,
        "entropy-2": 5.200439718141092,
        "cond_entropy-2": 0.25580644700733524,
        "distinct-3": 0.8163265306122449,
        "vocab_size-3": 40,
        "unique-3": 31,
        "entropy-3": 5.247362905339699,
        "cond_entropy-3": 0.036719105565952974,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 17.333333333333332,
        "std_pred_length-nopunct": 4.189935029992178,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6346153846153846,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.863713275750189,
        "distinct-2-nopunct": 0.7551020408163265,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 5.124913925747862,
        "cond_entropy-2-nopunct": 0.2716124730011967,
        "distinct-3-nopunct": 0.8260869565217391,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 5.175735869100489,
        "cond_entropy-3-nopunct": 0.03928689455050023,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.8571428571428571,
            "2": 0.8,
            "3": 0.6551724137931034
        },
        "nist": 3.131791844248794,
        "bleu": 43.13357,
        "rouge1": {
            "precision": 0.55984,
            "recall": 0.71961,
            "fmeasure": 0.62742
        },
        "rouge2": {
            "precision": 0.42929,
            "recall": 0.55884,
            "fmeasure": 0.48387
        },
        "rougeL": {
            "precision": 0.55018,
            "recall": 0.70862,
            "fmeasure": 0.61674
        },
        "rougeLsum": {
            "precision": 0.55018,
            "recall": 0.70862,
            "fmeasure": 0.61674
        },
        "nubia": {
            "semantic_relation": 3.69067,
            "contradiction": 32.25114,
            "irrelevancy": 23.6827,
            "logical_agreement": 44.06616,
            "grammar_ref": 4.37436,
            "grammar_hyp": 4.25313,
            "nubia_score": 0.64716
        },
        "meteor": 0.3449270796368267,
        "bleurt": 0.03328,
        "bertscore": {
            "precision": 0.89377,
            "recall": 0.91204,
            "f1": 0.90142
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_339": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.6
        },
        "nist": 2.1572542481898718,
        "bleu": 31.21235,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.66667,
            "fmeasure": 0.75676
        },
        "rouge2": {
            "precision": 0.71111,
            "recall": 0.5254,
            "fmeasure": 0.60423
        },
        "rougeL": {
            "precision": 0.6875,
            "recall": 0.52381,
            "fmeasure": 0.59459
        },
        "rougeLsum": {
            "precision": 0.6875,
            "recall": 0.52381,
            "fmeasure": 0.59459
        },
        "nubia": {
            "semantic_relation": 4.12613,
            "contradiction": 0.22819,
            "irrelevancy": 5.77898,
            "logical_agreement": 93.99284,
            "grammar_ref": 3.42286,
            "grammar_hyp": 3.80149,
            "nubia_score": 0.7768
        },
        "meteor": 0.3666631751732034,
        "bleurt": 0.30813,
        "bertscore": {
            "precision": 0.93862,
            "recall": 0.88057,
            "f1": 0.90867
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_123": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 78,
        "mean_pred_length": 19.5,
        "std_pred_length": 5.123475382979799,
        "median_pred_length": 19.0,
        "min_pred_length": 14,
        "max_pred_length": 26,
        "distinct-1": 0.7948717948717948,
        "vocab_size-1": 62,
        "unique-1": 51,
        "entropy-1": 5.820470648266224,
        "distinct-2": 0.972972972972973,
        "vocab_size-2": 72,
        "unique-2": 70,
        "entropy-2": 6.155399311574901,
        "cond_entropy-2": 0.25195199144900393,
        "distinct-3": 1.0,
        "vocab_size-3": 70,
        "unique-3": 70,
        "entropy-3": 6.129283016944973,
        "cond_entropy-3": -0.02302749154112618,
        "total_length-nopunct": 69,
        "mean_pred_length-nopunct": 17.25,
        "std_pred_length-nopunct": 3.832427429188973,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8405797101449275,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.767803079903862,
        "distinct-2-nopunct": 0.9846153846153847,
        "vocab_size-2-nopunct": 64,
        "unique-2-nopunct": 63,
        "entropy-2-nopunct": 5.991598582259227,
        "cond_entropy-2-nopunct": 0.22937835631685366,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 61,
        "unique-3-nopunct": 61,
        "entropy-3-nopunct": 5.930737337562883,
        "cond_entropy-3-nopunct": -0.05884359021966676,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.6,
            "3": 0.8775510204081632
        },
        "nist": 5.204107997467899,
        "bleu": 45.05067,
        "rouge1": {
            "precision": 0.74586,
            "recall": 0.83349,
            "fmeasure": 0.78641
        },
        "rouge2": {
            "precision": 0.54052,
            "recall": 0.58834,
            "fmeasure": 0.56068
        },
        "rougeL": {
            "precision": 0.61537,
            "recall": 0.67842,
            "fmeasure": 0.64467
        },
        "rougeLsum": {
            "precision": 0.61537,
            "recall": 0.67842,
            "fmeasure": 0.64467
        },
        "nubia": {
            "semantic_relation": 4.08344,
            "contradiction": 12.23213,
            "irrelevancy": 30.07401,
            "logical_agreement": 57.69386,
            "grammar_ref": 5.56433,
            "grammar_hyp": 4.77339,
            "nubia_score": 0.75307
        },
        "meteor": 0.42536535864337716,
        "bleurt": 0.27502,
        "bertscore": {
            "precision": 0.9389,
            "recall": 0.91233,
            "f1": 0.92396
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_340": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 8,
        "total_length": 156,
        "mean_pred_length": 19.5,
        "std_pred_length": 6.5383484153110105,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.6282051282051282,
        "vocab_size-1": 98,
        "unique-1": 71,
        "entropy-1": 6.310958190219023,
        "distinct-2": 0.9391891891891891,
        "vocab_size-2": 139,
        "unique-2": 132,
        "entropy-2": 7.074318230493812,
        "cond_entropy-2": 0.6538705283095729,
        "distinct-3": 0.9857142857142858,
        "vocab_size-3": 138,
        "unique-3": 136,
        "entropy-3": 7.100711588373549,
        "cond_entropy-3": 0.0341153656017309,
        "total_length-nopunct": 135,
        "mean_pred_length-nopunct": 16.875,
        "std_pred_length-nopunct": 5.732309743899051,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6888888888888889,
        "vocab_size-1-nopunct": 93,
        "unique-1-nopunct": 70,
        "entropy-1-nopunct": 6.309047148963849,
        "distinct-2-nopunct": 0.952755905511811,
        "vocab_size-2-nopunct": 121,
        "unique-2-nopunct": 117,
        "entropy-2-nopunct": 6.878448466299708,
        "cond_entropy-2-nopunct": 0.5895366329577392,
        "distinct-3-nopunct": 0.9915966386554622,
        "vocab_size-3-nopunct": 118,
        "unique-3-nopunct": 117,
        "entropy-3-nopunct": 6.878011040618866,
        "cond_entropy-3-nopunct": 0.006973412670231471,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.72,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.55,
            "3": 0.8613861386138614
        },
        "nist": 5.251125450957356,
        "bleu": 49.55761,
        "rouge1": {
            "precision": 0.79029,
            "recall": 0.81477,
            "fmeasure": 0.79418
        },
        "rouge2": {
            "precision": 0.58431,
            "recall": 0.59263,
            "fmeasure": 0.5829
        },
        "rougeL": {
            "precision": 0.67685,
            "recall": 0.73759,
            "fmeasure": 0.6967
        },
        "rougeLsum": {
            "precision": 0.67685,
            "recall": 0.73759,
            "fmeasure": 0.6967
        },
        "nubia": {
            "semantic_relation": 4.56843,
            "contradiction": 2.11121,
            "irrelevancy": 26.59782,
            "logical_agreement": 71.29096,
            "grammar_ref": 4.58534,
            "grammar_hyp": 4.40753,
            "nubia_score": 0.87795
        },
        "meteor": 0.43317278851910207,
        "bleurt": 0.5269,
        "bertscore": {
            "precision": 0.93884,
            "recall": 0.94743,
            "f1": 0.94288
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_366": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 49,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 3.8586123009300755,
        "median_pred_length": 18.0,
        "min_pred_length": 11,
        "max_pred_length": 20,
        "distinct-1": 0.8367346938775511,
        "vocab_size-1": 41,
        "unique-1": 37,
        "entropy-1": 5.199107232347856,
        "distinct-2": 1.0,
        "vocab_size-2": 46,
        "unique-2": 46,
        "entropy-2": 5.5235619560570095,
        "cond_entropy-2": 0.24819212225564796,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.09729720135491506,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 3.2998316455372216,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.104667062400097,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.357552004618081,
        "cond_entropy-2-nopunct": 0.27884332438168435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.10962449117449787,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.4,
            "3": 0.7714285714285715
        },
        "nist": 4.308385183081688,
        "bleu": 49.56151,
        "rouge1": {
            "precision": 0.75359,
            "recall": 0.68524,
            "fmeasure": 0.70189
        },
        "rouge2": {
            "precision": 0.56636,
            "recall": 0.51132,
            "fmeasure": 0.52451
        },
        "rougeL": {
            "precision": 0.71438,
            "recall": 0.65099,
            "fmeasure": 0.66668
        },
        "rougeLsum": {
            "precision": 0.71438,
            "recall": 0.65099,
            "fmeasure": 0.66668
        },
        "nubia": {
            "semantic_relation": 4.19142,
            "contradiction": 1.25626,
            "irrelevancy": 31.26975,
            "logical_agreement": 67.47399,
            "grammar_ref": 5.35172,
            "grammar_hyp": 4.91609,
            "nubia_score": 0.74152
        },
        "meteor": 0.41059845238286286,
        "bleurt": 0.23929,
        "bertscore": {
            "precision": 0.93324,
            "recall": 0.92936,
            "f1": 0.9309
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_266": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 8,
        "total_length": 119,
        "mean_pred_length": 14.875,
        "std_pred_length": 3.75624480032918,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 24,
        "distinct-1": 0.7058823529411765,
        "vocab_size-1": 84,
        "unique-1": 70,
        "entropy-1": 6.0680905329919455,
        "distinct-2": 0.918918918918919,
        "vocab_size-2": 102,
        "unique-2": 94,
        "entropy-2": 6.6254529158801745,
        "cond_entropy-2": 0.4007301111992832,
        "distinct-3": 0.9514563106796117,
        "vocab_size-3": 98,
        "unique-3": 93,
        "entropy-3": 6.589413148542455,
        "cond_entropy-3": -0.04233390710704791,
        "total_length-nopunct": 106,
        "mean_pred_length-nopunct": 13.25,
        "std_pred_length-nopunct": 3.4550687402713134,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7547169811320755,
        "vocab_size-1-nopunct": 80,
        "unique-1-nopunct": 69,
        "entropy-1-nopunct": 6.063953092227305,
        "distinct-2-nopunct": 0.9183673469387755,
        "vocab_size-2-nopunct": 90,
        "unique-2-nopunct": 83,
        "entropy-2-nopunct": 6.4437416042972195,
        "cond_entropy-2-nopunct": 0.4135817661381351,
        "distinct-3-nopunct": 0.9555555555555556,
        "vocab_size-3-nopunct": 86,
        "unique-3-nopunct": 82,
        "entropy-3-nopunct": 6.402964207440774,
        "cond_entropy-3-nopunct": -0.047802442205939634,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.74,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5428571428571428,
            "3": 0.927536231884058
        },
        "nist": 5.902365911708346,
        "bleu": 48.18253,
        "rouge1": {
            "precision": 0.78537,
            "recall": 0.78998,
            "fmeasure": 0.77947
        },
        "rouge2": {
            "precision": 0.55396,
            "recall": 0.56487,
            "fmeasure": 0.55341
        },
        "rougeL": {
            "precision": 0.66571,
            "recall": 0.66385,
            "fmeasure": 0.65782
        },
        "rougeLsum": {
            "precision": 0.66571,
            "recall": 0.66385,
            "fmeasure": 0.65782
        },
        "nubia": {
            "semantic_relation": 4.30391,
            "contradiction": 14.15338,
            "irrelevancy": 26.40969,
            "logical_agreement": 59.43693,
            "grammar_ref": 4.49967,
            "grammar_hyp": 4.56009,
            "nubia_score": 0.78245
        },
        "meteor": 0.46863892966189397,
        "bleurt": 0.32213,
        "bertscore": {
            "precision": 0.94131,
            "recall": 0.95613,
            "f1": 0.94532
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_610": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.13652573434569684,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966062,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9375
        },
        "nist": 4.476798555485602,
        "bleu": 90.8655,
        "rouge1": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rouge2": {
            "precision": 0.9375,
            "recall": 0.9375,
            "fmeasure": 0.9375
        },
        "rougeL": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rougeLsum": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "nubia": {
            "semantic_relation": 3.73924,
            "contradiction": 97.74814,
            "irrelevancy": 1.732,
            "logical_agreement": 0.51986,
            "grammar_ref": 5.25838,
            "grammar_hyp": 5.11348,
            "nubia_score": 0.53087
        },
        "meteor": 0.5772487688020834,
        "bleurt": 0.71432,
        "bertscore": {
            "precision": 0.98484,
            "recall": 0.98886,
            "f1": 0.98685
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_423": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 2.5,
        "median_pred_length": 14.5,
        "min_pred_length": 12,
        "max_pred_length": 17,
        "distinct-1": 0.9310344827586207,
        "vocab_size-1": 27,
        "unique-1": 25,
        "entropy-1": 4.720049960644813,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": -0.029019418890029344,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.96,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.5638561897747225,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": -0.03333771197858132,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.3,
            "3": 1.0
        },
        "nist": 4.33554232417899,
        "bleu": 58.56777,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.80156,
            "fmeasure": 0.75949
        },
        "rouge2": {
            "precision": 0.50108,
            "recall": 0.56085,
            "fmeasure": 0.52392
        },
        "rougeL": {
            "precision": 0.68611,
            "recall": 0.7539,
            "fmeasure": 0.71232
        },
        "rougeLsum": {
            "precision": 0.68611,
            "recall": 0.7539,
            "fmeasure": 0.71232
        },
        "nubia": {
            "semantic_relation": 4.29934,
            "contradiction": 0.12974,
            "irrelevancy": 35.13294,
            "logical_agreement": 64.73732,
            "grammar_ref": 4.57807,
            "grammar_hyp": 4.1184,
            "nubia_score": 0.81161
        },
        "meteor": 0.4570636705689241,
        "bleurt": 0.42275,
        "bertscore": {
            "precision": 0.94957,
            "recall": 0.96467,
            "f1": 0.95672
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_612": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 45,
        "mean_pred_length": 15.0,
        "std_pred_length": 4.08248290463863,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 20,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 39,
        "unique-1": 36,
        "entropy-1": 5.163966707392708,
        "distinct-2": 0.9761904761904762,
        "vocab_size-2": 41,
        "unique-2": 40,
        "entropy-2": 5.344698375159715,
        "cond_entropy-2": 0.09094051692527624,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.05563315263446058,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 3.681787005729087,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9024390243902439,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.1136495655936915,
        "distinct-2-nopunct": 0.9736842105263158,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.19529593449622,
        "cond_entropy-2-nopunct": 0.10090182461497572,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.061501639355761785,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.46153846153846156,
            "3": 0.56
        },
        "nist": 3.003583628822778,
        "bleu": 23.71361,
        "rouge1": {
            "precision": 0.62348,
            "recall": 0.5902,
            "fmeasure": 0.60094
        },
        "rouge2": {
            "precision": 0.37179,
            "recall": 0.33776,
            "fmeasure": 0.3512
        },
        "rougeL": {
            "precision": 0.52084,
            "recall": 0.48626,
            "fmeasure": 0.49917
        },
        "rougeLsum": {
            "precision": 0.52084,
            "recall": 0.48626,
            "fmeasure": 0.49917
        },
        "nubia": {
            "semantic_relation": 3.96088,
            "contradiction": 0.17906,
            "irrelevancy": 46.66083,
            "logical_agreement": 53.16011,
            "grammar_ref": 4.28129,
            "grammar_hyp": 3.9377,
            "nubia_score": 0.78505
        },
        "meteor": 0.33907929148145416,
        "bleurt": 0.19588,
        "bertscore": {
            "precision": 0.89873,
            "recall": 0.90167,
            "f1": 0.89943
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_594": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 3.5,
        "median_pred_length": 18.5,
        "min_pred_length": 15,
        "max_pred_length": 22,
        "distinct-1": 0.7837837837837838,
        "vocab_size-1": 29,
        "unique-1": 25,
        "entropy-1": 4.628108095241737,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.4772517942967866,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.08488889758651327,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.571860873964194,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.506316405574909,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.09019780897157811,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 0.8666666666666667,
            "3": 1.0
        },
        "nist": 4.898766887303841,
        "bleu": 64.48718,
        "rouge1": {
            "precision": 0.76984,
            "recall": 0.90809,
            "fmeasure": 0.83025
        },
        "rouge2": {
            "precision": 0.63512,
            "recall": 0.75785,
            "fmeasure": 0.68807
        },
        "rougeL": {
            "precision": 0.75873,
            "recall": 0.8942,
            "fmeasure": 0.8179
        },
        "rougeLsum": {
            "precision": 0.75873,
            "recall": 0.8942,
            "fmeasure": 0.8179
        },
        "nubia": {
            "semantic_relation": 3.83449,
            "contradiction": 50.57811,
            "irrelevancy": 0.92407,
            "logical_agreement": 48.49782,
            "grammar_ref": 4.13759,
            "grammar_hyp": 3.95557,
            "nubia_score": 0.67565
        },
        "meteor": 0.4839278707856681,
        "bleurt": 0.61027,
        "bertscore": {
            "precision": 0.957,
            "recall": 0.97003,
            "f1": 0.96347
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_268": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 88,
        "mean_pred_length": 17.6,
        "std_pred_length": 4.454211490264018,
        "median_pred_length": 17.0,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.6931818181818182,
        "vocab_size-1": 61,
        "unique-1": 48,
        "entropy-1": 5.626443335582683,
        "distinct-2": 0.963855421686747,
        "vocab_size-2": 80,
        "unique-2": 77,
        "entropy-2": 6.302750274720425,
        "cond_entropy-2": 0.6301014140205488,
        "distinct-3": 1.0,
        "vocab_size-3": 78,
        "unique-3": 78,
        "entropy-3": 6.285402218862257,
        "cond_entropy-3": -0.03835516120262511,
        "total_length-nopunct": 77,
        "mean_pred_length-nopunct": 15.4,
        "std_pred_length-nopunct": 4.079215610874228,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7662337662337663,
        "vocab_size-1-nopunct": 59,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.673910119209148,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 69,
        "unique-2-nopunct": 66,
        "entropy-2-nopunct": 6.086591668108984,
        "cond_entropy-2-nopunct": 0.4260757448363451,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 67,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 6.066089190457767,
        "cond_entropy-3-nopunct": -0.01428357217856975,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.42857142857142855,
            "3": 0.6984126984126984
        },
        "nist": 4.0223963245534735,
        "bleu": 42.76743,
        "rouge1": {
            "precision": 0.75526,
            "recall": 0.66723,
            "fmeasure": 0.70028
        },
        "rouge2": {
            "precision": 0.50742,
            "recall": 0.4549,
            "fmeasure": 0.47381
        },
        "rougeL": {
            "precision": 0.68458,
            "recall": 0.62499,
            "fmeasure": 0.64561
        },
        "rougeLsum": {
            "precision": 0.68458,
            "recall": 0.62499,
            "fmeasure": 0.64561
        },
        "nubia": {
            "semantic_relation": 3.90477,
            "contradiction": 13.27016,
            "irrelevancy": 42.59027,
            "logical_agreement": 44.13956,
            "grammar_ref": 4.37077,
            "grammar_hyp": 4.47636,
            "nubia_score": 0.64254
        },
        "meteor": 0.33443846315942183,
        "bleurt": 0.04411,
        "bertscore": {
            "precision": 0.9293,
            "recall": 0.90978,
            "f1": 0.91705
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_270": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 31,
        "total_length": 477,
        "mean_pred_length": 15.387096774193548,
        "std_pred_length": 4.419001634107828,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.5744234800838575,
        "vocab_size-1": 274,
        "unique-1": 220,
        "entropy-1": 7.2905380748498825,
        "distinct-2": 0.9349775784753364,
        "vocab_size-2": 417,
        "unique-2": 396,
        "entropy-2": 8.653199669021408,
        "cond_entropy-2": 1.138057398691299,
        "distinct-3": 0.9855421686746988,
        "vocab_size-3": 409,
        "unique-3": 403,
        "entropy-3": 8.66805186358372,
        "cond_entropy-3": 0.016246669641517816,
        "total_length-nopunct": 414,
        "mean_pred_length-nopunct": 13.35483870967742,
        "std_pred_length-nopunct": 3.7117806099722648,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6521739130434783,
        "vocab_size-1-nopunct": 270,
        "unique-1-nopunct": 220,
        "entropy-1-nopunct": 7.547825947226812,
        "distinct-2-nopunct": 0.9399477806788512,
        "vocab_size-2-nopunct": 360,
        "unique-2-nopunct": 345,
        "entropy-2-nopunct": 8.440536605473408,
        "cond_entropy-2-nopunct": 0.9604143888412635,
        "distinct-3-nopunct": 0.9914772727272727,
        "vocab_size-3-nopunct": 349,
        "unique-3-nopunct": 346,
        "entropy-3-nopunct": 8.442386164091811,
        "cond_entropy-3-nopunct": -0.0016287914688926993,
        "msttr-100": 0.7275,
        "msttr-100_nopunct": 0.7725,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16,
            "2": 0.5822784810126582,
            "3": 0.81875
        },
        "nist": 6.7914990976224345,
        "bleu": 49.21108,
        "rouge1": {
            "precision": 0.8193,
            "recall": 0.78893,
            "fmeasure": 0.79793
        },
        "rouge2": {
            "precision": 0.59538,
            "recall": 0.57655,
            "fmeasure": 0.58198
        },
        "rougeL": {
            "precision": 0.67856,
            "recall": 0.67161,
            "fmeasure": 0.67017
        },
        "rougeLsum": {
            "precision": 0.67856,
            "recall": 0.67161,
            "fmeasure": 0.67017
        },
        "nubia": {
            "semantic_relation": 4.40549,
            "contradiction": 4.57193,
            "irrelevancy": 23.78788,
            "logical_agreement": 71.64019,
            "grammar_ref": 4.63543,
            "grammar_hyp": 4.67212,
            "nubia_score": 0.78392
        },
        "meteor": 0.4213731684200465,
        "bleurt": 0.3786,
        "bertscore": {
            "precision": 0.93528,
            "recall": 0.93519,
            "f1": 0.93377
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_405": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.875
        },
        "nist": 2.9898332363522426,
        "bleu": 61.0195,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.30005,
            "irrelevancy": 0.4565,
            "logical_agreement": 99.24345,
            "grammar_ref": 4.34196,
            "grammar_hyp": 4.46114,
            "nubia_score": 0.99737
        },
        "meteor": 0.5064321156600579,
        "bleurt": 0.83294,
        "bertscore": {
            "precision": 0.99622,
            "recall": 0.98673,
            "f1": 0.99146
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_368": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 7,
        "total_length": 120,
        "mean_pred_length": 17.142857142857142,
        "std_pred_length": 4.940461847368738,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 24,
        "distinct-1": 0.7333333333333333,
        "vocab_size-1": 88,
        "unique-1": 77,
        "entropy-1": 6.10726353745685,
        "distinct-2": 1.0,
        "vocab_size-2": 113,
        "unique-2": 113,
        "entropy-2": 6.8201789624152065,
        "cond_entropy-2": 0.588542902415503,
        "distinct-3": 1.0,
        "vocab_size-3": 106,
        "unique-3": 106,
        "entropy-3": 6.727920454563184,
        "cond_entropy-3": -0.09225850785198826,
        "total_length-nopunct": 107,
        "mean_pred_length-nopunct": 15.285714285714286,
        "std_pred_length-nopunct": 5.0061187051243525,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8037383177570093,
        "vocab_size-1-nopunct": 86,
        "unique-1-nopunct": 77,
        "entropy-1-nopunct": 6.17329887874253,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 100,
        "unique-2-nopunct": 100,
        "entropy-2-nopunct": 6.6438561897747395,
        "cond_entropy-2-nopunct": 0.5103290785682895,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 93,
        "unique-3-nopunct": 93,
        "entropy-3-nopunct": 6.539158811108037,
        "cond_entropy-3-nopunct": -0.10469737866669346,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.81,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21212121212121213,
            "2": 0.4,
            "3": 0.8441558441558441
        },
        "nist": 5.325013758058748,
        "bleu": 40.72696,
        "rouge1": {
            "precision": 0.78775,
            "recall": 0.81475,
            "fmeasure": 0.79442
        },
        "rouge2": {
            "precision": 0.50544,
            "recall": 0.52496,
            "fmeasure": 0.51004
        },
        "rougeL": {
            "precision": 0.64716,
            "recall": 0.65552,
            "fmeasure": 0.64539
        },
        "rougeLsum": {
            "precision": 0.64716,
            "recall": 0.65552,
            "fmeasure": 0.64539
        },
        "nubia": {
            "semantic_relation": 4.36073,
            "contradiction": 1.14339,
            "irrelevancy": 32.4478,
            "logical_agreement": 66.4088,
            "grammar_ref": 4.94315,
            "grammar_hyp": 4.75853,
            "nubia_score": 0.81227
        },
        "meteor": 0.4218447903221516,
        "bleurt": 0.36226,
        "bertscore": {
            "precision": 0.9302,
            "recall": 0.93459,
            "f1": 0.92998
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_272": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 7,
        "total_length": 81,
        "mean_pred_length": 11.571428571428571,
        "std_pred_length": 2.969229955832361,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 17,
        "distinct-1": 0.6172839506172839,
        "vocab_size-1": 50,
        "unique-1": 39,
        "entropy-1": 5.203367133152381,
        "distinct-2": 0.8648648648648649,
        "vocab_size-2": 64,
        "unique-2": 56,
        "entropy-2": 5.912156068331657,
        "cond_entropy-2": 0.5507334707701087,
        "distinct-3": 0.9253731343283582,
        "vocab_size-3": 62,
        "unique-3": 57,
        "entropy-3": 5.916835459114484,
        "cond_entropy-3": 0.005889556172106417,
        "total_length-nopunct": 69,
        "mean_pred_length-nopunct": 9.857142857142858,
        "std_pred_length-nopunct": 2.695423180587601,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.6956521739130435,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.227452173887279,
        "distinct-2-nopunct": 0.8709677419354839,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.663873729741712,
        "cond_entropy-2-nopunct": 0.5036393942453385,
        "distinct-3-nopunct": 0.9454545454545454,
        "vocab_size-3-nopunct": 52,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.672268804433746,
        "cond_entropy-3-nopunct": 0.008981584955966314,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1875,
            "2": 0.6153846153846154,
            "3": 0.7857142857142857
        },
        "nist": 5.088883027706059,
        "bleu": 54.34612,
        "rouge1": {
            "precision": 0.8164,
            "recall": 0.7679,
            "fmeasure": 0.786
        },
        "rouge2": {
            "precision": 0.60625,
            "recall": 0.56858,
            "fmeasure": 0.58175
        },
        "rougeL": {
            "precision": 0.76502,
            "recall": 0.71284,
            "fmeasure": 0.7327
        },
        "rougeLsum": {
            "precision": 0.76502,
            "recall": 0.71284,
            "fmeasure": 0.7327
        },
        "nubia": {
            "semantic_relation": 4.3506,
            "contradiction": 21.89212,
            "irrelevancy": 18.00751,
            "logical_agreement": 60.10036,
            "grammar_ref": 5.14386,
            "grammar_hyp": 5.0632,
            "nubia_score": 0.78445
        },
        "meteor": 0.4375294572673365,
        "bleurt": 0.46014,
        "bertscore": {
            "precision": 0.9543,
            "recall": 0.95035,
            "f1": 0.95109
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_124": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 14,
        "total_length": 235,
        "mean_pred_length": 16.785714285714285,
        "std_pred_length": 5.621115438728349,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 29,
        "distinct-1": 0.5319148936170213,
        "vocab_size-1": 125,
        "unique-1": 96,
        "entropy-1": 6.22399985293706,
        "distinct-2": 0.8506787330316742,
        "vocab_size-2": 188,
        "unique-2": 170,
        "entropy-2": 7.373587976543738,
        "cond_entropy-2": 1.063588253310445,
        "distinct-3": 0.9371980676328503,
        "vocab_size-3": 194,
        "unique-3": 183,
        "entropy-3": 7.558221257016208,
        "cond_entropy-3": 0.1862804908165896,
        "total_length-nopunct": 204,
        "mean_pred_length-nopunct": 14.571428571428571,
        "std_pred_length-nopunct": 4.995916700013061,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5931372549019608,
        "vocab_size-1-nopunct": 121,
        "unique-1-nopunct": 96,
        "entropy-1-nopunct": 6.231988051286167,
        "distinct-2-nopunct": 0.8421052631578947,
        "vocab_size-2-nopunct": 160,
        "unique-2-nopunct": 145,
        "entropy-2-nopunct": 7.119521277755499,
        "cond_entropy-2-nopunct": 0.9563682750395556,
        "distinct-3-nopunct": 0.9318181818181818,
        "vocab_size-3-nopunct": 164,
        "unique-3-nopunct": 154,
        "entropy-3-nopunct": 7.311704345910037,
        "cond_entropy-3-nopunct": 0.19130380116259918,
        "msttr-100": 0.63,
        "msttr-100_nopunct": 0.665,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19047619047619047,
            "2": 0.4444444444444444,
            "3": 0.6764705882352942
        },
        "nist": 5.734103618151547,
        "bleu": 43.97203,
        "rouge1": {
            "precision": 0.74004,
            "recall": 0.70169,
            "fmeasure": 0.7154
        },
        "rouge2": {
            "precision": 0.49258,
            "recall": 0.47333,
            "fmeasure": 0.47875
        },
        "rougeL": {
            "precision": 0.64666,
            "recall": 0.62431,
            "fmeasure": 0.63053
        },
        "rougeLsum": {
            "precision": 0.64666,
            "recall": 0.62431,
            "fmeasure": 0.63053
        },
        "nubia": {
            "semantic_relation": 4.30491,
            "contradiction": 8.94638,
            "irrelevancy": 15.59202,
            "logical_agreement": 75.4616,
            "grammar_ref": 4.7817,
            "grammar_hyp": 4.84535,
            "nubia_score": 0.75011
        },
        "meteor": 0.37096805736676214,
        "bleurt": 0.32274,
        "bertscore": {
            "precision": 0.93885,
            "recall": 0.92869,
            "f1": 0.93264
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_510": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 1.0,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 15,
        "distinct-1": 0.8214285714285714,
        "vocab_size-1": 23,
        "unique-1": 19,
        "entropy-1": 4.423251796980338,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.22981123847439044,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9130434782608695,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.349648912578752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.05923165719793806,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.14438990933517493,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.0,
            "3": 0.75
        },
        "nist": 3.73348864222407,
        "bleu": 9.95128,
        "rouge1": {
            "precision": 0.71282,
            "recall": 0.64937,
            "fmeasure": 0.66526
        },
        "rouge2": {
            "precision": 0.35648,
            "recall": 0.34365,
            "fmeasure": 0.34201
        },
        "rougeL": {
            "precision": 0.4141,
            "recall": 0.39287,
            "fmeasure": 0.39513
        },
        "rougeLsum": {
            "precision": 0.4141,
            "recall": 0.39287,
            "fmeasure": 0.39513
        },
        "nubia": {
            "semantic_relation": 4.42022,
            "contradiction": 0.25141,
            "irrelevancy": 0.79258,
            "logical_agreement": 98.95601,
            "grammar_ref": 5.35082,
            "grammar_hyp": 5.72188,
            "nubia_score": 0.7909
        },
        "meteor": 0.3701057752542399,
        "bleurt": 0.30301,
        "bertscore": {
            "precision": 0.91443,
            "recall": 0.90755,
            "f1": 0.90753
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_462": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 82,
        "mean_pred_length": 20.5,
        "std_pred_length": 5.5,
        "median_pred_length": 21.5,
        "min_pred_length": 12,
        "max_pred_length": 27,
        "distinct-1": 0.7682926829268293,
        "vocab_size-1": 63,
        "unique-1": 53,
        "entropy-1": 5.782924986584383,
        "distinct-2": 0.9358974358974359,
        "vocab_size-2": 73,
        "unique-2": 68,
        "entropy-2": 6.157197090657128,
        "cond_entropy-2": 0.378099130638572,
        "distinct-3": 0.972972972972973,
        "vocab_size-3": 72,
        "unique-3": 70,
        "entropy-3": 6.155399311574901,
        "cond_entropy-3": 0.005132227847782368,
        "total_length-nopunct": 73,
        "mean_pred_length-nopunct": 18.25,
        "std_pred_length-nopunct": 5.7608593109014565,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8082191780821918,
        "vocab_size-1-nopunct": 59,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.730786545122122,
        "distinct-2-nopunct": 0.927536231884058,
        "vocab_size-2-nopunct": 64,
        "unique-2-nopunct": 59,
        "entropy-2-nopunct": 5.963596920546281,
        "cond_entropy-2-nopunct": 0.25942127477245513,
        "distinct-3-nopunct": 0.9692307692307692,
        "vocab_size-3-nopunct": 63,
        "unique-3-nopunct": 61,
        "entropy-3-nopunct": 5.960829351489997,
        "cond_entropy-3-nopunct": 0.0061510485579777535,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5,
            "3": 0.6388888888888888
        },
        "nist": 3.410781453901441,
        "bleu": 35.92183,
        "rouge1": {
            "precision": 0.77009,
            "recall": 0.6944,
            "fmeasure": 0.72813
        },
        "rouge2": {
            "precision": 0.55223,
            "recall": 0.51203,
            "fmeasure": 0.53027
        },
        "rougeL": {
            "precision": 0.69122,
            "recall": 0.63264,
            "fmeasure": 0.6591
        },
        "rougeLsum": {
            "precision": 0.69122,
            "recall": 0.63264,
            "fmeasure": 0.6591
        },
        "nubia": {
            "semantic_relation": 3.89304,
            "contradiction": 20.49851,
            "irrelevancy": 26.86819,
            "logical_agreement": 52.6333,
            "grammar_ref": 4.59177,
            "grammar_hyp": 4.65582,
            "nubia_score": 0.62416
        },
        "meteor": 0.3103116549212985,
        "bleurt": 0.1482,
        "bertscore": {
            "precision": 0.93046,
            "recall": 0.9061,
            "f1": 0.91801
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_595": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 47,
        "mean_pred_length": 23.5,
        "std_pred_length": 0.5,
        "median_pred_length": 23.5,
        "min_pred_length": 23,
        "max_pred_length": 24,
        "distinct-1": 0.7659574468085106,
        "vocab_size-1": 36,
        "unique-1": 29,
        "entropy-1": 4.9936414479201865,
        "distinct-2": 0.9555555555555556,
        "vocab_size-2": 43,
        "unique-2": 41,
        "entropy-2": 5.402964207440784,
        "cond_entropy-2": 0.38265535313454646,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": 0.027434914186376908,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 21.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 21.5,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7441860465116279,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.813136197106742,
        "distinct-2-nopunct": 0.9512195121951219,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.259991029008325,
        "cond_entropy-2-nopunct": 0.42013114946995933,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": 0.030414316808267495,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666,
            "3": 0.8
        },
        "nist": 3.0245956062136967,
        "bleu": 26.77928,
        "rouge1": {
            "precision": 0.59306,
            "recall": 0.80881,
            "fmeasure": 0.6749
        },
        "rouge2": {
            "precision": 0.36842,
            "recall": 0.55857,
            "fmeasure": 0.43826
        },
        "rougeL": {
            "precision": 0.5125,
            "recall": 0.78602,
            "fmeasure": 0.61564
        },
        "rougeLsum": {
            "precision": 0.5125,
            "recall": 0.78602,
            "fmeasure": 0.61564
        },
        "nubia": {
            "semantic_relation": 4.1287,
            "contradiction": 1.43886,
            "irrelevancy": 56.24821,
            "logical_agreement": 42.31293,
            "grammar_ref": 4.12394,
            "grammar_hyp": 3.36897,
            "nubia_score": 0.69541
        },
        "meteor": 0.40755685579216316,
        "bleurt": 0.09598,
        "bertscore": {
            "precision": 0.88057,
            "recall": 0.93488,
            "f1": 0.9055
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_615": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 51,
        "mean_pred_length": 17.0,
        "std_pred_length": 3.7416573867739413,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.803921568627451,
        "vocab_size-1": 41,
        "unique-1": 35,
        "entropy-1": 5.2114493614945,
        "distinct-2": 1.0,
        "vocab_size-2": 48,
        "unique-2": 48,
        "entropy-2": 5.5849625007211605,
        "cond_entropy-2": 0.3606574713398053,
        "distinct-3": 1.0,
        "vocab_size-3": 45,
        "unique-3": 45,
        "entropy-3": 5.491853096329673,
        "cond_entropy-3": -0.09310940439148176,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 3.559026084010437,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.191635874011297,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.3923174227787625,
        "cond_entropy-2-nopunct": 0.22212563607591748,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": -0.10691520391651191,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.11764705882352941,
            "3": 0.8055555555555556
        },
        "nist": 4.134685189381422,
        "bleu": 45.7577,
        "rouge1": {
            "precision": 0.78184,
            "recall": 0.74053,
            "fmeasure": 0.75888
        },
        "rouge2": {
            "precision": 0.56004,
            "recall": 0.53018,
            "fmeasure": 0.5434
        },
        "rougeL": {
            "precision": 0.64231,
            "recall": 0.60868,
            "fmeasure": 0.62289
        },
        "rougeLsum": {
            "precision": 0.64231,
            "recall": 0.60868,
            "fmeasure": 0.62289
        },
        "nubia": {
            "semantic_relation": 4.4354,
            "contradiction": 2.43983,
            "irrelevancy": 32.75108,
            "logical_agreement": 64.80909,
            "grammar_ref": 4.60968,
            "grammar_hyp": 4.84402,
            "nubia_score": 0.73328
        },
        "meteor": 0.39186730725880503,
        "bleurt": 0.11022,
        "bertscore": {
            "precision": 0.93446,
            "recall": 0.9341,
            "f1": 0.93427
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_273": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 14,
        "total_length": 226,
        "mean_pred_length": 16.142857142857142,
        "std_pred_length": 5.779979521183974,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.5796460176991151,
        "vocab_size-1": 131,
        "unique-1": 104,
        "entropy-1": 6.362410291349644,
        "distinct-2": 0.9009433962264151,
        "vocab_size-2": 191,
        "unique-2": 177,
        "entropy-2": 7.500256952174103,
        "cond_entropy-2": 1.0246555512830735,
        "distinct-3": 0.9494949494949495,
        "vocab_size-3": 188,
        "unique-3": 181,
        "entropy-3": 7.516908829642772,
        "cond_entropy-3": 0.012547276627521229,
        "total_length-nopunct": 200,
        "mean_pred_length-nopunct": 14.285714285714286,
        "std_pred_length-nopunct": 5.29728463363976,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.635,
        "vocab_size-1-nopunct": 127,
        "unique-1-nopunct": 102,
        "entropy-1-nopunct": 6.427374912174878,
        "distinct-2-nopunct": 0.9032258064516129,
        "vocab_size-2-nopunct": 168,
        "unique-2-nopunct": 157,
        "entropy-2-nopunct": 7.311929442793581,
        "cond_entropy-2-nopunct": 0.9438595730186929,
        "distinct-3-nopunct": 0.9476744186046512,
        "vocab_size-3-nopunct": 163,
        "unique-3-nopunct": 157,
        "entropy-3-nopunct": 7.308446949431775,
        "cond_entropy-3-nopunct": 0.0033850133615085072,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.71,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.273972602739726,
            "2": 0.5076923076923077,
            "3": 0.6695652173913044
        },
        "nist": 4.990965358529537,
        "bleu": 35.25724,
        "rouge1": {
            "precision": 0.69174,
            "recall": 0.64122,
            "fmeasure": 0.65482
        },
        "rouge2": {
            "precision": 0.46665,
            "recall": 0.41316,
            "fmeasure": 0.42977
        },
        "rougeL": {
            "precision": 0.585,
            "recall": 0.53312,
            "fmeasure": 0.54846
        },
        "rougeLsum": {
            "precision": 0.585,
            "recall": 0.53312,
            "fmeasure": 0.54846
        },
        "nubia": {
            "semantic_relation": 3.73488,
            "contradiction": 6.72989,
            "irrelevancy": 49.97466,
            "logical_agreement": 43.29545,
            "grammar_ref": 4.00042,
            "grammar_hyp": 4.09458,
            "nubia_score": 0.62888
        },
        "meteor": 0.3341486024896085,
        "bleurt": 0.05725,
        "bertscore": {
            "precision": 0.92151,
            "recall": 0.90458,
            "f1": 0.91119
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_702": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.625
        },
        "nist": 1.5354391108485552,
        "bleu": 6.25612,
        "rouge1": {
            "precision": 0.54762,
            "recall": 0.74411,
            "fmeasure": 0.62957
        },
        "rouge2": {
            "precision": 0.20513,
            "recall": 0.28333,
            "fmeasure": 0.23741
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.55556,
            "fmeasure": 0.43478
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.55556,
            "fmeasure": 0.43478
        },
        "nubia": {
            "semantic_relation": 3.64791,
            "contradiction": 14.94755,
            "irrelevancy": 81.74272,
            "logical_agreement": 3.30972,
            "grammar_ref": 6.0554,
            "grammar_hyp": 6.26651,
            "nubia_score": 0.40608
        },
        "meteor": 0.30244809061549693,
        "bleurt": -0.43352,
        "bertscore": {
            "precision": 0.85464,
            "recall": 0.90004,
            "f1": 0.87675
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_616": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 57,
        "mean_pred_length": 14.25,
        "std_pred_length": 4.602988159880492,
        "median_pred_length": 14.5,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.7017543859649122,
        "vocab_size-1": 40,
        "unique-1": 30,
        "entropy-1": 5.11149676015134,
        "distinct-2": 0.9811320754716981,
        "vocab_size-2": 52,
        "unique-2": 51,
        "entropy-2": 5.690184605506592,
        "cond_entropy-2": 0.48218922301664113,
        "distinct-3": 1.0,
        "vocab_size-3": 49,
        "unique-3": 49,
        "entropy-3": 5.614709844115208,
        "cond_entropy-3": -0.07239428391737851,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 3.840572873934304,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.72,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.9814678801994505,
        "distinct-2-nopunct": 0.9782608695652174,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.480083695187445,
        "cond_entropy-2-nopunct": 0.5217590918919097,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.3923174227787625,
        "cond_entropy-3-nopunct": -0.08362548565920482,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.5,
            "3": 1.0
        },
        "nist": 3.9465544802120847,
        "bleu": 40.85809,
        "rouge1": {
            "precision": 0.65648,
            "recall": 0.74702,
            "fmeasure": 0.67419
        },
        "rouge2": {
            "precision": 0.41282,
            "recall": 0.52045,
            "fmeasure": 0.45064
        },
        "rougeL": {
            "precision": 0.54921,
            "recall": 0.64906,
            "fmeasure": 0.57771
        },
        "rougeLsum": {
            "precision": 0.54921,
            "recall": 0.64906,
            "fmeasure": 0.57771
        },
        "nubia": {
            "semantic_relation": 3.86447,
            "contradiction": 20.2827,
            "irrelevancy": 41.0635,
            "logical_agreement": 38.65379,
            "grammar_ref": 4.6519,
            "grammar_hyp": 5.29125,
            "nubia_score": 0.56606
        },
        "meteor": 0.34957388779701354,
        "bleurt": 0.17972,
        "bertscore": {
            "precision": 0.90059,
            "recall": 0.91267,
            "f1": 0.90408
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_406": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 5.715476066494082,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.8541666666666666,
        "vocab_size-1": 41,
        "unique-1": 37,
        "entropy-1": 5.246115365169276,
        "distinct-2": 1.0,
        "vocab_size-2": 45,
        "unique-2": 45,
        "entropy-2": 5.491853096329673,
        "cond_entropy-2": 0.16266337348244989,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.0995356735509143,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 5.734883511361751,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9069767441860465,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.205107196461936,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.3219280948873635,
        "cond_entropy-2-nopunct": 0.13340771529343784,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.11247472925841272,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.8333333333333334,
            "2": 0.2857142857142857,
            "3": 0.7272727272727273
        },
        "nist": 3.726726712065226,
        "bleu": 30.27776,
        "rouge1": {
            "precision": 0.57672,
            "recall": 0.51087,
            "fmeasure": 0.51331
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.23903,
            "fmeasure": 0.24167
        },
        "rougeL": {
            "precision": 0.48254,
            "recall": 0.4382,
            "fmeasure": 0.43899
        },
        "rougeLsum": {
            "precision": 0.48254,
            "recall": 0.4382,
            "fmeasure": 0.43899
        },
        "nubia": {
            "semantic_relation": 3.4926,
            "contradiction": 16.99522,
            "irrelevancy": 47.45504,
            "logical_agreement": 35.54974,
            "grammar_ref": 4.68806,
            "grammar_hyp": 5.71952,
            "nubia_score": 0.53123
        },
        "meteor": 0.27384407824552853,
        "bleurt": -0.03019,
        "bertscore": {
            "precision": 0.8906,
            "recall": 0.86012,
            "f1": 0.87347
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_275": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 8,
        "total_length": 143,
        "mean_pred_length": 17.875,
        "std_pred_length": 5.840323193111833,
        "median_pred_length": 15.5,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.6573426573426573,
        "vocab_size-1": 94,
        "unique-1": 70,
        "entropy-1": 6.191315438428618,
        "distinct-2": 0.9259259259259259,
        "vocab_size-2": 125,
        "unique-2": 115,
        "entropy-2": 6.928667448902707,
        "cond_entropy-2": 0.6614145822281293,
        "distinct-3": 0.968503937007874,
        "vocab_size-3": 123,
        "unique-3": 119,
        "entropy-3": 6.925692560787896,
        "cond_entropy-3": 0.00635727869771305,
        "total_length-nopunct": 124,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 5.172040216394301,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7016129032258065,
        "vocab_size-1-nopunct": 87,
        "unique-1-nopunct": 68,
        "entropy-1-nopunct": 6.117514004242878,
        "distinct-2-nopunct": 0.9224137931034483,
        "vocab_size-2-nopunct": 107,
        "unique-2-nopunct": 98,
        "entropy-2-nopunct": 6.702808581334454,
        "cond_entropy-2-nopunct": 0.6257554257911655,
        "distinct-3-nopunct": 0.9722222222222222,
        "vocab_size-3-nopunct": 105,
        "unique-3-nopunct": 102,
        "entropy-3-nopunct": 6.699331946607902,
        "cond_entropy-3-nopunct": 0.008017618147007681,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.72,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.32,
            "2": 0.3181818181818182,
            "3": 0.8085106382978723
        },
        "nist": 5.658300171124445,
        "bleu": 51.3134,
        "rouge1": {
            "precision": 0.78051,
            "recall": 0.74353,
            "fmeasure": 0.75271
        },
        "rouge2": {
            "precision": 0.54966,
            "recall": 0.53497,
            "fmeasure": 0.53598
        },
        "rougeL": {
            "precision": 0.72194,
            "recall": 0.67613,
            "fmeasure": 0.69078
        },
        "rougeLsum": {
            "precision": 0.72194,
            "recall": 0.67613,
            "fmeasure": 0.69078
        },
        "nubia": {
            "semantic_relation": 3.98488,
            "contradiction": 35.97491,
            "irrelevancy": 11.12,
            "logical_agreement": 52.9051,
            "grammar_ref": 5.01189,
            "grammar_hyp": 4.97467,
            "nubia_score": 0.62127
        },
        "meteor": 0.4166697997987147,
        "bleurt": 0.28172,
        "bertscore": {
            "precision": 0.94715,
            "recall": 0.93664,
            "f1": 0.93901
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_464": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.7391304347826086,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 3.8120607396830883,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.5741696572035989,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7391304347826086,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.8120607396830883,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.5741696572035989,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.875
        },
        "nist": 1.6926672858542593,
        "bleu": 32.33843,
        "rouge1": {
            "precision": 0.4375,
            "recall": 0.77747,
            "fmeasure": 0.55974
        },
        "rouge2": {
            "precision": 0.36957,
            "recall": 0.67949,
            "fmeasure": 0.47857
        },
        "rougeL": {
            "precision": 0.4375,
            "recall": 0.77747,
            "fmeasure": 0.55974
        },
        "rougeLsum": {
            "precision": 0.4375,
            "recall": 0.77747,
            "fmeasure": 0.55974
        },
        "nubia": {
            "semantic_relation": 2.96138,
            "contradiction": 97.48406,
            "irrelevancy": 2.16533,
            "logical_agreement": 0.35061,
            "grammar_ref": 3.57757,
            "grammar_hyp": 3.20166,
            "nubia_score": 0.49164
        },
        "meteor": 0.3756573986439153,
        "bleurt": 0.05451,
        "bertscore": {
            "precision": 0.86085,
            "recall": 0.95775,
            "f1": 0.90672
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_424": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 61,
        "mean_pred_length": 15.25,
        "std_pred_length": 6.015604707757983,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.6721311475409836,
        "vocab_size-1": 41,
        "unique-1": 31,
        "entropy-1": 5.086314796508344,
        "distinct-2": 0.9649122807017544,
        "vocab_size-2": 55,
        "unique-2": 53,
        "entropy-2": 5.762714575568245,
        "cond_entropy-2": 0.5953066240461877,
        "distinct-3": 1.0,
        "vocab_size-3": 53,
        "unique-3": 53,
        "entropy-3": 5.727920454563195,
        "cond_entropy-3": -0.029497861488334932,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 5.629165124598851,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7090909090909091,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.026636531627803,
        "distinct-2-nopunct": 0.9607843137254902,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.59399396942248,
        "cond_entropy-2-nopunct": 0.6069435697081488,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.55458885167764,
        "cond_entropy-3-nopunct": -0.054006703059815496,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0,
            "3": 0.7
        },
        "nist": 4.026274447199566,
        "bleu": 34.64124,
        "rouge1": {
            "precision": 0.63676,
            "recall": 0.74514,
            "fmeasure": 0.68013
        },
        "rouge2": {
            "precision": 0.36423,
            "recall": 0.43135,
            "fmeasure": 0.39105
        },
        "rougeL": {
            "precision": 0.53417,
            "recall": 0.6271,
            "fmeasure": 0.57027
        },
        "rougeLsum": {
            "precision": 0.53417,
            "recall": 0.6271,
            "fmeasure": 0.57027
        },
        "nubia": {
            "semantic_relation": 4.49758,
            "contradiction": 0.28165,
            "irrelevancy": 26.77182,
            "logical_agreement": 72.94653,
            "grammar_ref": 4.90076,
            "grammar_hyp": 4.70519,
            "nubia_score": 0.81522
        },
        "meteor": 0.39754016185226,
        "bleurt": 0.18421,
        "bertscore": {
            "precision": 0.9104,
            "recall": 0.92698,
            "f1": 0.91836
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_407": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "nist": 3.268791839123143,
        "bleu": 29.37717,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.76515,
            "fmeasure": 0.70899
        },
        "rouge2": {
            "precision": 0.40741,
            "recall": 0.48095,
            "fmeasure": 0.4386
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.76515,
            "fmeasure": 0.70899
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.76515,
            "fmeasure": 0.70899
        },
        "nubia": {
            "semantic_relation": 3.72984,
            "contradiction": 0.08344,
            "irrelevancy": 99.77021,
            "logical_agreement": 0.14636,
            "grammar_ref": 4.68733,
            "grammar_hyp": 4.87498,
            "nubia_score": 0.62575
        },
        "meteor": 0.502066823618207,
        "bleurt": -0.08053,
        "bertscore": {
            "precision": 0.90278,
            "recall": 0.95952,
            "f1": 0.93028
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_47": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 3.0,
        "median_pred_length": 17.0,
        "min_pred_length": 14,
        "max_pred_length": 20,
        "distinct-1": 0.7941176470588235,
        "vocab_size-1": 27,
        "unique-1": 21,
        "entropy-1": 4.6534955617749425,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.3111273931922692,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.09310940439148141,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.601409765557392,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": 0.33205351234730085,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.09953567355091442,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9230769230769231
        },
        "nist": 3.9665634650549704,
        "bleu": 61.79655,
        "rouge1": {
            "precision": 0.79853,
            "recall": 0.86147,
            "fmeasure": 0.82738
        },
        "rouge2": {
            "precision": 0.65,
            "recall": 0.7,
            "fmeasure": 0.67273
        },
        "rougeL": {
            "precision": 0.76007,
            "recall": 0.81602,
            "fmeasure": 0.78571
        },
        "rougeLsum": {
            "precision": 0.76007,
            "recall": 0.81602,
            "fmeasure": 0.78571
        },
        "nubia": {
            "semantic_relation": 4.62931,
            "contradiction": 0.15839,
            "irrelevancy": 50.31043,
            "logical_agreement": 49.53118,
            "grammar_ref": 5.14789,
            "grammar_hyp": 5.0586,
            "nubia_score": 0.85041
        },
        "meteor": 0.47913692003636676,
        "bleurt": 0.59964,
        "bertscore": {
            "precision": 0.95435,
            "recall": 0.97155,
            "f1": 0.96285
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_512": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9565217391304348,
        "vocab_size-1": 22,
        "unique-1": 21,
        "entropy-1": 4.436605434317882,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.026778753489375348,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9545454545454546,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.368522527728205,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.02812389937955851,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.5
        },
        "nist": 0.6371497437072996,
        "bleu": 8.86242,
        "rouge1": {
            "precision": 0.78788,
            "recall": 0.40686,
            "fmeasure": 0.53626
        },
        "rouge2": {
            "precision": 0.36508,
            "recall": 0.17278,
            "fmeasure": 0.23453
        },
        "rougeL": {
            "precision": 0.5303,
            "recall": 0.26334,
            "fmeasure": 0.3517
        },
        "rougeLsum": {
            "precision": 0.5303,
            "recall": 0.26334,
            "fmeasure": 0.3517
        },
        "nubia": {
            "semantic_relation": 3.48276,
            "contradiction": 1.79069,
            "irrelevancy": 91.00938,
            "logical_agreement": 7.19993,
            "grammar_ref": 4.78179,
            "grammar_hyp": 4.45815,
            "nubia_score": 0.37745
        },
        "meteor": 0.19992304291471027,
        "bleurt": -0.4445,
        "bertscore": {
            "precision": 0.87709,
            "recall": 0.81921,
            "f1": 0.84714
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_774": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 2.0,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 24,
        "unique-1": 20,
        "entropy-1": 4.52164063634332,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.12385402685271857,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.88,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.403856189774722,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.14057533149967955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6,
            "3": 0.68
        },
        "nist": 3.254882890186693,
        "bleu": 21.50748,
        "rouge1": {
            "precision": 0.75325,
            "recall": 0.68019,
            "fmeasure": 0.70397
        },
        "rouge2": {
            "precision": 0.34872,
            "recall": 0.33995,
            "fmeasure": 0.33775
        },
        "rougeL": {
            "precision": 0.61905,
            "recall": 0.48985,
            "fmeasure": 0.54082
        },
        "rougeLsum": {
            "precision": 0.61905,
            "recall": 0.48985,
            "fmeasure": 0.54082
        },
        "nubia": {
            "semantic_relation": 4.53912,
            "contradiction": 0.21582,
            "irrelevancy": 0.58289,
            "logical_agreement": 99.20129,
            "grammar_ref": 4.18803,
            "grammar_hyp": 4.1108,
            "nubia_score": 0.85693
        },
        "meteor": 0.30532229925816584,
        "bleurt": 0.29323,
        "bertscore": {
            "precision": 0.91606,
            "recall": 0.89062,
            "f1": 0.89557
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_465": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 1.0,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 13,
        "distinct-1": 0.9583333333333334,
        "vocab_size-1": 23,
        "unique-1": 22,
        "entropy-1": 4.501629167387823,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.39231742277876,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.14438990933517493,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.8,
            "2": 0.375,
            "3": 0.75
        },
        "nist": 4.112900387136639,
        "bleu": 32.19348,
        "rouge1": {
            "precision": 0.82273,
            "recall": 0.70196,
            "fmeasure": 0.75675
        },
        "rouge2": {
            "precision": 0.54259,
            "recall": 0.45662,
            "fmeasure": 0.49528
        },
        "rougeL": {
            "precision": 0.65,
            "recall": 0.59857,
            "fmeasure": 0.61693
        },
        "rougeLsum": {
            "precision": 0.65,
            "recall": 0.59857,
            "fmeasure": 0.61693
        },
        "nubia": {
            "semantic_relation": 3.95748,
            "contradiction": 30.20545,
            "irrelevancy": 22.25315,
            "logical_agreement": 47.5414,
            "grammar_ref": 5.19402,
            "grammar_hyp": 5.59866,
            "nubia_score": 0.5305
        },
        "meteor": 0.35718727209392626,
        "bleurt": 0.12365,
        "bertscore": {
            "precision": 0.92298,
            "recall": 0.92992,
            "f1": 0.92017
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_513": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.8571428571428571
        },
        "nist": 2.1717051482041896,
        "bleu": 18.84239,
        "rouge1": {
            "precision": 0.54167,
            "recall": 0.60317,
            "fmeasure": 0.5641
        },
        "rouge2": {
            "precision": 0.18182,
            "recall": 0.22596,
            "fmeasure": 0.19956
        },
        "rougeL": {
            "precision": 0.54167,
            "recall": 0.60317,
            "fmeasure": 0.5641
        },
        "rougeLsum": {
            "precision": 0.54167,
            "recall": 0.60317,
            "fmeasure": 0.5641
        },
        "nubia": {
            "semantic_relation": 3.05933,
            "contradiction": 13.89129,
            "irrelevancy": 67.64748,
            "logical_agreement": 18.46123,
            "grammar_ref": 5.58883,
            "grammar_hyp": 4.25367,
            "nubia_score": 0.39826
        },
        "meteor": 0.3814227898237972,
        "bleurt": 0.19523,
        "bertscore": {
            "precision": 0.85706,
            "recall": 0.92701,
            "f1": 0.89066
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_468": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 6,
        "total_length": 88,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 4.853406592853679,
        "median_pred_length": 13.5,
        "min_pred_length": 8,
        "max_pred_length": 21,
        "distinct-1": 0.6931818181818182,
        "vocab_size-1": 61,
        "unique-1": 48,
        "entropy-1": 5.638060312529419,
        "distinct-2": 0.9390243902439024,
        "vocab_size-2": 77,
        "unique-2": 72,
        "entropy-2": 6.235600785105892,
        "cond_entropy-2": 0.5160598306522142,
        "distinct-3": 0.9736842105263158,
        "vocab_size-3": 74,
        "unique-3": 72,
        "entropy-3": 6.195295934496223,
        "cond_entropy-3": -0.030677122753445273,
        "total_length-nopunct": 81,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 4.924428900898052,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7283950617283951,
        "vocab_size-1-nopunct": 59,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.615516244081443,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 70,
        "unique-2-nopunct": 65,
        "entropy-2-nopunct": 6.0954853571625565,
        "cond_entropy-2-nopunct": 0.5379158137853511,
        "distinct-3-nopunct": 0.9710144927536232,
        "vocab_size-3-nopunct": 67,
        "unique-3-nopunct": 65,
        "entropy-3-nopunct": 6.05055344228541,
        "cond_entropy-3-nopunct": -0.03333771197858131,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.5555555555555556,
            "3": 0.7101449275362319
        },
        "nist": 4.736307652325771,
        "bleu": 42.66062,
        "rouge1": {
            "precision": 0.78061,
            "recall": 0.73104,
            "fmeasure": 0.74928
        },
        "rouge2": {
            "precision": 0.54655,
            "recall": 0.5115,
            "fmeasure": 0.52427
        },
        "rougeL": {
            "precision": 0.69447,
            "recall": 0.65574,
            "fmeasure": 0.66926
        },
        "rougeLsum": {
            "precision": 0.69447,
            "recall": 0.65574,
            "fmeasure": 0.66926
        },
        "nubia": {
            "semantic_relation": 4.32744,
            "contradiction": 13.88906,
            "irrelevancy": 28.29797,
            "logical_agreement": 57.81296,
            "grammar_ref": 4.9652,
            "grammar_hyp": 5.30416,
            "nubia_score": 0.72679
        },
        "meteor": 0.3850027272896468,
        "bleurt": 0.38404,
        "bertscore": {
            "precision": 0.93607,
            "recall": 0.91906,
            "f1": 0.92577
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_425": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 1.0,
            "3": 0.5714285714285714
        },
        "nist": 2.5715848628172226,
        "bleu": 32.5234,
        "rouge1": {
            "precision": 0.61538,
            "recall": 0.48718,
            "fmeasure": 0.54094
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.44444,
            "fmeasure": 0.41111
        },
        "rougeL": {
            "precision": 0.4359,
            "recall": 0.49288,
            "fmeasure": 0.45921
        },
        "rougeLsum": {
            "precision": 0.4359,
            "recall": 0.49288,
            "fmeasure": 0.45921
        },
        "nubia": {
            "semantic_relation": 1.82661,
            "contradiction": 63.96276,
            "irrelevancy": 33.72023,
            "logical_agreement": 2.31701,
            "grammar_ref": 4.13721,
            "grammar_hyp": 4.13063,
            "nubia_score": 0.14762
        },
        "meteor": 0.21739878851510824,
        "bleurt": -0.44794,
        "bertscore": {
            "precision": 0.89771,
            "recall": 0.89598,
            "f1": 0.87776
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_469": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 4.642796092394707,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 18,
        "distinct-1": 0.825,
        "vocab_size-1": 33,
        "unique-1": 28,
        "entropy-1": 4.93418371977919,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.17819790593519452,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.12199052437861026,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 4.189935029992179,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8857142857142857,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.8791433740260075,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.14430721749764197,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.14201900487242786,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.4117647058823529,
            "3": 0.8125
        },
        "nist": 3.728738851320958,
        "bleu": 39.51082,
        "rouge1": {
            "precision": 0.68269,
            "recall": 0.81217,
            "fmeasure": 0.69906
        },
        "rouge2": {
            "precision": 0.51389,
            "recall": 0.57613,
            "fmeasure": 0.51958
        },
        "rougeL": {
            "precision": 0.58654,
            "recall": 0.73016,
            "fmeasure": 0.61414
        },
        "rougeLsum": {
            "precision": 0.58654,
            "recall": 0.73016,
            "fmeasure": 0.61414
        },
        "nubia": {
            "semantic_relation": 3.85926,
            "contradiction": 1.09976,
            "irrelevancy": 43.64878,
            "logical_agreement": 55.25146,
            "grammar_ref": 6.27104,
            "grammar_hyp": 5.5771,
            "nubia_score": 0.67274
        },
        "meteor": 0.33066340715367665,
        "bleurt": 0.20581,
        "bertscore": {
            "precision": 0.90588,
            "recall": 0.9238,
            "f1": 0.91343
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_369": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 49,
        "mean_pred_length": 12.25,
        "std_pred_length": 1.0897247358851685,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 14,
        "distinct-1": 0.6530612244897959,
        "vocab_size-1": 32,
        "unique-1": 23,
        "entropy-1": 4.736759843938598,
        "distinct-2": 0.8222222222222222,
        "vocab_size-2": 37,
        "unique-2": 30,
        "entropy-2": 5.119522262948262,
        "cond_entropy-2": 0.2830246412475866,
        "distinct-3": 0.8536585365853658,
        "vocab_size-3": 35,
        "unique-3": 29,
        "entropy-3": 5.0648690777888135,
        "cond_entropy-3": -0.01832822580516503,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 11.25,
        "std_pred_length-nopunct": 1.0897247358851685,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.6888888888888889,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.713640873915143,
        "distinct-2-nopunct": 0.8048780487804879,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.948896211882388,
        "cond_entropy-2-nopunct": 0.2867882377150042,
        "distinct-3-nopunct": 0.8378378378378378,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.885129041304629,
        "cond_entropy-3-nopunct": -0.04661519298471588,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.09090909090909091,
            "3": 0.8333333333333334
        },
        "nist": 3.901895625651088,
        "bleu": 39.46936,
        "rouge1": {
            "precision": 0.73776,
            "recall": 0.71989,
            "fmeasure": 0.71335
        },
        "rouge2": {
            "precision": 0.55,
            "recall": 0.48477,
            "fmeasure": 0.50395
        },
        "rougeL": {
            "precision": 0.65734,
            "recall": 0.63021,
            "fmeasure": 0.63025
        },
        "rougeLsum": {
            "precision": 0.65734,
            "recall": 0.63021,
            "fmeasure": 0.63025
        },
        "nubia": {
            "semantic_relation": 4.21204,
            "contradiction": 0.41789,
            "irrelevancy": 23.45581,
            "logical_agreement": 76.1263,
            "grammar_ref": 5.27719,
            "grammar_hyp": 5.35301,
            "nubia_score": 0.71673
        },
        "meteor": 0.38657320588921595,
        "bleurt": 0.22686,
        "bertscore": {
            "precision": 0.93262,
            "recall": 0.92923,
            "f1": 0.9299
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_515": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 46,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 2.494438257849294,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.782608695652174,
        "vocab_size-1": 36,
        "unique-1": 28,
        "entropy-1": 5.055958151615122,
        "distinct-2": 0.9302325581395349,
        "vocab_size-2": 40,
        "unique-2": 37,
        "entropy-2": 5.286729870981167,
        "cond_entropy-2": 0.15281646148609582,
        "distinct-3": 1.0,
        "vocab_size-3": 40,
        "unique-3": 40,
        "entropy-3": 5.3219280948873635,
        "cond_entropy-3": 0.04566334018526421,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 2.160246899469287,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8095238095238095,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.993391529870107,
        "distinct-2-nopunct": 0.8974358974358975,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 5.0802740137340425,
        "cond_entropy-2-nopunct": 0.11756909101075651,
        "distinct-3-nopunct": 0.9722222222222222,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.114369445886754,
        "cond_entropy-3-nopunct": 0.051189449246730793,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 1.0
        },
        "nist": 5.187199069971218,
        "bleu": 82.12549,
        "rouge1": {
            "precision": 0.88287,
            "recall": 0.97454,
            "fmeasure": 0.92251
        },
        "rouge2": {
            "precision": 0.85132,
            "recall": 0.96498,
            "fmeasure": 0.8981
        },
        "rougeL": {
            "precision": 0.87546,
            "recall": 0.97596,
            "fmeasure": 0.91763
        },
        "rougeLsum": {
            "precision": 0.87546,
            "recall": 0.97596,
            "fmeasure": 0.91763
        },
        "nubia": {
            "semantic_relation": 4.54485,
            "contradiction": 0.53232,
            "irrelevancy": 47.15769,
            "logical_agreement": 52.30999,
            "grammar_ref": 4.92539,
            "grammar_hyp": 4.74708,
            "nubia_score": 0.85186
        },
        "meteor": 0.5890646732423985,
        "bleurt": 0.65616,
        "bertscore": {
            "precision": 0.97094,
            "recall": 0.98603,
            "f1": 0.97676
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_276": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 18,
        "total_length": 278,
        "mean_pred_length": 15.444444444444445,
        "std_pred_length": 4.9578470038495785,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.6258992805755396,
        "vocab_size-1": 174,
        "unique-1": 150,
        "entropy-1": 6.7127796652565,
        "distinct-2": 0.95,
        "vocab_size-2": 247,
        "unique-2": 242,
        "entropy-2": 7.871274687970206,
        "cond_entropy-2": 0.9885874728411835,
        "distinct-3": 1.0,
        "vocab_size-3": 242,
        "unique-3": 242,
        "entropy-3": 7.9188632372745955,
        "cond_entropy-3": 0.05882688092028986,
        "total_length-nopunct": 242,
        "mean_pred_length-nopunct": 13.444444444444445,
        "std_pred_length-nopunct": 4.6930471293206395,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6983471074380165,
        "vocab_size-1-nopunct": 169,
        "unique-1-nopunct": 147,
        "entropy-1-nopunct": 6.855119423330111,
        "distinct-2-nopunct": 0.9419642857142857,
        "vocab_size-2-nopunct": 211,
        "unique-2-nopunct": 206,
        "entropy-2-nopunct": 7.631978973329248,
        "cond_entropy-2-nopunct": 0.8578746779054268,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 206,
        "unique-3-nopunct": 206,
        "entropy-3-nopunct": 7.686500527183218,
        "cond_entropy-3-nopunct": 0.06984566587874197,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.775,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.42857142857142855,
            "3": 0.7684210526315789
        },
        "nist": 5.913432205750982,
        "bleu": 44.15262,
        "rouge1": {
            "precision": 0.72043,
            "recall": 0.74494,
            "fmeasure": 0.72579
        },
        "rouge2": {
            "precision": 0.47308,
            "recall": 0.50111,
            "fmeasure": 0.48206
        },
        "rougeL": {
            "precision": 0.65241,
            "recall": 0.67561,
            "fmeasure": 0.65773
        },
        "rougeLsum": {
            "precision": 0.65241,
            "recall": 0.67561,
            "fmeasure": 0.65773
        },
        "nubia": {
            "semantic_relation": 4.34768,
            "contradiction": 5.65577,
            "irrelevancy": 20.72023,
            "logical_agreement": 73.62399,
            "grammar_ref": 5.08526,
            "grammar_hyp": 4.92611,
            "nubia_score": 0.77869
        },
        "meteor": 0.41423729425811967,
        "bleurt": 0.38776,
        "bertscore": {
            "precision": 0.92774,
            "recall": 0.93219,
            "f1": 0.92931
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_516": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 76,
        "mean_pred_length": 19.0,
        "std_pred_length": 6.96419413859206,
        "median_pred_length": 20.5,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.8157894736842105,
        "vocab_size-1": 62,
        "unique-1": 52,
        "entropy-1": 5.833325210755079,
        "distinct-2": 0.9722222222222222,
        "vocab_size-2": 70,
        "unique-2": 68,
        "entropy-2": 6.114369445886762,
        "cond_entropy-2": 0.2380375921954418,
        "distinct-3": 1.0,
        "vocab_size-3": 68,
        "unique-3": 68,
        "entropy-3": 6.087462841250345,
        "cond_entropy-3": -0.023638630780208267,
        "total_length-nopunct": 68,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 6.442049363362563,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8529411764705882,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.763933429485637,
        "distinct-2-nopunct": 0.984375,
        "vocab_size-2-nopunct": 63,
        "unique-2-nopunct": 62,
        "entropy-2-nopunct": 5.96875,
        "cond_entropy-2-nopunct": 0.22503715874966085,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 60,
        "unique-3-nopunct": 60,
        "entropy-3-nopunct": 5.906890595608517,
        "cond_entropy-3-nopunct": -0.05977607105814808,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6,
            "3": 0.7164179104477612
        },
        "nist": 3.745635055766289,
        "bleu": 32.70165,
        "rouge1": {
            "precision": 0.85889,
            "recall": 0.72314,
            "fmeasure": 0.77793
        },
        "rouge2": {
            "precision": 0.58272,
            "recall": 0.47873,
            "fmeasure": 0.5209
        },
        "rougeL": {
            "precision": 0.75944,
            "recall": 0.64778,
            "fmeasure": 0.69366
        },
        "rougeLsum": {
            "precision": 0.75944,
            "recall": 0.64778,
            "fmeasure": 0.69366
        },
        "nubia": {
            "semantic_relation": 4.26898,
            "contradiction": 0.84959,
            "irrelevancy": 31.81739,
            "logical_agreement": 67.33302,
            "grammar_ref": 4.38942,
            "grammar_hyp": 4.73451,
            "nubia_score": 0.69623
        },
        "meteor": 0.3602165013785364,
        "bleurt": 0.22046,
        "bertscore": {
            "precision": 0.94363,
            "recall": 0.91694,
            "f1": 0.92986
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_519": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.046930949929641655,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.546593564294939,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8181818181818182
        },
        "nist": 3.349837437109427,
        "bleu": 41.62799,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.82143,
            "fmeasure": 0.86845
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.66154,
            "fmeasure": 0.70222
        },
        "rougeL": {
            "precision": 0.61538,
            "recall": 0.55873,
            "fmeasure": 0.58554
        },
        "rougeLsum": {
            "precision": 0.61538,
            "recall": 0.55873,
            "fmeasure": 0.58554
        },
        "nubia": {
            "semantic_relation": 4.98933,
            "contradiction": 0.19485,
            "irrelevancy": 0.59564,
            "logical_agreement": 99.20951,
            "grammar_ref": 5.37123,
            "grammar_hyp": 6.25224,
            "nubia_score": 0.84302
        },
        "meteor": 0.4786875298297855,
        "bleurt": 0.4806,
        "bertscore": {
            "precision": 0.96047,
            "recall": 0.94875,
            "f1": 0.95423
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_370": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 7,
        "total_length": 112,
        "mean_pred_length": 16.0,
        "std_pred_length": 2.5634797778466227,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 20,
        "distinct-1": 0.6875,
        "vocab_size-1": 77,
        "unique-1": 64,
        "entropy-1": 5.9331036099067616,
        "distinct-2": 0.9619047619047619,
        "vocab_size-2": 101,
        "unique-2": 98,
        "entropy-2": 6.630865636693128,
        "cond_entropy-2": 0.568888452792584,
        "distinct-3": 0.9897959183673469,
        "vocab_size-3": 97,
        "unique-3": 96,
        "entropy-3": 6.594301680849911,
        "cond_entropy-3": -0.030608250059450157,
        "total_length-nopunct": 99,
        "mean_pred_length-nopunct": 14.142857142857142,
        "std_pred_length-nopunct": 2.166535841157586,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7474747474747475,
        "vocab_size-1-nopunct": 74,
        "unique-1-nopunct": 64,
        "entropy-1-nopunct": 5.939814574559512,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 88,
        "unique-2-nopunct": 85,
        "entropy-2-nopunct": 6.428400135381336,
        "cond_entropy-2-nopunct": 0.5410507164592182,
        "distinct-3-nopunct": 0.9882352941176471,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 83,
        "entropy-3-nopunct": 6.385861524373001,
        "cond_entropy-3-nopunct": -0.03470175518797617,
        "msttr-100": 0.72,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.16666666666666666,
            "3": 0.9010989010989011
        },
        "nist": 6.539528940254072,
        "bleu": 72.83533,
        "rouge1": {
            "precision": 0.89428,
            "recall": 0.88273,
            "fmeasure": 0.88762
        },
        "rouge2": {
            "precision": 0.74719,
            "recall": 0.73507,
            "fmeasure": 0.74032
        },
        "rougeL": {
            "precision": 0.81114,
            "recall": 0.79898,
            "fmeasure": 0.80424
        },
        "rougeLsum": {
            "precision": 0.81114,
            "recall": 0.79898,
            "fmeasure": 0.80424
        },
        "nubia": {
            "semantic_relation": 4.79805,
            "contradiction": 4.48344,
            "irrelevancy": 4.62513,
            "logical_agreement": 90.89143,
            "grammar_ref": 4.9924,
            "grammar_hyp": 4.98674,
            "nubia_score": 0.90263
        },
        "meteor": 0.4946522293661524,
        "bleurt": 0.62745,
        "bertscore": {
            "precision": 0.98462,
            "recall": 0.98023,
            "f1": 0.98225
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_520": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 7,
        "total_length": 110,
        "mean_pred_length": 15.714285714285714,
        "std_pred_length": 2.5475077857324298,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 20,
        "distinct-1": 0.8,
        "vocab_size-1": 88,
        "unique-1": 81,
        "entropy-1": 6.1893650273540874,
        "distinct-2": 1.0,
        "vocab_size-2": 103,
        "unique-2": 103,
        "entropy-2": 6.686500527183236,
        "cond_entropy-2": 0.3334846532582065,
        "distinct-3": 1.0,
        "vocab_size-3": 96,
        "unique-3": 96,
        "entropy-3": 6.5849625007211605,
        "cond_entropy-3": -0.1015380264620621,
        "total_length-nopunct": 96,
        "mean_pred_length-nopunct": 13.714285714285714,
        "std_pred_length-nopunct": 2.3733211036908783,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8854166666666666,
        "vocab_size-1-nopunct": 85,
        "unique-1-nopunct": 80,
        "entropy-1-nopunct": 6.277569011092754,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 89,
        "unique-2-nopunct": 89,
        "entropy-2-nopunct": 6.47573343096641,
        "cond_entropy-2-nopunct": 0.22234143591183625,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 82,
        "unique-3-nopunct": 82,
        "entropy-3-nopunct": 6.357552004618087,
        "cond_entropy-3-nopunct": -0.11818142634831395,
        "msttr-100": 0.82,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.8405797101449275
        },
        "nist": 4.354511268021327,
        "bleu": 41.63231,
        "rouge1": {
            "precision": 0.70323,
            "recall": 0.74464,
            "fmeasure": 0.70504
        },
        "rouge2": {
            "precision": 0.52103,
            "recall": 0.55898,
            "fmeasure": 0.53191
        },
        "rougeL": {
            "precision": 0.62682,
            "recall": 0.64452,
            "fmeasure": 0.62329
        },
        "rougeLsum": {
            "precision": 0.62682,
            "recall": 0.64452,
            "fmeasure": 0.62329
        },
        "nubia": {
            "semantic_relation": 3.91437,
            "contradiction": 5.75556,
            "irrelevancy": 65.00017,
            "logical_agreement": 29.24427,
            "grammar_ref": 4.63553,
            "grammar_hyp": 4.62152,
            "nubia_score": 0.64215
        },
        "meteor": 0.37310915363942704,
        "bleurt": 0.24978,
        "bertscore": {
            "precision": 0.90833,
            "recall": 0.91407,
            "f1": 0.9092
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_371": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.85,
        "vocab_size-1": 17,
        "unique-1": 14,
        "entropy-1": 4.021928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.2417888922404337,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.8365916681089787,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.21165548686685057,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "nist": 3.6823762073921302,
        "bleu": 37.48171,
        "rouge1": {
            "precision": 0.71875,
            "recall": 0.81795,
            "fmeasure": 0.76418
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.46429,
            "fmeasure": 0.42912
        },
        "rougeL": {
            "precision": 0.34375,
            "recall": 0.38718,
            "fmeasure": 0.36374
        },
        "rougeLsum": {
            "precision": 0.34375,
            "recall": 0.38718,
            "fmeasure": 0.36374
        },
        "nubia": {
            "semantic_relation": 3.34453,
            "contradiction": 49.88488,
            "irrelevancy": 49.78801,
            "logical_agreement": 0.32711,
            "grammar_ref": 4.56931,
            "grammar_hyp": 4.14187,
            "nubia_score": 0.51437
        },
        "meteor": 0.4176346771779895,
        "bleurt": -0.21233,
        "bertscore": {
            "precision": 0.90954,
            "recall": 0.92863,
            "f1": 0.91899
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_522": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964164,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9166666666666666
        },
        "nist": 4.770721208389991,
        "bleu": 80.52254,
        "rouge1": {
            "precision": 0.97222,
            "recall": 0.84455,
            "fmeasure": 0.9019
        },
        "rouge2": {
            "precision": 0.84848,
            "recall": 0.73333,
            "fmeasure": 0.78484
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.80288,
            "fmeasure": 0.85429
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.80288,
            "fmeasure": 0.85429
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.11768,
            "irrelevancy": 0.47514,
            "logical_agreement": 99.40718,
            "grammar_ref": 4.55634,
            "grammar_hyp": 4.71917,
            "nubia_score": 0.98117
        },
        "meteor": 0.5469432736955866,
        "bleurt": 0.74939,
        "bertscore": {
            "precision": 0.99811,
            "recall": 0.98882,
            "f1": 0.99345
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_472": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.186704345910024,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.2186000898557489,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966059,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.433288378057127,
        "bleu": 78.39204,
        "rouge1": {
            "precision": 0.88235,
            "recall": 0.88235,
            "fmeasure": 0.88235
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.75,
            "fmeasure": 0.75
        },
        "rougeL": {
            "precision": 0.88235,
            "recall": 0.88235,
            "fmeasure": 0.88235
        },
        "rougeLsum": {
            "precision": 0.88235,
            "recall": 0.88235,
            "fmeasure": 0.88235
        },
        "nubia": {
            "semantic_relation": 4.85453,
            "contradiction": 0.33848,
            "irrelevancy": 2.11318,
            "logical_agreement": 97.54834,
            "grammar_ref": 5.82691,
            "grammar_hyp": 5.31084,
            "nubia_score": 0.99053
        },
        "meteor": 0.5347033086663171,
        "bleurt": 0.61374,
        "bertscore": {
            "precision": 0.96805,
            "recall": 0.97648,
            "f1": 0.97224
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_524": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.004886164091841,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.40907628033193943,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.875
        },
        "nist": 1.7878134178836338,
        "bleu": 31.4205,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.9697,
            "fmeasure": 0.75973
        },
        "rouge2": {
            "precision": 0.57778,
            "recall": 0.93333,
            "fmeasure": 0.71333
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.9697,
            "fmeasure": 0.75973
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.9697,
            "fmeasure": 0.75973
        },
        "nubia": {
            "semantic_relation": 3.37505,
            "contradiction": 5.20004,
            "irrelevancy": 94.34141,
            "logical_agreement": 0.45855,
            "grammar_ref": 4.055,
            "grammar_hyp": 3.9507,
            "nubia_score": 0.47847
        },
        "meteor": 0.4557938392097601,
        "bleurt": -0.07334,
        "bertscore": {
            "precision": 0.86652,
            "recall": 0.97273,
            "f1": 0.91656
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_849": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 0.7058823529411765
        },
        "nist": 3.6340911243642924,
        "bleu": 22.37906,
        "rouge1": {
            "precision": 0.87037,
            "recall": 0.65278,
            "fmeasure": 0.74603
        },
        "rouge2": {
            "precision": 0.45098,
            "recall": 0.343,
            "fmeasure": 0.38947
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.57449,
            "fmeasure": 0.63968
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.57449,
            "fmeasure": 0.63968
        },
        "nubia": {
            "semantic_relation": 4.27361,
            "contradiction": 0.60843,
            "irrelevancy": 3.47562,
            "logical_agreement": 95.91595,
            "grammar_ref": 3.8277,
            "grammar_hyp": 4.10445,
            "nubia_score": 0.76247
        },
        "meteor": 0.3309740265950007,
        "bleurt": 0.36222,
        "bertscore": {
            "precision": 0.92552,
            "recall": 0.88904,
            "f1": 0.90691
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_705": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.3333333333333333,
            "3": 0.7
        },
        "nist": 3.135877532693031,
        "bleu": 22.82484,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.6337,
            "fmeasure": 0.67487
        },
        "rouge2": {
            "precision": 0.45455,
            "recall": 0.40598,
            "fmeasure": 0.42874
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.51282,
            "fmeasure": 0.53333
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.51282,
            "fmeasure": 0.53333
        },
        "nubia": {
            "semantic_relation": 4.02488,
            "contradiction": 0.11967,
            "irrelevancy": 95.63983,
            "logical_agreement": 4.2405,
            "grammar_ref": 5.35534,
            "grammar_hyp": 4.62716,
            "nubia_score": 0.78975
        },
        "meteor": 0.3332579037365062,
        "bleurt": 0.02943,
        "bertscore": {
            "precision": 0.91369,
            "recall": 0.8982,
            "f1": 0.90588
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_618": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 41,
        "mean_pred_length": 13.666666666666666,
        "std_pred_length": 2.0548046676563256,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 16,
        "distinct-1": 0.926829268292683,
        "vocab_size-1": 38,
        "unique-1": 36,
        "entropy-1": 5.192798650906777,
        "distinct-2": 1.0,
        "vocab_size-2": 38,
        "unique-2": 38,
        "entropy-2": 5.247927513443589,
        "cond_entropy-2": -0.05699291222712945,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": -0.11864449649861893,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 1.699673171197595,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.972972972972973,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.1553993115749,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.087462841250338,
        "cond_entropy-2-nopunct": -0.06316699496684557,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.13326653086346418,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1875,
            "2": 0.3333333333333333,
            "3": 0.8333333333333334
        },
        "nist": 4.021595367232481,
        "bleu": 56.70479,
        "rouge1": {
            "precision": 0.76654,
            "recall": 0.68516,
            "fmeasure": 0.711
        },
        "rouge2": {
            "precision": 0.59259,
            "recall": 0.51727,
            "fmeasure": 0.54112
        },
        "rougeL": {
            "precision": 0.6763,
            "recall": 0.69643,
            "fmeasure": 0.66792
        },
        "rougeLsum": {
            "precision": 0.6763,
            "recall": 0.69643,
            "fmeasure": 0.66792
        },
        "nubia": {
            "semantic_relation": 3.98634,
            "contradiction": 0.2137,
            "irrelevancy": 62.90779,
            "logical_agreement": 36.87852,
            "grammar_ref": 4.66623,
            "grammar_hyp": 4.40346,
            "nubia_score": 0.7292
        },
        "meteor": 0.40427892990391695,
        "bleurt": 0.09395,
        "bertscore": {
            "precision": 0.91967,
            "recall": 0.9211,
            "f1": 0.90549
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_525": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6363636363636364
        },
        "nist": 2.0773589208389827,
        "bleu": 10.5215,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.61111,
            "fmeasure": 0.54762
        },
        "rouge2": {
            "precision": 0.06667,
            "recall": 0.08283,
            "fmeasure": 0.0735
        },
        "rougeL": {
            "precision": 0.3125,
            "recall": 0.38194,
            "fmeasure": 0.34226
        },
        "rougeLsum": {
            "precision": 0.3125,
            "recall": 0.38194,
            "fmeasure": 0.34226
        },
        "nubia": {
            "semantic_relation": 3.46142,
            "contradiction": 26.49646,
            "irrelevancy": 68.36202,
            "logical_agreement": 5.14152,
            "grammar_ref": 5.53377,
            "grammar_hyp": 4.84368,
            "nubia_score": 0.51738
        },
        "meteor": 0.24745797266050804,
        "bleurt": -0.17401,
        "bertscore": {
            "precision": 0.83035,
            "recall": 0.84755,
            "f1": 0.83481
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_372": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 36,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.160246899469287,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 14,
        "distinct-1": 0.75,
        "vocab_size-1": 27,
        "unique-1": 22,
        "entropy-1": 4.572431251322118,
        "distinct-2": 1.0,
        "vocab_size-2": 33,
        "unique-2": 33,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": 0.382192981618064,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.13750352374993471,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 9.333333333333334,
        "std_pred_length-nopunct": 1.699673171197595,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.49468036840891,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.1466967678036592,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1844245711374276,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6153846153846154,
            "3": 0.4444444444444444
        },
        "nist": 2.341887686019774,
        "bleu": 22.91186,
        "rouge1": {
            "precision": 0.82222,
            "recall": 0.5451,
            "fmeasure": 0.61659
        },
        "rouge2": {
            "precision": 0.49832,
            "recall": 0.25943,
            "fmeasure": 0.31444
        },
        "rougeL": {
            "precision": 0.68889,
            "recall": 0.46422,
            "fmeasure": 0.51593
        },
        "rougeLsum": {
            "precision": 0.68889,
            "recall": 0.46422,
            "fmeasure": 0.51593
        },
        "nubia": {
            "semantic_relation": 3.79991,
            "contradiction": 0.67759,
            "irrelevancy": 9.34083,
            "logical_agreement": 89.98158,
            "grammar_ref": 4.97796,
            "grammar_hyp": 5.33622,
            "nubia_score": 0.53923
        },
        "meteor": 0.28033799513460644,
        "bleurt": 0.00192,
        "bertscore": {
            "precision": 0.91054,
            "recall": 0.84617,
            "f1": 0.87484
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_852": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "nist": 2.7109047337507373,
        "bleu": 53.10725,
        "rouge1": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.65278,
            "fmeasure": 0.5381
        },
        "rougeL": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rougeLsum": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "nubia": {
            "semantic_relation": 4.03158,
            "contradiction": 0.1933,
            "irrelevancy": 99.65987,
            "logical_agreement": 0.14683,
            "grammar_ref": 5.68221,
            "grammar_hyp": 4.97464,
            "nubia_score": 0.75981
        },
        "meteor": 0.5033950705050299,
        "bleurt": 0.22576,
        "bertscore": {
            "precision": 0.91794,
            "recall": 0.99099,
            "f1": 0.95307
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_473": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 15,
        "unique-1": 12,
        "entropy-1": 3.8365916681089787,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.27047901627861526,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.734521664779752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.2875371587496606,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.6470588235294118
        },
        "nist": 2.3057655541705024,
        "bleu": 20.11122,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.55988,
            "fmeasure": 0.60741
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.25589,
            "fmeasure": 0.28896
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.26163,
            "fmeasure": 0.29259
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.26163,
            "fmeasure": 0.29259
        },
        "nubia": {
            "semantic_relation": 3.8879,
            "contradiction": 15.85869,
            "irrelevancy": 5.16689,
            "logical_agreement": 78.97442,
            "grammar_ref": 4.86737,
            "grammar_hyp": 6.27449,
            "nubia_score": 0.46117
        },
        "meteor": 0.3049387393248897,
        "bleurt": -0.14861,
        "bertscore": {
            "precision": 0.88456,
            "recall": 0.83523,
            "f1": 0.85618
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_600": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 38,
        "mean_pred_length": 12.666666666666666,
        "std_pred_length": 1.247219128924647,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 14,
        "distinct-1": 0.7894736842105263,
        "vocab_size-1": 30,
        "unique-1": 25,
        "entropy-1": 4.754377842334022,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.281355503501381,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.12928301694496638,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.816496580927726,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8484848484848485,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.680757755722091,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": 0.22916314291673193,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.15200309344505,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.78125
        },
        "nist": 4.066091455935767,
        "bleu": 47.23418,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.82099,
            "fmeasure": 0.80364
        },
        "rouge2": {
            "precision": 0.69169,
            "recall": 0.56136,
            "fmeasure": 0.61432
        },
        "rougeL": {
            "precision": 0.79545,
            "recall": 0.79954,
            "fmeasure": 0.77639
        },
        "rougeLsum": {
            "precision": 0.79545,
            "recall": 0.79954,
            "fmeasure": 0.77639
        },
        "nubia": {
            "semantic_relation": 4.03799,
            "contradiction": 3.27836,
            "irrelevancy": 32.943,
            "logical_agreement": 63.77864,
            "grammar_ref": 4.26152,
            "grammar_hyp": 4.3252,
            "nubia_score": 0.68366
        },
        "meteor": 0.44322617557295046,
        "bleurt": 0.53051,
        "bertscore": {
            "precision": 0.96885,
            "recall": 0.94182,
            "f1": 0.94647
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_620": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.45454545454545453,
            "2": 0.7142857142857143
        },
        "nist": 2.7577002436843325,
        "bleu": 13.03689,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.60714,
            "fmeasure": 0.5125
        },
        "rouge2": {
            "precision": 0.14706,
            "recall": 0.20629,
            "fmeasure": 0.17143
        },
        "rougeL": {
            "precision": 0.30556,
            "recall": 0.41667,
            "fmeasure": 0.35208
        },
        "rougeLsum": {
            "precision": 0.30556,
            "recall": 0.41667,
            "fmeasure": 0.35208
        },
        "nubia": {
            "semantic_relation": 4.02176,
            "contradiction": 5.67349,
            "irrelevancy": 84.53083,
            "logical_agreement": 9.79568,
            "grammar_ref": 5.74657,
            "grammar_hyp": 4.88853,
            "nubia_score": 0.66571
        },
        "meteor": 0.2682854786381321,
        "bleurt": -0.09213,
        "bertscore": {
            "precision": 0.83798,
            "recall": 0.86415,
            "f1": 0.85086
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_780": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.1699250014423126,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.22767,
            "irrelevancy": 0.5448,
            "logical_agreement": 99.22753,
            "grammar_ref": 5.18772,
            "grammar_hyp": 5.18772,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.99428,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_621": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "nist": 4.251192788981044,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 0.95238,
            "recall": 0.91667,
            "fmeasure": 0.93333
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "nubia": {
            "semantic_relation": 4.42679,
            "contradiction": 6.87785,
            "irrelevancy": 1.70123,
            "logical_agreement": 91.42092,
            "grammar_ref": 7.10682,
            "grammar_hyp": 7.20763,
            "nubia_score": 0.72464
        },
        "meteor": 1.0,
        "bleurt": 0.64779,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_623": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 2.9143184224283365,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.90476,
            "fmeasure": 0.92308
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "nubia": {
            "semantic_relation": 4.47646,
            "contradiction": 0.85873,
            "irrelevancy": 0.61324,
            "logical_agreement": 98.52803,
            "grammar_ref": 5.29735,
            "grammar_hyp": 5.49873,
            "nubia_score": 0.81214
        },
        "meteor": 1.0,
        "bleurt": 0.61495,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_707": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.090634124990776,
        "bleu": 76.11606,
        "rouge1": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rouge2": {
            "precision": 0.78788,
            "recall": 0.8963,
            "fmeasure": 0.8381
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "nubia": {
            "semantic_relation": 4.3761,
            "contradiction": 0.09394,
            "irrelevancy": 99.63689,
            "logical_agreement": 0.26917,
            "grammar_ref": 5.85321,
            "grammar_hyp": 5.83654,
            "nubia_score": 0.79202
        },
        "meteor": 0.5715186082473627,
        "bleurt": 0.48581,
        "bertscore": {
            "precision": 0.98299,
            "recall": 0.99732,
            "f1": 0.9901
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_650": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": 0.0930692077718899,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.5216406363433186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": 0.11094091199688534,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 3.50789957099271,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nubia": {
            "semantic_relation": 4.97499,
            "contradiction": 0.89945,
            "irrelevancy": 0.58957,
            "logical_agreement": 98.51098,
            "grammar_ref": 4.12966,
            "grammar_hyp": 4.39551,
            "nubia_score": 0.98513
        },
        "meteor": 1.0,
        "bleurt": 0.89367,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_528": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 3.5,
        "median_pred_length": 15.5,
        "min_pred_length": 12,
        "max_pred_length": 19,
        "distinct-1": 0.8709677419354839,
        "vocab_size-1": 27,
        "unique-1": 23,
        "entropy-1": 4.696131794257844,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.11068123646483508,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.532665279941249,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.1289686876112561,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.8461538461538461
        },
        "nist": 4.560415151991368,
        "bleu": 67.35462,
        "rouge1": {
            "precision": 0.94737,
            "recall": 0.85877,
            "fmeasure": 0.89699
        },
        "rouge2": {
            "precision": 0.82407,
            "recall": 0.76912,
            "fmeasure": 0.79402
        },
        "rougeL": {
            "precision": 0.89474,
            "recall": 0.83597,
            "fmeasure": 0.86295
        },
        "rougeLsum": {
            "precision": 0.89474,
            "recall": 0.83597,
            "fmeasure": 0.86295
        },
        "nubia": {
            "semantic_relation": 4.24925,
            "contradiction": 6.36147,
            "irrelevancy": 2.96138,
            "logical_agreement": 90.67715,
            "grammar_ref": 4.36539,
            "grammar_hyp": 4.52193,
            "nubia_score": 0.73171
        },
        "meteor": 0.4637239579485288,
        "bleurt": 0.51294,
        "bertscore": {
            "precision": 0.97169,
            "recall": 0.94658,
            "f1": 0.95702
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_375": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 8,
        "total_length": 120,
        "mean_pred_length": 15.0,
        "std_pred_length": 4.949747468305833,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.7,
        "vocab_size-1": 84,
        "unique-1": 67,
        "entropy-1": 6.090789267342721,
        "distinct-2": 0.9375,
        "vocab_size-2": 105,
        "unique-2": 98,
        "entropy-2": 6.682354922057592,
        "cond_entropy-2": 0.474398924105282,
        "distinct-3": 0.9615384615384616,
        "vocab_size-3": 100,
        "unique-3": 96,
        "entropy-3": 6.623516641218022,
        "cond_entropy-3": -0.04922289622420451,
        "total_length-nopunct": 106,
        "mean_pred_length-nopunct": 13.25,
        "std_pred_length-nopunct": 4.789311015167004,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7735849056603774,
        "vocab_size-1-nopunct": 82,
        "unique-1-nopunct": 67,
        "entropy-1-nopunct": 6.174814883967991,
        "distinct-2-nopunct": 0.9489795918367347,
        "vocab_size-2-nopunct": 93,
        "unique-2-nopunct": 88,
        "entropy-2-nopunct": 6.512669027788688,
        "cond_entropy-2-nopunct": 0.383005618971302,
        "distinct-3-nopunct": 0.9666666666666667,
        "vocab_size-3-nopunct": 87,
        "unique-3-nopunct": 84,
        "entropy-3-nopunct": 6.425186429662996,
        "cond_entropy-3-nopunct": -0.07841230334108923,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16216216216216217,
            "2": 0.6666666666666666,
            "3": 0.8166666666666667
        },
        "nist": 5.159956014624724,
        "bleu": 36.34291,
        "rouge1": {
            "precision": 0.74727,
            "recall": 0.75314,
            "fmeasure": 0.73854
        },
        "rouge2": {
            "precision": 0.47806,
            "recall": 0.48942,
            "fmeasure": 0.4718
        },
        "rougeL": {
            "precision": 0.59659,
            "recall": 0.59494,
            "fmeasure": 0.58588
        },
        "rougeLsum": {
            "precision": 0.59659,
            "recall": 0.59494,
            "fmeasure": 0.58588
        },
        "nubia": {
            "semantic_relation": 4.01312,
            "contradiction": 10.93489,
            "irrelevancy": 49.60061,
            "logical_agreement": 39.4645,
            "grammar_ref": 5.34109,
            "grammar_hyp": 5.398,
            "nubia_score": 0.6459
        },
        "meteor": 0.3782314733805803,
        "bleurt": 0.11586,
        "bertscore": {
            "precision": 0.91721,
            "recall": 0.91466,
            "f1": 0.91097
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_474": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 0.5,
        "median_pred_length": 12.5,
        "min_pred_length": 12,
        "max_pred_length": 13,
        "distinct-1": 0.8,
        "vocab_size-1": 20,
        "unique-1": 15,
        "entropy-1": 4.243856189774723,
        "distinct-2": 0.9130434782608695,
        "vocab_size-2": 21,
        "unique-2": 19,
        "entropy-2": 4.349648912578752,
        "cond_entropy-2": 0.05361880976054911,
        "distinct-3": 0.9523809523809523,
        "vocab_size-3": 20,
        "unique-3": 19,
        "entropy-3": 4.297079327540665,
        "cond_entropy-3": -0.03600643804015718,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.095795255000932,
        "distinct-2-nopunct": 0.9,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.1219280948873624,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 0.9444444444444444,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.058813890331201,
        "cond_entropy-3-nopunct": -0.04089198233393865,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.9473684210526315
        },
        "nist": 5.11203951875503,
        "bleu": 77.84561,
        "rouge1": {
            "precision": 0.98485,
            "recall": 0.95833,
            "fmeasure": 0.97032
        },
        "rouge2": {
            "precision": 0.91667,
            "recall": 0.89057,
            "fmeasure": 0.90226
        },
        "rougeL": {
            "precision": 0.98485,
            "recall": 0.95833,
            "fmeasure": 0.97032
        },
        "rougeLsum": {
            "precision": 0.98485,
            "recall": 0.95833,
            "fmeasure": 0.97032
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.1504,
            "irrelevancy": 0.45916,
            "logical_agreement": 99.39044,
            "grammar_ref": 4.16906,
            "grammar_hyp": 4.31056,
            "nubia_score": 0.98187
        },
        "meteor": 0.5877739026147655,
        "bleurt": 0.87274,
        "bertscore": {
            "precision": 0.99629,
            "recall": 0.99082,
            "f1": 0.99354
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_475": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 7,
        "total_length": 103,
        "mean_pred_length": 14.714285714285714,
        "std_pred_length": 4.772369453854305,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.5922330097087378,
        "vocab_size-1": 61,
        "unique-1": 42,
        "entropy-1": 5.534354561522479,
        "distinct-2": 0.9166666666666666,
        "vocab_size-2": 88,
        "unique-2": 80,
        "entropy-2": 6.418295834054493,
        "cond_entropy-2": 0.7632489527947482,
        "distinct-3": 0.9550561797752809,
        "vocab_size-3": 85,
        "unique-3": 81,
        "entropy-3": 6.385845790516971,
        "cond_entropy-3": -0.04181333941767969,
        "total_length-nopunct": 88,
        "mean_pred_length-nopunct": 12.571428571428571,
        "std_pred_length-nopunct": 4.337778985911137,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6590909090909091,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.533184175406315,
        "distinct-2-nopunct": 0.9259259259259259,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 69,
        "entropy-2-nopunct": 6.191701854736466,
        "cond_entropy-2-nopunct": 0.70152671763408,
        "distinct-3-nopunct": 0.972972972972973,
        "vocab_size-3-nopunct": 72,
        "unique-3-nopunct": 70,
        "entropy-3-nopunct": 6.155399311574901,
        "cond_entropy-3-nopunct": -0.04931555617459417,
        "msttr-100": 0.61,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19230769230769232,
            "2": 0.7083333333333334,
            "3": 0.717391304347826
        },
        "nist": 4.249744415189908,
        "bleu": 30.37722,
        "rouge1": {
            "precision": 0.63482,
            "recall": 0.66776,
            "fmeasure": 0.6303
        },
        "rouge2": {
            "precision": 0.31458,
            "recall": 0.33664,
            "fmeasure": 0.31181
        },
        "rougeL": {
            "precision": 0.51352,
            "recall": 0.55049,
            "fmeasure": 0.51304
        },
        "rougeLsum": {
            "precision": 0.51352,
            "recall": 0.55049,
            "fmeasure": 0.51304
        },
        "nubia": {
            "semantic_relation": 4.25933,
            "contradiction": 13.61126,
            "irrelevancy": 42.62315,
            "logical_agreement": 43.76558,
            "grammar_ref": 5.09695,
            "grammar_hyp": 4.41786,
            "nubia_score": 0.75119
        },
        "meteor": 0.3429651850035037,
        "bleurt": 0.14876,
        "bertscore": {
            "precision": 0.90867,
            "recall": 0.90996,
            "f1": 0.90851
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_651": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.7142857142857143
        },
        "nist": 1.729050000786716,
        "bleu": 18.36028,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.625,
            "fmeasure": 0.55556
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.42857,
            "fmeasure": 0.375
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.625,
            "fmeasure": 0.55556
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.625,
            "fmeasure": 0.55556
        },
        "nubia": {
            "semantic_relation": 3.74104,
            "contradiction": 0.61327,
            "irrelevancy": 98.74637,
            "logical_agreement": 0.64036,
            "grammar_ref": 5.1072,
            "grammar_hyp": 6.23498,
            "nubia_score": 0.39932
        },
        "meteor": 0.31494702990483003,
        "bleurt": -0.93516,
        "bertscore": {
            "precision": 0.83631,
            "recall": 0.9152,
            "f1": 0.87398
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_912": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 52,
        "mean_pred_length": 13.0,
        "std_pred_length": 4.949747468305833,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 20,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 40,
        "unique-1": 32,
        "entropy-1": 5.161978179679556,
        "distinct-2": 1.0,
        "vocab_size-2": 48,
        "unique-2": 48,
        "entropy-2": 5.5849625007211605,
        "cond_entropy-2": 0.3011894492467311,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": -0.12553088208385924,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 10.75,
        "std_pred_length-nopunct": 3.897114317029974,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.813953488372093,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 5.007660103539307,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.285402218862247,
        "cond_entropy-2-nopunct": 0.320675925698612,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.15611920191728196,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.5,
            "3": 0.7037037037037037
        },
        "nist": 3.538043184800456,
        "bleu": 50.78563,
        "rouge1": {
            "precision": 0.80437,
            "recall": 0.6448,
            "fmeasure": 0.69752
        },
        "rouge2": {
            "precision": 0.61591,
            "recall": 0.46397,
            "fmeasure": 0.508
        },
        "rougeL": {
            "precision": 0.75134,
            "recall": 0.60591,
            "fmeasure": 0.6528
        },
        "rougeLsum": {
            "precision": 0.75134,
            "recall": 0.60591,
            "fmeasure": 0.6528
        },
        "nubia": {
            "semantic_relation": 3.36073,
            "contradiction": 34.49817,
            "irrelevancy": 33.64011,
            "logical_agreement": 31.86172,
            "grammar_ref": 4.43752,
            "grammar_hyp": 5.04485,
            "nubia_score": 0.44537
        },
        "meteor": 0.41591087523840276,
        "bleurt": 0.09493,
        "bertscore": {
            "precision": 0.9333,
            "recall": 0.91484,
            "f1": 0.92131
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_915": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 50,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 10.842303978193728,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 32,
        "distinct-1": 0.76,
        "vocab_size-1": 38,
        "unique-1": 28,
        "entropy-1": 5.133660689688187,
        "distinct-2": 0.9574468085106383,
        "vocab_size-2": 45,
        "unique-2": 43,
        "entropy-2": 5.469482468698917,
        "cond_entropy-2": 0.26721963003405036,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": -0.004248142131249447,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 7.542472332656507,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.825,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.953055907333277,
        "distinct-2-nopunct": 0.972972972972973,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.155399311574899,
        "cond_entropy-2-nopunct": 0.23225195998924858,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.06316699496684555,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.6,
            "3": 0.9032258064516129
        },
        "nist": 4.345997777479957,
        "bleu": 45.97559,
        "rouge1": {
            "precision": 0.81944,
            "recall": 0.86579,
            "fmeasure": 0.84117
        },
        "rouge2": {
            "precision": 0.57059,
            "recall": 0.61612,
            "fmeasure": 0.59175
        },
        "rougeL": {
            "precision": 0.69167,
            "recall": 0.75361,
            "fmeasure": 0.7205
        },
        "rougeLsum": {
            "precision": 0.69167,
            "recall": 0.75361,
            "fmeasure": 0.7205
        },
        "nubia": {
            "semantic_relation": 4.24427,
            "contradiction": 18.79837,
            "irrelevancy": 40.18558,
            "logical_agreement": 41.01605,
            "grammar_ref": 5.15251,
            "grammar_hyp": 4.87892,
            "nubia_score": 0.73271
        },
        "meteor": 0.4647297156085676,
        "bleurt": 0.33688,
        "bertscore": {
            "precision": 0.9448,
            "recall": 0.95591,
            "f1": 0.95015
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_624": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 75,
        "mean_pred_length": 18.75,
        "std_pred_length": 5.539629951540085,
        "median_pred_length": 20.0,
        "min_pred_length": 11,
        "max_pred_length": 24,
        "distinct-1": 0.7066666666666667,
        "vocab_size-1": 53,
        "unique-1": 42,
        "entropy-1": 5.445420190467039,
        "distinct-2": 0.971830985915493,
        "vocab_size-2": 69,
        "unique-2": 67,
        "entropy-2": 6.093409091335665,
        "cond_entropy-2": 0.6251537811214776,
        "distinct-3": 0.9850746268656716,
        "vocab_size-3": 66,
        "unique-3": 65,
        "entropy-3": 6.03623844418911,
        "cond_entropy-3": -0.05380718277825277,
        "total_length-nopunct": 68,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 5.431390245600108,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 51,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.410992253015047,
        "distinct-2-nopunct": 0.96875,
        "vocab_size-2-nopunct": 62,
        "unique-2-nopunct": 60,
        "entropy-2-nopunct": 5.9375,
        "cond_entropy-2-nopunct": 0.5531621587496602,
        "distinct-3-nopunct": 0.9833333333333333,
        "vocab_size-3-nopunct": 59,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.873557262275184,
        "cond_entropy-3-nopunct": -0.059776071058148146,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5789473684210527,
            "3": 0.6296296296296297
        },
        "nist": 4.019532261375164,
        "bleu": 29.85684,
        "rouge1": {
            "precision": 0.70896,
            "recall": 0.66631,
            "fmeasure": 0.65882
        },
        "rouge2": {
            "precision": 0.42648,
            "recall": 0.40498,
            "fmeasure": 0.39672
        },
        "rougeL": {
            "precision": 0.58271,
            "recall": 0.53991,
            "fmeasure": 0.52882
        },
        "rougeLsum": {
            "precision": 0.58271,
            "recall": 0.53991,
            "fmeasure": 0.52882
        },
        "nubia": {
            "semantic_relation": 3.75556,
            "contradiction": 4.21922,
            "irrelevancy": 52.77211,
            "logical_agreement": 43.00867,
            "grammar_ref": 4.54253,
            "grammar_hyp": 4.34646,
            "nubia_score": 0.56
        },
        "meteor": 0.3399081901862342,
        "bleurt": 0.06076,
        "bertscore": {
            "precision": 0.8986,
            "recall": 0.90259,
            "f1": 0.89975
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_625": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 15,
        "unique-1": 12,
        "entropy-1": 3.8365916681089787,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.27047901627861526,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.734521664779752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.28753715874966057,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.0,
            "3": 0.5833333333333334
        },
        "nist": 3.1252986916398657,
        "bleu": 38.05371,
        "rouge1": {
            "precision": 0.64706,
            "recall": 0.54783,
            "fmeasure": 0.5875
        },
        "rouge2": {
            "precision": 0.39583,
            "recall": 0.32576,
            "fmeasure": 0.35213
        },
        "rougeL": {
            "precision": 0.35294,
            "recall": 0.30546,
            "fmeasure": 0.32222
        },
        "rougeLsum": {
            "precision": 0.35294,
            "recall": 0.30546,
            "fmeasure": 0.32222
        },
        "nubia": {
            "semantic_relation": 2.91892,
            "contradiction": 1.57642,
            "irrelevancy": 54.51539,
            "logical_agreement": 43.90819,
            "grammar_ref": 4.61776,
            "grammar_hyp": 3.52612,
            "nubia_score": 0.47587
        },
        "meteor": 0.2741259497872204,
        "bleurt": -0.47511,
        "bertscore": {
            "precision": 0.8311,
            "recall": 0.8221,
            "f1": 0.82658
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_918": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.875,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.303508854797679,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.1633788032246528,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.02961067210860197,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.4166666666666667,
            "3": 0.9
        },
        "nist": 3.319989778760841,
        "bleu": 23.99195,
        "rouge1": {
            "precision": 0.56061,
            "recall": 0.75641,
            "fmeasure": 0.62738
        },
        "rouge2": {
            "precision": 0.31746,
            "recall": 0.46889,
            "fmeasure": 0.36978
        },
        "rougeL": {
            "precision": 0.42424,
            "recall": 0.58974,
            "fmeasure": 0.48175
        },
        "rougeLsum": {
            "precision": 0.42424,
            "recall": 0.58974,
            "fmeasure": 0.48175
        },
        "nubia": {
            "semantic_relation": 3.3733,
            "contradiction": 64.87572,
            "irrelevancy": 32.20182,
            "logical_agreement": 2.92245,
            "grammar_ref": 4.65446,
            "grammar_hyp": 4.57689,
            "nubia_score": 0.43182
        },
        "meteor": 0.37022737425755703,
        "bleurt": -0.48283,
        "bertscore": {
            "precision": 0.90478,
            "recall": 0.93187,
            "f1": 0.90549
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1010": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.8181818181818182
        },
        "nist": 3.2546028831755143,
        "bleu": 53.98996,
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.83333,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.63636,
            "fmeasure": 0.6087
        },
        "rougeL": {
            "precision": 0.76923,
            "recall": 0.83333,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.76923,
            "recall": 0.83333,
            "fmeasure": 0.8
        },
        "nubia": {
            "semantic_relation": 4.61182,
            "contradiction": 0.16869,
            "irrelevancy": 34.7694,
            "logical_agreement": 65.06191,
            "grammar_ref": 4.00353,
            "grammar_hyp": 4.0447,
            "nubia_score": 0.85766
        },
        "meteor": 0.4769193272293322,
        "bleurt": 0.4808,
        "bertscore": {
            "precision": 0.95165,
            "recall": 0.96381,
            "f1": 0.95605
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_654": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.3333333333333333,
            "3": 0.4444444444444444
        },
        "nist": 1.5111175197071034,
        "bleu": 22.74629,
        "rouge1": {
            "precision": 0.63889,
            "recall": 0.38947,
            "fmeasure": 0.48387
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.24074,
            "fmeasure": 0.28948
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.35098,
            "fmeasure": 0.4296
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.35098,
            "fmeasure": 0.4296
        },
        "nubia": {
            "semantic_relation": 2.39265,
            "contradiction": 98.51609,
            "irrelevancy": 1.17353,
            "logical_agreement": 0.31037,
            "grammar_ref": 3.79365,
            "grammar_hyp": 3.72845,
            "nubia_score": 0.20918
        },
        "meteor": 0.2182498974972204,
        "bleurt": -0.71266,
        "bertscore": {
            "precision": 0.90432,
            "recall": 0.83124,
            "f1": 0.86624
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_785": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 1.0,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 14,
        "distinct-1": 0.6153846153846154,
        "vocab_size-1": 16,
        "unique-1": 8,
        "entropy-1": 3.8542858719872455,
        "distinct-2": 0.8333333333333334,
        "vocab_size-2": 20,
        "unique-2": 16,
        "entropy-2": 4.251629167387823,
        "cond_entropy-2": 0.3845227825800641,
        "distinct-3": 0.9090909090909091,
        "vocab_size-3": 20,
        "unique-3": 18,
        "entropy-3": 4.277613436819113,
        "cond_entropy-3": 0.05628729973432273,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.625,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.751629167387823,
        "distinct-2-nopunct": 0.8181818181818182,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 4.095795255000931,
        "cond_entropy-2-nopunct": 0.41992366337068643,
        "distinct-3-nopunct": 0.9,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.1219280948873624,
        "cond_entropy-3-nopunct": 0.06249647625006499,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.367341111834657,
        "bleu": 54.53667,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.8323,
            "fmeasure": 0.864
        },
        "rouge2": {
            "precision": 0.76667,
            "recall": 0.70694,
            "fmeasure": 0.73147
        },
        "rougeL": {
            "precision": 0.87879,
            "recall": 0.8127,
            "fmeasure": 0.84019
        },
        "rougeLsum": {
            "precision": 0.87879,
            "recall": 0.8127,
            "fmeasure": 0.84019
        },
        "nubia": {
            "semantic_relation": 4.98476,
            "contradiction": 0.38211,
            "irrelevancy": 0.62619,
            "logical_agreement": 98.9917,
            "grammar_ref": 4.6711,
            "grammar_hyp": 4.70851,
            "nubia_score": 0.94361
        },
        "meteor": 0.5821996250308573,
        "bleurt": 0.59557,
        "bertscore": {
            "precision": 0.96646,
            "recall": 0.9856,
            "f1": 0.97584
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_408": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 15,
        "total_length": 227,
        "mean_pred_length": 15.133333333333333,
        "std_pred_length": 5.352465683111747,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.6563876651982379,
        "vocab_size-1": 149,
        "unique-1": 122,
        "entropy-1": 6.70865476733408,
        "distinct-2": 0.9575471698113207,
        "vocab_size-2": 203,
        "unique-2": 194,
        "entropy-2": 7.6430147941858495,
        "cond_entropy-2": 0.7370253422537548,
        "distinct-3": 0.9898477157360406,
        "vocab_size-3": 195,
        "unique-3": 193,
        "entropy-3": 7.601747250928419,
        "cond_entropy-3": -0.06525949805098535,
        "total_length-nopunct": 199,
        "mean_pred_length-nopunct": 13.266666666666667,
        "std_pred_length-nopunct": 4.781445620544296,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7236180904522613,
        "vocab_size-1-nopunct": 144,
        "unique-1-nopunct": 121,
        "entropy-1-nopunct": 6.796632080362394,
        "distinct-2-nopunct": 0.967391304347826,
        "vocab_size-2-nopunct": 178,
        "unique-2-nopunct": 172,
        "entropy-2-nopunct": 7.458344564752677,
        "cond_entropy-2-nopunct": 0.6966579360276518,
        "distinct-3-nopunct": 0.9940828402366864,
        "vocab_size-3-nopunct": 168,
        "unique-3-nopunct": 167,
        "entropy-3-nopunct": 7.3890451167555495,
        "cond_entropy-3-nopunct": -0.07534524166831988,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.8,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2978723404255319,
            "2": 0.48148148148148145,
            "3": 0.7548387096774194
        },
        "nist": 6.122710659612514,
        "bleu": 48.9932,
        "rouge1": {
            "precision": 0.75192,
            "recall": 0.75267,
            "fmeasure": 0.743
        },
        "rouge2": {
            "precision": 0.55275,
            "recall": 0.54263,
            "fmeasure": 0.53869
        },
        "rougeL": {
            "precision": 0.64976,
            "recall": 0.6678,
            "fmeasure": 0.65192
        },
        "rougeLsum": {
            "precision": 0.64976,
            "recall": 0.6678,
            "fmeasure": 0.65192
        },
        "nubia": {
            "semantic_relation": 4.14754,
            "contradiction": 13.45906,
            "irrelevancy": 31.07792,
            "logical_agreement": 55.46302,
            "grammar_ref": 4.56596,
            "grammar_hyp": 4.76652,
            "nubia_score": 0.7146
        },
        "meteor": 0.42332030730911113,
        "bleurt": 0.19586,
        "bertscore": {
            "precision": 0.93886,
            "recall": 0.94141,
            "f1": 0.93733
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_708": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 34,
        "mean_pred_length": 11.333333333333334,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 12,
        "distinct-1": 0.7352941176470589,
        "vocab_size-1": 25,
        "unique-1": 17,
        "entropy-1": 4.5358485029514135,
        "distinct-2": 0.8064516129032258,
        "vocab_size-2": 25,
        "unique-2": 19,
        "entropy-2": 4.567099536193328,
        "cond_entropy-2": -0.06875040183120606,
        "distinct-3": 0.8214285714285714,
        "vocab_size-3": 23,
        "unique-3": 18,
        "entropy-3": 4.450212064914748,
        "cond_entropy-3": -0.07541281690069972,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 10.333333333333334,
        "std_pred_length-nopunct": 0.4714045207910317,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.7741935483870968,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.50258340716107,
        "distinct-2-nopunct": 0.7857142857142857,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.378783493486177,
        "cond_entropy-2-nopunct": -0.0754128169006997,
        "distinct-3-nopunct": 0.8,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 4.243856189774722,
        "cond_entropy-3-nopunct": -0.08349873228287957,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.7,
            "3": 0.9523809523809523
        },
        "nist": 4.07428210691877,
        "bleu": 68.84926,
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.86667,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.77778,
            "fmeasure": 0.77778
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.83333,
            "fmeasure": 0.83333
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.83333,
            "fmeasure": 0.83333
        },
        "nubia": {
            "semantic_relation": 4.42816,
            "contradiction": 23.82865,
            "irrelevancy": 16.56989,
            "logical_agreement": 59.60146,
            "grammar_ref": 5.72052,
            "grammar_hyp": 5.79654,
            "nubia_score": 0.72216
        },
        "meteor": 0.4842013968853952,
        "bleurt": 0.64452,
        "bertscore": {
            "precision": 0.96819,
            "recall": 0.95756,
            "f1": 0.96273
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_410": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 10,
        "total_length": 158,
        "mean_pred_length": 15.8,
        "std_pred_length": 4.377213725647858,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 22,
        "distinct-1": 0.6075949367088608,
        "vocab_size-1": 96,
        "unique-1": 76,
        "entropy-1": 6.1112513783991895,
        "distinct-2": 0.8851351351351351,
        "vocab_size-2": 131,
        "unique-2": 118,
        "entropy-2": 6.956008939924035,
        "cond_entropy-2": 0.7631717081314711,
        "distinct-3": 0.9710144927536232,
        "vocab_size-3": 134,
        "unique-3": 130,
        "entropy-3": 7.0505534422854135,
        "cond_entropy-3": 0.11291004045593654,
        "total_length-nopunct": 140,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.33589667773576,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6642857142857143,
        "vocab_size-1-nopunct": 93,
        "unique-1-nopunct": 75,
        "entropy-1-nopunct": 6.158637906859753,
        "distinct-2-nopunct": 0.8846153846153846,
        "vocab_size-2-nopunct": 115,
        "unique-2-nopunct": 104,
        "entropy-2-nopunct": 6.764600312995172,
        "cond_entropy-2-nopunct": 0.6806274146035172,
        "distinct-3-nopunct": 0.975,
        "vocab_size-3-nopunct": 117,
        "unique-3-nopunct": 114,
        "entropy-3-nopunct": 6.856890595608535,
        "cond_entropy-3-nopunct": 0.11377090761612174,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.72,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20833333333333334,
            "2": 0.5769230769230769,
            "3": 0.9541284403669725
        },
        "nist": 6.7494447737228125,
        "bleu": 72.00472,
        "rouge1": {
            "precision": 0.88648,
            "recall": 0.86666,
            "fmeasure": 0.87495
        },
        "rouge2": {
            "precision": 0.75671,
            "recall": 0.74073,
            "fmeasure": 0.74693
        },
        "rougeL": {
            "precision": 0.77051,
            "recall": 0.76705,
            "fmeasure": 0.76724
        },
        "rougeLsum": {
            "precision": 0.77051,
            "recall": 0.76705,
            "fmeasure": 0.76724
        },
        "nubia": {
            "semantic_relation": 4.55292,
            "contradiction": 10.59762,
            "irrelevancy": 16.03759,
            "logical_agreement": 73.36479,
            "grammar_ref": 4.86973,
            "grammar_hyp": 4.96083,
            "nubia_score": 0.82444
        },
        "meteor": 0.5106185811962515,
        "bleurt": 0.55447,
        "bertscore": {
            "precision": 0.96747,
            "recall": 0.96488,
            "f1": 0.96494
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_656": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.03126257645096008,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2,
            "3": 0.6363636363636364
        },
        "nist": 1.8309648186493623,
        "bleu": 6.79832,
        "rouge1": {
            "precision": 0.54902,
            "recall": 0.70833,
            "fmeasure": 0.61581
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.41414,
            "fmeasure": 0.35444
        },
        "rougeL": {
            "precision": 0.35294,
            "recall": 0.45833,
            "fmeasure": 0.39707
        },
        "rougeLsum": {
            "precision": 0.35294,
            "recall": 0.45833,
            "fmeasure": 0.39707
        },
        "nubia": {
            "semantic_relation": 4.15831,
            "contradiction": 0.49045,
            "irrelevancy": 41.43432,
            "logical_agreement": 58.07522,
            "grammar_ref": 4.67419,
            "grammar_hyp": 3.94411,
            "nubia_score": 0.77717
        },
        "meteor": 0.3807834049357218,
        "bleurt": 0.35486,
        "bertscore": {
            "precision": 0.85779,
            "recall": 0.8946,
            "f1": 0.86278
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1014": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.277613436819116,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8
        },
        "nist": 1.077067708633815,
        "bleu": 15.85117,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.8,
            "fmeasure": 0.61538
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.5,
            "fmeasure": 0.36364
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.8,
            "fmeasure": 0.61538
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.8,
            "fmeasure": 0.61538
        },
        "nubia": {
            "semantic_relation": 4.32515,
            "contradiction": 0.1052,
            "irrelevancy": 99.78136,
            "logical_agreement": 0.11345,
            "grammar_ref": 6.34893,
            "grammar_hyp": 4.71705,
            "nubia_score": 1.0
        },
        "meteor": 0.4157242800169579,
        "bleurt": 0.52633,
        "bertscore": {
            "precision": 0.88308,
            "recall": 0.96214,
            "f1": 0.92092
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_627": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.9583333333333334,
        "vocab_size-1": 23,
        "unique-1": 22,
        "entropy-1": 4.501629167387823,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.025555977074987166,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.9565217391304348,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.436605434317882,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.026778753489375348,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.1,
            "3": 0.5833333333333334
        },
        "nist": 1.789958984324756,
        "bleu": 4.70524,
        "rouge1": {
            "precision": 0.36232,
            "recall": 0.42754,
            "fmeasure": 0.387
        },
        "rouge2": {
            "precision": 0.04545,
            "recall": 0.06643,
            "fmeasure": 0.05325
        },
        "rougeL": {
            "precision": 0.2029,
            "recall": 0.1913,
            "fmeasure": 0.19686
        },
        "rougeLsum": {
            "precision": 0.2029,
            "recall": 0.1913,
            "fmeasure": 0.19686
        },
        "nubia": {
            "semantic_relation": 3.92395,
            "contradiction": 0.06301,
            "irrelevancy": 98.22577,
            "logical_agreement": 1.71122,
            "grammar_ref": 4.57081,
            "grammar_hyp": 4.63146,
            "nubia_score": 0.61283
        },
        "meteor": 0.19644646848703898,
        "bleurt": -0.09074,
        "bertscore": {
            "precision": 0.81155,
            "recall": 0.83914,
            "f1": 0.82128
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_854": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 55,
        "mean_pred_length": 18.333333333333332,
        "std_pred_length": 2.0548046676563256,
        "median_pred_length": 18.0,
        "min_pred_length": 16,
        "max_pred_length": 21,
        "distinct-1": 0.5818181818181818,
        "vocab_size-1": 32,
        "unique-1": 19,
        "entropy-1": 4.7588355142968854,
        "distinct-2": 0.8461538461538461,
        "vocab_size-2": 44,
        "unique-2": 39,
        "entropy-2": 5.323331247478848,
        "cond_entropy-2": 0.5320473696342639,
        "distinct-3": 0.8979591836734694,
        "vocab_size-3": 44,
        "unique-3": 39,
        "entropy-3": 5.410628211462147,
        "cond_entropy-3": 0.11038523769731642,
        "total_length-nopunct": 51,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 2.449489742783178,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.5882352941176471,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.662936254611419,
        "distinct-2-nopunct": 0.8333333333333334,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.176428324170392,
        "cond_entropy-2-nopunct": 0.5018984187539536,
        "distinct-3-nopunct": 0.8888888888888888,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.269630874107452,
        "cond_entropy-3-nopunct": 0.1204381617071142,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6,
            "3": 0.5789473684210527
        },
        "nist": 3.0842208876710115,
        "bleu": 15.77205,
        "rouge1": {
            "precision": 0.59536,
            "recall": 0.64354,
            "fmeasure": 0.60437
        },
        "rouge2": {
            "precision": 0.31736,
            "recall": 0.31168,
            "fmeasure": 0.30579
        },
        "rougeL": {
            "precision": 0.40852,
            "recall": 0.46657,
            "fmeasure": 0.42557
        },
        "rougeLsum": {
            "precision": 0.40852,
            "recall": 0.46657,
            "fmeasure": 0.42557
        },
        "nubia": {
            "semantic_relation": 3.22287,
            "contradiction": 32.80116,
            "irrelevancy": 34.541,
            "logical_agreement": 32.65784,
            "grammar_ref": 3.73262,
            "grammar_hyp": 4.09935,
            "nubia_score": 0.4567
        },
        "meteor": 0.3410631539354583,
        "bleurt": -0.15105,
        "bertscore": {
            "precision": 0.87539,
            "recall": 0.84828,
            "f1": 0.86155
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_791": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.11768784439846626,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.029610672108601983,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0,
            "3": 0.42105263157894735
        },
        "nist": 1.9856821517014,
        "bleu": 8.59098,
        "rouge1": {
            "precision": 0.51515,
            "recall": 0.48485,
            "fmeasure": 0.49934
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.20842,
            "fmeasure": 0.21501
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.35837,
            "fmeasure": 0.36094
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.35837,
            "fmeasure": 0.36094
        },
        "nubia": {
            "semantic_relation": 3.67671,
            "contradiction": 23.20749,
            "irrelevancy": 51.57436,
            "logical_agreement": 25.21816,
            "grammar_ref": 4.34096,
            "grammar_hyp": 5.08758,
            "nubia_score": 0.46279
        },
        "meteor": 0.266504178786823,
        "bleurt": -0.0892,
        "bertscore": {
            "precision": 0.89009,
            "recall": 0.88953,
            "f1": 0.88981
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1152": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.3333333333333333
        },
        "nist": 1.4089039873913056,
        "bleu": 10.1471,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.125,
            "fmeasure": 0.125
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "nubia": {
            "semantic_relation": 4.34836,
            "contradiction": 0.26908,
            "irrelevancy": 85.70123,
            "logical_agreement": 14.02968,
            "grammar_ref": 3.99081,
            "grammar_hyp": 3.95602,
            "nubia_score": 0.88307
        },
        "meteor": 0.21184095372658285,
        "bleurt": 0.14403,
        "bertscore": {
            "precision": 0.84745,
            "recall": 0.8339,
            "f1": 0.84062
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_855": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.12336199461765365,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.03740119765411,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.08866415466539351,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.3333333333333333,
            "3": 0.9090909090909091
        },
        "nist": 3.9433473139725552,
        "bleu": 47.49124,
        "rouge1": {
            "precision": 0.78947,
            "recall": 0.71429,
            "fmeasure": 0.75
        },
        "rouge2": {
            "precision": 0.59259,
            "recall": 0.53333,
            "fmeasure": 0.5614
        },
        "rougeL": {
            "precision": 0.57895,
            "recall": 0.69841,
            "fmeasure": 0.62778
        },
        "rougeLsum": {
            "precision": 0.57895,
            "recall": 0.69841,
            "fmeasure": 0.62778
        },
        "nubia": {
            "semantic_relation": 4.55984,
            "contradiction": 0.17333,
            "irrelevancy": 33.55913,
            "logical_agreement": 66.26754,
            "grammar_ref": 3.68983,
            "grammar_hyp": 3.4422,
            "nubia_score": 0.9057
        },
        "meteor": 0.44414806255774797,
        "bleurt": 0.24713,
        "bertscore": {
            "precision": 0.92365,
            "recall": 0.93884,
            "f1": 0.92226
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_792": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 7.0,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.8125,
        "vocab_size-1": 26,
        "unique-1": 20,
        "entropy-1": 4.625,
        "distinct-2": 0.9666666666666667,
        "vocab_size-2": 29,
        "unique-2": 28,
        "entropy-2": 4.840223928941852,
        "cond_entropy-2": 0.17355726227518525,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.028107102122342915,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 6.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8214285714285714,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.450212064914748,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.623516641218013,
        "cond_entropy-2-nopunct": 0.16231556531425706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.03214388408660257,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.14285714285714285,
            "3": 0.7142857142857143
        },
        "nist": 4.205105690960413,
        "bleu": 33.11076,
        "rouge1": {
            "precision": 0.67708,
            "recall": 0.64444,
            "fmeasure": 0.65931
        },
        "rouge2": {
            "precision": 0.34762,
            "recall": 0.32933,
            "fmeasure": 0.33763
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.56111,
            "fmeasure": 0.58987
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.56111,
            "fmeasure": 0.58987
        },
        "nubia": {
            "semantic_relation": 4.46442,
            "contradiction": 0.26626,
            "irrelevancy": 1.87231,
            "logical_agreement": 97.86143,
            "grammar_ref": 4.56769,
            "grammar_hyp": 5.20019,
            "nubia_score": 0.77057
        },
        "meteor": 0.403835411600142,
        "bleurt": 0.3579,
        "bertscore": {
            "precision": 0.94324,
            "recall": 0.94492,
            "f1": 0.94259
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_657": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 47,
        "mean_pred_length": 23.5,
        "std_pred_length": 0.5,
        "median_pred_length": 23.5,
        "min_pred_length": 23,
        "max_pred_length": 24,
        "distinct-1": 0.7446808510638298,
        "vocab_size-1": 35,
        "unique-1": 25,
        "entropy-1": 5.011827681372811,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 42,
        "unique-2": 39,
        "entropy-2": 5.358519762996339,
        "cond_entropy-2": 0.3263703558593026,
        "distinct-3": 0.9534883720930233,
        "vocab_size-3": 41,
        "unique-3": 39,
        "entropy-3": 5.333241498888144,
        "cond_entropy-3": -0.01907671372059983,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.775,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.83418371977919,
        "distinct-2-nopunct": 0.9210526315789473,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.090032776601483,
        "cond_entropy-2-nopunct": 0.25520402393324787,
        "distinct-3-nopunct": 0.9444444444444444,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.058813890331199,
        "cond_entropy-3-nopunct": -0.0224469564457176,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.06666666666666667,
            "3": 0.8484848484848485
        },
        "nist": 3.6475879005761485,
        "bleu": 48.37657,
        "rouge1": {
            "precision": 0.77807,
            "recall": 0.71387,
            "fmeasure": 0.73019
        },
        "rouge2": {
            "precision": 0.52437,
            "recall": 0.49852,
            "fmeasure": 0.50144
        },
        "rougeL": {
            "precision": 0.67807,
            "recall": 0.64589,
            "fmeasure": 0.64941
        },
        "rougeLsum": {
            "precision": 0.67807,
            "recall": 0.64589,
            "fmeasure": 0.64941
        },
        "nubia": {
            "semantic_relation": 3.95625,
            "contradiction": 2.29297,
            "irrelevancy": 95.55194,
            "logical_agreement": 2.15509,
            "grammar_ref": 3.5955,
            "grammar_hyp": 3.77558,
            "nubia_score": 0.62272
        },
        "meteor": 0.36010698584126377,
        "bleurt": -0.03012,
        "bertscore": {
            "precision": 0.92224,
            "recall": 0.91115,
            "f1": 0.91442
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_660": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 41,
        "mean_pred_length": 13.666666666666666,
        "std_pred_length": 1.699673171197595,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.8048780487804879,
        "vocab_size-1": 33,
        "unique-1": 27,
        "entropy-1": 4.930484321585719,
        "distinct-2": 0.9736842105263158,
        "vocab_size-2": 37,
        "unique-2": 36,
        "entropy-2": 5.19529593449622,
        "cond_entropy-2": 0.17339886414559325,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": -0.061501639355761785,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 10.666666666666666,
        "std_pred_length-nopunct": 0.9428090415820634,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.726409765557392,
        "distinct-2-nopunct": 0.9655172413793104,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.789015477886192,
        "cond_entropy-2-nopunct": 0.0909081503745883,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.0806182000634031,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.3333333333333333,
            "3": 0.7916666666666666
        },
        "nist": 5.03895629561971,
        "bleu": 53.59747,
        "rouge1": {
            "precision": 0.82593,
            "recall": 0.71955,
            "fmeasure": 0.76561
        },
        "rouge2": {
            "precision": 0.51515,
            "recall": 0.48743,
            "fmeasure": 0.49932
        },
        "rougeL": {
            "precision": 0.56481,
            "recall": 0.53837,
            "fmeasure": 0.54921
        },
        "rougeLsum": {
            "precision": 0.56481,
            "recall": 0.53837,
            "fmeasure": 0.54921
        },
        "nubia": {
            "semantic_relation": 4.49928,
            "contradiction": 40.72967,
            "irrelevancy": 24.11718,
            "logical_agreement": 35.15315,
            "grammar_ref": 4.31237,
            "grammar_hyp": 4.37359,
            "nubia_score": 0.81468
        },
        "meteor": 0.45455940280907975,
        "bleurt": 0.2979,
        "bertscore": {
            "precision": 0.94635,
            "recall": 0.93687,
            "f1": 0.94079
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_856": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.3333333333333333,
            "3": 0.4666666666666667
        },
        "nist": 2.931845215359404,
        "bleu": 28.83895,
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.50794,
            "fmeasure": 0.53016
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.23913,
            "fmeasure": 0.24419
        },
        "rougeL": {
            "precision": 0.47619,
            "recall": 0.45635,
            "fmeasure": 0.46561
        },
        "rougeLsum": {
            "precision": 0.47619,
            "recall": 0.45635,
            "fmeasure": 0.46561
        },
        "nubia": {
            "semantic_relation": 3.92419,
            "contradiction": 3.33769,
            "irrelevancy": 92.25675,
            "logical_agreement": 4.40557,
            "grammar_ref": 6.02354,
            "grammar_hyp": 6.05598,
            "nubia_score": 0.57948
        },
        "meteor": 0.3141062021038885,
        "bleurt": -0.13855,
        "bertscore": {
            "precision": 0.87227,
            "recall": 0.85707,
            "f1": 0.8646
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_663": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 45,
        "mean_pred_length": 15.0,
        "std_pred_length": 5.0990195135927845,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.7555555555555555,
        "vocab_size-1": 34,
        "unique-1": 28,
        "entropy-1": 4.908193929518776,
        "distinct-2": 0.9761904761904762,
        "vocab_size-2": 41,
        "unique-2": 40,
        "entropy-2": 5.344698375159715,
        "cond_entropy-2": 0.3649827789330602,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.055633152634460545,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 4.027681991198191,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7631578947368421,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.681880802803404,
        "distinct-2-nopunct": 0.9714285714285714,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.072140159802107,
        "cond_entropy-2-nopunct": 0.43877764648215045,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.06678301694496641,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "nist": 4.442754114641934,
        "bleu": 60.3779,
        "rouge1": {
            "precision": 0.73701,
            "recall": 0.7549,
            "fmeasure": 0.74375
        },
        "rouge2": {
            "precision": 0.56151,
            "recall": 0.58611,
            "fmeasure": 0.57163
        },
        "rougeL": {
            "precision": 0.71478,
            "recall": 0.73529,
            "fmeasure": 0.72291
        },
        "rougeLsum": {
            "precision": 0.71478,
            "recall": 0.73529,
            "fmeasure": 0.72291
        },
        "nubia": {
            "semantic_relation": 3.70282,
            "contradiction": 35.2097,
            "irrelevancy": 29.38587,
            "logical_agreement": 35.40443,
            "grammar_ref": 4.11451,
            "grammar_hyp": 3.6638,
            "nubia_score": 0.67872
        },
        "meteor": 0.46919665806689126,
        "bleurt": 0.4436,
        "bertscore": {
            "precision": 0.94968,
            "recall": 0.94577,
            "f1": 0.94768
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_665": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.084183719779189,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.17625665551219516,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.9057645846554525,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.19723710464117222,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "nist": 3.3670106639146886,
        "bleu": 44.89771,
        "rouge1": {
            "precision": 0.63889,
            "recall": 0.85,
            "fmeasure": 0.72727
        },
        "rouge2": {
            "precision": 0.44118,
            "recall": 0.6039,
            "fmeasure": 0.50806
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.81667,
            "fmeasure": 0.69697
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.81667,
            "fmeasure": 0.69697
        },
        "nubia": {
            "semantic_relation": 4.15263,
            "contradiction": 0.11395,
            "irrelevancy": 98.98795,
            "logical_agreement": 0.8981,
            "grammar_ref": 5.25223,
            "grammar_hyp": 4.59394,
            "nubia_score": 0.79698
        },
        "meteor": 0.5206368906659975,
        "bleurt": 0.40702,
        "bertscore": {
            "precision": 0.93677,
            "recall": 0.95171,
            "f1": 0.93114
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_603": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.84,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.243856189774722,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.35777297761309823,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.061400544664143256,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8260869565217391,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.088779347361362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.39041511712573906,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.18181818181818182,
            "3": 0.5238095238095238
        },
        "nist": 1.8093773681640686,
        "bleu": 50.25007,
        "rouge1": {
            "precision": 0.71014,
            "recall": 0.53673,
            "fmeasure": 0.60656
        },
        "rouge2": {
            "precision": 0.56061,
            "recall": 0.4188,
            "fmeasure": 0.47541
        },
        "rougeL": {
            "precision": 0.71014,
            "recall": 0.53673,
            "fmeasure": 0.60656
        },
        "rougeLsum": {
            "precision": 0.71014,
            "recall": 0.53673,
            "fmeasure": 0.60656
        },
        "nubia": {
            "semantic_relation": 2.51019,
            "contradiction": 99.39381,
            "irrelevancy": 0.4904,
            "logical_agreement": 0.11579,
            "grammar_ref": 3.4256,
            "grammar_hyp": 3.57207,
            "nubia_score": 0.19516
        },
        "meteor": 0.2953707771004424,
        "bleurt": -0.37799,
        "bertscore": {
            "precision": 0.93221,
            "recall": 0.87795,
            "f1": 0.90427
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_858": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.023638630780208267,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 1.0
        },
        "nist": 3.6338394482318477,
        "bleu": 42.15503,
        "rouge1": {
            "precision": 0.79412,
            "recall": 1.0,
            "fmeasure": 0.88495
        },
        "rouge2": {
            "precision": 0.34375,
            "recall": 0.4391,
            "fmeasure": 0.38547
        },
        "rougeL": {
            "precision": 0.64706,
            "recall": 0.81593,
            "fmeasure": 0.72151
        },
        "rougeLsum": {
            "precision": 0.64706,
            "recall": 0.81593,
            "fmeasure": 0.72151
        },
        "nubia": {
            "semantic_relation": 4.76617,
            "contradiction": 99.0295,
            "irrelevancy": 0.86343,
            "logical_agreement": 0.10707,
            "grammar_ref": 4.1674,
            "grammar_hyp": 4.2861,
            "nubia_score": 0.84543
        },
        "meteor": 0.44305591839751945,
        "bleurt": 0.35918,
        "bertscore": {
            "precision": 0.95121,
            "recall": 0.9751,
            "f1": 0.96301
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_720": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 70,
        "mean_pred_length": 17.5,
        "std_pred_length": 5.937171043518958,
        "median_pred_length": 18.5,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.7,
        "vocab_size-1": 49,
        "unique-1": 35,
        "entropy-1": 5.446791052504722,
        "distinct-2": 0.9696969696969697,
        "vocab_size-2": 64,
        "unique-2": 62,
        "entropy-2": 5.983788058752401,
        "cond_entropy-2": 0.506316405574909,
        "distinct-3": 1.0,
        "vocab_size-3": 62,
        "unique-3": 62,
        "entropy-3": 5.954196310386873,
        "cond_entropy-3": -0.025681679939320096,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 5.477225575051661,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.734375,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.402114648336088,
        "distinct-2-nopunct": 0.9666666666666667,
        "vocab_size-2-nopunct": 58,
        "unique-2-nopunct": 56,
        "entropy-2-nopunct": 5.8402239289418505,
        "cond_entropy-2-nopunct": 0.4779683040500249,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 56,
        "unique-3-nopunct": 56,
        "entropy-3-nopunct": 5.807354922057609,
        "cond_entropy-3-nopunct": -0.028107102122342957,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1875,
            "2": 0.5,
            "3": 0.7105263157894737
        },
        "nist": 3.5549367591412557,
        "bleu": 26.91506,
        "rouge1": {
            "precision": 0.60755,
            "recall": 0.66885,
            "fmeasure": 0.63446
        },
        "rouge2": {
            "precision": 0.337,
            "recall": 0.38381,
            "fmeasure": 0.35733
        },
        "rougeL": {
            "precision": 0.57346,
            "recall": 0.63754,
            "fmeasure": 0.60125
        },
        "rougeLsum": {
            "precision": 0.57346,
            "recall": 0.63754,
            "fmeasure": 0.60125
        },
        "nubia": {
            "semantic_relation": 4.41606,
            "contradiction": 5.85298,
            "irrelevancy": 23.78461,
            "logical_agreement": 70.36241,
            "grammar_ref": 4.54108,
            "grammar_hyp": 4.36444,
            "nubia_score": 0.76801
        },
        "meteor": 0.33214808114681715,
        "bleurt": 0.39135,
        "bertscore": {
            "precision": 0.88898,
            "recall": 0.91345,
            "f1": 0.90047
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_667": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.875,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.303508854797679,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.23229021629948574,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8695652173913043,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.229871195093384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.24291000358771486,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5625
        },
        "nist": 2.0449453572777565,
        "bleu": 9.42925,
        "rouge1": {
            "precision": 0.50725,
            "recall": 0.56429,
            "fmeasure": 0.53418
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.18889,
            "fmeasure": 0.17698
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.37063,
            "fmeasure": 0.35095
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.37063,
            "fmeasure": 0.35095
        },
        "nubia": {
            "semantic_relation": 3.98179,
            "contradiction": 0.62267,
            "irrelevancy": 61.63993,
            "logical_agreement": 37.7374,
            "grammar_ref": 4.46991,
            "grammar_hyp": 5.32667,
            "nubia_score": 0.55285
        },
        "meteor": 0.27831924034874833,
        "bleurt": -0.53503,
        "bertscore": {
            "precision": 0.83341,
            "recall": 0.83075,
            "f1": 0.83208
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_604": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.875
        },
        "nist": 2.542526363222396,
        "bleu": 9.57846,
        "rouge1": {
            "precision": 0.69697,
            "recall": 0.74411,
            "fmeasure": 0.71818
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.25,
            "fmeasure": 0.22222
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.55556,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.55556,
            "fmeasure": 0.5
        },
        "nubia": {
            "semantic_relation": 4.85053,
            "contradiction": 1.0102,
            "irrelevancy": 2.74819,
            "logical_agreement": 96.24162,
            "grammar_ref": 6.26263,
            "grammar_hyp": 5.9583,
            "nubia_score": 0.82481
        },
        "meteor": 0.31937200237426067,
        "bleurt": 0.60772,
        "bertscore": {
            "precision": 0.95304,
            "recall": 0.92033,
            "f1": 0.9364
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_630": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 68,
        "mean_pred_length": 17.0,
        "std_pred_length": 4.06201920231798,
        "median_pred_length": 17.5,
        "min_pred_length": 11,
        "max_pred_length": 22,
        "distinct-1": 0.5441176470588235,
        "vocab_size-1": 37,
        "unique-1": 25,
        "entropy-1": 4.7937250699115594,
        "distinct-2": 0.8125,
        "vocab_size-2": 52,
        "unique-2": 40,
        "entropy-2": 5.625,
        "cond_entropy-2": 0.7871335407971151,
        "distinct-3": 0.8666666666666667,
        "vocab_size-3": 52,
        "unique-3": 44,
        "entropy-3": 5.640223928941851,
        "cond_entropy-3": 0.006890595608518559,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 4.06201920231798,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.5625,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.7504036179525455,
        "distinct-2-nopunct": 0.8166666666666667,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.540223928941851,
        "cond_entropy-2-nopunct": 0.8064600697924699,
        "distinct-3-nopunct": 0.875,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.557354922057607,
        "cond_entropy-3-nopunct": 0.007607183591942772,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.803921568627451
        },
        "nist": 4.512442250724066,
        "bleu": 55.75347,
        "rouge1": {
            "precision": 0.82341,
            "recall": 0.83466,
            "fmeasure": 0.8251
        },
        "rouge2": {
            "precision": 0.66357,
            "recall": 0.6761,
            "fmeasure": 0.66602
        },
        "rougeL": {
            "precision": 0.80675,
            "recall": 0.8172,
            "fmeasure": 0.80805
        },
        "rougeLsum": {
            "precision": 0.80675,
            "recall": 0.8172,
            "fmeasure": 0.80805
        },
        "nubia": {
            "semantic_relation": 3.86953,
            "contradiction": 45.52812,
            "irrelevancy": 10.43308,
            "logical_agreement": 44.0388,
            "grammar_ref": 3.98368,
            "grammar_hyp": 4.00257,
            "nubia_score": 0.65267
        },
        "meteor": 0.4539736864254907,
        "bleurt": 0.59492,
        "bertscore": {
            "precision": 0.96336,
            "recall": 0.95911,
            "f1": 0.96112
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_860": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6
        },
        "nist": 1.9669791651768762,
        "bleu": 17.3935,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.27273,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.41667,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.41667,
            "fmeasure": 0.5
        },
        "nubia": {
            "semantic_relation": 4.77921,
            "contradiction": 1.87906,
            "irrelevancy": 1.12407,
            "logical_agreement": 96.99688,
            "grammar_ref": 5.64121,
            "grammar_hyp": 6.71744,
            "nubia_score": 0.72009
        },
        "meteor": 0.3509395707573647,
        "bleurt": 0.44059,
        "bertscore": {
            "precision": 0.95438,
            "recall": 0.88575,
            "f1": 0.91824
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_864": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 8,
        "unique-1": 7,
        "entropy-1": 2.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": 0.08007499855768763,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": 0.0930692077718899,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 2.4156844010247407,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "nubia": {
            "semantic_relation": 4.64096,
            "contradiction": 0.21793,
            "irrelevancy": 0.49368,
            "logical_agreement": 99.2884,
            "grammar_ref": 5.14316,
            "grammar_hyp": 5.3673,
            "nubia_score": 0.85584
        },
        "meteor": 1.0,
        "bleurt": 0.6432,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_868": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 2.0,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.6428571428571429,
        "vocab_size-1": 18,
        "unique-1": 8,
        "entropy-1": 4.09306920777189,
        "distinct-2": 0.7692307692307693,
        "vocab_size-2": 20,
        "unique-2": 14,
        "entropy-2": 4.238901256602629,
        "cond_entropy-2": 0.1238540268527186,
        "distinct-3": 0.8333333333333334,
        "vocab_size-3": 20,
        "unique-3": 16,
        "entropy-3": 4.251629167387823,
        "cond_entropy-3": 0.051189449246730766,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.6538461538461539,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 4.008132025833399,
        "distinct-2-nopunct": 0.75,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 4.084962500721157,
        "cond_entropy-2-nopunct": 0.09285611591339743,
        "distinct-3-nopunct": 0.8181818181818182,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 4.095795255000931,
        "cond_entropy-3-nopunct": 0.05628729973432271,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.42857142857142855,
            "3": 0.6875
        },
        "nist": 3.9752404190424424,
        "bleu": 42.20561,
        "rouge1": {
            "precision": 0.61463,
            "recall": 0.72451,
            "fmeasure": 0.6638
        },
        "rouge2": {
            "precision": 0.47917,
            "recall": 0.51088,
            "fmeasure": 0.48417
        },
        "rougeL": {
            "precision": 0.58522,
            "recall": 0.68697,
            "fmeasure": 0.63082
        },
        "rougeLsum": {
            "precision": 0.58522,
            "recall": 0.68697,
            "fmeasure": 0.63082
        },
        "nubia": {
            "semantic_relation": 3.88999,
            "contradiction": 10.72588,
            "irrelevancy": 49.39931,
            "logical_agreement": 39.87481,
            "grammar_ref": 3.56015,
            "grammar_hyp": 3.55171,
            "nubia_score": 0.6952
        },
        "meteor": 0.4355261946268065,
        "bleurt": 0.04119,
        "bertscore": {
            "precision": 0.90968,
            "recall": 0.9419,
            "f1": 0.9255
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_873": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.7083333333333334,
        "vocab_size-1": 17,
        "unique-1": 12,
        "entropy-1": 3.91829583405449,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 22,
        "unique-2": 21,
        "entropy-2": 4.436605434317882,
        "cond_entropy-2": 0.5472951075097698,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": 0.026778753489375355,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7647058823529411,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.499227547132693,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.875,
        "cond_entropy-2-nopunct": 0.41253715874966074,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": 0.040223928941851894,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.6428571428571429
        },
        "nist": 2.8727031626071873,
        "bleu": 6.60451,
        "rouge1": {
            "precision": 0.70588,
            "recall": 0.59436,
            "fmeasure": 0.6406
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.26495,
            "fmeasure": 0.28446
        },
        "rougeL": {
            "precision": 0.55882,
            "recall": 0.47304,
            "fmeasure": 0.50861
        },
        "rougeLsum": {
            "precision": 0.55882,
            "recall": 0.47304,
            "fmeasure": 0.50861
        },
        "nubia": {
            "semantic_relation": 4.02037,
            "contradiction": 14.35207,
            "irrelevancy": 4.64969,
            "logical_agreement": 80.99824,
            "grammar_ref": 4.95035,
            "grammar_hyp": 5.06107,
            "nubia_score": 0.59555
        },
        "meteor": 0.3106134684207108,
        "bleurt": 0.20171,
        "bertscore": {
            "precision": 0.89074,
            "recall": 0.89641,
            "f1": 0.89357
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1015": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 41,
        "mean_pred_length": 20.5,
        "std_pred_length": 1.5,
        "median_pred_length": 20.5,
        "min_pred_length": 19,
        "max_pred_length": 22,
        "distinct-1": 0.8780487804878049,
        "vocab_size-1": 36,
        "unique-1": 32,
        "entropy-1": 5.095237675297022,
        "distinct-2": 1.0,
        "vocab_size-2": 39,
        "unique-2": 39,
        "entropy-2": 5.285402218862247,
        "cond_entropy-2": 0.177975534812459,
        "distinct-3": 1.0,
        "vocab_size-3": 37,
        "unique-3": 37,
        "entropy-3": 5.209453365628954,
        "cond_entropy-3": -0.07594885323329875,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9142857142857143,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.9362862311688644,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.11980466308510698,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.09019780897157811,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2962962962962963,
            "2": 0.8095238095238095
        },
        "nist": 4.773856042450574,
        "bleu": 44.26615,
        "rouge1": {
            "precision": 0.65441,
            "recall": 0.67191,
            "fmeasure": 0.65709
        },
        "rouge2": {
            "precision": 0.41938,
            "recall": 0.41805,
            "fmeasure": 0.41383
        },
        "rougeL": {
            "precision": 0.55656,
            "recall": 0.56457,
            "fmeasure": 0.55479
        },
        "rougeLsum": {
            "precision": 0.55656,
            "recall": 0.56457,
            "fmeasure": 0.55479
        },
        "nubia": {
            "semantic_relation": 3.80531,
            "contradiction": 1.44748,
            "irrelevancy": 82.66095,
            "logical_agreement": 15.89157,
            "grammar_ref": 4.87596,
            "grammar_hyp": 4.51089,
            "nubia_score": 0.61577
        },
        "meteor": 0.3641011297428962,
        "bleurt": -0.13881,
        "bertscore": {
            "precision": 0.9253,
            "recall": 0.93774,
            "f1": 0.92325
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_795": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5454545454545454
        },
        "nist": 1.1985265509331526,
        "bleu": 4.80804,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.66667,
            "fmeasure": 0.75
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.28571,
            "recall": 0.22222,
            "fmeasure": 0.25
        },
        "rougeLsum": {
            "precision": 0.28571,
            "recall": 0.22222,
            "fmeasure": 0.25
        },
        "nubia": {
            "semantic_relation": 3.63266,
            "contradiction": 0.17952,
            "irrelevancy": 97.73248,
            "logical_agreement": 2.08799,
            "grammar_ref": 4.80739,
            "grammar_hyp": 5.36283,
            "nubia_score": 0.56183
        },
        "meteor": 0.2369020501138952,
        "bleurt": -0.3923,
        "bertscore": {
            "precision": 0.80465,
            "recall": 0.73945,
            "f1": 0.77067
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_876": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7142857142857143
        },
        "nist": 1.6363636363636365,
        "bleu": 11.73118,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.85714,
            "fmeasure": 0.70588
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.5,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.85714,
            "fmeasure": 0.70588
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.85714,
            "fmeasure": 0.70588
        },
        "nubia": {
            "semantic_relation": 4.63911,
            "contradiction": 0.15419,
            "irrelevancy": 34.47586,
            "logical_agreement": 65.36995,
            "grammar_ref": 5.74517,
            "grammar_hyp": 4.51844,
            "nubia_score": 0.9699
        },
        "meteor": 0.3691424994520742,
        "bleurt": 0.43507,
        "bertscore": {
            "precision": 0.86756,
            "recall": 0.90492,
            "f1": 0.88585
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_605": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.75
        },
        "nist": 1.9438230237901655,
        "bleu": 53.47161,
        "rouge1": {
            "precision": 0.87179,
            "recall": 0.65833,
            "fmeasure": 0.74817
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.52632,
            "fmeasure": 0.64516
        },
        "rougeL": {
            "precision": 0.71795,
            "recall": 0.54167,
            "fmeasure": 0.61581
        },
        "rougeLsum": {
            "precision": 0.71795,
            "recall": 0.54167,
            "fmeasure": 0.61581
        },
        "nubia": {
            "semantic_relation": 4.65753,
            "contradiction": 0.28054,
            "irrelevancy": 0.47929,
            "logical_agreement": 99.24018,
            "grammar_ref": 3.95052,
            "grammar_hyp": 4.96557,
            "nubia_score": 0.82061
        },
        "meteor": 0.3970655806086951,
        "bleurt": 0.42696,
        "bertscore": {
            "precision": 0.95582,
            "recall": 0.92292,
            "f1": 0.93908
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_606": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 44,
        "mean_pred_length": 11.0,
        "std_pred_length": 2.0,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 13,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 36,
        "unique-1": 32,
        "entropy-1": 5.004886164091842,
        "distinct-2": 1.0,
        "vocab_size-2": 40,
        "unique-2": 40,
        "entropy-2": 5.3219280948873635,
        "cond_entropy-2": 0.16249647625006497,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.021928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.1699250014423095,
        "cond_entropy-2-nopunct": 0.1813302398882836,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.16992500144231223,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.8,
            "3": 0.88
        },
        "nist": 4.88782290859977,
        "bleu": 59.58281,
        "rouge1": {
            "precision": 0.84028,
            "recall": 0.95291,
            "fmeasure": 0.88551
        },
        "rouge2": {
            "precision": 0.6553,
            "recall": 0.72822,
            "fmeasure": 0.68206
        },
        "rougeL": {
            "precision": 0.78472,
            "recall": 0.88439,
            "fmeasure": 0.82418
        },
        "rougeLsum": {
            "precision": 0.78472,
            "recall": 0.88439,
            "fmeasure": 0.82418
        },
        "nubia": {
            "semantic_relation": 4.41189,
            "contradiction": 3.23264,
            "irrelevancy": 45.56329,
            "logical_agreement": 51.20407,
            "grammar_ref": 4.98306,
            "grammar_hyp": 4.80913,
            "nubia_score": 0.80618
        },
        "meteor": 0.5184490128613273,
        "bleurt": 0.63194,
        "bertscore": {
            "precision": 0.94557,
            "recall": 0.9734,
            "f1": 0.95831
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1155": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.7857142857142857,
        "vocab_size-1": 11,
        "unique-1": 9,
        "entropy-1": 3.3248629576173574,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 12,
        "unique-2": 11,
        "entropy-2": 3.5465935642949384,
        "cond_entropy-2": 0.2588453731729854,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": 0.05118944924673077,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7692307692307693,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.180832987205441,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.418295834054489,
        "cond_entropy-2-nopunct": 0.28076340776035313,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": 0.056287299734322706,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.7
        },
        "nist": 4.3635205456253825,
        "bleu": 72.8596,
        "rouge1": {
            "precision": 0.95238,
            "recall": 0.81569,
            "fmeasure": 0.87801
        },
        "rouge2": {
            "precision": 0.92308,
            "recall": 0.77976,
            "fmeasure": 0.84461
        },
        "rougeL": {
            "precision": 0.95238,
            "recall": 0.81569,
            "fmeasure": 0.87801
        },
        "rougeLsum": {
            "precision": 0.95238,
            "recall": 0.81569,
            "fmeasure": 0.87801
        },
        "nubia": {
            "semantic_relation": 4.25413,
            "contradiction": 0.21369,
            "irrelevancy": 1.15034,
            "logical_agreement": 98.63597,
            "grammar_ref": 3.50326,
            "grammar_hyp": 3.58434,
            "nubia_score": 0.86093
        },
        "meteor": 0.48154318343732727,
        "bleurt": 0.48403,
        "bertscore": {
            "precision": 0.98022,
            "recall": 0.89828,
            "f1": 0.93746
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_798": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 51,
        "mean_pred_length": 17.0,
        "std_pred_length": 4.08248290463863,
        "median_pred_length": 17.0,
        "min_pred_length": 12,
        "max_pred_length": 22,
        "distinct-1": 0.5882352941176471,
        "vocab_size-1": 30,
        "unique-1": 18,
        "entropy-1": 4.679696116812856,
        "distinct-2": 0.7708333333333334,
        "vocab_size-2": 37,
        "unique-2": 29,
        "entropy-2": 5.07944869850261,
        "cond_entropy-2": 0.36273800196709427,
        "distinct-3": 0.8444444444444444,
        "vocab_size-3": 38,
        "unique-3": 33,
        "entropy-3": 5.147191429566852,
        "cond_entropy-3": 0.05699920676770648,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 3.2998316455372216,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6086956521739131,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.569772760819465,
        "distinct-2-nopunct": 0.7674418604651163,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.908481905713948,
        "cond_entropy-2-nopunct": 0.29725592154420316,
        "distinct-3-nopunct": 0.85,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.98418371977919,
        "cond_entropy-3-nopunct": 0.03528740270329315,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.8,
            "2": 0.16666666666666666,
            "3": 0.7368421052631579
        },
        "nist": 4.562720530194678,
        "bleu": 42.76854,
        "rouge1": {
            "precision": 0.78309,
            "recall": 0.66084,
            "fmeasure": 0.70855
        },
        "rouge2": {
            "precision": 0.47778,
            "recall": 0.38048,
            "fmeasure": 0.41932
        },
        "rougeL": {
            "precision": 0.66265,
            "recall": 0.54929,
            "fmeasure": 0.59397
        },
        "rougeLsum": {
            "precision": 0.66265,
            "recall": 0.54929,
            "fmeasure": 0.59397
        },
        "nubia": {
            "semantic_relation": 4.23001,
            "contradiction": 0.36981,
            "irrelevancy": 40.30732,
            "logical_agreement": 59.32287,
            "grammar_ref": 5.76985,
            "grammar_hyp": 5.7541,
            "nubia_score": 0.69394
        },
        "meteor": 0.38616455871393296,
        "bleurt": -0.03757,
        "bertscore": {
            "precision": 0.92586,
            "recall": 0.89827,
            "f1": 0.91135
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_670": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.6666666666666666,
            "3": 0.6666666666666666
        },
        "nist": 2.7765468173623633,
        "bleu": 27.20696,
        "rouge1": {
            "precision": 0.53333,
            "recall": 0.64171,
            "fmeasure": 0.57692
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.35556,
            "fmeasure": 0.31418
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.64171,
            "fmeasure": 0.57692
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.64171,
            "fmeasure": 0.57692
        },
        "nubia": {
            "semantic_relation": 3.76001,
            "contradiction": 0.62681,
            "irrelevancy": 65.57063,
            "logical_agreement": 33.80256,
            "grammar_ref": 4.84054,
            "grammar_hyp": 4.47636,
            "nubia_score": 0.6061
        },
        "meteor": 0.4011104429111581,
        "bleurt": -0.10325,
        "bertscore": {
            "precision": 0.87972,
            "recall": 0.92105,
            "f1": 0.89899
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1164": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 1.5,
        "median_pred_length": 14.5,
        "min_pred_length": 13,
        "max_pred_length": 16,
        "distinct-1": 0.7241379310344828,
        "vocab_size-1": 21,
        "unique-1": 14,
        "entropy-1": 4.280226253673659,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.4433838219308399,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7307692307692307,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.132944044980958,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.49930976183687525,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.1111111111111111,
            "3": 0.5882352941176471
        },
        "nist": 2.295552375737449,
        "bleu": 19.43848,
        "rouge1": {
            "precision": 0.51944,
            "recall": 0.56742,
            "fmeasure": 0.53437
        },
        "rouge2": {
            "precision": 0.26948,
            "recall": 0.29148,
            "fmeasure": 0.27537
        },
        "rougeL": {
            "precision": 0.50833,
            "recall": 0.55909,
            "fmeasure": 0.52484
        },
        "rougeLsum": {
            "precision": 0.50833,
            "recall": 0.55909,
            "fmeasure": 0.52484
        },
        "nubia": {
            "semantic_relation": 3.81997,
            "contradiction": 44.9559,
            "irrelevancy": 52.70954,
            "logical_agreement": 2.33456,
            "grammar_ref": 4.30067,
            "grammar_hyp": 4.34039,
            "nubia_score": 0.64922
        },
        "meteor": 0.27994448805938027,
        "bleurt": 0.26951,
        "bertscore": {
            "precision": 0.88848,
            "recall": 0.90224,
            "f1": 0.88961
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_672": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 7.0,
        "median_pred_length": 20.0,
        "min_pred_length": 13,
        "max_pred_length": 27,
        "distinct-1": 0.8,
        "vocab_size-1": 32,
        "unique-1": 26,
        "entropy-1": 4.8719280948873624,
        "distinct-2": 1.0,
        "vocab_size-2": 38,
        "unique-2": 38,
        "entropy-2": 5.247927513443589,
        "cond_entropy-2": 0.3733678396088548,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.0780025120012732,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.843568731230678,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.18783837514075938,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.09019780897157811,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.16666666666666666,
            "3": 0.6666666666666666
        },
        "nist": 3.590719923780303,
        "bleu": 38.71158,
        "rouge1": {
            "precision": 0.67544,
            "recall": 0.61294,
            "fmeasure": 0.64096
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.37778,
            "fmeasure": 0.38272
        },
        "rougeL": {
            "precision": 0.51754,
            "recall": 0.45504,
            "fmeasure": 0.48306
        },
        "rougeLsum": {
            "precision": 0.51754,
            "recall": 0.45504,
            "fmeasure": 0.48306
        },
        "nubia": {
            "semantic_relation": 3.19784,
            "contradiction": 0.29951,
            "irrelevancy": 42.77609,
            "logical_agreement": 56.92439,
            "grammar_ref": 4.36031,
            "grammar_hyp": 4.38669,
            "nubia_score": 0.4739
        },
        "meteor": 0.3368961520206747,
        "bleurt": -0.01674,
        "bertscore": {
            "precision": 0.88051,
            "recall": 0.85635,
            "f1": 0.86668
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_632": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717246,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "nist": 0.05784726708778937,
        "bleu": 15.84584,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.34119,
            "fmeasure": 0.49223
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.22283,
            "fmeasure": 0.32792
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.29854,
            "fmeasure": 0.4307
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.29854,
            "fmeasure": 0.4307
        },
        "nubia": {
            "semantic_relation": 3.00313,
            "contradiction": 11.09423,
            "irrelevancy": 2.36107,
            "logical_agreement": 86.54471,
            "grammar_ref": 5.07625,
            "grammar_hyp": 6.20892,
            "nubia_score": 0.19742
        },
        "meteor": 0.20130815671219748,
        "bleurt": -0.3862,
        "bertscore": {
            "precision": 0.9061,
            "recall": 0.82782,
            "f1": 0.86519
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_800": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 46,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 4.4969125210773475,
        "median_pred_length": 18.0,
        "min_pred_length": 9,
        "max_pred_length": 19,
        "distinct-1": 0.7391304347826086,
        "vocab_size-1": 34,
        "unique-1": 27,
        "entropy-1": 4.919769836256634,
        "distinct-2": 0.9302325581395349,
        "vocab_size-2": 40,
        "unique-2": 38,
        "entropy-2": 5.26917434767504,
        "cond_entropy-2": 0.28095076391230356,
        "distinct-3": 1.0,
        "vocab_size-3": 40,
        "unique-3": 40,
        "entropy-3": 5.3219280948873635,
        "cond_entropy-3": 0.0645355277393509,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 4.189935029992179,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7804878048780488,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.8448800531875,
        "distinct-2-nopunct": 0.9210526315789473,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.0701673160182334,
        "cond_entropy-2-nopunct": 0.2657613642594599,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": 0.07435228927748018,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.3333333333333333,
            "3": 0.7241379310344828
        },
        "nist": 2.6010792958673288,
        "bleu": 6.87549,
        "rouge1": {
            "precision": 0.55234,
            "recall": 0.70808,
            "fmeasure": 0.61947
        },
        "rouge2": {
            "precision": 0.19841,
            "recall": 0.2659,
            "fmeasure": 0.22687
        },
        "rougeL": {
            "precision": 0.40029,
            "recall": 0.49524,
            "fmeasure": 0.44231
        },
        "rougeLsum": {
            "precision": 0.40029,
            "recall": 0.49524,
            "fmeasure": 0.44231
        },
        "nubia": {
            "semantic_relation": 4.38304,
            "contradiction": 15.78098,
            "irrelevancy": 15.74209,
            "logical_agreement": 68.47692,
            "grammar_ref": 5.969,
            "grammar_hyp": 5.37649,
            "nubia_score": 0.75864
        },
        "meteor": 0.33099168390586,
        "bleurt": 0.17138,
        "bertscore": {
            "precision": 0.89694,
            "recall": 0.90648,
            "f1": 0.89936
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_608": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 3.0,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.7666666666666667,
        "vocab_size-1": 23,
        "unique-1": 16,
        "entropy-1": 4.440223928941852,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 24,
        "unique-2": 20,
        "entropy-2": 4.52164063634332,
        "cond_entropy-2": 0.04332146930622849,
        "distinct-3": 0.9230769230769231,
        "vocab_size-3": 24,
        "unique-3": 22,
        "entropy-3": 4.546593564294937,
        "cond_entropy-3": 0.046930949929641676,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.378783493486177,
        "distinct-2-nopunct": 0.8461538461538461,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.392747410448783,
        "cond_entropy-2-nopunct": 0.0084694114681032,
        "distinct-3-nopunct": 0.9166666666666666,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.418295834054489,
        "cond_entropy-3-nopunct": 0.009522782580064105,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.8095238095238095
        },
        "nist": 3.2105583816990757,
        "bleu": 41.0308,
        "rouge1": {
            "precision": 0.6738,
            "recall": 0.78791,
            "fmeasure": 0.72535
        },
        "rouge2": {
            "precision": 0.46458,
            "recall": 0.52259,
            "fmeasure": 0.49179
        },
        "rougeL": {
            "precision": 0.66399,
            "recall": 0.74524,
            "fmeasure": 0.70209
        },
        "rougeLsum": {
            "precision": 0.66399,
            "recall": 0.74524,
            "fmeasure": 0.70209
        },
        "nubia": {
            "semantic_relation": 4.79162,
            "contradiction": 0.23026,
            "irrelevancy": 15.00238,
            "logical_agreement": 84.76736,
            "grammar_ref": 4.34398,
            "grammar_hyp": 4.43986,
            "nubia_score": 0.89472
        },
        "meteor": 0.41972488818049963,
        "bleurt": 0.59131,
        "bertscore": {
            "precision": 0.91324,
            "recall": 0.92543,
            "f1": 0.91929
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_426": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 62,
        "mean_pred_length": 20.666666666666668,
        "std_pred_length": 1.247219128924647,
        "median_pred_length": 21.0,
        "min_pred_length": 19,
        "max_pred_length": 22,
        "distinct-1": 0.7258064516129032,
        "vocab_size-1": 45,
        "unique-1": 31,
        "entropy-1": 5.3613755442229465,
        "distinct-2": 0.8983050847457628,
        "vocab_size-2": 53,
        "unique-2": 47,
        "entropy-2": 5.679253218853362,
        "cond_entropy-2": 0.31412279833366874,
        "distinct-3": 0.9107142857142857,
        "vocab_size-3": 51,
        "unique-3": 46,
        "entropy-3": 5.62878349348618,
        "cond_entropy-3": -0.039573841589951544,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 18.333333333333332,
        "std_pred_length-nopunct": 1.699673171197595,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7636363636363637,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.272268804433748,
        "distinct-2-nopunct": 0.8846153846153846,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.469670487371864,
        "cond_entropy-2-nopunct": 0.18831077384720177,
        "distinct-3-nopunct": 0.8979591836734694,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.410628211462147,
        "cond_entropy-3-nopunct": -0.06532171076057765,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.45161290322580644,
            "3": 0.6
        },
        "nist": 3.4639273256812206,
        "bleu": 30.98236,
        "rouge1": {
            "precision": 0.65079,
            "recall": 0.55985,
            "fmeasure": 0.59636
        },
        "rouge2": {
            "precision": 0.41474,
            "recall": 0.36295,
            "fmeasure": 0.3844
        },
        "rougeL": {
            "precision": 0.55314,
            "recall": 0.48971,
            "fmeasure": 0.51506
        },
        "rougeLsum": {
            "precision": 0.55314,
            "recall": 0.48971,
            "fmeasure": 0.51506
        },
        "nubia": {
            "semantic_relation": 3.21387,
            "contradiction": 19.9419,
            "irrelevancy": 45.44089,
            "logical_agreement": 34.61722,
            "grammar_ref": 3.62435,
            "grammar_hyp": 3.39164,
            "nubia_score": 0.57879
        },
        "meteor": 0.2560527813931742,
        "bleurt": -0.06746,
        "bertscore": {
            "precision": 0.89331,
            "recall": 0.86248,
            "f1": 0.87588
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_427": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 55,
        "mean_pred_length": 18.333333333333332,
        "std_pred_length": 5.312459150169742,
        "median_pred_length": 18.0,
        "min_pred_length": 12,
        "max_pred_length": 25,
        "distinct-1": 0.7090909090909091,
        "vocab_size-1": 39,
        "unique-1": 31,
        "entropy-1": 5.047459204859197,
        "distinct-2": 0.9615384615384616,
        "vocab_size-2": 50,
        "unique-2": 48,
        "entropy-2": 5.623516641218019,
        "cond_entropy-2": 0.5799363118587458,
        "distinct-3": 1.0,
        "vocab_size-3": 49,
        "unique-3": 49,
        "entropy-3": 5.614709844115208,
        "cond_entropy-3": -0.004097220964659245,
        "total_length-nopunct": 51,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 5.354126134736337,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7254901960784313,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 4.959395381646003,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.5016291673878275,
        "cond_entropy-2-nopunct": 0.5867981582621664,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 45,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.491853096329673,
        "cond_entropy-3-nopunct": -0.004220515502592885,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.6153846153846154,
            "3": 0.7666666666666667
        },
        "nist": 5.072534531955115,
        "bleu": 59.07654,
        "rouge1": {
            "precision": 0.72196,
            "recall": 0.78445,
            "fmeasure": 0.7494
        },
        "rouge2": {
            "precision": 0.48784,
            "recall": 0.57761,
            "fmeasure": 0.52771
        },
        "rougeL": {
            "precision": 0.68493,
            "recall": 0.74995,
            "fmeasure": 0.71368
        },
        "rougeLsum": {
            "precision": 0.68493,
            "recall": 0.74995,
            "fmeasure": 0.71368
        },
        "nubia": {
            "semantic_relation": 4.51809,
            "contradiction": 0.69265,
            "irrelevancy": 63.21089,
            "logical_agreement": 36.09646,
            "grammar_ref": 4.38609,
            "grammar_hyp": 4.01807,
            "nubia_score": 0.80197
        },
        "meteor": 0.48168277386501385,
        "bleurt": 0.36551,
        "bertscore": {
            "precision": 0.93492,
            "recall": 0.95097,
            "f1": 0.94219
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_428": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75
        },
        "nist": 2.728440861296354,
        "bleu": 51.3345,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.675,
            "fmeasure": 0.70833
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.39683,
            "fmeasure": 0.41071
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.675,
            "fmeasure": 0.70833
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.675,
            "fmeasure": 0.70833
        },
        "nubia": {
            "semantic_relation": 3.8356,
            "contradiction": 0.29358,
            "irrelevancy": 2.30585,
            "logical_agreement": 97.40056,
            "grammar_ref": 6.57359,
            "grammar_hyp": 6.42103,
            "nubia_score": 0.64627
        },
        "meteor": 0.4099828269763827,
        "bleurt": 0.49581,
        "bertscore": {
            "precision": 0.95461,
            "recall": 0.9542,
            "f1": 0.95441
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_920": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 53,
        "mean_pred_length": 17.666666666666668,
        "std_pred_length": 2.6246692913372702,
        "median_pred_length": 19.0,
        "min_pred_length": 14,
        "max_pred_length": 20,
        "distinct-1": 0.7358490566037735,
        "vocab_size-1": 39,
        "unique-1": 28,
        "entropy-1": 5.147639558295962,
        "distinct-2": 0.96,
        "vocab_size-2": 48,
        "unique-2": 46,
        "entropy-2": 5.563856189774728,
        "cond_entropy-2": 0.35593573521152544,
        "distinct-3": 1.0,
        "vocab_size-3": 47,
        "unique-3": 47,
        "entropy-3": 5.55458885167764,
        "cond_entropy-3": -0.004160955118363874,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 3.7712361663282534,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7608695652173914,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 5.001822825622229,
        "distinct-2-nopunct": 0.9534883720930233,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.333241498888144,
        "cond_entropy-2-nopunct": 0.3445632637613638,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.02933665981473582,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.3,
            "3": 0.6388888888888888
        },
        "nist": 3.783771946130819,
        "bleu": 34.09661,
        "rouge1": {
            "precision": 0.65595,
            "recall": 0.66667,
            "fmeasure": 0.65965
        },
        "rouge2": {
            "precision": 0.41558,
            "recall": 0.44464,
            "fmeasure": 0.42879
        },
        "rougeL": {
            "precision": 0.54873,
            "recall": 0.56667,
            "fmeasure": 0.55619
        },
        "rougeLsum": {
            "precision": 0.54873,
            "recall": 0.56667,
            "fmeasure": 0.55619
        },
        "nubia": {
            "semantic_relation": 3.77475,
            "contradiction": 14.92983,
            "irrelevancy": 51.99732,
            "logical_agreement": 33.07285,
            "grammar_ref": 4.46773,
            "grammar_hyp": 4.30049,
            "nubia_score": 0.60635
        },
        "meteor": 0.3075732686851682,
        "bleurt": -0.03332,
        "bertscore": {
            "precision": 0.89865,
            "recall": 0.88503,
            "f1": 0.8916
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1165": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.5
        },
        "nist": 1.8094988549899862,
        "bleu": 24.59813,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.26984,
            "fmeasure": 0.32727
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "nubia": {
            "semantic_relation": 4.18837,
            "contradiction": 0.38664,
            "irrelevancy": 0.58445,
            "logical_agreement": 99.02891,
            "grammar_ref": 4.24352,
            "grammar_hyp": 4.86986,
            "nubia_score": 0.75842
        },
        "meteor": 0.3010544205973617,
        "bleurt": 0.30353,
        "bertscore": {
            "precision": 0.97738,
            "recall": 0.94093,
            "f1": 0.95881
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_924": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8125
        },
        "nist": 2.2762518143707022,
        "bleu": 35.51985,
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.76974,
            "fmeasure": 0.81404
        },
        "rouge2": {
            "precision": 0.64286,
            "recall": 0.56667,
            "fmeasure": 0.60129
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.65132,
            "fmeasure": 0.6888
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.65132,
            "fmeasure": 0.6888
        },
        "nubia": {
            "semantic_relation": 4.14265,
            "contradiction": 0.42922,
            "irrelevancy": 80.41171,
            "logical_agreement": 19.15907,
            "grammar_ref": 4.542,
            "grammar_hyp": 4.75152,
            "nubia_score": 0.65101
        },
        "meteor": 0.3925802954802998,
        "bleurt": 0.13403,
        "bertscore": {
            "precision": 0.94259,
            "recall": 0.84472,
            "f1": 0.89097
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_609": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.12336199461765371,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.129610672108602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "nist": 3.1540335134510618,
        "bleu": 39.34843,
        "rouge1": {
            "precision": 0.74603,
            "recall": 0.77109,
            "fmeasure": 0.75794
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.49206,
            "fmeasure": 0.49593
        },
        "rougeL": {
            "precision": 0.4127,
            "recall": 0.42607,
            "fmeasure": 0.41905
        },
        "rougeLsum": {
            "precision": 0.4127,
            "recall": 0.42607,
            "fmeasure": 0.41905
        },
        "nubia": {
            "semantic_relation": 4.17442,
            "contradiction": 0.19849,
            "irrelevancy": 5.82596,
            "logical_agreement": 93.97555,
            "grammar_ref": 5.09304,
            "grammar_hyp": 4.09121,
            "nubia_score": 0.82439
        },
        "meteor": 0.3612091389743566,
        "bleurt": 0.10268,
        "bertscore": {
            "precision": 0.92915,
            "recall": 0.92262,
            "f1": 0.92587
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_925": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "nist": 2.76984493924432,
        "bleu": 30.85696,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.71429,
            "fmeasure": 0.71429
        },
        "rouge2": {
            "precision": 0.53846,
            "recall": 0.53846,
            "fmeasure": 0.53846
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "nubia": {
            "semantic_relation": 4.30494,
            "contradiction": 0.25466,
            "irrelevancy": 21.48437,
            "logical_agreement": 78.26097,
            "grammar_ref": 5.0526,
            "grammar_hyp": 5.43484,
            "nubia_score": 0.65632
        },
        "meteor": 0.43269127941823876,
        "bleurt": 0.24827,
        "bertscore": {
            "precision": 0.92814,
            "recall": 0.90694,
            "f1": 0.91742
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_635": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 4.482634504257068,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2983,
            "irrelevancy": 0.53829,
            "logical_agreement": 99.16341,
            "grammar_ref": 5.3705,
            "grammar_hyp": 5.33734,
            "nubia_score": 0.99191
        },
        "meteor": 1.0,
        "bleurt": 0.76845,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_882": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 3.5,
        "median_pred_length": 16.5,
        "min_pred_length": 13,
        "max_pred_length": 20,
        "distinct-1": 0.8787878787878788,
        "vocab_size-1": 29,
        "unique-1": 25,
        "entropy-1": 4.801969876934214,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": 0.10335057812519607,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.09621531525930291,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9259259259259259,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.606739354015323,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.048968687611256036,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.0,
            "3": 0.88
        },
        "nist": 4.441130377054252,
        "bleu": 59.46238,
        "rouge1": {
            "precision": 0.90625,
            "recall": 0.80333,
            "fmeasure": 0.84643
        },
        "rouge2": {
            "precision": 0.72222,
            "recall": 0.66826,
            "fmeasure": 0.69131
        },
        "rougeL": {
            "precision": 0.73958,
            "recall": 0.68406,
            "fmeasure": 0.70798
        },
        "rougeLsum": {
            "precision": 0.73958,
            "recall": 0.68406,
            "fmeasure": 0.70798
        },
        "nubia": {
            "semantic_relation": 4.70127,
            "contradiction": 1.07712,
            "irrelevancy": 0.87056,
            "logical_agreement": 98.05231,
            "grammar_ref": 4.2058,
            "grammar_hyp": 4.42822,
            "nubia_score": 0.90011
        },
        "meteor": 0.4443350722682987,
        "bleurt": 0.59699,
        "bertscore": {
            "precision": 0.94503,
            "recall": 0.94438,
            "f1": 0.9447
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_636": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.02961067210860197,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.5294117647058824
        },
        "nist": 2.3411650783784506,
        "bleu": 10.63188,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.53755,
            "fmeasure": 0.567
        },
        "rouge2": {
            "precision": 0.35088,
            "recall": 0.31313,
            "fmeasure": 0.33089
        },
        "rougeL": {
            "precision": 0.45,
            "recall": 0.40316,
            "fmeasure": 0.42525
        },
        "rougeLsum": {
            "precision": 0.45,
            "recall": 0.40316,
            "fmeasure": 0.42525
        },
        "nubia": {
            "semantic_relation": 2.95167,
            "contradiction": 99.63358,
            "irrelevancy": 0.28912,
            "logical_agreement": 0.0773,
            "grammar_ref": 3.0511,
            "grammar_hyp": 2.41824,
            "nubia_score": 0.52134
        },
        "meteor": 0.2787979724840176,
        "bleurt": 0.05277,
        "bertscore": {
            "precision": 0.90422,
            "recall": 0.90079,
            "f1": 0.9025
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1310": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.2776134368191165,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.548645758111165,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "rouge2": {
            "precision": 0.88889,
            "recall": 0.8,
            "fmeasure": 0.84211
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "nubia": {
            "semantic_relation": 4.65439,
            "contradiction": 0.55881,
            "irrelevancy": 1.76619,
            "logical_agreement": 97.675,
            "grammar_ref": 4.67316,
            "grammar_hyp": 4.54703,
            "nubia_score": 0.85279
        },
        "meteor": 0.5161210442123606,
        "bleurt": 0.7198,
        "bertscore": {
            "precision": 0.98951,
            "recall": 0.9715,
            "f1": 0.98042
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1168": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.7727272727272727,
        "vocab_size-1": 17,
        "unique-1": 12,
        "entropy-1": 4.004886164091841,
        "distinct-2": 0.9047619047619048,
        "vocab_size-2": 19,
        "unique-2": 17,
        "entropy-2": 4.201841232302569,
        "cond_entropy-2": 0.21860008985574894,
        "distinct-3": 0.95,
        "vocab_size-3": 19,
        "unique-3": 18,
        "entropy-3": 4.221928094887362,
        "cond_entropy-3": 0.02961067210860201,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7647058823529411,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.6168746059562227,
        "distinct-2-nopunct": 0.875,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.75,
        "cond_entropy-2-nopunct": 0.1000371587496606,
        "distinct-3-nopunct": 0.9333333333333333,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7735572622751845,
        "cond_entropy-3-nopunct": 0.040223928941851894,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.4444444444444444
        },
        "nist": 1.439806163001984,
        "bleu": 9.38765,
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.37037,
            "fmeasure": 0.44444
        },
        "rouge2": {
            "precision": 0.23529,
            "recall": 0.15385,
            "fmeasure": 0.18605
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.37037,
            "fmeasure": 0.44444
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.37037,
            "fmeasure": 0.44444
        },
        "nubia": {
            "semantic_relation": 2.94597,
            "contradiction": 94.25505,
            "irrelevancy": 1.86146,
            "logical_agreement": 3.88349,
            "grammar_ref": 4.95946,
            "grammar_hyp": 5.64502,
            "nubia_score": 0.26037
        },
        "meteor": 0.20462421934021977,
        "bleurt": -0.1904,
        "bertscore": {
            "precision": 0.89927,
            "recall": 0.86543,
            "f1": 0.88203
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_888": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 54,
        "mean_pred_length": 13.5,
        "std_pred_length": 4.716990566028302,
        "median_pred_length": 12.5,
        "min_pred_length": 8,
        "max_pred_length": 21,
        "distinct-1": 0.7407407407407407,
        "vocab_size-1": 40,
        "unique-1": 34,
        "entropy-1": 5.0436583918566775,
        "distinct-2": 1.0,
        "vocab_size-2": 50,
        "unique-2": 50,
        "entropy-2": 5.643856189774728,
        "cond_entropy-2": 0.4970961267425906,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 11.75,
        "std_pred_length-nopunct": 3.5619517121937516,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7659574468085106,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 4.907644767495368,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.426264754702098,
        "cond_entropy-2-nopunct": 0.5788008322469421,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": -0.14086253583984967,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5909090909090909,
            "3": 0.3783783783783784
        },
        "nist": 2.583558983199953,
        "bleu": 26.41134,
        "rouge1": {
            "precision": 0.67227,
            "recall": 0.50176,
            "fmeasure": 0.55312
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.33826,
            "fmeasure": 0.35465
        },
        "rougeL": {
            "precision": 0.52649,
            "recall": 0.42764,
            "fmeasure": 0.45728
        },
        "rougeLsum": {
            "precision": 0.52649,
            "recall": 0.42764,
            "fmeasure": 0.45728
        },
        "nubia": {
            "semantic_relation": 2.88608,
            "contradiction": 33.9064,
            "irrelevancy": 8.50458,
            "logical_agreement": 57.58902,
            "grammar_ref": 4.12218,
            "grammar_hyp": 3.43003,
            "nubia_score": 0.45563
        },
        "meteor": 0.2514602457153866,
        "bleurt": 0.073,
        "bertscore": {
            "precision": 0.88345,
            "recall": 0.85404,
            "f1": 0.86703
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_675": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.27630381192071,
        "bleu": 64.00572,
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.76923,
            "fmeasure": 0.76923
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.63333,
            "fmeasure": 0.59091
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.75058,
            "fmeasure": 0.70513
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.75058,
            "fmeasure": 0.70513
        },
        "nubia": {
            "semantic_relation": 4.80973,
            "contradiction": 0.62133,
            "irrelevancy": 38.0045,
            "logical_agreement": 61.37417,
            "grammar_ref": 4.43463,
            "grammar_hyp": 4.76683,
            "nubia_score": 0.85605
        },
        "meteor": 0.5205559484776897,
        "bleurt": 0.21352,
        "bertscore": {
            "precision": 0.928,
            "recall": 0.96387,
            "f1": 0.94559
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_931": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.11768784439846629,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.02961067210860201,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.875
        },
        "nist": 1.9748374269254563,
        "bleu": 10.08685,
        "rouge1": {
            "precision": 0.40476,
            "recall": 0.73462,
            "fmeasure": 0.51992
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.375,
            "fmeasure": 0.2597
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.58462,
            "fmeasure": 0.42315
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.58462,
            "fmeasure": 0.42315
        },
        "nubia": {
            "semantic_relation": 2.87086,
            "contradiction": 0.99186,
            "irrelevancy": 98.35344,
            "logical_agreement": 0.6547,
            "grammar_ref": 4.19915,
            "grammar_hyp": 4.65534,
            "nubia_score": 0.24779
        },
        "meteor": 0.29813660150472904,
        "bleurt": -0.83765,
        "bertscore": {
            "precision": 0.82889,
            "recall": 0.87316,
            "f1": 0.85045
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1170": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.625
        },
        "nist": 1.353289509199005,
        "bleu": 42.13953,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.5641,
            "fmeasure": 0.675
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.41667,
            "fmeasure": 0.50794
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.5641,
            "fmeasure": 0.675
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.5641,
            "fmeasure": 0.675
        },
        "nubia": {
            "semantic_relation": 3.58413,
            "contradiction": 0.90915,
            "irrelevancy": 0.77982,
            "logical_agreement": 98.31103,
            "grammar_ref": 4.45494,
            "grammar_hyp": 5.04864,
            "nubia_score": 0.50694
        },
        "meteor": 0.2969362339094229,
        "bleurt": 0.02674,
        "bertscore": {
            "precision": 0.95405,
            "recall": 0.92629,
            "f1": 0.93996
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_429": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 2.0548046676563256,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 16,
        "distinct-1": 0.8,
        "vocab_size-1": 32,
        "unique-1": 28,
        "entropy-1": 4.8341837197791895,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.2863060140433026,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.12199052437861026,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 1.632993161855452,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.760067015271103,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.3215869210120033,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.13750352374993471,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7,
            "2": 0.5,
            "3": 0.8181818181818182
        },
        "nist": 4.064378892982646,
        "bleu": 35.50891,
        "rouge1": {
            "precision": 0.73651,
            "recall": 0.78962,
            "fmeasure": 0.7562
        },
        "rouge2": {
            "precision": 0.41453,
            "recall": 0.44444,
            "fmeasure": 0.42561
        },
        "rougeL": {
            "precision": 0.50562,
            "recall": 0.54469,
            "fmeasure": 0.51973
        },
        "rougeLsum": {
            "precision": 0.50562,
            "recall": 0.54469,
            "fmeasure": 0.51973
        },
        "nubia": {
            "semantic_relation": 4.46538,
            "contradiction": 0.3845,
            "irrelevancy": 39.54466,
            "logical_agreement": 60.07083,
            "grammar_ref": 5.1114,
            "grammar_hyp": 4.69428,
            "nubia_score": 0.79779
        },
        "meteor": 0.39618991657696506,
        "bleurt": 0.25224,
        "bertscore": {
            "precision": 0.93789,
            "recall": 0.94072,
            "f1": 0.9393
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_678": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0
        },
        "nist": 3.898626692302749,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.9,
            "fmeasure": 0.92105
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.371,
            "irrelevancy": 0.46802,
            "logical_agreement": 99.16099,
            "grammar_ref": 5.30755,
            "grammar_hyp": 5.2666,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.90186,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1020": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.0,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 18,
        "distinct-1": 0.8214285714285714,
        "vocab_size-1": 23,
        "unique-1": 18,
        "entropy-1": 4.450212064914748,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.2007771037757955,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.251629167387823,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.23810548155250444,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.7272727272727273,
            "3": 0.8181818181818182
        },
        "nist": 4.088050360275576,
        "bleu": 56.06671,
        "rouge1": {
            "precision": 0.72801,
            "recall": 0.66468,
            "fmeasure": 0.67361
        },
        "rouge2": {
            "precision": 0.58611,
            "recall": 0.51694,
            "fmeasure": 0.52698
        },
        "rougeL": {
            "precision": 0.68634,
            "recall": 0.625,
            "fmeasure": 0.63337
        },
        "rougeLsum": {
            "precision": 0.68634,
            "recall": 0.625,
            "fmeasure": 0.63337
        },
        "nubia": {
            "semantic_relation": 3.96781,
            "contradiction": 4.41412,
            "irrelevancy": 32.62184,
            "logical_agreement": 62.96404,
            "grammar_ref": 4.3679,
            "grammar_hyp": 3.98738,
            "nubia_score": 0.71847
        },
        "meteor": 0.34740764736901036,
        "bleurt": 0.18667,
        "bertscore": {
            "precision": 0.94167,
            "recall": 0.93663,
            "f1": 0.93207
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1022": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.375
        },
        "nist": 1.2501570421932473,
        "bleu": 3.9538,
        "rouge1": {
            "precision": 0.30769,
            "recall": 0.44444,
            "fmeasure": 0.36364
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.15385,
            "recall": 0.22222,
            "fmeasure": 0.18182
        },
        "rougeLsum": {
            "precision": 0.15385,
            "recall": 0.22222,
            "fmeasure": 0.18182
        },
        "nubia": {
            "semantic_relation": 3.09008,
            "contradiction": 12.60533,
            "irrelevancy": 71.53211,
            "logical_agreement": 15.86255,
            "grammar_ref": 5.49813,
            "grammar_hyp": 6.27577,
            "nubia_score": 0.27784
        },
        "meteor": 0.13533834586466165,
        "bleurt": -0.0014,
        "bertscore": {
            "precision": 0.83002,
            "recall": 0.83552,
            "f1": 0.83276
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_889": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0,
            "3": 0.3333333333333333
        },
        "nist": 1.6279181227895325,
        "bleu": 3.94384,
        "rouge1": {
            "precision": 0.27273,
            "recall": 0.42857,
            "fmeasure": 0.33333
        },
        "rouge2": {
            "precision": 0.1,
            "recall": 0.16667,
            "fmeasure": 0.125
        },
        "rougeL": {
            "precision": 0.27273,
            "recall": 0.42857,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.27273,
            "recall": 0.42857,
            "fmeasure": 0.33333
        },
        "nubia": {
            "semantic_relation": 0.94629,
            "contradiction": 33.42707,
            "irrelevancy": 66.24642,
            "logical_agreement": 0.32652,
            "grammar_ref": 4.92688,
            "grammar_hyp": 4.26696,
            "nubia_score": 0.07433
        },
        "meteor": 0.1997310199604772,
        "bleurt": -0.79707,
        "bertscore": {
            "precision": 0.82104,
            "recall": 0.82493,
            "f1": 0.79827
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1172": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "nist": 1.9616316503469575,
        "bleu": 48.8923,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.72222,
            "fmeasure": 0.76389
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.43704,
            "fmeasure": 0.44762
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.72222,
            "fmeasure": 0.76389
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.72222,
            "fmeasure": 0.76389
        },
        "nubia": {
            "semantic_relation": 4.1499,
            "contradiction": 10.6602,
            "irrelevancy": 8.30309,
            "logical_agreement": 81.0367,
            "grammar_ref": 7.45181,
            "grammar_hyp": 7.75689,
            "nubia_score": 0.64551
        },
        "meteor": 0.9866666666666668,
        "bleurt": 0.16823,
        "bertscore": {
            "precision": 0.97746,
            "recall": 0.97746,
            "f1": 0.97746
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_936": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.186704345910023,
        "distinct-2": 0.95,
        "vocab_size-2": 19,
        "unique-2": 18,
        "entropy-2": 4.221928094887362,
        "cond_entropy-2": -0.037503523749935014,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.04089198233393866,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.03740119765411,
        "distinct-2-nopunct": 0.9411764705882353,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.969815782426811,
        "cond_entropy-2-nopunct": -0.04281761336971672,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.0472389123084875,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.06666666666666667,
            "2": 0.3333333333333333,
            "3": 0.5769230769230769
        },
        "nist": 1.1687342404589263,
        "bleu": 45.42774,
        "rouge1": {
            "precision": 0.87879,
            "recall": 0.68021,
            "fmeasure": 0.74181
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.59487,
            "fmeasure": 0.62799
        },
        "rougeL": {
            "precision": 0.77273,
            "recall": 0.63571,
            "fmeasure": 0.68031
        },
        "rougeLsum": {
            "precision": 0.77273,
            "recall": 0.63571,
            "fmeasure": 0.68031
        },
        "nubia": {
            "semantic_relation": 3.90868,
            "contradiction": 32.5794,
            "irrelevancy": 13.2178,
            "logical_agreement": 54.2028,
            "grammar_ref": 4.54027,
            "grammar_hyp": 4.57142,
            "nubia_score": 0.60328
        },
        "meteor": 0.3417132168375659,
        "bleurt": 0.29406,
        "bertscore": {
            "precision": 0.95368,
            "recall": 0.91313,
            "f1": 0.9286
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_890": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.5714285714285714
        },
        "nist": 1.717973844867594,
        "bleu": 16.59039,
        "rouge1": {
            "precision": 0.54167,
            "recall": 0.76389,
            "fmeasure": 0.63333
        },
        "rouge2": {
            "precision": 0.31818,
            "recall": 0.46429,
            "fmeasure": 0.37719
        },
        "rougeL": {
            "precision": 0.54167,
            "recall": 0.76389,
            "fmeasure": 0.63333
        },
        "rougeLsum": {
            "precision": 0.54167,
            "recall": 0.76389,
            "fmeasure": 0.63333
        },
        "nubia": {
            "semantic_relation": 4.50583,
            "contradiction": 2.39631,
            "irrelevancy": 6.70886,
            "logical_agreement": 90.89484,
            "grammar_ref": 4.73918,
            "grammar_hyp": 3.96084,
            "nubia_score": 0.82769
        },
        "meteor": 0.35661278140771957,
        "bleurt": 0.55531,
        "bertscore": {
            "precision": 0.86779,
            "recall": 0.89538,
            "f1": 0.88007
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1174": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 3.0,
        "median_pred_length": 10.0,
        "min_pred_length": 7,
        "max_pred_length": 13,
        "distinct-1": 0.75,
        "vocab_size-1": 15,
        "unique-1": 10,
        "entropy-1": 3.821928094887362,
        "distinct-2": 0.8333333333333334,
        "vocab_size-2": 15,
        "unique-2": 12,
        "entropy-2": 3.8365916681089787,
        "cond_entropy-2": -0.04089198233393866,
        "distinct-3": 0.875,
        "vocab_size-3": 14,
        "unique-3": 12,
        "entropy-3": 3.75,
        "cond_entropy-3": -0.04492500144231237,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.7254805569978675,
        "distinct-2-nopunct": 0.8125,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.625,
        "cond_entropy-2-nopunct": -0.10742500144231237,
        "distinct-3-nopunct": 0.8571428571428571,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.521640636343319,
        "cond_entropy-3-nopunct": -0.12121650651382439,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9375
        },
        "nist": 3.980352302429953,
        "bleu": 80.17494,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.93452,
            "fmeasure": 0.92718
        },
        "rouge2": {
            "precision": 0.84167,
            "recall": 0.85354,
            "fmeasure": 0.84585
        },
        "rougeL": {
            "precision": 0.92308,
            "recall": 0.93452,
            "fmeasure": 0.92718
        },
        "rougeLsum": {
            "precision": 0.92308,
            "recall": 0.93452,
            "fmeasure": 0.92718
        },
        "nubia": {
            "semantic_relation": 4.93787,
            "contradiction": 0.82427,
            "irrelevancy": 0.91292,
            "logical_agreement": 98.26281,
            "grammar_ref": 4.94813,
            "grammar_hyp": 5.10466,
            "nubia_score": 0.9183
        },
        "meteor": 0.5859552163896863,
        "bleurt": 0.80221,
        "bertscore": {
            "precision": 0.98723,
            "recall": 0.99228,
            "f1": 0.98974
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_895": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 11.0,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.631578947368421,
        "vocab_size-1": 24,
        "unique-1": 20,
        "entropy-1": 4.144871014472701,
        "distinct-2": 0.8611111111111112,
        "vocab_size-2": 31,
        "unique-2": 30,
        "entropy-2": 4.739097917988784,
        "cond_entropy-2": 0.5999522645700237,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": 0.37370769287646655,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 8.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7333333333333333,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.093344863722963,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.6718577919672675,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5333333333333333,
            "3": 1.0
        },
        "nist": 1.9432603360860337,
        "bleu": 9.31378,
        "rouge1": {
            "precision": 0.5528,
            "recall": 0.59631,
            "fmeasure": 0.5674
        },
        "rouge2": {
            "precision": 0.31818,
            "recall": 0.32328,
            "fmeasure": 0.3171
        },
        "rougeL": {
            "precision": 0.53106,
            "recall": 0.5668,
            "fmeasure": 0.54239
        },
        "rougeLsum": {
            "precision": 0.53106,
            "recall": 0.5668,
            "fmeasure": 0.54239
        },
        "nubia": {
            "semantic_relation": 3.71449,
            "contradiction": 7.29967,
            "irrelevancy": 33.99536,
            "logical_agreement": 58.70497,
            "grammar_ref": 4.46901,
            "grammar_hyp": 3.93769,
            "nubia_score": 0.69549
        },
        "meteor": 0.2923761680502355,
        "bleurt": 0.35873,
        "bertscore": {
            "precision": 0.90176,
            "recall": 0.92171,
            "f1": 0.9115
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_430": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 8,
        "total_length": 116,
        "mean_pred_length": 14.5,
        "std_pred_length": 3.7416573867739413,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.7155172413793104,
        "vocab_size-1": 83,
        "unique-1": 64,
        "entropy-1": 6.144438754324396,
        "distinct-2": 0.9259259259259259,
        "vocab_size-2": 100,
        "unique-2": 92,
        "entropy-2": 6.60673935401531,
        "cond_entropy-2": 0.31169805688660385,
        "distinct-3": 0.97,
        "vocab_size-3": 97,
        "unique-3": 94,
        "entropy-3": 6.583856189774739,
        "cond_entropy-3": -0.011031312388743978,
        "total_length-nopunct": 103,
        "mean_pred_length-nopunct": 12.875,
        "std_pred_length-nopunct": 3.018174116912409,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7766990291262136,
        "vocab_size-1-nopunct": 80,
        "unique-1-nopunct": 63,
        "entropy-1-nopunct": 6.186405624228602,
        "distinct-2-nopunct": 0.9157894736842105,
        "vocab_size-2-nopunct": 87,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.401434555699369,
        "cond_entropy-2-nopunct": 0.25714218645643405,
        "distinct-3-nopunct": 0.9655172413793104,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 81,
        "entropy-3-nopunct": 6.373977978607344,
        "cond_entropy-3-nopunct": -0.011969583746587496,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.2,
            "3": 0.8584905660377359
        },
        "nist": 5.98220581531433,
        "bleu": 66.73392,
        "rouge1": {
            "precision": 0.92213,
            "recall": 0.87299,
            "fmeasure": 0.88776
        },
        "rouge2": {
            "precision": 0.82499,
            "recall": 0.7886,
            "fmeasure": 0.79798
        },
        "rougeL": {
            "precision": 0.87081,
            "recall": 0.83119,
            "fmeasure": 0.84279
        },
        "rougeLsum": {
            "precision": 0.87081,
            "recall": 0.83119,
            "fmeasure": 0.84279
        },
        "nubia": {
            "semantic_relation": 4.46943,
            "contradiction": 1.77439,
            "irrelevancy": 7.25701,
            "logical_agreement": 90.9686,
            "grammar_ref": 5.14689,
            "grammar_hyp": 4.94644,
            "nubia_score": 0.81594
        },
        "meteor": 0.48128246671164765,
        "bleurt": 0.54493,
        "bertscore": {
            "precision": 0.96815,
            "recall": 0.95143,
            "f1": 0.95886
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1315": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432272,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "nist": 2.267137506299753,
        "bleu": 10.32038,
        "rouge1": {
            "precision": 0.51515,
            "recall": 0.80556,
            "fmeasure": 0.61552
        },
        "rouge2": {
            "precision": 0.26667,
            "recall": 0.46061,
            "fmeasure": 0.33016
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.55556,
            "fmeasure": 0.42967
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.55556,
            "fmeasure": 0.42967
        },
        "nubia": {
            "semantic_relation": 4.39257,
            "contradiction": 6.35028,
            "irrelevancy": 70.00683,
            "logical_agreement": 23.6429,
            "grammar_ref": 5.75818,
            "grammar_hyp": 4.64809,
            "nubia_score": 0.79049
        },
        "meteor": 0.41759659784253267,
        "bleurt": 0.0442,
        "bertscore": {
            "precision": 0.8345,
            "recall": 0.88436,
            "f1": 0.84575
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1176": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.186704345910023,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.1219280948873624,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0,
            "3": 0.8
        },
        "nist": 3.4442803468328713,
        "bleu": 56.23413,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.73333,
            "fmeasure": 0.69398
        },
        "rouge2": {
            "precision": 0.51852,
            "recall": 0.56296,
            "fmeasure": 0.53439
        },
        "rougeL": {
            "precision": 0.63333,
            "recall": 0.73333,
            "fmeasure": 0.67083
        },
        "rougeLsum": {
            "precision": 0.63333,
            "recall": 0.73333,
            "fmeasure": 0.67083
        },
        "nubia": {
            "semantic_relation": 4.05075,
            "contradiction": 0.53974,
            "irrelevancy": 46.87378,
            "logical_agreement": 52.58648,
            "grammar_ref": 5.47595,
            "grammar_hyp": 5.12186,
            "nubia_score": 0.69526
        },
        "meteor": 0.4237643662078615,
        "bleurt": 0.24072,
        "bertscore": {
            "precision": 0.92145,
            "recall": 0.93219,
            "f1": 0.92675
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_938": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 28,
        "mean_pred_length": 28.0,
        "std_pred_length": 0.0,
        "median_pred_length": 28.0,
        "min_pred_length": 28,
        "max_pred_length": 28,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 24,
        "unique-1": 21,
        "entropy-1": 4.49468036840891,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.2717876727785855,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.05444778402237652,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.88,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.373660689688184,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.22255995686990965,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.061400544664143256,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7916666666666666
        },
        "nist": 3.9415303043683587,
        "bleu": 55.23712,
        "rouge1": {
            "precision": 0.84,
            "recall": 0.80769,
            "fmeasure": 0.82353
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.64,
            "fmeasure": 0.65306
        },
        "rougeL": {
            "precision": 0.76,
            "recall": 0.73077,
            "fmeasure": 0.7451
        },
        "rougeLsum": {
            "precision": 0.76,
            "recall": 0.73077,
            "fmeasure": 0.7451
        },
        "nubia": {
            "semantic_relation": 3.82283,
            "contradiction": 11.33255,
            "irrelevancy": 2.64893,
            "logical_agreement": 86.01852,
            "grammar_ref": 4.59074,
            "grammar_hyp": 4.36523,
            "nubia_score": 0.61201
        },
        "meteor": 0.43186208334523635,
        "bleurt": 0.30068,
        "bertscore": {
            "precision": 0.94618,
            "recall": 0.93841,
            "f1": 0.94228
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_432": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 87,
        "mean_pred_length": 17.4,
        "std_pred_length": 7.964923100695951,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.7471264367816092,
        "vocab_size-1": 65,
        "unique-1": 53,
        "entropy-1": 5.8105348750596,
        "distinct-2": 1.0,
        "vocab_size-2": 82,
        "unique-2": 82,
        "entropy-2": 6.357552004618087,
        "cond_entropy-2": 0.4880176552163541,
        "distinct-3": 1.0,
        "vocab_size-3": 77,
        "unique-3": 77,
        "entropy-3": 6.266786540694905,
        "cond_entropy-3": -0.09076546392318265,
        "total_length-nopunct": 73,
        "mean_pred_length-nopunct": 14.6,
        "std_pred_length-nopunct": 6.651315659326356,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8082191780821918,
        "vocab_size-1-nopunct": 59,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.703389284848148,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 68,
        "unique-2-nopunct": 68,
        "entropy-2-nopunct": 6.087462841250345,
        "cond_entropy-2-nopunct": 0.4198408559633654,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 63,
        "unique-3-nopunct": 63,
        "entropy-3-nopunct": 5.97727992349992,
        "cond_entropy-3-nopunct": -0.11018291775042297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.125,
            "3": 0.6623376623376623
        },
        "nist": 3.911336161331239,
        "bleu": 41.48824,
        "rouge1": {
            "precision": 0.80462,
            "recall": 0.68572,
            "fmeasure": 0.73699
        },
        "rouge2": {
            "precision": 0.62141,
            "recall": 0.52873,
            "fmeasure": 0.56814
        },
        "rougeL": {
            "precision": 0.72188,
            "recall": 0.61424,
            "fmeasure": 0.66052
        },
        "rougeLsum": {
            "precision": 0.72188,
            "recall": 0.61424,
            "fmeasure": 0.66052
        },
        "nubia": {
            "semantic_relation": 4.32452,
            "contradiction": 2.89821,
            "irrelevancy": 25.63186,
            "logical_agreement": 71.46993,
            "grammar_ref": 4.65184,
            "grammar_hyp": 5.10232,
            "nubia_score": 0.70801
        },
        "meteor": 0.3581511730974653,
        "bleurt": 0.40745,
        "bertscore": {
            "precision": 0.95057,
            "recall": 0.92693,
            "f1": 0.93824
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_434": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 3.5,
        "median_pred_length": 17.5,
        "min_pred_length": 14,
        "max_pred_length": 21,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 25,
        "unique-1": 18,
        "entropy-1": 4.479143374026008,
        "distinct-2": 0.9393939393939394,
        "vocab_size-2": 31,
        "unique-2": 29,
        "entropy-2": 4.923181998146335,
        "cond_entropy-2": 0.4228349661154101,
        "distinct-3": 0.967741935483871,
        "vocab_size-3": 30,
        "unique-3": 29,
        "entropy-3": 4.889680181354619,
        "cond_entropy-3": -0.025681679939320114,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7931034482758621,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.418157288156418,
        "distinct-2-nopunct": 0.9629629629629629,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.6808134280893965,
        "cond_entropy-2-nopunct": 0.2952356737826916,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.03103131238874398,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666,
            "3": 0.6875
        },
        "nist": 3.7308100270185536,
        "bleu": 39.99374,
        "rouge1": {
            "precision": 0.58824,
            "recall": 0.66667,
            "fmeasure": 0.62084
        },
        "rouge2": {
            "precision": 0.40341,
            "recall": 0.45183,
            "fmeasure": 0.41703
        },
        "rougeL": {
            "precision": 0.57435,
            "recall": 0.62958,
            "fmeasure": 0.5943
        },
        "rougeLsum": {
            "precision": 0.57435,
            "recall": 0.62958,
            "fmeasure": 0.5943
        },
        "nubia": {
            "semantic_relation": 2.48751,
            "contradiction": 78.61034,
            "irrelevancy": 21.08,
            "logical_agreement": 0.30967,
            "grammar_ref": 4.76014,
            "grammar_hyp": 4.53045,
            "nubia_score": 0.27745
        },
        "meteor": 0.3542882422330313,
        "bleurt": -0.4727,
        "bertscore": {
            "precision": 0.88979,
            "recall": 0.87409,
            "f1": 0.88118
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_940": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.029610672108601997,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.03310859910983796,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.14285714285714285,
            "3": 1.0
        },
        "nist": 2.756823681310266,
        "bleu": 12.26456,
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.69975,
            "fmeasure": 0.61925
        },
        "rouge2": {
            "precision": 0.28333,
            "recall": 0.37083,
            "fmeasure": 0.32116
        },
        "rougeL": {
            "precision": 0.4127,
            "recall": 0.49329,
            "fmeasure": 0.44912
        },
        "rougeLsum": {
            "precision": 0.4127,
            "recall": 0.49329,
            "fmeasure": 0.44912
        },
        "nubia": {
            "semantic_relation": 2.94339,
            "contradiction": 1.73624,
            "irrelevancy": 84.61515,
            "logical_agreement": 13.64861,
            "grammar_ref": 3.5564,
            "grammar_hyp": 3.5456,
            "nubia_score": 0.44592
        },
        "meteor": 0.36322455560088057,
        "bleurt": -0.08979,
        "bertscore": {
            "precision": 0.85621,
            "recall": 0.89339,
            "f1": 0.8744
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1320": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717246,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.05263157894736842,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 1.637390128310375,
        "bleu": 46.7138,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.66026,
            "fmeasure": 0.68599
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.42063,
            "fmeasure": 0.44246
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.52564,
            "fmeasure": 0.55395
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.52564,
            "fmeasure": 0.55395
        },
        "nubia": {
            "semantic_relation": 4.23567,
            "contradiction": 0.3575,
            "irrelevancy": 61.68704,
            "logical_agreement": 37.95546,
            "grammar_ref": 4.62626,
            "grammar_hyp": 4.09683,
            "nubia_score": 0.78234
        },
        "meteor": 0.38044486355760443,
        "bleurt": -0.07235,
        "bertscore": {
            "precision": 0.94468,
            "recall": 0.92087,
            "f1": 0.92348
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_805": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.4,
            "3": 0.8571428571428571
        },
        "nist": 3.6803124471772164,
        "bleu": 80.34284,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.80556,
            "fmeasure": 0.85
        },
        "rouge2": {
            "precision": 0.80952,
            "recall": 0.51515,
            "fmeasure": 0.62963
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.66667,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.66667,
            "fmeasure": 0.8
        },
        "nubia": {
            "semantic_relation": 4.3357,
            "contradiction": 0.20805,
            "irrelevancy": 1.7035,
            "logical_agreement": 98.08846,
            "grammar_ref": 5.08958,
            "grammar_hyp": 5.60434,
            "nubia_score": 0.72586
        },
        "meteor": 0.37025361638847254,
        "bleurt": 0.27536,
        "bertscore": {
            "precision": 0.95409,
            "recall": 0.91438,
            "f1": 0.92651
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_808": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.17355726227518525,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6923076923076923
        },
        "nist": 3.0259269177086545,
        "bleu": 39.31752,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.62626,
            "fmeasure": 0.64063
        },
        "rouge2": {
            "precision": 0.48889,
            "recall": 0.45455,
            "fmeasure": 0.46598
        },
        "rougeL": {
            "precision": 0.64583,
            "recall": 0.61111,
            "fmeasure": 0.62309
        },
        "rougeLsum": {
            "precision": 0.64583,
            "recall": 0.61111,
            "fmeasure": 0.62309
        },
        "nubia": {
            "semantic_relation": 3.20308,
            "contradiction": 18.45192,
            "irrelevancy": 80.23237,
            "logical_agreement": 1.31571,
            "grammar_ref": 4.44297,
            "grammar_hyp": 4.65182,
            "nubia_score": 0.34876
        },
        "meteor": 0.34829234270838705,
        "bleurt": -0.13846,
        "bertscore": {
            "precision": 0.91161,
            "recall": 0.9299,
            "f1": 0.92062
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_680": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 6.5,
        "median_pred_length": 16.5,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 27,
        "unique-1": 23,
        "entropy-1": 4.620151695116031,
        "distinct-2": 0.967741935483871,
        "vocab_size-2": 30,
        "unique-2": 29,
        "entropy-2": 4.889680181354619,
        "cond_entropy-2": 0.2968989652219703,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.02724979801792366,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 7.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.5625,
        "distinct-2-nopunct": 0.9666666666666667,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.840223928941852,
        "cond_entropy-2-nopunct": 0.30689059560851856,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.028107102122342915,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 0.72
        },
        "nist": 4.096666176091259,
        "bleu": 46.27425,
        "rouge1": {
            "precision": 0.71739,
            "recall": 0.72619,
            "fmeasure": 0.70727
        },
        "rouge2": {
            "precision": 0.56061,
            "recall": 0.56834,
            "fmeasure": 0.55288
        },
        "rougeL": {
            "precision": 0.65942,
            "recall": 0.68978,
            "fmeasure": 0.66198
        },
        "rougeLsum": {
            "precision": 0.65942,
            "recall": 0.68978,
            "fmeasure": 0.66198
        },
        "nubia": {
            "semantic_relation": 4.33434,
            "contradiction": 0.24592,
            "irrelevancy": 55.96784,
            "logical_agreement": 43.78624,
            "grammar_ref": 5.14413,
            "grammar_hyp": 4.40072,
            "nubia_score": 0.84481
        },
        "meteor": 0.3649929598865587,
        "bleurt": 0.23628,
        "bertscore": {
            "precision": 0.94369,
            "recall": 0.91809,
            "f1": 0.93038
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_721": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.0,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.9583333333333334,
        "vocab_size-1": 23,
        "unique-1": 22,
        "entropy-1": 4.501629167387823,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.39231742277876,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.14438990933517493,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.8461538461538461,
            "3": 0.8888888888888888
        },
        "nist": 4.362733893725655,
        "bleu": 85.01485,
        "rouge1": {
            "precision": 0.95833,
            "recall": 0.85732,
            "fmeasure": 0.9032
        },
        "rouge2": {
            "precision": 0.81439,
            "recall": 0.72406,
            "fmeasure": 0.76453
        },
        "rougeL": {
            "precision": 0.93056,
            "recall": 0.83232,
            "fmeasure": 0.87688
        },
        "rougeLsum": {
            "precision": 0.93056,
            "recall": 0.83232,
            "fmeasure": 0.87688
        },
        "nubia": {
            "semantic_relation": 4.64029,
            "contradiction": 2.08086,
            "irrelevancy": 18.74545,
            "logical_agreement": 79.17369,
            "grammar_ref": 4.61516,
            "grammar_hyp": 4.68218,
            "nubia_score": 0.85129
        },
        "meteor": 0.531361466778432,
        "bleurt": 0.58533,
        "bertscore": {
            "precision": 0.99435,
            "recall": 0.97733,
            "f1": 0.98569
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_726": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 4.4969125210773475,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 22,
        "distinct-1": 0.9148936170212766,
        "vocab_size-1": 43,
        "unique-1": 40,
        "entropy-1": 5.368314649503949,
        "distinct-2": 1.0,
        "vocab_size-2": 44,
        "unique-2": 44,
        "entropy-2": 5.4594316186372955,
        "cond_entropy-2": -0.004248142131249445,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.10187961401921372,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.559026084010437,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9761904761904762,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.344698375159715,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.285402218862247,
        "cond_entropy-2-nopunct": -0.05563315263446056,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.1154772174199358,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.9130434782608695
        },
        "nist": 4.192097938694146,
        "bleu": 50.00157,
        "rouge1": {
            "precision": 0.83187,
            "recall": 0.81489,
            "fmeasure": 0.80352
        },
        "rouge2": {
            "precision": 0.64478,
            "recall": 0.64291,
            "fmeasure": 0.62963
        },
        "rougeL": {
            "precision": 0.75146,
            "recall": 0.71983,
            "fmeasure": 0.71911
        },
        "rougeLsum": {
            "precision": 0.75146,
            "recall": 0.71983,
            "fmeasure": 0.71911
        },
        "nubia": {
            "semantic_relation": 4.04073,
            "contradiction": 7.0096,
            "irrelevancy": 59.59909,
            "logical_agreement": 33.39131,
            "grammar_ref": 4.8308,
            "grammar_hyp": 5.07597,
            "nubia_score": 0.6059
        },
        "meteor": 0.4529257500219591,
        "bleurt": 0.26849,
        "bertscore": {
            "precision": 0.92963,
            "recall": 0.94656,
            "f1": 0.9371
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1032": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.4
        },
        "nist": 1.780527301227646,
        "bleu": 13.91231,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.36364,
            "fmeasure": 0.34783
        },
        "rouge2": {
            "precision": 0.18182,
            "recall": 0.2,
            "fmeasure": 0.19048
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.27273,
            "fmeasure": 0.26087
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.27273,
            "fmeasure": 0.26087
        },
        "nubia": {
            "semantic_relation": 1.76361,
            "contradiction": 92.01455,
            "irrelevancy": 6.68981,
            "logical_agreement": 1.29564,
            "grammar_ref": 4.59968,
            "grammar_hyp": 4.94842,
            "nubia_score": 0.11353
        },
        "meteor": 0.18951086543033585,
        "bleurt": -1.01744,
        "bertscore": {
            "precision": 0.79943,
            "recall": 0.79445,
            "f1": 0.79111
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_810": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 0.5,
        "median_pred_length": 18.5,
        "min_pred_length": 18,
        "max_pred_length": 19,
        "distinct-1": 0.7837837837837838,
        "vocab_size-1": 29,
        "unique-1": 25,
        "entropy-1": 4.6590607176127286,
        "distinct-2": 0.9714285714285714,
        "vocab_size-2": 34,
        "unique-2": 33,
        "entropy-2": 5.072140159802107,
        "cond_entropy-2": 0.38738759350459606,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.02428283698045264,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7941176470588235,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.547329665467977,
        "distinct-2-nopunct": 0.96875,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.9375,
        "cond_entropy-2-nopunct": 0.42392865801841945,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.026442737724814768,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.8095238095238095
        },
        "nist": 3.5648999648779727,
        "bleu": 53.61146,
        "rouge1": {
            "precision": 0.68519,
            "recall": 0.8632,
            "fmeasure": 0.7483
        },
        "rouge2": {
            "precision": 0.57617,
            "recall": 0.60317,
            "fmeasure": 0.5684
        },
        "rougeL": {
            "precision": 0.68519,
            "recall": 0.8632,
            "fmeasure": 0.7483
        },
        "rougeLsum": {
            "precision": 0.68519,
            "recall": 0.8632,
            "fmeasure": 0.7483
        },
        "nubia": {
            "semantic_relation": 4.05547,
            "contradiction": 0.46138,
            "irrelevancy": 50.75731,
            "logical_agreement": 48.78131,
            "grammar_ref": 5.29605,
            "grammar_hyp": 4.42147,
            "nubia_score": 0.74342
        },
        "meteor": 0.48718716576728854,
        "bleurt": 0.07398,
        "bertscore": {
            "precision": 0.90643,
            "recall": 0.9465,
            "f1": 0.92532
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_728": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.625,
        "vocab_size-1": 15,
        "unique-1": 8,
        "entropy-1": 3.751629167387823,
        "distinct-2": 0.7272727272727273,
        "vocab_size-2": 16,
        "unique-2": 10,
        "entropy-2": 3.9139770731827506,
        "cond_entropy-2": 0.14719639064341358,
        "distinct-3": 0.75,
        "vocab_size-3": 15,
        "unique-3": 10,
        "entropy-3": 3.8219280948873626,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.6363636363636364,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.641249800455478,
        "distinct-2-nopunct": 0.7,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.7219280948873625,
        "cond_entropy-2-nopunct": 0.16249647625006497,
        "distinct-3-nopunct": 0.7222222222222222,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.6143694458867563,
        "cond_entropy-3-nopunct": -0.04089198233393865,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.6666666666666666,
            "3": 0.6666666666666666
        },
        "nist": 3.357046268735128,
        "bleu": 27.09199,
        "rouge1": {
            "precision": 0.59091,
            "recall": 0.64316,
            "fmeasure": 0.59797
        },
        "rouge2": {
            "precision": 0.35,
            "recall": 0.35505,
            "fmeasure": 0.34228
        },
        "rougeL": {
            "precision": 0.4697,
            "recall": 0.53846,
            "fmeasure": 0.48565
        },
        "rougeLsum": {
            "precision": 0.4697,
            "recall": 0.53846,
            "fmeasure": 0.48565
        },
        "nubia": {
            "semantic_relation": 3.64044,
            "contradiction": 0.19681,
            "irrelevancy": 65.91776,
            "logical_agreement": 33.88544,
            "grammar_ref": 5.09196,
            "grammar_hyp": 4.66319,
            "nubia_score": 0.61591
        },
        "meteor": 0.3788089831293786,
        "bleurt": -0.26244,
        "bertscore": {
            "precision": 0.86655,
            "recall": 0.89271,
            "f1": 0.87831
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_435": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 88,
        "mean_pred_length": 22.0,
        "std_pred_length": 4.415880433163924,
        "median_pred_length": 23.0,
        "min_pred_length": 15,
        "max_pred_length": 27,
        "distinct-1": 0.6818181818181818,
        "vocab_size-1": 60,
        "unique-1": 45,
        "entropy-1": 5.669841352099073,
        "distinct-2": 0.9642857142857143,
        "vocab_size-2": 81,
        "unique-2": 78,
        "entropy-2": 6.320888851350189,
        "cond_entropy-2": 0.6320412321557555,
        "distinct-3": 1.0,
        "vocab_size-3": 80,
        "unique-3": 80,
        "entropy-3": 6.321928094887356,
        "cond_entropy-3": 0.004610672108601989,
        "total_length-nopunct": 80,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 4.743416490252569,
        "median_pred_length-nopunct": 20.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.725,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.6579354014028125,
        "distinct-2-nopunct": 0.9736842105263158,
        "vocab_size-2-nopunct": 74,
        "unique-2-nopunct": 72,
        "entropy-2-nopunct": 6.195295934496223,
        "cond_entropy-2-nopunct": 0.5723075169610099,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 72,
        "unique-3-nopunct": 72,
        "entropy-3-nopunct": 6.1699250014423175,
        "cond_entropy-3-nopunct": -0.022446956445717602,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.6,
            "3": 0.7272727272727273
        },
        "nist": 3.6428566341283757,
        "bleu": 25.60513,
        "rouge1": {
            "precision": 0.60253,
            "recall": 0.66467,
            "fmeasure": 0.62965
        },
        "rouge2": {
            "precision": 0.34655,
            "recall": 0.38306,
            "fmeasure": 0.36254
        },
        "rougeL": {
            "precision": 0.4854,
            "recall": 0.52074,
            "fmeasure": 0.49958
        },
        "rougeLsum": {
            "precision": 0.4854,
            "recall": 0.52074,
            "fmeasure": 0.49958
        },
        "nubia": {
            "semantic_relation": 3.19073,
            "contradiction": 42.60317,
            "irrelevancy": 50.84481,
            "logical_agreement": 6.55202,
            "grammar_ref": 4.16687,
            "grammar_hyp": 4.56517,
            "nubia_score": 0.52424
        },
        "meteor": 0.3112046447741091,
        "bleurt": -0.13835,
        "bertscore": {
            "precision": 0.8636,
            "recall": 0.88157,
            "f1": 0.86995
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1036": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 2.5,
        "median_pred_length": 12.5,
        "min_pred_length": 10,
        "max_pred_length": 15,
        "distinct-1": 0.92,
        "vocab_size-1": 23,
        "unique-1": 22,
        "entropy-1": 4.453660689688184,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": -0.051382820642878885,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8947368421052632
        },
        "nist": 3.941506593645461,
        "bleu": 71.29276,
        "rouge1": {
            "precision": 0.87037,
            "recall": 0.82593,
            "fmeasure": 0.84259
        },
        "rouge2": {
            "precision": 0.72917,
            "recall": 0.70238,
            "fmeasure": 0.71212
        },
        "rougeL": {
            "precision": 0.75926,
            "recall": 0.72963,
            "fmeasure": 0.74074
        },
        "rougeLsum": {
            "precision": 0.75926,
            "recall": 0.72963,
            "fmeasure": 0.74074
        },
        "nubia": {
            "semantic_relation": 4.36634,
            "contradiction": 0.37159,
            "irrelevancy": 0.59003,
            "logical_agreement": 99.03839,
            "grammar_ref": 4.70186,
            "grammar_hyp": 5.14226,
            "nubia_score": 0.74643
        },
        "meteor": 0.494331701675106,
        "bleurt": 0.52796,
        "bertscore": {
            "precision": 0.96812,
            "recall": 0.94619,
            "f1": 0.95344
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_812": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.098214829261011,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2797,
            "irrelevancy": 0.5863,
            "logical_agreement": 99.13399,
            "grammar_ref": 4.58246,
            "grammar_hyp": 4.67996,
            "nubia_score": 0.98883
        },
        "meteor": 1.0,
        "bleurt": 0.94053,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_896": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 8,
        "total_length": 121,
        "mean_pred_length": 15.125,
        "std_pred_length": 4.399928976699511,
        "median_pred_length": 14.5,
        "min_pred_length": 9,
        "max_pred_length": 22,
        "distinct-1": 0.5950413223140496,
        "vocab_size-1": 72,
        "unique-1": 47,
        "entropy-1": 5.834908563753349,
        "distinct-2": 0.831858407079646,
        "vocab_size-2": 94,
        "unique-2": 78,
        "entropy-2": 6.463854515455112,
        "cond_entropy-2": 0.5198453976147623,
        "distinct-3": 0.8952380952380953,
        "vocab_size-3": 94,
        "unique-3": 84,
        "entropy-3": 6.497532303359796,
        "cond_entropy-3": 0.04177869814928646,
        "total_length-nopunct": 109,
        "mean_pred_length-nopunct": 13.625,
        "std_pred_length-nopunct": 4.29934588047996,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6422018348623854,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.858473173436816,
        "distinct-2-nopunct": 0.8217821782178217,
        "vocab_size-2-nopunct": 83,
        "unique-2-nopunct": 68,
        "entropy-2-nopunct": 6.279353438133064,
        "cond_entropy-2-nopunct": 0.463233623218245,
        "distinct-3-nopunct": 0.8817204301075269,
        "vocab_size-3-nopunct": 82,
        "unique-3-nopunct": 72,
        "entropy-3-nopunct": 6.2944826014073545,
        "cond_entropy-3-nopunct": 0.036966414424268026,
        "msttr-100": 0.62,
        "msttr-100_nopunct": 0.68,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3076923076923077,
            "2": 0.5675675675675675,
            "3": 0.6575342465753424
        },
        "nist": 4.277845300347745,
        "bleu": 42.12189,
        "rouge1": {
            "precision": 0.74149,
            "recall": 0.61742,
            "fmeasure": 0.64881
        },
        "rouge2": {
            "precision": 0.53327,
            "recall": 0.46076,
            "fmeasure": 0.47451
        },
        "rougeL": {
            "precision": 0.62252,
            "recall": 0.54674,
            "fmeasure": 0.5619
        },
        "rougeLsum": {
            "precision": 0.62252,
            "recall": 0.54674,
            "fmeasure": 0.5619
        },
        "nubia": {
            "semantic_relation": 3.5999,
            "contradiction": 17.59674,
            "irrelevancy": 40.53496,
            "logical_agreement": 41.86829,
            "grammar_ref": 4.28101,
            "grammar_hyp": 4.30067,
            "nubia_score": 0.52532
        },
        "meteor": 0.3311120161278102,
        "bleurt": -0.05603,
        "bertscore": {
            "precision": 0.87383,
            "recall": 0.86503,
            "f1": 0.86613
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_436": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.01117167855772,
        "bleu": 100.0,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.86667,
            "fmeasure": 0.86667
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "nubia": {
            "semantic_relation": 4.66362,
            "contradiction": 2.49017,
            "irrelevancy": 1.24853,
            "logical_agreement": 96.2613,
            "grammar_ref": 6.06085,
            "grammar_hyp": 5.70692,
            "nubia_score": 0.90186
        },
        "meteor": 1.0,
        "bleurt": 0.77386,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_476": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 5.5,
        "median_pred_length": 17.5,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 30,
        "unique-1": 26,
        "entropy-1": 4.822000516883151,
        "distinct-2": 1.0,
        "vocab_size-2": 33,
        "unique-2": 33,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": 0.18041072369116756,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.09019780897157811,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.773557262275186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9629629629629629
        },
        "nist": 4.559085227900948,
        "bleu": 66.20326,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.95956,
            "fmeasure": 0.93697
        },
        "rouge2": {
            "precision": 0.79412,
            "recall": 0.8125,
            "fmeasure": 0.80303
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.85294,
            "fmeasure": 0.84286
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.85294,
            "fmeasure": 0.84286
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.31848,
            "irrelevancy": 0.55243,
            "logical_agreement": 99.12909,
            "grammar_ref": 5.04945,
            "grammar_hyp": 4.67156,
            "nubia_score": 1.0
        },
        "meteor": 0.5188269218464097,
        "bleurt": 0.7966,
        "bertscore": {
            "precision": 0.97954,
            "recall": 0.98544,
            "f1": 0.98247
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_815": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 0.5,
        "median_pred_length": 14.5,
        "min_pred_length": 14,
        "max_pred_length": 15,
        "distinct-1": 0.896551724137931,
        "vocab_size-1": 26,
        "unique-1": 23,
        "entropy-1": 4.651084443403434,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.045054655184044716,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.96,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.5638561897747225,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": -0.03333771197858132,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.25,
            "3": 0.8421052631578947
        },
        "nist": 3.7722198679045023,
        "bleu": 45.92071,
        "rouge1": {
            "precision": 0.7619,
            "recall": 0.8141,
            "fmeasure": 0.78701
        },
        "rouge2": {
            "precision": 0.55128,
            "recall": 0.59343,
            "fmeasure": 0.5715
        },
        "rougeL": {
            "precision": 0.54396,
            "recall": 0.58333,
            "fmeasure": 0.56291
        },
        "rougeLsum": {
            "precision": 0.54396,
            "recall": 0.58333,
            "fmeasure": 0.56291
        },
        "nubia": {
            "semantic_relation": 4.72333,
            "contradiction": 0.28444,
            "irrelevancy": 0.51783,
            "logical_agreement": 99.19773,
            "grammar_ref": 4.97173,
            "grammar_hyp": 4.61893,
            "nubia_score": 0.89046
        },
        "meteor": 0.4733424634507623,
        "bleurt": 0.52341,
        "bertscore": {
            "precision": 0.92994,
            "recall": 0.94583,
            "f1": 0.93779
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_900": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.0,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 20,
        "unique-1": 16,
        "entropy-1": 4.251629167387823,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.1471963906434136,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.106603137064473,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.17139956434903564,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0,
            "3": 0.8947368421052632
        },
        "nist": 4.731204208554486,
        "bleu": 68.98812,
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.96154,
            "fmeasure": 0.94394
        },
        "rouge2": {
            "precision": 0.82492,
            "recall": 0.85119,
            "fmeasure": 0.83429
        },
        "rougeL": {
            "precision": 0.93333,
            "recall": 0.96154,
            "fmeasure": 0.94394
        },
        "rougeLsum": {
            "precision": 0.93333,
            "recall": 0.96154,
            "fmeasure": 0.94394
        },
        "nubia": {
            "semantic_relation": 4.35851,
            "contradiction": 0.43944,
            "irrelevancy": 33.58722,
            "logical_agreement": 65.97334,
            "grammar_ref": 5.10267,
            "grammar_hyp": 4.8468,
            "nubia_score": 0.83574
        },
        "meteor": 0.5379150329353749,
        "bleurt": 0.59674,
        "bertscore": {
            "precision": 0.97481,
            "recall": 0.97724,
            "f1": 0.97595
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1043": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6
        },
        "nist": 2.2055847652448333,
        "bleu": 35.08365,
        "rouge1": {
            "precision": 0.46154,
            "recall": 0.5303,
            "fmeasure": 0.49333
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.33766,
            "fmeasure": 0.33445
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.46667,
            "fmeasure": 0.46286
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.46667,
            "fmeasure": 0.46286
        },
        "nubia": {
            "semantic_relation": 3.03002,
            "contradiction": 3.68755,
            "irrelevancy": 74.58448,
            "logical_agreement": 21.72796,
            "grammar_ref": 5.20931,
            "grammar_hyp": 5.15778,
            "nubia_score": 0.35377
        },
        "meteor": 0.2678332634847198,
        "bleurt": -0.51558,
        "bertscore": {
            "precision": 0.7962,
            "recall": 0.81247,
            "f1": 0.79788
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1330": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 8.5,
        "median_pred_length": 16.5,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.7878787878787878,
        "vocab_size-1": 26,
        "unique-1": 21,
        "entropy-1": 4.574400937409154,
        "distinct-2": 0.967741935483871,
        "vocab_size-2": 30,
        "unique-2": 29,
        "entropy-2": 4.889680181354619,
        "cond_entropy-2": 0.34560138471638757,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.027249798017923668,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 8.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7741935483870968,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.453880987666651,
        "distinct-2-nopunct": 0.9655172413793104,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.789015477886192,
        "cond_entropy-2-nopunct": 0.3696389952347294,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.02901941889002934,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5,
            "3": 0.7894736842105263
        },
        "nist": 3.506271399724286,
        "bleu": 14.62784,
        "rouge1": {
            "precision": 0.69643,
            "recall": 0.72727,
            "fmeasure": 0.7075
        },
        "rouge2": {
            "precision": 0.39251,
            "recall": 0.40065,
            "fmeasure": 0.39301
        },
        "rougeL": {
            "precision": 0.55754,
            "recall": 0.56892,
            "fmeasure": 0.55959
        },
        "rougeLsum": {
            "precision": 0.55754,
            "recall": 0.56892,
            "fmeasure": 0.55959
        },
        "nubia": {
            "semantic_relation": 4.18765,
            "contradiction": 0.72085,
            "irrelevancy": 37.29349,
            "logical_agreement": 61.98566,
            "grammar_ref": 6.00658,
            "grammar_hyp": 6.20754,
            "nubia_score": 0.73462
        },
        "meteor": 0.35522509175634526,
        "bleurt": -0.29817,
        "bertscore": {
            "precision": 0.89464,
            "recall": 0.8797,
            "f1": 0.88686
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_816": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 99,
        "mean_pred_length": 19.8,
        "std_pred_length": 7.35934779718964,
        "median_pred_length": 17.0,
        "min_pred_length": 12,
        "max_pred_length": 33,
        "distinct-1": 0.6565656565656566,
        "vocab_size-1": 65,
        "unique-1": 51,
        "entropy-1": 5.691034872710111,
        "distinct-2": 0.8829787234042553,
        "vocab_size-2": 83,
        "unique-2": 74,
        "entropy-2": 6.3044848622698915,
        "cond_entropy-2": 0.5782543378241359,
        "distinct-3": 0.9438202247191011,
        "vocab_size-3": 84,
        "unique-3": 79,
        "entropy-3": 6.3633738804046125,
        "cond_entropy-3": 0.05046789394411945,
        "total_length-nopunct": 78,
        "mean_pred_length-nopunct": 15.6,
        "std_pred_length-nopunct": 4.882622246293481,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7692307692307693,
        "vocab_size-1-nopunct": 60,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.697270129363187,
        "distinct-2-nopunct": 0.8904109589041096,
        "vocab_size-2-nopunct": 65,
        "unique-2-nopunct": 58,
        "entropy-2-nopunct": 5.960305552001076,
        "cond_entropy-2-nopunct": 0.2759211821926143,
        "distinct-3-nopunct": 0.9264705882352942,
        "vocab_size-3-nopunct": 63,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.940404017720932,
        "cond_entropy-3-nopunct": -0.017731019068450267,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.49019607843137253,
            "3": 0.8285714285714286
        },
        "nist": 4.255073405879328,
        "bleu": 43.24696,
        "rouge1": {
            "precision": 0.72349,
            "recall": 0.70791,
            "fmeasure": 0.69837
        },
        "rouge2": {
            "precision": 0.55157,
            "recall": 0.53626,
            "fmeasure": 0.52977
        },
        "rougeL": {
            "precision": 0.64127,
            "recall": 0.61306,
            "fmeasure": 0.61148
        },
        "rougeLsum": {
            "precision": 0.64127,
            "recall": 0.61306,
            "fmeasure": 0.61148
        },
        "nubia": {
            "semantic_relation": 3.76844,
            "contradiction": 16.93939,
            "irrelevancy": 30.87015,
            "logical_agreement": 52.19046,
            "grammar_ref": 4.74118,
            "grammar_hyp": 4.54032,
            "nubia_score": 0.62725
        },
        "meteor": 0.3888105586776836,
        "bleurt": 0.02138,
        "bertscore": {
            "precision": 0.92377,
            "recall": 0.91973,
            "f1": 0.91919
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1180": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 18,
        "mean_pred_length": 9.0,
        "std_pred_length": 1.0,
        "median_pred_length": 9.0,
        "min_pred_length": 8,
        "max_pred_length": 10,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.16992500144231232,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.19264507794239588,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.19264507794239588,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644807,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.47619047619047616
        },
        "nist": 2.0570004954511734,
        "bleu": 25.02032,
        "rouge1": {
            "precision": 0.5873,
            "recall": 0.41148,
            "fmeasure": 0.48337
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.20299,
            "fmeasure": 0.24603
        },
        "rougeL": {
            "precision": 0.5873,
            "recall": 0.41148,
            "fmeasure": 0.48337
        },
        "rougeLsum": {
            "precision": 0.5873,
            "recall": 0.41148,
            "fmeasure": 0.48337
        },
        "nubia": {
            "semantic_relation": 3.90396,
            "contradiction": 0.73527,
            "irrelevancy": 0.79681,
            "logical_agreement": 98.46792,
            "grammar_ref": 5.01983,
            "grammar_hyp": 6.06757,
            "nubia_score": 0.54498
        },
        "meteor": 0.264394661171643,
        "bleurt": 0.36291,
        "bertscore": {
            "precision": 0.94566,
            "recall": 0.89406,
            "f1": 0.91909
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_682": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "nist": 4.474416099899872,
        "bleu": 51.47302,
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.75556,
            "fmeasure": 0.75569
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.56614,
            "fmeasure": 0.56899
        },
        "rougeL": {
            "precision": 0.76923,
            "recall": 0.75556,
            "fmeasure": 0.75569
        },
        "rougeLsum": {
            "precision": 0.76923,
            "recall": 0.75556,
            "fmeasure": 0.75569
        },
        "nubia": {
            "semantic_relation": 4.58246,
            "contradiction": 0.86231,
            "irrelevancy": 56.25508,
            "logical_agreement": 42.88262,
            "grammar_ref": 4.75278,
            "grammar_hyp": 5.26027,
            "nubia_score": 0.74168
        },
        "meteor": 0.4748101853768951,
        "bleurt": 0.33863,
        "bertscore": {
            "precision": 0.96933,
            "recall": 0.95282,
            "f1": 0.95899
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1050": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9565217391304348,
        "vocab_size-1": 22,
        "unique-1": 21,
        "entropy-1": 4.436605434317882,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.026778753489375348,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.9565217391304348,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.436605434317882,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.026778753489375348,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.5,
            "3": 0.75
        },
        "nist": 1.0760229597015292,
        "bleu": 4.69944,
        "rouge1": {
            "precision": 0.26389,
            "recall": 0.58889,
            "fmeasure": 0.35043
        },
        "rouge2": {
            "precision": 0.11594,
            "recall": 0.27619,
            "fmeasure": 0.15573
        },
        "rougeL": {
            "precision": 0.19444,
            "recall": 0.82222,
            "fmeasure": 0.31418
        },
        "rougeLsum": {
            "precision": 0.19444,
            "recall": 0.82222,
            "fmeasure": 0.31418
        },
        "nubia": {
            "semantic_relation": 3.73597,
            "contradiction": 0.08168,
            "irrelevancy": 99.75537,
            "logical_agreement": 0.16295,
            "grammar_ref": 5.27628,
            "grammar_hyp": 3.99904,
            "nubia_score": 0.39954
        },
        "meteor": 0.2690351444652819,
        "bleurt": -0.38744,
        "bertscore": {
            "precision": 0.78871,
            "recall": 0.9429,
            "f1": 0.83431
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1055": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 2.8483609718589222,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.21732,
            "irrelevancy": 0.45505,
            "logical_agreement": 99.32763,
            "grammar_ref": 5.4078,
            "grammar_hyp": 5.46881,
            "nubia_score": 0.9943
        },
        "meteor": 1.0,
        "bleurt": 0.96931,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1182": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.5
        },
        "nist": 3.1268405918888638,
        "bleu": 47.4955,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.75556,
            "fmeasure": 0.85926
        },
        "rouge2": {
            "precision": 0.7619,
            "recall": 0.56566,
            "fmeasure": 0.64815
        },
        "rougeL": {
            "precision": 0.95833,
            "recall": 0.72778,
            "fmeasure": 0.82593
        },
        "rougeLsum": {
            "precision": 0.95833,
            "recall": 0.72778,
            "fmeasure": 0.82593
        },
        "nubia": {
            "semantic_relation": 4.55817,
            "contradiction": 0.15708,
            "irrelevancy": 0.46705,
            "logical_agreement": 99.37587,
            "grammar_ref": 4.40566,
            "grammar_hyp": 5.99736,
            "nubia_score": 0.75797
        },
        "meteor": 0.4660555812366501,
        "bleurt": 0.24671,
        "bertscore": {
            "precision": 0.92753,
            "recall": 0.90468,
            "f1": 0.91596
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_735": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.8695652173913043,
        "vocab_size-1": 20,
        "unique-1": 17,
        "entropy-1": 4.2626923908396215,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.20859693530755724,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.12961067210860203,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.8333333333333334,
            "3": 0.8
        },
        "nist": 3.1505247251195825,
        "bleu": 35.13875,
        "rouge1": {
            "precision": 0.57971,
            "recall": 0.81569,
            "fmeasure": 0.67719
        },
        "rouge2": {
            "precision": 0.27273,
            "recall": 0.41071,
            "fmeasure": 0.32749
        },
        "rougeL": {
            "precision": 0.49275,
            "recall": 0.72941,
            "fmeasure": 0.58772
        },
        "rougeLsum": {
            "precision": 0.49275,
            "recall": 0.72941,
            "fmeasure": 0.58772
        },
        "nubia": {
            "semantic_relation": 4.21975,
            "contradiction": 35.06424,
            "irrelevancy": 26.02615,
            "logical_agreement": 38.90961,
            "grammar_ref": 4.69116,
            "grammar_hyp": 3.38041,
            "nubia_score": 0.82219
        },
        "meteor": 0.3697542246094317,
        "bleurt": 0.25613,
        "bertscore": {
            "precision": 0.87822,
            "recall": 0.93522,
            "f1": 0.89818
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_684": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 6,
        "total_length": 92,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 3.815174380753199,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 21,
        "distinct-1": 0.6956521739130435,
        "vocab_size-1": 64,
        "unique-1": 50,
        "entropy-1": 5.747648064912956,
        "distinct-2": 0.9302325581395349,
        "vocab_size-2": 80,
        "unique-2": 74,
        "entropy-2": 6.286729870981169,
        "cond_entropy-2": 0.412869112376797,
        "distinct-3": 0.9625,
        "vocab_size-3": 77,
        "unique-3": 74,
        "entropy-3": 6.246928094887356,
        "cond_entropy-3": -0.05433665981473586,
        "total_length-nopunct": 81,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 3.304037933599835,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7654320987654321,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.793372687989673,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 70,
        "unique-2-nopunct": 65,
        "entropy-2-nopunct": 6.095485357162557,
        "cond_entropy-2-nopunct": 0.31916418769779537,
        "distinct-3-nopunct": 0.9565217391304348,
        "vocab_size-3-nopunct": 66,
        "unique-3-nopunct": 63,
        "entropy-3-nopunct": 6.021567935039033,
        "cond_entropy-3-nopunct": -0.06232321922495813,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35,
            "2": 0.55,
            "3": 0.6935483870967742
        },
        "nist": 4.8213235311231815,
        "bleu": 43.56339,
        "rouge1": {
            "precision": 0.74552,
            "recall": 0.68183,
            "fmeasure": 0.70708
        },
        "rouge2": {
            "precision": 0.54344,
            "recall": 0.50235,
            "fmeasure": 0.51705
        },
        "rougeL": {
            "precision": 0.64329,
            "recall": 0.61675,
            "fmeasure": 0.62476
        },
        "rougeLsum": {
            "precision": 0.64329,
            "recall": 0.61675,
            "fmeasure": 0.62476
        },
        "nubia": {
            "semantic_relation": 4.39214,
            "contradiction": 3.82833,
            "irrelevancy": 36.83368,
            "logical_agreement": 59.33799,
            "grammar_ref": 4.51194,
            "grammar_hyp": 4.63551,
            "nubia_score": 0.77302
        },
        "meteor": 0.39192235208908,
        "bleurt": 0.25125,
        "bertscore": {
            "precision": 0.92508,
            "recall": 0.91131,
            "f1": 0.916
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_438": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5,
            "3": 0.7777777777777778
        },
        "nist": 3.232383717502119,
        "bleu": 17.3958,
        "rouge1": {
            "precision": 0.69444,
            "recall": 0.67235,
            "fmeasure": 0.67805
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.42963,
            "fmeasure": 0.39365
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.48485,
            "fmeasure": 0.44796
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.48485,
            "fmeasure": 0.44796
        },
        "nubia": {
            "semantic_relation": 3.98784,
            "contradiction": 0.18169,
            "irrelevancy": 0.99873,
            "logical_agreement": 98.81957,
            "grammar_ref": 5.84412,
            "grammar_hyp": 6.32171,
            "nubia_score": 0.57155
        },
        "meteor": 0.3568330242611599,
        "bleurt": -0.27582,
        "bertscore": {
            "precision": 0.91678,
            "recall": 0.94418,
            "f1": 0.92553
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_686": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 2.8936441277848375,
        "bleu": 100.0,
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "rouge2": {
            "precision": 0.92593,
            "recall": 0.75926,
            "fmeasure": 0.83069
        },
        "rougeL": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "rougeLsum": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "nubia": {
            "semantic_relation": 4.57319,
            "contradiction": 0.20028,
            "irrelevancy": 0.43256,
            "logical_agreement": 99.36716,
            "grammar_ref": 4.05789,
            "grammar_hyp": 4.18715,
            "nubia_score": 0.88792
        },
        "meteor": 0.9652173913043478,
        "bleurt": 0.55466,
        "bertscore": {
            "precision": 0.98107,
            "recall": 0.98047,
            "f1": 0.98047
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_903": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.6402239289418516,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.11475004073479991,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.423065265165703,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.31517,
            "irrelevancy": 0.55477,
            "logical_agreement": 99.13006,
            "grammar_ref": 5.42428,
            "grammar_hyp": 5.51742,
            "nubia_score": 0.98965
        },
        "meteor": 1.0,
        "bleurt": 0.94038,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_440": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 8,
        "total_length": 118,
        "mean_pred_length": 14.75,
        "std_pred_length": 4.841229182759271,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.7796610169491526,
        "vocab_size-1": 92,
        "unique-1": 82,
        "entropy-1": 6.2621406684391765,
        "distinct-2": 1.0,
        "vocab_size-2": 110,
        "unique-2": 110,
        "entropy-2": 6.781359713524669,
        "cond_entropy-2": 0.34616467278894175,
        "distinct-3": 1.0,
        "vocab_size-3": 102,
        "unique-3": 102,
        "entropy-3": 6.6724253419715,
        "cond_entropy-3": -0.10893437155316373,
        "total_length-nopunct": 105,
        "mean_pred_length-nopunct": 13.125,
        "std_pred_length-nopunct": 4.2555111326373005,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 90,
        "unique-1-nopunct": 82,
        "entropy-1-nopunct": 6.356058465528621,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 97,
        "unique-2-nopunct": 97,
        "entropy-2-nopunct": 6.599912842187142,
        "cond_entropy-2-nopunct": 0.27339557683478694,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 89,
        "unique-3-nopunct": 89,
        "entropy-3-nopunct": 6.47573343096641,
        "cond_entropy-3-nopunct": -0.12417941122073,
        "msttr-100": 0.8,
        "msttr-100_nopunct": 0.87,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14634146341463414,
            "2": 0.4,
            "3": 0.8840579710144928
        },
        "nist": 5.5200052580443355,
        "bleu": 44.25974,
        "rouge1": {
            "precision": 0.73437,
            "recall": 0.71525,
            "fmeasure": 0.71083
        },
        "rouge2": {
            "precision": 0.51547,
            "recall": 0.54658,
            "fmeasure": 0.51232
        },
        "rougeL": {
            "precision": 0.65316,
            "recall": 0.62539,
            "fmeasure": 0.62518
        },
        "rougeLsum": {
            "precision": 0.65316,
            "recall": 0.62539,
            "fmeasure": 0.62518
        },
        "nubia": {
            "semantic_relation": 3.75515,
            "contradiction": 9.37253,
            "irrelevancy": 41.55307,
            "logical_agreement": 49.07439,
            "grammar_ref": 4.83092,
            "grammar_hyp": 4.80715,
            "nubia_score": 0.60257
        },
        "meteor": 0.41697387549710146,
        "bleurt": 0.13795,
        "bertscore": {
            "precision": 0.91886,
            "recall": 0.92657,
            "f1": 0.91974
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_822": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.0,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": -0.034621791174768206,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.039126751440438104,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.3333333333333333,
            "3": 0.5882352941176471
        },
        "nist": 3.3447125839455847,
        "bleu": 31.70233,
        "rouge1": {
            "precision": 0.62019,
            "recall": 0.51891,
            "fmeasure": 0.5642
        },
        "rouge2": {
            "precision": 0.30754,
            "recall": 0.24466,
            "fmeasure": 0.27202
        },
        "rougeL": {
            "precision": 0.54487,
            "recall": 0.4402,
            "fmeasure": 0.48642
        },
        "rougeLsum": {
            "precision": 0.54487,
            "recall": 0.4402,
            "fmeasure": 0.48642
        },
        "nubia": {
            "semantic_relation": 4.19095,
            "contradiction": 22.59572,
            "irrelevancy": 12.53674,
            "logical_agreement": 64.86754,
            "grammar_ref": 4.56502,
            "grammar_hyp": 5.4949,
            "nubia_score": 0.66115
        },
        "meteor": 0.3247773845161736,
        "bleurt": 0.4063,
        "bertscore": {
            "precision": 0.90693,
            "recall": 0.89061,
            "f1": 0.89841
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_477": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 41,
        "mean_pred_length": 20.5,
        "std_pred_length": 6.5,
        "median_pred_length": 20.5,
        "min_pred_length": 14,
        "max_pred_length": 27,
        "distinct-1": 0.8048780487804879,
        "vocab_size-1": 33,
        "unique-1": 29,
        "entropy-1": 4.832923345975962,
        "distinct-2": 0.9487179487179487,
        "vocab_size-2": 37,
        "unique-2": 35,
        "entropy-2": 5.182838116298145,
        "cond_entropy-2": 0.3255367528166505,
        "distinct-3": 0.972972972972973,
        "vocab_size-3": 36,
        "unique-3": 35,
        "entropy-3": 5.1553993115749,
        "cond_entropy-3": -0.02189479917924466,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 18.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8108108108108109,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.682162149295792,
        "distinct-2-nopunct": 0.9428571428571428,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 5.014997302659249,
        "cond_entropy-2-nopunct": 0.362966080011072,
        "distinct-3-nopunct": 0.9696969696969697,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.9837880587523955,
        "cond_entropy-3-nopunct": -0.02428283698045265,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.75,
            "3": 0.9615384615384616
        },
        "nist": 5.0736711131808985,
        "bleu": 78.10313,
        "rouge1": {
            "precision": 0.831,
            "recall": 0.8946,
            "fmeasure": 0.85966
        },
        "rouge2": {
            "precision": 0.71032,
            "recall": 0.75183,
            "fmeasure": 0.72885
        },
        "rougeL": {
            "precision": 0.831,
            "recall": 0.8946,
            "fmeasure": 0.85966
        },
        "rougeLsum": {
            "precision": 0.831,
            "recall": 0.8946,
            "fmeasure": 0.85966
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2991,
            "irrelevancy": 1.41466,
            "logical_agreement": 98.28624,
            "grammar_ref": 3.8433,
            "grammar_hyp": 3.70848,
            "nubia_score": 0.99302
        },
        "meteor": 0.5562490766961962,
        "bleurt": 0.79642,
        "bertscore": {
            "precision": 0.97351,
            "recall": 0.9793,
            "f1": 0.97559
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_736": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 19,
        "mean_pred_length": 9.5,
        "std_pred_length": 0.5,
        "median_pred_length": 9.5,
        "min_pred_length": 9,
        "max_pred_length": 10,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.042817613369716734,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.18057224564182078,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.047238912308487487,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.2064508774674265,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8823529411764706
        },
        "nist": 3.767792283860976,
        "bleu": 45.61542,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.98333,
            "fmeasure": 0.96182
        },
        "rouge2": {
            "precision": 0.79167,
            "recall": 0.82011,
            "fmeasure": 0.80392
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.85833,
            "fmeasure": 0.84417
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.85833,
            "fmeasure": 0.84417
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.22464,
            "irrelevancy": 2.17776,
            "logical_agreement": 97.59761,
            "grammar_ref": 4.99735,
            "grammar_hyp": 4.77239,
            "nubia_score": 0.99262
        },
        "meteor": 0.5434177609343566,
        "bleurt": 0.73402,
        "bertscore": {
            "precision": 0.97337,
            "recall": 0.9777,
            "f1": 0.9755
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_909": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 37,
        "mean_pred_length": 12.333333333333334,
        "std_pred_length": 1.247219128924647,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 14,
        "distinct-1": 0.7027027027027027,
        "vocab_size-1": 26,
        "unique-1": 19,
        "entropy-1": 4.519999987133629,
        "distinct-2": 0.8529411764705882,
        "vocab_size-2": 29,
        "unique-2": 24,
        "entropy-2": 4.793345194191516,
        "cond_entropy-2": 0.19432969627325647,
        "distinct-3": 0.9032258064516129,
        "vocab_size-3": 28,
        "unique-3": 25,
        "entropy-3": 4.760647923290102,
        "cond_entropy-3": -0.06875040183120606,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.816496580927726,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.7272727272727273,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.41545813444441,
        "distinct-2-nopunct": 0.8666666666666667,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.640223928941851,
        "cond_entropy-2-nopunct": 0.15432605965551416,
        "distinct-3-nopunct": 0.9259259259259259,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.606739354015322,
        "cond_entropy-3-nopunct": -0.07792901937097599,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.7741935483870968
        },
        "nist": 4.230058695976361,
        "bleu": 48.11768,
        "rouge1": {
            "precision": 0.8129,
            "recall": 0.7904,
            "fmeasure": 0.79914
        },
        "rouge2": {
            "precision": 0.64074,
            "recall": 0.61414,
            "fmeasure": 0.62511
        },
        "rougeL": {
            "precision": 0.76162,
            "recall": 0.73316,
            "fmeasure": 0.74506
        },
        "rougeLsum": {
            "precision": 0.76162,
            "recall": 0.73316,
            "fmeasure": 0.74506
        },
        "nubia": {
            "semantic_relation": 4.80401,
            "contradiction": 0.64661,
            "irrelevancy": 0.88347,
            "logical_agreement": 98.46992,
            "grammar_ref": 3.77014,
            "grammar_hyp": 4.27614,
            "nubia_score": 0.87305
        },
        "meteor": 0.4575850598570988,
        "bleurt": 0.57324,
        "bertscore": {
            "precision": 0.97543,
            "recall": 0.96451,
            "f1": 0.96778
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_828": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 49,
        "mean_pred_length": 24.5,
        "std_pred_length": 1.5,
        "median_pred_length": 24.5,
        "min_pred_length": 23,
        "max_pred_length": 26,
        "distinct-1": 0.8367346938775511,
        "vocab_size-1": 41,
        "unique-1": 37,
        "entropy-1": 5.199107232347856,
        "distinct-2": 1.0,
        "vocab_size-2": 47,
        "unique-2": 47,
        "entropy-2": 5.55458885167764,
        "cond_entropy-2": 0.3731668368517967,
        "distinct-3": 1.0,
        "vocab_size-3": 45,
        "unique-3": 45,
        "entropy-3": 5.491853096329673,
        "cond_entropy-3": -0.06273575534796279,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 22.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 22.5,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.144972196897744,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.426264754702098,
        "cond_entropy-2-nopunct": 0.2974265531267679,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.06871275008401433,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0,
            "3": 0.6923076923076923
        },
        "nist": 4.386507269104944,
        "bleu": 46.4865,
        "rouge1": {
            "precision": 0.73584,
            "recall": 0.65005,
            "fmeasure": 0.68873
        },
        "rouge2": {
            "precision": 0.50685,
            "recall": 0.42449,
            "fmeasure": 0.46023
        },
        "rougeL": {
            "precision": 0.52569,
            "recall": 0.46951,
            "fmeasure": 0.49212
        },
        "rougeLsum": {
            "precision": 0.52569,
            "recall": 0.46951,
            "fmeasure": 0.49212
        },
        "nubia": {
            "semantic_relation": 2.80686,
            "contradiction": 48.94556,
            "irrelevancy": 1.38243,
            "logical_agreement": 49.672,
            "grammar_ref": 3.79147,
            "grammar_hyp": 3.82717,
            "nubia_score": 0.41019
        },
        "meteor": 0.3467122808903926,
        "bleurt": 0.18546,
        "bertscore": {
            "precision": 0.92103,
            "recall": 0.88285,
            "f1": 0.89894
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_830": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.5766176449086644,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.6306023492300306,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.4677201004745006,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2588453731729854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.6850099544647112,
        "bleu": 53.25086,
        "rouge1": {
            "precision": 0.9375,
            "recall": 1.0,
            "fmeasure": 0.96774
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.71429,
            "fmeasure": 0.68966
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.6,
            "fmeasure": 0.58065
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.6,
            "fmeasure": 0.58065
        },
        "nubia": {
            "semantic_relation": 4.92011,
            "contradiction": 0.61901,
            "irrelevancy": 12.82002,
            "logical_agreement": 86.56097,
            "grammar_ref": 4.08392,
            "grammar_hyp": 3.73453,
            "nubia_score": 0.97673
        },
        "meteor": 0.5159842562220408,
        "bleurt": 0.66623,
        "bertscore": {
            "precision": 0.96362,
            "recall": 0.96971,
            "f1": 0.96666
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_740": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.14421971022094904,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.17355726227518523,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.5
        },
        "nist": 1.7469578512763395,
        "bleu": 21.79747,
        "rouge1": {
            "precision": 0.35294,
            "recall": 0.57778,
            "fmeasure": 0.43269
        },
        "rouge2": {
            "precision": 0.27083,
            "recall": 0.50758,
            "fmeasure": 0.35185
        },
        "rougeL": {
            "precision": 0.35294,
            "recall": 0.57778,
            "fmeasure": 0.43269
        },
        "rougeLsum": {
            "precision": 0.35294,
            "recall": 0.57778,
            "fmeasure": 0.43269
        },
        "nubia": {
            "semantic_relation": 1.04104,
            "contradiction": 96.13572,
            "irrelevancy": 3.7357,
            "logical_agreement": 0.12858,
            "grammar_ref": 4.01628,
            "grammar_hyp": 2.53642,
            "nubia_score": 0.22639
        },
        "meteor": 0.2874983309502435,
        "bleurt": -0.20266,
        "bertscore": {
            "precision": 0.8183,
            "recall": 0.87838,
            "f1": 0.84728
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1359": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.7272727272727273
        },
        "nist": 2.4499839463215753,
        "bleu": 25.3271,
        "rouge1": {
            "precision": 0.60714,
            "recall": 0.5881,
            "fmeasure": 0.59729
        },
        "rouge2": {
            "precision": 0.34615,
            "recall": 0.33516,
            "fmeasure": 0.34046
        },
        "rougeL": {
            "precision": 0.46429,
            "recall": 0.45,
            "fmeasure": 0.4569
        },
        "rougeLsum": {
            "precision": 0.46429,
            "recall": 0.45,
            "fmeasure": 0.4569
        },
        "nubia": {
            "semantic_relation": 4.47174,
            "contradiction": 0.11293,
            "irrelevancy": 1.15359,
            "logical_agreement": 98.73348,
            "grammar_ref": 5.03823,
            "grammar_hyp": 4.12563,
            "nubia_score": 0.97188
        },
        "meteor": 0.3122252463664076,
        "bleurt": 0.14279,
        "bertscore": {
            "precision": 0.89013,
            "recall": 0.85068,
            "f1": 0.8693
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_441": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 44,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 6.018490028422596,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 36,
        "unique-1": 29,
        "entropy-1": 5.078638720860853,
        "distinct-2": 0.9512195121951219,
        "vocab_size-2": 39,
        "unique-2": 37,
        "entropy-2": 5.259991029008325,
        "cond_entropy-2": 0.09324233720029841,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.004361333279761042,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 4.642796092394707,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.932138039759376,
        "distinct-2-nopunct": 0.9428571428571428,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 5.01499730265925,
        "cond_entropy-2-nopunct": 0.08135550350138106,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.035533016944966425,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21212121212121213,
            "2": 0.7
        },
        "nist": 3.4273491417270225,
        "bleu": 34.32978,
        "rouge1": {
            "precision": 0.56378,
            "recall": 0.58842,
            "fmeasure": 0.55199
        },
        "rouge2": {
            "precision": 0.32007,
            "recall": 0.39149,
            "fmeasure": 0.34134
        },
        "rougeL": {
            "precision": 0.49968,
            "recall": 0.55279,
            "fmeasure": 0.5062
        },
        "rougeLsum": {
            "precision": 0.49968,
            "recall": 0.55279,
            "fmeasure": 0.5062
        },
        "nubia": {
            "semantic_relation": 3.55417,
            "contradiction": 14.26615,
            "irrelevancy": 66.59318,
            "logical_agreement": 19.14067,
            "grammar_ref": 5.06451,
            "grammar_hyp": 4.86796,
            "nubia_score": 0.60307
        },
        "meteor": 0.3289209078515422,
        "bleurt": -0.08282,
        "bertscore": {
            "precision": 0.90472,
            "recall": 0.9197,
            "f1": 0.91103
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_742": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 2.456435556800404,
        "bleu": 50.0,
        "rouge1": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.8,
            "fmeasure": 0.72727
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.14589,
            "irrelevancy": 0.6446,
            "logical_agreement": 98.20952,
            "grammar_ref": 4.87815,
            "grammar_hyp": 4.39193,
            "nubia_score": 1.0
        },
        "meteor": 0.5277006683854432,
        "bleurt": 0.93658,
        "bertscore": {
            "precision": 0.98601,
            "recall": 0.99497,
            "f1": 0.99047
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_910": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 4.0,
        "median_pred_length": 18.0,
        "min_pred_length": 14,
        "max_pred_length": 22,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 28,
        "unique-1": 21,
        "entropy-1": 4.7045114597155475,
        "distinct-2": 0.9705882352941176,
        "vocab_size-2": 33,
        "unique-2": 32,
        "entropy-2": 5.028639311838573,
        "cond_entropy-2": 0.3515051192834233,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.024962841250339405,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7647058823529411,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.594672032363178,
        "distinct-2-nopunct": 0.96875,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.9375,
        "cond_entropy-2-nopunct": 0.3736273931922691,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.02644273772481478,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.875,
            "3": 0.4
        },
        "nist": 1.9252340753817028,
        "bleu": 12.31198,
        "rouge1": {
            "precision": 0.47756,
            "recall": 0.70669,
            "fmeasure": 0.56958
        },
        "rouge2": {
            "precision": 0.26727,
            "recall": 0.4212,
            "fmeasure": 0.32698
        },
        "rougeL": {
            "precision": 0.44551,
            "recall": 0.67824,
            "fmeasure": 0.53759
        },
        "rougeLsum": {
            "precision": 0.44551,
            "recall": 0.67824,
            "fmeasure": 0.53759
        },
        "nubia": {
            "semantic_relation": 4.0675,
            "contradiction": 6.98255,
            "irrelevancy": 56.00741,
            "logical_agreement": 37.01004,
            "grammar_ref": 4.27476,
            "grammar_hyp": 3.76087,
            "nubia_score": 0.68566
        },
        "meteor": 0.2939508159454824,
        "bleurt": 0.13504,
        "bertscore": {
            "precision": 0.87469,
            "recall": 0.89878,
            "f1": 0.8865
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_442": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.4182958340544896,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432271,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.277613436819116,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.037503523749935014,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.625
        },
        "nist": 2.1445103950503444,
        "bleu": 11.0168,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.49206,
            "fmeasure": 0.49
        },
        "rouge2": {
            "precision": 0.15,
            "recall": 0.13942,
            "fmeasure": 0.14251
        },
        "rougeL": {
            "precision": 0.22727,
            "recall": 0.21825,
            "fmeasure": 0.22
        },
        "rougeLsum": {
            "precision": 0.22727,
            "recall": 0.21825,
            "fmeasure": 0.22
        },
        "nubia": {
            "semantic_relation": 3.86571,
            "contradiction": 29.03312,
            "irrelevancy": 23.97359,
            "logical_agreement": 46.99329,
            "grammar_ref": 5.77141,
            "grammar_hyp": 5.6998,
            "nubia_score": 0.48937
        },
        "meteor": 0.28157730961461186,
        "bleurt": 0.08145,
        "bertscore": {
            "precision": 0.90159,
            "recall": 0.90417,
            "f1": 0.90288
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_480": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 10,
        "total_length": 165,
        "mean_pred_length": 16.5,
        "std_pred_length": 3.3241540277189325,
        "median_pred_length": 16.5,
        "min_pred_length": 12,
        "max_pred_length": 22,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 110,
        "unique-1": 92,
        "entropy-1": 6.34521001557442,
        "distinct-2": 0.9225806451612903,
        "vocab_size-2": 143,
        "unique-2": 132,
        "entropy-2": 7.116415453647394,
        "cond_entropy-2": 0.653023483064776,
        "distinct-3": 0.9517241379310345,
        "vocab_size-3": 138,
        "unique-3": 131,
        "entropy-3": 7.083357365877025,
        "cond_entropy-3": -0.022043677313347946,
        "total_length-nopunct": 151,
        "mean_pred_length-nopunct": 15.1,
        "std_pred_length-nopunct": 3.726929030716845,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7152317880794702,
        "vocab_size-1-nopunct": 108,
        "unique-1-nopunct": 92,
        "entropy-1-nopunct": 6.388440849965054,
        "distinct-2-nopunct": 0.9219858156028369,
        "vocab_size-2-nopunct": 130,
        "unique-2-nopunct": 120,
        "entropy-2-nopunct": 6.978169171532365,
        "cond_entropy-2-nopunct": 0.6500094484722847,
        "distinct-3-nopunct": 0.9465648854961832,
        "vocab_size-3-nopunct": 124,
        "unique-3-nopunct": 117,
        "entropy-3-nopunct": 6.926552772529817,
        "cond_entropy-3-nopunct": -0.03929714855475192,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.82,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3611111111111111,
            "3": 0.7863247863247863
        },
        "nist": 5.12031556700196,
        "bleu": 47.02995,
        "rouge1": {
            "precision": 0.80363,
            "recall": 0.7049,
            "fmeasure": 0.74778
        },
        "rouge2": {
            "precision": 0.60934,
            "recall": 0.53217,
            "fmeasure": 0.56521
        },
        "rougeL": {
            "precision": 0.71196,
            "recall": 0.61267,
            "fmeasure": 0.65546
        },
        "rougeLsum": {
            "precision": 0.71196,
            "recall": 0.61267,
            "fmeasure": 0.65546
        },
        "nubia": {
            "semantic_relation": 4.31247,
            "contradiction": 19.08102,
            "irrelevancy": 5.2711,
            "logical_agreement": 75.64788,
            "grammar_ref": 4.07874,
            "grammar_hyp": 4.54304,
            "nubia_score": 0.72757
        },
        "meteor": 0.3823977427883388,
        "bleurt": 0.38102,
        "bertscore": {
            "precision": 0.94514,
            "recall": 0.93064,
            "f1": 0.9371
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1379": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.875,
        "vocab_size-1": 21,
        "unique-1": 18,
        "entropy-1": 4.334962500721156,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 22,
        "unique-2": 21,
        "entropy-2": 4.436605434317882,
        "cond_entropy-2": 0.11251249881411754,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": 0.026778753489375355,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8695652173913043,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.262692390839622,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.368522527728204,
        "cond_entropy-2-nopunct": 0.1176878443984663,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": 0.02812389937955851,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9047619047619048
        },
        "nist": 3.467258952997759,
        "bleu": 62.86102,
        "rouge1": {
            "precision": 0.95652,
            "recall": 0.81481,
            "fmeasure": 0.88
        },
        "rouge2": {
            "precision": 0.86364,
            "recall": 0.73077,
            "fmeasure": 0.79167
        },
        "rougeL": {
            "precision": 0.95652,
            "recall": 0.81481,
            "fmeasure": 0.88
        },
        "rougeLsum": {
            "precision": 0.95652,
            "recall": 0.81481,
            "fmeasure": 0.88
        },
        "nubia": {
            "semantic_relation": 4.24894,
            "contradiction": 0.13552,
            "irrelevancy": 9.62716,
            "logical_agreement": 90.23731,
            "grammar_ref": 4.19464,
            "grammar_hyp": 4.49828,
            "nubia_score": 0.69269
        },
        "meteor": 0.4972635721787356,
        "bleurt": 0.31997,
        "bertscore": {
            "precision": 0.97265,
            "recall": 0.94448,
            "f1": 0.95781
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1680": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8
        },
        "nist": 2.9066733640678954,
        "bleu": 29.42096,
        "rouge1": {
            "precision": 0.78788,
            "recall": 0.86667,
            "fmeasure": 0.8254
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.51852,
            "fmeasure": 0.49123
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.7,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.7,
            "fmeasure": 0.66667
        },
        "nubia": {
            "semantic_relation": 4.91061,
            "contradiction": 0.26067,
            "irrelevancy": 1.02487,
            "logical_agreement": 98.71446,
            "grammar_ref": 4.2439,
            "grammar_hyp": 4.12469,
            "nubia_score": 0.97214
        },
        "meteor": 0.4599797110107353,
        "bleurt": 0.54612,
        "bertscore": {
            "precision": 0.92701,
            "recall": 0.95814,
            "f1": 0.94232
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1056": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.7142857142857143
        },
        "nist": 1.5199426646357361,
        "bleu": 42.26839,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.62092,
            "fmeasure": 0.67521
        },
        "rouge2": {
            "precision": 0.5625,
            "recall": 0.46875,
            "fmeasure": 0.5
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.5915,
            "fmeasure": 0.63675
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.5915,
            "fmeasure": 0.63675
        },
        "nubia": {
            "semantic_relation": 4.27546,
            "contradiction": 1.24357,
            "irrelevancy": 1.58726,
            "logical_agreement": 97.16917,
            "grammar_ref": 5.6106,
            "grammar_hyp": 5.58011,
            "nubia_score": 0.70715
        },
        "meteor": 0.4933048476086122,
        "bleurt": 0.20795,
        "bertscore": {
            "precision": 0.94446,
            "recall": 0.93812,
            "f1": 0.94128
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_748": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 4.5,
        "median_pred_length": 16.5,
        "min_pred_length": 12,
        "max_pred_length": 21,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 24,
        "unique-1": 17,
        "entropy-1": 4.4531888161970326,
        "distinct-2": 0.8387096774193549,
        "vocab_size-2": 26,
        "unique-2": 21,
        "entropy-2": 4.631615665225586,
        "cond_entropy-2": 0.15205299761961344,
        "distinct-3": 0.8620689655172413,
        "vocab_size-3": 25,
        "unique-3": 21,
        "entropy-3": 4.582118926162054,
        "cond_entropy-3": -0.09621531525930294,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.351823225551768,
        "distinct-2-nopunct": 0.8461538461538461,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.392747410448783,
        "cond_entropy-2-nopunct": -0.0009579922948403236,
        "distinct-3-nopunct": 0.875,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.334962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993587,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.6363636363636364,
            "3": 0.9444444444444444
        },
        "nist": 4.706413891296889,
        "bleu": 64.34169,
        "rouge1": {
            "precision": 0.92068,
            "recall": 0.88003,
            "fmeasure": 0.89933
        },
        "rouge2": {
            "precision": 0.7625,
            "recall": 0.77492,
            "fmeasure": 0.76445
        },
        "rougeL": {
            "precision": 0.7344,
            "recall": 0.79864,
            "fmeasure": 0.75993
        },
        "rougeLsum": {
            "precision": 0.7344,
            "recall": 0.79864,
            "fmeasure": 0.75993
        },
        "nubia": {
            "semantic_relation": 4.72611,
            "contradiction": 0.58795,
            "irrelevancy": 16.76996,
            "logical_agreement": 82.6421,
            "grammar_ref": 3.87403,
            "grammar_hyp": 3.82289,
            "nubia_score": 0.92541
        },
        "meteor": 0.5777942208724922,
        "bleurt": 0.47526,
        "bertscore": {
            "precision": 0.98053,
            "recall": 0.97897,
            "f1": 0.97851
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1384": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964168,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.6666666666666666
        },
        "nist": 2.1528533890550183,
        "bleu": 31.61488,
        "rouge1": {
            "precision": 0.42308,
            "recall": 0.69048,
            "fmeasure": 0.52273
        },
        "rouge2": {
            "precision": 0.29167,
            "recall": 0.52083,
            "fmeasure": 0.37222
        },
        "rougeL": {
            "precision": 0.38462,
            "recall": 0.63492,
            "fmeasure": 0.47727
        },
        "rougeLsum": {
            "precision": 0.38462,
            "recall": 0.63492,
            "fmeasure": 0.47727
        },
        "nubia": {
            "semantic_relation": 3.36369,
            "contradiction": 0.10807,
            "irrelevancy": 85.08287,
            "logical_agreement": 14.80905,
            "grammar_ref": 4.8549,
            "grammar_hyp": 3.58476,
            "nubia_score": 0.58946
        },
        "meteor": 0.35149642178137297,
        "bleurt": 0.39891,
        "bertscore": {
            "precision": 0.87927,
            "recall": 0.92302,
            "f1": 0.90061
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1188": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 1.0,
        "vocab_size-1": 20,
        "unique-1": 20,
        "entropy-1": 4.321928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.07400058144377676,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.6363636363636364
        },
        "nist": 2.8814877565303627,
        "bleu": 32.91599,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.61667,
            "fmeasure": 0.55208
        },
        "rouge2": {
            "precision": 0.23529,
            "recall": 0.29121,
            "fmeasure": 0.26022
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.54762,
            "fmeasure": 0.49053
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.54762,
            "fmeasure": 0.49053
        },
        "nubia": {
            "semantic_relation": 3.92626,
            "contradiction": 76.92075,
            "irrelevancy": 14.38413,
            "logical_agreement": 8.69512,
            "grammar_ref": 4.95834,
            "grammar_hyp": 4.40025,
            "nubia_score": 0.63795
        },
        "meteor": 0.363968114957037,
        "bleurt": 0.25023,
        "bertscore": {
            "precision": 0.899,
            "recall": 0.93292,
            "f1": 0.91565
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1400": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 18,
        "unique-1": 15,
        "entropy-1": 4.106603137064473,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.22961067210860203,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.021928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.2417888922404337,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 1.0
        },
        "nist": 2.76144546927857,
        "bleu": 40.64458,
        "rouge1": {
            "precision": 0.6,
            "recall": 1.0,
            "fmeasure": 0.74878
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.85833,
            "fmeasure": 0.6307
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.83217,
            "fmeasure": 0.62366
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.83217,
            "fmeasure": 0.62366
        },
        "nubia": {
            "semantic_relation": 4.09334,
            "contradiction": 1.17512,
            "irrelevancy": 93.09373,
            "logical_agreement": 5.73116,
            "grammar_ref": 4.75081,
            "grammar_hyp": 3.52687,
            "nubia_score": 0.71358
        },
        "meteor": 0.4783493683826736,
        "bleurt": 0.35058,
        "bertscore": {
            "precision": 0.91244,
            "recall": 0.96894,
            "f1": 0.93984
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_483": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 32,
        "mean_pred_length": 10.666666666666666,
        "std_pred_length": 3.858612300930075,
        "median_pred_length": 9.0,
        "min_pred_length": 7,
        "max_pred_length": 16,
        "distinct-1": 0.8125,
        "vocab_size-1": 26,
        "unique-1": 22,
        "entropy-1": 4.577819531114783,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.1598736676159676,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.15754127698647996,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 9.666666666666666,
        "std_pred_length-nopunct": 3.858612300930075,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8620689655172413,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.556088322639176,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.17918516540442264,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.17687776208407924,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1875,
            "2": 0.7692307692307693,
            "3": 0.9166666666666666
        },
        "nist": 4.536548730636486,
        "bleu": 64.69255,
        "rouge1": {
            "precision": 0.81587,
            "recall": 0.80019,
            "fmeasure": 0.80754
        },
        "rouge2": {
            "precision": 0.67857,
            "recall": 0.66518,
            "fmeasure": 0.67143
        },
        "rougeL": {
            "precision": 0.81587,
            "recall": 0.80019,
            "fmeasure": 0.80754
        },
        "rougeLsum": {
            "precision": 0.81587,
            "recall": 0.80019,
            "fmeasure": 0.80754
        },
        "nubia": {
            "semantic_relation": 4.67046,
            "contradiction": 0.40791,
            "irrelevancy": 0.66576,
            "logical_agreement": 98.92634,
            "grammar_ref": 5.27099,
            "grammar_hyp": 5.37553,
            "nubia_score": 0.89103
        },
        "meteor": 0.4694292615516455,
        "bleurt": 0.61802,
        "bertscore": {
            "precision": 0.94786,
            "recall": 0.95774,
            "f1": 0.95191
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1072": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 2.0,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.75,
        "vocab_size-1": 21,
        "unique-1": 17,
        "entropy-1": 4.178439190827719,
        "distinct-2": 0.9615384615384616,
        "vocab_size-2": 25,
        "unique-2": 24,
        "entropy-2": 4.623516641218013,
        "cond_entropy-2": 0.41653250663874974,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.03214388408660256,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.76,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0194705707972505,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.436605434317882,
        "cond_entropy-2-nopunct": 0.42795100430127997,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.03600643804015718,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.0,
            "3": 0.5238095238095238
        },
        "nist": 2.7436280045969634,
        "bleu": 21.52571,
        "rouge1": {
            "precision": 0.52381,
            "recall": 0.50977,
            "fmeasure": 0.51303
        },
        "rouge2": {
            "precision": 0.23776,
            "recall": 0.24466,
            "fmeasure": 0.24091
        },
        "rougeL": {
            "precision": 0.45238,
            "recall": 0.43468,
            "fmeasure": 0.43984
        },
        "rougeLsum": {
            "precision": 0.45238,
            "recall": 0.43468,
            "fmeasure": 0.43984
        },
        "nubia": {
            "semantic_relation": 3.72203,
            "contradiction": 5.99236,
            "irrelevancy": 51.56725,
            "logical_agreement": 42.4404,
            "grammar_ref": 4.47266,
            "grammar_hyp": 3.97121,
            "nubia_score": 0.64883
        },
        "meteor": 0.2465645071224073,
        "bleurt": -0.07117,
        "bertscore": {
            "precision": 0.87821,
            "recall": 0.87207,
            "f1": 0.87513
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_749": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.037537158749660585,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185189,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.75
        },
        "nist": 2.5848040654130635,
        "bleu": 37.42032,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.76923,
            "fmeasure": 0.68966
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.58333,
            "fmeasure": 0.51852
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.76923,
            "fmeasure": 0.68966
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.76923,
            "fmeasure": 0.68966
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.06983,
            "irrelevancy": 2.29714,
            "logical_agreement": 97.63303,
            "grammar_ref": 4.23153,
            "grammar_hyp": 3.7095,
            "nubia_score": 0.99841
        },
        "meteor": 0.4854043997759893,
        "bleurt": 0.62156,
        "bertscore": {
            "precision": 0.9266,
            "recall": 0.9505,
            "f1": 0.9384
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1408": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 14,
        "unique-1": 11,
        "entropy-1": 3.68354236243323,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.43253122228823104,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7647058823529411,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.572469458770136,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.45971762763487756,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "nist": 1.1729520220840473,
        "bleu": 5.75139,
        "rouge1": {
            "precision": 0.23529,
            "recall": 0.28356,
            "fmeasure": 0.25621
        },
        "rouge2": {
            "precision": 0.0625,
            "recall": 0.07639,
            "fmeasure": 0.06845
        },
        "rougeL": {
            "precision": 0.21569,
            "recall": 0.23379,
            "fmeasure": 0.22353
        },
        "rougeLsum": {
            "precision": 0.21569,
            "recall": 0.23379,
            "fmeasure": 0.22353
        },
        "nubia": {
            "semantic_relation": 1.31376,
            "contradiction": 22.12994,
            "irrelevancy": 76.12684,
            "logical_agreement": 1.74322,
            "grammar_ref": 4.12033,
            "grammar_hyp": 3.32162,
            "nubia_score": 0.13504
        },
        "meteor": 0.1189948230202452,
        "bleurt": -0.50823,
        "bertscore": {
            "precision": 0.68034,
            "recall": 0.68077,
            "f1": 0.68053
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_485": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7735572622751845,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.04332146930622849,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.8
        },
        "nist": 2.6856265017985197,
        "bleu": 21.83001,
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.80828,
            "fmeasure": 0.86616
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.4902,
            "fmeasure": 0.5276
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.63508,
            "fmeasure": 0.68056
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.63508,
            "fmeasure": 0.68056
        },
        "nubia": {
            "semantic_relation": 4.80086,
            "contradiction": 0.1395,
            "irrelevancy": 0.76855,
            "logical_agreement": 99.09195,
            "grammar_ref": 3.15249,
            "grammar_hyp": 3.4049,
            "nubia_score": 0.96253
        },
        "meteor": 0.41081248021664324,
        "bleurt": 0.42937,
        "bertscore": {
            "precision": 0.95812,
            "recall": 0.93418,
            "f1": 0.946
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_833": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966058,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185188,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.247740257543667,
        "bleu": 62.81882,
        "rouge1": {
            "precision": 0.94118,
            "recall": 0.87329,
            "fmeasure": 0.90582
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.80828,
            "fmeasure": 0.84017
        },
        "rougeL": {
            "precision": 0.70588,
            "recall": 0.65497,
            "fmeasure": 0.67937
        },
        "rougeLsum": {
            "precision": 0.70588,
            "recall": 0.65497,
            "fmeasure": 0.67937
        },
        "nubia": {
            "semantic_relation": 4.25796,
            "contradiction": 1.5175,
            "irrelevancy": 0.82484,
            "logical_agreement": 97.65766,
            "grammar_ref": 4.95426,
            "grammar_hyp": 5.35301,
            "nubia_score": 0.66237
        },
        "meteor": 0.5114847281933983,
        "bleurt": 0.02091,
        "bertscore": {
            "precision": 0.93144,
            "recall": 0.93115,
            "f1": 0.9313
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_693": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673076,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8
        },
        "nist": 3.4595216280661427,
        "bleu": 38.14156,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.71429,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.56667,
            "recall": 0.4359,
            "fmeasure": 0.49275
        },
        "rougeL": {
            "precision": 0.84848,
            "recall": 0.66667,
            "fmeasure": 0.74667
        },
        "rougeLsum": {
            "precision": 0.84848,
            "recall": 0.66667,
            "fmeasure": 0.74667
        },
        "nubia": {
            "semantic_relation": 4.61109,
            "contradiction": 3.09482,
            "irrelevancy": 8.3594,
            "logical_agreement": 88.54578,
            "grammar_ref": 4.18993,
            "grammar_hyp": 4.96442,
            "nubia_score": 0.74324
        },
        "meteor": 0.3918734238227112,
        "bleurt": 0.44858,
        "bertscore": {
            "precision": 0.96123,
            "recall": 0.92567,
            "f1": 0.94312
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1683": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.7619047619047619,
        "vocab_size-1": 16,
        "unique-1": 13,
        "entropy-1": 3.8442328987631913,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.42585129728889104,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.702819531114783,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.2238830957527498,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.5
        },
        "nist": 2.4161987950056085,
        "bleu": 24.78616,
        "rouge1": {
            "precision": 0.77083,
            "recall": 0.64141,
            "fmeasure": 0.69866
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.33053,
            "fmeasure": 0.36111
        },
        "rougeL": {
            "precision": 0.4375,
            "recall": 0.36532,
            "fmeasure": 0.39732
        },
        "rougeLsum": {
            "precision": 0.4375,
            "recall": 0.36532,
            "fmeasure": 0.39732
        },
        "nubia": {
            "semantic_relation": 3.24027,
            "contradiction": 88.65079,
            "irrelevancy": 5.52148,
            "logical_agreement": 5.82773,
            "grammar_ref": 4.78465,
            "grammar_hyp": 5.3561,
            "nubia_score": 0.33952
        },
        "meteor": 0.3097920238598472,
        "bleurt": -0.31776,
        "bertscore": {
            "precision": 0.92449,
            "recall": 0.85354,
            "f1": 0.88698
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_834": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0
        },
        "nist": 3.2414851729709646,
        "bleu": 54.08439,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.74661,
            "fmeasure": 0.81931
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.58333,
            "fmeasure": 0.64412
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.50452,
            "fmeasure": 0.55586
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.50452,
            "fmeasure": 0.55586
        },
        "nubia": {
            "semantic_relation": 4.23015,
            "contradiction": 0.30962,
            "irrelevancy": 0.87818,
            "logical_agreement": 98.81219,
            "grammar_ref": 4.29821,
            "grammar_hyp": 4.71423,
            "nubia_score": 0.7174
        },
        "meteor": 0.47058904521438194,
        "bleurt": 0.49887,
        "bertscore": {
            "precision": 0.96621,
            "recall": 0.95745,
            "f1": 0.96181
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_945": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.0,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 18,
        "distinct-1": 0.8214285714285714,
        "vocab_size-1": 23,
        "unique-1": 19,
        "entropy-1": 4.423251796980338,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.22981123847439044,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.303508854797679,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.18150945892357132,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8421052631578947
        },
        "nist": 3.652838982782965,
        "bleu": 51.27269,
        "rouge1": {
            "precision": 0.78519,
            "recall": 0.69166,
            "fmeasure": 0.72613
        },
        "rouge2": {
            "precision": 0.48214,
            "recall": 0.47863,
            "fmeasure": 0.47549
        },
        "rougeL": {
            "precision": 0.5963,
            "recall": 0.51965,
            "fmeasure": 0.54823
        },
        "rougeLsum": {
            "precision": 0.5963,
            "recall": 0.51965,
            "fmeasure": 0.54823
        },
        "nubia": {
            "semantic_relation": 3.79949,
            "contradiction": 0.47483,
            "irrelevancy": 1.16283,
            "logical_agreement": 98.36233,
            "grammar_ref": 4.25678,
            "grammar_hyp": 4.17105,
            "nubia_score": 0.64468
        },
        "meteor": 0.4462230843450909,
        "bleurt": 0.21817,
        "bertscore": {
            "precision": 0.93672,
            "recall": 0.93634,
            "f1": 0.93623
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1428": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.14421971022094898,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.15283195745508588,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 2.285561330828295,
        "bleu": 18.1072,
        "rouge1": {
            "precision": 0.51852,
            "recall": 0.66667,
            "fmeasure": 0.58333
        },
        "rouge2": {
            "precision": 0.29412,
            "recall": 0.37546,
            "fmeasure": 0.32975
        },
        "rougeL": {
            "precision": 0.48148,
            "recall": 0.61905,
            "fmeasure": 0.54167
        },
        "rougeLsum": {
            "precision": 0.48148,
            "recall": 0.61905,
            "fmeasure": 0.54167
        },
        "nubia": {
            "semantic_relation": 3.31535,
            "contradiction": 10.8968,
            "irrelevancy": 70.9382,
            "logical_agreement": 18.165,
            "grammar_ref": 3.90604,
            "grammar_hyp": 3.47259,
            "nubia_score": 0.55667
        },
        "meteor": 0.36796906475005675,
        "bleurt": -0.20405,
        "bertscore": {
            "precision": 0.86042,
            "recall": 0.86887,
            "f1": 0.86378
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_840": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 80,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.69041575982343,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 23,
        "distinct-1": 0.725,
        "vocab_size-1": 58,
        "unique-1": 43,
        "entropy-1": 5.682935401402815,
        "distinct-2": 0.9066666666666666,
        "vocab_size-2": 68,
        "unique-2": 61,
        "entropy-2": 6.04215202382922,
        "cond_entropy-2": 0.2470209289995447,
        "distinct-3": 0.9142857142857143,
        "vocab_size-3": 64,
        "unique-3": 58,
        "entropy-3": 5.957854445516396,
        "cond_entropy-3": -0.07096424497948589,
        "total_length-nopunct": 69,
        "mean_pred_length-nopunct": 13.8,
        "std_pred_length-nopunct": 3.9191835884530852,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7681159420289855,
        "vocab_size-1-nopunct": 53,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.604830435007679,
        "distinct-2-nopunct": 0.90625,
        "vocab_size-2-nopunct": 58,
        "unique-2-nopunct": 52,
        "entropy-2-nopunct": 5.8125,
        "cond_entropy-2-nopunct": 0.2313956604431354,
        "distinct-3-nopunct": 0.9152542372881356,
        "vocab_size-3-nopunct": 54,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.713151523938108,
        "cond_entropy-3-nopunct": -0.08345864555341295,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6428571428571429,
            "3": 0.782608695652174
        },
        "nist": 4.15935994101443,
        "bleu": 47.99906,
        "rouge1": {
            "precision": 0.72698,
            "recall": 0.78932,
            "fmeasure": 0.75154
        },
        "rouge2": {
            "precision": 0.5768,
            "recall": 0.61668,
            "fmeasure": 0.59249
        },
        "rougeL": {
            "precision": 0.65608,
            "recall": 0.76355,
            "fmeasure": 0.68968
        },
        "rougeLsum": {
            "precision": 0.65608,
            "recall": 0.76355,
            "fmeasure": 0.68968
        },
        "nubia": {
            "semantic_relation": 4.33119,
            "contradiction": 0.29259,
            "irrelevancy": 45.06022,
            "logical_agreement": 54.64719,
            "grammar_ref": 5.02868,
            "grammar_hyp": 4.65796,
            "nubia_score": 0.79188
        },
        "meteor": 0.4190129205811678,
        "bleurt": 0.47256,
        "bertscore": {
            "precision": 0.91349,
            "recall": 0.93888,
            "f1": 0.92537
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_752": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.12336199461765374,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.033108599109837954,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5454545454545454,
            "2": 1.0
        },
        "nist": 2.955116912262305,
        "bleu": 57.58522,
        "rouge1": {
            "precision": 0.52632,
            "recall": 0.79514,
            "fmeasure": 0.62143
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.67917,
            "fmeasure": 0.52564
        },
        "rougeL": {
            "precision": 0.52632,
            "recall": 0.79514,
            "fmeasure": 0.62143
        },
        "rougeLsum": {
            "precision": 0.52632,
            "recall": 0.79514,
            "fmeasure": 0.62143
        },
        "nubia": {
            "semantic_relation": 2.97247,
            "contradiction": 0.80565,
            "irrelevancy": 98.37998,
            "logical_agreement": 0.81437,
            "grammar_ref": 4.24724,
            "grammar_hyp": 3.60471,
            "nubia_score": 0.41302
        },
        "meteor": 0.5139078546685881,
        "bleurt": -0.27918,
        "bertscore": {
            "precision": 0.91138,
            "recall": 0.95707,
            "f1": 0.93367
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_637": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.2857142857142857,
            "3": 0.8333333333333334
        },
        "nist": 2.673080697822403,
        "bleu": 14.24779,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.58803,
            "fmeasure": 0.6242
        },
        "rouge2": {
            "precision": 0.24242,
            "recall": 0.22619,
            "fmeasure": 0.23018
        },
        "rougeL": {
            "precision": 0.52778,
            "recall": 0.54416,
            "fmeasure": 0.53206
        },
        "rougeLsum": {
            "precision": 0.52778,
            "recall": 0.54416,
            "fmeasure": 0.53206
        },
        "nubia": {
            "semantic_relation": 3.82739,
            "contradiction": 0.16231,
            "irrelevancy": 66.6577,
            "logical_agreement": 33.17998,
            "grammar_ref": 5.94843,
            "grammar_hyp": 5.48285,
            "nubia_score": 0.63825
        },
        "meteor": 0.3236590061282141,
        "bleurt": 0.13611,
        "bertscore": {
            "precision": 0.91326,
            "recall": 0.91476,
            "f1": 0.91401
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_640": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 58,
        "mean_pred_length": 14.5,
        "std_pred_length": 7.92148975887743,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 25,
        "distinct-1": 0.8620689655172413,
        "vocab_size-1": 50,
        "unique-1": 43,
        "entropy-1": 5.569103624400614,
        "distinct-2": 1.0,
        "vocab_size-2": 54,
        "unique-2": 54,
        "entropy-2": 5.7548875021634665,
        "cond_entropy-2": 0.11912872925811868,
        "distinct-3": 1.0,
        "vocab_size-3": 50,
        "unique-3": 50,
        "entropy-3": 5.643856189774728,
        "cond_entropy-3": -0.11103131238874385,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 7.44983221287567,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.9038461538461539,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.508132025833403,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.5849625007211605,
        "cond_entropy-2-nopunct": 0.09285611591339735,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.4594316186372955,
        "cond_entropy-3-nopunct": -0.12553088208385924,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.8,
            "3": 0.7333333333333333
        },
        "nist": 4.416363738384437,
        "bleu": 47.61631,
        "rouge1": {
            "precision": 0.85735,
            "recall": 0.75334,
            "fmeasure": 0.79772
        },
        "rouge2": {
            "precision": 0.53693,
            "recall": 0.47374,
            "fmeasure": 0.5004
        },
        "rougeL": {
            "precision": 0.78398,
            "recall": 0.69664,
            "fmeasure": 0.73407
        },
        "rougeLsum": {
            "precision": 0.78398,
            "recall": 0.69664,
            "fmeasure": 0.73407
        },
        "nubia": {
            "semantic_relation": 4.68102,
            "contradiction": 0.28673,
            "irrelevancy": 0.51213,
            "logical_agreement": 99.20114,
            "grammar_ref": 4.34153,
            "grammar_hyp": 4.98291,
            "nubia_score": 0.85685
        },
        "meteor": 0.42203038742681737,
        "bleurt": 0.45874,
        "bertscore": {
            "precision": 0.94929,
            "recall": 0.91453,
            "f1": 0.93095
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1441": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 62,
        "mean_pred_length": 20.666666666666668,
        "std_pred_length": 2.6246692913372702,
        "median_pred_length": 22.0,
        "min_pred_length": 17,
        "max_pred_length": 23,
        "distinct-1": 0.5967741935483871,
        "vocab_size-1": 37,
        "unique-1": 21,
        "entropy-1": 4.967724383633163,
        "distinct-2": 0.847457627118644,
        "vocab_size-2": 50,
        "unique-2": 41,
        "entropy-2": 5.577558303599125,
        "cond_entropy-2": 0.6091460518347993,
        "distinct-3": 0.9285714285714286,
        "vocab_size-3": 52,
        "unique-3": 48,
        "entropy-3": 5.664497779200465,
        "cond_entropy-3": 0.06756901555290555,
        "total_length-nopunct": 59,
        "mean_pred_length-nopunct": 19.666666666666668,
        "std_pred_length-nopunct": 3.299831645537222,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.5932203389830508,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.8799098381969195,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.521640636343323,
        "cond_entropy-2-nopunct": 0.6418772201730871,
        "distinct-3-nopunct": 0.9433962264150944,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.614712907393385,
        "cond_entropy-3-nopunct": 0.07150892873201016,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.8,
            "2": 0.4444444444444444,
            "3": 0.6666666666666666
        },
        "nist": 3.7603510046154978,
        "bleu": 35.04226,
        "rouge1": {
            "precision": 0.55606,
            "recall": 0.6452,
            "fmeasure": 0.594
        },
        "rouge2": {
            "precision": 0.33109,
            "recall": 0.40241,
            "fmeasure": 0.36051
        },
        "rougeL": {
            "precision": 0.46566,
            "recall": 0.54406,
            "fmeasure": 0.49832
        },
        "rougeLsum": {
            "precision": 0.46566,
            "recall": 0.54406,
            "fmeasure": 0.49832
        },
        "nubia": {
            "semantic_relation": 3.31658,
            "contradiction": 38.09707,
            "irrelevancy": 44.2363,
            "logical_agreement": 17.66664,
            "grammar_ref": 4.27064,
            "grammar_hyp": 4.24933,
            "nubia_score": 0.48875
        },
        "meteor": 0.3297880703947001,
        "bleurt": -0.28753,
        "bertscore": {
            "precision": 0.87405,
            "recall": 0.8896,
            "f1": 0.88014
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_952": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.5714285714285714
        },
        "nist": 1.143036834274724,
        "bleu": 10.69332,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.46154,
            "fmeasure": 0.57143
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.30556,
            "fmeasure": 0.35526
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.46154,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.46154,
            "fmeasure": 0.57143
        },
        "nubia": {
            "semantic_relation": 3.95129,
            "contradiction": 21.44126,
            "irrelevancy": 66.86017,
            "logical_agreement": 11.69857,
            "grammar_ref": 5.35395,
            "grammar_hyp": 5.26689,
            "nubia_score": 0.51227
        },
        "meteor": 0.30322303338174816,
        "bleurt": -0.32232,
        "bertscore": {
            "precision": 0.93123,
            "recall": 0.86391,
            "f1": 0.89631
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_642": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 39,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.943920288775949,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.8205128205128205,
        "vocab_size-1": 32,
        "unique-1": 28,
        "entropy-1": 4.868359590490698,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.2042387549224791,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 10.666666666666666,
        "std_pred_length-nopunct": 2.6246692913372702,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.702819531114783,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.18590427113884586,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.15754127698647996,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.14285714285714285,
            "3": 0.6216216216216216
        },
        "nist": 2.9649349036896937,
        "bleu": 43.35934,
        "rouge1": {
            "precision": 0.83069,
            "recall": 0.6166,
            "fmeasure": 0.70683
        },
        "rouge2": {
            "precision": 0.70406,
            "recall": 0.52115,
            "fmeasure": 0.59835
        },
        "rougeL": {
            "precision": 0.82275,
            "recall": 0.61155,
            "fmeasure": 0.70066
        },
        "rougeLsum": {
            "precision": 0.82275,
            "recall": 0.61155,
            "fmeasure": 0.70066
        },
        "nubia": {
            "semantic_relation": 2.93495,
            "contradiction": 33.43755,
            "irrelevancy": 0.3751,
            "logical_agreement": 66.18735,
            "grammar_ref": 4.591,
            "grammar_hyp": 4.37907,
            "nubia_score": 0.46076
        },
        "meteor": 0.33046365174682124,
        "bleurt": 0.01618,
        "bertscore": {
            "precision": 0.93451,
            "recall": 0.89078,
            "f1": 0.9121
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_755": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 1.0,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.6363636363636364,
        "vocab_size-1": 14,
        "unique-1": 6,
        "entropy-1": 3.73215889136457,
        "distinct-2": 0.75,
        "vocab_size-2": 15,
        "unique-2": 10,
        "entropy-2": 3.821928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 0.7777777777777778,
        "vocab_size-3": 14,
        "unique-3": 10,
        "entropy-3": 3.7254805569978675,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.65,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.621928094887362,
        "distinct-2-nopunct": 0.7777777777777778,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.7254805569978675,
        "cond_entropy-2-nopunct": 0.07021912877717248,
        "distinct-3-nopunct": 0.8125,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.625,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.490498678107601,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nubia": {
            "semantic_relation": 4.91381,
            "contradiction": 0.28512,
            "irrelevancy": 0.56352,
            "logical_agreement": 99.15137,
            "grammar_ref": 5.78027,
            "grammar_hyp": 5.87845,
            "nubia_score": 0.96986
        },
        "meteor": 1.0,
        "bleurt": 0.92254,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1080": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.84,
        "vocab_size-1": 21,
        "unique-1": 18,
        "entropy-1": 4.293660689688184,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.3058932902032429,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.061400544664143256,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.1523912776298655,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.25454711376829503,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.75,
            "3": 0.8571428571428571
        },
        "nist": 4.192569911497692,
        "bleu": 54.91475,
        "rouge1": {
            "precision": 0.78788,
            "recall": 0.81667,
            "fmeasure": 0.80055
        },
        "rouge2": {
            "precision": 0.47619,
            "recall": 0.61988,
            "fmeasure": 0.53704
        },
        "rougeL": {
            "precision": 0.5303,
            "recall": 0.68333,
            "fmeasure": 0.59566
        },
        "rougeLsum": {
            "precision": 0.5303,
            "recall": 0.68333,
            "fmeasure": 0.59566
        },
        "nubia": {
            "semantic_relation": 3.9149,
            "contradiction": 25.96465,
            "irrelevancy": 37.79499,
            "logical_agreement": 36.24037,
            "grammar_ref": 4.75667,
            "grammar_hyp": 3.77677,
            "nubia_score": 0.73435
        },
        "meteor": 0.4353012597855097,
        "bleurt": -0.11108,
        "bertscore": {
            "precision": 0.90225,
            "recall": 0.91185,
            "f1": 0.89356
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_756": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.03310859910983796,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.75
        },
        "nist": 3.47764544934222,
        "bleu": 39.19146,
        "rouge1": {
            "precision": 0.56818,
            "recall": 0.67101,
            "fmeasure": 0.60841
        },
        "rouge2": {
            "precision": 0.35714,
            "recall": 0.41883,
            "fmeasure": 0.38073
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.58261,
            "fmeasure": 0.53213
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.58261,
            "fmeasure": 0.53213
        },
        "nubia": {
            "semantic_relation": 3.51095,
            "contradiction": 14.37809,
            "irrelevancy": 82.42809,
            "logical_agreement": 3.19383,
            "grammar_ref": 5.51157,
            "grammar_hyp": 5.59073,
            "nubia_score": 0.46345
        },
        "meteor": 0.3472000893303224,
        "bleurt": -0.38029,
        "bertscore": {
            "precision": 0.88811,
            "recall": 0.91813,
            "f1": 0.90287
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1685": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nist": 1.8200785863811701,
        "bleu": 30.25543,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.5098,
            "fmeasure": 0.5977
        },
        "rouge2": {
            "precision": 0.51515,
            "recall": 0.35417,
            "fmeasure": 0.41975
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.39216,
            "fmeasure": 0.45977
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.39216,
            "fmeasure": 0.45977
        },
        "nubia": {
            "semantic_relation": 4.14143,
            "contradiction": 8.46344,
            "irrelevancy": 14.96147,
            "logical_agreement": 76.57509,
            "grammar_ref": 3.28677,
            "grammar_hyp": 5.09187,
            "nubia_score": 0.55245
        },
        "meteor": 0.29563020110735383,
        "bleurt": 0.42762,
        "bertscore": {
            "precision": 0.93948,
            "recall": 0.91825,
            "f1": 0.92848
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1446": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322734,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.7142857142857143
        },
        "nist": 2.5406471597574325,
        "bleu": 28.64629,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.93333,
            "fmeasure": 0.81212
        },
        "rouge2": {
            "precision": 0.63636,
            "recall": 0.92593,
            "fmeasure": 0.75185
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.93333,
            "fmeasure": 0.81212
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.93333,
            "fmeasure": 0.81212
        },
        "nubia": {
            "semantic_relation": 4.33107,
            "contradiction": 0.17271,
            "irrelevancy": 33.61136,
            "logical_agreement": 66.21592,
            "grammar_ref": 3.90726,
            "grammar_hyp": 3.15779,
            "nubia_score": 0.91944
        },
        "meteor": 0.5450030037868164,
        "bleurt": 0.44359,
        "bertscore": {
            "precision": 0.93351,
            "recall": 0.97838,
            "f1": 0.94558
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_760": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 53,
        "mean_pred_length": 13.25,
        "std_pred_length": 4.322904116447646,
        "median_pred_length": 12.5,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.7547169811320755,
        "vocab_size-1": 40,
        "unique-1": 35,
        "entropy-1": 5.079533134249983,
        "distinct-2": 0.9591836734693877,
        "vocab_size-2": 47,
        "unique-2": 45,
        "entropy-2": 5.533077191053984,
        "cond_entropy-2": 0.3432083278499741,
        "distinct-3": 1.0,
        "vocab_size-3": 45,
        "unique-3": 45,
        "entropy-3": 5.491853096329673,
        "cond_entropy-3": -0.033967858896644755,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 11.75,
        "std_pred_length-nopunct": 4.02336923485777,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7872340425531915,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 4.9936414479201865,
        "distinct-2-nopunct": 0.9534883720930233,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.333241498888144,
        "cond_entropy-2-nopunct": 0.3917812048058624,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": -0.03829843327574716,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.16666666666666666,
            "3": 0.8695652173913043
        },
        "nist": 3.1378798726373116,
        "bleu": 21.17848,
        "rouge1": {
            "precision": 0.59621,
            "recall": 0.67606,
            "fmeasure": 0.59113
        },
        "rouge2": {
            "precision": 0.2803,
            "recall": 0.331,
            "fmeasure": 0.28722
        },
        "rougeL": {
            "precision": 0.51466,
            "recall": 0.60981,
            "fmeasure": 0.52078
        },
        "rougeLsum": {
            "precision": 0.51466,
            "recall": 0.60981,
            "fmeasure": 0.52078
        },
        "nubia": {
            "semantic_relation": 3.67915,
            "contradiction": 24.94581,
            "irrelevancy": 22.99752,
            "logical_agreement": 52.05667,
            "grammar_ref": 4.9362,
            "grammar_hyp": 4.37061,
            "nubia_score": 0.54662
        },
        "meteor": 0.25340831463096297,
        "bleurt": -0.02895,
        "bertscore": {
            "precision": 0.8829,
            "recall": 0.87148,
            "f1": 0.8728
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_644": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 2.0,
        "median_pred_length": 16.0,
        "min_pred_length": 14,
        "max_pred_length": 18,
        "distinct-1": 0.9375,
        "vocab_size-1": 30,
        "unique-1": 28,
        "entropy-1": 4.875,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": -0.026442737724814765,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9655172413793104,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.789015477886192,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": -0.029019418890029344,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.96
        },
        "nist": 4.582811788213659,
        "bleu": 62.99695,
        "rouge1": {
            "precision": 0.88654,
            "recall": 0.87979,
            "fmeasure": 0.88308
        },
        "rouge2": {
            "precision": 0.75877,
            "recall": 0.75307,
            "fmeasure": 0.75585
        },
        "rougeL": {
            "precision": 0.79487,
            "recall": 0.77366,
            "fmeasure": 0.78376
        },
        "rougeLsum": {
            "precision": 0.79487,
            "recall": 0.77366,
            "fmeasure": 0.78376
        },
        "nubia": {
            "semantic_relation": 4.69629,
            "contradiction": 1.56424,
            "irrelevancy": 2.41365,
            "logical_agreement": 96.02211,
            "grammar_ref": 4.65278,
            "grammar_hyp": 4.65382,
            "nubia_score": 0.88578
        },
        "meteor": 0.500635692420539,
        "bleurt": 0.54798,
        "bertscore": {
            "precision": 0.97196,
            "recall": 0.9745,
            "f1": 0.97323
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1194": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "nist": 1.8335314239396923,
        "bleu": 6.27466,
        "rouge1": {
            "precision": 0.46667,
            "recall": 0.48148,
            "fmeasure": 0.47368
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.12037,
            "fmeasure": 0.11547
        },
        "rougeL": {
            "precision": 0.36667,
            "recall": 0.37778,
            "fmeasure": 0.37193
        },
        "rougeLsum": {
            "precision": 0.36667,
            "recall": 0.37778,
            "fmeasure": 0.37193
        },
        "nubia": {
            "semantic_relation": 4.62074,
            "contradiction": 0.3184,
            "irrelevancy": 0.44897,
            "logical_agreement": 99.23264,
            "grammar_ref": 4.16465,
            "grammar_hyp": 4.1001,
            "nubia_score": 0.90721
        },
        "meteor": 0.229313854030578,
        "bleurt": 0.49724,
        "bertscore": {
            "precision": 0.88729,
            "recall": 0.87991,
            "f1": 0.88359
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_764": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "nist": 3.368551600409571,
        "bleu": 62.22142,
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.68421,
            "fmeasure": 0.76471
        },
        "rouge2": {
            "precision": 0.78571,
            "recall": 0.61111,
            "fmeasure": 0.6875
        },
        "rougeL": {
            "precision": 0.86667,
            "recall": 0.68421,
            "fmeasure": 0.76471
        },
        "rougeLsum": {
            "precision": 0.86667,
            "recall": 0.68421,
            "fmeasure": 0.76471
        },
        "nubia": {
            "semantic_relation": 3.97227,
            "contradiction": 1.50172,
            "irrelevancy": 4.39492,
            "logical_agreement": 94.10337,
            "grammar_ref": 4.21408,
            "grammar_hyp": 5.60097,
            "nubia_score": 0.50716
        },
        "meteor": 0.3993500396692958,
        "bleurt": 0.38877,
        "bertscore": {
            "precision": 0.95507,
            "recall": 0.90862,
            "f1": 0.93127
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_845": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 8,
        "unique-1": 7,
        "entropy-1": 2.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": 0.08007499855768763,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": 0.09306920777188987,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.3333333333333333
        },
        "nist": 0.1397422175629664,
        "bleu": 10.73076,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.42222,
            "fmeasure": 0.54444
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.38571,
            "fmeasure": 0.50649
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.42222,
            "fmeasure": 0.54444
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.42222,
            "fmeasure": 0.54444
        },
        "nubia": {
            "semantic_relation": 4.12657,
            "contradiction": 0.39164,
            "irrelevancy": 0.57766,
            "logical_agreement": 99.0307,
            "grammar_ref": 2.70093,
            "grammar_hyp": 3.00648,
            "nubia_score": 0.87578
        },
        "meteor": 0.2907157047389913,
        "bleurt": -0.17145,
        "bertscore": {
            "precision": 0.9333,
            "recall": 0.85146,
            "f1": 0.8905
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1688": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.4
        },
        "nist": 0.31592321743697377,
        "bleu": 15.98205,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.41176,
            "fmeasure": 0.53846
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.25,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.35294,
            "fmeasure": 0.46154
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.35294,
            "fmeasure": 0.46154
        },
        "nubia": {
            "semantic_relation": 2.15211,
            "contradiction": 97.26095,
            "irrelevancy": 1.79871,
            "logical_agreement": 0.94034,
            "grammar_ref": 4.28272,
            "grammar_hyp": 4.47104,
            "nubia_score": 0.12897
        },
        "meteor": 0.22923407173743382,
        "bleurt": -0.01146,
        "bertscore": {
            "precision": 0.88467,
            "recall": 0.83511,
            "f1": 0.85917
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_765": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.768492245572466,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.373,
            "irrelevancy": 0.51156,
            "logical_agreement": 99.11544,
            "grammar_ref": 5.07856,
            "grammar_hyp": 5.22425,
            "nubia_score": 0.9763
        },
        "meteor": 1.0,
        "bleurt": 0.97268,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1098": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.218725846082821,
        "bleu": 65.8037,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.84259,
            "fmeasure": 0.85784
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.68452,
            "fmeasure": 0.69841
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.84259,
            "fmeasure": 0.85784
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.84259,
            "fmeasure": 0.85784
        },
        "nubia": {
            "semantic_relation": 4.68121,
            "contradiction": 0.23407,
            "irrelevancy": 0.60193,
            "logical_agreement": 99.164,
            "grammar_ref": 5.1757,
            "grammar_hyp": 5.22369,
            "nubia_score": 0.89839
        },
        "meteor": 0.5312513743477362,
        "bleurt": 0.58344,
        "bertscore": {
            "precision": 0.98124,
            "recall": 0.97997,
            "f1": 0.97952
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_645": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 1.0,
        "vocab_size-1": 24,
        "unique-1": 24,
        "entropy-1": 4.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": -0.061400544664143256,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.459431618637295,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": -0.06711419585853673,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.8888888888888888
        },
        "nist": 4.196759270427408,
        "bleu": 57.41866,
        "rouge1": {
            "precision": 0.80303,
            "recall": 0.89825,
            "fmeasure": 0.84785
        },
        "rouge2": {
            "precision": 0.5873,
            "recall": 0.65984,
            "fmeasure": 0.62137
        },
        "rougeL": {
            "precision": 0.75758,
            "recall": 0.84737,
            "fmeasure": 0.79985
        },
        "rougeLsum": {
            "precision": 0.75758,
            "recall": 0.84737,
            "fmeasure": 0.79985
        },
        "nubia": {
            "semantic_relation": 3.91458,
            "contradiction": 77.8607,
            "irrelevancy": 20.50751,
            "logical_agreement": 1.6318,
            "grammar_ref": 3.98302,
            "grammar_hyp": 4.22097,
            "nubia_score": 0.58446
        },
        "meteor": 0.457487574581841,
        "bleurt": 0.1465,
        "bertscore": {
            "precision": 0.93989,
            "recall": 0.95565,
            "f1": 0.9477
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2282": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5714285714285714
        },
        "nist": 2.0915649828905534,
        "bleu": 11.26871,
        "rouge1": {
            "precision": 0.47368,
            "recall": 0.52941,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.25,
            "fmeasure": 0.23529
        },
        "rougeL": {
            "precision": 0.36842,
            "recall": 0.41176,
            "fmeasure": 0.38889
        },
        "rougeLsum": {
            "precision": 0.36842,
            "recall": 0.41176,
            "fmeasure": 0.38889
        },
        "nubia": {
            "semantic_relation": 2.92615,
            "contradiction": 99.33555,
            "irrelevancy": 0.53599,
            "logical_agreement": 0.12846,
            "grammar_ref": 3.64996,
            "grammar_hyp": 3.64047,
            "nubia_score": 0.42158
        },
        "meteor": 0.23007824194556054,
        "bleurt": -0.0012,
        "bertscore": {
            "precision": 0.90186,
            "recall": 0.90287,
            "f1": 0.90237
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1470": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 64,
        "mean_pred_length": 16.0,
        "std_pred_length": 6.041522986797286,
        "median_pred_length": 17.5,
        "min_pred_length": 7,
        "max_pred_length": 22,
        "distinct-1": 0.703125,
        "vocab_size-1": 45,
        "unique-1": 35,
        "entropy-1": 5.2504036179525455,
        "distinct-2": 0.9666666666666667,
        "vocab_size-2": 58,
        "unique-2": 56,
        "entropy-2": 5.8402239289418505,
        "cond_entropy-2": 0.48499819679997885,
        "distinct-3": 1.0,
        "vocab_size-3": 56,
        "unique-3": 56,
        "entropy-3": 5.807354922057609,
        "cond_entropy-3": -0.02810710212234292,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 4.968651728587948,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7818181818181819,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.265641023041015,
        "distinct-2-nopunct": 0.9607843137254902,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.59399396942248,
        "cond_entropy-2-nopunct": 0.3688014711252731,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.55458885167764,
        "cond_entropy-3-nopunct": -0.032730107315134656,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.2222222222222222,
            "3": 0.4482758620689655
        },
        "nist": 2.5308692729038422,
        "bleu": 16.41169,
        "rouge1": {
            "precision": 0.48512,
            "recall": 0.46664,
            "fmeasure": 0.45869
        },
        "rouge2": {
            "precision": 0.20614,
            "recall": 0.19825,
            "fmeasure": 0.19522
        },
        "rougeL": {
            "precision": 0.3278,
            "recall": 0.26914,
            "fmeasure": 0.28279
        },
        "rougeLsum": {
            "precision": 0.3278,
            "recall": 0.26914,
            "fmeasure": 0.28279
        },
        "nubia": {
            "semantic_relation": 3.41666,
            "contradiction": 9.53843,
            "irrelevancy": 59.92822,
            "logical_agreement": 30.53335,
            "grammar_ref": 5.44243,
            "grammar_hyp": 5.55947,
            "nubia_score": 0.43492
        },
        "meteor": 0.1901193936150962,
        "bleurt": -0.35718,
        "bertscore": {
            "precision": 0.84426,
            "recall": 0.83037,
            "f1": 0.83118
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1503": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.8,
        "vocab_size-1": 16,
        "unique-1": 13,
        "entropy-1": 3.884183719779189,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.3867829713016689,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7894736842105263,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.787143960698138,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.40838012700780835,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.8125
        },
        "nist": 3.9669473836805667,
        "bleu": 31.54909,
        "rouge1": {
            "precision": 0.77193,
            "recall": 0.83007,
            "fmeasure": 0.7998
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.42892,
            "fmeasure": 0.40784
        },
        "rougeL": {
            "precision": 0.57895,
            "recall": 0.67402,
            "fmeasure": 0.62275
        },
        "rougeLsum": {
            "precision": 0.57895,
            "recall": 0.67402,
            "fmeasure": 0.62275
        },
        "nubia": {
            "semantic_relation": 3.59526,
            "contradiction": 7.23592,
            "irrelevancy": 2.16565,
            "logical_agreement": 90.59843,
            "grammar_ref": 4.86284,
            "grammar_hyp": 4.60398,
            "nubia_score": 0.56203
        },
        "meteor": 0.36792300893974306,
        "bleurt": 0.04398,
        "bertscore": {
            "precision": 0.89739,
            "recall": 0.88195,
            "f1": 0.8896
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_770": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.8260869565217391,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.088779347361362,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.39041511712573906,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.004886164091841,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.40907628033193943,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.5,
            "3": 0.9166666666666666
        },
        "nist": 3.6112670779386553,
        "bleu": 34.94189,
        "rouge1": {
            "precision": 0.68182,
            "recall": 0.75,
            "fmeasure": 0.71429
        },
        "rouge2": {
            "precision": 0.49206,
            "recall": 0.54386,
            "fmeasure": 0.51667
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.62105,
            "fmeasure": 0.58072
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.62105,
            "fmeasure": 0.58072
        },
        "nubia": {
            "semantic_relation": 3.18426,
            "contradiction": 31.59466,
            "irrelevancy": 60.46745,
            "logical_agreement": 7.93789,
            "grammar_ref": 5.26752,
            "grammar_hyp": 5.60808,
            "nubia_score": 0.40035
        },
        "meteor": 0.4188376355138648,
        "bleurt": -0.54918,
        "bertscore": {
            "precision": 0.89166,
            "recall": 0.91194,
            "f1": 0.90169
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2290": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 11,
        "unique-1": 9,
        "entropy-1": 3.3927474104487847,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.21785611591339743,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.2516291673878226,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.14719639064341364,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.8888888888888888
        },
        "nist": 2.553618663440155,
        "bleu": 36.36684,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.71673,
            "fmeasure": 0.7935
        },
        "rouge2": {
            "precision": 0.58824,
            "recall": 0.46898,
            "fmeasure": 0.52182
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.40316,
            "fmeasure": 0.44634
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.40316,
            "fmeasure": 0.44634
        },
        "nubia": {
            "semantic_relation": 4.42412,
            "contradiction": 2.98841,
            "irrelevancy": 0.88698,
            "logical_agreement": 96.12461,
            "grammar_ref": 3.13705,
            "grammar_hyp": 3.36593,
            "nubia_score": 0.87309
        },
        "meteor": 0.4587352280410959,
        "bleurt": 0.36405,
        "bertscore": {
            "precision": 0.94962,
            "recall": 0.93092,
            "f1": 0.94018
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1914": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.043321469306228495,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.46153846153846156
        },
        "nist": 1.729296257154445,
        "bleu": 7.73598,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.44074,
            "fmeasure": 0.46767
        },
        "rouge2": {
            "precision": 0.15385,
            "recall": 0.1369,
            "fmeasure": 0.14474
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.31481,
            "fmeasure": 0.33405
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.31481,
            "fmeasure": 0.33405
        },
        "nubia": {
            "semantic_relation": 3.99976,
            "contradiction": 0.22129,
            "irrelevancy": 89.75008,
            "logical_agreement": 10.02863,
            "grammar_ref": 4.4151,
            "grammar_hyp": 5.7045,
            "nubia_score": 0.50311
        },
        "meteor": 0.2278224947275717,
        "bleurt": -0.24173,
        "bertscore": {
            "precision": 0.86055,
            "recall": 0.84231,
            "f1": 0.85133
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1100": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 44,
        "mean_pred_length": 22.0,
        "std_pred_length": 3.0,
        "median_pred_length": 22.0,
        "min_pred_length": 19,
        "max_pred_length": 25,
        "distinct-1": 0.75,
        "vocab_size-1": 33,
        "unique-1": 24,
        "entropy-1": 4.913977073182751,
        "distinct-2": 0.9523809523809523,
        "vocab_size-2": 40,
        "unique-2": 38,
        "entropy-2": 5.297079327540667,
        "cond_entropy-2": 0.3614572327128919,
        "distinct-3": 1.0,
        "vocab_size-3": 40,
        "unique-3": 40,
        "entropy-3": 5.3219280948873635,
        "cond_entropy-3": 0.029610672108601993,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7894736842105263,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.77424330291727,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.058813890331199,
        "cond_entropy-2-nopunct": 0.2831085991098379,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": 0.005773133925674086,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.6,
            "3": 0.7391304347826086
        },
        "nist": 3.8734925078741465,
        "bleu": 45.1936,
        "rouge1": {
            "precision": 0.60417,
            "recall": 0.66815,
            "fmeasure": 0.6183
        },
        "rouge2": {
            "precision": 0.4127,
            "recall": 0.61255,
            "fmeasure": 0.47779
        },
        "rougeL": {
            "precision": 0.51989,
            "recall": 0.70387,
            "fmeasure": 0.58116
        },
        "rougeLsum": {
            "precision": 0.51989,
            "recall": 0.70387,
            "fmeasure": 0.58116
        },
        "nubia": {
            "semantic_relation": 4.04212,
            "contradiction": 48.40871,
            "irrelevancy": 50.77063,
            "logical_agreement": 0.82067,
            "grammar_ref": 4.39403,
            "grammar_hyp": 4.27807,
            "nubia_score": 0.66134
        },
        "meteor": 0.38493760575607994,
        "bleurt": 0.32596,
        "bertscore": {
            "precision": 0.88741,
            "recall": 0.93212,
            "f1": 0.90823
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2304": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.0,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 15,
        "distinct-1": 0.8846153846153846,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.46967048737186,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.051189449246730766,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.277613436819114,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7647058823529411
        },
        "nist": 2.811995446754461,
        "bleu": 38.45893,
        "rouge1": {
            "precision": 0.65,
            "recall": 0.60216,
            "fmeasure": 0.62442
        },
        "rouge2": {
            "precision": 0.45455,
            "recall": 0.42479,
            "fmeasure": 0.4386
        },
        "rougeL": {
            "precision": 0.65,
            "recall": 0.60216,
            "fmeasure": 0.62442
        },
        "rougeLsum": {
            "precision": 0.65,
            "recall": 0.60216,
            "fmeasure": 0.62442
        },
        "nubia": {
            "semantic_relation": 2.71584,
            "contradiction": 41.17476,
            "irrelevancy": 57.41438,
            "logical_agreement": 1.41086,
            "grammar_ref": 3.80999,
            "grammar_hyp": 4.96169,
            "nubia_score": 0.21243
        },
        "meteor": 0.3008158315751296,
        "bleurt": -0.02868,
        "bertscore": {
            "precision": 0.91255,
            "recall": 0.89411,
            "f1": 0.89899
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1113": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 21,
        "unique-1": 18,
        "entropy-1": 4.208410187268527,
        "distinct-2": 0.9615384615384616,
        "vocab_size-2": 25,
        "unique-2": 24,
        "entropy-2": 4.623516641218013,
        "cond_entropy-2": 0.375164716033097,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": 0.023416471633632516,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.16829583405449,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.436605434317882,
        "cond_entropy-2-nopunct": 0.28642554229237843,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": 0.02677875348937537,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6296296296296297
        },
        "nist": 2.2296480879521607,
        "bleu": 42.93318,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.55682,
            "fmeasure": 0.6391
        },
        "rouge2": {
            "precision": 0.69565,
            "recall": 0.51075,
            "fmeasure": 0.589
        },
        "rougeL": {
            "precision": 0.70833,
            "recall": 0.52588,
            "fmeasure": 0.60359
        },
        "rougeLsum": {
            "precision": 0.70833,
            "recall": 0.52588,
            "fmeasure": 0.60359
        },
        "nubia": {
            "semantic_relation": 3.00984,
            "contradiction": 47.91816,
            "irrelevancy": 19.6583,
            "logical_agreement": 32.42354,
            "grammar_ref": 3.7645,
            "grammar_hyp": 3.65457,
            "nubia_score": 0.38165
        },
        "meteor": 0.33682671008504056,
        "bleurt": -0.34524,
        "bertscore": {
            "precision": 0.91522,
            "recall": 0.83854,
            "f1": 0.87521
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_648": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.070656113151927,
        "distinct-2": 0.95,
        "vocab_size-2": 19,
        "unique-2": 18,
        "entropy-2": 4.221928094887362,
        "cond_entropy-2": 0.1673550472167754,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": 0.031262576450960075,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.9841837197791885,
        "distinct-2-nopunct": 0.9473684210526315,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.142664355548846,
        "cond_entropy-2-nopunct": 0.17625665551219521,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": 0.033108599109837954,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6
        },
        "nist": 2.1005757739882736,
        "bleu": 13.22953,
        "rouge1": {
            "precision": 0.55,
            "recall": 0.64706,
            "fmeasure": 0.59459
        },
        "rouge2": {
            "precision": 0.21053,
            "recall": 0.25,
            "fmeasure": 0.22857
        },
        "rougeL": {
            "precision": 0.3,
            "recall": 0.35294,
            "fmeasure": 0.32432
        },
        "rougeLsum": {
            "precision": 0.3,
            "recall": 0.35294,
            "fmeasure": 0.32432
        },
        "nubia": {
            "semantic_relation": 4.32758,
            "contradiction": 27.33148,
            "irrelevancy": 51.57579,
            "logical_agreement": 21.09273,
            "grammar_ref": 3.58521,
            "grammar_hyp": 3.81495,
            "nubia_score": 0.74595
        },
        "meteor": 0.3555369681775948,
        "bleurt": 0.19629,
        "bertscore": {
            "precision": 0.90275,
            "recall": 0.89688,
            "f1": 0.89981
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5166": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.3333333333333333
        },
        "nist": 0.7588972220619653,
        "bleu": 5.1081,
        "rouge1": {
            "precision": 0.35294,
            "recall": 0.5303,
            "fmeasure": 0.42365
        },
        "rouge2": {
            "precision": 0.1875,
            "recall": 0.29091,
            "fmeasure": 0.22792
        },
        "rougeL": {
            "precision": 0.35294,
            "recall": 0.5303,
            "fmeasure": 0.42365
        },
        "rougeLsum": {
            "precision": 0.35294,
            "recall": 0.5303,
            "fmeasure": 0.42365
        },
        "nubia": {
            "semantic_relation": 2.94584,
            "contradiction": 3.04289,
            "irrelevancy": 96.34183,
            "logical_agreement": 0.61528,
            "grammar_ref": 4.79209,
            "grammar_hyp": 3.31795,
            "nubia_score": 0.4603
        },
        "meteor": 0.26964735915645677,
        "bleurt": -0.30206,
        "bertscore": {
            "precision": 0.7798,
            "recall": 0.84185,
            "f1": 0.80946
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1552": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.875
        },
        "nist": 2.706035196791379,
        "bleu": 29.78202,
        "rouge1": {
            "precision": 0.80556,
            "recall": 0.85606,
            "fmeasure": 0.82971
        },
        "rouge2": {
            "precision": 0.54545,
            "recall": 0.58182,
            "fmeasure": 0.56277
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.79545,
            "fmeasure": 0.77174
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.79545,
            "fmeasure": 0.77174
        },
        "nubia": {
            "semantic_relation": 4.93381,
            "contradiction": 0.24377,
            "irrelevancy": 0.94097,
            "logical_agreement": 98.81525,
            "grammar_ref": 6.27756,
            "grammar_hyp": 6.02711,
            "nubia_score": 0.96262
        },
        "meteor": 0.463545445204617,
        "bleurt": 0.58276,
        "bertscore": {
            "precision": 0.96018,
            "recall": 0.97849,
            "f1": 0.96783
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_445": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.7666666666666667,
        "vocab_size-1": 23,
        "unique-1": 17,
        "entropy-1": 4.415061012203069,
        "distinct-2": 0.9642857142857143,
        "vocab_size-2": 27,
        "unique-2": 26,
        "entropy-2": 4.735926350629034,
        "cond_entropy-2": 0.2845674515263523,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.029992126993435266,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.84,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.323856189774723,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.436605434317882,
        "cond_entropy-2-nopunct": 0.14057533149967955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.03600643804015718,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.4,
            "3": 0.8571428571428571
        },
        "nist": 5.055403100052785,
        "bleu": 68.48162,
        "rouge1": {
            "precision": 0.90919,
            "recall": 0.78059,
            "fmeasure": 0.83474
        },
        "rouge2": {
            "precision": 0.72348,
            "recall": 0.6266,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.78419,
            "recall": 0.68844,
            "fmeasure": 0.72874
        },
        "rougeLsum": {
            "precision": 0.78419,
            "recall": 0.68844,
            "fmeasure": 0.72874
        },
        "nubia": {
            "semantic_relation": 4.95577,
            "contradiction": 0.39719,
            "irrelevancy": 0.58902,
            "logical_agreement": 99.0138,
            "grammar_ref": 5.26806,
            "grammar_hyp": 4.75064,
            "nubia_score": 0.99202
        },
        "meteor": 0.44192573486803804,
        "bleurt": 0.6152,
        "bertscore": {
            "precision": 0.96711,
            "recall": 0.94201,
            "f1": 0.95431
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1926": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 11,
        "unique-1": 9,
        "entropy-1": 3.3927474104487847,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.21785611591339743,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.0957952550009344,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.262496476250065,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.7777777777777778
        },
        "nist": 2.873738260036439,
        "bleu": 39.43633,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.76923,
            "fmeasure": 0.83333
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.5,
            "fmeasure": 0.54545
        },
        "rougeL": {
            "precision": 0.78788,
            "recall": 0.60513,
            "fmeasure": 0.68376
        },
        "rougeLsum": {
            "precision": 0.78788,
            "recall": 0.60513,
            "fmeasure": 0.68376
        },
        "nubia": {
            "semantic_relation": 4.99198,
            "contradiction": 0.20539,
            "irrelevancy": 1.34828,
            "logical_agreement": 98.44634,
            "grammar_ref": 4.20051,
            "grammar_hyp": 4.84711,
            "nubia_score": 0.95073
        },
        "meteor": 0.3983240151613566,
        "bleurt": 0.55388,
        "bertscore": {
            "precision": 0.97785,
            "recall": 0.95937,
            "f1": 0.96852
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1560": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 4.0,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 19,
        "distinct-1": 0.6333333333333333,
        "vocab_size-1": 19,
        "unique-1": 11,
        "entropy-1": 4.081727678869736,
        "distinct-2": 0.7857142857142857,
        "vocab_size-2": 22,
        "unique-2": 16,
        "entropy-2": 4.378783493486177,
        "cond_entropy-2": 0.28456745152635227,
        "distinct-3": 0.8461538461538461,
        "vocab_size-3": 22,
        "unique-3": 18,
        "entropy-3": 4.3927474104487825,
        "cond_entropy-3": -0.02999212699343525,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6296296296296297,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.9121138909722304,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.243856189774723,
        "cond_entropy-2-nopunct": 0.3191641876977947,
        "distinct-3-nopunct": 0.8695652173913043,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.2626923908396215,
        "cond_entropy-3-nopunct": -0.03333771197858132,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.75,
            "2": 0.25,
            "3": 0.9333333333333333
        },
        "nist": 3.9976188821191108,
        "bleu": 51.0859,
        "rouge1": {
            "precision": 0.775,
            "recall": 0.88959,
            "fmeasure": 0.79111
        },
        "rouge2": {
            "precision": 0.55175,
            "recall": 0.6547,
            "fmeasure": 0.56613
        },
        "rougeL": {
            "precision": 0.71288,
            "recall": 0.8282,
            "fmeasure": 0.73062
        },
        "rougeLsum": {
            "precision": 0.71288,
            "recall": 0.8282,
            "fmeasure": 0.73062
        },
        "nubia": {
            "semantic_relation": 3.98522,
            "contradiction": 33.74519,
            "irrelevancy": 16.61263,
            "logical_agreement": 49.64218,
            "grammar_ref": 4.07172,
            "grammar_hyp": 4.09302,
            "nubia_score": 0.65032
        },
        "meteor": 0.47153763299755297,
        "bleurt": 0.44639,
        "bertscore": {
            "precision": 0.93369,
            "recall": 0.96288,
            "f1": 0.94288
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2313": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 44,
        "mean_pred_length": 22.0,
        "std_pred_length": 1.0,
        "median_pred_length": 22.0,
        "min_pred_length": 21,
        "max_pred_length": 23,
        "distinct-1": 0.7727272727272727,
        "vocab_size-1": 34,
        "unique-1": 25,
        "entropy-1": 4.987729629951762,
        "distinct-2": 0.9761904761904762,
        "vocab_size-2": 41,
        "unique-2": 40,
        "entropy-2": 5.344698375159715,
        "cond_entropy-2": 0.37943074466916493,
        "distinct-3": 1.0,
        "vocab_size-3": 40,
        "unique-3": 40,
        "entropy-3": 5.3219280948873635,
        "cond_entropy-3": -0.020389327891398024,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7631578947368421,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.754377842334021,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.1699250014423095,
        "cond_entropy-2-nopunct": 0.4429665852810454,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.45454545454545453,
            "2": 0.125,
            "3": 0.38235294117647056
        },
        "nist": 1.1259774445768618,
        "bleu": 10.43092,
        "rouge1": {
            "precision": 0.56217,
            "recall": 0.39695,
            "fmeasure": 0.43929
        },
        "rouge2": {
            "precision": 0.25147,
            "recall": 0.15657,
            "fmeasure": 0.18212
        },
        "rougeL": {
            "precision": 0.52513,
            "recall": 0.38121,
            "fmeasure": 0.41721
        },
        "rougeLsum": {
            "precision": 0.52513,
            "recall": 0.38121,
            "fmeasure": 0.41721
        },
        "nubia": {
            "semantic_relation": 1.48689,
            "contradiction": 95.83141,
            "irrelevancy": 3.55668,
            "logical_agreement": 0.6119,
            "grammar_ref": 3.44707,
            "grammar_hyp": 3.84486,
            "nubia_score": 0.09677
        },
        "meteor": 0.14582527105886092,
        "bleurt": -0.43681,
        "bertscore": {
            "precision": 0.87245,
            "recall": 0.80598,
            "f1": 0.83693
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1206": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 2.0,
        "median_pred_length": 20.0,
        "min_pred_length": 18,
        "max_pred_length": 22,
        "distinct-1": 0.75,
        "vocab_size-1": 30,
        "unique-1": 23,
        "entropy-1": 4.753055907333276,
        "distinct-2": 0.9736842105263158,
        "vocab_size-2": 37,
        "unique-2": 36,
        "entropy-2": 5.19529593449622,
        "cond_entropy-2": 0.4458648791394723,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.0224469564457176,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7222222222222222,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.537844793048881,
        "distinct-2-nopunct": 0.9705882352941176,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.028639311838573,
        "cond_entropy-2-nopunct": 0.49856394281283506,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.024962841250339415,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855,
            "3": 0.7
        },
        "nist": 3.9187705668418187,
        "bleu": 48.78059,
        "rouge1": {
            "precision": 0.81373,
            "recall": 0.69259,
            "fmeasure": 0.73856
        },
        "rouge2": {
            "precision": 0.60532,
            "recall": 0.54658,
            "fmeasure": 0.56804
        },
        "rougeL": {
            "precision": 0.69092,
            "recall": 0.61481,
            "fmeasure": 0.64332
        },
        "rougeLsum": {
            "precision": 0.69092,
            "recall": 0.61481,
            "fmeasure": 0.64332
        },
        "nubia": {
            "semantic_relation": 4.24834,
            "contradiction": 1.75554,
            "irrelevancy": 52.41624,
            "logical_agreement": 45.82822,
            "grammar_ref": 4.16263,
            "grammar_hyp": 4.1826,
            "nubia_score": 0.73735
        },
        "meteor": 0.3329638771335421,
        "bleurt": 0.03088,
        "bertscore": {
            "precision": 0.91833,
            "recall": 0.88157,
            "f1": 0.89608
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_695": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 1.0,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 14,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 20,
        "unique-1": 14,
        "entropy-1": 4.23890125660263,
        "distinct-2": 0.8333333333333334,
        "vocab_size-2": 20,
        "unique-2": 16,
        "entropy-2": 4.251629167387823,
        "cond_entropy-2": -0.032143884086602556,
        "distinct-3": 0.8636363636363636,
        "vocab_size-3": 19,
        "unique-3": 16,
        "entropy-3": 4.186704345910023,
        "cond_entropy-3": -0.0346217911747682,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7916666666666666,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.16829583405449,
        "distinct-2-nopunct": 0.8181818181818182,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 4.095795255000932,
        "cond_entropy-2-nopunct": -0.08007633662931364,
        "distinct-3-nopunct": 0.85,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 4.021928094887363,
        "cond_entropy-3-nopunct": -0.08750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.287165657505093,
        "bleu": 83.90527,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.36033,
            "irrelevancy": 0.57765,
            "logical_agreement": 99.06202,
            "grammar_ref": 6.12532,
            "grammar_hyp": 5.69755,
            "nubia_score": 1.0
        },
        "meteor": 0.6317139091272116,
        "bleurt": 0.88717,
        "bertscore": {
            "precision": 0.97954,
            "recall": 0.99788,
            "f1": 0.98854
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1210": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.029610672108601997,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.6666666666666666,
            "3": 0.8571428571428571
        },
        "nist": 4.7986339970995635,
        "bleu": 81.37489,
        "rouge1": {
            "precision": 0.88333,
            "recall": 0.8153,
            "fmeasure": 0.84785
        },
        "rouge2": {
            "precision": 0.78947,
            "recall": 0.7381,
            "fmeasure": 0.76282
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.70335,
            "fmeasure": 0.72527
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.70335,
            "fmeasure": 0.72527
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.19028,
            "irrelevancy": 1.04106,
            "logical_agreement": 98.76866,
            "grammar_ref": 3.4928,
            "grammar_hyp": 3.50195,
            "nubia_score": 0.99691
        },
        "meteor": 0.5499272876836233,
        "bleurt": 0.60983,
        "bertscore": {
            "precision": 0.97756,
            "recall": 0.9661,
            "f1": 0.97179
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2385": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6153846153846154
        },
        "nist": 2.38831296494047,
        "bleu": 15.74908,
        "rouge1": {
            "precision": 0.5625,
            "recall": 0.48333,
            "fmeasure": 0.51961
        },
        "rouge2": {
            "precision": 0.26667,
            "recall": 0.22704,
            "fmeasure": 0.2451
        },
        "rougeL": {
            "precision": 0.3125,
            "recall": 0.26852,
            "fmeasure": 0.28867
        },
        "rougeLsum": {
            "precision": 0.3125,
            "recall": 0.26852,
            "fmeasure": 0.28867
        },
        "nubia": {
            "semantic_relation": 3.17037,
            "contradiction": 12.32989,
            "irrelevancy": 64.58536,
            "logical_agreement": 23.08475,
            "grammar_ref": 4.59116,
            "grammar_hyp": 4.61651,
            "nubia_score": 0.39239
        },
        "meteor": 0.28263627083116716,
        "bleurt": -0.40235,
        "bertscore": {
            "precision": 0.85755,
            "recall": 0.82105,
            "f1": 0.83891
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_696": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 59,
        "mean_pred_length": 19.666666666666668,
        "std_pred_length": 4.784233364802441,
        "median_pred_length": 22.0,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.847457627118644,
        "vocab_size-1": 50,
        "unique-1": 46,
        "entropy-1": 5.482479651490027,
        "distinct-2": 1.0,
        "vocab_size-2": 56,
        "unique-2": 56,
        "entropy-2": 5.807354922057609,
        "cond_entropy-2": 0.34631259545356285,
        "distinct-3": 1.0,
        "vocab_size-3": 53,
        "unique-3": 53,
        "entropy-3": 5.727920454563195,
        "cond_entropy-3": -0.07943446749440497,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 18.666666666666668,
        "std_pred_length-nopunct": 4.784233364802441,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.421468485014094,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 53,
        "entropy-2-nopunct": 5.727920454563195,
        "cond_entropy-2-nopunct": 0.3282945980610064,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.643856189774728,
        "cond_entropy-3-nopunct": -0.08406426478847459,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.15384615384615385,
            "3": 0.7804878048780488
        },
        "nist": 4.056619681804887,
        "bleu": 42.98109,
        "rouge1": {
            "precision": 0.71366,
            "recall": 0.68022,
            "fmeasure": 0.69457
        },
        "rouge2": {
            "precision": 0.50601,
            "recall": 0.52348,
            "fmeasure": 0.51274
        },
        "rougeL": {
            "precision": 0.6144,
            "recall": 0.63622,
            "fmeasure": 0.62295
        },
        "rougeLsum": {
            "precision": 0.6144,
            "recall": 0.63622,
            "fmeasure": 0.62295
        },
        "nubia": {
            "semantic_relation": 3.75917,
            "contradiction": 8.92016,
            "irrelevancy": 54.91289,
            "logical_agreement": 36.16696,
            "grammar_ref": 4.54005,
            "grammar_hyp": 4.47551,
            "nubia_score": 0.59733
        },
        "meteor": 0.38613851918007674,
        "bleurt": -0.0545,
        "bertscore": {
            "precision": 0.91539,
            "recall": 0.91521,
            "f1": 0.91079
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3047": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.6153846153846154,
        "vocab_size-1": 16,
        "unique-1": 6,
        "entropy-1": 3.931208948910323,
        "distinct-2": 0.625,
        "vocab_size-2": 15,
        "unique-2": 6,
        "entropy-2": 3.8349625007211565,
        "cond_entropy-2": -0.11547721741993588,
        "distinct-3": 0.6363636363636364,
        "vocab_size-3": 14,
        "unique-3": 6,
        "entropy-3": 3.7321588913645702,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.625,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.8349625007211565,
        "distinct-2-nopunct": 0.6363636363636364,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 3.7321588913645702,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 0.65,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 3.6219280948873624,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9545454545454546
        },
        "nist": 3.1103359996409683,
        "bleu": 77.79319,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.95455,
            "fmeasure": 0.91304
        },
        "rouge2": {
            "precision": 0.77273,
            "recall": 0.85,
            "fmeasure": 0.80952
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.95455,
            "fmeasure": 0.91304
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.95455,
            "fmeasure": 0.91304
        },
        "nubia": {
            "semantic_relation": 4.39526,
            "contradiction": 0.35576,
            "irrelevancy": 94.77989,
            "logical_agreement": 4.86435,
            "grammar_ref": 3.76088,
            "grammar_hyp": 3.45423,
            "nubia_score": 0.89179
        },
        "meteor": 0.5664771340463897,
        "bleurt": 0.51078,
        "bertscore": {
            "precision": 0.93381,
            "recall": 0.9737,
            "f1": 0.95333
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1216": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.084183719779189,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.17625665551219524,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.5454545454545454,
            "3": 0.4444444444444444
        },
        "nist": 3.2021937958018083,
        "bleu": 25.65851,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.42319,
            "fmeasure": 0.50448
        },
        "rouge2": {
            "precision": 0.24444,
            "recall": 0.18581,
            "fmeasure": 0.21092
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.25391,
            "fmeasure": 0.30269
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.25391,
            "fmeasure": 0.30269
        },
        "nubia": {
            "semantic_relation": 3.00453,
            "contradiction": 17.53117,
            "irrelevancy": 25.78233,
            "logical_agreement": 56.6865,
            "grammar_ref": 3.96534,
            "grammar_hyp": 3.3186,
            "nubia_score": 0.45561
        },
        "meteor": 0.25218300402616173,
        "bleurt": -0.31904,
        "bertscore": {
            "precision": 0.89182,
            "recall": 0.84238,
            "f1": 0.8653
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5360": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.14285714285714285,
            "3": 0.6
        },
        "nist": 1.015497983962738,
        "bleu": 25.57666,
        "rouge1": {
            "precision": 0.7037,
            "recall": 0.52963,
            "fmeasure": 0.59389
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.28105,
            "fmeasure": 0.31529
        },
        "rougeL": {
            "precision": 0.59259,
            "recall": 0.44444,
            "fmeasure": 0.49903
        },
        "rougeLsum": {
            "precision": 0.59259,
            "recall": 0.44444,
            "fmeasure": 0.49903
        },
        "nubia": {
            "semantic_relation": 4.44824,
            "contradiction": 1.23881,
            "irrelevancy": 1.07273,
            "logical_agreement": 97.68847,
            "grammar_ref": 3.74426,
            "grammar_hyp": 3.80806,
            "nubia_score": 0.85915
        },
        "meteor": 0.3536218099557811,
        "bleurt": 0.36894,
        "bertscore": {
            "precision": 0.95994,
            "recall": 0.90415,
            "f1": 0.93121
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1122": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322706,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.875
        },
        "nist": 2.8015020510845376,
        "bleu": 50.48006,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.64394,
            "fmeasure": 0.73781
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.36797,
            "fmeasure": 0.41475
        },
        "rougeL": {
            "precision": 0.59091,
            "recall": 0.42803,
            "fmeasure": 0.48617
        },
        "rougeLsum": {
            "precision": 0.59091,
            "recall": 0.42803,
            "fmeasure": 0.48617
        },
        "nubia": {
            "semantic_relation": 3.74564,
            "contradiction": 0.67737,
            "irrelevancy": 51.58465,
            "logical_agreement": 47.73799,
            "grammar_ref": 4.87259,
            "grammar_hyp": 5.05482,
            "nubia_score": 0.51396
        },
        "meteor": 0.4535606800758789,
        "bleurt": 0.04878,
        "bertscore": {
            "precision": 0.94882,
            "recall": 0.95324,
            "f1": 0.95102
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_700": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 2.0,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 13,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.186704345910024,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.04492500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.19264507794239588,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.9090909090909091
        },
        "nist": 3.3268266978864705,
        "bleu": 47.77214,
        "rouge1": {
            "precision": 0.65201,
            "recall": 0.81296,
            "fmeasure": 0.72256
        },
        "rouge2": {
            "precision": 0.52778,
            "recall": 0.60833,
            "fmeasure": 0.55108
        },
        "rougeL": {
            "precision": 0.67582,
            "recall": 0.72963,
            "fmeasure": 0.69051
        },
        "rougeLsum": {
            "precision": 0.67582,
            "recall": 0.72963,
            "fmeasure": 0.69051
        },
        "nubia": {
            "semantic_relation": 4.32112,
            "contradiction": 6.09712,
            "irrelevancy": 15.46913,
            "logical_agreement": 78.43375,
            "grammar_ref": 5.35128,
            "grammar_hyp": 5.10117,
            "nubia_score": 0.72709
        },
        "meteor": 0.41723986262464624,
        "bleurt": 0.31588,
        "bertscore": {
            "precision": 0.92999,
            "recall": 0.94488,
            "f1": 0.93715
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1928": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.7916666666666666,
        "vocab_size-1": 19,
        "unique-1": 15,
        "entropy-1": 4.136842188131013,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.4062032597777467,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.106603137064474,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.22961067210860203,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 1.0
        },
        "nist": 3.1413422994806957,
        "bleu": 34.11915,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.8631,
            "fmeasure": 0.74938
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.54444,
            "fmeasure": 0.47009
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.76885,
            "fmeasure": 0.67162
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.76885,
            "fmeasure": 0.67162
        },
        "nubia": {
            "semantic_relation": 4.44599,
            "contradiction": 0.85085,
            "irrelevancy": 64.39505,
            "logical_agreement": 34.7541,
            "grammar_ref": 3.89472,
            "grammar_hyp": 3.71571,
            "nubia_score": 0.81476
        },
        "meteor": 0.439457568155737,
        "bleurt": 0.01458,
        "bertscore": {
            "precision": 0.93146,
            "recall": 0.94751,
            "f1": 0.93942
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5418": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.031262576450960075,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3684210526315789
        },
        "nist": 1.3391694460686496,
        "bleu": 11.67012,
        "rouge1": {
            "precision": 0.38889,
            "recall": 0.26884,
            "fmeasure": 0.31657
        },
        "rouge2": {
            "precision": 0.11765,
            "recall": 0.07445,
            "fmeasure": 0.09086
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.23043,
            "fmeasure": 0.27134
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.23043,
            "fmeasure": 0.27134
        },
        "nubia": {
            "semantic_relation": 2.98147,
            "contradiction": 45.58884,
            "irrelevancy": 53.67991,
            "logical_agreement": 0.73125,
            "grammar_ref": 4.294,
            "grammar_hyp": 5.32501,
            "nubia_score": 0.19581
        },
        "meteor": 0.16526346985399668,
        "bleurt": -0.36245,
        "bertscore": {
            "precision": 0.81238,
            "recall": 0.79359,
            "f1": 0.80264
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1692": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 1.0,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.037503523749935014,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.04089198233393866,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3684210526315789,
            "3": 0.6666666666666666
        },
        "nist": 2.4980223118630516,
        "bleu": 8.02285,
        "rouge1": {
            "precision": 0.69048,
            "recall": 0.56414,
            "fmeasure": 0.62039
        },
        "rouge2": {
            "precision": 0.30288,
            "recall": 0.27865,
            "fmeasure": 0.28824
        },
        "rougeL": {
            "precision": 0.47222,
            "recall": 0.38535,
            "fmeasure": 0.42401
        },
        "rougeLsum": {
            "precision": 0.47222,
            "recall": 0.38535,
            "fmeasure": 0.42401
        },
        "nubia": {
            "semantic_relation": 4.00649,
            "contradiction": 3.29295,
            "irrelevancy": 46.41885,
            "logical_agreement": 50.2882,
            "grammar_ref": 5.11675,
            "grammar_hyp": 5.45093,
            "nubia_score": 0.57121
        },
        "meteor": 0.24510094566782617,
        "bleurt": 0.12199,
        "bertscore": {
            "precision": 0.88065,
            "recall": 0.86838,
            "f1": 0.86949
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1128": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.36363636363636365,
            "3": 1.0
        },
        "nist": 3.368202460797976,
        "bleu": 38.49743,
        "rouge1": {
            "precision": 0.60606,
            "recall": 0.63333,
            "fmeasure": 0.61836
        },
        "rouge2": {
            "precision": 0.36667,
            "recall": 0.38721,
            "fmeasure": 0.37594
        },
        "rougeL": {
            "precision": 0.60606,
            "recall": 0.63333,
            "fmeasure": 0.61836
        },
        "rougeLsum": {
            "precision": 0.60606,
            "recall": 0.63333,
            "fmeasure": 0.61836
        },
        "nubia": {
            "semantic_relation": 3.44618,
            "contradiction": 69.15691,
            "irrelevancy": 26.5209,
            "logical_agreement": 4.3222,
            "grammar_ref": 4.72922,
            "grammar_hyp": 5.15738,
            "nubia_score": 0.37262
        },
        "meteor": 0.3054610628368104,
        "bleurt": 0.27908,
        "bertscore": {
            "precision": 0.89557,
            "recall": 0.89236,
            "f1": 0.89396
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1700": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.3015782866651606,
        "bleu": 45.56162,
        "rouge1": {
            "precision": 0.81481,
            "recall": 0.73333,
            "fmeasure": 0.77193
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.48148,
            "fmeasure": 0.5098
        },
        "rougeL": {
            "precision": 0.81481,
            "recall": 0.73333,
            "fmeasure": 0.77193
        },
        "rougeLsum": {
            "precision": 0.81481,
            "recall": 0.73333,
            "fmeasure": 0.77193
        },
        "nubia": {
            "semantic_relation": 4.97453,
            "contradiction": 3.25469,
            "irrelevancy": 3.19749,
            "logical_agreement": 93.54782,
            "grammar_ref": 5.6957,
            "grammar_hyp": 4.86722,
            "nubia_score": 0.9895
        },
        "meteor": 0.48117686361121714,
        "bleurt": 0.13518,
        "bertscore": {
            "precision": 0.98659,
            "recall": 0.97404,
            "f1": 0.98027
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-8": {
        "predictions_file": "ByT5-base (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2271,
        "mean_pred_length": 21.42452830188679,
        "std_pred_length": 3.256193266503333,
        "median_pred_length": 22.0,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.42800528401585203,
        "vocab_size-1": 972,
        "unique-1": 737,
        "entropy-1": 8.411983811729474,
        "distinct-2": 0.8628175519630485,
        "vocab_size-2": 1868,
        "unique-2": 1725,
        "entropy-2": 10.684783556977978,
        "cond_entropy-2": 2.2165541541031977,
        "distinct-3": 0.9791160757649344,
        "vocab_size-3": 2016,
        "unique-3": 1984,
        "entropy-3": 10.960559870106339,
        "cond_entropy-3": 0.29321632370604744,
        "total_length-nopunct": 2164,
        "mean_pred_length-nopunct": 20.41509433962264,
        "std_pred_length-nopunct": 3.3698662549136422,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.44593345656192235,
        "vocab_size-1-nopunct": 965,
        "unique-1-nopunct": 737,
        "entropy-1-nopunct": 8.462630576669806,
        "distinct-2-nopunct": 0.8649173955296404,
        "vocab_size-2-nopunct": 1780,
        "unique-2-nopunct": 1646,
        "entropy-2-nopunct": 10.615019539242024,
        "cond_entropy-2-nopunct": 2.2600267999125614,
        "distinct-3-nopunct": 0.9810450819672131,
        "vocab_size-3-nopunct": 1915,
        "unique-3-nopunct": 1886,
        "entropy-3-nopunct": 10.888980280695975,
        "cond_entropy-3-nopunct": 0.289738370362436,
        "msttr-100": 0.73773,
        "msttr-100_nopunct": 0.74048,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.31152073732718893
        },
        "nist": 2.8215038256325617,
        "bleu": 6.34604,
        "rouge1": {
            "precision": 0.358,
            "recall": 0.34312,
            "fmeasure": 0.34458
        },
        "rouge2": {
            "precision": 0.11777,
            "recall": 0.1095,
            "fmeasure": 0.11119
        },
        "rougeL": {
            "precision": 0.27053,
            "recall": 0.25953,
            "fmeasure": 0.25995
        },
        "rougeLsum": {
            "precision": 0.27053,
            "recall": 0.25953,
            "fmeasure": 0.25995
        },
        "nubia": {
            "semantic_relation": 2.63287,
            "contradiction": 29.40715,
            "irrelevancy": 62.85015,
            "logical_agreement": 7.7427,
            "grammar_ref": 3.78639,
            "grammar_hyp": 4.24985,
            "nubia_score": 0.31319
        },
        "meteor": 0.1428378706754008,
        "bleurt": -0.49521,
        "bertscore": {
            "precision": 0.8183,
            "recall": 0.81292,
            "f1": 0.81533
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5455": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.238703514944046,
        "bleu": 54.10823,
        "rouge1": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.81818,
            "fmeasure": 0.78261
        },
        "rougeL": {
            "precision": 0.76923,
            "recall": 0.83333,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.76923,
            "recall": 0.83333,
            "fmeasure": 0.8
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.21631,
            "irrelevancy": 9.48924,
            "logical_agreement": 90.29445,
            "grammar_ref": 4.72684,
            "grammar_hyp": 4.28863,
            "nubia_score": 1.0
        },
        "meteor": 0.5145692356432209,
        "bleurt": 0.6871,
        "bertscore": {
            "precision": 0.96002,
            "recall": 0.96374,
            "f1": 0.96188
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1730": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 55,
        "mean_pred_length": 18.333333333333332,
        "std_pred_length": 3.39934634239519,
        "median_pred_length": 17.0,
        "min_pred_length": 15,
        "max_pred_length": 23,
        "distinct-1": 0.509090909090909,
        "vocab_size-1": 28,
        "unique-1": 15,
        "entropy-1": 4.512442441855188,
        "distinct-2": 0.7884615384615384,
        "vocab_size-2": 41,
        "unique-2": 32,
        "entropy-2": 5.248328660365576,
        "cond_entropy-2": 0.7176528399112488,
        "distinct-3": 0.8571428571428571,
        "vocab_size-3": 42,
        "unique-3": 36,
        "entropy-3": 5.313589691009832,
        "cond_entropy-3": 0.09294129948765642,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 2.943920288775949,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.5777777777777777,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.483318029990693,
        "distinct-2-nopunct": 0.8095238095238095,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.993391529870107,
        "cond_entropy-2-nopunct": 0.5344926712845779,
        "distinct-3-nopunct": 0.8974358974358975,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 5.0802740137340425,
        "cond_entropy-3-nopunct": 0.09192806536973086,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8
        },
        "nist": 4.830090974194842,
        "bleu": 58.51401,
        "rouge1": {
            "precision": 0.93087,
            "recall": 0.78993,
            "fmeasure": 0.85282
        },
        "rouge2": {
            "precision": 0.68419,
            "recall": 0.58238,
            "fmeasure": 0.62772
        },
        "rougeL": {
            "precision": 0.75668,
            "recall": 0.64011,
            "fmeasure": 0.69219
        },
        "rougeLsum": {
            "precision": 0.75668,
            "recall": 0.64011,
            "fmeasure": 0.69219
        },
        "nubia": {
            "semantic_relation": 3.82915,
            "contradiction": 52.47118,
            "irrelevancy": 14.36143,
            "logical_agreement": 33.16739,
            "grammar_ref": 4.73012,
            "grammar_hyp": 4.81837,
            "nubia_score": 0.53832
        },
        "meteor": 0.43868161955889157,
        "bleurt": 0.3097,
        "bertscore": {
            "precision": 0.96576,
            "recall": 0.94084,
            "f1": 0.95277
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-9": {
        "predictions_file": "ByT5-base (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2275,
        "mean_pred_length": 21.462264150943398,
        "std_pred_length": 3.660535398261078,
        "median_pred_length": 22.0,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.41010989010989013,
        "vocab_size-1": 933,
        "unique-1": 711,
        "entropy-1": 8.348934251058088,
        "distinct-2": 0.8386353158137391,
        "vocab_size-2": 1819,
        "unique-2": 1658,
        "entropy-2": 10.617701702462043,
        "cond_entropy-2": 2.1782748231230977,
        "distinct-3": 0.9626757149781872,
        "vocab_size-3": 1986,
        "unique-3": 1926,
        "entropy-3": 10.92746545613603,
        "cond_entropy-3": 0.3255403178176892,
        "total_length-nopunct": 2160,
        "mean_pred_length-nopunct": 20.37735849056604,
        "std_pred_length-nopunct": 3.81024643928556,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.4287037037037037,
        "vocab_size-1-nopunct": 926,
        "unique-1-nopunct": 709,
        "entropy-1-nopunct": 8.411167810422452,
        "distinct-2-nopunct": 0.8398247322297955,
        "vocab_size-2-nopunct": 1725,
        "unique-2-nopunct": 1578,
        "entropy-2-nopunct": 10.536980987111274,
        "cond_entropy-2-nopunct": 2.2197834532147787,
        "distinct-3-nopunct": 0.9640657084188912,
        "vocab_size-3-nopunct": 1878,
        "unique-3-nopunct": 1822,
        "entropy-3-nopunct": 10.848851572984527,
        "cond_entropy-3-nopunct": 0.33204438777612155,
        "msttr-100": 0.73455,
        "msttr-100_nopunct": 0.74619,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.31502347417840376
        },
        "nist": 2.804853935487385,
        "bleu": 7.08285,
        "rouge1": {
            "precision": 0.35532,
            "recall": 0.34664,
            "fmeasure": 0.34562
        },
        "rouge2": {
            "precision": 0.12268,
            "recall": 0.11944,
            "fmeasure": 0.11932
        },
        "rougeL": {
            "precision": 0.27091,
            "recall": 0.26494,
            "fmeasure": 0.26386
        },
        "rougeLsum": {
            "precision": 0.27091,
            "recall": 0.26494,
            "fmeasure": 0.26386
        },
        "nubia": {
            "semantic_relation": 2.50467,
            "contradiction": 34.02908,
            "irrelevancy": 57.17044,
            "logical_agreement": 8.80048,
            "grammar_ref": 3.81724,
            "grammar_hyp": 4.02659,
            "nubia_score": 0.31522
        },
        "meteor": 0.14315606975031753,
        "bleurt": -0.4915,
        "bertscore": {
            "precision": 0.81524,
            "recall": 0.80957,
            "f1": 0.81217
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 335,
        "total_length": 8092,
        "mean_pred_length": 24.155223880597013,
        "std_pred_length": 3.2174562856202846,
        "median_pred_length": 25.0,
        "min_pred_length": 15,
        "max_pred_length": 32,
        "distinct-1": 0.11653484923381117,
        "vocab_size-1": 943,
        "unique-1": 471,
        "entropy-1": 7.545218575530949,
        "distinct-2": 0.32783292509990974,
        "vocab_size-2": 2543,
        "unique-2": 1564,
        "entropy-2": 10.11588449738361,
        "cond_entropy-2": 2.5298453822068616,
        "distinct-3": 0.5311236863379143,
        "vocab_size-3": 3942,
        "unique-3": 2870,
        "entropy-3": 11.27278539734285,
        "cond_entropy-3": 1.1486889789930799,
        "total_length-nopunct": 7429,
        "mean_pred_length-nopunct": 22.176119402985076,
        "std_pred_length-nopunct": 2.9374620760836203,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.12518508547583793,
        "vocab_size-1-nopunct": 930,
        "unique-1-nopunct": 468,
        "entropy-1-nopunct": 7.580015743045176,
        "distinct-2-nopunct": 0.3443755286157316,
        "vocab_size-2-nopunct": 2443,
        "unique-2-nopunct": 1549,
        "entropy-2-nopunct": 10.076997250995865,
        "cond_entropy-2-nopunct": 2.5197349592036278,
        "distinct-3-nopunct": 0.5471223553780145,
        "vocab_size-3-nopunct": 3698,
        "unique-3-nopunct": 2761,
        "entropy-3-nopunct": 11.175178719645164,
        "cond_entropy-3-nopunct": 1.1194255369988522,
        "msttr-100": 0.65625,
        "msttr-100_nopunct": 0.65986,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6543949044585987
        },
        "nist": 6.823705027145968,
        "bleu": 39.5367,
        "rouge1": {
            "precision": 0.76452,
            "recall": 0.67391,
            "fmeasure": 0.70972
        },
        "rouge2": {
            "precision": 0.55143,
            "recall": 0.48511,
            "fmeasure": 0.51121
        },
        "rougeL": {
            "precision": 0.654,
            "recall": 0.57612,
            "fmeasure": 0.60693
        },
        "rougeLsum": {
            "precision": 0.654,
            "recall": 0.57612,
            "fmeasure": 0.60693
        },
        "nubia": {
            "semantic_relation": 4.33176,
            "contradiction": 3.63603,
            "irrelevancy": 9.0712,
            "logical_agreement": 87.29276,
            "grammar_ref": 4.45968,
            "grammar_hyp": 4.55655,
            "nubia_score": 0.75427
        },
        "meteor": 0.36740382468591354,
        "bleurt": -0.00306,
        "bertscore": {
            "precision": 0.91395,
            "recall": 0.89239,
            "f1": 0.90278
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1260": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 4.5,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 24,
        "unique-1": 22,
        "entropy-1": 4.504706483564824,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.07916418769779476,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.92,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.453660689688183,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.08644000550678685,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.17647058823529413,
            "3": 0.6428571428571429
        },
        "nist": 0.989612977936229,
        "bleu": 37.27807,
        "rouge1": {
            "precision": 0.85417,
            "recall": 0.52482,
            "fmeasure": 0.63119
        },
        "rouge2": {
            "precision": 0.54911,
            "recall": 0.31671,
            "fmeasure": 0.38839
        },
        "rougeL": {
            "precision": 0.76225,
            "recall": 0.47684,
            "fmeasure": 0.57008
        },
        "rougeLsum": {
            "precision": 0.76225,
            "recall": 0.47684,
            "fmeasure": 0.57008
        },
        "nubia": {
            "semantic_relation": 4.18819,
            "contradiction": 17.39522,
            "irrelevancy": 14.20148,
            "logical_agreement": 68.4033,
            "grammar_ref": 3.63495,
            "grammar_hyp": 5.73519,
            "nubia_score": 0.49803
        },
        "meteor": 0.3113817368805241,
        "bleurt": -0.07957,
        "bertscore": {
            "precision": 0.92275,
            "recall": 0.85511,
            "f1": 0.87942
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1135": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 1.0,
            "3": 0.6363636363636364
        },
        "nist": 3.5227012107126456,
        "bleu": 31.55366,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.55278,
            "fmeasure": 0.60427
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.2963,
            "fmeasure": 0.3358
        },
        "rougeL": {
            "precision": 0.61538,
            "recall": 0.49591,
            "fmeasure": 0.54762
        },
        "rougeLsum": {
            "precision": 0.61538,
            "recall": 0.49591,
            "fmeasure": 0.54762
        },
        "nubia": {
            "semantic_relation": 4.06676,
            "contradiction": 0.11201,
            "irrelevancy": 0.77624,
            "logical_agreement": 99.11174,
            "grammar_ref": 5.46955,
            "grammar_hyp": 4.35524,
            "nubia_score": 0.83735
        },
        "meteor": 0.2551351310505003,
        "bleurt": 0.00123,
        "bertscore": {
            "precision": 0.86141,
            "recall": 0.85078,
            "f1": 0.85413
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1573": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.12336199461765371,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.12961067210860203,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.5714285714285714
        },
        "nist": 0.9591587986712041,
        "bleu": 5.4065,
        "rouge1": {
            "precision": 0.24638,
            "recall": 0.57197,
            "fmeasure": 0.34282
        },
        "rouge2": {
            "precision": 0.09091,
            "recall": 0.28571,
            "fmeasure": 0.13793
        },
        "rougeL": {
            "precision": 0.23188,
            "recall": 0.5303,
            "fmeasure": 0.32132
        },
        "rougeLsum": {
            "precision": 0.23188,
            "recall": 0.5303,
            "fmeasure": 0.32132
        },
        "nubia": {
            "semantic_relation": 3.12195,
            "contradiction": 2.94088,
            "irrelevancy": 96.15811,
            "logical_agreement": 0.90101,
            "grammar_ref": 5.51883,
            "grammar_hyp": 3.424,
            "nubia_score": 0.19851
        },
        "meteor": 0.23219660154673893,
        "bleurt": -0.29692,
        "bertscore": {
            "precision": 0.77285,
            "recall": 0.81035,
            "f1": 0.79116
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1582": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 3.5,
        "median_pred_length": 14.5,
        "min_pred_length": 11,
        "max_pred_length": 18,
        "distinct-1": 0.9310344827586207,
        "vocab_size-1": 27,
        "unique-1": 25,
        "entropy-1": 4.720049960644813,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": -0.029019418890029347,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9583333333333334,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.501629167387823,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": -0.034621791174768185,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8461538461538461
        },
        "nist": 4.544344575193639,
        "bleu": 68.19953,
        "rouge1": {
            "precision": 0.91111,
            "recall": 0.8303,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.61607,
            "recall": 0.57857,
            "fmeasure": 0.59524
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.73939,
            "fmeasure": 0.76667
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.73939,
            "fmeasure": 0.76667
        },
        "nubia": {
            "semantic_relation": 4.83486,
            "contradiction": 0.11419,
            "irrelevancy": 1.96424,
            "logical_agreement": 97.92157,
            "grammar_ref": 3.76682,
            "grammar_hyp": 4.13307,
            "nubia_score": 0.94676
        },
        "meteor": 0.4774658213643147,
        "bleurt": 0.55189,
        "bertscore": {
            "precision": 0.96285,
            "recall": 0.94811,
            "f1": 0.95469
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3141": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714
        },
        "nist": 1.3266029805022201,
        "bleu": 14.44881,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.45455,
            "fmeasure": 0.52632
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.2,
            "fmeasure": 0.23529
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.36364,
            "fmeasure": 0.42105
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.36364,
            "fmeasure": 0.42105
        },
        "nubia": {
            "semantic_relation": 3.20122,
            "contradiction": 0.10513,
            "irrelevancy": 99.75742,
            "logical_agreement": 0.13745,
            "grammar_ref": 4.25346,
            "grammar_hyp": 4.51152,
            "nubia_score": 0.51088
        },
        "meteor": 0.20468712467413674,
        "bleurt": -0.34825,
        "bertscore": {
            "precision": 0.85509,
            "recall": 0.82953,
            "f1": 0.84212
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-10": {
        "predictions_file": "ByT5-base (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2193,
        "mean_pred_length": 20.68867924528302,
        "std_pred_length": 4.411313088102833,
        "median_pred_length": 21.0,
        "min_pred_length": 4,
        "max_pred_length": 30,
        "distinct-1": 0.43365253077975374,
        "vocab_size-1": 951,
        "unique-1": 722,
        "entropy-1": 8.424715715236388,
        "distinct-2": 0.849544801149976,
        "vocab_size-2": 1773,
        "unique-2": 1630,
        "entropy-2": 10.600366274905968,
        "cond_entropy-2": 2.0897403308662326,
        "distinct-3": 0.9757698132256436,
        "vocab_size-3": 1933,
        "unique-3": 1900,
        "entropy-3": 10.896599516474572,
        "cond_entropy-3": 0.3082151586210944,
        "total_length-nopunct": 2078,
        "mean_pred_length-nopunct": 19.60377358490566,
        "std_pred_length-nopunct": 4.452430426570771,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.4538017324350337,
        "vocab_size-1-nopunct": 943,
        "unique-1-nopunct": 719,
        "entropy-1-nopunct": 8.493811389691574,
        "distinct-2-nopunct": 0.8519269776876268,
        "vocab_size-2-nopunct": 1680,
        "unique-2-nopunct": 1548,
        "entropy-2-nopunct": 10.523000321120033,
        "cond_entropy-2-nopunct": 2.130684241342246,
        "distinct-3-nopunct": 0.9769560557341908,
        "vocab_size-3-nopunct": 1823,
        "unique-3-nopunct": 1793,
        "entropy-3-nopunct": 10.81333539437181,
        "cond_entropy-3-nopunct": 0.3089733436793452,
        "msttr-100": 0.74571,
        "msttr-100_nopunct": 0.757,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.2782101167315175
        },
        "nist": 2.520534738175574,
        "bleu": 6.15255,
        "rouge1": {
            "precision": 0.3306,
            "recall": 0.32186,
            "fmeasure": 0.31809
        },
        "rouge2": {
            "precision": 0.11158,
            "recall": 0.10704,
            "fmeasure": 0.10738
        },
        "rougeL": {
            "precision": 0.26582,
            "recall": 0.2603,
            "fmeasure": 0.25635
        },
        "rougeLsum": {
            "precision": 0.26582,
            "recall": 0.2603,
            "fmeasure": 0.25635
        },
        "nubia": {
            "semantic_relation": 2.27907,
            "contradiction": 26.30379,
            "irrelevancy": 65.48501,
            "logical_agreement": 8.2112,
            "grammar_ref": 3.93729,
            "grammar_hyp": 4.24518,
            "nubia_score": 0.26515
        },
        "meteor": 0.1282051304714244,
        "bleurt": -0.57927,
        "bertscore": {
            "precision": 0.80906,
            "recall": 0.79964,
            "f1": 0.80396
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3204": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.640223928941851,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337134,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.21785611591339743,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.925938214656137,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.62106,
            "irrelevancy": 0.60577,
            "logical_agreement": 98.77318,
            "grammar_ref": 3.94537,
            "grammar_hyp": 3.78782,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.92236,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1936": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 18,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.7222222222222222,
        "vocab_size-1": 13,
        "unique-1": 8,
        "entropy-1": 3.614369445886757,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.3300749985576878,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.19264507794239588,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.5,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.3073549220576041,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644807,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5
        },
        "nist": 1.2365972673111516,
        "bleu": 12.474,
        "rouge1": {
            "precision": 0.9,
            "recall": 0.57407,
            "fmeasure": 0.68842
        },
        "rouge2": {
            "precision": 0.53968,
            "recall": 0.34557,
            "fmeasure": 0.41288
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 0.57407,
            "fmeasure": 0.68842
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 0.57407,
            "fmeasure": 0.68842
        },
        "nubia": {
            "semantic_relation": 4.36823,
            "contradiction": 1.32765,
            "irrelevancy": 3.49691,
            "logical_agreement": 95.17545,
            "grammar_ref": 3.22845,
            "grammar_hyp": 3.71742,
            "nubia_score": 0.75384
        },
        "meteor": 0.3298849611676232,
        "bleurt": 0.3511,
        "bertscore": {
            "precision": 0.94259,
            "recall": 0.88426,
            "f1": 0.9118
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1969": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 2.740591772516287,
        "bleu": 71.70327,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.80556,
            "fmeasure": 0.75661
        },
        "rouge2": {
            "precision": 0.63636,
            "recall": 0.76471,
            "fmeasure": 0.68045
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.81481,
            "fmeasure": 0.74921
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.81481,
            "fmeasure": 0.74921
        },
        "nubia": {
            "semantic_relation": 4.07226,
            "contradiction": 0.09575,
            "irrelevancy": 66.65279,
            "logical_agreement": 33.25146,
            "grammar_ref": 4.62828,
            "grammar_hyp": 5.12179,
            "nubia_score": 0.64024
        },
        "meteor": 0.5431954619825489,
        "bleurt": -0.0131,
        "bertscore": {
            "precision": 0.92697,
            "recall": 0.94737,
            "f1": 0.92218
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1974": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 0.5,
        "median_pred_length": 11.5,
        "min_pred_length": 11,
        "max_pred_length": 12,
        "distinct-1": 0.5652173913043478,
        "vocab_size-1": 13,
        "unique-1": 5,
        "entropy-1": 3.567040216926579,
        "distinct-2": 0.6666666666666666,
        "vocab_size-2": 14,
        "unique-2": 7,
        "entropy-2": 3.7256507561120937,
        "cond_entropy-2": 0.15446975243603328,
        "distinct-3": 0.7368421052631579,
        "vocab_size-3": 14,
        "unique-3": 9,
        "entropy-3": 3.7216117239699007,
        "cond_entropy-3": -0.03912675144043809,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.5714285714285714,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 3.4399364703978077,
        "distinct-2-nopunct": 0.6842105263157895,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 3.616348566075164,
        "cond_entropy-2-nopunct": 0.17139956434903558,
        "distinct-3-nopunct": 0.7647058823529411,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.6168746059562227,
        "cond_entropy-3-nopunct": -0.04281761336971671,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 4.895103199704214,
        "bleu": 100.0,
        "rouge1": {
            "precision": 0.96818,
            "recall": 1.0,
            "fmeasure": 0.98329
        },
        "rouge2": {
            "precision": 0.92963,
            "recall": 0.96065,
            "fmeasure": 0.94427
        },
        "rougeL": {
            "precision": 0.96818,
            "recall": 1.0,
            "fmeasure": 0.98329
        },
        "rougeLsum": {
            "precision": 0.96818,
            "recall": 1.0,
            "fmeasure": 0.98329
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.62103,
            "irrelevancy": 0.59937,
            "logical_agreement": 98.7796,
            "grammar_ref": 4.85767,
            "grammar_hyp": 4.76417,
            "nubia_score": 0.96108
        },
        "meteor": 1.0,
        "bleurt": 0.87789,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3222": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.334679141051595,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.2807634077603532,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.188721875540867,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.30673161811281996,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "nist": 2.304149183762355,
        "bleu": 62.07107,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.72751,
            "fmeasure": 0.80855
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.51584,
            "fmeasure": 0.57937
        },
        "rougeL": {
            "precision": 0.86111,
            "recall": 0.51704,
            "fmeasure": 0.64264
        },
        "rougeLsum": {
            "precision": 0.86111,
            "recall": 0.51704,
            "fmeasure": 0.64264
        },
        "nubia": {
            "semantic_relation": 3.02537,
            "contradiction": 89.68174,
            "irrelevancy": 5.1453,
            "logical_agreement": 5.17295,
            "grammar_ref": 3.09217,
            "grammar_hyp": 3.0199,
            "nubia_score": 0.4514
        },
        "meteor": 0.3918734238227112,
        "bleurt": 0.13222,
        "bertscore": {
            "precision": 0.95617,
            "recall": 0.91945,
            "f1": 0.93745
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3432": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.794653473544342,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.3148841634647017,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6901165175936654,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.33471762763487756,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "nist": 2.8259671171936906,
        "bleu": 27.43407,
        "rouge1": {
            "precision": 0.7037,
            "recall": 0.84444,
            "fmeasure": 0.76768
        },
        "rouge2": {
            "precision": 0.45098,
            "recall": 0.54762,
            "fmeasure": 0.49462
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.62222,
            "fmeasure": 0.51717
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.62222,
            "fmeasure": 0.51717
        },
        "nubia": {
            "semantic_relation": 3.82661,
            "contradiction": 46.64262,
            "irrelevancy": 52.35571,
            "logical_agreement": 1.00168,
            "grammar_ref": 4.47457,
            "grammar_hyp": 4.12312,
            "nubia_score": 0.62998
        },
        "meteor": 0.42444110445269284,
        "bleurt": -0.03909,
        "bertscore": {
            "precision": 0.90094,
            "recall": 0.9312,
            "f1": 0.91582
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1272": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8,
        "vocab_size-1": 12,
        "unique-1": 10,
        "entropy-1": 3.4565647621309536,
        "distinct-2": 0.9285714285714286,
        "vocab_size-2": 13,
        "unique-2": 12,
        "entropy-2": 3.6644977792004623,
        "cond_entropy-2": 0.24009914803219046,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": 0.04693094992964167,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3248629576173574,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.5465935642949384,
        "cond_entropy-2-nopunct": 0.2588453731729854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": 0.05118944924673077,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5
        },
        "nist": 2.3862183568652164,
        "bleu": 25.33655,
        "rouge1": {
            "precision": 0.53333,
            "recall": 0.53125,
            "fmeasure": 0.5317
        },
        "rouge2": {
            "precision": 0.32143,
            "recall": 0.31538,
            "fmeasure": 0.31801
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.53125,
            "fmeasure": 0.5317
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.53125,
            "fmeasure": 0.5317
        },
        "nubia": {
            "semantic_relation": 4.9768,
            "contradiction": 0.09439,
            "irrelevancy": 0.8312,
            "logical_agreement": 99.07441,
            "grammar_ref": 3.06207,
            "grammar_hyp": 3.30096,
            "nubia_score": 0.9868
        },
        "meteor": 0.3811715051406498,
        "bleurt": 0.43184,
        "bertscore": {
            "precision": 0.93001,
            "recall": 0.92018,
            "f1": 0.92372
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5538": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5555555555555556
        },
        "nist": 2.32249814589546,
        "bleu": 41.10546,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.47222,
            "fmeasure": 0.55238
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "nubia": {
            "semantic_relation": 4.62868,
            "contradiction": 0.5038,
            "irrelevancy": 0.54324,
            "logical_agreement": 98.95296,
            "grammar_ref": 4.24503,
            "grammar_hyp": 4.03961,
            "nubia_score": 0.96227
        },
        "meteor": 0.8569614896318238,
        "bleurt": 0.65075,
        "bertscore": {
            "precision": 0.96587,
            "recall": 0.9307,
            "f1": 0.94796
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1770": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.03126257645096008,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.037537158749660605,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75
        },
        "nist": 1.410174054857258,
        "bleu": 14.25391,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.69697,
            "fmeasure": 0.54253
        },
        "rouge2": {
            "precision": 0.23529,
            "recall": 0.38182,
            "fmeasure": 0.29101
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.69697,
            "fmeasure": 0.54253
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.69697,
            "fmeasure": 0.54253
        },
        "nubia": {
            "semantic_relation": 3.95423,
            "contradiction": 0.12248,
            "irrelevancy": 99.50236,
            "logical_agreement": 0.37517,
            "grammar_ref": 5.10481,
            "grammar_hyp": 3.89211,
            "nubia_score": 0.7413
        },
        "meteor": 0.29922905874209405,
        "bleurt": -0.1125,
        "bertscore": {
            "precision": 0.84185,
            "recall": 0.90906,
            "f1": 0.87417
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1980": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.75
        },
        "nist": 3.0980270595396986,
        "bleu": 52.5382,
        "rouge1": {
            "precision": 0.92593,
            "recall": 0.89167,
            "fmeasure": 0.90609
        },
        "rouge2": {
            "precision": 0.79167,
            "recall": 0.75661,
            "fmeasure": 0.77124
        },
        "rougeL": {
            "precision": 0.92593,
            "recall": 0.89167,
            "fmeasure": 0.90609
        },
        "rougeLsum": {
            "precision": 0.92593,
            "recall": 0.89167,
            "fmeasure": 0.90609
        },
        "nubia": {
            "semantic_relation": 4.86362,
            "contradiction": 0.92393,
            "irrelevancy": 59.89205,
            "logical_agreement": 39.18402,
            "grammar_ref": 6.57473,
            "grammar_hyp": 5.1186,
            "nubia_score": 1.0
        },
        "meteor": 0.44890462185517277,
        "bleurt": 0.38004,
        "bertscore": {
            "precision": 0.97137,
            "recall": 0.91991,
            "f1": 0.94494
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1140": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "nist": 3.8535769082186824,
        "bleu": 76.74162,
        "rouge1": {
            "precision": 0.96154,
            "recall": 0.92857,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.84295,
            "fmeasure": 0.85833
        },
        "rougeL": {
            "precision": 0.80769,
            "recall": 0.78022,
            "fmeasure": 0.79345
        },
        "rougeLsum": {
            "precision": 0.80769,
            "recall": 0.78022,
            "fmeasure": 0.79345
        },
        "nubia": {
            "semantic_relation": 3.73103,
            "contradiction": 47.93643,
            "irrelevancy": 1.84919,
            "logical_agreement": 50.21438,
            "grammar_ref": 2.33019,
            "grammar_hyp": 2.4164,
            "nubia_score": 0.6985
        },
        "meteor": 0.5426177315437225,
        "bleurt": 0.39021,
        "bertscore": {
            "precision": 0.9822,
            "recall": 0.97494,
            "f1": 0.97856
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1773": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 5,
        "mean_pred_length": 5.0,
        "std_pred_length": 0.0,
        "median_pred_length": 5.0,
        "min_pred_length": 5,
        "max_pred_length": 5,
        "distinct-1": 1.0,
        "vocab_size-1": 5,
        "unique-1": 5,
        "entropy-1": 2.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 4,
        "unique-2": 4,
        "entropy-2": 2.0,
        "cond_entropy-2": -0.32192809488736235,
        "distinct-3": 1.0,
        "vocab_size-3": 3,
        "unique-3": 3,
        "entropy-3": 1.584962500721156,
        "cond_entropy-3": -0.4150374992788437,
        "total_length-nopunct": 4,
        "mean_pred_length-nopunct": 4.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 4.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 4,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 4,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 2.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 3,
        "unique-2-nopunct": 3,
        "entropy-2-nopunct": 1.584962500721156,
        "cond_entropy-2-nopunct": -0.4150374992788437,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 2,
        "unique-3-nopunct": 2,
        "entropy-3-nopunct": 1.0,
        "cond_entropy-3-nopunct": -0.5849625007211562,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4
        },
        "nist": 0.41592024599199884,
        "bleu": 7.71549,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.29167,
            "fmeasure": 0.36667
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.14583,
            "fmeasure": 0.18333
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.14583,
            "fmeasure": 0.18333
        },
        "nubia": {
            "semantic_relation": 3.5766,
            "contradiction": 0.9709,
            "irrelevancy": 0.94806,
            "logical_agreement": 98.08103,
            "grammar_ref": 7.18676,
            "grammar_hyp": 8.82795,
            "nubia_score": 0.52038
        },
        "meteor": 0.2243542435424354,
        "bleurt": -0.43641,
        "bertscore": {
            "precision": 0.8716,
            "recall": 0.79534,
            "f1": 0.83173
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1782": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.037537158749660585,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185189,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.7
        },
        "nist": 2.5558417176275143,
        "bleu": 26.21684,
        "rouge1": {
            "precision": 0.5625,
            "recall": 0.47594,
            "fmeasure": 0.51356
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.25149,
            "fmeasure": 0.2724
        },
        "rougeL": {
            "precision": 0.34375,
            "recall": 0.28342,
            "fmeasure": 0.30941
        },
        "rougeLsum": {
            "precision": 0.34375,
            "recall": 0.28342,
            "fmeasure": 0.30941
        },
        "nubia": {
            "semantic_relation": 2.39915,
            "contradiction": 3.06475,
            "irrelevancy": 96.7082,
            "logical_agreement": 0.22706,
            "grammar_ref": 3.66593,
            "grammar_hyp": 3.91447,
            "nubia_score": 0.2415
        },
        "meteor": 0.30240957020118453,
        "bleurt": -0.91594,
        "bertscore": {
            "precision": 0.86685,
            "recall": 0.83628,
            "f1": 0.85129
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1296": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.589898095464287,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.2400991480321905,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.334679141051595,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.2807634077603532,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.6666666666666666
        },
        "nist": 3.6433864755514778,
        "bleu": 36.60592,
        "rouge1": {
            "precision": 0.7381,
            "recall": 0.71652,
            "fmeasure": 0.72299
        },
        "rouge2": {
            "precision": 0.46154,
            "recall": 0.38562,
            "fmeasure": 0.41778
        },
        "rougeL": {
            "precision": 0.7381,
            "recall": 0.63818,
            "fmeasure": 0.68056
        },
        "rougeLsum": {
            "precision": 0.7381,
            "recall": 0.63818,
            "fmeasure": 0.68056
        },
        "nubia": {
            "semantic_relation": 3.70572,
            "contradiction": 0.76012,
            "irrelevancy": 92.0939,
            "logical_agreement": 7.14598,
            "grammar_ref": 5.3293,
            "grammar_hyp": 5.43749,
            "nubia_score": 0.49263
        },
        "meteor": 0.3604596676079415,
        "bleurt": -0.04096,
        "bertscore": {
            "precision": 0.94117,
            "recall": 0.9438,
            "f1": 0.93784
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1141": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.046930949929641655,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.6
        },
        "nist": 2.615262025604985,
        "bleu": 15.3965,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.61869,
            "fmeasure": 0.60024
        },
        "rouge2": {
            "precision": 0.18182,
            "recall": 0.18095,
            "fmeasure": 0.18032
        },
        "rougeL": {
            "precision": 0.38889,
            "recall": 0.39192,
            "fmeasure": 0.38862
        },
        "rougeLsum": {
            "precision": 0.38889,
            "recall": 0.39192,
            "fmeasure": 0.38862
        },
        "nubia": {
            "semantic_relation": 4.68353,
            "contradiction": 0.55602,
            "irrelevancy": 32.19669,
            "logical_agreement": 67.2473,
            "grammar_ref": 4.53537,
            "grammar_hyp": 4.32406,
            "nubia_score": 0.87247
        },
        "meteor": 0.313154029534101,
        "bleurt": 0.25712,
        "bertscore": {
            "precision": 0.90231,
            "recall": 0.93079,
            "f1": 0.91633
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2392": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 49,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 0.9428090415820634,
        "median_pred_length": 17.0,
        "min_pred_length": 15,
        "max_pred_length": 17,
        "distinct-1": 0.4897959183673469,
        "vocab_size-1": 24,
        "unique-1": 7,
        "entropy-1": 4.451045558224314,
        "distinct-2": 0.6304347826086957,
        "vocab_size-2": 29,
        "unique-2": 15,
        "entropy-2": 4.724542662531719,
        "cond_entropy-2": 0.24602113377499887,
        "distinct-3": 0.7209302325581395,
        "vocab_size-3": 31,
        "unique-3": 19,
        "entropy-3": 4.868125219818376,
        "cond_entropy-3": 0.15281646148609587,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 1.4142135623730951,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.47619047619047616,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 4.195539744052797,
        "distinct-2-nopunct": 0.6153846153846154,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 4.445533308550364,
        "cond_entropy-2-nopunct": 0.2501312705349183,
        "distinct-3-nopunct": 0.7222222222222222,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.614369445886756,
        "cond_entropy-3-nopunct": 0.13924292150901732,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "nist": 2.552226661108703,
        "bleu": 23.03749,
        "rouge1": {
            "precision": 0.52308,
            "recall": 0.52525,
            "fmeasure": 0.50586
        },
        "rouge2": {
            "precision": 0.30952,
            "recall": 0.30192,
            "fmeasure": 0.29309
        },
        "rougeL": {
            "precision": 0.43419,
            "recall": 0.40404,
            "fmeasure": 0.4033
        },
        "rougeLsum": {
            "precision": 0.43419,
            "recall": 0.40404,
            "fmeasure": 0.4033
        },
        "nubia": {
            "semantic_relation": 3.44457,
            "contradiction": 0.26898,
            "irrelevancy": 99.16658,
            "logical_agreement": 0.56444,
            "grammar_ref": 4.141,
            "grammar_hyp": 4.72286,
            "nubia_score": 0.45104
        },
        "meteor": 0.2607472936073921,
        "bleurt": -0.04546,
        "bertscore": {
            "precision": 0.83253,
            "recall": 0.87607,
            "f1": 0.85284
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1638": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 11,
        "unique-1": 9,
        "entropy-1": 3.3927474104487847,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.21785611591339743,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.2516291673878226,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.23810548155250455,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "nist": 2.4544666759778946,
        "bleu": 39.83287,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.8963,
            "fmeasure": 0.79942
        },
        "rouge2": {
            "precision": 0.60606,
            "recall": 0.76852,
            "fmeasure": 0.67719
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.8963,
            "fmeasure": 0.79942
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.8963,
            "fmeasure": 0.79942
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.35718,
            "irrelevancy": 0.72381,
            "logical_agreement": 98.91902,
            "grammar_ref": 4.6206,
            "grammar_hyp": 3.91998,
            "nubia_score": 0.96992
        },
        "meteor": 0.909197285279663,
        "bleurt": 0.72015,
        "bertscore": {
            "precision": 0.94956,
            "recall": 0.97508,
            "f1": 0.96215
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3479": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 1.0,
        "vocab_size-1": 20,
        "unique-1": 20,
        "entropy-1": 4.321928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.07400058144377676,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.247927513443583,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.07800251200127316,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9444444444444444
        },
        "nist": 4.131714648834222,
        "bleu": 69.1107,
        "rouge1": {
            "precision": 0.89474,
            "recall": 0.87982,
            "fmeasure": 0.88709
        },
        "rouge2": {
            "precision": 0.75926,
            "recall": 0.74659,
            "fmeasure": 0.75275
        },
        "rougeL": {
            "precision": 0.89474,
            "recall": 0.87982,
            "fmeasure": 0.88709
        },
        "rougeLsum": {
            "precision": 0.89474,
            "recall": 0.87982,
            "fmeasure": 0.88709
        },
        "nubia": {
            "semantic_relation": 4.64554,
            "contradiction": 0.35775,
            "irrelevancy": 0.60574,
            "logical_agreement": 99.0365,
            "grammar_ref": 4.62058,
            "grammar_hyp": 4.55895,
            "nubia_score": 0.87567
        },
        "meteor": 0.49909889384100203,
        "bleurt": 0.74856,
        "bertscore": {
            "precision": 0.9881,
            "recall": 0.98083,
            "f1": 0.98399
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1788": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nist": 2.5259953235721566,
        "bleu": 20.55276,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.58824,
            "fmeasure": 0.625
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.25,
            "fmeasure": 0.26667
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.52941,
            "fmeasure": 0.5625
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.52941,
            "fmeasure": 0.5625
        },
        "nubia": {
            "semantic_relation": 3.67977,
            "contradiction": 0.24521,
            "irrelevancy": 6.18152,
            "logical_agreement": 93.57327,
            "grammar_ref": 4.8802,
            "grammar_hyp": 5.43673,
            "nubia_score": 0.51904
        },
        "meteor": 0.3266075620720411,
        "bleurt": 0.43007,
        "bertscore": {
            "precision": 0.9332,
            "recall": 0.89935,
            "f1": 0.91596
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1640": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.024962841250339415,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6875
        },
        "nist": 2.523357736178485,
        "bleu": 12.41952,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.55,
            "fmeasure": 0.62857
        },
        "rouge2": {
            "precision": 0.35714,
            "recall": 0.26316,
            "fmeasure": 0.30303
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.3,
            "fmeasure": 0.34286
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.3,
            "fmeasure": 0.34286
        },
        "nubia": {
            "semantic_relation": 3.93352,
            "contradiction": 0.37056,
            "irrelevancy": 97.85772,
            "logical_agreement": 1.77172,
            "grammar_ref": 4.55046,
            "grammar_hyp": 5.30838,
            "nubia_score": 0.52005
        },
        "meteor": 0.27290554756543445,
        "bleurt": 0.03633,
        "bertscore": {
            "precision": 0.89209,
            "recall": 0.88613,
            "f1": 0.88902
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3492": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7272727272727273
        },
        "nist": 2.6996390168973416,
        "bleu": 52.6561,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.66667,
            "fmeasure": 0.72727
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.54545,
            "fmeasure": 0.6
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.66667,
            "fmeasure": 0.72727
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.66667,
            "fmeasure": 0.72727
        },
        "nubia": {
            "semantic_relation": 4.13086,
            "contradiction": 0.63106,
            "irrelevancy": 21.16836,
            "logical_agreement": 78.20058,
            "grammar_ref": 4.14586,
            "grammar_hyp": 3.4501,
            "nubia_score": 0.86642
        },
        "meteor": 0.4000589570944282,
        "bleurt": 0.54722,
        "bertscore": {
            "precision": 0.96234,
            "recall": 0.94385,
            "f1": 0.95301
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3540": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.462425934400558,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.90476,
            "fmeasure": 0.92308
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "nubia": {
            "semantic_relation": 4.21715,
            "contradiction": 0.42269,
            "irrelevancy": 0.62596,
            "logical_agreement": 98.95136,
            "grammar_ref": 6.37596,
            "grammar_hyp": 6.07415,
            "nubia_score": 0.84205
        },
        "meteor": 1.0,
        "bleurt": 0.45919,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1302": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.5555555555555556
        },
        "nist": 1.259375898165659,
        "bleu": 23.09472,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.56173,
            "fmeasure": 0.68372
        },
        "rouge2": {
            "precision": 0.57778,
            "recall": 0.38785,
            "fmeasure": 0.46394
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.5303,
            "fmeasure": 0.62105
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.5303,
            "fmeasure": 0.62105
        },
        "nubia": {
            "semantic_relation": 3.85327,
            "contradiction": 0.17167,
            "irrelevancy": 33.45547,
            "logical_agreement": 66.37286,
            "grammar_ref": 3.86337,
            "grammar_hyp": 3.58191,
            "nubia_score": 0.72381
        },
        "meteor": 0.32038272111982113,
        "bleurt": 0.18008,
        "bertscore": {
            "precision": 0.96471,
            "recall": 0.89731,
            "f1": 0.92814
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5550": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "nist": 1.361654166907052,
        "bleu": 8.51659,
        "rouge1": {
            "precision": 0.36364,
            "recall": 0.44444,
            "fmeasure": 0.4
        },
        "rouge2": {
            "precision": 0.1,
            "recall": 0.125,
            "fmeasure": 0.11111
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.44444,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.44444,
            "fmeasure": 0.4
        },
        "nubia": {
            "semantic_relation": 4.65827,
            "contradiction": 0.0754,
            "irrelevancy": 8.41041,
            "logical_agreement": 91.51419,
            "grammar_ref": 4.6877,
            "grammar_hyp": 4.66268,
            "nubia_score": 0.86866
        },
        "meteor": 0.25126759644615476,
        "bleurt": 0.2819,
        "bertscore": {
            "precision": 0.84036,
            "recall": 0.8504,
            "f1": 0.84535
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2400": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7735572622751845,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.6
        },
        "nist": 1.8290414066556506,
        "bleu": 6.91718,
        "rouge1": {
            "precision": 0.46667,
            "recall": 0.63636,
            "fmeasure": 0.53846
        },
        "rouge2": {
            "precision": 0.07143,
            "recall": 0.1,
            "fmeasure": 0.08333
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.45455,
            "fmeasure": 0.38462
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.45455,
            "fmeasure": 0.38462
        },
        "nubia": {
            "semantic_relation": 3.88244,
            "contradiction": 0.09661,
            "irrelevancy": 99.71912,
            "logical_agreement": 0.18427,
            "grammar_ref": 5.42176,
            "grammar_hyp": 4.76828,
            "nubia_score": 0.62173
        },
        "meteor": 0.27177234747117585,
        "bleurt": -0.01206,
        "bertscore": {
            "precision": 0.78475,
            "recall": 0.84776,
            "f1": 0.81504
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1656": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5833333333333334
        },
        "nist": 2.2141962401646635,
        "bleu": 9.62102,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.53846,
            "fmeasure": 0.56
        },
        "rouge2": {
            "precision": 0.18182,
            "recall": 0.16667,
            "fmeasure": 0.17391
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.38462,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.38462,
            "fmeasure": 0.4
        },
        "nubia": {
            "semantic_relation": 4.40445,
            "contradiction": 0.55238,
            "irrelevancy": 82.87155,
            "logical_agreement": 16.57607,
            "grammar_ref": 3.76485,
            "grammar_hyp": 3.97554,
            "nubia_score": 0.82723
        },
        "meteor": 0.2697029506830848,
        "bleurt": 0.33558,
        "bertscore": {
            "precision": 0.86305,
            "recall": 0.86497,
            "f1": 0.86401
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 256,
        "total_length": 6377,
        "mean_pred_length": 24.91015625,
        "std_pred_length": 3.0878628289783108,
        "median_pred_length": 25.0,
        "min_pred_length": 15,
        "max_pred_length": 31,
        "distinct-1": 0.09330406147091108,
        "vocab_size-1": 595,
        "unique-1": 253,
        "entropy-1": 7.206957180844803,
        "distinct-2": 0.29815389642215323,
        "vocab_size-2": 1825,
        "unique-2": 1015,
        "entropy-2": 9.760209484604282,
        "cond_entropy-2": 2.572238550143295,
        "distinct-3": 0.528388746803069,
        "vocab_size-3": 3099,
        "unique-3": 2193,
        "entropy-3": 10.995158660722323,
        "cond_entropy-3": 1.273129247821244,
        "total_length-nopunct": 5950,
        "mean_pred_length-nopunct": 23.2421875,
        "std_pred_length-nopunct": 2.9692331021399703,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.09865546218487395,
        "vocab_size-1-nopunct": 587,
        "unique-1-nopunct": 251,
        "entropy-1-nopunct": 7.2098545547632815,
        "distinct-2-nopunct": 0.3085704250087812,
        "vocab_size-2-nopunct": 1757,
        "unique-2-nopunct": 1001,
        "entropy-2-nopunct": 9.695958844905928,
        "cond_entropy-2-nopunct": 2.5552814316891928,
        "distinct-3-nopunct": 0.5360426627436558,
        "vocab_size-3-nopunct": 2915,
        "unique-3-nopunct": 2088,
        "entropy-3-nopunct": 10.89699573650284,
        "cond_entropy-3-nopunct": 1.244274687488591,
        "msttr-100": 0.63873,
        "msttr-100_nopunct": 0.63661,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5588846039750816
        },
        "nist": 4.919904766994537,
        "bleu": 28.01656,
        "rouge1": {
            "precision": 0.70651,
            "recall": 0.57055,
            "fmeasure": 0.62313
        },
        "rouge2": {
            "precision": 0.4572,
            "recall": 0.36857,
            "fmeasure": 0.4024
        },
        "rougeL": {
            "precision": 0.58908,
            "recall": 0.47424,
            "fmeasure": 0.5187
        },
        "rougeLsum": {
            "precision": 0.58908,
            "recall": 0.47424,
            "fmeasure": 0.5187
        },
        "nubia": {
            "semantic_relation": 3.70712,
            "contradiction": 5.50853,
            "irrelevancy": 17.08749,
            "logical_agreement": 77.40398,
            "grammar_ref": 4.19274,
            "grammar_hyp": 4.3413,
            "nubia_score": 0.56632
        },
        "meteor": 0.3006930139706148,
        "bleurt": -0.20563,
        "bertscore": {
            "precision": 0.89516,
            "recall": 0.866,
            "f1": 0.88002
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3546": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 4.567897103570576,
        "bleu": 79.28586,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rougeL": {
            "precision": 0.9375,
            "recall": 0.9375,
            "fmeasure": 0.9375
        },
        "rougeLsum": {
            "precision": 0.9375,
            "recall": 0.9375,
            "fmeasure": 0.9375
        },
        "nubia": {
            "semantic_relation": 4.77002,
            "contradiction": 0.12889,
            "irrelevancy": 33.55525,
            "logical_agreement": 66.31586,
            "grammar_ref": 4.41465,
            "grammar_hyp": 4.38147,
            "nubia_score": 0.92634
        },
        "meteor": 0.5390173114622395,
        "bleurt": 0.65449,
        "bertscore": {
            "precision": 0.98764,
            "recall": 0.98437,
            "f1": 0.986
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2040": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 3.0,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 19,
        "distinct-1": 0.625,
        "vocab_size-1": 20,
        "unique-1": 11,
        "entropy-1": 4.163909765557392,
        "distinct-2": 0.7666666666666667,
        "vocab_size-2": 23,
        "unique-2": 16,
        "entropy-2": 4.440223928941852,
        "cond_entropy-2": 0.22638934563255705,
        "distinct-3": 0.8214285714285714,
        "vocab_size-3": 23,
        "unique-3": 18,
        "entropy-3": 4.450212064914748,
        "cond_entropy-3": 0.043321469306228495,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6551724137931034,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 4.0993603054724,
        "distinct-2-nopunct": 0.7407407407407407,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 4.236368983644952,
        "cond_entropy-2-nopunct": 0.15616576629515583,
        "distinct-3-nopunct": 0.8,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 4.243856189774723,
        "cond_entropy-3-nopunct": 0.008968687611256052,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.75,
            "3": 0.9565217391304348
        },
        "nist": 5.0231828457761205,
        "bleu": 87.61561,
        "rouge1": {
            "precision": 0.9567,
            "recall": 0.93106,
            "fmeasure": 0.94337
        },
        "rouge2": {
            "precision": 0.9536,
            "recall": 0.92582,
            "fmeasure": 0.93911
        },
        "rougeL": {
            "precision": 0.9567,
            "recall": 0.93106,
            "fmeasure": 0.94337
        },
        "rougeLsum": {
            "precision": 0.9567,
            "recall": 0.93106,
            "fmeasure": 0.94337
        },
        "nubia": {
            "semantic_relation": 4.26852,
            "contradiction": 37.26383,
            "irrelevancy": 33.89224,
            "logical_agreement": 28.84393,
            "grammar_ref": 4.08754,
            "grammar_hyp": 3.85271,
            "nubia_score": 0.79475
        },
        "meteor": 0.5500189041722019,
        "bleurt": 0.43983,
        "bertscore": {
            "precision": 0.98627,
            "recall": 0.96742,
            "f1": 0.97669
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 46,
        "total_length": 1126,
        "mean_pred_length": 24.47826086956522,
        "std_pred_length": 3.4624641290547036,
        "median_pred_length": 25.0,
        "min_pred_length": 18,
        "max_pred_length": 30,
        "distinct-1": 0.16429840142095914,
        "vocab_size-1": 185,
        "unique-1": 74,
        "entropy-1": 6.362211204403177,
        "distinct-2": 0.4361111111111111,
        "vocab_size-2": 471,
        "unique-2": 273,
        "entropy-2": 8.20287473578797,
        "cond_entropy-2": 1.8448953105738481,
        "distinct-3": 0.6305609284332688,
        "vocab_size-3": 652,
        "unique-3": 476,
        "entropy-3": 8.998494875627461,
        "cond_entropy-3": 0.808609553510897,
        "total_length-nopunct": 1056,
        "mean_pred_length-nopunct": 22.956521739130434,
        "std_pred_length-nopunct": 3.148198392587835,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.17140151515151514,
        "vocab_size-1-nopunct": 181,
        "unique-1-nopunct": 74,
        "entropy-1-nopunct": 6.316730761874326,
        "distinct-2-nopunct": 0.4396039603960396,
        "vocab_size-2-nopunct": 444,
        "unique-2-nopunct": 260,
        "entropy-2-nopunct": 8.111157717156562,
        "cond_entropy-2-nopunct": 1.8241839727363418,
        "distinct-3-nopunct": 0.6317427385892116,
        "vocab_size-3-nopunct": 609,
        "unique-3-nopunct": 448,
        "entropy-3-nopunct": 8.892344751260508,
        "cond_entropy-3-nopunct": 0.8102319213128223,
        "msttr-100": 0.56091,
        "msttr-100_nopunct": 0.55,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5772089182493807
        },
        "nist": 4.381190369701281,
        "bleu": 30.40059,
        "rouge1": {
            "precision": 0.71534,
            "recall": 0.60852,
            "fmeasure": 0.64371
        },
        "rouge2": {
            "precision": 0.46167,
            "recall": 0.40462,
            "fmeasure": 0.42223
        },
        "rougeL": {
            "precision": 0.58034,
            "recall": 0.50428,
            "fmeasure": 0.5286
        },
        "rougeLsum": {
            "precision": 0.58034,
            "recall": 0.50428,
            "fmeasure": 0.5286
        },
        "nubia": {
            "semantic_relation": 3.90016,
            "contradiction": 15.82624,
            "irrelevancy": 18.07162,
            "logical_agreement": 66.10215,
            "grammar_ref": 4.5797,
            "grammar_hyp": 4.74469,
            "nubia_score": 0.59226
        },
        "meteor": 0.296340093647174,
        "bleurt": -0.18086,
        "bertscore": {
            "precision": 0.89716,
            "recall": 0.87498,
            "f1": 0.88549
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5656": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 1.0,
        "median_pred_length": 15.0,
        "min_pred_length": 14,
        "max_pred_length": 16,
        "distinct-1": 0.9,
        "vocab_size-1": 27,
        "unique-1": 24,
        "entropy-1": 4.7068905956085185,
        "distinct-2": 0.9642857142857143,
        "vocab_size-2": 27,
        "unique-2": 26,
        "entropy-2": 4.735926350629034,
        "cond_entropy-2": -0.028107102122342922,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.029992126993435266,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.546593564294937,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.501629167387823,
        "cond_entropy-2-nopunct": -0.032143884086602556,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.03462179117476819,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.8947368421052632
        },
        "nist": 3.6355683587498597,
        "bleu": 55.18712,
        "rouge1": {
            "precision": 0.67842,
            "recall": 0.76852,
            "fmeasure": 0.71673
        },
        "rouge2": {
            "precision": 0.5947,
            "recall": 0.66389,
            "fmeasure": 0.62381
        },
        "rougeL": {
            "precision": 0.67842,
            "recall": 0.76852,
            "fmeasure": 0.71673
        },
        "rougeLsum": {
            "precision": 0.67842,
            "recall": 0.76852,
            "fmeasure": 0.71673
        },
        "nubia": {
            "semantic_relation": 4.78261,
            "contradiction": 0.26157,
            "irrelevancy": 21.83348,
            "logical_agreement": 77.90494,
            "grammar_ref": 6.17452,
            "grammar_hyp": 5.41481,
            "nubia_score": 0.92238
        },
        "meteor": 0.43455495471070577,
        "bleurt": 0.42049,
        "bertscore": {
            "precision": 0.92198,
            "recall": 0.92159,
            "f1": 0.92061
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1304": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.85,
        "vocab_size-1": 17,
        "unique-1": 14,
        "entropy-1": 4.021928094887363,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 18,
        "unique-2": 17,
        "entropy-2": 4.142664355548846,
        "cond_entropy-2": 0.13652573434569687,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": 0.03310859910983796,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.9321380397593733,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.058813890331201,
        "cond_entropy-2-nopunct": 0.14421971022094898,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": 0.03518489863155644,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2,
            "3": 0.9
        },
        "nist": 3.304684081583286,
        "bleu": 29.19355,
        "rouge1": {
            "precision": 0.69697,
            "recall": 0.92063,
            "fmeasure": 0.7886
        },
        "rouge2": {
            "precision": 0.5873,
            "recall": 0.80238,
            "fmeasure": 0.6741
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.72381,
            "fmeasure": 0.61848
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.72381,
            "fmeasure": 0.61848
        },
        "nubia": {
            "semantic_relation": 3.77838,
            "contradiction": 0.08677,
            "irrelevancy": 99.66686,
            "logical_agreement": 0.24638,
            "grammar_ref": 3.44293,
            "grammar_hyp": 3.24527,
            "nubia_score": 0.76497
        },
        "meteor": 0.4712318754035105,
        "bleurt": 0.21297,
        "bertscore": {
            "precision": 0.87558,
            "recall": 0.96198,
            "f1": 0.91
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2080": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.8,
        "vocab_size-1": 20,
        "unique-1": 16,
        "entropy-1": 4.213660689688184,
        "distinct-2": 0.9583333333333334,
        "vocab_size-2": 23,
        "unique-2": 22,
        "entropy-2": 4.501629167387823,
        "cond_entropy-2": 0.30589329020324285,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": 0.02555597707498716,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8095238095238095,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.975418017913832,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.3673550472167754,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.4,
            "3": 0.45
        },
        "nist": 3.1356862377493124,
        "bleu": 17.2437,
        "rouge1": {
            "precision": 0.56522,
            "recall": 0.4433,
            "fmeasure": 0.49686
        },
        "rouge2": {
            "precision": 0.31818,
            "recall": 0.23333,
            "fmeasure": 0.26854
        },
        "rougeL": {
            "precision": 0.52174,
            "recall": 0.4092,
            "fmeasure": 0.45864
        },
        "rougeLsum": {
            "precision": 0.52174,
            "recall": 0.4092,
            "fmeasure": 0.45864
        },
        "nubia": {
            "semantic_relation": 2.84986,
            "contradiction": 26.59084,
            "irrelevancy": 3.9328,
            "logical_agreement": 69.47636,
            "grammar_ref": 5.53052,
            "grammar_hyp": 4.59885,
            "nubia_score": 0.42826
        },
        "meteor": 0.2274979754257273,
        "bleurt": -0.48871,
        "bertscore": {
            "precision": 0.87463,
            "recall": 0.81485,
            "f1": 0.84368
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-2": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 1397,
        "total_length": 26701,
        "mean_pred_length": 19.11309949892627,
        "std_pred_length": 5.402889698409361,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 33,
        "distinct-1": 0.06688888056627093,
        "vocab_size-1": 1786,
        "unique-1": 850,
        "entropy-1": 7.580176132559666,
        "distinct-2": 0.22664400885235536,
        "vocab_size-2": 5735,
        "unique-2": 3499,
        "entropy-2": 10.463317007333902,
        "cond_entropy-2": 2.801755911297566,
        "distinct-3": 0.41569414815744343,
        "vocab_size-3": 9938,
        "unique-3": 7196,
        "entropy-3": 11.968247570064053,
        "cond_entropy-3": 1.5133320456020767,
        "total_length-nopunct": 24206,
        "mean_pred_length-nopunct": 17.327129563350034,
        "std_pred_length-nopunct": 5.2504560111155385,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.07320499049822358,
        "vocab_size-1-nopunct": 1772,
        "unique-1-nopunct": 847,
        "entropy-1-nopunct": 7.64105304125683,
        "distinct-2-nopunct": 0.24332500328817572,
        "vocab_size-2-nopunct": 5550,
        "unique-2-nopunct": 3460,
        "entropy-2-nopunct": 10.436402082066143,
        "cond_entropy-2-nopunct": 2.8635011493082545,
        "distinct-3-nopunct": 0.438632542499533,
        "vocab_size-3-nopunct": 9392,
        "unique-3-nopunct": 6921,
        "entropy-3-nopunct": 11.930404581359129,
        "cond_entropy-3-nopunct": 1.5179252637034135,
        "msttr-100": 0.64187,
        "msttr-100_nopunct": 0.64793,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6305815372102481
        },
        "nist": 6.899106204006438,
        "bleu": 36.12943,
        "rouge1": {
            "precision": 0.68275,
            "recall": 0.64392,
            "fmeasure": 0.65137
        },
        "rouge2": {
            "precision": 0.46815,
            "recall": 0.44252,
            "fmeasure": 0.44685
        },
        "rougeL": {
            "precision": 0.59005,
            "recall": 0.55777,
            "fmeasure": 0.56374
        },
        "rougeLsum": {
            "precision": 0.59005,
            "recall": 0.55777,
            "fmeasure": 0.56374
        },
        "nubia": {
            "semantic_relation": 4.1234,
            "contradiction": 3.43582,
            "irrelevancy": 19.40055,
            "logical_agreement": 77.16363,
            "grammar_ref": 4.97201,
            "grammar_hyp": 4.96713,
            "nubia_score": 0.6969
        },
        "meteor": 0.342998900462454,
        "bleurt": -0.06918,
        "bertscore": {
            "precision": 0.88695,
            "recall": 0.87982,
            "f1": 0.88294
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6225": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 1.0,
        "vocab_size-1": 22,
        "unique-1": 22,
        "entropy-1": 4.459431618637295,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": -0.06711419585853673,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.07400058144377676,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.1,
            "3": 0.8181818181818182
        },
        "nist": 3.153597888210301,
        "bleu": 11.23785,
        "rouge1": {
            "precision": 0.59091,
            "recall": 0.61905,
            "fmeasure": 0.60465
        },
        "rouge2": {
            "precision": 0.2381,
            "recall": 0.25,
            "fmeasure": 0.2439
        },
        "rougeL": {
            "precision": 0.39394,
            "recall": 0.4127,
            "fmeasure": 0.4031
        },
        "rougeLsum": {
            "precision": 0.39394,
            "recall": 0.4127,
            "fmeasure": 0.4031
        },
        "nubia": {
            "semantic_relation": 4.28204,
            "contradiction": 0.1321,
            "irrelevancy": 93.87162,
            "logical_agreement": 5.99628,
            "grammar_ref": 3.9898,
            "grammar_hyp": 4.75256,
            "nubia_score": 0.67167
        },
        "meteor": 0.30538143191249223,
        "bleurt": 0.2161,
        "bertscore": {
            "precision": 0.88152,
            "recall": 0.89238,
            "f1": 0.88535
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3591": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.6875,
        "vocab_size-1": 11,
        "unique-1": 7,
        "entropy-1": 3.327819531114783,
        "distinct-2": 0.8,
        "vocab_size-2": 12,
        "unique-2": 9,
        "entropy-2": 3.5068905956085183,
        "cond_entropy-2": 0.22388309575274978,
        "distinct-3": 0.9285714285714286,
        "vocab_size-3": 13,
        "unique-3": 12,
        "entropy-3": 3.6644977792004623,
        "cond_entropy-3": 0.18617861216337128,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.6153846153846154,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 2.873140679513133,
        "distinct-2-nopunct": 0.75,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 3.084962500721156,
        "cond_entropy-2-nopunct": 0.2807634077603532,
        "distinct-3-nopunct": 0.9090909090909091,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.2776134368191165,
        "cond_entropy-3-nopunct": 0.23810548155250458,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 2.335875509205763,
        "bleu": 48.41525,
        "rouge1": {
            "precision": 0.69231,
            "recall": 1.0,
            "fmeasure": 0.81818
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 1.0,
            "fmeasure": 0.8
        },
        "rougeL": {
            "precision": 0.69231,
            "recall": 1.0,
            "fmeasure": 0.81818
        },
        "rougeLsum": {
            "precision": 0.69231,
            "recall": 1.0,
            "fmeasure": 0.81818
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 2.80225,
            "irrelevancy": 2.20481,
            "logical_agreement": 94.99294,
            "grammar_ref": 7.00423,
            "grammar_hyp": 4.8462,
            "nubia_score": 1.0
        },
        "meteor": 0.5158883169898099,
        "bleurt": 0.72955,
        "bertscore": {
            "precision": 0.94806,
            "recall": 0.97904,
            "f1": 0.9633
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2104": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "nist": 1.0545733173664176,
        "bleu": 8.89896,
        "rouge1": {
            "precision": 0.74074,
            "recall": 0.425,
            "fmeasure": 0.54
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.20952,
            "fmeasure": 0.26877
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.38431,
            "fmeasure": 0.48718
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.38431,
            "fmeasure": 0.48718
        },
        "nubia": {
            "semantic_relation": 2.66084,
            "contradiction": 98.7718,
            "irrelevancy": 0.90169,
            "logical_agreement": 0.3265,
            "grammar_ref": 4.68072,
            "grammar_hyp": 5.02104,
            "nubia_score": 0.19971
        },
        "meteor": 0.18531240129047372,
        "bleurt": -0.46112,
        "bertscore": {
            "precision": 0.88086,
            "recall": 0.79858,
            "f1": 0.83563
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6643": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 5,
        "mean_pred_length": 5.0,
        "std_pred_length": 0.0,
        "median_pred_length": 5.0,
        "min_pred_length": 5,
        "max_pred_length": 5,
        "distinct-1": 1.0,
        "vocab_size-1": 5,
        "unique-1": 5,
        "entropy-1": 2.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 4,
        "unique-2": 4,
        "entropy-2": 2.0,
        "cond_entropy-2": -0.32192809488736235,
        "distinct-3": 1.0,
        "vocab_size-3": 3,
        "unique-3": 3,
        "entropy-3": 1.584962500721156,
        "cond_entropy-3": -0.4150374992788437,
        "total_length-nopunct": 4,
        "mean_pred_length-nopunct": 4.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 4.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 4,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 4,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 2.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 3,
        "unique-2-nopunct": 3,
        "entropy-2-nopunct": 1.584962500721156,
        "cond_entropy-2-nopunct": -0.4150374992788437,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 2,
        "unique-3-nopunct": 2,
        "entropy-3-nopunct": 1.0,
        "cond_entropy-3-nopunct": -0.5849625007211562,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "nist": 1.3934338964335204,
        "bleu": 28.6419,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.2,
            "fmeasure": 0.25
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "nubia": {
            "semantic_relation": 4.93787,
            "contradiction": 0.30154,
            "irrelevancy": 0.49604,
            "logical_agreement": 99.20242,
            "grammar_ref": 5.72796,
            "grammar_hyp": 7.07513,
            "nubia_score": 0.79132
        },
        "meteor": 0.4307001776843669,
        "bleurt": 0.82527,
        "bertscore": {
            "precision": 0.97397,
            "recall": 0.93815,
            "f1": 0.95573
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3612": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 1.0,
        "vocab_size-1": 24,
        "unique-1": 24,
        "entropy-1": 4.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": -0.061400544664143256,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.07400058144377676,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.2,
            "3": 0.8
        },
        "nist": 3.6683476094025633,
        "bleu": 17.47829,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.57937,
            "fmeasure": 0.58943
        },
        "rouge2": {
            "precision": 0.31579,
            "recall": 0.30833,
            "fmeasure": 0.3116
        },
        "rougeL": {
            "precision": 0.48333,
            "recall": 0.46587,
            "fmeasure": 0.47439
        },
        "rougeLsum": {
            "precision": 0.48333,
            "recall": 0.46587,
            "fmeasure": 0.47439
        },
        "nubia": {
            "semantic_relation": 3.83731,
            "contradiction": 48.44623,
            "irrelevancy": 37.82425,
            "logical_agreement": 13.72952,
            "grammar_ref": 5.50536,
            "grammar_hyp": 5.27401,
            "nubia_score": 0.57006
        },
        "meteor": 0.369560013188906,
        "bleurt": -0.21515,
        "bertscore": {
            "precision": 0.89038,
            "recall": 0.91393,
            "f1": 0.902
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-3": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 983,
        "total_length": 5797,
        "mean_pred_length": 5.897253306205493,
        "std_pred_length": 1.9996496600394746,
        "median_pred_length": 5.0,
        "min_pred_length": 2,
        "max_pred_length": 19,
        "distinct-1": 0.0255304467828187,
        "vocab_size-1": 148,
        "unique-1": 52,
        "entropy-1": 4.61511045689412,
        "distinct-2": 0.07685916078105526,
        "vocab_size-2": 370,
        "unique-2": 174,
        "entropy-2": 5.875174265516254,
        "cond_entropy-2": 1.0296654669851117,
        "distinct-3": 0.1297311406943357,
        "vocab_size-3": 497,
        "unique-3": 265,
        "entropy-3": 6.779645985558892,
        "cond_entropy-3": 0.7528844503596183,
        "total_length-nopunct": 4621,
        "mean_pred_length-nopunct": 4.700915564598169,
        "std_pred_length-nopunct": 1.635711951099691,
        "median_pred_length-nopunct": 4.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.03094568275265094,
        "vocab_size-1-nopunct": 143,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 4.548906931324151,
        "distinct-2-nopunct": 0.08411214953271028,
        "vocab_size-2-nopunct": 306,
        "unique-2-nopunct": 153,
        "entropy-2-nopunct": 5.583769004480444,
        "cond_entropy-2-nopunct": 0.9130822931848145,
        "distinct-3-nopunct": 0.13403614457831325,
        "vocab_size-3-nopunct": 356,
        "unique-3-nopunct": 199,
        "entropy-3-nopunct": 6.137135183097477,
        "cond_entropy-3-nopunct": 0.6807114221319465,
        "msttr-100": 0.29737,
        "msttr-100_nopunct": 0.30348,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.4590023549561122
        },
        "nist": 2.5684717725058785,
        "bleu": 26.24106,
        "rouge1": {
            "precision": 0.48232,
            "recall": 0.4764,
            "fmeasure": 0.47013
        },
        "rouge2": {
            "precision": 0.31326,
            "recall": 0.30855,
            "fmeasure": 0.30491
        },
        "rougeL": {
            "precision": 0.48102,
            "recall": 0.47509,
            "fmeasure": 0.46885
        },
        "rougeLsum": {
            "precision": 0.48102,
            "recall": 0.47509,
            "fmeasure": 0.46885
        },
        "nubia": {
            "semantic_relation": 2.96119,
            "contradiction": 3.83054,
            "irrelevancy": 27.46034,
            "logical_agreement": 68.70912,
            "grammar_ref": 4.77701,
            "grammar_hyp": 4.67104,
            "nubia_score": 0.54881
        },
        "meteor": 0.2569368650112586,
        "bleurt": 0.06217,
        "bertscore": {
            "precision": 0.84686,
            "recall": 0.84596,
            "f1": 0.84598
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8082": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.144219710220949,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.15283195745508585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5833333333333334
        },
        "nist": 1.573459197543666,
        "bleu": 21.31457,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.75,
            "fmeasure": 0.6
        },
        "rouge2": {
            "precision": 0.35294,
            "recall": 0.54545,
            "fmeasure": 0.42857
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.5,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.5,
            "fmeasure": 0.4
        },
        "nubia": {
            "semantic_relation": 3.91109,
            "contradiction": 0.62604,
            "irrelevancy": 96.84184,
            "logical_agreement": 2.53211,
            "grammar_ref": 4.44512,
            "grammar_hyp": 4.36587,
            "nubia_score": 0.63303
        },
        "meteor": 0.3753510566691571,
        "bleurt": -0.17518,
        "bertscore": {
            "precision": 0.8477,
            "recall": 0.90439,
            "f1": 0.87297
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3720": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 1.5,
        "median_pred_length": 15.5,
        "min_pred_length": 14,
        "max_pred_length": 17,
        "distinct-1": 0.6129032258064516,
        "vocab_size-1": 19,
        "unique-1": 9,
        "entropy-1": 4.11548663296752,
        "distinct-2": 0.7241379310344828,
        "vocab_size-2": 21,
        "unique-2": 13,
        "entropy-2": 4.306256857196538,
        "cond_entropy-2": 0.1796467537062143,
        "distinct-3": 0.8148148148148148,
        "vocab_size-3": 22,
        "unique-3": 17,
        "entropy-3": 4.3845171317931,
        "cond_entropy-3": 0.04505465518404472,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.6521739130434783,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.82790978214397,
        "distinct-2-nopunct": 0.7619047619047619,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.916126946588283,
        "cond_entropy-2-nopunct": 0.059231657197938034,
        "distinct-3-nopunct": 0.8421052631578947,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.9321380397593733,
        "cond_entropy-3-nopunct": -0.03912675144043809,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9565217391304348
        },
        "nist": 4.725958657424895,
        "bleu": 88.23314,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nubia": {
            "semantic_relation": 4.59491,
            "contradiction": 0.51227,
            "irrelevancy": 10.44657,
            "logical_agreement": 89.04116,
            "grammar_ref": 4.1188,
            "grammar_hyp": 4.00862,
            "nubia_score": 0.9067
        },
        "meteor": 0.5463176402057991,
        "bleurt": 0.56181,
        "bertscore": {
            "precision": 0.99215,
            "recall": 0.94723,
            "f1": 0.96862
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-4": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 1027,
        "total_length": 10729,
        "mean_pred_length": 10.446932814021421,
        "std_pred_length": 4.477560392394565,
        "median_pred_length": 9.0,
        "min_pred_length": 1,
        "max_pred_length": 28,
        "distinct-1": 0.11333768291546277,
        "vocab_size-1": 1216,
        "unique-1": 650,
        "entropy-1": 7.446255611969065,
        "distinct-2": 0.33230261801690375,
        "vocab_size-2": 3224,
        "unique-2": 2053,
        "entropy-2": 10.382979285287991,
        "cond_entropy-2": 2.5672359070134245,
        "distinct-3": 0.5408022130013831,
        "vocab_size-3": 4692,
        "unique-3": 3461,
        "entropy-3": 11.514893009087409,
        "cond_entropy-3": 1.1824753390004281,
        "total_length-nopunct": 9247,
        "mean_pred_length-nopunct": 9.003894839337878,
        "std_pred_length-nopunct": 4.213390859185903,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.13042067697631665,
        "vocab_size-1-nopunct": 1206,
        "unique-1-nopunct": 649,
        "entropy-1-nopunct": 7.741427987114983,
        "distinct-2-nopunct": 0.34683698296836984,
        "vocab_size-2-nopunct": 2851,
        "unique-2-nopunct": 1835,
        "entropy-2-nopunct": 10.238301019269713,
        "cond_entropy-2-nopunct": 2.7479593744800055,
        "distinct-3-nopunct": 0.5606671299513551,
        "vocab_size-3-nopunct": 4034,
        "unique-3-nopunct": 3046,
        "entropy-3-nopunct": 11.308396097193866,
        "cond_entropy-3-nopunct": 1.20284130266424,
        "msttr-100": 0.63486,
        "msttr-100_nopunct": 0.67565,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6295519752813948
        },
        "nist": 7.299737996613284,
        "bleu": 44.72209,
        "rouge1": {
            "precision": 0.66894,
            "recall": 0.6549,
            "fmeasure": 0.65123
        },
        "rouge2": {
            "precision": 0.46663,
            "recall": 0.4575,
            "fmeasure": 0.45256
        },
        "rougeL": {
            "precision": 0.60592,
            "recall": 0.59262,
            "fmeasure": 0.58936
        },
        "rougeLsum": {
            "precision": 0.60592,
            "recall": 0.59262,
            "fmeasure": 0.58936
        },
        "nubia": {
            "semantic_relation": 4.11515,
            "contradiction": 3.82813,
            "irrelevancy": 18.52044,
            "logical_agreement": 77.65144,
            "grammar_ref": 4.86642,
            "grammar_hyp": 4.84033,
            "nubia_score": 0.7559
        },
        "meteor": 0.37710226799040436,
        "bleurt": 0.16597,
        "bertscore": {
            "precision": 0.90205,
            "recall": 0.89924,
            "f1": 0.90027
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8822": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 3.0,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 17,
        "distinct-1": 0.7857142857142857,
        "vocab_size-1": 22,
        "unique-1": 17,
        "entropy-1": 4.351823225551767,
        "distinct-2": 0.8846153846153846,
        "vocab_size-2": 23,
        "unique-2": 20,
        "entropy-2": 4.46967048737186,
        "cond_entropy-2": 0.0759650846282366,
        "distinct-3": 0.9166666666666666,
        "vocab_size-3": 22,
        "unique-3": 20,
        "entropy-3": 4.418295834054489,
        "cond_entropy-3": -0.03214388408660256,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8076923076923077,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.286790198827111,
        "distinct-2-nopunct": 0.875,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.334962500721156,
        "cond_entropy-2-nopunct": 0.08264309517020867,
        "distinct-3-nopunct": 0.9090909090909091,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.277613436819114,
        "cond_entropy-3-nopunct": -0.03462179117476819,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.5,
            "3": 0.8666666666666667
        },
        "nist": 3.175687036731989,
        "bleu": 17.17143,
        "rouge1": {
            "precision": 0.62917,
            "recall": 0.73769,
            "fmeasure": 0.66747
        },
        "rouge2": {
            "precision": 0.34444,
            "recall": 0.38194,
            "fmeasure": 0.35725
        },
        "rougeL": {
            "precision": 0.57708,
            "recall": 0.71481,
            "fmeasure": 0.62667
        },
        "rougeLsum": {
            "precision": 0.57708,
            "recall": 0.71481,
            "fmeasure": 0.62667
        },
        "nubia": {
            "semantic_relation": 4.17843,
            "contradiction": 0.5049,
            "irrelevancy": 43.23392,
            "logical_agreement": 56.26119,
            "grammar_ref": 5.12311,
            "grammar_hyp": 3.86771,
            "nubia_score": 0.79185
        },
        "meteor": 0.39096613675142927,
        "bleurt": 0.33866,
        "bertscore": {
            "precision": 0.90986,
            "recall": 0.90408,
            "f1": 0.90547
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1792": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.875
        },
        "nist": 3.0519474393426598,
        "bleu": 55.58273,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.77273,
            "fmeasure": 0.87179
        },
        "rouge2": {
            "precision": 0.85417,
            "recall": 0.65079,
            "fmeasure": 0.73874
        },
        "rougeL": {
            "precision": 0.94118,
            "recall": 0.72727,
            "fmeasure": 0.82051
        },
        "rougeLsum": {
            "precision": 0.94118,
            "recall": 0.72727,
            "fmeasure": 0.82051
        },
        "nubia": {
            "semantic_relation": 4.20613,
            "contradiction": 0.8828,
            "irrelevancy": 32.25646,
            "logical_agreement": 66.86074,
            "grammar_ref": 3.23206,
            "grammar_hyp": 3.92533,
            "nubia_score": 0.7412
        },
        "meteor": 0.4584506334147761,
        "bleurt": -0.03141,
        "bertscore": {
            "precision": 0.96991,
            "recall": 0.93247,
            "f1": 0.95082
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8946": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "nist": 2.8045330046640538,
        "bleu": 34.66668,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.66667,
            "fmeasure": 0.75
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.375,
            "fmeasure": 0.42857
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.66667,
            "fmeasure": 0.75
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.66667,
            "fmeasure": 0.75
        },
        "nubia": {
            "semantic_relation": 4.82331,
            "contradiction": 0.93144,
            "irrelevancy": 0.65741,
            "logical_agreement": 98.41114,
            "grammar_ref": 5.69157,
            "grammar_hyp": 6.14878,
            "nubia_score": 0.83549
        },
        "meteor": 0.47818878613286225,
        "bleurt": 0.66772,
        "bertscore": {
            "precision": 0.95557,
            "recall": 0.92279,
            "f1": 0.9389
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3908": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518528,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.640223928941851,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.18617861216337128,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.5
        },
        "nist": 1.6870094371917188,
        "bleu": 6.95958,
        "rouge1": {
            "precision": 0.36667,
            "recall": 0.49145,
            "fmeasure": 0.41667
        },
        "rouge2": {
            "precision": 0.03571,
            "recall": 0.04167,
            "fmeasure": 0.03846
        },
        "rougeL": {
            "precision": 0.23333,
            "recall": 0.32051,
            "fmeasure": 0.26786
        },
        "rougeLsum": {
            "precision": 0.23333,
            "recall": 0.32051,
            "fmeasure": 0.26786
        },
        "nubia": {
            "semantic_relation": 2.80455,
            "contradiction": 0.75051,
            "irrelevancy": 95.81873,
            "logical_agreement": 3.43076,
            "grammar_ref": 4.60771,
            "grammar_hyp": 4.98922,
            "nubia_score": 0.30304
        },
        "meteor": 0.2389804801958015,
        "bleurt": -0.24923,
        "bertscore": {
            "precision": 0.78895,
            "recall": 0.84781,
            "f1": 0.80831
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-5": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 958,
        "total_length": 19604,
        "mean_pred_length": 20.46346555323591,
        "std_pred_length": 4.7965085264409275,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.08437053662517853,
        "vocab_size-1": 1654,
        "unique-1": 759,
        "entropy-1": 7.7528791182853904,
        "distinct-2": 0.27239086131073686,
        "vocab_size-2": 5079,
        "unique-2": 3041,
        "entropy-2": 10.678673951702821,
        "cond_entropy-2": 2.810498665749186,
        "distinct-3": 0.47088421528720037,
        "vocab_size-3": 8329,
        "unique-3": 5910,
        "entropy-3": 12.068266008110243,
        "cond_entropy-3": 1.4605387488292547,
        "total_length-nopunct": 17368,
        "mean_pred_length-nopunct": 18.129436325678498,
        "std_pred_length-nopunct": 4.482854124538906,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.09442653155228005,
        "vocab_size-1-nopunct": 1640,
        "unique-1-nopunct": 756,
        "entropy-1-nopunct": 7.960100630936705,
        "distinct-2-nopunct": 0.2927483241925655,
        "vocab_size-2-nopunct": 4804,
        "unique-2-nopunct": 2958,
        "entropy-2-nopunct": 10.681023799688944,
        "cond_entropy-2-nopunct": 2.864714317489548,
        "distinct-3-nopunct": 0.5040124255759773,
        "vocab_size-3-nopunct": 7788,
        "unique-3-nopunct": 5647,
        "entropy-3-nopunct": 12.109296638983336,
        "cond_entropy-3-nopunct": 1.5120912489956702,
        "msttr-100": 0.66883,
        "msttr-100_nopunct": 0.69173,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6019268914706716
        },
        "nist": 6.60309511709245,
        "bleu": 31.45925,
        "rouge1": {
            "precision": 0.65704,
            "recall": 0.61757,
            "fmeasure": 0.6275
        },
        "rouge2": {
            "precision": 0.41728,
            "recall": 0.39228,
            "fmeasure": 0.39829
        },
        "rougeL": {
            "precision": 0.5684,
            "recall": 0.53432,
            "fmeasure": 0.54295
        },
        "rougeLsum": {
            "precision": 0.5684,
            "recall": 0.53432,
            "fmeasure": 0.54295
        },
        "nubia": {
            "semantic_relation": 4.32924,
            "contradiction": 3.8027,
            "irrelevancy": 16.87486,
            "logical_agreement": 79.32243,
            "grammar_ref": 4.83769,
            "grammar_hyp": 4.8378,
            "nubia_score": 0.74824
        },
        "meteor": 0.332753218726574,
        "bleurt": -0.05725,
        "bertscore": {
            "precision": 0.88757,
            "recall": 0.87861,
            "f1": 0.88273
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3944": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.4444444444444444
        },
        "nist": 1.877424865499507,
        "bleu": 15.13322,
        "rouge1": {
            "precision": 0.375,
            "recall": 0.43182,
            "fmeasure": 0.40119
        },
        "rouge2": {
            "precision": 0.13636,
            "recall": 0.16111,
            "fmeasure": 0.14762
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.43182,
            "fmeasure": 0.40119
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.43182,
            "fmeasure": 0.40119
        },
        "nubia": {
            "semantic_relation": 4.6799,
            "contradiction": 0.10711,
            "irrelevancy": 39.87684,
            "logical_agreement": 60.01605,
            "grammar_ref": 4.7527,
            "grammar_hyp": 4.72298,
            "nubia_score": 0.8365
        },
        "meteor": 0.3372339088906288,
        "bleurt": 0.28344,
        "bertscore": {
            "precision": 0.86052,
            "recall": 0.87275,
            "f1": 0.86659
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2422": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8095238095238095,
        "vocab_size-1": 17,
        "unique-1": 13,
        "entropy-1": 4.011365041826378,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.32961067210860195,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.7254805569978675,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.3881260751021447,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.9
        },
        "nist": 3.6344911745852104,
        "bleu": 36.46328,
        "rouge1": {
            "precision": 0.70175,
            "recall": 0.85671,
            "fmeasure": 0.76852
        },
        "rouge2": {
            "precision": 0.35185,
            "recall": 0.43056,
            "fmeasure": 0.38562
        },
        "rougeL": {
            "precision": 0.59649,
            "recall": 0.727,
            "fmeasure": 0.65278
        },
        "rougeLsum": {
            "precision": 0.59649,
            "recall": 0.727,
            "fmeasure": 0.65278
        },
        "nubia": {
            "semantic_relation": 3.83329,
            "contradiction": 5.19315,
            "irrelevancy": 93.78856,
            "logical_agreement": 1.0183,
            "grammar_ref": 5.01319,
            "grammar_hyp": 4.46235,
            "nubia_score": 0.5973
        },
        "meteor": 0.3721163167276862,
        "bleurt": -0.01897,
        "bertscore": {
            "precision": 0.92957,
            "recall": 0.93365,
            "f1": 0.9247
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4050": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.03126257645096008,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.03310859910983796,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6153846153846154
        },
        "nist": 2.362678690652273,
        "bleu": 16.19557,
        "rouge1": {
            "precision": 0.45614,
            "recall": 0.51961,
            "fmeasure": 0.48571
        },
        "rouge2": {
            "precision": 0.14815,
            "recall": 0.16944,
            "fmeasure": 0.15805
        },
        "rougeL": {
            "precision": 0.35088,
            "recall": 0.39951,
            "fmeasure": 0.37354
        },
        "rougeLsum": {
            "precision": 0.35088,
            "recall": 0.39951,
            "fmeasure": 0.37354
        },
        "nubia": {
            "semantic_relation": 4.24848,
            "contradiction": 0.14168,
            "irrelevancy": 4.26901,
            "logical_agreement": 95.58931,
            "grammar_ref": 5.85115,
            "grammar_hyp": 5.77706,
            "nubia_score": 0.73175
        },
        "meteor": 0.27439976490041224,
        "bleurt": -0.06928,
        "bertscore": {
            "precision": 0.87405,
            "recall": 0.89298,
            "f1": 0.88296
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-9": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 72,
        "total_length": 1814,
        "mean_pred_length": 25.194444444444443,
        "std_pred_length": 3.294097789518942,
        "median_pred_length": 26.0,
        "min_pred_length": 14,
        "max_pred_length": 30,
        "distinct-1": 0.20837927232635062,
        "vocab_size-1": 378,
        "unique-1": 217,
        "entropy-1": 7.006355043062751,
        "distinct-2": 0.48679678530424797,
        "vocab_size-2": 848,
        "unique-2": 595,
        "entropy-2": 8.990947390372394,
        "cond_entropy-2": 1.9985235171913691,
        "distinct-3": 0.6706586826347305,
        "vocab_size-3": 1120,
        "unique-3": 910,
        "entropy-3": 9.686858287291093,
        "cond_entropy-3": 0.7384371434789684,
        "total_length-nopunct": 1634,
        "mean_pred_length-nopunct": 22.694444444444443,
        "std_pred_length-nopunct": 3.2086640041235266,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.22766217870257038,
        "vocab_size-1-nopunct": 372,
        "unique-1-nopunct": 217,
        "entropy-1-nopunct": 7.082272696925577,
        "distinct-2-nopunct": 0.5185659411011524,
        "vocab_size-2-nopunct": 810,
        "unique-2-nopunct": 581,
        "entropy-2-nopunct": 8.967348732227904,
        "cond_entropy-2-nopunct": 1.9364037959458047,
        "distinct-3-nopunct": 0.7006711409395974,
        "vocab_size-3-nopunct": 1044,
        "unique-3-nopunct": 863,
        "entropy-3-nopunct": 9.627007634776957,
        "cond_entropy-3-nopunct": 0.7010805664607085,
        "msttr-100": 0.63722,
        "msttr-100_nopunct": 0.6475,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5032354405176704
        },
        "nist": 3.7770510255501413,
        "bleu": 25.68875,
        "rouge1": {
            "precision": 0.67335,
            "recall": 0.51068,
            "fmeasure": 0.5726
        },
        "rouge2": {
            "precision": 0.41986,
            "recall": 0.31848,
            "fmeasure": 0.35666
        },
        "rougeL": {
            "precision": 0.55911,
            "recall": 0.42336,
            "fmeasure": 0.47487
        },
        "rougeLsum": {
            "precision": 0.55911,
            "recall": 0.42336,
            "fmeasure": 0.47487
        },
        "nubia": {
            "semantic_relation": 3.62005,
            "contradiction": 4.63056,
            "irrelevancy": 13.68038,
            "logical_agreement": 81.68905,
            "grammar_ref": 4.20036,
            "grammar_hyp": 4.41567,
            "nubia_score": 0.52687
        },
        "meteor": 0.2728529091687696,
        "bleurt": -0.27934,
        "bertscore": {
            "precision": 0.89228,
            "recall": 0.84682,
            "f1": 0.86862
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-10": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 1024,
        "total_length": 10160,
        "mean_pred_length": 9.921875,
        "std_pred_length": 5.527607381080443,
        "median_pred_length": 8.0,
        "min_pred_length": 2,
        "max_pred_length": 28,
        "distinct-1": 0.0796259842519685,
        "vocab_size-1": 809,
        "unique-1": 451,
        "entropy-1": 6.6065566696676665,
        "distinct-2": 0.24211908931698775,
        "vocab_size-2": 2212,
        "unique-2": 1339,
        "entropy-2": 9.488502578583445,
        "cond_entropy-2": 2.5884145355512995,
        "distinct-3": 0.42110453648915186,
        "vocab_size-3": 3416,
        "unique-3": 2349,
        "entropy-3": 10.689626232063587,
        "cond_entropy-3": 1.1882156573920695,
        "total_length-nopunct": 8601,
        "mean_pred_length-nopunct": 8.3994140625,
        "std_pred_length-nopunct": 4.909298381049704,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.09289617486338798,
        "vocab_size-1-nopunct": 799,
        "unique-1-nopunct": 449,
        "entropy-1-nopunct": 6.84748181192086,
        "distinct-2-nopunct": 0.26989573709911574,
        "vocab_size-2-nopunct": 2045,
        "unique-2-nopunct": 1273,
        "entropy-2-nopunct": 9.42371785240932,
        "cond_entropy-2-nopunct": 2.7652914760805176,
        "distinct-3-nopunct": 0.47131522734208114,
        "vocab_size-3-nopunct": 3089,
        "unique-3-nopunct": 2230,
        "entropy-3-nopunct": 10.61649656202687,
        "cond_entropy-3-nopunct": 1.1984455208218014,
        "msttr-100": 0.53406,
        "msttr-100_nopunct": 0.56244,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.4087271132551255
        },
        "nist": 4.305107350031421,
        "bleu": 23.28274,
        "rouge1": {
            "precision": 0.39425,
            "recall": 0.37292,
            "fmeasure": 0.37404
        },
        "rouge2": {
            "precision": 0.19429,
            "recall": 0.18405,
            "fmeasure": 0.18507
        },
        "rougeL": {
            "precision": 0.35395,
            "recall": 0.3337,
            "fmeasure": 0.33497
        },
        "rougeLsum": {
            "precision": 0.35395,
            "recall": 0.3337,
            "fmeasure": 0.33497
        },
        "nubia": {
            "semantic_relation": 2.3084,
            "contradiction": 14.57623,
            "irrelevancy": 33.3584,
            "logical_agreement": 52.06537,
            "grammar_ref": 5.2128,
            "grammar_hyp": 5.17916,
            "nubia_score": 0.38162
        },
        "meteor": 0.23539746217267338,
        "bleurt": -0.61457,
        "bertscore": {
            "precision": 0.83208,
            "recall": 0.8291,
            "f1": 0.83015
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_536": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 50,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 2.6246692913372702,
        "median_pred_length": 18.0,
        "min_pred_length": 13,
        "max_pred_length": 19,
        "distinct-1": 0.76,
        "vocab_size-1": 38,
        "unique-1": 32,
        "entropy-1": 5.053660689688188,
        "distinct-2": 0.9787234042553191,
        "vocab_size-2": 46,
        "unique-2": 45,
        "entropy-2": 5.512035660188278,
        "cond_entropy-2": 0.3948792045021355,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": -0.04970268758579481,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 2.494438257849294,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.782608695652174,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 4.9854122277491095,
        "distinct-2-nopunct": 0.9767441860465116,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.379753126795121,
        "cond_entropy-2-nopunct": 0.40863041497446784,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.05433665981473581,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.125,
            "3": 0.8055555555555556
        },
        "nist": 4.527972944372265,
        "bleu": 48.11501,
        "rouge1": {
            "precision": 0.77671,
            "recall": 0.73673,
            "fmeasure": 0.74939
        },
        "rouge2": {
            "precision": 0.51199,
            "recall": 0.48065,
            "fmeasure": 0.49123
        },
        "rougeL": {
            "precision": 0.60823,
            "recall": 0.55135,
            "fmeasure": 0.57364
        },
        "rougeLsum": {
            "precision": 0.60823,
            "recall": 0.55135,
            "fmeasure": 0.57364
        },
        "nubia": {
            "semantic_relation": 4.60503,
            "contradiction": 0.34342,
            "irrelevancy": 13.63444,
            "logical_agreement": 86.02214,
            "grammar_ref": 4.10939,
            "grammar_hyp": 4.07567,
            "nubia_score": 0.89193
        },
        "meteor": 0.412201607717469,
        "bleurt": 0.19592,
        "bertscore": {
            "precision": 0.91343,
            "recall": 0.92178,
            "f1": 0.9137
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-11": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 1246,
        "total_length": 18619,
        "mean_pred_length": 14.943017656500803,
        "std_pred_length": 4.629876653641936,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 31,
        "distinct-1": 0.10210000537085773,
        "vocab_size-1": 1901,
        "unique-1": 879,
        "entropy-1": 8.040142587750854,
        "distinct-2": 0.3102515397455822,
        "vocab_size-2": 5390,
        "unique-2": 3325,
        "entropy-2": 10.923095331531956,
        "cond_entropy-2": 2.667438537844479,
        "distinct-3": 0.5105723321138463,
        "vocab_size-3": 8234,
        "unique-3": 6009,
        "entropy-3": 12.191201275993425,
        "cond_entropy-3": 1.3107243224258815,
        "total_length-nopunct": 16601,
        "mean_pred_length-nopunct": 13.323434991974318,
        "std_pred_length-nopunct": 4.192657314846832,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.11360761399915668,
        "vocab_size-1-nopunct": 1886,
        "unique-1-nopunct": 876,
        "entropy-1-nopunct": 8.218445033561112,
        "distinct-2-nopunct": 0.3223054379680886,
        "vocab_size-2-nopunct": 4949,
        "unique-2-nopunct": 3150,
        "entropy-2-nopunct": 10.787759338712615,
        "cond_entropy-2-nopunct": 2.7091021825326065,
        "distinct-3-nopunct": 0.5241335317882203,
        "vocab_size-3-nopunct": 7395,
        "unique-3-nopunct": 5508,
        "entropy-3-nopunct": 12.035542717099863,
        "cond_entropy-3-nopunct": 1.3202402228939063,
        "msttr-100": 0.68296,
        "msttr-100_nopunct": 0.70711,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6457463309867557
        },
        "nist": 7.446537205231302,
        "bleu": 39.43154,
        "rouge1": {
            "precision": 0.70445,
            "recall": 0.67199,
            "fmeasure": 0.67756
        },
        "rouge2": {
            "precision": 0.4938,
            "recall": 0.47138,
            "fmeasure": 0.47453
        },
        "rougeL": {
            "precision": 0.61518,
            "recall": 0.58575,
            "fmeasure": 0.59124
        },
        "rougeLsum": {
            "precision": 0.61518,
            "recall": 0.58575,
            "fmeasure": 0.59124
        },
        "nubia": {
            "semantic_relation": 4.36344,
            "contradiction": 3.71931,
            "irrelevancy": 17.12589,
            "logical_agreement": 79.15479,
            "grammar_ref": 4.92094,
            "grammar_hyp": 4.85051,
            "nubia_score": 0.78557
        },
        "meteor": 0.37273071439315664,
        "bleurt": 0.00625,
        "bertscore": {
            "precision": 0.90164,
            "recall": 0.89406,
            "f1": 0.89742
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-12": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "total_length": 4176,
        "mean_pred_length": 8.352,
        "std_pred_length": 1.7709025947239447,
        "median_pred_length": 8.0,
        "min_pred_length": 4,
        "max_pred_length": 18,
        "distinct-1": 0.035201149425287355,
        "vocab_size-1": 147,
        "unique-1": 47,
        "entropy-1": 5.196591726347933,
        "distinct-2": 0.1235038084874864,
        "vocab_size-2": 454,
        "unique-2": 203,
        "entropy-2": 7.038824993751507,
        "cond_entropy-2": 1.5847874880161728,
        "distinct-3": 0.2364609571788413,
        "vocab_size-3": 751,
        "unique-3": 394,
        "entropy-3": 8.026874284247151,
        "cond_entropy-3": 1.0495516365972428,
        "total_length-nopunct": 3679,
        "mean_pred_length-nopunct": 7.358,
        "std_pred_length-nopunct": 1.7440860070535513,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.038869257950530034,
        "vocab_size-1-nopunct": 143,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.268817618042117,
        "distinct-2-nopunct": 0.1245674740484429,
        "vocab_size-2-nopunct": 396,
        "unique-2-nopunct": 178,
        "entropy-2-nopunct": 6.761521400029114,
        "cond_entropy-2-nopunct": 1.6877232055944755,
        "distinct-3-nopunct": 0.23553564762971257,
        "vocab_size-3-nopunct": 631,
        "unique-3-nopunct": 340,
        "entropy-3-nopunct": 7.663057496506279,
        "cond_entropy-3-nopunct": 1.1558211643018435,
        "msttr-100": 0.36902,
        "msttr-100_nopunct": 0.37472,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5123440403504115
        },
        "nist": 3.6130466263647976,
        "bleu": 26.38361,
        "rouge1": {
            "precision": 0.55629,
            "recall": 0.5351,
            "fmeasure": 0.53571
        },
        "rouge2": {
            "precision": 0.3224,
            "recall": 0.30895,
            "fmeasure": 0.30926
        },
        "rougeL": {
            "precision": 0.53536,
            "recall": 0.51499,
            "fmeasure": 0.51564
        },
        "rougeLsum": {
            "precision": 0.53536,
            "recall": 0.51499,
            "fmeasure": 0.51564
        },
        "nubia": {
            "semantic_relation": 3.6922,
            "contradiction": 3.47084,
            "irrelevancy": 27.31747,
            "logical_agreement": 69.2117,
            "grammar_ref": 4.43492,
            "grammar_hyp": 4.2774,
            "nubia_score": 0.68721
        },
        "meteor": 0.28476970887507863,
        "bleurt": 0.04172,
        "bertscore": {
            "precision": 0.88624,
            "recall": 0.88202,
            "f1": 0.8838
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_10500": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0
        },
        "nist": 2.881123244281595,
        "bleu": 50.0,
        "rouge1": {
            "precision": 0.78571,
            "recall": 0.85714,
            "fmeasure": 0.81868
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.48333,
            "fmeasure": 0.44697
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.78571,
            "fmeasure": 0.74725
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.78571,
            "fmeasure": 0.74725
        },
        "nubia": {
            "semantic_relation": 4.99023,
            "contradiction": 1.04284,
            "irrelevancy": 2.66336,
            "logical_agreement": 96.2938,
            "grammar_ref": 7.77345,
            "grammar_hyp": 8.83754,
            "nubia_score": 0.8593
        },
        "meteor": 0.5174540534653375,
        "bleurt": 0.5924,
        "bertscore": {
            "precision": 0.95772,
            "recall": 0.98358,
            "f1": 0.97048
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_539": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518523,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.6402239289418516,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.18617861216337134,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "nist": 1.3941520836137833,
        "bleu": 10.93488,
        "rouge1": {
            "precision": 0.41176,
            "recall": 0.58333,
            "fmeasure": 0.48276
        },
        "rouge2": {
            "precision": 0.1875,
            "recall": 0.27273,
            "fmeasure": 0.22222
        },
        "rougeL": {
            "precision": 0.35294,
            "recall": 0.5,
            "fmeasure": 0.41379
        },
        "rougeLsum": {
            "precision": 0.35294,
            "recall": 0.5,
            "fmeasure": 0.41379
        },
        "nubia": {
            "semantic_relation": 3.85597,
            "contradiction": 0.11211,
            "irrelevancy": 99.2718,
            "logical_agreement": 0.6161,
            "grammar_ref": 5.68739,
            "grammar_hyp": 4.17625,
            "nubia_score": 0.68217
        },
        "meteor": 0.31169309104230053,
        "bleurt": -0.04781,
        "bertscore": {
            "precision": 0.8062,
            "recall": 0.8328,
            "f1": 0.81928
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-13": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 2078,
        "total_length": 21806,
        "mean_pred_length": 10.493743984600577,
        "std_pred_length": 5.389605128548342,
        "median_pred_length": 9.0,
        "min_pred_length": 2,
        "max_pred_length": 31,
        "distinct-1": 0.026231312482802898,
        "vocab_size-1": 572,
        "unique-1": 196,
        "entropy-1": 6.356692845701321,
        "distinct-2": 0.1354420113544201,
        "vocab_size-2": 2672,
        "unique-2": 1272,
        "entropy-2": 9.333982363865777,
        "cond_entropy-2": 2.6815692000351117,
        "distinct-3": 0.2927478753541076,
        "vocab_size-3": 5167,
        "unique-3": 3204,
        "entropy-3": 10.782897592366147,
        "cond_entropy-3": 1.5104693435832401,
        "total_length-nopunct": 19102,
        "mean_pred_length-nopunct": 9.192492781520693,
        "std_pred_length-nopunct": 4.95751938998865,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.02963040519317349,
        "vocab_size-1-nopunct": 566,
        "unique-1-nopunct": 196,
        "entropy-1-nopunct": 6.526099717264854,
        "distinct-2-nopunct": 0.146968984962406,
        "vocab_size-2-nopunct": 2502,
        "unique-2-nopunct": 1277,
        "entropy-2-nopunct": 9.097011675003309,
        "cond_entropy-2-nopunct": 2.7663148652243184,
        "distinct-3-nopunct": 0.30644190246839254,
        "vocab_size-3-nopunct": 4581,
        "unique-3-nopunct": 2992,
        "entropy-3-nopunct": 10.518396967095857,
        "cond_entropy-3-nopunct": 1.5392231584535443,
        "msttr-100": 0.52128,
        "msttr-100_nopunct": 0.5411,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.43421120711957367
        },
        "nist": 3.679894795611554,
        "bleu": 17.23994,
        "rouge1": {
            "precision": 0.46753,
            "recall": 0.43752,
            "fmeasure": 0.43715
        },
        "rouge2": {
            "precision": 0.22901,
            "recall": 0.21811,
            "fmeasure": 0.21479
        },
        "rougeL": {
            "precision": 0.42636,
            "recall": 0.39963,
            "fmeasure": 0.39925
        },
        "rougeLsum": {
            "precision": 0.42636,
            "recall": 0.39963,
            "fmeasure": 0.39925
        },
        "nubia": {
            "semantic_relation": 3.14981,
            "contradiction": 9.02498,
            "irrelevancy": 27.55791,
            "logical_agreement": 63.41711,
            "grammar_ref": 4.54436,
            "grammar_hyp": 4.45801,
            "nubia_score": 0.52634
        },
        "meteor": 0.23397236870847288,
        "bleurt": -0.27346,
        "bertscore": {
            "precision": 0.84423,
            "recall": 0.83531,
            "f1": 0.83899
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_13590": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 18,
        "unique-1": 15,
        "entropy-1": 4.061482186720775,
        "distinct-2": 0.95,
        "vocab_size-2": 19,
        "unique-2": 18,
        "entropy-2": 4.221928094887362,
        "cond_entropy-2": 0.0417446012861228,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.04089198233393865,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.94770277922009,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.875,
        "cond_entropy-2-nopunct": -0.04492500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.04978793508525296,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.21428571428571427,
            "3": 1.0
        },
        "nist": 2.373727166393957,
        "bleu": 28.38702,
        "rouge1": {
            "precision": 0.47222,
            "recall": 0.52083,
            "fmeasure": 0.49071
        },
        "rouge2": {
            "precision": 0.29167,
            "recall": 0.31905,
            "fmeasure": 0.3037
        },
        "rougeL": {
            "precision": 0.4537,
            "recall": 0.51199,
            "fmeasure": 0.47801
        },
        "rougeLsum": {
            "precision": 0.4537,
            "recall": 0.51199,
            "fmeasure": 0.47801
        },
        "nubia": {
            "semantic_relation": 3.23465,
            "contradiction": 61.06854,
            "irrelevancy": 21.02031,
            "logical_agreement": 17.91115,
            "grammar_ref": 5.40028,
            "grammar_hyp": 4.7424,
            "nubia_score": 0.42603
        },
        "meteor": 0.33214685295823027,
        "bleurt": -0.11761,
        "bertscore": {
            "precision": 0.81995,
            "recall": 0.86997,
            "f1": 0.84368
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_14710": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 3.392398719107628,
        "bleu": 48.58974,
        "rouge1": {
            "precision": 0.6,
            "recall": 1.0,
            "fmeasure": 0.75
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.6,
            "fmeasure": 0.42857
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 1.0,
            "fmeasure": 0.75
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 1.0,
            "fmeasure": 0.75
        },
        "nubia": {
            "semantic_relation": 4.4608,
            "contradiction": 0.43629,
            "irrelevancy": 65.45263,
            "logical_agreement": 34.11108,
            "grammar_ref": 5.78237,
            "grammar_hyp": 6.13232,
            "nubia_score": 0.69399
        },
        "meteor": 0.49467060723934386,
        "bleurt": 0.54908,
        "bertscore": {
            "precision": 0.89798,
            "recall": 0.93613,
            "f1": 0.91666
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15144": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.1699250014423126,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.45873,
            "irrelevancy": 0.46812,
            "logical_agreement": 99.07315,
            "grammar_ref": 5.85687,
            "grammar_hyp": 5.85687,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.95702,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-15": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 715,
        "total_length": 6267,
        "mean_pred_length": 8.765034965034966,
        "std_pred_length": 3.370486025446255,
        "median_pred_length": 8.0,
        "min_pred_length": 2,
        "max_pred_length": 25,
        "distinct-1": 0.02553055688527206,
        "vocab_size-1": 160,
        "unique-1": 55,
        "entropy-1": 4.795105697492059,
        "distinct-2": 0.09005763688760807,
        "vocab_size-2": 500,
        "unique-2": 254,
        "entropy-2": 6.4138626156804595,
        "cond_entropy-2": 1.4123968270495653,
        "distinct-3": 0.1509199917304114,
        "vocab_size-3": 730,
        "unique-3": 425,
        "entropy-3": 7.149326791062166,
        "cond_entropy-3": 0.6826574815814483,
        "total_length-nopunct": 5468,
        "mean_pred_length-nopunct": 7.647552447552448,
        "std_pred_length-nopunct": 3.0986537155106335,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.02852962692026335,
        "vocab_size-1-nopunct": 156,
        "unique-1-nopunct": 54,
        "entropy-1-nopunct": 4.769283102027707,
        "distinct-2-nopunct": 0.09657058699768567,
        "vocab_size-2-nopunct": 459,
        "unique-2-nopunct": 244,
        "entropy-2-nopunct": 6.184597661347613,
        "cond_entropy-2-nopunct": 1.3734577101238385,
        "distinct-3-nopunct": 0.1570084200099059,
        "vocab_size-3-nopunct": 634,
        "unique-3-nopunct": 375,
        "entropy-3-nopunct": 6.887468317655904,
        "cond_entropy-3-nopunct": 0.648527676805293,
        "msttr-100": 0.29645,
        "msttr-100_nopunct": 0.29333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5112147855732998
        },
        "nist": 2.9649660332556165,
        "bleu": 24.6587,
        "rouge1": {
            "precision": 0.53435,
            "recall": 0.52342,
            "fmeasure": 0.51655
        },
        "rouge2": {
            "precision": 0.29665,
            "recall": 0.28796,
            "fmeasure": 0.28304
        },
        "rougeL": {
            "precision": 0.46598,
            "recall": 0.45366,
            "fmeasure": 0.44886
        },
        "rougeLsum": {
            "precision": 0.46598,
            "recall": 0.45366,
            "fmeasure": 0.44886
        },
        "nubia": {
            "semantic_relation": 3.53292,
            "contradiction": 2.22313,
            "irrelevancy": 26.09528,
            "logical_agreement": 71.68159,
            "grammar_ref": 4.09289,
            "grammar_hyp": 3.91705,
            "nubia_score": 0.67302
        },
        "meteor": 0.2718887457244776,
        "bleurt": 0.0825,
        "bertscore": {
            "precision": 0.85273,
            "recall": 0.84809,
            "f1": 0.8498
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4060": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 1.5,
        "median_pred_length": 17.5,
        "min_pred_length": 16,
        "max_pred_length": 19,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 25,
        "unique-1": 19,
        "entropy-1": 4.400432302535623,
        "distinct-2": 0.9090909090909091,
        "vocab_size-2": 30,
        "unique-2": 27,
        "entropy-2": 4.862575937540274,
        "cond_entropy-2": 0.44571034496884854,
        "distinct-3": 0.967741935483871,
        "vocab_size-3": 30,
        "unique-3": 29,
        "entropy-3": 4.889680181354619,
        "cond_entropy-3": 0.038834449092937956,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.392747410448783,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.501629167387823,
        "cond_entropy-2-nopunct": 0.1345227825800641,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.0346217911747682,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.9545454545454546
        },
        "nist": 3.7717959146886173,
        "bleu": 54.60873,
        "rouge1": {
            "precision": 0.87179,
            "recall": 0.96047,
            "fmeasure": 0.91269
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.86364,
            "fmeasure": 0.80237
        },
        "rougeL": {
            "precision": 0.80769,
            "recall": 0.91667,
            "fmeasure": 0.85833
        },
        "rougeLsum": {
            "precision": 0.80769,
            "recall": 0.91667,
            "fmeasure": 0.85833
        },
        "nubia": {
            "semantic_relation": 4.27485,
            "contradiction": 5.34872,
            "irrelevancy": 73.1664,
            "logical_agreement": 21.48489,
            "grammar_ref": 6.50157,
            "grammar_hyp": 6.45305,
            "nubia_score": 0.67497
        },
        "meteor": 0.49497184896964097,
        "bleurt": -0.00377,
        "bertscore": {
            "precision": 0.89323,
            "recall": 0.97397,
            "f1": 0.93021
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-0": {
        "predictions_file": "ByT5-base (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2293,
        "mean_pred_length": 21.632075471698112,
        "std_pred_length": 3.1272553271353587,
        "median_pred_length": 22.0,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.4191016136066289,
        "vocab_size-1": 961,
        "unique-1": 734,
        "entropy-1": 8.399525152542363,
        "distinct-2": 0.8500228623685414,
        "vocab_size-2": 1859,
        "unique-2": 1715,
        "entropy-2": 10.659726997782974,
        "cond_entropy-2": 2.1973980609434265,
        "distinct-3": 0.9711677078327727,
        "vocab_size-3": 2021,
        "unique-3": 1981,
        "entropy-3": 10.95261273511072,
        "cond_entropy-3": 0.30015136890535465,
        "total_length-nopunct": 2169,
        "mean_pred_length-nopunct": 20.462264150943398,
        "std_pred_length-nopunct": 3.2101681855131643,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.43937298294144767,
        "vocab_size-1-nopunct": 953,
        "unique-1-nopunct": 731,
        "entropy-1-nopunct": 8.466613995781923,
        "distinct-2-nopunct": 0.8560349006301503,
        "vocab_size-2-nopunct": 1766,
        "unique-2-nopunct": 1632,
        "entropy-2-nopunct": 10.596324767219427,
        "cond_entropy-2-nopunct": 2.2055642431010005,
        "distinct-3-nopunct": 0.9780275932549821,
        "vocab_size-3-nopunct": 1914,
        "unique-3-nopunct": 1880,
        "entropy-3-nopunct": 10.886510596829844,
        "cond_entropy-3-nopunct": 0.28931768520068607,
        "msttr-100": 0.74682,
        "msttr-100_nopunct": 0.75667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.429295489102889
        },
        "nist": 3.9065589344688036,
        "bleu": 16.25533,
        "rouge1": {
            "precision": 0.43029,
            "recall": 0.45133,
            "fmeasure": 0.43184
        },
        "rouge2": {
            "precision": 0.21207,
            "recall": 0.22354,
            "fmeasure": 0.21354
        },
        "rougeL": {
            "precision": 0.35387,
            "recall": 0.37079,
            "fmeasure": 0.35559
        },
        "rougeLsum": {
            "precision": 0.35387,
            "recall": 0.37079,
            "fmeasure": 0.35559
        },
        "nubia": {
            "semantic_relation": 2.98946,
            "contradiction": 20.18916,
            "irrelevancy": 67.50505,
            "logical_agreement": 12.30579,
            "grammar_ref": 3.74062,
            "grammar_hyp": 3.99352,
            "nubia_score": 0.41526
        },
        "meteor": 0.20818294730665748,
        "bleurt": -0.35171,
        "bertscore": {
            "precision": 0.83884,
            "recall": 0.84274,
            "f1": 0.84047
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2490": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 28,
        "mean_pred_length": 28.0,
        "std_pred_length": 0.0,
        "median_pred_length": 28.0,
        "min_pred_length": 28,
        "max_pred_length": 28,
        "distinct-1": 0.7857142857142857,
        "vocab_size-1": 22,
        "unique-1": 19,
        "entropy-1": 4.297902689682948,
        "distinct-2": 0.9259259259259259,
        "vocab_size-2": 25,
        "unique-2": 24,
        "entropy-2": 4.578780557638898,
        "cond_entropy-2": 0.29974646915501035,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": 0.12843250452237231,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.84,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.2634651896016456,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.386842188131012,
        "cond_entropy-2-nopunct": 0.13922662353657617,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": 0.14533369456035533,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714,
            "3": 0.6666666666666666
        },
        "nist": 3.677859618789786,
        "bleu": 27.42825,
        "rouge1": {
            "precision": 0.72,
            "recall": 0.58065,
            "fmeasure": 0.64286
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.4,
            "fmeasure": 0.44444
        },
        "rougeL": {
            "precision": 0.72,
            "recall": 0.58065,
            "fmeasure": 0.64286
        },
        "rougeLsum": {
            "precision": 0.72,
            "recall": 0.58065,
            "fmeasure": 0.64286
        },
        "nubia": {
            "semantic_relation": 2.38307,
            "contradiction": 78.514,
            "irrelevancy": 17.76263,
            "logical_agreement": 3.72337,
            "grammar_ref": 4.34568,
            "grammar_hyp": 4.19581,
            "nubia_score": 0.19912
        },
        "meteor": 0.2850342058607252,
        "bleurt": -0.30505,
        "bertscore": {
            "precision": 0.95523,
            "recall": 0.95679,
            "f1": 0.95601
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4320": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 41,
        "mean_pred_length": 20.5,
        "std_pred_length": 2.5,
        "median_pred_length": 20.5,
        "min_pred_length": 18,
        "max_pred_length": 23,
        "distinct-1": 0.6585365853658537,
        "vocab_size-1": 27,
        "unique-1": 16,
        "entropy-1": 4.61938950445978,
        "distinct-2": 0.7692307692307693,
        "vocab_size-2": 30,
        "unique-2": 21,
        "entropy-2": 4.823863757323786,
        "cond_entropy-2": 0.2016886759305559,
        "distinct-3": 0.7837837837837838,
        "vocab_size-3": 29,
        "unique-3": 21,
        "entropy-3": 4.77702093319652,
        "cond_entropy-3": -0.04892182620627169,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.631578947368421,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.451489026430681,
        "distinct-2-nopunct": 0.75,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.66992500144231,
        "cond_entropy-2-nopunct": 0.21865582149231705,
        "distinct-3-nopunct": 0.7647058823529411,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.616874605956221,
        "cond_entropy-3-nopunct": -0.05305039548609062,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.6,
            "3": 0.8857142857142857
        },
        "nist": 4.04581613366496,
        "bleu": 68.36852,
        "rouge1": {
            "precision": 0.98413,
            "recall": 0.82516,
            "fmeasure": 0.88871
        },
        "rouge2": {
            "precision": 0.91667,
            "recall": 0.77621,
            "fmeasure": 0.83192
        },
        "rougeL": {
            "precision": 0.88095,
            "recall": 0.75621,
            "fmeasure": 0.80612
        },
        "rougeLsum": {
            "precision": 0.88095,
            "recall": 0.75621,
            "fmeasure": 0.80612
        },
        "nubia": {
            "semantic_relation": 4.5392,
            "contradiction": 1.10239,
            "irrelevancy": 1.1095,
            "logical_agreement": 97.78811,
            "grammar_ref": 4.56621,
            "grammar_hyp": 4.62175,
            "nubia_score": 0.79411
        },
        "meteor": 0.49363965789782366,
        "bleurt": 0.45008,
        "bertscore": {
            "precision": 0.96478,
            "recall": 0.93442,
            "f1": 0.94909
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-1": {
        "predictions_file": "ByT5-base (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2286,
        "mean_pred_length": 21.566037735849058,
        "std_pred_length": 3.0868524236458823,
        "median_pred_length": 22.0,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.4321959755030621,
        "vocab_size-1": 988,
        "unique-1": 761,
        "entropy-1": 8.461476356142684,
        "distinct-2": 0.8522935779816514,
        "vocab_size-2": 1858,
        "unique-2": 1721,
        "entropy-2": 10.647770147380621,
        "cond_entropy-2": 2.128138310565043,
        "distinct-3": 0.9720347155255545,
        "vocab_size-3": 2016,
        "unique-3": 1978,
        "entropy-3": 10.951587364002393,
        "cond_entropy-3": 0.31489453725716543,
        "total_length-nopunct": 2184,
        "mean_pred_length-nopunct": 20.60377358490566,
        "std_pred_length-nopunct": 3.26987174545961,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.44963369963369965,
        "vocab_size-1-nopunct": 982,
        "unique-1-nopunct": 760,
        "entropy-1-nopunct": 8.507989452471275,
        "distinct-2-nopunct": 0.8556304138594802,
        "vocab_size-2-nopunct": 1778,
        "unique-2-nopunct": 1649,
        "entropy-2-nopunct": 10.586721032929287,
        "cond_entropy-2-nopunct": 2.162945032617646,
        "distinct-3-nopunct": 0.9761663286004056,
        "vocab_size-3-nopunct": 1925,
        "unique-3-nopunct": 1892,
        "entropy-3-nopunct": 10.890804583861597,
        "cond_entropy-3-nopunct": 0.31400585285237925,
        "msttr-100": 0.75455,
        "msttr-100_nopunct": 0.76,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.4130743723353861
        },
        "nist": 3.838014080624804,
        "bleu": 12.86737,
        "rouge1": {
            "precision": 0.45126,
            "recall": 0.44252,
            "fmeasure": 0.44127
        },
        "rouge2": {
            "precision": 0.19969,
            "recall": 0.19204,
            "fmeasure": 0.19274
        },
        "rougeL": {
            "precision": 0.34584,
            "recall": 0.33718,
            "fmeasure": 0.3372
        },
        "rougeLsum": {
            "precision": 0.34584,
            "recall": 0.33718,
            "fmeasure": 0.3372
        },
        "nubia": {
            "semantic_relation": 2.97557,
            "contradiction": 25.12021,
            "irrelevancy": 63.74257,
            "logical_agreement": 11.13722,
            "grammar_ref": 3.75111,
            "grammar_hyp": 4.12642,
            "nubia_score": 0.39887
        },
        "meteor": 0.19568754861419826,
        "bleurt": -0.38258,
        "bertscore": {
            "precision": 0.83928,
            "recall": 0.83278,
            "f1": 0.8357
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-2": {
        "predictions_file": "ByT5-base (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2327,
        "mean_pred_length": 21.952830188679247,
        "std_pred_length": 2.99175620624061,
        "median_pred_length": 22.0,
        "min_pred_length": 14,
        "max_pred_length": 28,
        "distinct-1": 0.4172754619681994,
        "vocab_size-1": 971,
        "unique-1": 720,
        "entropy-1": 8.432712484204588,
        "distinct-2": 0.8532192705988294,
        "vocab_size-2": 1895,
        "unique-2": 1740,
        "entropy-2": 10.705135246810364,
        "cond_entropy-2": 2.205280352276663,
        "distinct-3": 0.9749408983451536,
        "vocab_size-3": 2062,
        "unique-3": 2026,
        "entropy-3": 10.98680177520035,
        "cond_entropy-3": 0.28772202184160894,
        "total_length-nopunct": 2211,
        "mean_pred_length-nopunct": 20.858490566037737,
        "std_pred_length-nopunct": 3.142642438330206,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4364540931705111,
        "vocab_size-1-nopunct": 965,
        "unique-1-nopunct": 718,
        "entropy-1-nopunct": 8.501461365103303,
        "distinct-2-nopunct": 0.857957244655582,
        "vocab_size-2-nopunct": 1806,
        "unique-2-nopunct": 1661,
        "entropy-2-nopunct": 10.641997326906443,
        "cond_entropy-2-nopunct": 2.2177637878047403,
        "distinct-3-nopunct": 0.9794897448724362,
        "vocab_size-3-nopunct": 1958,
        "unique-3-nopunct": 1925,
        "entropy-3-nopunct": 10.920775950835088,
        "cond_entropy-3-nopunct": 0.2890521215661514,
        "msttr-100": 0.7487,
        "msttr-100_nopunct": 0.75955,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3640552995391705
        },
        "nist": 3.3262306395811487,
        "bleu": 9.27155,
        "rouge1": {
            "precision": 0.3945,
            "recall": 0.38128,
            "fmeasure": 0.38279
        },
        "rouge2": {
            "precision": 0.15827,
            "recall": 0.15246,
            "fmeasure": 0.15321
        },
        "rougeL": {
            "precision": 0.3124,
            "recall": 0.30184,
            "fmeasure": 0.30302
        },
        "rougeLsum": {
            "precision": 0.3124,
            "recall": 0.30184,
            "fmeasure": 0.30302
        },
        "nubia": {
            "semantic_relation": 2.72764,
            "contradiction": 27.14851,
            "irrelevancy": 62.17176,
            "logical_agreement": 10.67973,
            "grammar_ref": 3.66018,
            "grammar_hyp": 4.06498,
            "nubia_score": 0.35285
        },
        "meteor": 0.1703458444873062,
        "bleurt": -0.44777,
        "bertscore": {
            "precision": 0.82892,
            "recall": 0.82297,
            "f1": 0.82562
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15834": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "nist": 3.0633227445129942,
        "bleu": 40.89601,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.72222,
            "fmeasure": 0.69281
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.27381,
            "fmeasure": 0.26111
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.72222,
            "fmeasure": 0.69281
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.72222,
            "fmeasure": 0.69281
        },
        "nubia": {
            "semantic_relation": 4.60992,
            "contradiction": 0.09225,
            "irrelevancy": 16.21338,
            "logical_agreement": 83.69437,
            "grammar_ref": 5.6187,
            "grammar_hyp": 5.70721,
            "nubia_score": 0.84812
        },
        "meteor": 0.4162683426198592,
        "bleurt": 0.51082,
        "bertscore": {
            "precision": 0.9006,
            "recall": 0.92443,
            "f1": 0.91236
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-3": {
        "predictions_file": "ByT5-base (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2265,
        "mean_pred_length": 21.367924528301888,
        "std_pred_length": 3.2803746671025515,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 29,
        "distinct-1": 0.42251655629139073,
        "vocab_size-1": 957,
        "unique-1": 718,
        "entropy-1": 8.410392422401854,
        "distinct-2": 0.84251968503937,
        "vocab_size-2": 1819,
        "unique-2": 1665,
        "entropy-2": 10.624468201458543,
        "cond_entropy-2": 2.1430609390322117,
        "distinct-3": 0.9712615684364345,
        "vocab_size-3": 1994,
        "unique-3": 1949,
        "entropy-3": 10.937989746003355,
        "cond_entropy-3": 0.3218987041216385,
        "total_length-nopunct": 2159,
        "mean_pred_length-nopunct": 20.367924528301888,
        "std_pred_length-nopunct": 3.443137751994492,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.43955534969893467,
        "vocab_size-1-nopunct": 949,
        "unique-1-nopunct": 715,
        "entropy-1-nopunct": 8.461796117107575,
        "distinct-2-nopunct": 0.8460789089137847,
        "vocab_size-2-nopunct": 1737,
        "unique-2-nopunct": 1591,
        "entropy-2-nopunct": 10.562075236481194,
        "cond_entropy-2-nopunct": 2.1783242211292984,
        "distinct-3-nopunct": 0.9758602978941961,
        "vocab_size-3-nopunct": 1900,
        "unique-3-nopunct": 1861,
        "entropy-3-nopunct": 10.874125227267868,
        "cond_entropy-3-nopunct": 0.32050046516361425,
        "msttr-100": 0.74455,
        "msttr-100_nopunct": 0.75095,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.35690866510538644
        },
        "nist": 3.254233679899136,
        "bleu": 9.51513,
        "rouge1": {
            "precision": 0.40129,
            "recall": 0.38676,
            "fmeasure": 0.38901
        },
        "rouge2": {
            "precision": 0.14752,
            "recall": 0.14401,
            "fmeasure": 0.14361
        },
        "rougeL": {
            "precision": 0.29908,
            "recall": 0.2897,
            "fmeasure": 0.29081
        },
        "rougeLsum": {
            "precision": 0.29908,
            "recall": 0.2897,
            "fmeasure": 0.29081
        },
        "nubia": {
            "semantic_relation": 2.75343,
            "contradiction": 21.48674,
            "irrelevancy": 68.95274,
            "logical_agreement": 9.56051,
            "grammar_ref": 3.68583,
            "grammar_hyp": 4.04429,
            "nubia_score": 0.36017
        },
        "meteor": 0.16744988749983433,
        "bleurt": -0.45873,
        "bertscore": {
            "precision": 0.82169,
            "recall": 0.81591,
            "f1": 0.81854
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2640": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "nist": 2.3196816181136892,
        "bleu": 40.52128,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.90909,
            "fmeasure": 0.76923
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.7,
            "fmeasure": 0.58333
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.72727,
            "fmeasure": 0.61538
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.72727,
            "fmeasure": 0.61538
        },
        "nubia": {
            "semantic_relation": 3.20822,
            "contradiction": 99.74808,
            "irrelevancy": 0.19459,
            "logical_agreement": 0.05734,
            "grammar_ref": 5.20642,
            "grammar_hyp": 4.12398,
            "nubia_score": 0.48819
        },
        "meteor": 0.4343270781303907,
        "bleurt": -0.29988,
        "bertscore": {
            "precision": 0.89197,
            "recall": 0.9455,
            "f1": 0.91795
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 5049,
        "total_length": 38223,
        "mean_pred_length": 7.570409982174688,
        "std_pred_length": 2.735056601074063,
        "median_pred_length": 7.0,
        "min_pred_length": 1,
        "max_pred_length": 27,
        "distinct-1": 0.03432488292389399,
        "vocab_size-1": 1312,
        "unique-1": 559,
        "entropy-1": 7.030947068222923,
        "distinct-2": 0.14797733164526436,
        "vocab_size-2": 4909,
        "unique-2": 2528,
        "entropy-2": 10.028780134442323,
        "cond_entropy-2": 2.5970818005619853,
        "distinct-3": 0.2804522505866458,
        "vocab_size-3": 7888,
        "unique-3": 4870,
        "entropy-3": 11.20381299806634,
        "cond_entropy-3": 1.1905389588383848,
        "total_length-nopunct": 32428,
        "mean_pred_length-nopunct": 6.4226579520697165,
        "std_pred_length-nopunct": 2.5314049611820653,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.040088812137658816,
        "vocab_size-1-nopunct": 1300,
        "unique-1-nopunct": 558,
        "entropy-1-nopunct": 7.245138067209987,
        "distinct-2-nopunct": 0.1559589466379342,
        "vocab_size-2-nopunct": 4270,
        "unique-2-nopunct": 2280,
        "entropy-2-nopunct": 9.760507361425462,
        "cond_entropy-2-nopunct": 2.7367763408650845,
        "distinct-3-nopunct": 0.2892062497201952,
        "vocab_size-3-nopunct": 6460,
        "unique-3-nopunct": 4117,
        "entropy-3-nopunct": 10.841185637739978,
        "cond_entropy-3-nopunct": 1.2145163916607056,
        "msttr-100": 0.59162,
        "msttr-100_nopunct": 0.62216,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.4453651109679686
        },
        "nist": 4.583512455914728,
        "bleu": 25.04132,
        "rouge1": {
            "precision": 0.48436,
            "recall": 0.46404,
            "fmeasure": 0.46177
        },
        "rouge2": {
            "precision": 0.28062,
            "recall": 0.27034,
            "fmeasure": 0.2673
        },
        "rougeL": {
            "precision": 0.46132,
            "recall": 0.4418,
            "fmeasure": 0.43983
        },
        "rougeLsum": {
            "precision": 0.46132,
            "recall": 0.4418,
            "fmeasure": 0.43983
        },
        "nubia": {
            "semantic_relation": 3.0739,
            "contradiction": 7.74698,
            "irrelevancy": 28.38699,
            "logical_agreement": 63.86603,
            "grammar_ref": 4.77787,
            "grammar_hyp": 4.70747,
            "nubia_score": 0.54697
        },
        "meteor": 0.25489982999704486,
        "bleurt": -0.16209,
        "bertscore": {
            "precision": 0.84996,
            "recall": 0.84527,
            "f1": 0.84701
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-4": {
        "predictions_file": "ByT5-base (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2297,
        "mean_pred_length": 21.669811320754718,
        "std_pred_length": 2.9770242775808535,
        "median_pred_length": 22.0,
        "min_pred_length": 14,
        "max_pred_length": 29,
        "distinct-1": 0.4235959947757945,
        "vocab_size-1": 973,
        "unique-1": 728,
        "entropy-1": 8.431862310671415,
        "distinct-2": 0.8521223185759927,
        "vocab_size-2": 1867,
        "unique-2": 1729,
        "entropy-2": 10.651137731754154,
        "cond_entropy-2": 2.1579660806150787,
        "distinct-3": 0.9688249400479616,
        "vocab_size-3": 2020,
        "unique-3": 1982,
        "entropy-3": 10.947355453011854,
        "cond_entropy-3": 0.3097545099143921,
        "total_length-nopunct": 2192,
        "mean_pred_length-nopunct": 20.67924528301887,
        "std_pred_length-nopunct": 3.193587826252346,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4402372262773723,
        "vocab_size-1-nopunct": 965,
        "unique-1-nopunct": 727,
        "entropy-1-nopunct": 8.473269134478985,
        "distinct-2-nopunct": 0.8557046979865772,
        "vocab_size-2-nopunct": 1785,
        "unique-2-nopunct": 1660,
        "entropy-2-nopunct": 10.587614433844418,
        "cond_entropy-2-nopunct": 2.2019218951858623,
        "distinct-3-nopunct": 0.9732323232323232,
        "vocab_size-3-nopunct": 1927,
        "unique-3-nopunct": 1894,
        "entropy-3-nopunct": 10.887096036214206,
        "cond_entropy-3-nopunct": 0.3121060105571054,
        "msttr-100": 0.73364,
        "msttr-100_nopunct": 0.74238,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.32969531605275126
        },
        "nist": 3.049539752853362,
        "bleu": 8.08908,
        "rouge1": {
            "precision": 0.38759,
            "recall": 0.36223,
            "fmeasure": 0.37016
        },
        "rouge2": {
            "precision": 0.14008,
            "recall": 0.12952,
            "fmeasure": 0.13298
        },
        "rougeL": {
            "precision": 0.2964,
            "recall": 0.27723,
            "fmeasure": 0.28327
        },
        "rougeLsum": {
            "precision": 0.2964,
            "recall": 0.27723,
            "fmeasure": 0.28327
        },
        "nubia": {
            "semantic_relation": 2.73499,
            "contradiction": 28.44671,
            "irrelevancy": 58.20544,
            "logical_agreement": 13.34785,
            "grammar_ref": 3.83852,
            "grammar_hyp": 4.12212,
            "nubia_score": 0.35873
        },
        "meteor": 0.15594512651540482,
        "bleurt": -0.45293,
        "bertscore": {
            "precision": 0.82311,
            "recall": 0.81301,
            "f1": 0.8178
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2667": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 2.5,
        "median_pred_length": 11.5,
        "min_pred_length": 9,
        "max_pred_length": 14,
        "distinct-1": 0.6086956521739131,
        "vocab_size-1": 14,
        "unique-1": 7,
        "entropy-1": 3.675310868912364,
        "distinct-2": 0.6666666666666666,
        "vocab_size-2": 14,
        "unique-2": 8,
        "entropy-2": 3.689703732199547,
        "cond_entropy-2": -5.9414127611068235e-05,
        "distinct-3": 0.7368421052631579,
        "vocab_size-3": 14,
        "unique-3": 9,
        "entropy-3": 3.7216117239699007,
        "cond_entropy-3": 0.0006041697260603099,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.6190476190476191,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.5585186130489053,
        "distinct-2-nopunct": 0.6842105263157895,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.5766176449086653,
        "cond_entropy-2-nopunct": 0.0006041697260603064,
        "distinct-3-nopunct": 0.7647058823529411,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.6168746059562227,
        "cond_entropy-3-nopunct": 0.001587533816369658,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 1.0
        },
        "nist": 3.8730980767647254,
        "bleu": 73.85255,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.94444,
            "fmeasure": 0.92892
        },
        "rouge2": {
            "precision": 0.80357,
            "recall": 0.85833,
            "fmeasure": 0.82208
        },
        "rougeL": {
            "precision": 0.92308,
            "recall": 0.94444,
            "fmeasure": 0.92892
        },
        "rougeLsum": {
            "precision": 0.92308,
            "recall": 0.94444,
            "fmeasure": 0.92892
        },
        "nubia": {
            "semantic_relation": 4.92218,
            "contradiction": 0.47325,
            "irrelevancy": 13.63589,
            "logical_agreement": 85.89086,
            "grammar_ref": 4.57714,
            "grammar_hyp": 4.46355,
            "nubia_score": 0.95975
        },
        "meteor": 0.5363057668264603,
        "bleurt": 0.84843,
        "bertscore": {
            "precision": 0.98874,
            "recall": 0.99049,
            "f1": 0.98745
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2681": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.47058823529411764
        },
        "nist": 2.1677015619324047,
        "bleu": 7.20006,
        "rouge1": {
            "precision": 0.56863,
            "recall": 0.54684,
            "fmeasure": 0.55742
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.12255,
            "fmeasure": 0.12374
        },
        "rougeL": {
            "precision": 0.35294,
            "recall": 0.34641,
            "fmeasure": 0.34958
        },
        "rougeLsum": {
            "precision": 0.35294,
            "recall": 0.34641,
            "fmeasure": 0.34958
        },
        "nubia": {
            "semantic_relation": 3.5497,
            "contradiction": 0.3955,
            "irrelevancy": 76.4367,
            "logical_agreement": 23.16781,
            "grammar_ref": 4.84215,
            "grammar_hyp": 4.58749,
            "nubia_score": 0.51966
        },
        "meteor": 0.21855820519280914,
        "bleurt": -0.13128,
        "bertscore": {
            "precision": 0.85748,
            "recall": 0.87032,
            "f1": 0.86385
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 2517,
        "total_length": 37043,
        "mean_pred_length": 14.717123559793405,
        "std_pred_length": 4.185345908202128,
        "median_pred_length": 14.0,
        "min_pred_length": 3,
        "max_pred_length": 32,
        "distinct-1": 0.0697027778527657,
        "vocab_size-1": 2582,
        "unique-1": 1216,
        "entropy-1": 8.163097730195528,
        "distinct-2": 0.2736488443491861,
        "vocab_size-2": 9448,
        "unique-2": 5696,
        "entropy-2": 11.674701665511321,
        "cond_entropy-2": 3.2830928088673064,
        "distinct-3": 0.49089318629135553,
        "vocab_size-3": 15713,
        "unique-3": 11467,
        "entropy-3": 13.057126859278023,
        "cond_entropy-3": 1.4232359706918496,
        "total_length-nopunct": 32689,
        "mean_pred_length-nopunct": 12.987286452125547,
        "std_pred_length-nopunct": 3.785970020669056,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.07855853651075285,
        "vocab_size-1-nopunct": 2568,
        "unique-1-nopunct": 1214,
        "entropy-1-nopunct": 8.378833919009667,
        "distinct-2-nopunct": 0.29311944849529364,
        "vocab_size-2-nopunct": 8844,
        "unique-2-nopunct": 5540,
        "entropy-2-nopunct": 11.57163366563823,
        "cond_entropy-2-nopunct": 3.3546134423394003,
        "distinct-3-nopunct": 0.512457060206111,
        "vocab_size-3-nopunct": 14172,
        "unique-3-nopunct": 10637,
        "entropy-3-nopunct": 12.9112254912782,
        "cond_entropy-3-nopunct": 1.4153062922310493,
        "msttr-100": 0.69843,
        "msttr-100_nopunct": 0.72577,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5944560767523985
        },
        "nist": 6.958153543710238,
        "bleu": 33.50022,
        "rouge1": {
            "precision": 0.63591,
            "recall": 0.61715,
            "fmeasure": 0.61596
        },
        "rouge2": {
            "precision": 0.40479,
            "recall": 0.39369,
            "fmeasure": 0.39231
        },
        "rougeL": {
            "precision": 0.54903,
            "recall": 0.53253,
            "fmeasure": 0.53176
        },
        "rougeLsum": {
            "precision": 0.54903,
            "recall": 0.53253,
            "fmeasure": 0.53176
        },
        "nubia": {
            "semantic_relation": 4.07827,
            "contradiction": 3.96014,
            "irrelevancy": 20.98952,
            "logical_agreement": 75.05033,
            "grammar_ref": 4.80017,
            "grammar_hyp": 4.68893,
            "nubia_score": 0.72034
        },
        "meteor": 0.3325271586924424,
        "bleurt": -0.03954,
        "bertscore": {
            "precision": 0.88439,
            "recall": 0.88021,
            "f1": 0.88191
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2682": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.7083333333333334,
        "vocab_size-1": 17,
        "unique-1": 10,
        "entropy-1": 4.001629167387823,
        "distinct-2": 0.8695652173913043,
        "vocab_size-2": 20,
        "unique-2": 17,
        "entropy-2": 4.262692390839622,
        "cond_entropy-2": 0.2864255422923785,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": 0.20859693530755724,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6818181818181818,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.82306798227366,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.106603137064474,
        "cond_entropy-2-nopunct": 0.3138381850938442,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": 0.22961067210860203,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.0,
            "3": 0.7
        },
        "nist": 2.837923008510982,
        "bleu": 24.44078,
        "rouge1": {
            "precision": 0.43939,
            "recall": 0.66838,
            "fmeasure": 0.52973
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.34127,
            "fmeasure": 0.26898
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.55385,
            "fmeasure": 0.43861
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.55385,
            "fmeasure": 0.43861
        },
        "nubia": {
            "semantic_relation": 3.80495,
            "contradiction": 5.8465,
            "irrelevancy": 30.26597,
            "logical_agreement": 63.88752,
            "grammar_ref": 4.11472,
            "grammar_hyp": 2.78609,
            "nubia_score": 0.61269
        },
        "meteor": 0.3344656103055379,
        "bleurt": -0.17164,
        "bertscore": {
            "precision": 0.90522,
            "recall": 0.87733,
            "f1": 0.89106
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2718": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.3219280948873626,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29478,
            "irrelevancy": 0.49577,
            "logical_agreement": 99.20945,
            "grammar_ref": 4.98947,
            "grammar_hyp": 4.98947,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.97683,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-5": {
        "predictions_file": "ByT5-base (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2297,
        "mean_pred_length": 21.669811320754718,
        "std_pred_length": 3.027302486002783,
        "median_pred_length": 22.0,
        "min_pred_length": 14,
        "max_pred_length": 28,
        "distinct-1": 0.4270787984327383,
        "vocab_size-1": 981,
        "unique-1": 751,
        "entropy-1": 8.447589446868422,
        "distinct-2": 0.8607941579187586,
        "vocab_size-2": 1886,
        "unique-2": 1737,
        "entropy-2": 10.693518780439872,
        "cond_entropy-2": 2.1783126335533654,
        "distinct-3": 0.973621103117506,
        "vocab_size-3": 2030,
        "unique-3": 1980,
        "entropy-3": 10.97126359278738,
        "cond_entropy-3": 0.2862406834652575,
        "total_length-nopunct": 2183,
        "mean_pred_length-nopunct": 20.59433962264151,
        "std_pred_length-nopunct": 3.226594389810187,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.445716903344022,
        "vocab_size-1-nopunct": 973,
        "unique-1-nopunct": 748,
        "entropy-1-nopunct": 8.501499626985082,
        "distinct-2-nopunct": 0.8613384689455946,
        "vocab_size-2-nopunct": 1789,
        "unique-2-nopunct": 1649,
        "entropy-2-nopunct": 10.614249629439326,
        "cond_entropy-2-nopunct": 2.204732466365277,
        "distinct-3-nopunct": 0.976154236428209,
        "vocab_size-3-nopunct": 1924,
        "unique-3-nopunct": 1880,
        "entropy-3-nopunct": 10.89587154226764,
        "cond_entropy-3-nopunct": 0.2912187253708394,
        "msttr-100": 0.74727,
        "msttr-100_nopunct": 0.75048,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.35609532538955085
        },
        "nist": 3.2491662177259566,
        "bleu": 8.96414,
        "rouge1": {
            "precision": 0.40226,
            "recall": 0.37747,
            "fmeasure": 0.38388
        },
        "rouge2": {
            "precision": 0.14715,
            "recall": 0.13483,
            "fmeasure": 0.13841
        },
        "rougeL": {
            "precision": 0.31063,
            "recall": 0.28877,
            "fmeasure": 0.29491
        },
        "rougeLsum": {
            "precision": 0.31063,
            "recall": 0.28877,
            "fmeasure": 0.29491
        },
        "nubia": {
            "semantic_relation": 2.75205,
            "contradiction": 35.17212,
            "irrelevancy": 56.35688,
            "logical_agreement": 8.471,
            "grammar_ref": 3.63886,
            "grammar_hyp": 4.00829,
            "nubia_score": 0.34735
        },
        "meteor": 0.163504223226727,
        "bleurt": -0.43613,
        "bertscore": {
            "precision": 0.83387,
            "recall": 0.82435,
            "f1": 0.82884
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2112": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "nist": 3.0881978509745025,
        "bleu": 68.94026,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.5873,
            "fmeasure": 0.65152
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "nubia": {
            "semantic_relation": 4.6318,
            "contradiction": 0.66466,
            "irrelevancy": 0.56229,
            "logical_agreement": 98.77305,
            "grammar_ref": 5.07671,
            "grammar_hyp": 5.29413,
            "nubia_score": 0.85198
        },
        "meteor": 0.81809314801268,
        "bleurt": 0.64449,
        "bertscore": {
            "precision": 0.98644,
            "recall": 0.96366,
            "f1": 0.97492
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-6": {
        "predictions_file": "ByT5-base (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2293,
        "mean_pred_length": 21.632075471698112,
        "std_pred_length": 2.83949727047254,
        "median_pred_length": 22.0,
        "min_pred_length": 14,
        "max_pred_length": 28,
        "distinct-1": 0.41517662450937637,
        "vocab_size-1": 952,
        "unique-1": 731,
        "entropy-1": 8.35269878772536,
        "distinct-2": 0.8344764517604024,
        "vocab_size-2": 1825,
        "unique-2": 1665,
        "entropy-2": 10.613577438479423,
        "cond_entropy-2": 2.1955811888255643,
        "distinct-3": 0.9586737145603076,
        "vocab_size-3": 1995,
        "unique-3": 1934,
        "entropy-3": 10.92628081224569,
        "cond_entropy-3": 0.3279296289945694,
        "total_length-nopunct": 2188,
        "mean_pred_length-nopunct": 20.641509433962263,
        "std_pred_length-nopunct": 2.997447591073404,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4319012797074954,
        "vocab_size-1-nopunct": 945,
        "unique-1-nopunct": 728,
        "entropy-1-nopunct": 8.404698299446466,
        "distinct-2-nopunct": 0.835254562920269,
        "vocab_size-2-nopunct": 1739,
        "unique-2-nopunct": 1589,
        "entropy-2-nopunct": 10.541940805688116,
        "cond_entropy-2-nopunct": 2.2350920848921496,
        "distinct-3-nopunct": 0.9620445344129555,
        "vocab_size-3-nopunct": 1901,
        "unique-3-nopunct": 1846,
        "entropy-3-nopunct": 10.861449920874856,
        "cond_entropy-3-nopunct": 0.3329366018773027,
        "msttr-100": 0.73591,
        "msttr-100_nopunct": 0.75,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.33225208526413347
        },
        "nist": 2.938180094009331,
        "bleu": 6.85858,
        "rouge1": {
            "precision": 0.37734,
            "recall": 0.366,
            "fmeasure": 0.36518
        },
        "rouge2": {
            "precision": 0.12369,
            "recall": 0.12417,
            "fmeasure": 0.12117
        },
        "rougeL": {
            "precision": 0.2925,
            "recall": 0.28645,
            "fmeasure": 0.28423
        },
        "rougeLsum": {
            "precision": 0.2925,
            "recall": 0.28645,
            "fmeasure": 0.28423
        },
        "nubia": {
            "semantic_relation": 2.7582,
            "contradiction": 28.48191,
            "irrelevancy": 59.77786,
            "logical_agreement": 11.74023,
            "grammar_ref": 3.80483,
            "grammar_hyp": 4.04192,
            "nubia_score": 0.36264
        },
        "meteor": 0.15485444035570464,
        "bleurt": -0.4404,
        "bertscore": {
            "precision": 0.82231,
            "recall": 0.81791,
            "f1": 0.8198
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-7": {
        "predictions_file": "ByT5-base (Baseline)/xsum_test",
        "N": 106,
        "total_length": 2202,
        "mean_pred_length": 20.77358490566038,
        "std_pred_length": 4.160195520776988,
        "median_pred_length": 21.5,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.42188919164396005,
        "vocab_size-1": 929,
        "unique-1": 702,
        "entropy-1": 8.407701187888739,
        "distinct-2": 0.8583015267175572,
        "vocab_size-2": 1799,
        "unique-2": 1661,
        "entropy-2": 10.62842081165916,
        "cond_entropy-2": 2.1477211292465332,
        "distinct-3": 0.9753768844221106,
        "vocab_size-3": 1941,
        "unique-3": 1901,
        "entropy-3": 10.903143337287398,
        "cond_entropy-3": 0.27972319100591264,
        "total_length-nopunct": 2083,
        "mean_pred_length-nopunct": 19.650943396226417,
        "std_pred_length-nopunct": 4.317674192288978,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.44167066730676907,
        "vocab_size-1-nopunct": 920,
        "unique-1-nopunct": 700,
        "entropy-1-nopunct": 8.471778164202881,
        "distinct-2-nopunct": 0.8639352554375316,
        "vocab_size-2-nopunct": 1708,
        "unique-2-nopunct": 1586,
        "entropy-2-nopunct": 10.556072225530276,
        "cond_entropy-2-nopunct": 2.1682255687275194,
        "distinct-3-nopunct": 0.9812934259754142,
        "vocab_size-3-nopunct": 1836,
        "unique-3-nopunct": 1803,
        "entropy-3-nopunct": 10.831373760394989,
        "cond_entropy-3-nopunct": 0.27967592412956965,
        "msttr-100": 0.75136,
        "msttr-100_nopunct": 0.761,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.29911339244050394
        },
        "nist": 2.710730903668355,
        "bleu": 5.76156,
        "rouge1": {
            "precision": 0.35485,
            "recall": 0.32255,
            "fmeasure": 0.33218
        },
        "rouge2": {
            "precision": 0.11376,
            "recall": 0.10061,
            "fmeasure": 0.10473
        },
        "rougeL": {
            "precision": 0.27511,
            "recall": 0.24815,
            "fmeasure": 0.25624
        },
        "rougeLsum": {
            "precision": 0.27511,
            "recall": 0.24815,
            "fmeasure": 0.25624
        },
        "nubia": {
            "semantic_relation": 2.56009,
            "contradiction": 29.60688,
            "irrelevancy": 59.09412,
            "logical_agreement": 11.299,
            "grammar_ref": 3.75874,
            "grammar_hyp": 4.20054,
            "nubia_score": 0.30815
        },
        "meteor": 0.14060380673802733,
        "bleurt": -0.4562,
        "bertscore": {
            "precision": 0.81963,
            "recall": 0.80752,
            "f1": 0.81325
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 1328,
        "total_length": 25223,
        "mean_pred_length": 18.993222891566266,
        "std_pred_length": 4.662957962749347,
        "median_pred_length": 19.0,
        "min_pred_length": 7,
        "max_pred_length": 31,
        "distinct-1": 0.08206795385164334,
        "vocab_size-1": 2070,
        "unique-1": 988,
        "entropy-1": 8.068374262318578,
        "distinct-2": 0.29106507637581086,
        "vocab_size-2": 6955,
        "unique-2": 4232,
        "entropy-2": 11.321596791309679,
        "cond_entropy-2": 3.0950136439742097,
        "distinct-3": 0.5047635928568264,
        "vocab_size-3": 11391,
        "unique-3": 8293,
        "entropy-3": 12.665101019846087,
        "cond_entropy-3": 1.394976151920649,
        "total_length-nopunct": 22329,
        "mean_pred_length-nopunct": 16.814006024096386,
        "std_pred_length-nopunct": 4.199026304225561,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.09203278248018272,
        "vocab_size-1-nopunct": 2055,
        "unique-1-nopunct": 984,
        "entropy-1-nopunct": 8.279875025270268,
        "distinct-2-nopunct": 0.31365173086995857,
        "vocab_size-2-nopunct": 6587,
        "unique-2-nopunct": 4159,
        "entropy-2-nopunct": 11.271914957323718,
        "cond_entropy-2-nopunct": 3.1288442821727194,
        "distinct-3-nopunct": 0.5346413866720886,
        "vocab_size-3-nopunct": 10518,
        "unique-3-nopunct": 7885,
        "entropy-3-nopunct": 12.602169196971131,
        "cond_entropy-3-nopunct": 1.3936502038515504,
        "msttr-100": 0.69452,
        "msttr-100_nopunct": 0.72336,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6079504011670314
        },
        "nist": 6.8724325930995,
        "bleu": 32.45404,
        "rouge1": {
            "precision": 0.65155,
            "recall": 0.62792,
            "fmeasure": 0.62913
        },
        "rouge2": {
            "precision": 0.42026,
            "recall": 0.40731,
            "fmeasure": 0.40686
        },
        "rougeL": {
            "precision": 0.55118,
            "recall": 0.53121,
            "fmeasure": 0.53249
        },
        "rougeLsum": {
            "precision": 0.55118,
            "recall": 0.53121,
            "fmeasure": 0.53249
        },
        "nubia": {
            "semantic_relation": 4.24213,
            "contradiction": 3.1253,
            "irrelevancy": 17.28748,
            "logical_agreement": 79.58722,
            "grammar_ref": 4.79322,
            "grammar_hyp": 4.74439,
            "nubia_score": 0.73915
        },
        "meteor": 0.33300572273978907,
        "bleurt": -0.04237,
        "bertscore": {
            "precision": 0.88935,
            "recall": 0.88295,
            "f1": 0.88577
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1800": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 3.5,
        "median_pred_length": 12.5,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.8,
        "vocab_size-1": 20,
        "unique-1": 16,
        "entropy-1": 4.213660689688184,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.26035304898504774,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.061482186720775,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.3002408513582383,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.6923076923076923
        },
        "nist": 2.1145664827690718,
        "bleu": 34.00719,
        "rouge1": {
            "precision": 0.85417,
            "recall": 0.59263,
            "fmeasure": 0.69224
        },
        "rouge2": {
            "precision": 0.46429,
            "recall": 0.26,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.65417,
            "recall": 0.44979,
            "fmeasure": 0.52529
        },
        "rougeLsum": {
            "precision": 0.65417,
            "recall": 0.44979,
            "fmeasure": 0.52529
        },
        "nubia": {
            "semantic_relation": 3.75635,
            "contradiction": 19.07675,
            "irrelevancy": 2.9978,
            "logical_agreement": 77.92545,
            "grammar_ref": 4.38763,
            "grammar_hyp": 4.67398,
            "nubia_score": 0.55739
        },
        "meteor": 0.2783272046429298,
        "bleurt": -0.04049,
        "bertscore": {
            "precision": 0.92801,
            "recall": 0.89069,
            "f1": 0.90886
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1809": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.8521687236032816,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.16253715874966054,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.36363636363636365,
            "2": 0.5555555555555556
        },
        "nist": 2.453447367987751,
        "bleu": 11.95473,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.39286,
            "fmeasure": 0.40489
        },
        "rouge2": {
            "precision": 0.14706,
            "recall": 0.13248,
            "fmeasure": 0.13485
        },
        "rougeL": {
            "precision": 0.38889,
            "recall": 0.35714,
            "fmeasure": 0.36141
        },
        "rougeLsum": {
            "precision": 0.38889,
            "recall": 0.35714,
            "fmeasure": 0.36141
        },
        "nubia": {
            "semantic_relation": 2.71706,
            "contradiction": 0.17371,
            "irrelevancy": 95.85059,
            "logical_agreement": 3.97571,
            "grammar_ref": 3.10421,
            "grammar_hyp": 2.60177,
            "nubia_score": 0.45977
        },
        "meteor": 0.21296843612763133,
        "bleurt": -0.28388,
        "bertscore": {
            "precision": 0.84467,
            "recall": 0.79403,
            "f1": 0.81857
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2884": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.11251249881411757,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.9130434782608695,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.349648912578752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.11768784439846626,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333
        },
        "nist": 0.6666666666666666,
        "bleu": 3.74194,
        "rouge1": {
            "precision": 0.17391,
            "recall": 0.26667,
            "fmeasure": 0.21053
        },
        "rouge2": {
            "precision": 0.04545,
            "recall": 0.07143,
            "fmeasure": 0.05556
        },
        "rougeL": {
            "precision": 0.08696,
            "recall": 0.13333,
            "fmeasure": 0.10526
        },
        "rougeLsum": {
            "precision": 0.08696,
            "recall": 0.13333,
            "fmeasure": 0.10526
        },
        "nubia": {
            "semantic_relation": 2.13045,
            "contradiction": 22.9477,
            "irrelevancy": 76.56527,
            "logical_agreement": 0.48702,
            "grammar_ref": 5.48676,
            "grammar_hyp": 4.4836,
            "nubia_score": 0.286
        },
        "meteor": 0.11059885031200481,
        "bleurt": -0.70696,
        "bertscore": {
            "precision": 0.74983,
            "recall": 0.79725,
            "f1": 0.77147
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-base (Baseline)/schema_guided_dialog_test",
        "N": 469,
        "total_length": 9589,
        "mean_pred_length": 20.445628997867804,
        "std_pred_length": 4.280132996022055,
        "median_pred_length": 20.0,
        "min_pred_length": 9,
        "max_pred_length": 33,
        "distinct-1": 0.12545625195536553,
        "vocab_size-1": 1203,
        "unique-1": 603,
        "entropy-1": 7.916885401848969,
        "distinct-2": 0.3651315789473684,
        "vocab_size-2": 3330,
        "unique-2": 2116,
        "entropy-2": 10.596937339157728,
        "cond_entropy-2": 2.5724199384283923,
        "distinct-3": 0.571610218471853,
        "vocab_size-3": 4945,
        "unique-3": 3681,
        "entropy-3": 11.703018916370317,
        "cond_entropy-3": 1.127997325046442,
        "total_length-nopunct": 8646,
        "mean_pred_length-nopunct": 18.43496801705757,
        "std_pred_length-nopunct": 3.9445156454266312,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.13798288225769142,
        "vocab_size-1-nopunct": 1193,
        "unique-1-nopunct": 601,
        "entropy-1-nopunct": 8.063364429609996,
        "distinct-2-nopunct": 0.38253638253638256,
        "vocab_size-2-nopunct": 3128,
        "unique-2-nopunct": 2025,
        "entropy-2-nopunct": 10.537388495398886,
        "cond_entropy-2-nopunct": 2.5663775130001625,
        "distinct-3-nopunct": 0.5950960041515309,
        "vocab_size-3-nopunct": 4587,
        "unique-3-nopunct": 3472,
        "entropy-3-nopunct": 11.639881171514261,
        "cond_entropy-3-nopunct": 1.125214936904642,
        "msttr-100": 0.70726,
        "msttr-100_nopunct": 0.72395,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6412275622466705
        },
        "nist": 6.860374590451782,
        "bleu": 35.09267,
        "rouge1": {
            "precision": 0.69241,
            "recall": 0.65876,
            "fmeasure": 0.66507
        },
        "rouge2": {
            "precision": 0.46421,
            "recall": 0.44195,
            "fmeasure": 0.44573
        },
        "rougeL": {
            "precision": 0.59772,
            "recall": 0.5692,
            "fmeasure": 0.57452
        },
        "rougeLsum": {
            "precision": 0.59772,
            "recall": 0.5692,
            "fmeasure": 0.57452
        },
        "nubia": {
            "semantic_relation": 4.31852,
            "contradiction": 3.24847,
            "irrelevancy": 17.03379,
            "logical_agreement": 79.71774,
            "grammar_ref": 4.86994,
            "grammar_hyp": 4.857,
            "nubia_score": 0.74843
        },
        "meteor": 0.34931593621470663,
        "bleurt": -0.02948,
        "bertscore": {
            "precision": 0.89545,
            "recall": 0.88763,
            "f1": 0.89115
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2123": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.38461538461538464
        },
        "nist": 0.319876044137262,
        "bleu": 15.94926,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.34921,
            "fmeasure": 0.46898
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.22527,
            "fmeasure": 0.31053
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.34921,
            "fmeasure": 0.46898
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.34921,
            "fmeasure": 0.46898
        },
        "nubia": {
            "semantic_relation": 2.90216,
            "contradiction": 4.40652,
            "irrelevancy": 65.54935,
            "logical_agreement": 30.04413,
            "grammar_ref": 4.48877,
            "grammar_hyp": 5.14792,
            "nubia_score": 0.23715
        },
        "meteor": 0.20958083891290333,
        "bleurt": -0.11547,
        "bertscore": {
            "precision": 0.94568,
            "recall": 0.82935,
            "f1": 0.86239
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1820": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 1.0,
        "vocab_size-1": 20,
        "unique-1": 20,
        "entropy-1": 4.321928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.07400058144377676,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.247927513443583,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.07800251200127316,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.125,
            "3": 0.7142857142857143
        },
        "nist": 1.6582838972385718,
        "bleu": 7.12696,
        "rouge1": {
            "precision": 0.31579,
            "recall": 0.63333,
            "fmeasure": 0.41394
        },
        "rouge2": {
            "precision": 0.14815,
            "recall": 0.33333,
            "fmeasure": 0.20167
        },
        "rougeL": {
            "precision": 0.29825,
            "recall": 0.61111,
            "fmeasure": 0.39434
        },
        "rougeLsum": {
            "precision": 0.29825,
            "recall": 0.61111,
            "fmeasure": 0.39434
        },
        "nubia": {
            "semantic_relation": 3.54034,
            "contradiction": 0.23189,
            "irrelevancy": 99.59463,
            "logical_agreement": 0.17348,
            "grammar_ref": 4.70243,
            "grammar_hyp": 6.49635,
            "nubia_score": 0.32039
        },
        "meteor": 0.2843755973038106,
        "bleurt": -0.53772,
        "bertscore": {
            "precision": 0.82412,
            "recall": 0.92696,
            "f1": 0.86762
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1824": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 34,
        "mean_pred_length": 34.0,
        "std_pred_length": 0.0,
        "median_pred_length": 34.0,
        "min_pred_length": 34,
        "max_pred_length": 34,
        "distinct-1": 0.7352941176470589,
        "vocab_size-1": 25,
        "unique-1": 22,
        "entropy-1": 4.3815804883091625,
        "distinct-2": 0.9393939393939394,
        "vocab_size-2": 31,
        "unique-2": 30,
        "entropy-2": 4.900306619292896,
        "cond_entropy-2": 0.5401165053152817,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": 0.10419611508415498,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.251629167387823,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.28642554229237843,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.06413033741971555,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.7142857142857143
        },
        "nist": 2.6626854283925803,
        "bleu": 41.30571,
        "rouge1": {
            "precision": 0.51923,
            "recall": 0.69211,
            "fmeasure": 0.59324
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.54094,
            "fmeasure": 0.45983
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.66711,
            "fmeasure": 0.5715
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.66711,
            "fmeasure": 0.5715
        },
        "nubia": {
            "semantic_relation": 3.91276,
            "contradiction": 0.90998,
            "irrelevancy": 97.74483,
            "logical_agreement": 1.34519,
            "grammar_ref": 4.38153,
            "grammar_hyp": 3.981,
            "nubia_score": 0.68102
        },
        "meteor": 0.3945179771187226,
        "bleurt": -0.17542,
        "bertscore": {
            "precision": 0.88682,
            "recall": 0.93318,
            "f1": 0.90941
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2940": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.5769230769230769,
        "vocab_size-1": 15,
        "unique-1": 4,
        "entropy-1": 3.854285871987246,
        "distinct-2": 0.5833333333333334,
        "vocab_size-2": 14,
        "unique-2": 4,
        "entropy-2": 3.751629167387823,
        "cond_entropy-2": -0.11547721741993588,
        "distinct-3": 0.5909090909090909,
        "vocab_size-3": 13,
        "unique-3": 4,
        "entropy-3": 3.6412498004554794,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.5909090909090909,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 3.6412498004554794,
        "distinct-2-nopunct": 0.6,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 3.521928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 0.6111111111111112,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 3.392147223664534,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.854285871987245,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.32615,
            "irrelevancy": 0.47325,
            "logical_agreement": 99.2006,
            "grammar_ref": 5.00662,
            "grammar_hyp": 5.00662,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.94692,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2148": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.033108599109837954,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966059,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "nist": 2.3648022336944767,
        "bleu": 21.25925,
        "rouge1": {
            "precision": 0.78947,
            "recall": 0.62709,
            "fmeasure": 0.69841
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.34909,
            "fmeasure": 0.3907
        },
        "rougeL": {
            "precision": 0.68421,
            "recall": 0.54348,
            "fmeasure": 0.60529
        },
        "rougeLsum": {
            "precision": 0.68421,
            "recall": 0.54348,
            "fmeasure": 0.60529
        },
        "nubia": {
            "semantic_relation": 4.98853,
            "contradiction": 0.11199,
            "irrelevancy": 0.48887,
            "logical_agreement": 99.39915,
            "grammar_ref": 3.26294,
            "grammar_hyp": 3.32221,
            "nubia_score": 0.9897
        },
        "meteor": 0.357891468826395,
        "bleurt": 0.48312,
        "bertscore": {
            "precision": 0.92724,
            "recall": 0.88282,
            "f1": 0.90399
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2205": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 2.8483609718589222,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.37344,
            "irrelevancy": 0.48743,
            "logical_agreement": 99.13913,
            "grammar_ref": 6.21263,
            "grammar_hyp": 6.40603,
            "nubia_score": 0.97334
        },
        "meteor": 1.0,
        "bleurt": 0.90755,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_960": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 4,
        "total_length": 47,
        "mean_pred_length": 11.75,
        "std_pred_length": 1.6393596310755,
        "median_pred_length": 12.5,
        "min_pred_length": 9,
        "max_pred_length": 13,
        "distinct-1": 0.7446808510638298,
        "vocab_size-1": 35,
        "unique-1": 26,
        "entropy-1": 4.985335926099694,
        "distinct-2": 0.9302325581395349,
        "vocab_size-2": 40,
        "unique-2": 37,
        "entropy-2": 5.286729870981167,
        "cond_entropy-2": 0.1683011937724482,
        "distinct-3": 0.9743589743589743,
        "vocab_size-3": 38,
        "unique-3": 37,
        "entropy-3": 5.234120167580196,
        "cond_entropy-3": -0.03829843327574717,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.945772482251059,
        "distinct-2-nopunct": 0.9210526315789473,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.090032776601483,
        "cond_entropy-2-nopunct": 0.19126502493228484,
        "distinct-3-nopunct": 0.9705882352941176,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.028639311838573,
        "cond_entropy-3-nopunct": -0.04281761336971668,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5,
            "3": 0.8888888888888888
        },
        "nist": 5.084862309648267,
        "bleu": 70.52983,
        "rouge1": {
            "precision": 0.86742,
            "recall": 0.88943,
            "fmeasure": 0.86034
        },
        "rouge2": {
            "precision": 0.75852,
            "recall": 0.79087,
            "fmeasure": 0.75762
        },
        "rougeL": {
            "precision": 0.81187,
            "recall": 0.85268,
            "fmeasure": 0.81615
        },
        "rougeLsum": {
            "precision": 0.81187,
            "recall": 0.85268,
            "fmeasure": 0.81615
        },
        "nubia": {
            "semantic_relation": 4.71501,
            "contradiction": 3.2524,
            "irrelevancy": 25.08076,
            "logical_agreement": 71.66683,
            "grammar_ref": 4.5734,
            "grammar_hyp": 4.6277,
            "nubia_score": 0.87645
        },
        "meteor": 0.5270694154750788,
        "bleurt": 0.52231,
        "bertscore": {
            "precision": 0.97869,
            "recall": 0.97452,
            "f1": 0.97525
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1836": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.1125124988141176,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.277613436819114,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.12336199461765368,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.47368421052631576
        },
        "nist": 2.905671301005232,
        "bleu": 16.02072,
        "rouge1": {
            "precision": 0.53623,
            "recall": 0.51333,
            "fmeasure": 0.52407
        },
        "rouge2": {
            "precision": 0.25758,
            "recall": 0.24603,
            "fmeasure": 0.25143
        },
        "rougeL": {
            "precision": 0.34783,
            "recall": 0.34909,
            "fmeasure": 0.34815
        },
        "rougeLsum": {
            "precision": 0.34783,
            "recall": 0.34909,
            "fmeasure": 0.34815
        },
        "nubia": {
            "semantic_relation": 3.39581,
            "contradiction": 0.22544,
            "irrelevancy": 99.49694,
            "logical_agreement": 0.27762,
            "grammar_ref": 4.82125,
            "grammar_hyp": 5.40274,
            "nubia_score": 0.41501
        },
        "meteor": 0.2611786107979222,
        "bleurt": -0.38514,
        "bertscore": {
            "precision": 0.86876,
            "recall": 0.84596,
            "f1": 0.85721
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1840": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5714285714285714
        },
        "nist": 1.9876698209426706,
        "bleu": 26.64731,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.57143,
            "fmeasure": 0.61538
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.33333,
            "fmeasure": 0.36364
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.57143,
            "fmeasure": 0.61538
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.57143,
            "fmeasure": 0.61538
        },
        "nubia": {
            "semantic_relation": 4.02411,
            "contradiction": 2.3893,
            "irrelevancy": 0.94772,
            "logical_agreement": 96.66299,
            "grammar_ref": 4.38626,
            "grammar_hyp": 4.79151,
            "nubia_score": 0.68375
        },
        "meteor": 0.4312411957825655,
        "bleurt": 0.7003,
        "bertscore": {
            "precision": 0.96054,
            "recall": 0.92503,
            "f1": 0.94245
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2232": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.2222222222222222,
            "3": 0.5555555555555556
        },
        "nist": 2.2697085511895656,
        "bleu": 30.50639,
        "rouge1": {
            "precision": 0.5625,
            "recall": 0.4697,
            "fmeasure": 0.51084
        },
        "rouge2": {
            "precision": 0.37778,
            "recall": 0.29464,
            "fmeasure": 0.32975
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.34641,
            "fmeasure": 0.36007
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.34641,
            "fmeasure": 0.36007
        },
        "nubia": {
            "semantic_relation": 3.0202,
            "contradiction": 62.97745,
            "irrelevancy": 35.51398,
            "logical_agreement": 1.50858,
            "grammar_ref": 5.24053,
            "grammar_hyp": 5.59269,
            "nubia_score": 0.29784
        },
        "meteor": 0.2273195323604242,
        "bleurt": -0.62689,
        "bertscore": {
            "precision": 0.88415,
            "recall": 0.88076,
            "f1": 0.88122
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_966": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.4,
            "3": 1.0
        },
        "nist": 3.805370600382552,
        "bleu": 53.45211,
        "rouge1": {
            "precision": 0.80556,
            "recall": 0.92857,
            "fmeasure": 0.85348
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.78846,
            "fmeasure": 0.71345
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.88095,
            "fmeasure": 0.8022
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.88095,
            "fmeasure": 0.8022
        },
        "nubia": {
            "semantic_relation": 4.5822,
            "contradiction": 1.59498,
            "irrelevancy": 33.84598,
            "logical_agreement": 64.55905,
            "grammar_ref": 6.35753,
            "grammar_hyp": 7.57417,
            "nubia_score": 0.63577
        },
        "meteor": 0.5393886524709075,
        "bleurt": 0.45475,
        "bertscore": {
            "precision": 0.96823,
            "recall": 0.98807,
            "f1": 0.96292
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_968": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.12336199461765374,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.1219280948873624,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.08389415539832851,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666,
            "3": 0.8125
        },
        "nist": 3.3239685121969553,
        "bleu": 31.9752,
        "rouge1": {
            "precision": 0.68333,
            "recall": 0.7272,
            "fmeasure": 0.70103
        },
        "rouge2": {
            "precision": 0.52632,
            "recall": 0.45455,
            "fmeasure": 0.4878
        },
        "rougeL": {
            "precision": 0.65,
            "recall": 0.56522,
            "fmeasure": 0.60465
        },
        "rougeLsum": {
            "precision": 0.65,
            "recall": 0.56522,
            "fmeasure": 0.60465
        },
        "nubia": {
            "semantic_relation": 4.35152,
            "contradiction": 11.70713,
            "irrelevancy": 18.16682,
            "logical_agreement": 70.12605,
            "grammar_ref": 4.20692,
            "grammar_hyp": 4.17461,
            "nubia_score": 0.77749
        },
        "meteor": 0.4153035515213238,
        "bleurt": 0.51,
        "bertscore": {
            "precision": 0.94045,
            "recall": 0.95708,
            "f1": 0.94869
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_972": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7142857142857143
        },
        "nist": 3.926592062147975,
        "bleu": 24.50341,
        "rouge1": {
            "precision": 0.80392,
            "recall": 0.69758,
            "fmeasure": 0.74659
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.32222,
            "fmeasure": 0.34641
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.57978,
            "fmeasure": 0.61988
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.57978,
            "fmeasure": 0.61988
        },
        "nubia": {
            "semantic_relation": 4.18498,
            "contradiction": 0.21419,
            "irrelevancy": 33.28813,
            "logical_agreement": 66.49768,
            "grammar_ref": 4.42639,
            "grammar_hyp": 4.43353,
            "nubia_score": 0.74514
        },
        "meteor": 0.37423520854850306,
        "bleurt": 0.26882,
        "bertscore": {
            "precision": 0.93037,
            "recall": 0.92685,
            "f1": 0.92861
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1878": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 39,
        "mean_pred_length": 19.5,
        "std_pred_length": 1.5,
        "median_pred_length": 19.5,
        "min_pred_length": 18,
        "max_pred_length": 21,
        "distinct-1": 0.7435897435897436,
        "vocab_size-1": 29,
        "unique-1": 23,
        "entropy-1": 4.660670732282753,
        "distinct-2": 0.972972972972973,
        "vocab_size-2": 36,
        "unique-2": 35,
        "entropy-2": 5.155399311574899,
        "cond_entropy-2": 0.47444379478292487,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": -0.023027491541126217,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7941176470588235,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.5695322390610205,
        "distinct-2-nopunct": 0.96875,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.9375,
        "cond_entropy-2-nopunct": 0.4003384235758112,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.02644273772481478,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 1.0,
            "3": 0.8
        },
        "nist": 5.243830341027058,
        "bleu": 80.59148,
        "rouge1": {
            "precision": 0.90414,
            "recall": 0.82686,
            "fmeasure": 0.86331
        },
        "rouge2": {
            "precision": 0.80821,
            "recall": 0.73606,
            "fmeasure": 0.77
        },
        "rougeL": {
            "precision": 0.90414,
            "recall": 0.82686,
            "fmeasure": 0.86331
        },
        "rougeLsum": {
            "precision": 0.90414,
            "recall": 0.82686,
            "fmeasure": 0.86331
        },
        "nubia": {
            "semantic_relation": 4.04806,
            "contradiction": 35.89683,
            "irrelevancy": 2.98105,
            "logical_agreement": 61.12212,
            "grammar_ref": 4.13564,
            "grammar_hyp": 3.89723,
            "nubia_score": 0.72157
        },
        "meteor": 0.5143428739344426,
        "bleurt": 0.64432,
        "bertscore": {
            "precision": 0.97881,
            "recall": 0.968,
            "f1": 0.96902
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_976": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 20,
        "unique-1": 16,
        "entropy-1": 4.251629167387823,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.28642554229237843,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8260869565217391,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.175735869100492,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.2995060262166482,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.9333333333333333
        },
        "nist": 3.4942197687328003,
        "bleu": 66.89605,
        "rouge1": {
            "precision": 0.78261,
            "recall": 0.94737,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.88889,
            "fmeasure": 0.8
        },
        "rougeL": {
            "precision": 0.78261,
            "recall": 0.94737,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.78261,
            "recall": 0.94737,
            "fmeasure": 0.85714
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.10001,
            "irrelevancy": 0.60319,
            "logical_agreement": 99.2968,
            "grammar_ref": 3.47563,
            "grammar_hyp": 3.33557,
            "nubia_score": 0.99701
        },
        "meteor": 0.5269983999125724,
        "bleurt": 0.67699,
        "bertscore": {
            "precision": 0.94736,
            "recall": 0.96541,
            "f1": 0.9563
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_980": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9565217391304348,
        "vocab_size-1": 22,
        "unique-1": 21,
        "entropy-1": 4.436605434317882,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.026778753489375348,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9545454545454546,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.368522527728205,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.02812389937955851,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.5
        },
        "nist": 1.9529006912445332,
        "bleu": 14.3932,
        "rouge1": {
            "precision": 0.5942,
            "recall": 0.5381,
            "fmeasure": 0.562
        },
        "rouge2": {
            "precision": 0.27273,
            "recall": 0.24848,
            "fmeasure": 0.25874
        },
        "rougeL": {
            "precision": 0.3913,
            "recall": 0.3165,
            "fmeasure": 0.34836
        },
        "rougeLsum": {
            "precision": 0.3913,
            "recall": 0.3165,
            "fmeasure": 0.34836
        },
        "nubia": {
            "semantic_relation": 3.90293,
            "contradiction": 26.212,
            "irrelevancy": 52.4466,
            "logical_agreement": 21.3414,
            "grammar_ref": 3.59602,
            "grammar_hyp": 4.60711,
            "nubia_score": 0.50643
        },
        "meteor": 0.24924772158175207,
        "bleurt": -0.36251,
        "bertscore": {
            "precision": 0.86813,
            "recall": 0.84937,
            "f1": 0.85417
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2233": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "nist": 3.354990287206174,
        "bleu": 69.97522,
        "rouge1": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "rouge2": {
            "precision": 0.85,
            "recall": 0.81818,
            "fmeasure": 0.83333
        },
        "rougeL": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "rougeLsum": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.37452,
            "irrelevancy": 0.52123,
            "logical_agreement": 99.10425,
            "grammar_ref": 4.19853,
            "grammar_hyp": 3.27977,
            "nubia_score": 1.0
        },
        "meteor": 0.5740797318313066,
        "bleurt": 0.72733,
        "bertscore": {
            "precision": 0.95106,
            "recall": 0.98284,
            "f1": 0.96669
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1890": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6428571428571429
        },
        "nist": 1.5677117184814275,
        "bleu": 11.64621,
        "rouge1": {
            "precision": 0.69231,
            "recall": 0.52941,
            "fmeasure": 0.6
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.25,
            "fmeasure": 0.28571
        },
        "rougeL": {
            "precision": 0.53846,
            "recall": 0.41176,
            "fmeasure": 0.46667
        },
        "rougeLsum": {
            "precision": 0.53846,
            "recall": 0.41176,
            "fmeasure": 0.46667
        },
        "nubia": {
            "semantic_relation": 4.02161,
            "contradiction": 0.20815,
            "irrelevancy": 0.97497,
            "logical_agreement": 98.81689,
            "grammar_ref": 4.71038,
            "grammar_hyp": 4.86882,
            "nubia_score": 0.64879
        },
        "meteor": 0.2679298781767831,
        "bleurt": 0.2702,
        "bertscore": {
            "precision": 0.91007,
            "recall": 0.89421,
            "f1": 0.90207
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1908": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nist": 1.7434083720953837,
        "bleu": 9.23843,
        "rouge1": {
            "precision": 0.46154,
            "recall": 0.54971,
            "fmeasure": 0.48864
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.2037,
            "fmeasure": 0.17778
        },
        "rougeL": {
            "precision": 0.38462,
            "recall": 0.45809,
            "fmeasure": 0.4072
        },
        "rougeLsum": {
            "precision": 0.38462,
            "recall": 0.45809,
            "fmeasure": 0.4072
        },
        "nubia": {
            "semantic_relation": 4.43654,
            "contradiction": 0.08354,
            "irrelevancy": 4.97243,
            "logical_agreement": 94.94403,
            "grammar_ref": 3.44041,
            "grammar_hyp": 3.39319,
            "nubia_score": 0.88026
        },
        "meteor": 0.3239693003879582,
        "bleurt": 0.41639,
        "bertscore": {
            "precision": 0.91449,
            "recall": 0.93982,
            "f1": 0.92698
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_990": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.5,
        "vocab_size-1": 12,
        "unique-1": 2,
        "entropy-1": 3.5016291673878226,
        "distinct-2": 0.5909090909090909,
        "vocab_size-2": 13,
        "unique-2": 4,
        "entropy-2": 3.6412498004554794,
        "cond_entropy-2": 0.14719639064341367,
        "distinct-3": 0.65,
        "vocab_size-3": 13,
        "unique-3": 6,
        "entropy-3": 3.6219280948873624,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.5,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 2,
        "entropy-1-nopunct": 3.368522527728207,
        "distinct-2-nopunct": 0.6,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 3.521928094887362,
        "cond_entropy-2-nopunct": 0.162496476250065,
        "distinct-3-nopunct": 0.6666666666666666,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 3.503258334775645,
        "cond_entropy-3-nopunct": -0.04089198233393866,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714,
            "3": 0.631578947368421
        },
        "nist": 3.0753781696409983,
        "bleu": 33.51347,
        "rouge1": {
            "precision": 0.89394,
            "recall": 0.73769,
            "fmeasure": 0.80135
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.66667,
            "fmeasure": 0.64857
        },
        "rougeL": {
            "precision": 0.84848,
            "recall": 0.70644,
            "fmeasure": 0.76431
        },
        "rougeLsum": {
            "precision": 0.84848,
            "recall": 0.70644,
            "fmeasure": 0.76431
        },
        "nubia": {
            "semantic_relation": 4.02848,
            "contradiction": 0.21257,
            "irrelevancy": 17.70474,
            "logical_agreement": 82.08268,
            "grammar_ref": 4.70595,
            "grammar_hyp": 5.88377,
            "nubia_score": 0.53293
        },
        "meteor": 0.36452479981371805,
        "bleurt": 0.30361,
        "bertscore": {
            "precision": 0.96054,
            "recall": 0.88556,
            "f1": 0.92145
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1000": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.5
        },
        "nist": 1.508843745621185,
        "bleu": 10.55267,
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.54545,
            "fmeasure": 0.54545
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.4,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.54545,
            "fmeasure": 0.54545
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.54545,
            "fmeasure": 0.54545
        },
        "nubia": {
            "semantic_relation": 4.77365,
            "contradiction": 0.34933,
            "irrelevancy": 0.63561,
            "logical_agreement": 99.01505,
            "grammar_ref": 3.90557,
            "grammar_hyp": 4.32945,
            "nubia_score": 0.90901
        },
        "meteor": 0.1985490013826504,
        "bleurt": -0.30716,
        "bertscore": {
            "precision": 0.85197,
            "recall": 0.85544,
            "f1": 0.85147
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2247": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 29,
        "mean_pred_length": 9.666666666666666,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 10,
        "distinct-1": 0.5862068965517241,
        "vocab_size-1": 17,
        "unique-1": 9,
        "entropy-1": 3.9262723741395074,
        "distinct-2": 0.7307692307692307,
        "vocab_size-2": 19,
        "unique-2": 13,
        "entropy-2": 4.132944044980958,
        "cond_entropy-2": 0.13129622317994066,
        "distinct-3": 0.8260869565217391,
        "vocab_size-3": 19,
        "unique-3": 15,
        "entropy-3": 4.1757358691004915,
        "cond_entropy-3": -0.08992124034494874,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.625,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.740601562950723,
        "distinct-2-nopunct": 0.8095238095238095,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 4.011365041826378,
        "cond_entropy-2-nopunct": 0.16496325559698213,
        "distinct-3-nopunct": 0.8888888888888888,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.94770277922009,
        "cond_entropy-3-nopunct": -0.11128131022533687,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7037037037037037
        },
        "nist": 3.165506328899895,
        "bleu": 58.83776,
        "rouge1": {
            "precision": 0.92222,
            "recall": 0.79325,
            "fmeasure": 0.84303
        },
        "rouge2": {
            "precision": 0.79012,
            "recall": 0.69938,
            "fmeasure": 0.73264
        },
        "rougeL": {
            "precision": 0.92222,
            "recall": 0.79325,
            "fmeasure": 0.84303
        },
        "rougeLsum": {
            "precision": 0.92222,
            "recall": 0.79325,
            "fmeasure": 0.84303
        },
        "nubia": {
            "semantic_relation": 4.26651,
            "contradiction": 27.0207,
            "irrelevancy": 13.64259,
            "logical_agreement": 59.33671,
            "grammar_ref": 4.42296,
            "grammar_hyp": 4.43557,
            "nubia_score": 0.75137
        },
        "meteor": 0.4771917432722168,
        "bleurt": 0.52627,
        "bertscore": {
            "precision": 0.97637,
            "recall": 0.93233,
            "f1": 0.95265
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2248": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.046930949929641655,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.546593564294939,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 1.0
        },
        "nist": 2.9991662387674958,
        "bleu": 54.45179,
        "rouge1": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rougeL": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "rougeLsum": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "nubia": {
            "semantic_relation": 4.31239,
            "contradiction": 11.29198,
            "irrelevancy": 84.38835,
            "logical_agreement": 4.31966,
            "grammar_ref": 4.85772,
            "grammar_hyp": 5.14735,
            "nubia_score": 0.58383
        },
        "meteor": 0.5777337135978416,
        "bleurt": 0.49208,
        "bertscore": {
            "precision": 0.97343,
            "recall": 0.97664,
            "f1": 0.97503
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2260": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 1.0
        },
        "nist": 2.388588815861315,
        "bleu": 20.55668,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.5,
            "fmeasure": 0.47059
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.28571,
            "fmeasure": 0.26667
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.5,
            "fmeasure": 0.47059
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.5,
            "fmeasure": 0.47059
        },
        "nubia": {
            "semantic_relation": 3.97067,
            "contradiction": 0.3892,
            "irrelevancy": 69.78142,
            "logical_agreement": 29.82938,
            "grammar_ref": 5.57872,
            "grammar_hyp": 7.24518,
            "nubia_score": 0.4354
        },
        "meteor": 0.33860127940823076,
        "bleurt": -0.50165,
        "bertscore": {
            "precision": 0.87178,
            "recall": 0.90626,
            "f1": 0.88868
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_540": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 5,
        "total_length": 78,
        "mean_pred_length": 15.6,
        "std_pred_length": 4.17612260356422,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.7051282051282052,
        "vocab_size-1": 55,
        "unique-1": 48,
        "entropy-1": 5.415218847311903,
        "distinct-2": 0.9452054794520548,
        "vocab_size-2": 69,
        "unique-2": 65,
        "entropy-2": 6.080235517784136,
        "cond_entropy-2": 0.5655821003806506,
        "distinct-3": 0.9705882352941176,
        "vocab_size-3": 66,
        "unique-3": 64,
        "entropy-3": 6.02863931183858,
        "cond_entropy-3": -0.04353818821791297,
        "total_length-nopunct": 69,
        "mean_pred_length-nopunct": 13.8,
        "std_pred_length-nopunct": 4.48998886412873,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7391304347826086,
        "vocab_size-1-nopunct": 51,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.32208007262613,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 60,
        "unique-2-nopunct": 56,
        "entropy-2-nopunct": 5.875,
        "cond_entropy-2-nopunct": 0.6143608948857432,
        "distinct-3-nopunct": 0.9661016949152542,
        "vocab_size-3-nopunct": 57,
        "unique-3-nopunct": 55,
        "entropy-3-nopunct": 5.814846439192345,
        "cond_entropy-3-nopunct": -0.0495603404686672,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1875,
            "2": 0.875,
            "3": 0.9761904761904762
        },
        "nist": 5.813062542297611,
        "bleu": 67.93214,
        "rouge1": {
            "precision": 0.88158,
            "recall": 0.90081,
            "fmeasure": 0.88591
        },
        "rouge2": {
            "precision": 0.69623,
            "recall": 0.71129,
            "fmeasure": 0.6981
        },
        "rougeL": {
            "precision": 0.81206,
            "recall": 0.83891,
            "fmeasure": 0.82015
        },
        "rougeLsum": {
            "precision": 0.81206,
            "recall": 0.83891,
            "fmeasure": 0.82015
        },
        "nubia": {
            "semantic_relation": 4.32364,
            "contradiction": 24.80423,
            "irrelevancy": 24.39701,
            "logical_agreement": 50.79876,
            "grammar_ref": 4.71659,
            "grammar_hyp": 4.60831,
            "nubia_score": 0.77458
        },
        "meteor": 0.517278801226821,
        "bleurt": 0.49403,
        "bertscore": {
            "precision": 0.9507,
            "recall": 0.96846,
            "f1": 0.95862
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1005": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.2776134368191165,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0,
            "3": 0.7777777777777778
        },
        "nist": 3.8998572512287097,
        "bleu": 70.97039,
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.79167,
            "recall": 0.63333,
            "fmeasure": 0.7037
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "nubia": {
            "semantic_relation": 4.63806,
            "contradiction": 0.24928,
            "irrelevancy": 0.95419,
            "logical_agreement": 98.79652,
            "grammar_ref": 4.98843,
            "grammar_hyp": 5.32995,
            "nubia_score": 0.87141
        },
        "meteor": 0.5047034859011716,
        "bleurt": 0.5631,
        "bertscore": {
            "precision": 0.98967,
            "recall": 0.97294,
            "f1": 0.98123
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2262": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.031262576450960075,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.625
        },
        "nist": 1.290049191559112,
        "bleu": 5.23752,
        "rouge1": {
            "precision": 0.31579,
            "recall": 0.6,
            "fmeasure": 0.41379
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.22222,
            "fmeasure": 0.14815
        },
        "rougeL": {
            "precision": 0.31579,
            "recall": 0.6,
            "fmeasure": 0.41379
        },
        "rougeLsum": {
            "precision": 0.31579,
            "recall": 0.6,
            "fmeasure": 0.41379
        },
        "nubia": {
            "semantic_relation": 4.07591,
            "contradiction": 0.08023,
            "irrelevancy": 99.76757,
            "logical_agreement": 0.1522,
            "grammar_ref": 5.64952,
            "grammar_hyp": 3.55524,
            "nubia_score": 0.81977
        },
        "meteor": 0.22515285862098355,
        "bleurt": 0.02517,
        "bertscore": {
            "precision": 0.82773,
            "recall": 0.90626,
            "f1": 0.86522
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2280": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.051189449246730745,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322734,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.867976246918685,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nubia": {
            "semantic_relation": 4.77875,
            "contradiction": 0.20639,
            "irrelevancy": 0.55532,
            "logical_agreement": 99.23829,
            "grammar_ref": 4.35803,
            "grammar_hyp": 4.93905,
            "nubia_score": 0.9019
        },
        "meteor": 1.0,
        "bleurt": 0.73788,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_543": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8333333333333334
        },
        "nist": 2.1055161915432032,
        "bleu": 41.11336,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.6,
            "fmeasure": 0.54545
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "nubia": {
            "semantic_relation": 4.01521,
            "contradiction": 10.23484,
            "irrelevancy": 37.69891,
            "logical_agreement": 52.06625,
            "grammar_ref": 7.84225,
            "grammar_hyp": 7.31486,
            "nubia_score": 0.66591
        },
        "meteor": 0.4231469901582543,
        "bleurt": 0.18287,
        "bertscore": {
            "precision": 0.93887,
            "recall": 0.95113,
            "f1": 0.94496
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2960": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.75,
        "vocab_size-1": 12,
        "unique-1": 9,
        "entropy-1": 3.452819531114783,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 14,
        "unique-2": 13,
        "entropy-2": 3.7735572622751845,
        "cond_entropy-2": 0.3572164290860831,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": 0.04332146930622849,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7333333333333333,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.3232314287976203,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.6644977792004623,
        "cond_entropy-2-nopunct": 0.38295629088933336,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": 0.04693094992964167,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 1.9605832443099285,
        "bleu": 16.45193,
        "rouge1": {
            "precision": 0.41176,
            "recall": 0.79545,
            "fmeasure": 0.54
        },
        "rouge2": {
            "precision": 0.27083,
            "recall": 0.60119,
            "fmeasure": 0.37319
        },
        "rougeL": {
            "precision": 0.41176,
            "recall": 0.79545,
            "fmeasure": 0.54
        },
        "rougeLsum": {
            "precision": 0.41176,
            "recall": 0.79545,
            "fmeasure": 0.54
        },
        "nubia": {
            "semantic_relation": 2.87105,
            "contradiction": 0.15006,
            "irrelevancy": 99.67465,
            "logical_agreement": 0.17528,
            "grammar_ref": 3.66596,
            "grammar_hyp": 2.30837,
            "nubia_score": 0.53429
        },
        "meteor": 0.408726347872756,
        "bleurt": 0.11766,
        "bertscore": {
            "precision": 0.85352,
            "recall": 0.91625,
            "f1": 0.88377
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2976": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.75
        },
        "nist": 1.2247033945245331,
        "bleu": 15.6197,
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.63492,
            "fmeasure": 0.60073
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.37778,
            "fmeasure": 0.35354
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.63492,
            "fmeasure": 0.60073
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.63492,
            "fmeasure": 0.60073
        },
        "nubia": {
            "semantic_relation": 3.0362,
            "contradiction": 18.96535,
            "irrelevancy": 75.39687,
            "logical_agreement": 5.63779,
            "grammar_ref": 6.44614,
            "grammar_hyp": 5.77542,
            "nubia_score": 0.40537
        },
        "meteor": 0.2684504602000365,
        "bleurt": -0.97798,
        "bertscore": {
            "precision": 0.8654,
            "recall": 0.89754,
            "f1": 0.88118
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_544": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.875
        },
        "nist": 2.5035107458649075,
        "bleu": 57.06746,
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.88889,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.75,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.88889,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.88889,
            "fmeasure": 0.8
        },
        "nubia": {
            "semantic_relation": 4.87749,
            "contradiction": 0.54964,
            "irrelevancy": 28.01129,
            "logical_agreement": 71.43907,
            "grammar_ref": 5.45224,
            "grammar_hyp": 4.74617,
            "nubia_score": 0.97273
        },
        "meteor": 0.5514828886907929,
        "bleurt": 0.67145,
        "bertscore": {
            "precision": 0.96665,
            "recall": 0.9834,
            "f1": 0.97495
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_545": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 1.5,
        "median_pred_length": 11.5,
        "min_pred_length": 10,
        "max_pred_length": 13,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": -0.036006438040157185,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.14438990933517493,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.04089198233393866,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.8947368421052632
        },
        "nist": 4.6581610197849885,
        "bleu": 76.50871,
        "rouge1": {
            "precision": 0.95455,
            "recall": 0.83965,
            "fmeasure": 0.89081
        },
        "rouge2": {
            "precision": 0.82083,
            "recall": 0.72273,
            "fmeasure": 0.7654
        },
        "rougeL": {
            "precision": 0.95455,
            "recall": 0.83965,
            "fmeasure": 0.89081
        },
        "rougeLsum": {
            "precision": 0.95455,
            "recall": 0.83965,
            "fmeasure": 0.89081
        },
        "nubia": {
            "semantic_relation": 4.50448,
            "contradiction": 0.69848,
            "irrelevancy": 1.52816,
            "logical_agreement": 97.77336,
            "grammar_ref": 5.62679,
            "grammar_hyp": 5.89083,
            "nubia_score": 0.79149
        },
        "meteor": 0.4905609924994489,
        "bleurt": 0.57434,
        "bertscore": {
            "precision": 0.98147,
            "recall": 0.95541,
            "f1": 0.96808
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4340": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.8571428571428571
        },
        "nist": 3.4896841639750997,
        "bleu": 89.48393,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.71717,
            "fmeasure": 0.78638
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.4375,
            "fmeasure": 0.46667
        },
        "rougeL": {
            "precision": 0.6875,
            "recall": 0.58081,
            "fmeasure": 0.62848
        },
        "rougeLsum": {
            "precision": 0.6875,
            "recall": 0.58081,
            "fmeasure": 0.62848
        },
        "nubia": {
            "semantic_relation": 4.32287,
            "contradiction": 0.20943,
            "irrelevancy": 14.17715,
            "logical_agreement": 85.61343,
            "grammar_ref": 5.60099,
            "grammar_hyp": 5.20109,
            "nubia_score": 0.85843
        },
        "meteor": 0.540784604606,
        "bleurt": 0.34207,
        "bertscore": {
            "precision": 0.98426,
            "recall": 0.96072,
            "f1": 0.97235
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3000": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 14,
        "unique-1": 11,
        "entropy-1": 3.6163485660751626,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 17,
        "unique-2": 16,
        "entropy-2": 4.058813890331201,
        "cond_entropy-2": 0.47755304355428224,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": 0.03518489863155644,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.6875,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.25,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7735572622751845,
        "cond_entropy-2-nopunct": 0.5735572622751851,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": 0.04332146930622849,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.7777777777777778
        },
        "nist": 2.298860202137272,
        "bleu": 12.67372,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.66667,
            "fmeasure": 0.64516
        },
        "rouge2": {
            "precision": 0.23333,
            "recall": 0.25,
            "fmeasure": 0.24138
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.4,
            "fmeasure": 0.3871
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.4,
            "fmeasure": 0.3871
        },
        "nubia": {
            "semantic_relation": 3.84072,
            "contradiction": 22.80561,
            "irrelevancy": 67.41333,
            "logical_agreement": 9.78106,
            "grammar_ref": 5.62728,
            "grammar_hyp": 4.92647,
            "nubia_score": 0.6082
        },
        "meteor": 0.31731231446195296,
        "bleurt": -0.29232,
        "bertscore": {
            "precision": 0.90739,
            "recall": 0.91116,
            "f1": 0.90927
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4352": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.043321469306228516,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.9230769230769231
        },
        "nist": 4.373609831586596,
        "bleu": 85.22457,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9375,
            "fmeasure": 0.96774
        },
        "rouge2": {
            "precision": 0.92857,
            "recall": 0.86667,
            "fmeasure": 0.89655
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9375,
            "fmeasure": 0.96774
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9375,
            "fmeasure": 0.96774
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.35488,
            "irrelevancy": 10.42506,
            "logical_agreement": 89.22006,
            "grammar_ref": 4.10709,
            "grammar_hyp": 4.15345,
            "nubia_score": 0.98846
        },
        "meteor": 0.5747920211718521,
        "bleurt": 0.78906,
        "bertscore": {
            "precision": 0.99784,
            "recall": 0.98969,
            "f1": 0.99375
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5082": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 3.168269496489025,
        "bleu": 64.75445,
        "rouge1": {
            "precision": 0.74359,
            "recall": 1.0,
            "fmeasure": 0.85244
        },
        "rouge2": {
            "precision": 0.63889,
            "recall": 0.88426,
            "fmeasure": 0.74127
        },
        "rougeL": {
            "precision": 0.74359,
            "recall": 1.0,
            "fmeasure": 0.85244
        },
        "rougeLsum": {
            "precision": 0.74359,
            "recall": 1.0,
            "fmeasure": 0.85244
        },
        "nubia": {
            "semantic_relation": 4.30022,
            "contradiction": 0.30497,
            "irrelevancy": 95.91544,
            "logical_agreement": 3.77959,
            "grammar_ref": 4.96639,
            "grammar_hyp": 5.07776,
            "nubia_score": 0.64536
        },
        "meteor": 0.5581625488784977,
        "bleurt": 0.28435,
        "bertscore": {
            "precision": 0.92253,
            "recall": 0.9594,
            "f1": 0.94061
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_549": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 1.0,
        "median_pred_length": 19.0,
        "min_pred_length": 18,
        "max_pred_length": 20,
        "distinct-1": 0.7894736842105263,
        "vocab_size-1": 30,
        "unique-1": 24,
        "entropy-1": 4.787143960698141,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.35282457145225304,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.686146588249909,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.38510428436278793,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.09019780897157811,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.8,
            "3": 0.6521739130434783
        },
        "nist": 3.159037724502846,
        "bleu": 15.02733,
        "rouge1": {
            "precision": 0.6557,
            "recall": 0.76511,
            "fmeasure": 0.70139
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.37692,
            "fmeasure": 0.33118
        },
        "rougeL": {
            "precision": 0.49178,
            "recall": 0.58162,
            "fmeasure": 0.52872
        },
        "rougeLsum": {
            "precision": 0.49178,
            "recall": 0.58162,
            "fmeasure": 0.52872
        },
        "nubia": {
            "semantic_relation": 4.19273,
            "contradiction": 0.27603,
            "irrelevancy": 75.8927,
            "logical_agreement": 23.83127,
            "grammar_ref": 4.72797,
            "grammar_hyp": 4.31626,
            "nubia_score": 0.73999
        },
        "meteor": 0.39078206655368347,
        "bleurt": 0.1033,
        "bertscore": {
            "precision": 0.90959,
            "recall": 0.92936,
            "f1": 0.91934
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_550": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 5.0,
        "median_pred_length": 19.0,
        "min_pred_length": 14,
        "max_pred_length": 24,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 34,
        "unique-1": 30,
        "entropy-1": 5.0374011976541135,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.08866415466539351,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9142857142857143,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.957854445516392,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.09692928423166855,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.09019780897157811,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.25,
            "3": 0.8571428571428571
        },
        "nist": 4.230201262613105,
        "bleu": 54.5968,
        "rouge1": {
            "precision": 0.77369,
            "recall": 0.73134,
            "fmeasure": 0.74291
        },
        "rouge2": {
            "precision": 0.47348,
            "recall": 0.49406,
            "fmeasure": 0.47836
        },
        "rougeL": {
            "precision": 0.55017,
            "recall": 0.59507,
            "fmeasure": 0.56294
        },
        "rougeLsum": {
            "precision": 0.55017,
            "recall": 0.59507,
            "fmeasure": 0.56294
        },
        "nubia": {
            "semantic_relation": 4.34091,
            "contradiction": 0.50609,
            "irrelevancy": 1.88492,
            "logical_agreement": 97.60899,
            "grammar_ref": 4.42501,
            "grammar_hyp": 4.70071,
            "nubia_score": 0.73023
        },
        "meteor": 0.45245593923511324,
        "bleurt": 0.26401,
        "bertscore": {
            "precision": 0.93938,
            "recall": 0.93998,
            "f1": 0.93831
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3008": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9285714285714286
        },
        "nist": 4.049748410536706,
        "bleu": 80.03203,
        "rouge1": {
            "precision": 0.92857,
            "recall": 0.87395,
            "fmeasure": 0.89862
        },
        "rouge2": {
            "precision": 0.82051,
            "recall": 0.77244,
            "fmeasure": 0.79399
        },
        "rougeL": {
            "precision": 0.92857,
            "recall": 0.87395,
            "fmeasure": 0.89862
        },
        "rougeLsum": {
            "precision": 0.92857,
            "recall": 0.87395,
            "fmeasure": 0.89862
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.30843,
            "irrelevancy": 0.40659,
            "logical_agreement": 99.28498,
            "grammar_ref": 5.90677,
            "grammar_hyp": 6.88493,
            "nubia_score": 0.82108
        },
        "meteor": 0.5453172261251402,
        "bleurt": 0.68335,
        "bertscore": {
            "precision": 0.99654,
            "recall": 0.99654,
            "f1": 0.99654
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_552": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 59,
        "mean_pred_length": 19.666666666666668,
        "std_pred_length": 5.734883511361751,
        "median_pred_length": 19.0,
        "min_pred_length": 13,
        "max_pred_length": 27,
        "distinct-1": 0.6949152542372882,
        "vocab_size-1": 41,
        "unique-1": 33,
        "entropy-1": 5.105112490363071,
        "distinct-2": 0.9821428571428571,
        "vocab_size-2": 55,
        "unique-2": 54,
        "entropy-2": 5.7716406363433235,
        "cond_entropy-2": 0.6515757651865651,
        "distinct-3": 1.0,
        "vocab_size-3": 53,
        "unique-3": 53,
        "entropy-3": 5.727920454563195,
        "cond_entropy-3": -0.04169861843780113,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 17.333333333333332,
        "std_pred_length-nopunct": 5.312459150169742,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.063527882011021,
        "distinct-2-nopunct": 0.9795918367346939,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.5738935175845965,
        "cond_entropy-2-nopunct": 0.5493602377856216,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.5235619560570095,
        "cond_entropy-3-nopunct": -0.04766962718863017,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.6206896551724138
        },
        "nist": 2.2161720668079528,
        "bleu": 20.60851,
        "rouge1": {
            "precision": 0.4099,
            "recall": 0.57506,
            "fmeasure": 0.46826
        },
        "rouge2": {
            "precision": 0.17693,
            "recall": 0.3265,
            "fmeasure": 0.22861
        },
        "rougeL": {
            "precision": 0.34687,
            "recall": 0.5044,
            "fmeasure": 0.40237
        },
        "rougeLsum": {
            "precision": 0.34687,
            "recall": 0.5044,
            "fmeasure": 0.40237
        },
        "nubia": {
            "semantic_relation": 3.21808,
            "contradiction": 33.01218,
            "irrelevancy": 33.59178,
            "logical_agreement": 33.39604,
            "grammar_ref": 4.76688,
            "grammar_hyp": 4.01793,
            "nubia_score": 0.49548
        },
        "meteor": 0.27045575386835835,
        "bleurt": 0.00331,
        "bertscore": {
            "precision": 0.83177,
            "recall": 0.88072,
            "f1": 0.85398
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3016": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.8,
        "vocab_size-1": 8,
        "unique-1": 6,
        "entropy-1": 2.9219280948873623,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 8,
        "unique-2": 7,
        "entropy-2": 2.94770277922009,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": 0.08007499855768763,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.725480556997868,
        "distinct-2-nopunct": 0.875,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.75,
        "cond_entropy-2-nopunct": -0.04492500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.04978793508525296,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.47872969366552,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.20451,
            "irrelevancy": 0.76191,
            "logical_agreement": 98.03358,
            "grammar_ref": 4.07249,
            "grammar_hyp": 4.01604,
            "nubia_score": 0.98068
        },
        "meteor": 1.0,
        "bleurt": 0.9148,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_553": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 57,
        "mean_pred_length": 19.0,
        "std_pred_length": 5.887840577551898,
        "median_pred_length": 17.0,
        "min_pred_length": 13,
        "max_pred_length": 27,
        "distinct-1": 0.8245614035087719,
        "vocab_size-1": 47,
        "unique-1": 41,
        "entropy-1": 5.4290382596269495,
        "distinct-2": 0.9814814814814815,
        "vocab_size-2": 53,
        "unique-2": 52,
        "entropy-2": 5.717850465126429,
        "cond_entropy-2": 0.22319494182262314,
        "distinct-3": 1.0,
        "vocab_size-3": 51,
        "unique-3": 51,
        "entropy-3": 5.6724253419715005,
        "cond_entropy-3": -0.043246473917463175,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 5.887840577551898,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8518518518518519,
        "vocab_size-1-nopunct": 46,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.416653011302534,
        "distinct-2-nopunct": 0.9803921568627451,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.63320965569699,
        "cond_entropy-2-nopunct": 0.2364527909156818,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.5849625007211605,
        "cond_entropy-3-nopunct": -0.04579617458367275,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.5217391304347826,
            "3": 0.5882352941176471
        },
        "nist": 3.074930380728074,
        "bleu": 15.91,
        "rouge1": {
            "precision": 0.48898,
            "recall": 0.64836,
            "fmeasure": 0.55128
        },
        "rouge2": {
            "precision": 0.22827,
            "recall": 0.3254,
            "fmeasure": 0.26361
        },
        "rougeL": {
            "precision": 0.44197,
            "recall": 0.57526,
            "fmeasure": 0.49414
        },
        "rougeLsum": {
            "precision": 0.44197,
            "recall": 0.57526,
            "fmeasure": 0.49414
        },
        "nubia": {
            "semantic_relation": 3.93619,
            "contradiction": 0.43153,
            "irrelevancy": 79.94115,
            "logical_agreement": 19.62732,
            "grammar_ref": 4.61531,
            "grammar_hyp": 4.87495,
            "nubia_score": 0.65365
        },
        "meteor": 0.2800408403815979,
        "bleurt": 0.1376,
        "bertscore": {
            "precision": 0.86658,
            "recall": 0.90312,
            "f1": 0.88321
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_555": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.3764992953429935,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.23486,
            "irrelevancy": 0.53273,
            "logical_agreement": 99.23241,
            "grammar_ref": 4.18747,
            "grammar_hyp": 4.4235,
            "nubia_score": 0.98266
        },
        "meteor": 1.0,
        "bleurt": 0.91462,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_560": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 3,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 6.847546194724712,
        "median_pred_length": 20.0,
        "min_pred_length": 6,
        "max_pred_length": 21,
        "distinct-1": 0.7659574468085106,
        "vocab_size-1": 36,
        "unique-1": 30,
        "entropy-1": 4.995766245156567,
        "distinct-2": 1.0,
        "vocab_size-2": 44,
        "unique-2": 44,
        "entropy-2": 5.4594316186372955,
        "cond_entropy-2": 0.3937012897852718,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.10187961401921372,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 6.128258770283412,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8292682926829268,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.948896211882388,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.247927513443589,
        "cond_entropy-2-nopunct": 0.3312936009876984,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.11864449649861893,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "nist": 4.052077118208479,
        "bleu": 49.55891,
        "rouge1": {
            "precision": 0.69506,
            "recall": 0.61088,
            "fmeasure": 0.64713
        },
        "rouge2": {
            "precision": 0.40523,
            "recall": 0.36543,
            "fmeasure": 0.38404
        },
        "rougeL": {
            "precision": 0.63951,
            "recall": 0.54878,
            "fmeasure": 0.58784
        },
        "rougeLsum": {
            "precision": 0.63951,
            "recall": 0.54878,
            "fmeasure": 0.58784
        },
        "nubia": {
            "semantic_relation": 4.24967,
            "contradiction": 1.02191,
            "irrelevancy": 10.12383,
            "logical_agreement": 88.85426,
            "grammar_ref": 4.73268,
            "grammar_hyp": 4.93424,
            "nubia_score": 0.74428
        },
        "meteor": 0.41089422467827513,
        "bleurt": 0.18627,
        "bertscore": {
            "precision": 0.93004,
            "recall": 0.90314,
            "f1": 0.91623
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_561": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "nist": 3.0096426297586145,
        "bleu": 57.8357,
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.83333,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.72727,
            "fmeasure": 0.69565
        },
        "rougeL": {
            "precision": 0.76923,
            "recall": 0.83333,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.76923,
            "recall": 0.83333,
            "fmeasure": 0.8
        },
        "nubia": {
            "semantic_relation": 4.63204,
            "contradiction": 0.37861,
            "irrelevancy": 33.60955,
            "logical_agreement": 66.01184,
            "grammar_ref": 4.85143,
            "grammar_hyp": 4.65534,
            "nubia_score": 0.85696
        },
        "meteor": 0.917904473894868,
        "bleurt": 0.48371,
        "bertscore": {
            "precision": 0.95811,
            "recall": 0.96851,
            "f1": 0.96328
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_564": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 2.0,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 12,
        "distinct-1": 0.75,
        "vocab_size-1": 15,
        "unique-1": 10,
        "entropy-1": 3.821928094887362,
        "distinct-2": 0.8333333333333334,
        "vocab_size-2": 15,
        "unique-2": 12,
        "entropy-2": 3.8365916681089787,
        "cond_entropy-2": -0.04089198233393865,
        "distinct-3": 0.875,
        "vocab_size-3": 14,
        "unique-3": 12,
        "entropy-3": 3.75,
        "cond_entropy-3": -0.04492500144231237,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.7254805569978675,
        "distinct-2-nopunct": 0.8125,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.625,
        "cond_entropy-2-nopunct": -0.04492500144231237,
        "distinct-3-nopunct": 0.8571428571428571,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.521640636343319,
        "cond_entropy-3-nopunct": -0.04978793508525296,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.3333333333333333,
            "3": 0.8125
        },
        "nist": 3.7977172204899157,
        "bleu": 56.92923,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.85714,
            "fmeasure": 0.88462
        },
        "rouge2": {
            "precision": 0.80303,
            "recall": 0.75641,
            "fmeasure": 0.77778
        },
        "rougeL": {
            "precision": 0.84722,
            "recall": 0.79762,
            "fmeasure": 0.82051
        },
        "rougeLsum": {
            "precision": 0.84722,
            "recall": 0.79762,
            "fmeasure": 0.82051
        },
        "nubia": {
            "semantic_relation": 4.49394,
            "contradiction": 1.64404,
            "irrelevancy": 28.42628,
            "logical_agreement": 69.92969,
            "grammar_ref": 4.81259,
            "grammar_hyp": 4.75814,
            "nubia_score": 0.83985
        },
        "meteor": 0.4846160613920724,
        "bleurt": 0.70009,
        "bertscore": {
            "precision": 0.98662,
            "recall": 0.98073,
            "f1": 0.98366
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5094": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 1,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.875
        },
        "nist": 3.1550442434976054,
        "bleu": 75.06239,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.81667,
            "fmeasure": 0.84259
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.62434,
            "fmeasure": 0.64286
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.81667,
            "fmeasure": 0.84259
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.81667,
            "fmeasure": 0.84259
        },
        "nubia": {
            "semantic_relation": 4.54425,
            "contradiction": 1.94312,
            "irrelevancy": 1.0632,
            "logical_agreement": 96.99369,
            "grammar_ref": 4.01433,
            "grammar_hyp": 4.79201,
            "nubia_score": 0.75657
        },
        "meteor": 0.9529411764705881,
        "bleurt": 0.64502,
        "bertscore": {
            "precision": 0.97405,
            "recall": 0.97405,
            "f1": 0.97405
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_567": {
        "predictions_file": "ByT5-base (Baseline)/totto_test",
        "N": 2,
        "total_length": 41,
        "mean_pred_length": 20.5,
        "std_pred_length": 0.5,
        "median_pred_length": 20.5,
        "min_pred_length": 20,
        "max_pred_length": 21,
        "distinct-1": 0.8292682926829268,
        "vocab_size-1": 34,
        "unique-1": 29,
        "entropy-1": 4.967308102179057,
        "distinct-2": 1.0,
        "vocab_size-2": 39,
        "unique-2": 39,
        "entropy-2": 5.285402218862247,
        "cond_entropy-2": 0.28682457321852395,
        "distinct-3": 1.0,
        "vocab_size-3": 37,
        "unique-3": 37,
        "entropy-3": 5.209453365628954,
        "cond_entropy-3": -0.07594885323329875,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.786425874087821,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.2787474660498503,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.09019780897157811,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.875,
            "3": 0.8571428571428571
        },
        "nist": 4.208449564093882,
        "bleu": 57.48802,
        "rouge1": {
            "precision": 0.79303,
            "recall": 0.83449,
            "fmeasure": 0.81293
        },
        "rouge2": {
            "precision": 0.67096,
            "recall": 0.72157,
            "fmeasure": 0.69509
        },
        "rougeL": {
            "precision": 0.79303,
            "recall": 0.83449,
            "fmeasure": 0.81293
        },
        "rougeLsum": {
            "precision": 0.79303,
            "recall": 0.83449,
            "fmeasure": 0.81293
        },
        "nubia": {
            "semantic_relation": 3.49051,
            "contradiction": 50.01305,
            "irrelevancy": 49.05585,
            "logical_agreement": 0.93109,
            "grammar_ref": 3.41143,
            "grammar_hyp": 3.33088,
            "nubia_score": 0.64335
        },
        "meteor": 0.49319226569081726,
        "bleurt": 0.22761,
        "bertscore": {
            "precision": 0.9323,
            "recall": 0.95054,
            "f1": 0.94104
        }
    }
}
