{
    "submission_name": "T5-base (Baseline)",
    "param_count": 0,
    "totto_challenge_test_scramble": {
        "predictions_file": "T5-base (Baseline)/totto_challenge_test_scramble",
        "N": 378
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "T5-base (Baseline)/e2e_nlg_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 80,
        "mean_pred_length": 40.0,
        "std_pred_length": 0.0,
        "median_pred_length": 40.0,
        "min_pred_length": 40,
        "max_pred_length": 40,
        "distinct-1": 0.4125,
        "vocab_size-1": 33,
        "unique-1": 0,
        "entropy-1": 4.93418371977919,
        "distinct-2": 0.48717948717948717,
        "vocab_size-2": 38,
        "unique-2": 0,
        "entropy-2": 5.234120167580196,
        "cond_entropy-2": 0.28423758562429485,
        "distinct-3": 0.5,
        "vocab_size-3": 38,
        "unique-3": 0,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": 0.015156873528705482,
        "total_length-nopunct": 76,
        "mean_pred_length-nopunct": 38.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 38.0,
        "min_pred_length-nopunct": 38,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.42105263157894735,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 4.892407118592879,
        "distinct-2-nopunct": 0.4864864864864865,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 5.155399311574899,
        "cond_entropy-2-nopunct": 0.27260085230230846,
        "distinct-3-nopunct": 0.5,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": 0.016027191368918267,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 4.895933354053943,
        "bleu": 54.20021,
        "rouge1": {
            "precision": 0.89474,
            "recall": 0.85213,
            "fmeasure": 0.87237
        },
        "rouge2": {
            "precision": 0.64865,
            "recall": 0.61964,
            "fmeasure": 0.6334
        },
        "rougeL": {
            "precision": 0.46053,
            "recall": 0.44173,
            "fmeasure": 0.45066
        },
        "rougeLsum": {
            "precision": 0.46053,
            "recall": 0.44173,
            "fmeasure": 0.45066
        },
        "local_recall": {
            "1": 0.8714285714285714
        },
        "bertscore": {
            "precision": 0.93675,
            "recall": 0.92928,
            "f1": 0.933
        },
        "bleurt": 0.29455,
        "meteor": 0.45015981566681307,
        "nubia": {
            "semantic_relation": 4.87718,
            "contradiction": 0.2115,
            "irrelevancy": 0.42181,
            "logical_agreement": 99.3667,
            "grammar_ref": 4.16331,
            "grammar_hyp": 4.16743,
            "nubia_score": 0.8952
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_28": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 56,
        "mean_pred_length": 28.0,
        "std_pred_length": 9.0,
        "median_pred_length": 28.0,
        "min_pred_length": 19,
        "max_pred_length": 37,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 40,
        "unique-1": 34,
        "entropy-1": 4.860577243331645,
        "distinct-2": 1.0,
        "vocab_size-2": 54,
        "unique-2": 54,
        "entropy-2": 5.7548875021634665,
        "cond_entropy-2": 0.8923390617476031,
        "distinct-3": 1.0,
        "vocab_size-3": 52,
        "unique-3": 52,
        "entropy-3": 5.700439718141095,
        "cond_entropy-3": -0.054447784022376544,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.201841232302571,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.3219280948873635,
        "cond_entropy-2-nopunct": 0.10461067210860199,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.0740005814437768,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.8248712368423867,
        "bleu": 6.63089,
        "rouge1": {
            "precision": 0.41298,
            "recall": 0.46111,
            "fmeasure": 0.42583
        },
        "rouge2": {
            "precision": 0.15972,
            "recall": 0.18409,
            "fmeasure": 0.16456
        },
        "rougeL": {
            "precision": 0.33789,
            "recall": 0.37222,
            "fmeasure": 0.34687
        },
        "rougeLsum": {
            "precision": 0.33789,
            "recall": 0.37222,
            "fmeasure": 0.34687
        },
        "local_recall": {
            "1": 0.05555555555555555,
            "2": 0.3,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.76931,
            "recall": 0.84097,
            "f1": 0.7927
        },
        "bleurt": -0.06993,
        "meteor": 0.20286489973942962,
        "nubia": {
            "semantic_relation": 3.09059,
            "contradiction": 1.69878,
            "irrelevancy": 97.62944,
            "logical_agreement": 0.67178,
            "grammar_ref": 5.71002,
            "grammar_hyp": 4.10072,
            "nubia_score": 0.52229
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_32": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 30.0,
        "std_pred_length": 0.0,
        "median_pred_length": 30.0,
        "min_pred_length": 30,
        "max_pred_length": 30,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 25,
        "unique-1": 24,
        "entropy-1": 4.389898095464288,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.48591022725446525,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.0506260730699678,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.523561956057013,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": -0.06413033741971555,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.25454914142283,
        "bleu": 39.04311,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.50974,
            "fmeasure": 0.6435
        },
        "rouge2": {
            "precision": 0.56522,
            "recall": 0.32633,
            "fmeasure": 0.41296
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.36266,
            "fmeasure": 0.45853
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.36266,
            "fmeasure": 0.45853
        },
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "bertscore": {
            "precision": 0.96195,
            "recall": 0.87671,
            "f1": 0.91736
        },
        "bleurt": -0.49191,
        "meteor": 0.3081249564930013,
        "nubia": {
            "semantic_relation": 2.56388,
            "contradiction": 36.83088,
            "irrelevancy": 51.27143,
            "logical_agreement": 11.89769,
            "grammar_ref": 4.14314,
            "grammar_hyp": 4.01424,
            "nubia_score": 0.19874
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?select": {
        "predictions_file": "T5-base (Baseline)/cs_restaurants_test",
        "N": 12,
        "msttr-100": 0.47,
        "msttr-100_nopunct": 0.45,
        "total_length": 165,
        "mean_pred_length": 13.75,
        "std_pred_length": 4.639055219905593,
        "median_pred_length": 12.0,
        "min_pred_length": 6,
        "max_pred_length": 20,
        "distinct-1": 0.3151515151515151,
        "vocab_size-1": 52,
        "unique-1": 26,
        "entropy-1": 4.883798734875909,
        "distinct-2": 0.5555555555555556,
        "vocab_size-2": 85,
        "unique-2": 54,
        "entropy-2": 6.151265518962671,
        "cond_entropy-2": 1.1810009784905835,
        "distinct-3": 0.6028368794326241,
        "vocab_size-3": 85,
        "unique-3": 57,
        "entropy-3": 6.195318373245764,
        "cond_entropy-3": 0.056561314428006736,
        "total_length-nopunct": 144,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 4.339738855430512,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.3472222222222222,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.822234035647872,
        "distinct-2-nopunct": 0.553030303030303,
        "vocab_size-2-nopunct": 73,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.921536804797593,
        "cond_entropy-2-nopunct": 1.153536390766997,
        "distinct-3-nopunct": 0.6,
        "vocab_size-3-nopunct": 72,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.95591309517583,
        "cond_entropy-3-nopunct": 0.05703795931628516,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 0.5533200931819289,
        "bleu": 1.05784,
        "rouge1": {
            "precision": 0.28717,
            "recall": 0.28007,
            "fmeasure": 0.27974
        },
        "rouge2": {
            "precision": 0.15833,
            "recall": 0.16434,
            "fmeasure": 0.15933
        },
        "rougeL": {
            "precision": 0.28717,
            "recall": 0.28007,
            "fmeasure": 0.27974
        },
        "rougeLsum": {
            "precision": 0.28717,
            "recall": 0.28007,
            "fmeasure": 0.27974
        },
        "local_recall": {
            "1": 0.0975609756097561
        },
        "bertscore": {
            "precision": 0.814,
            "recall": 0.84281,
            "f1": 0.82801
        },
        "bleurt": -0.83379,
        "meteor": 0.05407769618026543,
        "nubia": {
            "semantic_relation": 2.09645,
            "contradiction": 39.35069,
            "irrelevancy": 32.22176,
            "logical_agreement": 28.42755,
            "grammar_ref": 6.83527,
            "grammar_hyp": 6.52976,
            "nubia_score": 0.19612
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_33": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.9482474682378366,
        "bleu": 39.46425,
        "rouge1": {
            "precision": 0.82353,
            "recall": 0.37838,
            "fmeasure": 0.51852
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.27778,
            "fmeasure": 0.38462
        },
        "rougeL": {
            "precision": 0.64706,
            "recall": 0.2973,
            "fmeasure": 0.40741
        },
        "rougeLsum": {
            "precision": 0.64706,
            "recall": 0.2973,
            "fmeasure": 0.40741
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5833333333333334,
            "3": 0.29411764705882354
        },
        "bertscore": {
            "precision": 0.92799,
            "recall": 0.82055,
            "f1": 0.87097
        },
        "bleurt": -0.30411,
        "meteor": 0.2284940453782765,
        "nubia": {
            "semantic_relation": 3.12202,
            "contradiction": 5.31008,
            "irrelevancy": 33.82442,
            "logical_agreement": 60.8655,
            "grammar_ref": 4.39709,
            "grammar_hyp": 4.88936,
            "nubia_score": 0.28286
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_34": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 55,
        "mean_pred_length": 55.0,
        "std_pred_length": 0.0,
        "median_pred_length": 55.0,
        "min_pred_length": 55,
        "max_pred_length": 55,
        "distinct-1": 0.5454545454545454,
        "vocab_size-1": 30,
        "unique-1": 22,
        "entropy-1": 4.334750207900345,
        "distinct-2": 0.7037037037037037,
        "vocab_size-2": 38,
        "unique-2": 28,
        "entropy-2": 4.97710972438569,
        "cond_entropy-2": 0.6691485814043129,
        "distinct-3": 0.8113207547169812,
        "vocab_size-3": 43,
        "unique-3": 33,
        "entropy-3": 5.350561963997161,
        "cond_entropy-3": 0.3881272920223723,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 36.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 36.0,
        "min_pred_length-nopunct": 36,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.6944444444444444,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.281036112553422,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.843568731230679,
        "cond_entropy-2-nopunct": 0.5879294440740823,
        "distinct-3-nopunct": 0.9117647058823529,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.910992253015045,
        "cond_entropy-3-nopunct": 0.07582688312890223,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.2223551952313956,
        "bleu": 12.62574,
        "rouge1": {
            "precision": 0.23148,
            "recall": 0.39609,
            "fmeasure": 0.29071
        },
        "rouge2": {
            "precision": 0.08571,
            "recall": 0.16111,
            "fmeasure": 0.11184
        },
        "rougeL": {
            "precision": 0.23148,
            "recall": 0.39609,
            "fmeasure": 0.29071
        },
        "rougeLsum": {
            "precision": 0.23148,
            "recall": 0.39609,
            "fmeasure": 0.29071
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.38095238095238093
        },
        "bertscore": {
            "precision": 0.77448,
            "recall": 0.8204,
            "f1": 0.79678
        },
        "bleurt": -1.16825,
        "meteor": 0.18855381395618112,
        "nubia": {
            "semantic_relation": 2.48785,
            "contradiction": 0.65286,
            "irrelevancy": 79.19893,
            "logical_agreement": 20.14821,
            "grammar_ref": 4.75948,
            "grammar_hyp": 3.90486,
            "nubia_score": 0.23578
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_35": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 4.0,
        "median_pred_length": 18.0,
        "min_pred_length": 14,
        "max_pred_length": 22,
        "distinct-1": 0.8055555555555556,
        "vocab_size-1": 29,
        "unique-1": 22,
        "entropy-1": 4.781036112553422,
        "distinct-2": 0.8823529411764706,
        "vocab_size-2": 30,
        "unique-2": 26,
        "entropy-2": 4.852168723603279,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 0.9375,
        "vocab_size-3": 30,
        "unique-3": 28,
        "entropy-3": 4.875,
        "cond_entropy-3": 0.037537158749660585,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.84375,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.6875,
        "distinct-2-nopunct": 0.9,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.706890595608519,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 0.9642857142857143,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.735926350629034,
        "cond_entropy-3-nopunct": 0.04332146930622849,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.097582261318436,
        "bleu": 10.08789,
        "rouge1": {
            "precision": 0.63961,
            "recall": 0.47018,
            "fmeasure": 0.54196
        },
        "rouge2": {
            "precision": 0.25824,
            "recall": 0.18678,
            "fmeasure": 0.21677
        },
        "rougeL": {
            "precision": 0.53571,
            "recall": 0.39386,
            "fmeasure": 0.45396
        },
        "rougeLsum": {
            "precision": 0.53571,
            "recall": 0.39386,
            "fmeasure": 0.45396
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.36363636363636365
        },
        "bertscore": {
            "precision": 0.8652,
            "recall": 0.81946,
            "f1": 0.84136
        },
        "bleurt": -0.18925,
        "meteor": 0.23415545316139538,
        "nubia": {
            "semantic_relation": 3.5227,
            "contradiction": 41.98497,
            "irrelevancy": 51.29937,
            "logical_agreement": 6.71566,
            "grammar_ref": 3.96887,
            "grammar_hyp": 4.58012,
            "nubia_score": 0.40804
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_38": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 12,
        "unique-1": 10,
        "entropy-1": 3.521640636343319,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.2007771037757955,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.21785611591339746,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.0600905711694244,
        "bleu": 5.85516,
        "rouge1": {
            "precision": 0.23077,
            "recall": 0.2,
            "fmeasure": 0.21429
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.07143,
            "fmeasure": 0.07692
        },
        "rougeL": {
            "precision": 0.23077,
            "recall": 0.2,
            "fmeasure": 0.21429
        },
        "rougeLsum": {
            "precision": 0.23077,
            "recall": 0.2,
            "fmeasure": 0.21429
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.25
        },
        "bertscore": {
            "precision": 0.79252,
            "recall": 0.78006,
            "f1": 0.78334
        },
        "bleurt": -0.34068,
        "meteor": 0.11705853950642585,
        "nubia": {
            "semantic_relation": 2.19814,
            "contradiction": 0.37339,
            "irrelevancy": 99.29582,
            "logical_agreement": 0.33079,
            "grammar_ref": 5.48676,
            "grammar_hyp": 4.70782,
            "nubia_score": 0.20289
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_40": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.7486278740651833,
        "bleu": 3.4436,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.26667,
            "fmeasure": 0.33333
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.22222,
            "recall": 0.13333,
            "fmeasure": 0.16667
        },
        "rougeLsum": {
            "precision": 0.22222,
            "recall": 0.13333,
            "fmeasure": 0.16667
        },
        "local_recall": {
            "1": 0,
            "2": 0.3076923076923077
        },
        "bertscore": {
            "precision": 0.79806,
            "recall": 0.74065,
            "f1": 0.76828
        },
        "bleurt": -0.92284,
        "meteor": 0.13665939633594423,
        "nubia": {
            "semantic_relation": 2.45903,
            "contradiction": 21.99102,
            "irrelevancy": 76.20683,
            "logical_agreement": 1.80215,
            "grammar_ref": 5.57252,
            "grammar_hyp": 4.88524,
            "nubia_score": 0.18525
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_41": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.419084227476942,
        "bleu": 83.07018,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.66154,
            "fmeasure": 0.75598
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.55556,
            "fmeasure": 0.57778
        },
        "rougeL": {
            "precision": 0.85185,
            "recall": 0.62821,
            "fmeasure": 0.72089
        },
        "rougeLsum": {
            "precision": 0.85185,
            "recall": 0.62821,
            "fmeasure": 0.72089
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.97063,
            "recall": 0.92974,
            "f1": 0.94975
        },
        "bleurt": 0.16055,
        "meteor": 0.4161361645043209,
        "nubia": {
            "semantic_relation": 3.43791,
            "contradiction": 27.69622,
            "irrelevancy": 34.07058,
            "logical_agreement": 38.23321,
            "grammar_ref": 6.66832,
            "grammar_hyp": 6.72793,
            "nubia_score": 0.4425
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_42": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 35.0,
        "std_pred_length": 0.0,
        "median_pred_length": 35.0,
        "min_pred_length": 35,
        "max_pred_length": 35,
        "distinct-1": 0.4857142857142857,
        "vocab_size-1": 17,
        "unique-1": 7,
        "entropy-1": 3.817393103776576,
        "distinct-2": 0.6764705882352942,
        "vocab_size-2": 23,
        "unique-2": 13,
        "entropy-2": 4.4182014441278845,
        "cond_entropy-2": 0.6393933377974366,
        "distinct-3": 0.7878787878787878,
        "vocab_size-3": 26,
        "unique-3": 19,
        "entropy-3": 4.62015169511603,
        "cond_entropy-3": 0.22223089938579496,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 33.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 33.0,
        "min_pred_length-nopunct": 33,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.45454545454545453,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 3.652995726604101,
        "distinct-2-nopunct": 0.65625,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 4.288909765557392,
        "cond_entropy-2-nopunct": 0.6481452387268641,
        "distinct-3-nopunct": 0.7741935483870968,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.50258340716107,
        "cond_entropy-3-nopunct": 0.20435397174698713,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.6785558450513327,
        "bleu": 16.55335,
        "rouge1": {
            "precision": 0.46465,
            "recall": 0.65333,
            "fmeasure": 0.54175
        },
        "rouge2": {
            "precision": 0.23958,
            "recall": 0.36905,
            "fmeasure": 0.28675
        },
        "rougeL": {
            "precision": 0.37374,
            "recall": 0.52333,
            "fmeasure": 0.43505
        },
        "rougeLsum": {
            "precision": 0.37374,
            "recall": 0.52333,
            "fmeasure": 0.43505
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.25,
            "3": 0.5833333333333334
        },
        "bertscore": {
            "precision": 0.90007,
            "recall": 0.8564,
            "f1": 0.87769
        },
        "bleurt": -0.37632,
        "meteor": 0.30443372713753597,
        "nubia": {
            "semantic_relation": 3.2894,
            "contradiction": 10.17085,
            "irrelevancy": 85.95155,
            "logical_agreement": 3.8776,
            "grammar_ref": 4.19943,
            "grammar_hyp": 3.42265,
            "nubia_score": 0.44891
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_52": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.0012871140898937446,
        "bleu": 0.86183,
        "rouge1": {
            "precision": 0.69231,
            "recall": 0.23571,
            "fmeasure": 0.35114
        },
        "rouge2": {
            "precision": 0.29167,
            "recall": 0.0929,
            "fmeasure": 0.14069
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.16905,
            "fmeasure": 0.25227
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.16905,
            "fmeasure": 0.25227
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.2857142857142857
        },
        "bertscore": {
            "precision": 0.87588,
            "recall": 0.67116,
            "f1": 0.75997
        },
        "bleurt": -0.49236,
        "meteor": 0.10847844827651555,
        "nubia": {
            "semantic_relation": 3.07368,
            "contradiction": 3.35594,
            "irrelevancy": 2.18378,
            "logical_agreement": 94.46027,
            "grammar_ref": 3.72412,
            "grammar_hyp": 4.67827,
            "nubia_score": 0.2244
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_60": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 2.0,
        "median_pred_length": 18.0,
        "min_pred_length": 16,
        "max_pred_length": 20,
        "distinct-1": 0.6388888888888888,
        "vocab_size-1": 23,
        "unique-1": 14,
        "entropy-1": 4.350209029099896,
        "distinct-2": 0.8823529411764706,
        "vocab_size-2": 30,
        "unique-2": 26,
        "entropy-2": 4.852168723603279,
        "cond_entropy-2": 0.491354751699996,
        "distinct-3": 0.90625,
        "vocab_size-3": 29,
        "unique-3": 26,
        "entropy-3": 4.8125,
        "cond_entropy-3": -0.02496284125033941,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6363636363636364,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.2107645737727895,
        "distinct-2-nopunct": 0.8709677419354839,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.696131794257844,
        "cond_entropy-2-nopunct": 0.5391497718131617,
        "distinct-3-nopunct": 0.896551724137931,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.651084443403434,
        "cond_entropy-3-nopunct": -0.02724979801792366,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.179538116680411,
        "bleu": 50.25918,
        "rouge1": {
            "precision": 0.87657,
            "recall": 0.84914,
            "fmeasure": 0.85549
        },
        "rouge2": {
            "precision": 0.57621,
            "recall": 0.56393,
            "fmeasure": 0.56407
        },
        "rougeL": {
            "precision": 0.63722,
            "recall": 0.63015,
            "fmeasure": 0.62792
        },
        "rougeLsum": {
            "precision": 0.63722,
            "recall": 0.63015,
            "fmeasure": 0.62792
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "bertscore": {
            "precision": 0.95794,
            "recall": 0.94705,
            "f1": 0.95159
        },
        "bleurt": 0.13087,
        "meteor": 0.4288540001363035,
        "nubia": {
            "semantic_relation": 3.29984,
            "contradiction": 99.17344,
            "irrelevancy": 0.30106,
            "logical_agreement": 0.5255,
            "grammar_ref": 4.80653,
            "grammar_hyp": 4.84914,
            "nubia_score": 0.41573
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_75": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.75,
        "vocab_size-1": 12,
        "unique-1": 8,
        "entropy-1": 3.5,
        "distinct-2": 0.8666666666666667,
        "vocab_size-2": 13,
        "unique-2": 11,
        "entropy-2": 3.640223928941851,
        "cond_entropy-2": 0.17355726227518525,
        "distinct-3": 0.9285714285714286,
        "vocab_size-3": 13,
        "unique-3": 12,
        "entropy-3": 3.6644977792004623,
        "cond_entropy-3": 0.04332146930622849,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7333333333333333,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.3735572622751846,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.521640636343319,
        "cond_entropy-2-nopunct": 0.11475004073479991,
        "distinct-3-nopunct": 0.9230769230769231,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.5465935642949384,
        "cond_entropy-3-nopunct": -0.029992126993435245,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.113393888911329,
        "bleu": 17.61507,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.44097,
            "fmeasure": 0.46823
        },
        "rouge2": {
            "precision": 0.21429,
            "recall": 0.18824,
            "fmeasure": 0.20022
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.44097,
            "fmeasure": 0.46823
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.44097,
            "fmeasure": 0.46823
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5
        },
        "bertscore": {
            "precision": 0.86504,
            "recall": 0.80055,
            "f1": 0.83155
        },
        "bleurt": -0.34062,
        "meteor": 0.18231363980747387,
        "nubia": {
            "semantic_relation": 3.00062,
            "contradiction": 0.34176,
            "irrelevancy": 98.71119,
            "logical_agreement": 0.94705,
            "grammar_ref": 4.60656,
            "grammar_hyp": 4.38645,
            "nubia_score": 0.38264
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_100": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.0433214693062285,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.046930949929641655,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5641644580845475,
        "bleu": 29.07154,
        "rouge1": {
            "precision": 0.64286,
            "recall": 0.65,
            "fmeasure": 0.62745
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.35673,
            "fmeasure": 0.32102
        },
        "rougeL": {
            "precision": 0.53571,
            "recall": 0.575,
            "fmeasure": 0.53922
        },
        "rougeLsum": {
            "precision": 0.53571,
            "recall": 0.575,
            "fmeasure": 0.53922
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.91812,
            "recall": 0.96193,
            "f1": 0.93951
        },
        "bleurt": 0.20636,
        "meteor": 0.444752109667806,
        "nubia": {
            "semantic_relation": 3.43704,
            "contradiction": 52.05832,
            "irrelevancy": 8.21551,
            "logical_agreement": 39.72617,
            "grammar_ref": 5.69136,
            "grammar_hyp": 5.783,
            "nubia_score": 0.39687
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_123": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9545454545454546,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.368522527728205,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.02812389937955851,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.023638630780208267,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.7187949817359927,
        "bleu": 25.27953,
        "rouge1": {
            "precision": 0.575,
            "recall": 0.28485,
            "fmeasure": 0.37333
        },
        "rouge2": {
            "precision": 0.21053,
            "recall": 0.09004,
            "fmeasure": 0.12386
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.23485,
            "fmeasure": 0.31333
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.23485,
            "fmeasure": 0.31333
        },
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.3181818181818182
        },
        "bertscore": {
            "precision": 0.91242,
            "recall": 0.83905,
            "f1": 0.85802
        },
        "bleurt": -0.12063,
        "meteor": 0.14943436542416594,
        "nubia": {
            "semantic_relation": 2.41488,
            "contradiction": 95.28497,
            "irrelevancy": 1.43262,
            "logical_agreement": 3.28241,
            "grammar_ref": 4.34131,
            "grammar_hyp": 5.23107,
            "nubia_score": 0.11469
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "T5-base (Baseline)/cs_restaurants_test",
        "N": 183,
        "msttr-100": 0.21969,
        "msttr-100_nopunct": 0.21185,
        "total_length": 3286,
        "mean_pred_length": 17.956284153005466,
        "std_pred_length": 2.6131762316418166,
        "median_pred_length": 19.0,
        "min_pred_length": 6,
        "max_pred_length": 20,
        "distinct-1": 0.021606816798539256,
        "vocab_size-1": 71,
        "unique-1": 21,
        "entropy-1": 4.213730698474262,
        "distinct-2": 0.0412504028359652,
        "vocab_size-2": 128,
        "unique-2": 51,
        "entropy-2": 4.936137986777099,
        "cond_entropy-2": 0.7196169498429734,
        "distinct-3": 0.04452054794520548,
        "vocab_size-3": 130,
        "unique-3": 55,
        "entropy-3": 4.886539558477465,
        "cond_entropy-3": -0.03190608344384153,
        "total_length-nopunct": 2785,
        "mean_pred_length-nopunct": 15.218579234972678,
        "std_pred_length-nopunct": 2.1869668975398175,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.024775583482944345,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.074611786642791,
        "distinct-2-nopunct": 0.04189085318985396,
        "vocab_size-2-nopunct": 109,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 4.691875055863591,
        "cond_entropy-2-nopunct": 0.6780842756856541,
        "distinct-3-nopunct": 0.0454733360892931,
        "vocab_size-3-nopunct": 110,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 4.632565090716247,
        "cond_entropy-3-nopunct": -0.040221173232513986,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 0.41350299723878053,
        "bleu": 0.89698,
        "rouge1": {
            "precision": 0.13031,
            "recall": 0.18103,
            "fmeasure": 0.14634
        },
        "rouge2": {
            "precision": 0.06484,
            "recall": 0.08634,
            "fmeasure": 0.07165
        },
        "rougeL": {
            "precision": 0.11899,
            "recall": 0.16681,
            "fmeasure": 0.13397
        },
        "rougeLsum": {
            "precision": 0.11899,
            "recall": 0.16681,
            "fmeasure": 0.13397
        },
        "local_recall": {
            "1": 0.11166500498504486
        },
        "bertscore": {
            "precision": 0.78555,
            "recall": 0.84043,
            "f1": 0.81188
        },
        "bleurt": -0.99938,
        "meteor": 0.06169575018000389,
        "nubia": {
            "semantic_relation": 1.28334,
            "contradiction": 47.85528,
            "irrelevancy": 36.69421,
            "logical_agreement": 15.45051,
            "grammar_ref": 6.72681,
            "grammar_hyp": 5.76898,
            "nubia_score": 0.05867
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_125": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 14,
        "unique-1": 11,
        "entropy-1": 3.68354236243323,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.43253122228823104,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7647058823529411,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.572469458770136,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.45971762763487756,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.1729520220840473,
        "bleu": 5.75139,
        "rouge1": {
            "precision": 0.22222,
            "recall": 0.28356,
            "fmeasure": 0.24823
        },
        "rouge2": {
            "precision": 0.05882,
            "recall": 0.07639,
            "fmeasure": 0.06618
        },
        "rougeL": {
            "precision": 0.2037,
            "recall": 0.23379,
            "fmeasure": 0.2169
        },
        "rougeLsum": {
            "precision": 0.2037,
            "recall": 0.23379,
            "fmeasure": 0.2169
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "bertscore": {
            "precision": 0.66774,
            "recall": 0.68904,
            "f1": 0.67822
        },
        "bleurt": -0.68978,
        "meteor": 0.1274449583988788,
        "nubia": {
            "semantic_relation": 1.19816,
            "contradiction": 41.25324,
            "irrelevancy": 56.07624,
            "logical_agreement": 2.67051,
            "grammar_ref": 4.12033,
            "grammar_hyp": 3.57188,
            "nubia_score": 0.1161
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_127": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185189,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.04332146930622849,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.660390334249472,
        "bleu": 42.31179,
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.60806,
            "fmeasure": 0.58046
        },
        "rouge2": {
            "precision": 0.45238,
            "recall": 0.49786,
            "fmeasure": 0.47388
        },
        "rougeL": {
            "precision": 0.42222,
            "recall": 0.46154,
            "fmeasure": 0.44089
        },
        "rougeLsum": {
            "precision": 0.42222,
            "recall": 0.46154,
            "fmeasure": 0.44089
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 0.6
        },
        "bertscore": {
            "precision": 0.92281,
            "recall": 0.91335,
            "f1": 0.91805
        },
        "bleurt": 0.13309,
        "meteor": 0.3994190729892483,
        "nubia": {
            "semantic_relation": 3.53956,
            "contradiction": 37.71308,
            "irrelevancy": 53.66906,
            "logical_agreement": 8.61786,
            "grammar_ref": 4.48671,
            "grammar_hyp": 3.81568,
            "nubia_score": 0.58222
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 214,
        "msttr-100": 0.46271,
        "msttr-100_nopunct": 0.45764,
        "total_length": 9665,
        "mean_pred_length": 45.16355140186916,
        "std_pred_length": 13.085855190973708,
        "median_pred_length": 43.0,
        "min_pred_length": 18,
        "max_pred_length": 78,
        "distinct-1": 0.12084842214174858,
        "vocab_size-1": 1168,
        "unique-1": 575,
        "entropy-1": 5.826076102984635,
        "distinct-2": 0.2947836207808697,
        "vocab_size-2": 2786,
        "unique-2": 1592,
        "entropy-2": 9.895450129622326,
        "cond_entropy-2": 4.060693959994991,
        "distinct-3": 0.4826242286456642,
        "vocab_size-3": 4458,
        "unique-3": 2906,
        "entropy-3": 11.31933936296449,
        "cond_entropy-3": 1.4587625022218975,
        "total_length-nopunct": 8949,
        "mean_pred_length-nopunct": 41.8177570093458,
        "std_pred_length-nopunct": 12.837571269149327,
        "median_pred_length-nopunct": 40.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 75,
        "distinct-1-nopunct": 0.12984691026930384,
        "vocab_size-1-nopunct": 1162,
        "unique-1-nopunct": 575,
        "entropy-1-nopunct": 5.726135199545562,
        "distinct-2-nopunct": 0.296508299942759,
        "vocab_size-2-nopunct": 2590,
        "unique-2-nopunct": 1473,
        "entropy-2-nopunct": 9.76378935616748,
        "cond_entropy-2-nopunct": 4.118212619964597,
        "distinct-3-nopunct": 0.4792864687243281,
        "vocab_size-3-nopunct": 4084,
        "unique-3-nopunct": 2674,
        "entropy-3-nopunct": 11.169390726827821,
        "cond_entropy-3-nopunct": 1.4425657620755972,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.122400150728885,
        "bleu": 2.23816,
        "rouge1": {
            "precision": 0.42963,
            "recall": 0.42873,
            "fmeasure": 0.42584
        },
        "rouge2": {
            "precision": 0.19884,
            "recall": 0.197,
            "fmeasure": 0.19658
        },
        "rougeL": {
            "precision": 0.40714,
            "recall": 0.40631,
            "fmeasure": 0.40335
        },
        "rougeLsum": {
            "precision": 0.40714,
            "recall": 0.40631,
            "fmeasure": 0.40335
        },
        "local_recall": {
            "1": 0.09641669745105283,
            "2": 0.2168309325246399,
            "3": 0.28886925795053003,
            "4": 0.18181818181818182
        },
        "bertscore": {
            "precision": 0.86203,
            "recall": 0.87429,
            "f1": 0.86744
        },
        "bleurt": -0.49744,
        "meteor": 0.1342310673650089,
        "nubia": {
            "semantic_relation": 3.27656,
            "contradiction": 30.93174,
            "irrelevancy": 16.97067,
            "logical_agreement": 52.09759,
            "grammar_ref": 2.61878,
            "grammar_hyp": 2.58684,
            "nubia_score": 0.14728
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_133": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.702819531114783,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.22388309575274973,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.4677201004744997,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.13692518080981952,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.8811331011233863,
        "bleu": 21.34639,
        "rouge1": {
            "precision": 0.42857,
            "recall": 0.35294,
            "fmeasure": 0.3871
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.25,
            "fmeasure": 0.27586
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.29412,
            "fmeasure": 0.32258
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.29412,
            "fmeasure": 0.32258
        },
        "local_recall": {
            "1": 0,
            "2": 0.4
        },
        "bertscore": {
            "precision": 0.86242,
            "recall": 0.79224,
            "f1": 0.82584
        },
        "bleurt": -0.25329,
        "meteor": 0.221314129122313,
        "nubia": {
            "semantic_relation": 2.61962,
            "contradiction": 59.38278,
            "irrelevancy": 33.53765,
            "logical_agreement": 7.07957,
            "grammar_ref": 4.28272,
            "grammar_hyp": 4.278,
            "nubia_score": 0.25906
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_496": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.9722195534156317,
        "bleu": 8.6979,
        "rouge1": {
            "precision": 0.35714,
            "recall": 0.34194,
            "fmeasure": 0.32593
        },
        "rouge2": {
            "precision": 0.07692,
            "recall": 0.08519,
            "fmeasure": 0.07611
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.16129,
            "fmeasure": 0.22222
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.16129,
            "fmeasure": 0.22222
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.2857142857142857,
            "3": 0.3333333333333333
        },
        "bertscore": {
            "precision": 0.85116,
            "recall": 0.77408,
            "f1": 0.80695
        },
        "bleurt": -0.429,
        "meteor": 0.11719349583040845,
        "nubia": {
            "semantic_relation": 1.60503,
            "contradiction": 66.12905,
            "irrelevancy": 25.53023,
            "logical_agreement": 8.34072,
            "grammar_ref": 4.34568,
            "grammar_hyp": 3.86986,
            "nubia_score": 0.10127
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 166,
        "msttr-100": 0.71519,
        "msttr-100_nopunct": 0.76826,
        "total_length": 2706,
        "mean_pred_length": 16.301204819277107,
        "std_pred_length": 7.234846964283577,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 46,
        "distinct-1": 0.45195861049519587,
        "vocab_size-1": 1223,
        "unique-1": 974,
        "entropy-1": 8.499301239510183,
        "distinct-2": 0.8744094488188976,
        "vocab_size-2": 2221,
        "unique-2": 2088,
        "entropy-2": 10.911847600586766,
        "cond_entropy-2": 2.1180109891953416,
        "distinct-3": 0.9734625105307498,
        "vocab_size-3": 2311,
        "unique-3": 2265,
        "entropy-3": 11.153591071994796,
        "cond_entropy-3": 0.256733100550193,
        "total_length-nopunct": 2374,
        "mean_pred_length-nopunct": 14.301204819277109,
        "std_pred_length-nopunct": 6.253162938959898,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.5117944397641112,
        "vocab_size-1-nopunct": 1215,
        "unique-1-nopunct": 974,
        "entropy-1-nopunct": 8.826382962769834,
        "distinct-2-nopunct": 0.8817934782608695,
        "vocab_size-2-nopunct": 1947,
        "unique-2-nopunct": 1843,
        "entropy-2-nopunct": 10.720584700816655,
        "cond_entropy-2-nopunct": 2.0432081934955497,
        "distinct-3-nopunct": 0.9769833496571988,
        "vocab_size-3-nopunct": 1995,
        "unique-3-nopunct": 1959,
        "entropy-3-nopunct": 10.94518722310335,
        "cond_entropy-3-nopunct": 0.24822058031240155,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 12.257085800832964,
        "bleu": 87.72975,
        "rouge1": {
            "precision": 0.90264,
            "recall": 0.87955,
            "fmeasure": 0.8828
        },
        "rouge2": {
            "precision": 0.80506,
            "recall": 0.78487,
            "fmeasure": 0.78433
        },
        "rougeL": {
            "precision": 0.88892,
            "recall": 0.86648,
            "fmeasure": 0.86955
        },
        "rougeLsum": {
            "precision": 0.88892,
            "recall": 0.86648,
            "fmeasure": 0.86955
        },
        "local_recall": {
            "1": 0.02858551010349926,
            "2": 0.12007168458781362,
            "3": 0.35231316725978645,
            "4": 0.48068669527896996,
            "5": 0.6682027649769585,
            "6": 0.7537878787878788,
            "7": 0.8133802816901409,
            "8": 0.864951768488746,
            "9": 0.8863636363636364,
            "10": 0.9471947194719472
        },
        "bertscore": {
            "precision": 0.97436,
            "recall": 0.96895,
            "f1": 0.96897
        },
        "bleurt": 0.30609,
        "meteor": 0.5309813407604925,
        "nubia": {
            "semantic_relation": 4.30735,
            "contradiction": 3.04439,
            "irrelevancy": 26.30045,
            "logical_agreement": 70.65516,
            "grammar_ref": 4.62208,
            "grammar_hyp": 4.88053,
            "nubia_score": 0.69112
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level1": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 0,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json"
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 58,
        "msttr-100": 0.72091,
        "msttr-100_nopunct": 0.74778,
        "total_length": 1119,
        "mean_pred_length": 19.29310344827586,
        "std_pred_length": 9.514070561251419,
        "median_pred_length": 19.5,
        "min_pred_length": 5,
        "max_pred_length": 46,
        "distinct-1": 0.5111706881143878,
        "vocab_size-1": 572,
        "unique-1": 468,
        "entropy-1": 7.974874246633369,
        "distinct-2": 0.9151743638077285,
        "vocab_size-2": 971,
        "unique-2": 926,
        "entropy-2": 9.825612257260655,
        "cond_entropy-2": 1.6392239966368822,
        "distinct-3": 0.9770687936191426,
        "vocab_size-3": 980,
        "unique-3": 967,
        "entropy-3": 9.908986280533481,
        "cond_entropy-3": 0.09641949451128563,
        "total_length-nopunct": 998,
        "mean_pred_length-nopunct": 17.20689655172414,
        "std_pred_length-nopunct": 8.733128800405435,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.5661322645290581,
        "vocab_size-1-nopunct": 565,
        "unique-1-nopunct": 467,
        "entropy-1-nopunct": 8.162361935217195,
        "distinct-2-nopunct": 0.9276595744680851,
        "vocab_size-2-nopunct": 872,
        "unique-2-nopunct": 832,
        "entropy-2-nopunct": 9.694670460427334,
        "cond_entropy-2-nopunct": 1.6353361992166324,
        "distinct-3-nopunct": 0.9875283446712018,
        "vocab_size-3-nopunct": 871,
        "unique-3-nopunct": 860,
        "entropy-3-nopunct": 9.759691534899925,
        "cond_entropy-3-nopunct": 0.07584544657704209,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 11.053754717202656,
        "bleu": 82.41232,
        "rouge1": {
            "precision": 0.89783,
            "recall": 0.80383,
            "fmeasure": 0.82822
        },
        "rouge2": {
            "precision": 0.79595,
            "recall": 0.72122,
            "fmeasure": 0.73445
        },
        "rougeL": {
            "precision": 0.87778,
            "recall": 0.78957,
            "fmeasure": 0.81186
        },
        "rougeLsum": {
            "precision": 0.87778,
            "recall": 0.78957,
            "fmeasure": 0.81186
        },
        "local_recall": {
            "1": 0.02553191489361702,
            "2": 0.15503875968992248,
            "3": 0.271523178807947,
            "4": 0.4727272727272727,
            "5": 0.6296296296296297,
            "6": 0.6923076923076923,
            "7": 0.7719298245614035,
            "8": 0.7755102040816326,
            "9": 0.7973856209150327,
            "10": 0.9295774647887324
        },
        "bertscore": {
            "precision": 0.96263,
            "recall": 0.94625,
            "f1": 0.95153
        },
        "bleurt": 0.17232,
        "meteor": 0.4916662851105384,
        "nubia": {
            "semantic_relation": 4.05726,
            "contradiction": 4.9182,
            "irrelevancy": 29.00234,
            "logical_agreement": 66.07946,
            "grammar_ref": 4.50862,
            "grammar_hyp": 4.91715,
            "nubia_score": 0.60808
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 32,
        "msttr-100": 0.72167,
        "msttr-100_nopunct": 0.76333,
        "total_length": 693,
        "mean_pred_length": 21.65625,
        "std_pred_length": 9.224997882791085,
        "median_pred_length": 20.5,
        "min_pred_length": 9,
        "max_pred_length": 46,
        "distinct-1": 0.5512265512265512,
        "vocab_size-1": 382,
        "unique-1": 306,
        "entropy-1": 7.679312448253975,
        "distinct-2": 0.9062027231467473,
        "vocab_size-2": 599,
        "unique-2": 566,
        "entropy-2": 9.132670498649366,
        "cond_entropy-2": 1.286238932852671,
        "distinct-3": 0.9713831478537361,
        "vocab_size-3": 611,
        "unique-3": 602,
        "entropy-3": 9.223825319039777,
        "cond_entropy-3": 0.09997318416052561,
        "total_length-nopunct": 612,
        "mean_pred_length-nopunct": 19.125,
        "std_pred_length-nopunct": 7.829232082394799,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.6127450980392157,
        "vocab_size-1-nopunct": 375,
        "unique-1-nopunct": 305,
        "entropy-1-nopunct": 7.850668530207721,
        "distinct-2-nopunct": 0.9224137931034483,
        "vocab_size-2-nopunct": 535,
        "unique-2-nopunct": 511,
        "entropy-2-nopunct": 8.984808201228638,
        "cond_entropy-2-nopunct": 1.198674249467139,
        "distinct-3-nopunct": 0.9817518248175182,
        "vocab_size-3-nopunct": 538,
        "unique-3-nopunct": 531,
        "entropy-3-nopunct": 9.056508565620897,
        "cond_entropy-3-nopunct": 0.08309311702206611,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 10.478257044973775,
        "bleu": 87.35492,
        "rouge1": {
            "precision": 0.88689,
            "recall": 0.8981,
            "fmeasure": 0.88711
        },
        "rouge2": {
            "precision": 0.78309,
            "recall": 0.7992,
            "fmeasure": 0.78273
        },
        "rougeL": {
            "precision": 0.87769,
            "recall": 0.87001,
            "fmeasure": 0.86718
        },
        "rougeLsum": {
            "precision": 0.87769,
            "recall": 0.87001,
            "fmeasure": 0.86718
        },
        "local_recall": {
            "1": 0.04722792607802875,
            "2": 0.18691588785046728,
            "3": 0.4084507042253521,
            "4": 0.71875,
            "5": 0.7636363636363637,
            "6": 0.7794117647058824,
            "7": 0.8333333333333334,
            "8": 0.9206349206349206,
            "9": 0.9404761904761905,
            "10": 0.9596774193548387
        },
        "bertscore": {
            "precision": 0.97019,
            "recall": 0.97638,
            "f1": 0.97092
        },
        "bleurt": 0.28724,
        "meteor": 0.5315336234134512,
        "nubia": {
            "semantic_relation": 4.41348,
            "contradiction": 2.91773,
            "irrelevancy": 30.923,
            "logical_agreement": 66.15927,
            "grammar_ref": 4.51508,
            "grammar_hyp": 4.57764,
            "nubia_score": 0.69704
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 84,
        "mean_pred_length": 16.8,
        "std_pred_length": 8.726969691708572,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 33,
        "distinct-1": 0.7261904761904762,
        "vocab_size-1": 61,
        "unique-1": 49,
        "entropy-1": 5.677841084314434,
        "distinct-2": 0.9873417721518988,
        "vocab_size-2": 78,
        "unique-2": 77,
        "entropy-2": 6.278464292480902,
        "cond_entropy-2": 0.49888575522830114,
        "distinct-3": 1.0,
        "vocab_size-3": 74,
        "unique-3": 74,
        "entropy-3": 6.2094533656289554,
        "cond_entropy-3": -0.06730035552112612,
        "total_length-nopunct": 77,
        "mean_pred_length-nopunct": 15.4,
        "std_pred_length-nopunct": 7.9899937421752725,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.7662337662337663,
        "vocab_size-1-nopunct": 59,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.664106385414817,
        "distinct-2-nopunct": 0.9861111111111112,
        "vocab_size-2-nopunct": 71,
        "unique-2-nopunct": 70,
        "entropy-2-nopunct": 6.14214722366454,
        "cond_entropy-2-nopunct": 0.5060047379219483,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 67,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 6.066089190457767,
        "cond_entropy-3-nopunct": -0.07398506471588323,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 7.4737184860188295,
        "bleu": 80.14155,
        "rouge1": {
            "precision": 0.91287,
            "recall": 0.80916,
            "fmeasure": 0.84935
        },
        "rouge2": {
            "precision": 0.77493,
            "recall": 0.70896,
            "fmeasure": 0.73323
        },
        "rougeL": {
            "precision": 0.8389,
            "recall": 0.78198,
            "fmeasure": 0.80313
        },
        "rougeLsum": {
            "precision": 0.8389,
            "recall": 0.78198,
            "fmeasure": 0.80313
        },
        "local_recall": {
            "1": 0.05555555555555555,
            "2": 0.23809523809523808,
            "3": 0.375,
            "4": 0.5,
            "5": 0.5714285714285714,
            "6": 0.6153846153846154,
            "7": 0.6666666666666666,
            "8": 1.0,
            "9": 0.75,
            "10": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.95971,
            "recall": 0.94253,
            "f1": 0.94688
        },
        "bleurt": 0.27468,
        "meteor": 0.4765675393919368,
        "nubia": {
            "semantic_relation": 3.94545,
            "contradiction": 0.19499,
            "irrelevancy": 44.07598,
            "logical_agreement": 55.72903,
            "grammar_ref": 5.04038,
            "grammar_hyp": 5.26043,
            "nubia_score": 0.5495
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 28,
        "msttr-100": 0.72667,
        "msttr-100_nopunct": 0.764,
        "total_length": 639,
        "mean_pred_length": 22.821428571428573,
        "std_pred_length": 7.874250855199639,
        "median_pred_length": 20.5,
        "min_pred_length": 8,
        "max_pred_length": 40,
        "distinct-1": 0.5586854460093896,
        "vocab_size-1": 357,
        "unique-1": 293,
        "entropy-1": 7.656978895323569,
        "distinct-2": 0.9132569558101473,
        "vocab_size-2": 558,
        "unique-2": 522,
        "entropy-2": 9.055725071437758,
        "cond_entropy-2": 1.245809040790838,
        "distinct-3": 0.9759862778730704,
        "vocab_size-3": 569,
        "unique-3": 559,
        "entropy-3": 9.132463565481917,
        "cond_entropy-3": 0.07572746995016269,
        "total_length-nopunct": 565,
        "mean_pred_length-nopunct": 20.178571428571427,
        "std_pred_length-nopunct": 6.713810773475881,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.6212389380530974,
        "vocab_size-1-nopunct": 351,
        "unique-1-nopunct": 292,
        "entropy-1-nopunct": 7.802829715015746,
        "distinct-2-nopunct": 0.9422718808193669,
        "vocab_size-2-nopunct": 506,
        "unique-2-nopunct": 483,
        "entropy-2-nopunct": 8.939337356189707,
        "cond_entropy-2-nopunct": 1.1918007708981624,
        "distinct-3-nopunct": 0.9941060903732809,
        "vocab_size-3-nopunct": 506,
        "unique-3-nopunct": 503,
        "entropy-3-nopunct": 8.979734026822317,
        "cond_entropy-3-nopunct": 0.0416232832264846,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 9.75803882520944,
        "bleu": 79.94961,
        "rouge1": {
            "precision": 0.87846,
            "recall": 0.84863,
            "fmeasure": 0.85594
        },
        "rouge2": {
            "precision": 0.77298,
            "recall": 0.75623,
            "fmeasure": 0.75497
        },
        "rougeL": {
            "precision": 0.85848,
            "recall": 0.8413,
            "fmeasure": 0.84078
        },
        "rougeLsum": {
            "precision": 0.85848,
            "recall": 0.8413,
            "fmeasure": 0.84078
        },
        "local_recall": {
            "1": 0.030828516377649325,
            "2": 0.125,
            "3": 0.2894736842105263,
            "4": 0.5161290322580645,
            "5": 0.5967741935483871,
            "6": 0.6349206349206349,
            "7": 0.8765432098765432,
            "8": 0.8870967741935484,
            "9": 0.9272727272727272,
            "10": 0.9418604651162791
        },
        "bertscore": {
            "precision": 0.96582,
            "recall": 0.96394,
            "f1": 0.96077
        },
        "bleurt": 0.1267,
        "meteor": 0.5057446587286168,
        "nubia": {
            "semantic_relation": 4.20888,
            "contradiction": 2.8585,
            "irrelevancy": 30.27368,
            "logical_agreement": 66.86781,
            "grammar_ref": 4.66117,
            "grammar_hyp": 4.84817,
            "nubia_score": 0.64293
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 71,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.69286,
        "total_length": 846,
        "mean_pred_length": 11.915492957746478,
        "std_pred_length": 4.695657205118212,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.42907801418439717,
        "vocab_size-1": 363,
        "unique-1": 287,
        "entropy-1": 7.080817827571367,
        "distinct-2": 0.7793548387096774,
        "vocab_size-2": 604,
        "unique-2": 537,
        "entropy-2": 8.92518902739166,
        "cond_entropy-2": 1.5213231258996676,
        "distinct-3": 0.8934659090909091,
        "vocab_size-3": 629,
        "unique-3": 592,
        "entropy-3": 9.179011018002022,
        "cond_entropy-3": 0.2574498679083169,
        "total_length-nopunct": 756,
        "mean_pred_length-nopunct": 10.647887323943662,
        "std_pred_length-nopunct": 4.189519423679596,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.4748677248677249,
        "vocab_size-1-nopunct": 359,
        "unique-1-nopunct": 287,
        "entropy-1-nopunct": 7.254002650938783,
        "distinct-2-nopunct": 0.7854014598540145,
        "vocab_size-2-nopunct": 538,
        "unique-2-nopunct": 479,
        "entropy-2-nopunct": 8.76486508960934,
        "cond_entropy-2-nopunct": 1.6633047588757408,
        "distinct-3-nopunct": 0.8876221498371335,
        "vocab_size-3-nopunct": 545,
        "unique-3-nopunct": 511,
        "entropy-3-nopunct": 8.964601009303273,
        "cond_entropy-3-nopunct": 0.25757264813857744,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.391280457565338,
        "bleu": 59.15165,
        "rouge1": {
            "precision": 0.78176,
            "recall": 0.78885,
            "fmeasure": 0.76881
        },
        "rouge2": {
            "precision": 0.61451,
            "recall": 0.629,
            "fmeasure": 0.60703
        },
        "rougeL": {
            "precision": 0.74714,
            "recall": 0.76307,
            "fmeasure": 0.73928
        },
        "rougeLsum": {
            "precision": 0.74714,
            "recall": 0.76307,
            "fmeasure": 0.73928
        },
        "local_recall": {
            "1": 0.2569832402234637,
            "2": 0.631578947368421,
            "3": 0.8132530120481928
        },
        "bertscore": {
            "precision": 0.94538,
            "recall": 0.94849,
            "f1": 0.94555
        },
        "bleurt": 0.38253,
        "meteor": 0.4398780101519456,
        "nubia": {
            "semantic_relation": 4.13673,
            "contradiction": 8.26649,
            "irrelevancy": 40.88432,
            "logical_agreement": 50.84918,
            "grammar_ref": 5.37595,
            "grammar_hyp": 5.25945,
            "nubia_score": 0.71005
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 7,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.78,
        "total_length": 180,
        "mean_pred_length": 25.714285714285715,
        "std_pred_length": 6.860118402024554,
        "median_pred_length": 24.0,
        "min_pred_length": 16,
        "max_pred_length": 40,
        "distinct-1": 0.7222222222222222,
        "vocab_size-1": 130,
        "unique-1": 116,
        "entropy-1": 6.6102583913626605,
        "distinct-2": 0.9595375722543352,
        "vocab_size-2": 166,
        "unique-2": 163,
        "entropy-2": 7.328474886731522,
        "cond_entropy-2": 0.6325006741825419,
        "distinct-3": 1.0,
        "vocab_size-3": 166,
        "unique-3": 166,
        "entropy-3": 7.375039431346908,
        "cond_entropy-3": 0.03899269754514165,
        "total_length-nopunct": 161,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 5.0426750270636544,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.7701863354037267,
        "vocab_size-1-nopunct": 124,
        "unique-1-nopunct": 114,
        "entropy-1-nopunct": 6.5829517576949135,
        "distinct-2-nopunct": 0.961038961038961,
        "vocab_size-2-nopunct": 148,
        "unique-2-nopunct": 146,
        "entropy-2-nopunct": 7.160523372015699,
        "cond_entropy-2-nopunct": 0.6115700288852854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 147,
        "unique-3-nopunct": 147,
        "entropy-3-nopunct": 7.199672344836354,
        "cond_entropy-3-nopunct": 0.044209123710172896,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 8.200189349611378,
        "bleu": 82.52532,
        "rouge1": {
            "precision": 0.8963,
            "recall": 0.92389,
            "fmeasure": 0.90727
        },
        "rouge2": {
            "precision": 0.81455,
            "recall": 0.86379,
            "fmeasure": 0.83542
        },
        "rougeL": {
            "precision": 0.8803,
            "recall": 0.91959,
            "fmeasure": 0.89765
        },
        "rougeLsum": {
            "precision": 0.8803,
            "recall": 0.91959,
            "fmeasure": 0.89765
        },
        "local_recall": {
            "1": 0.03529411764705882,
            "2": 0.18181818181818182,
            "3": 0.6666666666666666,
            "4": 0.8333333333333334,
            "5": 0.9375,
            "6": 1.0,
            "7": 0.8666666666666667,
            "8": 0.96,
            "9": 1.0,
            "10": 0.9583333333333334
        },
        "bertscore": {
            "precision": 0.97819,
            "recall": 0.98062,
            "f1": 0.97721
        },
        "bleurt": 0.26,
        "meteor": 0.564609589603065,
        "nubia": {
            "semantic_relation": 4.37957,
            "contradiction": 1.88486,
            "irrelevancy": 46.43947,
            "logical_agreement": 51.67567,
            "grammar_ref": 4.66733,
            "grammar_hyp": 4.66284,
            "nubia_score": 0.65046
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 63,
        "msttr-100": 0.74824,
        "msttr-100_nopunct": 0.78,
        "total_length": 1739,
        "mean_pred_length": 27.603174603174605,
        "std_pred_length": 9.893945049981498,
        "median_pred_length": 27.0,
        "min_pred_length": 10,
        "max_pred_length": 48,
        "distinct-1": 0.4795859689476711,
        "vocab_size-1": 834,
        "unique-1": 672,
        "entropy-1": 8.383329665337284,
        "distinct-2": 0.9039379474940334,
        "vocab_size-2": 1515,
        "unique-2": 1442,
        "entropy-2": 10.417102454837746,
        "cond_entropy-2": 1.884285387640566,
        "distinct-3": 0.9727216367017979,
        "vocab_size-3": 1569,
        "unique-3": 1560,
        "entropy-3": 10.548660318593909,
        "cond_entropy-3": 0.14116936448033068,
        "total_length-nopunct": 1558,
        "mean_pred_length-nopunct": 24.73015873015873,
        "std_pred_length-nopunct": 8.932207372549817,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.5301668806161746,
        "vocab_size-1-nopunct": 826,
        "unique-1-nopunct": 670,
        "entropy-1-nopunct": 8.593539038620296,
        "distinct-2-nopunct": 0.928428093645485,
        "vocab_size-2-nopunct": 1388,
        "unique-2-nopunct": 1330,
        "entropy-2-nopunct": 10.348354062718668,
        "cond_entropy-2-nopunct": 1.8222288374125721,
        "distinct-3-nopunct": 0.9958100558659218,
        "vocab_size-3-nopunct": 1426,
        "unique-3-nopunct": 1422,
        "entropy-3-nopunct": 10.474381576842163,
        "cond_entropy-3-nopunct": 0.13402141740628692,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 11.247565816117875,
        "bleu": 84.01331,
        "rouge1": {
            "precision": 0.87482,
            "recall": 0.89392,
            "fmeasure": 0.87904
        },
        "rouge2": {
            "precision": 0.78677,
            "recall": 0.79249,
            "fmeasure": 0.7825
        },
        "rougeL": {
            "precision": 0.86779,
            "recall": 0.88292,
            "fmeasure": 0.86979
        },
        "rougeLsum": {
            "precision": 0.86779,
            "recall": 0.88292,
            "fmeasure": 0.86979
        },
        "local_recall": {
            "1": 0.030204081632653063,
            "2": 0.20491803278688525,
            "3": 0.44298245614035087,
            "4": 0.656441717791411,
            "5": 0.7485029940119761,
            "6": 0.8494623655913979,
            "7": 0.8554216867469879,
            "8": 0.8883720930232558,
            "9": 0.9540229885057471,
            "10": 0.9490740740740741
        },
        "bertscore": {
            "precision": 0.96359,
            "recall": 0.97236,
            "f1": 0.96619
        },
        "bleurt": 0.10271,
        "meteor": 0.545774720600306,
        "nubia": {
            "semantic_relation": 4.19247,
            "contradiction": 1.58405,
            "irrelevancy": 42.32511,
            "logical_agreement": 56.09084,
            "grammar_ref": 4.4268,
            "grammar_hyp": 4.66887,
            "nubia_score": 0.58379
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 52,
        "msttr-100": 0.64,
        "msttr-100_nopunct": 0.68,
        "total_length": 761,
        "mean_pred_length": 14.634615384615385,
        "std_pred_length": 5.470300393080123,
        "median_pred_length": 13.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.43626806833114323,
        "vocab_size-1": 332,
        "unique-1": 253,
        "entropy-1": 7.103624292115845,
        "distinct-2": 0.767277856135402,
        "vocab_size-2": 544,
        "unique-2": 476,
        "entropy-2": 8.76143315751656,
        "cond_entropy-2": 1.4187267929534118,
        "distinct-3": 0.878234398782344,
        "vocab_size-3": 577,
        "unique-3": 534,
        "entropy-3": 9.027235885429183,
        "cond_entropy-3": 0.26929972226966403,
        "total_length-nopunct": 656,
        "mean_pred_length-nopunct": 12.615384615384615,
        "std_pred_length-nopunct": 4.5874152524297225,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.49847560975609756,
        "vocab_size-1-nopunct": 327,
        "unique-1-nopunct": 252,
        "entropy-1-nopunct": 7.27531841875196,
        "distinct-2-nopunct": 0.793046357615894,
        "vocab_size-2-nopunct": 479,
        "unique-2-nopunct": 426,
        "entropy-2-nopunct": 8.609527241363505,
        "cond_entropy-2-nopunct": 1.4144306456371196,
        "distinct-3-nopunct": 0.8931159420289855,
        "vocab_size-3-nopunct": 493,
        "unique-3-nopunct": 460,
        "entropy-3-nopunct": 8.828294299361438,
        "cond_entropy-3-nopunct": 0.2502195578006194,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.605014699268431,
        "bleu": 49.13658,
        "rouge1": {
            "precision": 0.7294,
            "recall": 0.74344,
            "fmeasure": 0.72387
        },
        "rouge2": {
            "precision": 0.53217,
            "recall": 0.51673,
            "fmeasure": 0.51661
        },
        "rougeL": {
            "precision": 0.69087,
            "recall": 0.69988,
            "fmeasure": 0.68338
        },
        "rougeLsum": {
            "precision": 0.69087,
            "recall": 0.69988,
            "fmeasure": 0.68338
        },
        "local_recall": {
            "1": 0.23026315789473684,
            "2": 0.5513513513513514,
            "3": 0.7969151670951157
        },
        "bertscore": {
            "precision": 0.9312,
            "recall": 0.93457,
            "f1": 0.93007
        },
        "bleurt": 0.37158,
        "meteor": 0.4162157325483554,
        "nubia": {
            "semantic_relation": 4.03083,
            "contradiction": 14.61858,
            "irrelevancy": 32.14158,
            "logical_agreement": 53.23984,
            "grammar_ref": 5.15177,
            "grammar_hyp": 4.92512,
            "nubia_score": 0.68496
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 200,
        "msttr-100": 0.46771,
        "msttr-100_nopunct": 0.46328,
        "total_length": 7026,
        "mean_pred_length": 35.13,
        "std_pred_length": 11.898869694218858,
        "median_pred_length": 33.0,
        "min_pred_length": 11,
        "max_pred_length": 85,
        "distinct-1": 0.13734699686877314,
        "vocab_size-1": 965,
        "unique-1": 498,
        "entropy-1": 5.756580908510457,
        "distinct-2": 0.3387049516554351,
        "vocab_size-2": 2312,
        "unique-2": 1403,
        "entropy-2": 9.778285121982188,
        "cond_entropy-2": 4.003818000104932,
        "distinct-3": 0.5357681859341986,
        "vocab_size-3": 3550,
        "unique-3": 2487,
        "entropy-3": 11.070505924116723,
        "cond_entropy-3": 1.3368311391046073,
        "total_length-nopunct": 6471,
        "mean_pred_length-nopunct": 32.355,
        "std_pred_length-nopunct": 11.483421746152146,
        "median_pred_length-nopunct": 30.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 78,
        "distinct-1-nopunct": 0.14773605316025343,
        "vocab_size-1-nopunct": 956,
        "unique-1-nopunct": 494,
        "entropy-1-nopunct": 5.64489586991832,
        "distinct-2-nopunct": 0.3359910700047839,
        "vocab_size-2-nopunct": 2107,
        "unique-2-nopunct": 1297,
        "entropy-2-nopunct": 9.60034275457302,
        "cond_entropy-2-nopunct": 4.063166039907108,
        "distinct-3-nopunct": 0.5287432054027343,
        "vocab_size-3-nopunct": 3210,
        "unique-3-nopunct": 2272,
        "entropy-3-nopunct": 10.88469474523888,
        "cond_entropy-3-nopunct": 1.3307913806234395,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.119823720393655,
        "bleu": 1.8984,
        "rouge1": {
            "precision": 0.38742,
            "recall": 0.3827,
            "fmeasure": 0.38138
        },
        "rouge2": {
            "precision": 0.18653,
            "recall": 0.18639,
            "fmeasure": 0.18616
        },
        "rougeL": {
            "precision": 0.36921,
            "recall": 0.36672,
            "fmeasure": 0.36418
        },
        "rougeLsum": {
            "precision": 0.36921,
            "recall": 0.36672,
            "fmeasure": 0.36418
        },
        "local_recall": {
            "1": 0.09872922776148582,
            "2": 0.19254032258064516,
            "3": 0.270481144343303,
            "4": 0.15,
            "5": 0.34615384615384615,
            "6": 0.0,
            "7": 0.16666666666666666
        },
        "bertscore": {
            "precision": 0.86493,
            "recall": 0.87651,
            "f1": 0.8701
        },
        "bleurt": -0.45674,
        "meteor": 0.14063803424132904,
        "nubia": {
            "semantic_relation": 3.2758,
            "contradiction": 32.94434,
            "irrelevancy": 16.98483,
            "logical_agreement": 50.07082,
            "grammar_ref": 2.7039,
            "grammar_hyp": 2.72167,
            "nubia_score": 0.17178
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 32,
        "msttr-100": 0.4619,
        "msttr-100_nopunct": 0.4615,
        "total_length": 2145,
        "mean_pred_length": 67.03125,
        "std_pred_length": 5.235004626311232,
        "median_pred_length": 67.0,
        "min_pred_length": 54,
        "max_pred_length": 76,
        "distinct-1": 0.1696969696969697,
        "vocab_size-1": 364,
        "unique-1": 177,
        "entropy-1": 5.306055556262522,
        "distinct-2": 0.37671557027922387,
        "vocab_size-2": 796,
        "unique-2": 443,
        "entropy-2": 8.784901143470233,
        "cond_entropy-2": 3.4814407610223452,
        "distinct-3": 0.5478135511773186,
        "vocab_size-3": 1140,
        "unique-3": 739,
        "entropy-3": 9.709395810617718,
        "cond_entropy-3": 0.9262329480253243,
        "total_length-nopunct": 2013,
        "mean_pred_length-nopunct": 62.90625,
        "std_pred_length-nopunct": 5.076658442075851,
        "median_pred_length-nopunct": 63.5,
        "min_pred_length-nopunct": 49,
        "max_pred_length-nopunct": 73,
        "distinct-1-nopunct": 0.17834078489816194,
        "vocab_size-1-nopunct": 359,
        "unique-1-nopunct": 177,
        "entropy-1-nopunct": 5.1896973479688535,
        "distinct-2-nopunct": 0.38414941948510856,
        "vocab_size-2-nopunct": 761,
        "unique-2-nopunct": 421,
        "entropy-2-nopunct": 8.737437654792728,
        "cond_entropy-2-nopunct": 3.562024661289673,
        "distinct-3-nopunct": 0.5541303232426885,
        "vocab_size-3-nopunct": 1080,
        "unique-3-nopunct": 706,
        "entropy-3-nopunct": 9.64626565443938,
        "cond_entropy-3-nopunct": 0.9103416526567143,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.1615974069394017,
        "bleu": 0.84729,
        "rouge1": {
            "precision": 0.80625,
            "recall": 0.72445,
            "fmeasure": 0.74205
        },
        "rouge2": {
            "precision": 0.48698,
            "recall": 0.44201,
            "fmeasure": 0.44509
        },
        "rougeL": {
            "precision": 0.74878,
            "recall": 0.67145,
            "fmeasure": 0.6867
        },
        "rougeLsum": {
            "precision": 0.74878,
            "recall": 0.67145,
            "fmeasure": 0.6867
        },
        "local_recall": {
            "1": 0.08620689655172414,
            "2": 0.17225950782997762,
            "3": 0.268370607028754
        },
        "bertscore": {
            "precision": 0.86593,
            "recall": 0.86766,
            "f1": 0.86654
        },
        "bleurt": -0.4669,
        "meteor": 0.11230786444937042,
        "nubia": {
            "semantic_relation": 3.23243,
            "contradiction": 34.05912,
            "irrelevancy": 21.26488,
            "logical_agreement": 44.676,
            "grammar_ref": 2.45871,
            "grammar_hyp": 2.41596,
            "nubia_score": 0.14085
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.706,
        "msttr-100_nopunct": 0.7475,
        "total_length": 549,
        "mean_pred_length": 15.25,
        "std_pred_length": 4.751461763382811,
        "median_pred_length": 14.5,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.5209471766848816,
        "vocab_size-1": 286,
        "unique-1": 231,
        "entropy-1": 7.240538977060456,
        "distinct-2": 0.8187134502923976,
        "vocab_size-2": 420,
        "unique-2": 380,
        "entropy-2": 8.492820717251744,
        "cond_entropy-2": 1.0200149584722378,
        "distinct-3": 0.9014675052410901,
        "vocab_size-3": 430,
        "unique-3": 405,
        "entropy-3": 8.644608584895549,
        "cond_entropy-3": 0.14360156205524646,
        "total_length-nopunct": 479,
        "mean_pred_length-nopunct": 13.305555555555555,
        "std_pred_length-nopunct": 3.7772671223492056,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.5782881002087683,
        "vocab_size-1-nopunct": 277,
        "unique-1-nopunct": 227,
        "entropy-1-nopunct": 7.346404234818004,
        "distinct-2-nopunct": 0.8216704288939052,
        "vocab_size-2-nopunct": 364,
        "unique-2-nopunct": 332,
        "entropy-2-nopunct": 8.279633486641735,
        "cond_entropy-2-nopunct": 0.9909254572158476,
        "distinct-3-nopunct": 0.9066339066339066,
        "vocab_size-3-nopunct": 369,
        "unique-3-nopunct": 349,
        "entropy-3-nopunct": 8.424943430174984,
        "cond_entropy-3-nopunct": 0.14878674566811315,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.04644201871145,
        "bleu": 39.9786,
        "rouge1": {
            "precision": 0.7432,
            "recall": 0.69913,
            "fmeasure": 0.70326
        },
        "rouge2": {
            "precision": 0.5202,
            "recall": 0.50029,
            "fmeasure": 0.49684
        },
        "rougeL": {
            "precision": 0.67374,
            "recall": 0.63209,
            "fmeasure": 0.63717
        },
        "rougeLsum": {
            "precision": 0.67374,
            "recall": 0.63209,
            "fmeasure": 0.63717
        },
        "local_recall": {
            "1": 0.15841584158415842,
            "2": 0.5714285714285714,
            "3": 0.7243401759530792
        },
        "bertscore": {
            "precision": 0.92315,
            "recall": 0.91055,
            "f1": 0.91441
        },
        "bleurt": 0.19879,
        "meteor": 0.36041632765405357,
        "nubia": {
            "semantic_relation": 3.96406,
            "contradiction": 13.77198,
            "irrelevancy": 42.46336,
            "logical_agreement": 43.76466,
            "grammar_ref": 4.68979,
            "grammar_hyp": 4.66659,
            "nubia_score": 0.66444
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-base (Baseline)/cs_restaurants_test",
        "N": 267,
        "msttr-100": 0.48091,
        "msttr-100_nopunct": 0.48467,
        "total_length": 3329,
        "mean_pred_length": 12.46816479400749,
        "std_pred_length": 4.484045541949941,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.11925503154100331,
        "vocab_size-1": 397,
        "unique-1": 196,
        "entropy-1": 5.895346572913367,
        "distinct-2": 0.2847811887655127,
        "vocab_size-2": 872,
        "unique-2": 502,
        "entropy-2": 8.365602372723053,
        "cond_entropy-2": 2.3498863654528517,
        "distinct-3": 0.38747763864042933,
        "vocab_size-3": 1083,
        "unique-3": 709,
        "entropy-3": 8.927837897184313,
        "cond_entropy-3": 0.7963676683209507,
        "total_length-nopunct": 3034,
        "mean_pred_length-nopunct": 11.363295880149813,
        "std_pred_length-nopunct": 4.287321391929742,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.12986156888595912,
        "vocab_size-1-nopunct": 394,
        "unique-1-nopunct": 196,
        "entropy-1-nopunct": 5.925154454937698,
        "distinct-2-nopunct": 0.25081315504156126,
        "vocab_size-2-nopunct": 694,
        "unique-2-nopunct": 379,
        "entropy-2-nopunct": 7.995583328583866,
        "cond_entropy-2-nopunct": 2.489377288847933,
        "distinct-3-nopunct": 0.348,
        "vocab_size-3-nopunct": 870,
        "unique-3-nopunct": 543,
        "entropy-3-nopunct": 8.554288323204407,
        "cond_entropy-3-nopunct": 0.865397999310662,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 1.889388161928803,
        "bleu": 6.5734,
        "rouge1": {
            "precision": 0.52451,
            "recall": 0.53841,
            "fmeasure": 0.51898
        },
        "rouge2": {
            "precision": 0.28545,
            "recall": 0.29703,
            "fmeasure": 0.28326
        },
        "rougeL": {
            "precision": 0.47936,
            "recall": 0.48682,
            "fmeasure": 0.47206
        },
        "rougeLsum": {
            "precision": 0.47936,
            "recall": 0.48682,
            "fmeasure": 0.47206
        },
        "local_recall": {
            "1": 0.31772908366533864
        },
        "bertscore": {
            "precision": 0.83982,
            "recall": 0.86322,
            "f1": 0.85113
        },
        "bleurt": -0.57038,
        "meteor": 0.15463114203939074,
        "nubia": {
            "semantic_relation": 3.26357,
            "contradiction": 31.78542,
            "irrelevancy": 22.26379,
            "logical_agreement": 45.95079,
            "grammar_ref": 7.44295,
            "grammar_hyp": 6.67075,
            "nubia_score": 0.44796
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 174,
        "msttr-100": 0.71815,
        "msttr-100_nopunct": 0.76708,
        "total_length": 2731,
        "mean_pred_length": 15.695402298850574,
        "std_pred_length": 6.959181614687291,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 39,
        "distinct-1": 0.4441596484804101,
        "vocab_size-1": 1213,
        "unique-1": 940,
        "entropy-1": 8.527025738989693,
        "distinct-2": 0.8830660930778256,
        "vocab_size-2": 2258,
        "unique-2": 2126,
        "entropy-2": 10.954573023719119,
        "cond_entropy-2": 2.114821724446926,
        "distinct-3": 0.9811162400335711,
        "vocab_size-3": 2338,
        "unique-3": 2306,
        "entropy-3": 11.175343043802616,
        "cond_entropy-3": 0.23697876340882884,
        "total_length-nopunct": 2409,
        "mean_pred_length-nopunct": 13.844827586206897,
        "std_pred_length-nopunct": 6.162926954656724,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.49937733499377335,
        "vocab_size-1-nopunct": 1203,
        "unique-1-nopunct": 938,
        "entropy-1-nopunct": 8.850344661646977,
        "distinct-2-nopunct": 0.8890380313199105,
        "vocab_size-2-nopunct": 1987,
        "unique-2-nopunct": 1884,
        "entropy-2-nopunct": 10.765986392189674,
        "cond_entropy-2-nopunct": 2.0638051185772497,
        "distinct-3-nopunct": 0.9854439592430859,
        "vocab_size-3-nopunct": 2031,
        "unique-3-nopunct": 2005,
        "entropy-3-nopunct": 10.978551618258944,
        "cond_entropy-3-nopunct": 0.23414830659072972,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 9.868814843385607,
        "bleu": 69.74785,
        "rouge1": {
            "precision": 0.87692,
            "recall": 0.78305,
            "fmeasure": 0.81237
        },
        "rouge2": {
            "precision": 0.73502,
            "recall": 0.65095,
            "fmeasure": 0.67488
        },
        "rougeL": {
            "precision": 0.84491,
            "recall": 0.75399,
            "fmeasure": 0.78193
        },
        "rougeLsum": {
            "precision": 0.84491,
            "recall": 0.75399,
            "fmeasure": 0.78193
        },
        "local_recall": {
            "1": 0.03777544596012592,
            "2": 0.14521452145214522,
            "3": 0.3492063492063492,
            "4": 0.5040322580645161,
            "5": 0.631578947368421,
            "6": 0.7417910447761195,
            "7": 0.8481012658227848
        },
        "bertscore": {
            "precision": 0.96047,
            "recall": 0.94003,
            "f1": 0.94774
        },
        "bleurt": 0.24874,
        "meteor": 0.4564686495434487,
        "nubia": {
            "semantic_relation": 4.26974,
            "contradiction": 5.08942,
            "irrelevancy": 13.81398,
            "logical_agreement": 81.0966,
            "grammar_ref": 4.58509,
            "grammar_hyp": 5.05288,
            "nubia_score": 0.68766
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 41,
        "msttr-100": 0.616,
        "msttr-100_nopunct": 0.6475,
        "total_length": 589,
        "mean_pred_length": 14.365853658536585,
        "std_pred_length": 4.912681933879114,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.43463497453310695,
        "vocab_size-1": 256,
        "unique-1": 203,
        "entropy-1": 6.835853790179644,
        "distinct-2": 0.7791970802919708,
        "vocab_size-2": 427,
        "unique-2": 381,
        "entropy-2": 8.459051843487119,
        "cond_entropy-2": 1.3967966975515005,
        "distinct-3": 0.8895463510848126,
        "vocab_size-3": 451,
        "unique-3": 424,
        "entropy-3": 8.688990865082308,
        "cond_entropy-3": 0.20859511589447816,
        "total_length-nopunct": 498,
        "mean_pred_length-nopunct": 12.146341463414634,
        "std_pred_length-nopunct": 4.045840837023212,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5020080321285141,
        "vocab_size-1-nopunct": 250,
        "unique-1-nopunct": 202,
        "entropy-1-nopunct": 6.971173054884374,
        "distinct-2-nopunct": 0.8161925601750547,
        "vocab_size-2-nopunct": 373,
        "unique-2-nopunct": 338,
        "entropy-2-nopunct": 8.306587883869762,
        "cond_entropy-2-nopunct": 1.4212306424891283,
        "distinct-3-nopunct": 0.9110576923076923,
        "vocab_size-3-nopunct": 379,
        "unique-3-nopunct": 361,
        "entropy-3-nopunct": 8.458542625633648,
        "cond_entropy-3-nopunct": 0.1536565718570307,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.281756633496054,
        "bleu": 45.37094,
        "rouge1": {
            "precision": 0.754,
            "recall": 0.75825,
            "fmeasure": 0.74348
        },
        "rouge2": {
            "precision": 0.53542,
            "recall": 0.52567,
            "fmeasure": 0.52274
        },
        "rougeL": {
            "precision": 0.65834,
            "recall": 0.656,
            "fmeasure": 0.6449
        },
        "rougeLsum": {
            "precision": 0.65834,
            "recall": 0.656,
            "fmeasure": 0.6449
        },
        "local_recall": {
            "1": 0.25555555555555554,
            "2": 0.4628099173553719,
            "3": 0.8090909090909091
        },
        "bertscore": {
            "precision": 0.92815,
            "recall": 0.93271,
            "f1": 0.92859
        },
        "bleurt": 0.33224,
        "meteor": 0.4147246630056023,
        "nubia": {
            "semantic_relation": 4.01754,
            "contradiction": 9.74323,
            "irrelevancy": 35.82839,
            "logical_agreement": 54.42839,
            "grammar_ref": 4.45723,
            "grammar_hyp": 4.37256,
            "nubia_score": 0.69552
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 254,
        "msttr-100": 0.46558,
        "msttr-100_nopunct": 0.46766,
        "total_length": 5215,
        "mean_pred_length": 20.531496062992126,
        "std_pred_length": 7.0691878916064255,
        "median_pred_length": 19.0,
        "min_pred_length": 6,
        "max_pred_length": 44,
        "distinct-1": 0.1654841802492809,
        "vocab_size-1": 863,
        "unique-1": 522,
        "entropy-1": 5.693693919727982,
        "distinct-2": 0.38318887321104617,
        "vocab_size-2": 1901,
        "unique-2": 1248,
        "entropy-2": 9.670516866041533,
        "cond_entropy-2": 3.9076594307711425,
        "distinct-3": 0.5670278308901636,
        "vocab_size-3": 2669,
        "unique-3": 1968,
        "entropy-3": 10.72568033202912,
        "cond_entropy-3": 1.12478856795932,
        "total_length-nopunct": 4754,
        "mean_pred_length-nopunct": 18.716535433070867,
        "std_pred_length-nopunct": 6.890479152962145,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.1802692469499369,
        "vocab_size-1-nopunct": 857,
        "unique-1-nopunct": 521,
        "entropy-1-nopunct": 5.594767796307725,
        "distinct-2-nopunct": 0.37,
        "vocab_size-2-nopunct": 1665,
        "unique-2-nopunct": 1080,
        "entropy-2-nopunct": 9.433482691235183,
        "cond_entropy-2-nopunct": 4.05731839442587,
        "distinct-3-nopunct": 0.5555817239755063,
        "vocab_size-3-nopunct": 2359,
        "unique-3-nopunct": 1748,
        "entropy-3-nopunct": 10.508531839031518,
        "cond_entropy-3-nopunct": 1.1461862331136603,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.1008539071740973,
        "bleu": 3.59434,
        "rouge1": {
            "precision": 0.32885,
            "recall": 0.33404,
            "fmeasure": 0.32926
        },
        "rouge2": {
            "precision": 0.19439,
            "recall": 0.19029,
            "fmeasure": 0.19132
        },
        "rougeL": {
            "precision": 0.32819,
            "recall": 0.33355,
            "fmeasure": 0.3287
        },
        "rougeLsum": {
            "precision": 0.32819,
            "recall": 0.33355,
            "fmeasure": 0.3287
        },
        "local_recall": {
            "1": 0.11005434782608696,
            "2": 0.20804438280166435,
            "3": 0.23208191126279865,
            "4": 0.22857142857142856,
            "5": 0.45454545454545453,
            "6": 0.2,
            "7": 0.3333333333333333
        },
        "bertscore": {
            "precision": 0.87184,
            "recall": 0.8816,
            "f1": 0.87628
        },
        "bleurt": -0.35998,
        "meteor": 0.157108233140328,
        "nubia": {
            "semantic_relation": 3.34642,
            "contradiction": 36.97651,
            "irrelevancy": 15.49718,
            "logical_agreement": 47.52631,
            "grammar_ref": 2.90382,
            "grammar_hyp": 3.00167,
            "nubia_score": 0.20835
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 453,
        "msttr-100": 0.52909,
        "msttr-100_nopunct": 0.55708,
        "total_length": 5529,
        "mean_pred_length": 12.205298013245033,
        "std_pred_length": 4.566870643218889,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 34,
        "distinct-1": 0.18086453246518358,
        "vocab_size-1": 1000,
        "unique-1": 548,
        "entropy-1": 7.43687082410642,
        "distinct-2": 0.4694641449960599,
        "vocab_size-2": 2383,
        "unique-2": 1620,
        "entropy-2": 10.463639277499489,
        "cond_entropy-2": 2.6829408368829837,
        "distinct-3": 0.663638330088687,
        "vocab_size-3": 3068,
        "unique-3": 2403,
        "entropy-3": 11.200682111119704,
        "cond_entropy-3": 0.8307752757158149,
        "total_length-nopunct": 4857,
        "mean_pred_length-nopunct": 10.721854304635762,
        "std_pred_length-nopunct": 4.120951057845382,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.20444718962322422,
        "vocab_size-1-nopunct": 993,
        "unique-1-nopunct": 548,
        "entropy-1-nopunct": 7.685904315059967,
        "distinct-2-nopunct": 0.45572207084468663,
        "vocab_size-2-nopunct": 2007,
        "unique-2-nopunct": 1345,
        "entropy-2-nopunct": 10.194415271955336,
        "cond_entropy-2-nopunct": 2.797405414690452,
        "distinct-3-nopunct": 0.6514806378132119,
        "vocab_size-3-nopunct": 2574,
        "unique-3-nopunct": 1983,
        "entropy-3-nopunct": 10.939185270169679,
        "cond_entropy-3-nopunct": 0.8715668497187872,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.470853364681698,
        "bleu": 41.41819,
        "rouge1": {
            "precision": 0.70059,
            "recall": 0.71256,
            "fmeasure": 0.69967
        },
        "rouge2": {
            "precision": 0.44771,
            "recall": 0.4569,
            "fmeasure": 0.4473
        },
        "rougeL": {
            "precision": 0.60467,
            "recall": 0.61535,
            "fmeasure": 0.60359
        },
        "rougeLsum": {
            "precision": 0.60467,
            "recall": 0.61535,
            "fmeasure": 0.60359
        },
        "local_recall": {
            "1": 0.2453846153846154,
            "2": 0.5906801007556675,
            "3": 0.765504753282028,
            "4": 1.0
        },
        "bertscore": {
            "precision": 0.91107,
            "recall": 0.91527,
            "f1": 0.91226
        },
        "bleurt": 0.06279,
        "meteor": 0.3753855108517027,
        "nubia": {
            "semantic_relation": 4.06884,
            "contradiction": 25.5917,
            "irrelevancy": 7.79718,
            "logical_agreement": 66.61112,
            "grammar_ref": 5.12238,
            "grammar_hyp": 5.26018,
            "nubia_score": 0.65152
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 58,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.76222,
        "total_length": 1076,
        "mean_pred_length": 18.551724137931036,
        "std_pred_length": 9.555955741358197,
        "median_pred_length": 16.5,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.5204460966542751,
        "vocab_size-1": 560,
        "unique-1": 451,
        "entropy-1": 7.979769851784766,
        "distinct-2": 0.9322200392927309,
        "vocab_size-2": 949,
        "unique-2": 906,
        "entropy-2": 9.82741708180665,
        "cond_entropy-2": 1.6289197251555976,
        "distinct-3": 0.9895833333333334,
        "vocab_size-3": 950,
        "unique-3": 942,
        "entropy-3": 9.884484579978997,
        "cond_entropy-3": 0.06698216101369327,
        "total_length-nopunct": 970,
        "mean_pred_length-nopunct": 16.724137931034484,
        "std_pred_length-nopunct": 8.762760357582723,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.5711340206185567,
        "vocab_size-1-nopunct": 554,
        "unique-1-nopunct": 450,
        "entropy-1-nopunct": 8.174318673260368,
        "distinct-2-nopunct": 0.9418859649122807,
        "vocab_size-2-nopunct": 859,
        "unique-2-nopunct": 822,
        "entropy-2-nopunct": 9.696344701650442,
        "cond_entropy-2-nopunct": 1.6193630117239939,
        "distinct-3-nopunct": 0.9929742388758782,
        "vocab_size-3-nopunct": 848,
        "unique-3-nopunct": 842,
        "entropy-3-nopunct": 9.72404073737213,
        "cond_entropy-3-nopunct": 0.036969604955726605,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 8.365027290957844,
        "bleu": 65.92355,
        "rouge1": {
            "precision": 0.84835,
            "recall": 0.72864,
            "fmeasure": 0.76557
        },
        "rouge2": {
            "precision": 0.72696,
            "recall": 0.60629,
            "fmeasure": 0.64129
        },
        "rougeL": {
            "precision": 0.83362,
            "recall": 0.71284,
            "fmeasure": 0.75005
        },
        "rougeLsum": {
            "precision": 0.83362,
            "recall": 0.71284,
            "fmeasure": 0.75005
        },
        "local_recall": {
            "1": 0.03751465416178194,
            "2": 0.14084507042253522,
            "3": 0.2987012987012987,
            "4": 0.47115384615384615,
            "5": 0.5307262569832403,
            "6": 0.7311827956989247,
            "7": 0.8192488262910798
        },
        "bertscore": {
            "precision": 0.95543,
            "recall": 0.92776,
            "f1": 0.93902
        },
        "bleurt": 0.15188,
        "meteor": 0.43374272127036767,
        "nubia": {
            "semantic_relation": 4.1909,
            "contradiction": 4.97432,
            "irrelevancy": 12.02254,
            "logical_agreement": 83.00314,
            "grammar_ref": 4.54049,
            "grammar_hyp": 5.01743,
            "nubia_score": 0.66908
        }
    },
    "web_nlg_en_challenge_test_numbers_parent": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 500,
        "msttr-100": 0.64094,
        "msttr-100_nopunct": 0.6807,
        "total_length": 12897,
        "mean_pred_length": 25.794,
        "std_pred_length": 12.973802989100768,
        "median_pred_length": 24.0,
        "min_pred_length": 5,
        "max_pred_length": 68,
        "distinct-1": 0.11436768240676126,
        "vocab_size-1": 1475,
        "unique-1": 545,
        "entropy-1": 7.983532988653181,
        "distinct-2": 0.3463741227716383,
        "vocab_size-2": 4294,
        "unique-2": 2386,
        "entropy-2": 11.1171716846401,
        "cond_entropy-2": 2.974292204400325,
        "distinct-3": 0.5470286626880726,
        "vocab_size-3": 6508,
        "unique-3": 4552,
        "entropy-3": 12.141828190644954,
        "cond_entropy-3": 1.0688566049510668,
        "total_length-nopunct": 11412,
        "mean_pred_length-nopunct": 22.824,
        "std_pred_length-nopunct": 11.622264151188443,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 60,
        "distinct-1-nopunct": 0.12837364178058183,
        "vocab_size-1-nopunct": 1465,
        "unique-1-nopunct": 545,
        "entropy-1-nopunct": 8.251972834967416,
        "distinct-2-nopunct": 0.36171187683284456,
        "vocab_size-2-nopunct": 3947,
        "unique-2-nopunct": 2298,
        "entropy-2-nopunct": 11.012034941250164,
        "cond_entropy-2-nopunct": 2.8821742924947324,
        "distinct-3-nopunct": 0.5591625048021513,
        "vocab_size-3-nopunct": 5822,
        "unique-3-nopunct": 4187,
        "entropy-3-nopunct": 11.980586668914045,
        "cond_entropy-3-nopunct": 1.0114371499593522,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.623472526601297,
        "bleu": 39.0342,
        "rouge1": {
            "precision": 0.68401,
            "recall": 0.68846,
            "fmeasure": 0.67983
        },
        "rouge2": {
            "precision": 0.41752,
            "recall": 0.42177,
            "fmeasure": 0.41541
        },
        "rougeL": {
            "precision": 0.5371,
            "recall": 0.54123,
            "fmeasure": 0.53372
        },
        "rougeLsum": {
            "precision": 0.5371,
            "recall": 0.54123,
            "fmeasure": 0.53372
        },
        "local_recall": {
            "1": 0.22370896926615094,
            "2": 0.5596835225318197,
            "3": 0.7793511381968095,
            "4": 0.5555555555555556,
            "5": 0.7272727272727273
        },
        "bertscore": {
            "precision": 0.89661,
            "recall": 0.89963,
            "f1": 0.89685
        },
        "bleurt": -0.04481,
        "meteor": 0.3422791334748946,
        "nubia": {
            "semantic_relation": 4.00387,
            "contradiction": 23.05312,
            "irrelevancy": 10.37063,
            "logical_agreement": 66.57625,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.64277,
            "nubia_score": 0.6603
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 379,
        "msttr-100": 0.70103,
        "msttr-100_nopunct": 0.75237,
        "total_length": 8764,
        "mean_pred_length": 23.12401055408971,
        "std_pred_length": 5.75836468649611,
        "median_pred_length": 23.0,
        "min_pred_length": 10,
        "max_pred_length": 42,
        "distinct-1": 0.33591967138293016,
        "vocab_size-1": 2944,
        "unique-1": 2152,
        "entropy-1": 9.206048748856896,
        "distinct-2": 0.757185450208706,
        "vocab_size-2": 6349,
        "unique-2": 5544,
        "entropy-2": 12.227852169906834,
        "cond_entropy-2": 2.8089763745935143,
        "distinct-3": 0.9233075193604796,
        "vocab_size-3": 7392,
        "unique-3": 6974,
        "entropy-3": 12.785320709836752,
        "cond_entropy-3": 0.5378056772836056,
        "total_length-nopunct": 7610,
        "mean_pred_length-nopunct": 20.07915567282322,
        "std_pred_length-nopunct": 5.05683406797864,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.3847568988173456,
        "vocab_size-1-nopunct": 2928,
        "unique-1-nopunct": 2150,
        "entropy-1-nopunct": 9.611422633162604,
        "distinct-2-nopunct": 0.794219333425529,
        "vocab_size-2-nopunct": 5743,
        "unique-2-nopunct": 5125,
        "entropy-2-nopunct": 12.144290463350258,
        "cond_entropy-2-nopunct": 2.6136627236301972,
        "distinct-3-nopunct": 0.9356392294220666,
        "vocab_size-3-nopunct": 6411,
        "unique-3-nopunct": 6106,
        "entropy-3-nopunct": 12.590713629346029,
        "cond_entropy-3-nopunct": 0.4661133903476388,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.7591643416175,
        "bleu": 41.27344,
        "rouge1": {
            "precision": 0.76504,
            "recall": 0.72581,
            "fmeasure": 0.73668
        },
        "rouge2": {
            "precision": 0.50381,
            "recall": 0.47756,
            "fmeasure": 0.48488
        },
        "rougeL": {
            "precision": 0.60788,
            "recall": 0.58085,
            "fmeasure": 0.58682
        },
        "rougeLsum": {
            "precision": 0.60788,
            "recall": 0.58085,
            "fmeasure": 0.58682
        },
        "local_recall": {
            "1": 0.23883928571428573,
            "2": 0.4375876577840112,
            "3": 0.7727930535455861
        },
        "bertscore": {
            "precision": 0.92609,
            "recall": 0.91829,
            "f1": 0.92054
        },
        "bleurt": 0.20651,
        "meteor": 0.38345471669167647,
        "nubia": {
            "semantic_relation": 4.1247,
            "contradiction": 9.64215,
            "irrelevancy": 29.52669,
            "logical_agreement": 60.83116,
            "grammar_ref": 4.27824,
            "grammar_hyp": 4.19622,
            "nubia_score": 0.71808
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 159,
        "msttr-100": 0.45165,
        "msttr-100_nopunct": 0.45078,
        "total_length": 9799,
        "mean_pred_length": 61.62893081761006,
        "std_pred_length": 9.336176650767342,
        "median_pred_length": 62.0,
        "min_pred_length": 36,
        "max_pred_length": 80,
        "distinct-1": 0.11246045514848454,
        "vocab_size-1": 1102,
        "unique-1": 501,
        "entropy-1": 5.717411307246636,
        "distinct-2": 0.27842323651452283,
        "vocab_size-2": 2684,
        "unique-2": 1475,
        "entropy-2": 9.76566346734808,
        "cond_entropy-2": 4.052498861391547,
        "distinct-3": 0.45817951692859404,
        "vocab_size-3": 4344,
        "unique-3": 2726,
        "entropy-3": 11.255406415003225,
        "cond_entropy-3": 1.5111652137921097,
        "total_length-nopunct": 9051,
        "mean_pred_length-nopunct": 56.924528301886795,
        "std_pred_length-nopunct": 9.46330029379058,
        "median_pred_length-nopunct": 57.0,
        "min_pred_length-nopunct": 31,
        "max_pred_length-nopunct": 75,
        "distinct-1-nopunct": 0.12109159208927191,
        "vocab_size-1-nopunct": 1096,
        "unique-1-nopunct": 500,
        "entropy-1-nopunct": 5.62406991907048,
        "distinct-2-nopunct": 0.282838506522717,
        "vocab_size-2-nopunct": 2515,
        "unique-2-nopunct": 1379,
        "entropy-2-nopunct": 9.676266695586845,
        "cond_entropy-2-nopunct": 4.103819700561559,
        "distinct-3-nopunct": 0.4616970113363105,
        "vocab_size-3-nopunct": 4032,
        "unique-3-nopunct": 2569,
        "entropy-3-nopunct": 11.125204059704831,
        "cond_entropy-3-nopunct": 1.4659898390436696,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.0535431469070917,
        "bleu": 1.90663,
        "rouge1": {
            "precision": 0.457,
            "recall": 0.38389,
            "fmeasure": 0.40381
        },
        "rouge2": {
            "precision": 0.23355,
            "recall": 0.18606,
            "fmeasure": 0.19744
        },
        "rougeL": {
            "precision": 0.43431,
            "recall": 0.36477,
            "fmeasure": 0.38291
        },
        "rougeLsum": {
            "precision": 0.43431,
            "recall": 0.36477,
            "fmeasure": 0.38291
        },
        "local_recall": {
            "1": 0.07017543859649122,
            "2": 0.16591639871382638,
            "3": 0.25043630017452007
        },
        "bertscore": {
            "precision": 0.85659,
            "recall": 0.86432,
            "f1": 0.86
        },
        "bleurt": -0.5231,
        "meteor": 0.11556255965386877,
        "nubia": {
            "semantic_relation": 3.29725,
            "contradiction": 32.70902,
            "irrelevancy": 17.92666,
            "logical_agreement": 49.36432,
            "grammar_ref": 2.45758,
            "grammar_hyp": 2.40189,
            "nubia_score": 0.12577
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 29,
        "msttr-100": 0.45105,
        "msttr-100_nopunct": 0.45167,
        "total_length": 1950,
        "mean_pred_length": 67.24137931034483,
        "std_pred_length": 4.336335433756791,
        "median_pred_length": 67.0,
        "min_pred_length": 59,
        "max_pred_length": 75,
        "distinct-1": 0.18,
        "vocab_size-1": 351,
        "unique-1": 196,
        "entropy-1": 5.2652772010239115,
        "distinct-2": 0.39458615304528893,
        "vocab_size-2": 758,
        "unique-2": 457,
        "entropy-2": 8.694769062578617,
        "cond_entropy-2": 3.4347311012628987,
        "distinct-3": 0.5597251585623678,
        "vocab_size-3": 1059,
        "unique-3": 705,
        "entropy-3": 9.597701475768872,
        "cond_entropy-3": 0.9054614286347107,
        "total_length-nopunct": 1805,
        "mean_pred_length-nopunct": 62.241379310344826,
        "std_pred_length-nopunct": 4.399491917481579,
        "median_pred_length-nopunct": 62.0,
        "min_pred_length-nopunct": 54,
        "max_pred_length-nopunct": 72,
        "distinct-1-nopunct": 0.19113573407202217,
        "vocab_size-1-nopunct": 345,
        "unique-1-nopunct": 193,
        "entropy-1-nopunct": 5.144824361170987,
        "distinct-2-nopunct": 0.40484234234234234,
        "vocab_size-2-nopunct": 719,
        "unique-2-nopunct": 432,
        "entropy-2-nopunct": 8.650348427665831,
        "cond_entropy-2-nopunct": 3.524532832244282,
        "distinct-3-nopunct": 0.5678305666857469,
        "vocab_size-3-nopunct": 992,
        "unique-3-nopunct": 661,
        "entropy-3-nopunct": 9.532390641313315,
        "cond_entropy-3-nopunct": 0.8856419709905097,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.2027415335928007,
        "bleu": 1.24537,
        "rouge1": {
            "precision": 0.76006,
            "recall": 0.65223,
            "fmeasure": 0.67237
        },
        "rouge2": {
            "precision": 0.49138,
            "recall": 0.44522,
            "fmeasure": 0.4476
        },
        "rougeL": {
            "precision": 0.74473,
            "recall": 0.64605,
            "fmeasure": 0.66167
        },
        "rougeLsum": {
            "precision": 0.74473,
            "recall": 0.64605,
            "fmeasure": 0.66167
        },
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.15294117647058825,
            "3": 0.26099706744868034
        },
        "bertscore": {
            "precision": 0.86098,
            "recall": 0.85959,
            "f1": 0.85991
        },
        "bleurt": -0.50181,
        "meteor": 0.1121987277876359,
        "nubia": {
            "semantic_relation": 3.15417,
            "contradiction": 35.36983,
            "irrelevancy": 21.35284,
            "logical_agreement": 43.27732,
            "grammar_ref": 2.50557,
            "grammar_hyp": 2.47068,
            "nubia_score": 0.17628
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 22,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.78,
        "total_length": 481,
        "mean_pred_length": 21.863636363636363,
        "std_pred_length": 9.891665245160395,
        "median_pred_length": 20.5,
        "min_pred_length": 9,
        "max_pred_length": 46,
        "distinct-1": 0.5862785862785863,
        "vocab_size-1": 282,
        "unique-1": 232,
        "entropy-1": 7.3599055696320805,
        "distinct-2": 0.9259259259259259,
        "vocab_size-2": 425,
        "unique-2": 403,
        "entropy-2": 8.667973219193199,
        "cond_entropy-2": 1.1597776476786388,
        "distinct-3": 0.9839816933638444,
        "vocab_size-3": 430,
        "unique-3": 425,
        "entropy-3": 8.735997993518088,
        "cond_entropy-3": 0.07680348538422904,
        "total_length-nopunct": 429,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 8.653690752295441,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.6456876456876457,
        "vocab_size-1-nopunct": 277,
        "unique-1-nopunct": 232,
        "entropy-1-nopunct": 7.499486191448108,
        "distinct-2-nopunct": 0.9361179361179361,
        "vocab_size-2-nopunct": 381,
        "unique-2-nopunct": 364,
        "entropy-2-nopunct": 8.51710503952222,
        "cond_entropy-2-nopunct": 1.0800209321358936,
        "distinct-3-nopunct": 0.9922077922077922,
        "vocab_size-3-nopunct": 382,
        "unique-3-nopunct": 379,
        "entropy-3-nopunct": 8.573130219997898,
        "cond_entropy-3-nopunct": 0.06469832017528299,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 8.188878601567664,
        "bleu": 64.83473,
        "rouge1": {
            "precision": 0.81032,
            "recall": 0.77787,
            "fmeasure": 0.77689
        },
        "rouge2": {
            "precision": 0.67727,
            "recall": 0.64546,
            "fmeasure": 0.64383
        },
        "rougeL": {
            "precision": 0.79039,
            "recall": 0.75947,
            "fmeasure": 0.75717
        },
        "rougeLsum": {
            "precision": 0.79039,
            "recall": 0.75947,
            "fmeasure": 0.75717
        },
        "local_recall": {
            "1": 0.04666666666666667,
            "2": 0.1694915254237288,
            "3": 0.40625,
            "4": 0.4897959183673469,
            "5": 0.6756756756756757,
            "6": 0.7575757575757576,
            "7": 0.8511904761904762
        },
        "bertscore": {
            "precision": 0.95586,
            "recall": 0.9458,
            "f1": 0.94887
        },
        "bleurt": 0.23151,
        "meteor": 0.44273999392696356,
        "nubia": {
            "semantic_relation": 4.31814,
            "contradiction": 2.67032,
            "irrelevancy": 14.64799,
            "logical_agreement": 82.68169,
            "grammar_ref": 4.50363,
            "grammar_hyp": 4.82615,
            "nubia_score": 0.70037
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 15.0,
        "std_pred_length": 1.632993161855452,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 17,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 40,
        "unique-1": 36,
        "entropy-1": 5.252855596281597,
        "distinct-2": 1.0,
        "vocab_size-2": 42,
        "unique-2": 42,
        "entropy-2": 5.3923174227787625,
        "cond_entropy-2": 0.04332146930622851,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.10691520391651191,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 1.247219128924647,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.926829268292683,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.211210541203447,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.247927513443589,
        "cond_entropy-2-nopunct": 0.0482702456676074,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.11864449649861893,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 3.894291204109616,
        "bleu": 45.966,
        "rouge1": {
            "precision": 0.84206,
            "recall": 0.70543,
            "fmeasure": 0.75545
        },
        "rouge2": {
            "precision": 0.68058,
            "recall": 0.54153,
            "fmeasure": 0.58726
        },
        "rougeL": {
            "precision": 0.81746,
            "recall": 0.67415,
            "fmeasure": 0.72628
        },
        "rougeLsum": {
            "precision": 0.81746,
            "recall": 0.67415,
            "fmeasure": 0.72628
        },
        "local_recall": {
            "1": 0.02564102564102564,
            "2": 0.06666666666666667,
            "3": 0.25,
            "4": 0.2857142857142857,
            "5": 0.5,
            "6": 0.42857142857142855,
            "7": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.95102,
            "recall": 0.91396,
            "f1": 0.92833
        },
        "bleurt": 0.18384,
        "meteor": 0.3469186977459762,
        "nubia": {
            "semantic_relation": 4.03601,
            "contradiction": 0.85092,
            "irrelevancy": 13.86609,
            "logical_agreement": 85.28299,
            "grammar_ref": 4.54431,
            "grammar_hyp": 4.73574,
            "nubia_score": 0.65965
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 30,
        "msttr-100": 0.72333,
        "msttr-100_nopunct": 0.756,
        "total_length": 631,
        "mean_pred_length": 21.033333333333335,
        "std_pred_length": 10.759440299362952,
        "median_pred_length": 18.5,
        "min_pred_length": 6,
        "max_pred_length": 52,
        "distinct-1": 0.5388272583201268,
        "vocab_size-1": 340,
        "unique-1": 269,
        "entropy-1": 7.621563070198149,
        "distinct-2": 0.9251247920133111,
        "vocab_size-2": 556,
        "unique-2": 522,
        "entropy-2": 9.066022823780889,
        "cond_entropy-2": 1.2833803457211752,
        "distinct-3": 0.9807355516637478,
        "vocab_size-3": 560,
        "unique-3": 551,
        "entropy-3": 9.116173949365779,
        "cond_entropy-3": 0.058830548891267834,
        "total_length-nopunct": 568,
        "mean_pred_length-nopunct": 18.933333333333334,
        "std_pred_length-nopunct": 9.437278327050773,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.5880281690140845,
        "vocab_size-1-nopunct": 334,
        "unique-1-nopunct": 269,
        "entropy-1-nopunct": 7.721830488589433,
        "distinct-2-nopunct": 0.9368029739776952,
        "vocab_size-2-nopunct": 504,
        "unique-2-nopunct": 476,
        "entropy-2-nopunct": 8.935738291908594,
        "cond_entropy-2-nopunct": 1.2764869370105907,
        "distinct-3-nopunct": 0.9901574803149606,
        "vocab_size-3-nopunct": 503,
        "unique-3-nopunct": 498,
        "entropy-3-nopunct": 8.96899964740216,
        "cond_entropy-3-nopunct": 0.037339548642025336,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 7.681975554397751,
        "bleu": 61.39866,
        "rouge1": {
            "precision": 0.79489,
            "recall": 0.70635,
            "fmeasure": 0.73071
        },
        "rouge2": {
            "precision": 0.63096,
            "recall": 0.57213,
            "fmeasure": 0.58345
        },
        "rougeL": {
            "precision": 0.76217,
            "recall": 0.68443,
            "fmeasure": 0.70288
        },
        "rougeLsum": {
            "precision": 0.76217,
            "recall": 0.68443,
            "fmeasure": 0.70288
        },
        "local_recall": {
            "1": 0.04524886877828054,
            "2": 0.16049382716049382,
            "3": 0.3559322033898305,
            "4": 0.34782608695652173,
            "5": 0.6086956521739131,
            "6": 0.7077922077922078,
            "7": 0.8493150684931506
        },
        "bertscore": {
            "precision": 0.94486,
            "recall": 0.93186,
            "f1": 0.93421
        },
        "bleurt": 0.10159,
        "meteor": 0.4319704728455816,
        "nubia": {
            "semantic_relation": 4.11532,
            "contradiction": 2.46038,
            "irrelevancy": 17.44582,
            "logical_agreement": 80.09381,
            "grammar_ref": 4.65355,
            "grammar_hyp": 5.02325,
            "nubia_score": 0.63808
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 9,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.83,
        "total_length": 183,
        "mean_pred_length": 20.333333333333332,
        "std_pred_length": 9.843215373488935,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 43,
        "distinct-1": 0.7103825136612022,
        "vocab_size-1": 130,
        "unique-1": 110,
        "entropy-1": 6.616741672547743,
        "distinct-2": 0.9540229885057471,
        "vocab_size-2": 166,
        "unique-2": 161,
        "entropy-2": 7.33024441266229,
        "cond_entropy-2": 0.5745714814084505,
        "distinct-3": 0.9878787878787879,
        "vocab_size-3": 163,
        "unique-3": 161,
        "entropy-3": 7.3420797900033845,
        "cond_entropy-3": 0.01798260006034105,
        "total_length-nopunct": 159,
        "mean_pred_length-nopunct": 17.666666666666668,
        "std_pred_length-nopunct": 7.60116950066092,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.779874213836478,
        "vocab_size-1-nopunct": 124,
        "unique-1-nopunct": 109,
        "entropy-1-nopunct": 6.651089673431514,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 144,
        "unique-2-nopunct": 141,
        "entropy-2-nopunct": 7.124754420666283,
        "cond_entropy-2-nopunct": 0.5133723441459328,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 141,
        "unique-3-nopunct": 141,
        "entropy-3-nopunct": 7.139551352398772,
        "cond_entropy-3-nopunct": 0.02143933193437947,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 6.768565757769792,
        "bleu": 53.91824,
        "rouge1": {
            "precision": 0.84404,
            "recall": 0.7151,
            "fmeasure": 0.76132
        },
        "rouge2": {
            "precision": 0.67052,
            "recall": 0.55711,
            "fmeasure": 0.58996
        },
        "rougeL": {
            "precision": 0.78681,
            "recall": 0.66112,
            "fmeasure": 0.70672
        },
        "rougeLsum": {
            "precision": 0.78681,
            "recall": 0.66112,
            "fmeasure": 0.70672
        },
        "local_recall": {
            "1": 0.07407407407407407,
            "2": 0.22727272727272727,
            "3": 0.5,
            "4": 0.75,
            "5": 0.47058823529411764,
            "6": 0.66,
            "7": 0.7936507936507936
        },
        "bertscore": {
            "precision": 0.93906,
            "recall": 0.91069,
            "f1": 0.92233
        },
        "bleurt": -0.00804,
        "meteor": 0.3993479852649743,
        "nubia": {
            "semantic_relation": 3.94182,
            "contradiction": 6.54204,
            "irrelevancy": 21.21242,
            "logical_agreement": 72.24554,
            "grammar_ref": 4.59683,
            "grammar_hyp": 5.2387,
            "nubia_score": 0.53827
        }
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 253,
        "msttr-100": 0.46431,
        "msttr-100_nopunct": 0.46574,
        "total_length": 5198,
        "mean_pred_length": 20.545454545454547,
        "std_pred_length": 7.0796505331025195,
        "median_pred_length": 19.0,
        "min_pred_length": 6,
        "max_pred_length": 44,
        "distinct-1": 0.1654482493266641,
        "vocab_size-1": 860,
        "unique-1": 521,
        "entropy-1": 5.693395874743553,
        "distinct-2": 0.38301314459049546,
        "vocab_size-2": 1894,
        "unique-2": 1244,
        "entropy-2": 9.666040378154642,
        "cond_entropy-2": 3.9035923893686943,
        "distinct-3": 0.56692242114237,
        "vocab_size-3": 2660,
        "unique-3": 1961,
        "entropy-3": 10.721443898272113,
        "cond_entropy-3": 1.1246858981388497,
        "total_length-nopunct": 4738,
        "mean_pred_length-nopunct": 18.727272727272727,
        "std_pred_length-nopunct": 6.901962205438656,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.1802448290417898,
        "vocab_size-1-nopunct": 854,
        "unique-1-nopunct": 520,
        "entropy-1-nopunct": 5.594272896055965,
        "distinct-2-nopunct": 0.36989966555183945,
        "vocab_size-2-nopunct": 1659,
        "unique-2-nopunct": 1077,
        "entropy-2-nopunct": 9.429270907873534,
        "cond_entropy-2-nopunct": 4.052654705905101,
        "distinct-3-nopunct": 0.5555293005671077,
        "vocab_size-3-nopunct": 2351,
        "unique-3-nopunct": 1742,
        "entropy-3-nopunct": 10.50429763450162,
        "cond_entropy-3-nopunct": 1.145729307915759,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.1033431418047115,
        "bleu": 3.60477,
        "rouge1": {
            "precision": 0.33015,
            "recall": 0.33536,
            "fmeasure": 0.33056
        },
        "rouge2": {
            "precision": 0.19516,
            "recall": 0.19104,
            "fmeasure": 0.19208
        },
        "rougeL": {
            "precision": 0.32949,
            "recall": 0.33487,
            "fmeasure": 0.33
        },
        "rougeLsum": {
            "precision": 0.32949,
            "recall": 0.33487,
            "fmeasure": 0.33
        },
        "local_recall": {
            "1": 0.110580204778157,
            "2": 0.20920502092050208,
            "3": 0.23208191126279865,
            "4": 0.22857142857142856,
            "5": 0.45454545454545453,
            "6": 0.2,
            "7": 0.3333333333333333
        },
        "bertscore": {
            "precision": 0.87191,
            "recall": 0.88175,
            "f1": 0.87639
        },
        "bleurt": -0.35967,
        "meteor": 0.15756627873363724,
        "nubia": {
            "semantic_relation": 3.34684,
            "contradiction": 36.94097,
            "irrelevancy": 15.49316,
            "logical_agreement": 47.56587,
            "grammar_ref": 2.90527,
            "grammar_hyp": 3.00275,
            "nubia_score": 0.20845
        }
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.5294117647058824,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 2.4092672522514684,
        "distinct-2": 0.9375,
        "vocab_size-2": 15,
        "unique-2": 14,
        "entropy-2": 3.875,
        "cond_entropy-2": 1.5706199720609615,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": 0.04022392894185189,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.5,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.216917186688699,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.773557262275185,
        "cond_entropy-2-nopunct": 1.6755122631405723,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": 0.04332146930622849,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.18646617655543016,
        "bleu": 2.28696,
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0
        },
        "bertscore": {
            "precision": 0.85343,
            "recall": 0.84426,
            "f1": 0.84882
        },
        "bleurt": -0.43683,
        "meteor": 0.02727272727272728,
        "nubia": {
            "semantic_relation": 3.2401,
            "contradiction": 45.96604,
            "irrelevancy": 16.51491,
            "logical_agreement": 37.51906,
            "grammar_ref": 2.53664,
            "grammar_hyp": 2.72926,
            "nubia_score": 0.18147
        }
    },
    "wiki_auto_asset_turk_test_asset": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72887,
        "msttr-100_nopunct": 0.76984,
        "total_length": 7160,
        "mean_pred_length": 19.944289693593316,
        "std_pred_length": 9.41268121583602,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 48,
        "distinct-1": 0.3741620111731844,
        "vocab_size-1": 2679,
        "unique-1": 1984,
        "entropy-1": 9.194120336853468,
        "distinct-2": 0.8406116747537127,
        "vocab_size-2": 5717,
        "unique-2": 5300,
        "entropy-2": 12.170006454560234,
        "cond_entropy-2": 2.710443523538477,
        "distinct-3": 0.9649177274138466,
        "vocab_size-3": 6216,
        "unique-3": 6107,
        "entropy-3": 12.534020277527619,
        "cond_entropy-3": 0.3791397457703247,
        "total_length-nopunct": 6345,
        "mean_pred_length-nopunct": 17.67409470752089,
        "std_pred_length-nopunct": 8.372735478286602,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.42048857368006304,
        "vocab_size-1-nopunct": 2668,
        "unique-1-nopunct": 1983,
        "entropy-1-nopunct": 9.54860391112204,
        "distinct-2-nopunct": 0.8591713999331774,
        "vocab_size-2-nopunct": 5143,
        "unique-2-nopunct": 4793,
        "entropy-2-nopunct": 12.065182536129276,
        "cond_entropy-2-nopunct": 2.6572962540486684,
        "distinct-3-nopunct": 0.9781411053847521,
        "vocab_size-3-nopunct": 5504,
        "unique-3-nopunct": 5417,
        "entropy-3-nopunct": 12.405641990946366,
        "cond_entropy-3-nopunct": 0.3650903204318789,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 13.27357163033192,
        "bleu": 85.75591,
        "rouge1": {
            "precision": 0.89371,
            "recall": 0.86896,
            "fmeasure": 0.87162
        },
        "rouge2": {
            "precision": 0.79569,
            "recall": 0.77545,
            "fmeasure": 0.7738
        },
        "rougeL": {
            "precision": 0.87917,
            "recall": 0.85515,
            "fmeasure": 0.85744
        },
        "rougeLsum": {
            "precision": 0.87917,
            "recall": 0.85515,
            "fmeasure": 0.85744
        },
        "local_recall": {
            "1": 0.030871003307607496,
            "2": 0.15498652291105122,
            "3": 0.3674698795180723,
            "4": 0.5565749235474006,
            "5": 0.6874051593323217,
            "6": 0.7633802816901408,
            "7": 0.825136612021858,
            "8": 0.864897466827503,
            "9": 0.8952380952380953,
            "10": 0.9441860465116279
        },
        "sari": 46.94513,
        "bertscore": {
            "precision": 0.96941,
            "recall": 0.96601,
            "f1": 0.96505
        },
        "bleurt": 0.23178,
        "meteor": 0.5255935126956474,
        "nubia": {
            "semantic_relation": 4.24493,
            "contradiction": 3.00277,
            "irrelevancy": 30.91127,
            "logical_agreement": 66.08596,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.82083,
            "nubia_score": 0.65288
        }
    },
    "web_nlg_ru_test_contrast_challenge_combinations-seen": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 494,
        "msttr-100": 0.46262,
        "msttr-100_nopunct": 0.45846,
        "total_length": 23306,
        "mean_pred_length": 47.178137651821864,
        "std_pred_length": 16.30033927558781,
        "median_pred_length": 44.0,
        "min_pred_length": 13,
        "max_pred_length": 87,
        "distinct-1": 0.06998197888955633,
        "vocab_size-1": 1631,
        "unique-1": 643,
        "entropy-1": 5.8435413459822145,
        "distinct-2": 0.19003156233561283,
        "vocab_size-2": 4335,
        "unique-2": 2117,
        "entropy-2": 10.062458372765754,
        "cond_entropy-2": 4.211423209421615,
        "distinct-3": 0.34219016040863875,
        "vocab_size-3": 7637,
        "unique-3": 4376,
        "entropy-3": 11.718119084537163,
        "cond_entropy-3": 1.6937115548366908,
        "total_length-nopunct": 21468,
        "mean_pred_length-nopunct": 43.45748987854251,
        "std_pred_length-nopunct": 15.52069320571507,
        "median_pred_length-nopunct": 40.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 82,
        "distinct-1-nopunct": 0.07555431339668343,
        "vocab_size-1-nopunct": 1622,
        "unique-1-nopunct": 641,
        "entropy-1-nopunct": 5.743174227938436,
        "distinct-2-nopunct": 0.19185658434251932,
        "vocab_size-2-nopunct": 4024,
        "unique-2-nopunct": 1996,
        "entropy-2-nopunct": 9.916168073429889,
        "cond_entropy-2-nopunct": 4.249345280738268,
        "distinct-3-nopunct": 0.34306640625,
        "vocab_size-3-nopunct": 7026,
        "unique-3-nopunct": 4125,
        "entropy-3-nopunct": 11.542309102527698,
        "cond_entropy-3-nopunct": 1.6615827293185441,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.1488536026893275,
        "bleu": 2.30637,
        "rouge1": {
            "precision": 0.38773,
            "recall": 0.35157,
            "fmeasure": 0.36001
        },
        "rouge2": {
            "precision": 0.18532,
            "recall": 0.16731,
            "fmeasure": 0.17132
        },
        "rougeL": {
            "precision": 0.36108,
            "recall": 0.32708,
            "fmeasure": 0.33441
        },
        "rougeLsum": {
            "precision": 0.36108,
            "recall": 0.32708,
            "fmeasure": 0.33441
        },
        "local_recall": {
            "1": 0.08508869179600886,
            "2": 0.1870608899297424,
            "3": 0.27373476172885114,
            "4": 0.0,
            "5": 0.5,
            "6": 0.0,
            "7": 0.0
        },
        "bertscore": {
            "precision": 0.86021,
            "recall": 0.87059,
            "f1": 0.86484
        },
        "bleurt": -0.50138,
        "meteor": 0.12926678487527302,
        "nubia": {
            "semantic_relation": 3.29561,
            "contradiction": 32.20382,
            "irrelevancy": 17.24038,
            "logical_agreement": 50.5558,
            "grammar_ref": 2.60025,
            "grammar_hyp": 2.57801,
            "nubia_score": 0.15303
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 144,
        "msttr-100": 0.70238,
        "msttr-100_nopunct": 0.75167,
        "total_length": 2105,
        "mean_pred_length": 14.618055555555555,
        "std_pred_length": 6.57330092936758,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 40,
        "distinct-1": 0.3672209026128266,
        "vocab_size-1": 773,
        "unique-1": 560,
        "entropy-1": 8.011616277622558,
        "distinct-2": 0.7011728709841918,
        "vocab_size-2": 1375,
        "unique-2": 1172,
        "entropy-2": 9.993718633702146,
        "cond_entropy-2": 1.6757675722712118,
        "distinct-3": 0.8420473307649973,
        "vocab_size-3": 1530,
        "unique-3": 1394,
        "entropy-3": 10.394820415882437,
        "cond_entropy-3": 0.37149464912619157,
        "total_length-nopunct": 1839,
        "mean_pred_length-nopunct": 12.770833333333334,
        "std_pred_length-nopunct": 5.641757446340044,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.41653072321914086,
        "vocab_size-1-nopunct": 766,
        "unique-1-nopunct": 559,
        "entropy-1-nopunct": 8.271350950756212,
        "distinct-2-nopunct": 0.7286135693215339,
        "vocab_size-2-nopunct": 1235,
        "unique-2-nopunct": 1075,
        "entropy-2-nopunct": 9.857071181865617,
        "cond_entropy-2-nopunct": 1.6425648169447353,
        "distinct-3-nopunct": 0.8575112830431979,
        "vocab_size-3-nopunct": 1330,
        "unique-3-nopunct": 1221,
        "entropy-3-nopunct": 10.21168743111215,
        "cond_entropy-3-nopunct": 0.36788544083460684,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.599995734372276,
        "bleu": 46.18258,
        "rouge1": {
            "precision": 0.75623,
            "recall": 0.70968,
            "fmeasure": 0.71392
        },
        "rouge2": {
            "precision": 0.52899,
            "recall": 0.49824,
            "fmeasure": 0.49909
        },
        "rougeL": {
            "precision": 0.6721,
            "recall": 0.63378,
            "fmeasure": 0.63449
        },
        "rougeLsum": {
            "precision": 0.6721,
            "recall": 0.63378,
            "fmeasure": 0.63449
        },
        "local_recall": {
            "1": 0.24708171206225682,
            "2": 0.5077262693156733,
            "3": 0.7431906614785992
        },
        "bertscore": {
            "precision": 0.92461,
            "recall": 0.91609,
            "f1": 0.91815
        },
        "bleurt": 0.24371,
        "meteor": 0.395784846135916,
        "nubia": {
            "semantic_relation": 4.08177,
            "contradiction": 6.82381,
            "irrelevancy": 34.12049,
            "logical_agreement": 59.0557,
            "grammar_ref": 4.70586,
            "grammar_hyp": 4.74385,
            "nubia_score": 0.70264
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_7": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 47,
        "msttr-100": 0.68286,
        "msttr-100_nopunct": 0.755,
        "total_length": 743,
        "mean_pred_length": 15.808510638297872,
        "std_pred_length": 6.708642561341621,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 41,
        "distinct-1": 0.46567967698519513,
        "vocab_size-1": 346,
        "unique-1": 264,
        "entropy-1": 7.4043218048286095,
        "distinct-2": 0.7916666666666666,
        "vocab_size-2": 551,
        "unique-2": 483,
        "entropy-2": 8.889532764998947,
        "cond_entropy-2": 1.2541484084023742,
        "distinct-3": 0.8813559322033898,
        "vocab_size-3": 572,
        "unique-3": 535,
        "entropy-3": 9.032804262956665,
        "cond_entropy-3": 0.15253236752624605,
        "total_length-nopunct": 629,
        "mean_pred_length-nopunct": 13.382978723404255,
        "std_pred_length-nopunct": 5.774312859513875,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.5405405405405406,
        "vocab_size-1-nopunct": 340,
        "unique-1-nopunct": 263,
        "entropy-1-nopunct": 7.632576595550217,
        "distinct-2-nopunct": 0.8161512027491409,
        "vocab_size-2-nopunct": 475,
        "unique-2-nopunct": 431,
        "entropy-2-nopunct": 8.678613240402235,
        "cond_entropy-2-nopunct": 1.1070213114423968,
        "distinct-3-nopunct": 0.8878504672897196,
        "vocab_size-3-nopunct": 475,
        "unique-3-nopunct": 450,
        "entropy-3-nopunct": 8.763485117987392,
        "cond_entropy-3-nopunct": 0.11065565107635306,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.548402280863931,
        "bleu": 47.33224,
        "rouge1": {
            "precision": 0.75183,
            "recall": 0.75765,
            "fmeasure": 0.74038
        },
        "rouge2": {
            "precision": 0.51259,
            "recall": 0.51041,
            "fmeasure": 0.50366
        },
        "rougeL": {
            "precision": 0.67478,
            "recall": 0.66935,
            "fmeasure": 0.65946
        },
        "rougeLsum": {
            "precision": 0.67478,
            "recall": 0.66935,
            "fmeasure": 0.65946
        },
        "local_recall": {
            "1": 0.1793103448275862,
            "2": 0.38848920863309355,
            "3": 0.7526881720430108
        },
        "bertscore": {
            "precision": 0.92738,
            "recall": 0.93137,
            "f1": 0.92756
        },
        "bleurt": 0.33634,
        "meteor": 0.4028354005929531,
        "nubia": {
            "semantic_relation": 4.08976,
            "contradiction": 12.70504,
            "irrelevancy": 26.75886,
            "logical_agreement": 60.5361,
            "grammar_ref": 4.53522,
            "grammar_hyp": 4.39586,
            "nubia_score": 0.69807
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 63,
        "msttr-100": 0.744,
        "msttr-100_nopunct": 0.77929,
        "total_length": 1598,
        "mean_pred_length": 25.365079365079364,
        "std_pred_length": 9.193340563037296,
        "median_pred_length": 25.0,
        "min_pred_length": 6,
        "max_pred_length": 53,
        "distinct-1": 0.47058823529411764,
        "vocab_size-1": 752,
        "unique-1": 585,
        "entropy-1": 8.30829722800152,
        "distinct-2": 0.8905537459283388,
        "vocab_size-2": 1367,
        "unique-2": 1285,
        "entropy-2": 10.243541508188713,
        "cond_entropy-2": 1.7723291293723735,
        "distinct-3": 0.9592391304347826,
        "vocab_size-3": 1412,
        "unique-3": 1390,
        "entropy-3": 10.374868257826414,
        "cond_entropy-3": 0.14182289788520158,
        "total_length-nopunct": 1442,
        "mean_pred_length-nopunct": 22.88888888888889,
        "std_pred_length-nopunct": 8.338305395023031,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 48,
        "distinct-1-nopunct": 0.515256588072122,
        "vocab_size-1-nopunct": 743,
        "unique-1-nopunct": 582,
        "entropy-1-nopunct": 8.4950302425825,
        "distinct-2-nopunct": 0.9144307469180566,
        "vocab_size-2-nopunct": 1261,
        "unique-2-nopunct": 1191,
        "entropy-2-nopunct": 10.194626557010768,
        "cond_entropy-2-nopunct": 1.7638475340248185,
        "distinct-3-nopunct": 0.9870820668693009,
        "vocab_size-3-nopunct": 1299,
        "unique-3-nopunct": 1284,
        "entropy-3-nopunct": 10.334588150634874,
        "cond_entropy-3-nopunct": 0.14619729964487946,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 9.092690942458864,
        "bleu": 63.21504,
        "rouge1": {
            "precision": 0.81596,
            "recall": 0.75559,
            "fmeasure": 0.77033
        },
        "rouge2": {
            "precision": 0.67853,
            "recall": 0.63108,
            "fmeasure": 0.6421
        },
        "rougeL": {
            "precision": 0.78451,
            "recall": 0.73127,
            "fmeasure": 0.74413
        },
        "rougeLsum": {
            "precision": 0.78451,
            "recall": 0.73127,
            "fmeasure": 0.74413
        },
        "local_recall": {
            "1": 0.048216007714561235,
            "2": 0.18012422360248448,
            "3": 0.35106382978723405,
            "4": 0.5298507462686567,
            "5": 0.6509803921568628,
            "6": 0.7556675062972292,
            "7": 0.8377358490566038
        },
        "bertscore": {
            "precision": 0.94149,
            "recall": 0.93393,
            "f1": 0.93549
        },
        "bleurt": 0.06461,
        "meteor": 0.4362843685335805,
        "nubia": {
            "semantic_relation": 4.10622,
            "contradiction": 4.37107,
            "irrelevancy": 20.0869,
            "logical_agreement": 75.54203,
            "grammar_ref": 4.43738,
            "grammar_hyp": 4.88464,
            "nubia_score": 0.62264
        }
    },
    "web_nlg_ru_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 354,
        "msttr-100": 0.46052,
        "msttr-100_nopunct": 0.4582,
        "total_length": 19297,
        "mean_pred_length": 54.51129943502825,
        "std_pred_length": 14.404806832907878,
        "median_pred_length": 58.0,
        "min_pred_length": 11,
        "max_pred_length": 78,
        "distinct-1": 0.07441571228688397,
        "vocab_size-1": 1436,
        "unique-1": 533,
        "entropy-1": 5.812068894763501,
        "distinct-2": 0.19094124478699256,
        "vocab_size-2": 3617,
        "unique-2": 1653,
        "entropy-2": 9.935122814436376,
        "cond_entropy-2": 4.125660499022196,
        "distinct-3": 0.32702135671633764,
        "vocab_size-3": 6079,
        "unique-3": 3265,
        "entropy-3": 11.445482746774271,
        "cond_entropy-3": 1.536624093127084,
        "total_length-nopunct": 17891,
        "mean_pred_length-nopunct": 50.53954802259887,
        "std_pred_length-nopunct": 13.986065131938021,
        "median_pred_length-nopunct": 53.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.07981666759823375,
        "vocab_size-1-nopunct": 1428,
        "unique-1-nopunct": 532,
        "entropy-1-nopunct": 5.722382184017361,
        "distinct-2-nopunct": 0.19279238182129213,
        "vocab_size-2-nopunct": 3381,
        "unique-2-nopunct": 1539,
        "entropy-2-nopunct": 9.856461470185135,
        "cond_entropy-2-nopunct": 4.193283674821242,
        "distinct-3-nopunct": 0.3289879532095676,
        "vocab_size-3-nopunct": 5653,
        "unique-3-nopunct": 3072,
        "entropy-3-nopunct": 11.336330349310812,
        "cond_entropy-3-nopunct": 1.5046111123456185,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.1209599160591437,
        "bleu": 1.59762,
        "rouge1": {
            "precision": 0.54877,
            "recall": 0.51043,
            "fmeasure": 0.5173
        },
        "rouge2": {
            "precision": 0.2772,
            "recall": 0.2601,
            "fmeasure": 0.26144
        },
        "rougeL": {
            "precision": 0.53093,
            "recall": 0.49465,
            "fmeasure": 0.50055
        },
        "rougeLsum": {
            "precision": 0.53093,
            "recall": 0.49465,
            "fmeasure": 0.50055
        },
        "local_recall": {
            "1": 0.0881082096562089,
            "2": 0.18434504792332268,
            "3": 0.258160237388724,
            "4": 0.1891891891891892,
            "5": 0.3181818181818182,
            "6": 0.0,
            "7": 0.2
        },
        "bertscore": {
            "precision": 0.86266,
            "recall": 0.87107,
            "f1": 0.86634
        },
        "bleurt": -0.48481,
        "meteor": 0.12005297675434067,
        "nubia": {
            "semantic_relation": 3.28534,
            "contradiction": 32.052,
            "irrelevancy": 18.02811,
            "logical_agreement": 49.91988,
            "grammar_ref": 2.54394,
            "grammar_hyp": 2.49848,
            "nubia_score": 0.13951
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 59,
        "msttr-100": 0.70125,
        "msttr-100_nopunct": 0.76,
        "total_length": 898,
        "mean_pred_length": 15.220338983050848,
        "std_pred_length": 4.758819810287568,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.4888641425389755,
        "vocab_size-1": 439,
        "unique-1": 358,
        "entropy-1": 7.637798406229314,
        "distinct-2": 0.8259833134684148,
        "vocab_size-2": 693,
        "unique-2": 630,
        "entropy-2": 9.22120076175614,
        "cond_entropy-2": 1.3208124572446707,
        "distinct-3": 0.9192307692307692,
        "vocab_size-3": 717,
        "unique-3": 679,
        "entropy-3": 9.410717177292808,
        "cond_entropy-3": 0.19384796375188101,
        "total_length-nopunct": 792,
        "mean_pred_length-nopunct": 13.423728813559322,
        "std_pred_length-nopunct": 4.2354572315579135,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.5429292929292929,
        "vocab_size-1-nopunct": 430,
        "unique-1-nopunct": 355,
        "entropy-1-nopunct": 7.815277007346524,
        "distinct-2-nopunct": 0.8212824010914052,
        "vocab_size-2-nopunct": 602,
        "unique-2-nopunct": 547,
        "entropy-2-nopunct": 9.006601074653396,
        "cond_entropy-2-nopunct": 1.2746624464955953,
        "distinct-3-nopunct": 0.9154302670623146,
        "vocab_size-3-nopunct": 617,
        "unique-3-nopunct": 582,
        "entropy-3-nopunct": 9.19096181540421,
        "cond_entropy-3-nopunct": 0.20851557104021887,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.169006586872292,
        "bleu": 47.45163,
        "rouge1": {
            "precision": 0.78437,
            "recall": 0.73334,
            "fmeasure": 0.75134
        },
        "rouge2": {
            "precision": 0.54762,
            "recall": 0.51773,
            "fmeasure": 0.52637
        },
        "rougeL": {
            "precision": 0.68962,
            "recall": 0.64661,
            "fmeasure": 0.66104
        },
        "rougeLsum": {
            "precision": 0.68962,
            "recall": 0.64661,
            "fmeasure": 0.66104
        },
        "local_recall": {
            "1": 0.22641509433962265,
            "2": 0.45112781954887216,
            "3": 0.7856025039123631
        },
        "bertscore": {
            "precision": 0.938,
            "recall": 0.92584,
            "f1": 0.93017
        },
        "bleurt": 0.37038,
        "meteor": 0.402632358848775,
        "nubia": {
            "semantic_relation": 4.28175,
            "contradiction": 5.26806,
            "irrelevancy": 26.874,
            "logical_agreement": 67.85794,
            "grammar_ref": 4.6237,
            "grammar_hyp": 4.58502,
            "nubia_score": 0.77148
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?request": {
        "predictions_file": "T5-base (Baseline)/cs_restaurants_test",
        "N": 149,
        "msttr-100": 0.15,
        "msttr-100_nopunct": 0.13,
        "total_length": 2831,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.005298481102084069,
        "vocab_size-1": 15,
        "unique-1": 0,
        "entropy-1": 3.7216117239698994,
        "distinct-2": 0.006711409395973154,
        "vocab_size-2": 18,
        "unique-2": 0,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.47755304355428224,
        "distinct-3": 0.006711409395973154,
        "vocab_size-3": 17,
        "unique-3": 0,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 2384,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.005453020134228188,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 3.5,
        "distinct-2-nopunct": 0.006711409395973154,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.44022392894185186,
        "distinct-3-nopunct": 0.006711409395973154,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 0.28808156627970205,
        "bleu": 0.32271,
        "rouge1": {
            "precision": 0.07958,
            "recall": 0.14152,
            "fmeasure": 0.09998
        },
        "rouge2": {
            "precision": 0.03201,
            "recall": 0.05856,
            "fmeasure": 0.04088
        },
        "rougeL": {
            "precision": 0.06951,
            "recall": 0.12792,
            "fmeasure": 0.08858
        },
        "rougeLsum": {
            "precision": 0.06951,
            "recall": 0.12792,
            "fmeasure": 0.08858
        },
        "local_recall": {
            "1": 0.0871313672922252
        },
        "bertscore": {
            "precision": 0.77103,
            "recall": 0.83398,
            "f1": 0.80118
        },
        "bleurt": -1.10539,
        "meteor": 0.0500369749526553,
        "nubia": {
            "semantic_relation": 1.05925,
            "contradiction": 50.96298,
            "irrelevancy": 38.41476,
            "logical_agreement": 10.62226,
            "grammar_ref": 6.81129,
            "grammar_hyp": 5.60226,
            "nubia_score": 0.0148
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-base (Baseline)/cs_restaurants_test",
        "N": 297,
        "msttr-100": 0.54196,
        "msttr-100_nopunct": 0.55262,
        "total_length": 4695,
        "mean_pred_length": 15.808080808080808,
        "std_pred_length": 6.109566546606187,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 33,
        "distinct-1": 0.0817891373801917,
        "vocab_size-1": 384,
        "unique-1": 146,
        "entropy-1": 6.1433081042159845,
        "distinct-2": 0.2385175079581628,
        "vocab_size-2": 1049,
        "unique-2": 521,
        "entropy-2": 8.853954734166972,
        "cond_entropy-2": 2.5788856400112383,
        "distinct-3": 0.3786881248475982,
        "vocab_size-3": 1553,
        "unique-3": 940,
        "entropy-3": 9.650424430596836,
        "cond_entropy-3": 0.7897477645275153,
        "total_length-nopunct": 4290,
        "mean_pred_length-nopunct": 14.444444444444445,
        "std_pred_length-nopunct": 5.757540315325966,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.08857808857808858,
        "vocab_size-1-nopunct": 380,
        "unique-1-nopunct": 145,
        "entropy-1-nopunct": 6.164809728590265,
        "distinct-2-nopunct": 0.23716503881793138,
        "vocab_size-2-nopunct": 947,
        "unique-2-nopunct": 454,
        "entropy-2-nopunct": 8.7440841798438,
        "cond_entropy-2-nopunct": 2.647869163698621,
        "distinct-3-nopunct": 0.38446969696969696,
        "vocab_size-3-nopunct": 1421,
        "unique-3-nopunct": 867,
        "entropy-3-nopunct": 9.52795743260644,
        "cond_entropy-3-nopunct": 0.7998010150534275,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 1.6508284651092722,
        "bleu": 3.72362,
        "rouge1": {
            "precision": 0.51091,
            "recall": 0.4678,
            "fmeasure": 0.47049
        },
        "rouge2": {
            "precision": 0.27004,
            "recall": 0.24882,
            "fmeasure": 0.24893
        },
        "rougeL": {
            "precision": 0.44299,
            "recall": 0.40688,
            "fmeasure": 0.40915
        },
        "rougeLsum": {
            "precision": 0.44299,
            "recall": 0.40688,
            "fmeasure": 0.40915
        },
        "local_recall": {
            "1": 0.3032281465360899
        },
        "bertscore": {
            "precision": 0.82569,
            "recall": 0.8418,
            "f1": 0.83325
        },
        "bleurt": -0.7225,
        "meteor": 0.13920970880004171,
        "nubia": {
            "semantic_relation": 3.1577,
            "contradiction": 27.8158,
            "irrelevancy": 23.68263,
            "logical_agreement": 48.50157,
            "grammar_ref": 6.65825,
            "grammar_hyp": 6.28158,
            "nubia_score": 0.39158
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 124,
        "msttr-100": 0.69833,
        "msttr-100_nopunct": 0.74923,
        "total_length": 3070,
        "mean_pred_length": 24.758064516129032,
        "std_pred_length": 6.71946014505622,
        "median_pred_length": 24.0,
        "min_pred_length": 10,
        "max_pred_length": 53,
        "distinct-1": 0.41433224755700326,
        "vocab_size-1": 1272,
        "unique-1": 971,
        "entropy-1": 8.588255989092195,
        "distinct-2": 0.8272233536999322,
        "vocab_size-2": 2437,
        "unique-2": 2179,
        "entropy-2": 11.018448200074328,
        "cond_entropy-2": 2.263578076378197,
        "distinct-3": 0.959603118355776,
        "vocab_size-3": 2708,
        "unique-3": 2609,
        "entropy-3": 11.376698245138321,
        "cond_entropy-3": 0.36204752764340475,
        "total_length-nopunct": 2665,
        "mean_pred_length-nopunct": 21.491935483870968,
        "std_pred_length-nopunct": 5.715705538451861,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.47354596622889306,
        "vocab_size-1-nopunct": 1262,
        "unique-1-nopunct": 968,
        "entropy-1-nopunct": 8.91517064259203,
        "distinct-2-nopunct": 0.8575364029909485,
        "vocab_size-2-nopunct": 2179,
        "unique-2-nopunct": 1987,
        "entropy-2-nopunct": 10.895075957522327,
        "cond_entropy-2-nopunct": 2.048664056036303,
        "distinct-3-nopunct": 0.9664873810508895,
        "vocab_size-3-nopunct": 2336,
        "unique-3-nopunct": 2265,
        "entropy-3-nopunct": 11.168093988636803,
        "cond_entropy-3-nopunct": 0.28453730939771776,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.68722853750012,
        "bleu": 38.32818,
        "rouge1": {
            "precision": 0.74018,
            "recall": 0.69711,
            "fmeasure": 0.70867
        },
        "rouge2": {
            "precision": 0.4679,
            "recall": 0.44883,
            "fmeasure": 0.45087
        },
        "rougeL": {
            "precision": 0.59296,
            "recall": 0.56429,
            "fmeasure": 0.57036
        },
        "rougeLsum": {
            "precision": 0.59296,
            "recall": 0.56429,
            "fmeasure": 0.57036
        },
        "local_recall": {
            "1": 0.22981366459627328,
            "2": 0.4040632054176072,
            "3": 0.7469635627530364
        },
        "bertscore": {
            "precision": 0.91882,
            "recall": 0.9101,
            "f1": 0.91229
        },
        "bleurt": 0.12856,
        "meteor": 0.3604518369739572,
        "nubia": {
            "semantic_relation": 3.93676,
            "contradiction": 11.30104,
            "irrelevancy": 35.45056,
            "logical_agreement": 53.2484,
            "grammar_ref": 4.3248,
            "grammar_hyp": 4.19526,
            "nubia_score": 0.6609
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_9": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 105,
        "msttr-100": 0.696,
        "msttr-100_nopunct": 0.74,
        "total_length": 1525,
        "mean_pred_length": 14.523809523809524,
        "std_pred_length": 8.111244679420853,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 53,
        "distinct-1": 0.40852459016393444,
        "vocab_size-1": 623,
        "unique-1": 487,
        "entropy-1": 7.822200273696915,
        "distinct-2": 0.752112676056338,
        "vocab_size-2": 1068,
        "unique-2": 937,
        "entropy-2": 9.73937294230192,
        "cond_entropy-2": 1.6232076291004436,
        "distinct-3": 0.864638783269962,
        "vocab_size-3": 1137,
        "unique-3": 1051,
        "entropy-3": 10.011632576731065,
        "cond_entropy-3": 0.2819257402101336,
        "total_length-nopunct": 1300,
        "mean_pred_length-nopunct": 12.380952380952381,
        "std_pred_length-nopunct": 6.689552554445238,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.4723076923076923,
        "vocab_size-1-nopunct": 614,
        "unique-1-nopunct": 484,
        "entropy-1-nopunct": 8.090433130059278,
        "distinct-2-nopunct": 0.7774058577405858,
        "vocab_size-2-nopunct": 929,
        "unique-2-nopunct": 831,
        "entropy-2-nopunct": 9.5597634883709,
        "cond_entropy-2-nopunct": 1.5786641138611766,
        "distinct-3-nopunct": 0.881651376146789,
        "vocab_size-3-nopunct": 961,
        "unique-3-nopunct": 902,
        "entropy-3-nopunct": 9.779981640427948,
        "cond_entropy-3-nopunct": 0.24076776322092447,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.869568995752759,
        "bleu": 41.34949,
        "rouge1": {
            "precision": 0.68009,
            "recall": 0.62672,
            "fmeasure": 0.63214
        },
        "rouge2": {
            "precision": 0.44657,
            "recall": 0.41937,
            "fmeasure": 0.41619
        },
        "rougeL": {
            "precision": 0.58493,
            "recall": 0.54336,
            "fmeasure": 0.54537
        },
        "rougeLsum": {
            "precision": 0.58493,
            "recall": 0.54336,
            "fmeasure": 0.54537
        },
        "local_recall": {
            "1": 0.21098265895953758,
            "2": 0.39628482972136225,
            "3": 0.7118279569892473
        },
        "bertscore": {
            "precision": 0.90638,
            "recall": 0.89868,
            "f1": 0.90082
        },
        "bleurt": 0.12478,
        "meteor": 0.3564630796091525,
        "nubia": {
            "semantic_relation": 3.60807,
            "contradiction": 17.83525,
            "irrelevancy": 30.16944,
            "logical_agreement": 51.99532,
            "grammar_ref": 4.94529,
            "grammar_hyp": 5.07697,
            "nubia_score": 0.60184
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-both_seen": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 1075,
        "msttr-100": 0.46264,
        "msttr-100_nopunct": 0.46097,
        "total_length": 47097,
        "mean_pred_length": 43.81116279069767,
        "std_pred_length": 19.016141638985662,
        "median_pred_length": 43.0,
        "min_pred_length": 6,
        "max_pred_length": 87,
        "distinct-1": 0.04870798564664416,
        "vocab_size-1": 2294,
        "unique-1": 721,
        "entropy-1": 5.958843568106519,
        "distinct-2": 0.1398461605319195,
        "vocab_size-2": 6436,
        "unique-2": 2713,
        "entropy-2": 10.326780471216171,
        "cond_entropy-2": 4.358068504168791,
        "distinct-3": 0.2610852782165662,
        "vocab_size-3": 11735,
        "unique-3": 5934,
        "entropy-3": 12.0879319063716,
        "cond_entropy-3": 1.806294077149412,
        "total_length-nopunct": 43467,
        "mean_pred_length-nopunct": 40.434418604651164,
        "std_pred_length-nopunct": 18.031345485315747,
        "median_pred_length-nopunct": 39.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 82,
        "distinct-1-nopunct": 0.05254560931281202,
        "vocab_size-1-nopunct": 2284,
        "unique-1-nopunct": 719,
        "entropy-1-nopunct": 5.8721449018105565,
        "distinct-2-nopunct": 0.14005000943574258,
        "vocab_size-2-nopunct": 5937,
        "unique-2-nopunct": 2506,
        "entropy-2-nopunct": 10.196623968397457,
        "cond_entropy-2-nopunct": 4.415085068783105,
        "distinct-3-nopunct": 0.2626521770699712,
        "vocab_size-3-nopunct": 10852,
        "unique-3-nopunct": 5600,
        "entropy-3-nopunct": 11.932794201060943,
        "cond_entropy-3-nopunct": 1.775960948925823,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.17004046238111,
        "bleu": 2.19273,
        "rouge1": {
            "precision": 0.42885,
            "recall": 0.40105,
            "fmeasure": 0.40597
        },
        "rouge2": {
            "precision": 0.21862,
            "recall": 0.20392,
            "fmeasure": 0.20637
        },
        "rougeL": {
            "precision": 0.4116,
            "recall": 0.38554,
            "fmeasure": 0.3896
        },
        "rougeLsum": {
            "precision": 0.4116,
            "recall": 0.38554,
            "fmeasure": 0.3896
        },
        "local_recall": {
            "1": 0.08906442495833031,
            "2": 0.18698390482855143,
            "3": 0.2652788388082506,
            "4": 0.19480519480519481,
            "5": 0.3783783783783784,
            "6": 0.15384615384615385,
            "7": 0.2222222222222222
        },
        "bertscore": {
            "precision": 0.86378,
            "recall": 0.87352,
            "f1": 0.86814
        },
        "bleurt": -0.46354,
        "meteor": 0.1278718364738606,
        "nubia": {
            "semantic_relation": 3.30923,
            "contradiction": 33.05608,
            "irrelevancy": 17.14811,
            "logical_agreement": 49.79581,
            "grammar_ref": 2.64396,
            "grammar_hyp": 2.64155,
            "nubia_score": 0.16134
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 64,
        "mean_pred_length": 16.0,
        "std_pred_length": 2.5495097567963922,
        "median_pred_length": 16.5,
        "min_pred_length": 12,
        "max_pred_length": 19,
        "distinct-1": 0.515625,
        "vocab_size-1": 33,
        "unique-1": 30,
        "entropy-1": 3.740532221599798,
        "distinct-2": 0.9833333333333333,
        "vocab_size-2": 59,
        "unique-2": 58,
        "entropy-2": 5.873557262275184,
        "cond_entropy-2": 2.150322892568734,
        "distinct-3": 1.0,
        "vocab_size-3": 56,
        "unique-3": 56,
        "entropy-3": 5.807354922057609,
        "cond_entropy-3": -0.06382138783662872,
        "total_length-nopunct": 58,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 2.179449471770337,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.5172413793103449,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 3.5027062051687308,
        "distinct-2-nopunct": 0.9629629629629629,
        "vocab_size-2-nopunct": 52,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.680813428089393,
        "cond_entropy-2-nopunct": 2.2635469310276624,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.643856189774728,
        "cond_entropy-3-nopunct": -0.031031312388743973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.3558702828385906,
        "bleu": 0.95689,
        "rouge1": {
            "precision": 0.16667,
            "recall": 0.16667,
            "fmeasure": 0.16667
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.125,
            "fmeasure": 0.125
        },
        "rougeL": {
            "precision": 0.16667,
            "recall": 0.16667,
            "fmeasure": 0.16667
        },
        "rougeLsum": {
            "precision": 0.16667,
            "recall": 0.16667,
            "fmeasure": 0.16667
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.07692307692307693,
            "3": 0.0
        },
        "bertscore": {
            "precision": 0.85886,
            "recall": 0.8712,
            "f1": 0.86461
        },
        "bleurt": -0.34657,
        "meteor": 0.0556291390728477,
        "nubia": {
            "semantic_relation": 3.2883,
            "contradiction": 48.6669,
            "irrelevancy": 11.86738,
            "logical_agreement": 39.46572,
            "grammar_ref": 3.0388,
            "grammar_hyp": 2.9459,
            "nubia_score": 0.17651
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 19,
        "msttr-100": 0.478,
        "msttr-100_nopunct": 0.48,
        "total_length": 536,
        "mean_pred_length": 28.210526315789473,
        "std_pred_length": 14.107030525568005,
        "median_pred_length": 25.0,
        "min_pred_length": 12,
        "max_pred_length": 63,
        "distinct-1": 0.27052238805970147,
        "vocab_size-1": 145,
        "unique-1": 90,
        "entropy-1": 5.022786306749597,
        "distinct-2": 0.5822050290135397,
        "vocab_size-2": 301,
        "unique-2": 205,
        "entropy-2": 7.88055545914389,
        "cond_entropy-2": 2.8340700960891265,
        "distinct-3": 0.7570281124497992,
        "vocab_size-3": 377,
        "unique-3": 308,
        "entropy-3": 8.362376920143719,
        "cond_entropy-3": 0.49627123049667454,
        "total_length-nopunct": 478,
        "mean_pred_length-nopunct": 25.157894736842106,
        "std_pred_length-nopunct": 13.171992447672874,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 60,
        "distinct-1-nopunct": 0.2928870292887029,
        "vocab_size-1-nopunct": 140,
        "unique-1-nopunct": 90,
        "entropy-1-nopunct": 4.8183327397928615,
        "distinct-2-nopunct": 0.5904139433551199,
        "vocab_size-2-nopunct": 271,
        "unique-2-nopunct": 192,
        "entropy-2-nopunct": 7.7033914549028,
        "cond_entropy-2-nopunct": 2.9540450604529536,
        "distinct-3-nopunct": 0.7659090909090909,
        "vocab_size-3-nopunct": 337,
        "unique-3-nopunct": 280,
        "entropy-3-nopunct": 8.197068961421708,
        "cond_entropy-3-nopunct": 0.5099237923948049,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.2341152156988806,
        "bleu": 2.67395,
        "rouge1": {
            "precision": 0.28546,
            "recall": 0.2802,
            "fmeasure": 0.28259
        },
        "rouge2": {
            "precision": 0.15088,
            "recall": 0.14444,
            "fmeasure": 0.14717
        },
        "rougeL": {
            "precision": 0.2482,
            "recall": 0.24169,
            "fmeasure": 0.24454
        },
        "rougeLsum": {
            "precision": 0.2482,
            "recall": 0.24169,
            "fmeasure": 0.24454
        },
        "local_recall": {
            "1": 0.07975460122699386,
            "2": 0.28125,
            "3": 0.22826086956521738
        },
        "bertscore": {
            "precision": 0.8588,
            "recall": 0.86122,
            "f1": 0.85934
        },
        "bleurt": -0.48989,
        "meteor": 0.17473939476873884,
        "nubia": {
            "semantic_relation": 3.0711,
            "contradiction": 38.67212,
            "irrelevancy": 14.75045,
            "logical_agreement": 46.57743,
            "grammar_ref": 2.97301,
            "grammar_hyp": 2.96952,
            "nubia_score": 0.17217
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 414,
        "msttr-100": 0.51449,
        "msttr-100_nopunct": 0.53808,
        "total_length": 8906,
        "mean_pred_length": 21.51207729468599,
        "std_pred_length": 7.831165227789758,
        "median_pred_length": 20.0,
        "min_pred_length": 7,
        "max_pred_length": 55,
        "distinct-1": 0.14585672580282955,
        "vocab_size-1": 1299,
        "unique-1": 539,
        "entropy-1": 7.832603338554388,
        "distinct-2": 0.40779557230334434,
        "vocab_size-2": 3463,
        "unique-2": 2141,
        "entropy-2": 10.853719455329633,
        "cond_entropy-2": 2.8420975161031405,
        "distinct-3": 0.6112899232483288,
        "vocab_size-3": 4938,
        "unique-3": 3670,
        "entropy-3": 11.82526564552086,
        "cond_entropy-3": 1.0326538083079062,
        "total_length-nopunct": 7828,
        "mean_pred_length-nopunct": 18.908212560386474,
        "std_pred_length-nopunct": 7.012499550456759,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.16492079713847727,
        "vocab_size-1-nopunct": 1291,
        "unique-1-nopunct": 538,
        "entropy-1-nopunct": 8.119266133703967,
        "distinct-2-nopunct": 0.41758834637172915,
        "vocab_size-2-nopunct": 3096,
        "unique-2-nopunct": 1958,
        "entropy-2-nopunct": 10.70806281224533,
        "cond_entropy-2-nopunct": 2.7434168200842346,
        "distinct-3-nopunct": 0.617,
        "vocab_size-3-nopunct": 4319,
        "unique-3-nopunct": 3256,
        "entropy-3-nopunct": 11.631823172501964,
        "cond_entropy-3-nopunct": 0.9769468609669837,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.358751339277963,
        "bleu": 37.52483,
        "rouge1": {
            "precision": 0.67734,
            "recall": 0.69843,
            "fmeasure": 0.68086
        },
        "rouge2": {
            "precision": 0.41952,
            "recall": 0.43421,
            "fmeasure": 0.42225
        },
        "rougeL": {
            "precision": 0.54821,
            "recall": 0.5664,
            "fmeasure": 0.55123
        },
        "rougeLsum": {
            "precision": 0.54821,
            "recall": 0.5664,
            "fmeasure": 0.55123
        },
        "local_recall": {
            "1": 0.21852799090650754,
            "2": 0.5444500251130086,
            "3": 0.784968152866242,
            "4": 0.6363636363636364,
            "5": 0.875
        },
        "bertscore": {
            "precision": 0.89551,
            "recall": 0.90249,
            "f1": 0.89766
        },
        "bleurt": -0.01361,
        "meteor": 0.34906860873192125,
        "nubia": {
            "semantic_relation": 4.08761,
            "contradiction": 24.06335,
            "irrelevancy": 9.40259,
            "logical_agreement": 66.53406,
            "grammar_ref": 4.63681,
            "grammar_hyp": 4.68745,
            "nubia_score": 0.68105
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-base (Baseline)/cs_restaurants_test",
        "N": 86,
        "msttr-100": 0.5475,
        "msttr-100_nopunct": 0.55842,
        "total_length": 2076,
        "mean_pred_length": 24.13953488372093,
        "std_pred_length": 6.854234458801725,
        "median_pred_length": 24.0,
        "min_pred_length": 10,
        "max_pred_length": 49,
        "distinct-1": 0.1416184971098266,
        "vocab_size-1": 294,
        "unique-1": 120,
        "entropy-1": 6.113566597442476,
        "distinct-2": 0.3688442211055276,
        "vocab_size-2": 734,
        "unique-2": 430,
        "entropy-2": 8.70435310108996,
        "cond_entropy-2": 2.5300028768654017,
        "distinct-3": 0.5199579831932774,
        "vocab_size-3": 990,
        "unique-3": 694,
        "entropy-3": 9.335363785717947,
        "cond_entropy-3": 0.6464323490208355,
        "total_length-nopunct": 1918,
        "mean_pred_length-nopunct": 22.302325581395348,
        "std_pred_length-nopunct": 6.473685136213683,
        "median_pred_length-nopunct": 22.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.15172054223149115,
        "vocab_size-1-nopunct": 291,
        "unique-1-nopunct": 120,
        "entropy-1-nopunct": 6.112962157399341,
        "distinct-2-nopunct": 0.3722707423580786,
        "vocab_size-2-nopunct": 682,
        "unique-2-nopunct": 398,
        "entropy-2-nopunct": 8.604437726999404,
        "cond_entropy-2-nopunct": 2.5868851336083107,
        "distinct-3-nopunct": 0.5303550973654066,
        "vocab_size-3-nopunct": 926,
        "unique-3-nopunct": 655,
        "entropy-3-nopunct": 9.252578729550834,
        "cond_entropy-3-nopunct": 0.6490089247151098,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 1.8188919625260793,
        "bleu": 4.86454,
        "rouge1": {
            "precision": 0.5646,
            "recall": 0.49537,
            "fmeasure": 0.51941
        },
        "rouge2": {
            "precision": 0.29456,
            "recall": 0.25967,
            "fmeasure": 0.27214
        },
        "rougeL": {
            "precision": 0.46497,
            "recall": 0.40867,
            "fmeasure": 0.4287
        },
        "rougeLsum": {
            "precision": 0.46497,
            "recall": 0.40867,
            "fmeasure": 0.4287
        },
        "local_recall": {
            "1": 0.314828897338403
        },
        "bertscore": {
            "precision": 0.82774,
            "recall": 0.85363,
            "f1": 0.84036
        },
        "bleurt": -0.60332,
        "meteor": 0.1395632875477767,
        "nubia": {
            "semantic_relation": 2.82453,
            "contradiction": 25.88369,
            "irrelevancy": 21.95625,
            "logical_agreement": 52.16006,
            "grammar_ref": 6.22337,
            "grammar_hyp": 5.70281,
            "nubia_score": 0.46593
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 4,
        "msttr-100": 0.42,
        "msttr-100_nopunct": 0.42,
        "total_length": 121,
        "mean_pred_length": 30.25,
        "std_pred_length": 6.94172168845741,
        "median_pred_length": 27.5,
        "min_pred_length": 24,
        "max_pred_length": 42,
        "distinct-1": 0.3884297520661157,
        "vocab_size-1": 47,
        "unique-1": 27,
        "entropy-1": 4.2231186793604385,
        "distinct-2": 0.7264957264957265,
        "vocab_size-2": 85,
        "unique-2": 57,
        "entropy-2": 6.297548052842767,
        "cond_entropy-2": 2.087209423500342,
        "distinct-3": 0.831858407079646,
        "vocab_size-3": 94,
        "unique-3": 75,
        "entropy-3": 6.483895776574493,
        "cond_entropy-3": 0.19777486237739278,
        "total_length-nopunct": 110,
        "mean_pred_length-nopunct": 27.5,
        "std_pred_length-nopunct": 6.103277807866851,
        "median_pred_length-nopunct": 24.5,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.4,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.012491976859426,
        "distinct-2-nopunct": 0.7075471698113207,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 6.102782129030263,
        "cond_entropy-2-nopunct": 2.1235060209914436,
        "distinct-3-nopunct": 0.8235294117647058,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 6.312083307636563,
        "cond_entropy-3-nopunct": 0.21420856392130563,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.9367951353494903,
        "bleu": 1.49132,
        "rouge1": {
            "precision": 0.55714,
            "recall": 0.52273,
            "fmeasure": 0.5366
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.15185,
            "fmeasure": 0.15764
        },
        "rougeL": {
            "precision": 0.45714,
            "recall": 0.42273,
            "fmeasure": 0.4366
        },
        "rougeLsum": {
            "precision": 0.45714,
            "recall": 0.42273,
            "fmeasure": 0.4366
        },
        "local_recall": {
            "1": 0.08823529411764706,
            "2": 0.15384615384615385,
            "3": 0.3076923076923077
        },
        "bertscore": {
            "precision": 0.86332,
            "recall": 0.86715,
            "f1": 0.8642
        },
        "bleurt": -0.43434,
        "meteor": 0.1135022269515387,
        "nubia": {
            "semantic_relation": 3.02609,
            "contradiction": 45.60229,
            "irrelevancy": 18.25932,
            "logical_agreement": 36.13839,
            "grammar_ref": 2.93748,
            "grammar_hyp": 3.13974,
            "nubia_score": 0.12125
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 339,
        "msttr-100": 0.43333,
        "msttr-100_nopunct": 0.4327,
        "total_length": 8170,
        "mean_pred_length": 24.100294985250738,
        "std_pred_length": 10.083514097285322,
        "median_pred_length": 22.0,
        "min_pred_length": 6,
        "max_pred_length": 67,
        "distinct-1": 0.13219094247246022,
        "vocab_size-1": 1080,
        "unique-1": 595,
        "entropy-1": 5.689608129823181,
        "distinct-2": 0.31809475162814455,
        "vocab_size-2": 2491,
        "unique-2": 1536,
        "entropy-2": 9.782197175845768,
        "cond_entropy-2": 4.044297345259557,
        "distinct-3": 0.4986652429257875,
        "vocab_size-3": 3736,
        "unique-3": 2621,
        "entropy-3": 11.016122142436416,
        "cond_entropy-3": 1.3067015262395099,
        "total_length-nopunct": 7479,
        "mean_pred_length-nopunct": 22.061946902654867,
        "std_pred_length-nopunct": 9.684049945565807,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.143602085840353,
        "vocab_size-1-nopunct": 1074,
        "unique-1-nopunct": 595,
        "entropy-1-nopunct": 5.579359696142188,
        "distinct-2-nopunct": 0.3072829131652661,
        "vocab_size-2-nopunct": 2194,
        "unique-2-nopunct": 1350,
        "entropy-2-nopunct": 9.54901499794105,
        "cond_entropy-2-nopunct": 4.162707733175404,
        "distinct-3-nopunct": 0.4869872077635642,
        "vocab_size-3-nopunct": 3312,
        "unique-3-nopunct": 2336,
        "entropy-3-nopunct": 10.79197107178077,
        "cond_entropy-3-nopunct": 1.3222082982557732,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.0030030656086593,
        "bleu": 2.62756,
        "rouge1": {
            "precision": 0.28327,
            "recall": 0.28863,
            "fmeasure": 0.28407
        },
        "rouge2": {
            "precision": 0.14565,
            "recall": 0.14258,
            "fmeasure": 0.14335
        },
        "rougeL": {
            "precision": 0.28278,
            "recall": 0.28827,
            "fmeasure": 0.28365
        },
        "rougeLsum": {
            "precision": 0.28278,
            "recall": 0.28827,
            "fmeasure": 0.28365
        },
        "local_recall": {
            "1": 0.0989628349178911,
            "2": 0.1840435176790571,
            "3": 0.20135363790186125,
            "4": 0.2222222222222222,
            "5": 0.4666666666666667,
            "6": 0.16666666666666666,
            "7": 0.25
        },
        "bertscore": {
            "precision": 0.86827,
            "recall": 0.87907,
            "f1": 0.87317
        },
        "bleurt": -0.39257,
        "meteor": 0.1410544229657147,
        "nubia": {
            "semantic_relation": 3.3224,
            "contradiction": 36.45089,
            "irrelevancy": 15.59216,
            "logical_agreement": 47.95695,
            "grammar_ref": 2.83259,
            "grammar_hyp": 2.90085,
            "nubia_score": 0.20046
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-base (Baseline)/cs_restaurants_test",
        "N": 9,
        "msttr-100": 0.55,
        "msttr-100_nopunct": 0.59,
        "total_length": 213,
        "mean_pred_length": 23.666666666666668,
        "std_pred_length": 3.0550504633038935,
        "median_pred_length": 22.0,
        "min_pred_length": 20,
        "max_pred_length": 28,
        "distinct-1": 0.4225352112676056,
        "vocab_size-1": 90,
        "unique-1": 58,
        "entropy-1": 5.476093718992747,
        "distinct-2": 0.7696078431372549,
        "vocab_size-2": 157,
        "unique-2": 127,
        "entropy-2": 7.120937628912586,
        "cond_entropy-2": 1.6046390966753272,
        "distinct-3": 0.8871794871794871,
        "vocab_size-3": 173,
        "unique-3": 156,
        "entropy-3": 7.355435875397011,
        "cond_entropy-3": 0.2355674870760151,
        "total_length-nopunct": 196,
        "mean_pred_length-nopunct": 21.77777777777778,
        "std_pred_length-nopunct": 3.083208205669246,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4489795918367347,
        "vocab_size-1-nopunct": 88,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.428200344371988,
        "distinct-2-nopunct": 0.786096256684492,
        "vocab_size-2-nopunct": 147,
        "unique-2-nopunct": 122,
        "entropy-2-nopunct": 7.028211473472161,
        "cond_entropy-2-nopunct": 1.6679940232874932,
        "distinct-3-nopunct": 0.8932584269662921,
        "vocab_size-3-nopunct": 159,
        "unique-3-nopunct": 144,
        "entropy-3-nopunct": 7.237730464805698,
        "cond_entropy-3-nopunct": 0.19661091601375374,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 1.7051625401715762,
        "bleu": 4.21193,
        "rouge1": {
            "precision": 0.56944,
            "recall": 0.47411,
            "fmeasure": 0.50929
        },
        "rouge2": {
            "precision": 0.30222,
            "recall": 0.26495,
            "fmeasure": 0.27851
        },
        "rougeL": {
            "precision": 0.46449,
            "recall": 0.38623,
            "fmeasure": 0.41545
        },
        "rougeLsum": {
            "precision": 0.46449,
            "recall": 0.38623,
            "fmeasure": 0.41545
        },
        "local_recall": {
            "1": 0.35555555555555557
        },
        "bertscore": {
            "precision": 0.83761,
            "recall": 0.86278,
            "f1": 0.8498
        },
        "bleurt": -0.61533,
        "meteor": 0.15534905566491608,
        "nubia": {
            "semantic_relation": 3.04028,
            "contradiction": 24.09513,
            "irrelevancy": 23.08212,
            "logical_agreement": 52.82276,
            "grammar_ref": 6.01604,
            "grammar_hyp": 5.66838,
            "nubia_score": 0.5124
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform": {
        "predictions_file": "T5-base (Baseline)/cs_restaurants_test",
        "N": 609,
        "msttr-100": 0.53696,
        "msttr-100_nopunct": 0.54976,
        "total_length": 9295,
        "mean_pred_length": 15.262725779967159,
        "std_pred_length": 6.483269345344055,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 49,
        "distinct-1": 0.06939214631522324,
        "vocab_size-1": 645,
        "unique-1": 248,
        "entropy-1": 6.29997536963014,
        "distinct-2": 0.20538798065853098,
        "vocab_size-2": 1784,
        "unique-2": 897,
        "entropy-2": 9.229414156576997,
        "cond_entropy-2": 2.8049532399767845,
        "distinct-3": 0.33440633898724775,
        "vocab_size-3": 2701,
        "unique-3": 1651,
        "entropy-3": 10.122018538459864,
        "cond_entropy-3": 0.9957322003594384,
        "total_length-nopunct": 8505,
        "mean_pred_length-nopunct": 13.96551724137931,
        "std_pred_length-nopunct": 6.139895628471259,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.07536743092298648,
        "vocab_size-1-nopunct": 641,
        "unique-1-nopunct": 247,
        "entropy-1-nopunct": 6.340469385354702,
        "distinct-2-nopunct": 0.19490881458966566,
        "vocab_size-2-nopunct": 1539,
        "unique-2-nopunct": 760,
        "entropy-2-nopunct": 9.020959041741396,
        "cond_entropy-2-nopunct": 2.9195297364289314,
        "distinct-3-nopunct": 0.3279813366268698,
        "vocab_size-3-nopunct": 2390,
        "unique-3-nopunct": 1458,
        "entropy-3-nopunct": 9.918527359265507,
        "cond_entropy-3-nopunct": 1.0379427773381789,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 1.913744796498855,
        "bleu": 5.04319,
        "rouge1": {
            "precision": 0.52657,
            "recall": 0.50172,
            "fmeasure": 0.49873
        },
        "rouge2": {
            "precision": 0.27974,
            "recall": 0.26941,
            "fmeasure": 0.26574
        },
        "rougeL": {
            "precision": 0.46505,
            "recall": 0.44284,
            "fmeasure": 0.44094
        },
        "rougeLsum": {
            "precision": 0.46505,
            "recall": 0.44284,
            "fmeasure": 0.44094
        },
        "local_recall": {
            "1": 0.3142197763181253
        },
        "bertscore": {
            "precision": 0.8321,
            "recall": 0.85217,
            "f1": 0.8417
        },
        "bleurt": -0.64132,
        "meteor": 0.1454828183285788,
        "nubia": {
            "semantic_relation": 3.1839,
            "contradiction": 28.88969,
            "irrelevancy": 22.98492,
            "logical_agreement": 48.12539,
            "grammar_ref": 6.96179,
            "grammar_hyp": 6.3904,
            "nubia_score": 0.43068
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?confirm": {
        "predictions_file": "T5-base (Baseline)/cs_restaurants_test",
        "N": 22,
        "msttr-100": 0.305,
        "msttr-100_nopunct": 0.285,
        "total_length": 290,
        "mean_pred_length": 13.181818181818182,
        "std_pred_length": 2.289032420366213,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.11379310344827587,
        "vocab_size-1": 33,
        "unique-1": 0,
        "entropy-1": 4.558927629105467,
        "distinct-2": 0.16417910447761194,
        "vocab_size-2": 44,
        "unique-2": 0,
        "entropy-2": 5.260635178666367,
        "cond_entropy-2": 0.6328795515384664,
        "distinct-3": 0.16666666666666666,
        "vocab_size-3": 41,
        "unique-3": 0,
        "entropy-3": 5.166733508788661,
        "cond_entropy-3": -0.08400014246198964,
        "total_length-nopunct": 257,
        "mean_pred_length-nopunct": 11.681818181818182,
        "std_pred_length-nopunct": 2.6864367010522194,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.12062256809338522,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 4.449502447058802,
        "distinct-2-nopunct": 0.16170212765957448,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 5.059290828982146,
        "cond_entropy-2-nopunct": 0.6904286956757981,
        "distinct-3-nopunct": 0.1643192488262911,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 4.950537847346412,
        "cond_entropy-3-nopunct": -0.0961015165104779,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 1.0820296372338931,
        "bleu": 5.70479,
        "rouge1": {
            "precision": 0.38831,
            "recall": 0.39458,
            "fmeasure": 0.38757
        },
        "rouge2": {
            "precision": 0.23621,
            "recall": 0.23194,
            "fmeasure": 0.23222
        },
        "rougeL": {
            "precision": 0.36234,
            "recall": 0.36843,
            "fmeasure": 0.36181
        },
        "rougeLsum": {
            "precision": 0.36234,
            "recall": 0.36843,
            "fmeasure": 0.36181
        },
        "local_recall": {
            "1": 0.22285714285714286
        },
        "bertscore": {
            "precision": 0.86844,
            "recall": 0.88282,
            "f1": 0.87552
        },
        "bleurt": -0.37176,
        "meteor": 0.12103963869479234,
        "nubia": {
            "semantic_relation": 2.35752,
            "contradiction": 31.44659,
            "irrelevancy": 27.48085,
            "logical_agreement": 41.07256,
            "grammar_ref": 6.09546,
            "grammar_hyp": 6.48315,
            "nubia_score": 0.28083
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 316,
        "msttr-100": 0.4313,
        "msttr-100_nopunct": 0.42659,
        "total_length": 14645,
        "mean_pred_length": 46.34493670886076,
        "std_pred_length": 15.793104758323699,
        "median_pred_length": 44.0,
        "min_pred_length": 13,
        "max_pred_length": 85,
        "distinct-1": 0.09245476271765107,
        "vocab_size-1": 1354,
        "unique-1": 583,
        "entropy-1": 5.789072590396393,
        "distinct-2": 0.24097983111173146,
        "vocab_size-2": 3453,
        "unique-2": 1814,
        "entropy-2": 9.974922769334022,
        "cond_entropy-2": 4.1795295649229525,
        "distinct-3": 0.4183258402911582,
        "vocab_size-3": 5862,
        "unique-3": 3636,
        "entropy-3": 11.541721025251011,
        "cond_entropy-3": 1.6048067716040497,
        "total_length-nopunct": 13525,
        "mean_pred_length-nopunct": 42.800632911392405,
        "std_pred_length-nopunct": 15.229721927178119,
        "median_pred_length-nopunct": 40.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 82,
        "distinct-1-nopunct": 0.09951940850277265,
        "vocab_size-1-nopunct": 1346,
        "unique-1-nopunct": 581,
        "entropy-1-nopunct": 5.685780166005529,
        "distinct-2-nopunct": 0.24218335983041867,
        "vocab_size-2-nopunct": 3199,
        "unique-2-nopunct": 1705,
        "entropy-2-nopunct": 9.840904532165682,
        "cond_entropy-2-nopunct": 4.232010323826927,
        "distinct-3-nopunct": 0.41751337935313737,
        "vocab_size-3-nopunct": 5383,
        "unique-3-nopunct": 3399,
        "entropy-3-nopunct": 11.38107080908994,
        "cond_entropy-3-nopunct": 1.5745349791624847,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.0103785403862906,
        "bleu": 1.57642,
        "rouge1": {
            "precision": 0.37653,
            "recall": 0.36959,
            "fmeasure": 0.36772
        },
        "rouge2": {
            "precision": 0.16204,
            "recall": 0.16134,
            "fmeasure": 0.1609
        },
        "rougeL": {
            "precision": 0.36369,
            "recall": 0.35815,
            "fmeasure": 0.35551
        },
        "rougeLsum": {
            "precision": 0.36369,
            "recall": 0.35815,
            "fmeasure": 0.35551
        },
        "local_recall": {
            "1": 0.09184629803186505,
            "2": 0.18427399903521466,
            "3": 0.24507042253521127,
            "4": 0.15789473684210525,
            "5": 0.3181818181818182,
            "6": 0.0,
            "7": 0.2
        },
        "bertscore": {
            "precision": 0.85939,
            "recall": 0.87186,
            "f1": 0.86502
        },
        "bleurt": -0.49122,
        "meteor": 0.12105308069672371,
        "nubia": {
            "semantic_relation": 3.31306,
            "contradiction": 32.06152,
            "irrelevancy": 17.11308,
            "logical_agreement": 50.8254,
            "grammar_ref": 2.6064,
            "grammar_hyp": 2.55272,
            "nubia_score": 0.1492
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_only_match": {
        "predictions_file": "T5-base (Baseline)/cs_restaurants_test",
        "N": 16,
        "msttr-100": 0.5075,
        "msttr-100_nopunct": 0.5175,
        "total_length": 448,
        "mean_pred_length": 28.0,
        "std_pred_length": 7.913595895672207,
        "median_pred_length": 27.5,
        "min_pred_length": 12,
        "max_pred_length": 47,
        "distinct-1": 0.23660714285714285,
        "vocab_size-1": 106,
        "unique-1": 51,
        "entropy-1": 5.514194292146258,
        "distinct-2": 0.48148148148148145,
        "vocab_size-2": 208,
        "unique-2": 122,
        "entropy-2": 7.2368163886396655,
        "cond_entropy-2": 1.693203496073466,
        "distinct-3": 0.6033653846153846,
        "vocab_size-3": 251,
        "unique-3": 163,
        "entropy-3": 7.667794908939,
        "cond_entropy-3": 0.4731281604777099,
        "total_length-nopunct": 407,
        "mean_pred_length-nopunct": 25.4375,
        "std_pred_length-nopunct": 7.390608483068224,
        "median_pred_length-nopunct": 25.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.25552825552825553,
        "vocab_size-1-nopunct": 104,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.485076645490541,
        "distinct-2-nopunct": 0.4859335038363171,
        "vocab_size-2-nopunct": 190,
        "unique-2-nopunct": 109,
        "entropy-2-nopunct": 7.126135503756165,
        "cond_entropy-2-nopunct": 1.7071149815668913,
        "distinct-3-nopunct": 0.616,
        "vocab_size-3-nopunct": 231,
        "unique-3-nopunct": 151,
        "entropy-3-nopunct": 7.576981545792695,
        "cond_entropy-3-nopunct": 0.4616128604632101,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 1.5795136090575859,
        "bleu": 6.49501,
        "rouge1": {
            "precision": 0.49055,
            "recall": 0.50348,
            "fmeasure": 0.48788
        },
        "rouge2": {
            "precision": 0.25291,
            "recall": 0.26831,
            "fmeasure": 0.25439
        },
        "rougeL": {
            "precision": 0.39284,
            "recall": 0.40595,
            "fmeasure": 0.39074
        },
        "rougeLsum": {
            "precision": 0.39284,
            "recall": 0.40595,
            "fmeasure": 0.39074
        },
        "local_recall": {
            "1": 0.3603238866396761
        },
        "bertscore": {
            "precision": 0.82973,
            "recall": 0.86398,
            "f1": 0.84637
        },
        "bleurt": -0.5451,
        "meteor": 0.16462734561126743,
        "nubia": {
            "semantic_relation": 2.81163,
            "contradiction": 33.37765,
            "irrelevancy": 26.67892,
            "logical_agreement": 39.94343,
            "grammar_ref": 5.92126,
            "grammar_hyp": 5.94621,
            "nubia_score": 0.38029
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_10": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 162,
        "msttr-100": 0.71478,
        "msttr-100_nopunct": 0.767,
        "total_length": 2367,
        "mean_pred_length": 14.61111111111111,
        "std_pred_length": 5.961036035563277,
        "median_pred_length": 13.5,
        "min_pred_length": 6,
        "max_pred_length": 37,
        "distinct-1": 0.3553020701309675,
        "vocab_size-1": 841,
        "unique-1": 618,
        "entropy-1": 8.095912642562233,
        "distinct-2": 0.7392290249433107,
        "vocab_size-2": 1630,
        "unique-2": 1389,
        "entropy-2": 10.333771895703226,
        "cond_entropy-2": 1.924088179682291,
        "distinct-3": 0.8874204601076848,
        "vocab_size-3": 1813,
        "unique-3": 1682,
        "entropy-3": 10.71094459295237,
        "cond_entropy-3": 0.3690199037571375,
        "total_length-nopunct": 2066,
        "mean_pred_length-nopunct": 12.753086419753087,
        "std_pred_length-nopunct": 5.1448904635007064,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.4022265246853824,
        "vocab_size-1-nopunct": 831,
        "unique-1-nopunct": 614,
        "entropy-1-nopunct": 8.39790168244168,
        "distinct-2-nopunct": 0.756827731092437,
        "vocab_size-2-nopunct": 1441,
        "unique-2-nopunct": 1251,
        "entropy-2-nopunct": 10.158708123892383,
        "cond_entropy-2-nopunct": 1.8572878713704721,
        "distinct-3-nopunct": 0.8972445464982779,
        "vocab_size-3-nopunct": 1563,
        "unique-3-nopunct": 1467,
        "entropy-3-nopunct": 10.501483052586103,
        "cond_entropy-3-nopunct": 0.36194690210554836,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.4546089524086145,
        "bleu": 42.23141,
        "rouge1": {
            "precision": 0.73681,
            "recall": 0.71621,
            "fmeasure": 0.71596
        },
        "rouge2": {
            "precision": 0.49149,
            "recall": 0.47351,
            "fmeasure": 0.4751
        },
        "rougeL": {
            "precision": 0.62224,
            "recall": 0.60535,
            "fmeasure": 0.60439
        },
        "rougeLsum": {
            "precision": 0.62224,
            "recall": 0.60535,
            "fmeasure": 0.60439
        },
        "local_recall": {
            "1": 0.18042813455657492,
            "2": 0.332579185520362,
            "3": 0.7616020343293071
        },
        "bertscore": {
            "precision": 0.92687,
            "recall": 0.92345,
            "f1": 0.92298
        },
        "bleurt": 0.29622,
        "meteor": 0.3859966954108029,
        "nubia": {
            "semantic_relation": 4.16646,
            "contradiction": 11.0342,
            "irrelevancy": 27.25336,
            "logical_agreement": 61.71244,
            "grammar_ref": 4.55751,
            "grammar_hyp": 4.51568,
            "nubia_score": 0.74199
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_no_match": {
        "predictions_file": "T5-base (Baseline)/cs_restaurants_test",
        "N": 34,
        "msttr-100": 0.532,
        "msttr-100_nopunct": 0.514,
        "total_length": 570,
        "mean_pred_length": 16.764705882352942,
        "std_pred_length": 5.122377799934276,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.22456140350877193,
        "vocab_size-1": 128,
        "unique-1": 56,
        "entropy-1": 5.488759698599453,
        "distinct-2": 0.45149253731343286,
        "vocab_size-2": 242,
        "unique-2": 127,
        "entropy-2": 7.500440538501824,
        "cond_entropy-2": 1.9162863173395903,
        "distinct-3": 0.5597609561752988,
        "vocab_size-3": 281,
        "unique-3": 169,
        "entropy-3": 7.835452445624384,
        "cond_entropy-3": 0.31520890091283144,
        "total_length-nopunct": 526,
        "mean_pred_length-nopunct": 15.470588235294118,
        "std_pred_length-nopunct": 4.942226779128228,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.23954372623574144,
        "vocab_size-1-nopunct": 126,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.465656643463226,
        "distinct-2-nopunct": 0.45528455284552843,
        "vocab_size-2-nopunct": 224,
        "unique-2-nopunct": 118,
        "entropy-2-nopunct": 7.395238841391122,
        "cond_entropy-2-nopunct": 1.9526271623952682,
        "distinct-3-nopunct": 0.5502183406113537,
        "vocab_size-3-nopunct": 252,
        "unique-3-nopunct": 151,
        "entropy-3-nopunct": 7.666063643181615,
        "cond_entropy-3-nopunct": 0.2998392440332606,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 1.0720585963387368,
        "bleu": 1.30598,
        "rouge1": {
            "precision": 0.49797,
            "recall": 0.46941,
            "fmeasure": 0.47121
        },
        "rouge2": {
            "precision": 0.29587,
            "recall": 0.28121,
            "fmeasure": 0.28144
        },
        "rougeL": {
            "precision": 0.41839,
            "recall": 0.38996,
            "fmeasure": 0.39355
        },
        "rougeLsum": {
            "precision": 0.41839,
            "recall": 0.38996,
            "fmeasure": 0.39355
        },
        "local_recall": {
            "1": 0.2298507462686567
        },
        "bertscore": {
            "precision": 0.82826,
            "recall": 0.84933,
            "f1": 0.83849
        },
        "bleurt": -0.73569,
        "meteor": 0.11192361593270324,
        "nubia": {
            "semantic_relation": 2.80878,
            "contradiction": 31.26432,
            "irrelevancy": 19.10219,
            "logical_agreement": 49.63348,
            "grammar_ref": 6.46033,
            "grammar_hyp": 5.9202,
            "nubia_score": 0.35946
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_26": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.645,
        "msttr-100_nopunct": 0.675,
        "total_length": 251,
        "mean_pred_length": 20.916666666666668,
        "std_pred_length": 13.009344931838633,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 53,
        "distinct-1": 0.49800796812749004,
        "vocab_size-1": 125,
        "unique-1": 91,
        "entropy-1": 6.2809544221065865,
        "distinct-2": 0.7949790794979079,
        "vocab_size-2": 190,
        "unique-2": 161,
        "entropy-2": 7.3891355840318464,
        "cond_entropy-2": 1.0130661810610933,
        "distinct-3": 0.8810572687224669,
        "vocab_size-3": 200,
        "unique-3": 181,
        "entropy-3": 7.55558031546567,
        "cond_entropy-3": 0.17587545692898224,
        "total_length-nopunct": 208,
        "mean_pred_length-nopunct": 17.333333333333332,
        "std_pred_length-nopunct": 10.426994879744703,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.5721153846153846,
        "vocab_size-1-nopunct": 119,
        "unique-1-nopunct": 91,
        "entropy-1-nopunct": 6.283443327437981,
        "distinct-2-nopunct": 0.8316326530612245,
        "vocab_size-2-nopunct": 163,
        "unique-2-nopunct": 145,
        "entropy-2-nopunct": 7.178235991963998,
        "cond_entropy-2-nopunct": 0.9152210149772251,
        "distinct-3-nopunct": 0.907608695652174,
        "vocab_size-3-nopunct": 167,
        "unique-3-nopunct": 155,
        "entropy-3-nopunct": 7.312937567458312,
        "cond_entropy-3-nopunct": 0.13599334846066943,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.508630420093026,
        "bleu": 68.06362,
        "rouge1": {
            "precision": 0.79415,
            "recall": 0.78844,
            "fmeasure": 0.78714
        },
        "rouge2": {
            "precision": 0.67456,
            "recall": 0.67355,
            "fmeasure": 0.6702
        },
        "rougeL": {
            "precision": 0.76024,
            "recall": 0.76237,
            "fmeasure": 0.75641
        },
        "rougeLsum": {
            "precision": 0.76024,
            "recall": 0.76237,
            "fmeasure": 0.75641
        },
        "local_recall": {
            "1": 0.1891891891891892,
            "2": 0.5,
            "3": 0.8992805755395683
        },
        "bertscore": {
            "precision": 0.95383,
            "recall": 0.95097,
            "f1": 0.9517
        },
        "bleurt": 0.49753,
        "meteor": 0.5132615909981011,
        "nubia": {
            "semantic_relation": 4.02767,
            "contradiction": 12.13333,
            "irrelevancy": 20.98495,
            "logical_agreement": 66.88172,
            "grammar_ref": 4.07585,
            "grammar_hyp": 3.95756,
            "nubia_score": 0.72799
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 128,
        "msttr-100": 0.67389,
        "msttr-100_nopunct": 0.72613,
        "total_length": 3661,
        "mean_pred_length": 28.6015625,
        "std_pred_length": 10.461491770230179,
        "median_pred_length": 26.0,
        "min_pred_length": 10,
        "max_pred_length": 53,
        "distinct-1": 0.3802239825184376,
        "vocab_size-1": 1392,
        "unique-1": 1086,
        "entropy-1": 8.427951451046829,
        "distinct-2": 0.7339371638833853,
        "vocab_size-2": 2593,
        "unique-2": 2343,
        "entropy-2": 10.767785109995357,
        "cond_entropy-2": 2.2073767162232985,
        "distinct-3": 0.849632892804699,
        "vocab_size-3": 2893,
        "unique-3": 2760,
        "entropy-3": 11.180439308995131,
        "cond_entropy-3": 0.4080448481383483,
        "total_length-nopunct": 3112,
        "mean_pred_length-nopunct": 24.3125,
        "std_pred_length-nopunct": 8.76672508694096,
        "median_pred_length-nopunct": 22.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.4434447300771208,
        "vocab_size-1-nopunct": 1380,
        "unique-1-nopunct": 1081,
        "entropy-1-nopunct": 8.791233271085709,
        "distinct-2-nopunct": 0.7667560321715817,
        "vocab_size-2-nopunct": 2288,
        "unique-2-nopunct": 2095,
        "entropy-2-nopunct": 10.657913188027448,
        "cond_entropy-2-nopunct": 1.9215294551318285,
        "distinct-3-nopunct": 0.8714985994397759,
        "vocab_size-3-nopunct": 2489,
        "unique-3-nopunct": 2397,
        "entropy-3-nopunct": 11.00443801789406,
        "cond_entropy-3-nopunct": 0.35771367262574905,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.24124309421948,
        "bleu": 50.39507,
        "rouge1": {
            "precision": 0.77064,
            "recall": 0.72457,
            "fmeasure": 0.73745
        },
        "rouge2": {
            "precision": 0.53217,
            "recall": 0.50023,
            "fmeasure": 0.51011
        },
        "rougeL": {
            "precision": 0.64233,
            "recall": 0.60578,
            "fmeasure": 0.6156
        },
        "rougeLsum": {
            "precision": 0.64233,
            "recall": 0.60578,
            "fmeasure": 0.6156
        },
        "local_recall": {
            "1": 0.21541950113378686,
            "2": 0.44573643410852715,
            "3": 0.7773242630385487
        },
        "bertscore": {
            "precision": 0.92543,
            "recall": 0.91694,
            "f1": 0.91955
        },
        "bleurt": 0.13896,
        "meteor": 0.40005737031384503,
        "nubia": {
            "semantic_relation": 3.91936,
            "contradiction": 14.68175,
            "irrelevancy": 25.65264,
            "logical_agreement": 59.66561,
            "grammar_ref": 4.11595,
            "grammar_hyp": 4.10022,
            "nubia_score": 0.65254
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 1099,
        "msttr-100": 0.44105,
        "msttr-100_nopunct": 0.43706,
        "total_length": 47656,
        "mean_pred_length": 43.36305732484077,
        "std_pred_length": 19.05315919886076,
        "median_pred_length": 42.0,
        "min_pred_length": 6,
        "max_pred_length": 87,
        "distinct-1": 0.04851435286217895,
        "vocab_size-1": 2312,
        "unique-1": 723,
        "entropy-1": 5.96437711717016,
        "distinct-2": 0.13914126769336513,
        "vocab_size-2": 6478,
        "unique-2": 2717,
        "entropy-2": 10.332766597527486,
        "cond_entropy-2": 4.357806089661041,
        "distinct-3": 0.2599102468212416,
        "vocab_size-3": 11815,
        "unique-3": 5959,
        "entropy-3": 12.095012848749882,
        "cond_entropy-3": 1.8070566651052464,
        "total_length-nopunct": 43969,
        "mean_pred_length-nopunct": 40.00818926296633,
        "std_pred_length-nopunct": 18.075741119312514,
        "median_pred_length-nopunct": 38.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 82,
        "distinct-1-nopunct": 0.052355068343605725,
        "vocab_size-1-nopunct": 2302,
        "unique-1-nopunct": 722,
        "entropy-1-nopunct": 5.877020703633975,
        "distinct-2-nopunct": 0.13949148588756707,
        "vocab_size-2-nopunct": 5980,
        "unique-2-nopunct": 2518,
        "entropy-2-nopunct": 10.202602948515588,
        "cond_entropy-2-nopunct": 4.416762719192251,
        "distinct-3-nopunct": 0.26173661152474204,
        "vocab_size-3-nopunct": 10933,
        "unique-3-nopunct": 5633,
        "entropy-3-nopunct": 11.940067677870214,
        "cond_entropy-3-nopunct": 1.7776705339029482,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.1761818902757228,
        "bleu": 2.20233,
        "rouge1": {
            "precision": 0.42705,
            "recall": 0.39965,
            "fmeasure": 0.40455
        },
        "rouge2": {
            "precision": 0.21752,
            "recall": 0.20297,
            "fmeasure": 0.20544
        },
        "rougeL": {
            "precision": 0.40917,
            "recall": 0.38345,
            "fmeasure": 0.38752
        },
        "rougeLsum": {
            "precision": 0.40917,
            "recall": 0.38345,
            "fmeasure": 0.38752
        },
        "local_recall": {
            "1": 0.0888793473593817,
            "2": 0.1881461061337009,
            "3": 0.2654286250234478,
            "4": 0.19480519480519481,
            "5": 0.3783783783783784,
            "6": 0.15384615384615385,
            "7": 0.2222222222222222
        },
        "bertscore": {
            "precision": 0.86371,
            "recall": 0.87329,
            "f1": 0.86798
        },
        "bleurt": -0.46342,
        "meteor": 0.12838550797624734,
        "nubia": {
            "semantic_relation": 3.30438,
            "contradiction": 33.26465,
            "irrelevancy": 17.10161,
            "logical_agreement": 49.63374,
            "grammar_ref": 2.65247,
            "grammar_hyp": 2.65054,
            "nubia_score": 0.16154
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_11": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.60167,
        "msttr-100_nopunct": 0.648,
        "total_length": 674,
        "mean_pred_length": 18.72222222222222,
        "std_pred_length": 8.48728169776896,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 41,
        "distinct-1": 0.39020771513353114,
        "vocab_size-1": 263,
        "unique-1": 206,
        "entropy-1": 6.80868804871025,
        "distinct-2": 0.700626959247649,
        "vocab_size-2": 447,
        "unique-2": 381,
        "entropy-2": 8.420453955977285,
        "cond_entropy-2": 1.4660726507106656,
        "distinct-3": 0.8289036544850499,
        "vocab_size-3": 499,
        "unique-3": 454,
        "entropy-3": 8.77801424445225,
        "cond_entropy-3": 0.34953885359389847,
        "total_length-nopunct": 562,
        "mean_pred_length-nopunct": 15.61111111111111,
        "std_pred_length-nopunct": 6.852727671753043,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.45729537366548045,
        "vocab_size-1-nopunct": 257,
        "unique-1-nopunct": 205,
        "entropy-1-nopunct": 6.946302885371412,
        "distinct-2-nopunct": 0.7566539923954373,
        "vocab_size-2-nopunct": 398,
        "unique-2-nopunct": 348,
        "entropy-2-nopunct": 8.362541753293321,
        "cond_entropy-2-nopunct": 1.4791582289867802,
        "distinct-3-nopunct": 0.863265306122449,
        "vocab_size-3-nopunct": 423,
        "unique-3-nopunct": 394,
        "entropy-3-nopunct": 8.580409988316458,
        "cond_entropy-3-nopunct": 0.22138255770379026,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.112136407415633,
        "bleu": 44.57015,
        "rouge1": {
            "precision": 0.76334,
            "recall": 0.77685,
            "fmeasure": 0.75953
        },
        "rouge2": {
            "precision": 0.56299,
            "recall": 0.57578,
            "fmeasure": 0.56165
        },
        "rougeL": {
            "precision": 0.67955,
            "recall": 0.6964,
            "fmeasure": 0.67926
        },
        "rougeLsum": {
            "precision": 0.67955,
            "recall": 0.6964,
            "fmeasure": 0.67926
        },
        "local_recall": {
            "1": 0.2894736842105263,
            "2": 0.49056603773584906,
            "3": 0.7712609970674487
        },
        "bertscore": {
            "precision": 0.93207,
            "recall": 0.93441,
            "f1": 0.93155
        },
        "bleurt": 0.34947,
        "meteor": 0.42814595213719453,
        "nubia": {
            "semantic_relation": 4.07386,
            "contradiction": 6.86548,
            "irrelevancy": 31.71326,
            "logical_agreement": 61.42126,
            "grammar_ref": 3.9304,
            "grammar_hyp": 3.88491,
            "nubia_score": 0.73277
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 61,
        "msttr-100": 0.64563,
        "msttr-100_nopunct": 0.71769,
        "total_length": 1613,
        "mean_pred_length": 26.442622950819672,
        "std_pred_length": 8.277016549228023,
        "median_pred_length": 27.0,
        "min_pred_length": 8,
        "max_pred_length": 46,
        "distinct-1": 0.4513329200247985,
        "vocab_size-1": 728,
        "unique-1": 570,
        "entropy-1": 8.0035571638136,
        "distinct-2": 0.8279639175257731,
        "vocab_size-2": 1285,
        "unique-2": 1147,
        "entropy-2": 10.110123182499386,
        "cond_entropy-2": 1.9740956259828297,
        "distinct-3": 0.9483568075117371,
        "vocab_size-3": 1414,
        "unique-3": 1346,
        "entropy-3": 10.433563913503495,
        "cond_entropy-3": 0.3153273847869617,
        "total_length-nopunct": 1358,
        "mean_pred_length-nopunct": 22.262295081967213,
        "std_pred_length-nopunct": 7.346018525379699,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.5301914580265096,
        "vocab_size-1-nopunct": 720,
        "unique-1-nopunct": 567,
        "entropy-1-nopunct": 8.37579101895689,
        "distinct-2-nopunct": 0.8720123361603701,
        "vocab_size-2-nopunct": 1131,
        "unique-2-nopunct": 1031,
        "entropy-2-nopunct": 10.012585735700517,
        "cond_entropy-2-nopunct": 1.687093731825667,
        "distinct-3-nopunct": 0.9652103559870551,
        "vocab_size-3-nopunct": 1193,
        "unique-3-nopunct": 1154,
        "entropy-3-nopunct": 10.199044116088478,
        "cond_entropy-3-nopunct": 0.19025380817037404,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.004672309159565,
        "bleu": 40.89391,
        "rouge1": {
            "precision": 0.71577,
            "recall": 0.67928,
            "fmeasure": 0.68749
        },
        "rouge2": {
            "precision": 0.4434,
            "recall": 0.42722,
            "fmeasure": 0.42762
        },
        "rougeL": {
            "precision": 0.59024,
            "recall": 0.57236,
            "fmeasure": 0.5716
        },
        "rougeLsum": {
            "precision": 0.59024,
            "recall": 0.57236,
            "fmeasure": 0.5716
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3755656108597285,
            "3": 0.7390396659707724
        },
        "bertscore": {
            "precision": 0.91887,
            "recall": 0.91226,
            "f1": 0.91361
        },
        "bleurt": 0.14531,
        "meteor": 0.36493013079113096,
        "nubia": {
            "semantic_relation": 3.94304,
            "contradiction": 14.12943,
            "irrelevancy": 29.99245,
            "logical_agreement": 55.87812,
            "grammar_ref": 4.28842,
            "grammar_hyp": 4.11733,
            "nubia_score": 0.67093
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 3,
        "msttr-100": 0.45,
        "msttr-100_nopunct": 0.46,
        "total_length": 162,
        "mean_pred_length": 54.0,
        "std_pred_length": 23.762715894162152,
        "median_pred_length": 65.0,
        "min_pred_length": 21,
        "max_pred_length": 76,
        "distinct-1": 0.41358024691358025,
        "vocab_size-1": 67,
        "unique-1": 54,
        "entropy-1": 4.292243902416622,
        "distinct-2": 0.7861635220125787,
        "vocab_size-2": 125,
        "unique-2": 108,
        "entropy-2": 6.748263851442712,
        "cond_entropy-2": 2.4627918302270277,
        "distinct-3": 0.8974358974358975,
        "vocab_size-3": 140,
        "unique-3": 128,
        "entropy-3": 7.057775456014015,
        "cond_entropy-3": 0.320369664260524,
        "total_length-nopunct": 144,
        "mean_pred_length-nopunct": 48.0,
        "std_pred_length-nopunct": 20.992061991778385,
        "median_pred_length-nopunct": 57.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 68,
        "distinct-1-nopunct": 0.4305555555555556,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 4.06789279125369,
        "distinct-2-nopunct": 0.7730496453900709,
        "vocab_size-2-nopunct": 109,
        "unique-2-nopunct": 94,
        "entropy-2-nopunct": 6.51863734515314,
        "cond_entropy-2-nopunct": 2.473723330070446,
        "distinct-3-nopunct": 0.8840579710144928,
        "vocab_size-3-nopunct": 122,
        "unique-3-nopunct": 110,
        "entropy-3-nopunct": 6.851207246601885,
        "cond_entropy-3-nopunct": 0.34606803204102615,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.6331381254950851,
        "bleu": 0.83579,
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "local_recall": {
            "1": 0.08108108108108109,
            "2": 0.08333333333333333,
            "3": 0.10714285714285714
        },
        "bertscore": {
            "precision": 0.85161,
            "recall": 0.87143,
            "f1": 0.86118
        },
        "bleurt": -0.48196,
        "meteor": 0.10764702388741089,
        "nubia": {
            "semantic_relation": 3.17083,
            "contradiction": 29.75871,
            "irrelevancy": 13.43855,
            "logical_agreement": 56.80273,
            "grammar_ref": 2.52713,
            "grammar_hyp": 2.49429,
            "nubia_score": 0.12206
        }
    },
    "web_nlg_ru_test": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 1102,
        "msttr-100": 0.46272,
        "msttr-100_nopunct": 0.46102,
        "total_length": 47818,
        "mean_pred_length": 43.39201451905626,
        "std_pred_length": 19.07561250637675,
        "median_pred_length": 42.0,
        "min_pred_length": 6,
        "max_pred_length": 87,
        "distinct-1": 0.048580032623698186,
        "vocab_size-1": 2323,
        "unique-1": 733,
        "entropy-1": 5.965558412841345,
        "distinct-2": 0.1393740902474527,
        "vocab_size-2": 6511,
        "unique-2": 2742,
        "entropy-2": 10.336709544522435,
        "cond_entropy-2": 4.3605035523894,
        "distinct-3": 0.26033673872056823,
        "vocab_size-3": 11875,
        "unique-3": 6005,
        "entropy-3": 12.10059483907425,
        "cond_entropy-3": 1.8087075423557866,
        "total_length-nopunct": 44113,
        "mean_pred_length-nopunct": 40.02994555353902,
        "std_pred_length-nopunct": 18.089112240978746,
        "median_pred_length-nopunct": 38.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 82,
        "distinct-1-nopunct": 0.05243352299775576,
        "vocab_size-1-nopunct": 2313,
        "unique-1-nopunct": 732,
        "entropy-1-nopunct": 5.878363476488943,
        "distinct-2-nopunct": 0.13968519681011834,
        "vocab_size-2-nopunct": 6008,
        "unique-2-nopunct": 2538,
        "entropy-2-nopunct": 10.205944074161206,
        "cond_entropy-2-nopunct": 4.418717547367445,
        "distinct-3-nopunct": 0.26211553604237753,
        "vocab_size-3-nopunct": 10985,
        "unique-3-nopunct": 5671,
        "entropy-3-nopunct": 11.94525992312374,
        "cond_entropy-3-nopunct": 1.7795633191861528,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.1749905018933597,
        "bleu": 2.19688,
        "rouge1": {
            "precision": 0.42589,
            "recall": 0.39856,
            "fmeasure": 0.40345
        },
        "rouge2": {
            "precision": 0.21693,
            "recall": 0.20242,
            "fmeasure": 0.20488
        },
        "rougeL": {
            "precision": 0.40806,
            "recall": 0.3824,
            "fmeasure": 0.38646
        },
        "rougeLsum": {
            "precision": 0.40806,
            "recall": 0.3824,
            "fmeasure": 0.38646
        },
        "local_recall": {
            "1": 0.0888587538362715,
            "2": 0.18797302876014862,
            "3": 0.2646016047770106,
            "4": 0.19480519480519481,
            "5": 0.3783783783783784,
            "6": 0.15384615384615385,
            "7": 0.2222222222222222
        },
        "bertscore": {
            "precision": 0.86368,
            "recall": 0.87328,
            "f1": 0.86796
        },
        "bleurt": -0.46347,
        "meteor": 0.12832074609156255,
        "nubia": {
            "semantic_relation": 3.30402,
            "contradiction": 33.25511,
            "irrelevancy": 17.09164,
            "logical_agreement": 49.65325,
            "grammar_ref": 2.65213,
            "grammar_hyp": 2.65011,
            "nubia_score": 0.16143
        }
    },
    "web_nlg_ru_challenge_train_sample": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_challenge_train_sample",
        "N": 501
    },
    "web_nlg_ru_challenge_validation_sample": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_challenge_validation_sample",
        "N": 500
    },
    "totto_test_contrast_challenge_table_size-table_size_27": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 40,
        "msttr-100": 0.65167,
        "msttr-100_nopunct": 0.69,
        "total_length": 611,
        "mean_pred_length": 15.275,
        "std_pred_length": 6.584024225350329,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 41,
        "distinct-1": 0.44844517184942717,
        "vocab_size-1": 274,
        "unique-1": 217,
        "entropy-1": 6.886833759066267,
        "distinct-2": 0.7933450087565674,
        "vocab_size-2": 453,
        "unique-2": 404,
        "entropy-2": 8.574448209891962,
        "cond_entropy-2": 1.4806979335483685,
        "distinct-3": 0.8851224105461394,
        "vocab_size-3": 470,
        "unique-3": 443,
        "entropy-3": 8.74842500770371,
        "cond_entropy-3": 0.18114473380885987,
        "total_length-nopunct": 525,
        "mean_pred_length-nopunct": 13.125,
        "std_pred_length-nopunct": 5.793045399442335,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.5104761904761905,
        "vocab_size-1-nopunct": 268,
        "unique-1-nopunct": 216,
        "entropy-1-nopunct": 7.055227415423928,
        "distinct-2-nopunct": 0.7958762886597938,
        "vocab_size-2-nopunct": 386,
        "unique-2-nopunct": 347,
        "entropy-2-nopunct": 8.335849222103898,
        "cond_entropy-2-nopunct": 1.3789997066416482,
        "distinct-3-nopunct": 0.8853932584269663,
        "vocab_size-3-nopunct": 394,
        "unique-3-nopunct": 372,
        "entropy-3-nopunct": 8.492290030546021,
        "cond_entropy-3-nopunct": 0.17913703000614148,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.405437513726364,
        "bleu": 45.4819,
        "rouge1": {
            "precision": 0.78512,
            "recall": 0.728,
            "fmeasure": 0.74196
        },
        "rouge2": {
            "precision": 0.56849,
            "recall": 0.51989,
            "fmeasure": 0.53177
        },
        "rougeL": {
            "precision": 0.69721,
            "recall": 0.65061,
            "fmeasure": 0.6611
        },
        "rougeLsum": {
            "precision": 0.69721,
            "recall": 0.65061,
            "fmeasure": 0.6611
        },
        "local_recall": {
            "1": 0.26495726495726496,
            "2": 0.4,
            "3": 0.7399527186761229
        },
        "bertscore": {
            "precision": 0.9293,
            "recall": 0.92542,
            "f1": 0.92591
        },
        "bleurt": 0.30768,
        "meteor": 0.3827905586436541,
        "nubia": {
            "semantic_relation": 4.20096,
            "contradiction": 7.76201,
            "irrelevancy": 23.77112,
            "logical_agreement": 68.46687,
            "grammar_ref": 4.3823,
            "grammar_hyp": 4.4679,
            "nubia_score": 0.74072
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 382,
        "msttr-100": 0.50971,
        "msttr-100_nopunct": 0.52387,
        "total_length": 10554,
        "mean_pred_length": 27.6282722513089,
        "std_pred_length": 8.30334800633822,
        "median_pred_length": 26.0,
        "min_pred_length": 9,
        "max_pred_length": 57,
        "distinct-1": 0.11995451961341672,
        "vocab_size-1": 1266,
        "unique-1": 413,
        "entropy-1": 7.906089474379249,
        "distinct-2": 0.3564687377113645,
        "vocab_size-2": 3626,
        "unique-2": 2011,
        "entropy-2": 10.909735302804108,
        "cond_entropy-2": 2.860400229558969,
        "distinct-3": 0.5516853932584269,
        "vocab_size-3": 5401,
        "unique-3": 3733,
        "entropy-3": 11.897332507039199,
        "cond_entropy-3": 1.031482198196405,
        "total_length-nopunct": 9361,
        "mean_pred_length-nopunct": 24.505235602094242,
        "std_pred_length-nopunct": 7.559448428727184,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 50,
        "distinct-1-nopunct": 0.1342805255848734,
        "vocab_size-1-nopunct": 1257,
        "unique-1-nopunct": 413,
        "entropy-1-nopunct": 8.174633032854972,
        "distinct-2-nopunct": 0.37342688495378107,
        "vocab_size-2-nopunct": 3353,
        "unique-2-nopunct": 1942,
        "entropy-2-nopunct": 10.816502417288019,
        "cond_entropy-2-nopunct": 2.7553893480040434,
        "distinct-3-nopunct": 0.5662440386181226,
        "vocab_size-3-nopunct": 4868,
        "unique-3-nopunct": 3468,
        "entropy-3-nopunct": 11.744929367700657,
        "cond_entropy-3-nopunct": 0.9609572434235482,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.517851567353488,
        "bleu": 38.69923,
        "rouge1": {
            "precision": 0.67637,
            "recall": 0.69822,
            "fmeasure": 0.68076
        },
        "rouge2": {
            "precision": 0.40694,
            "recall": 0.42126,
            "fmeasure": 0.40984
        },
        "rougeL": {
            "precision": 0.51765,
            "recall": 0.53692,
            "fmeasure": 0.52167
        },
        "rougeLsum": {
            "precision": 0.51765,
            "recall": 0.53692,
            "fmeasure": 0.52167
        },
        "local_recall": {
            "1": 0.22158666998259138,
            "2": 0.5611979166666666,
            "3": 0.7993527508090615,
            "4": 0.3333333333333333,
            "5": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.89294,
            "recall": 0.89761,
            "f1": 0.89387
        },
        "bleurt": -0.031,
        "meteor": 0.3490175836879674,
        "nubia": {
            "semantic_relation": 4.07174,
            "contradiction": 21.80657,
            "irrelevancy": 11.51338,
            "logical_agreement": 66.68004,
            "grammar_ref": 4.39371,
            "grammar_hyp": 4.46772,
            "nubia_score": 0.67576
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 217,
        "msttr-100": 0.44202,
        "msttr-100_nopunct": 0.4387,
        "total_length": 10926,
        "mean_pred_length": 50.35023041474654,
        "std_pred_length": 14.312731995741837,
        "median_pred_length": 50.0,
        "min_pred_length": 21,
        "max_pred_length": 81,
        "distinct-1": 0.11706022332051987,
        "vocab_size-1": 1279,
        "unique-1": 600,
        "entropy-1": 5.855326490566764,
        "distinct-2": 0.28807545055560746,
        "vocab_size-2": 3085,
        "unique-2": 1722,
        "entropy-2": 9.970689288917487,
        "cond_entropy-2": 4.110199566315442,
        "distinct-3": 0.47274113610369806,
        "vocab_size-3": 4960,
        "unique-3": 3153,
        "entropy-3": 11.44238415220645,
        "cond_entropy-3": 1.499845053675082,
        "total_length-nopunct": 10089,
        "mean_pred_length-nopunct": 46.49308755760369,
        "std_pred_length-nopunct": 13.926111738846581,
        "median_pred_length-nopunct": 45.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 79,
        "distinct-1-nopunct": 0.12607790663098423,
        "vocab_size-1-nopunct": 1272,
        "unique-1-nopunct": 598,
        "entropy-1-nopunct": 5.76401919055621,
        "distinct-2-nopunct": 0.2923419773095624,
        "vocab_size-2-nopunct": 2886,
        "unique-2-nopunct": 1607,
        "entropy-2-nopunct": 9.865410392715829,
        "cond_entropy-2-nopunct": 4.175803913682186,
        "distinct-3-nopunct": 0.4747799067840497,
        "vocab_size-3-nopunct": 4584,
        "unique-3-nopunct": 2942,
        "entropy-3-nopunct": 11.307896205466026,
        "cond_entropy-3-nopunct": 1.4681849027789335,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.1383535283233195,
        "bleu": 2.04824,
        "rouge1": {
            "precision": 0.50625,
            "recall": 0.47991,
            "fmeasure": 0.48569
        },
        "rouge2": {
            "precision": 0.25262,
            "recall": 0.24043,
            "fmeasure": 0.24253
        },
        "rougeL": {
            "precision": 0.48139,
            "recall": 0.45614,
            "fmeasure": 0.46124
        },
        "rougeLsum": {
            "precision": 0.48139,
            "recall": 0.45614,
            "fmeasure": 0.46124
        },
        "local_recall": {
            "1": 0.08680981595092024,
            "2": 0.19035369774919614,
            "3": 0.28539985326485695,
            "4": 0.18181818181818182
        },
        "bertscore": {
            "precision": 0.86208,
            "recall": 0.87169,
            "f1": 0.86624
        },
        "bleurt": -0.4982,
        "meteor": 0.12921388836377737,
        "nubia": {
            "semantic_relation": 3.30263,
            "contradiction": 30.50257,
            "irrelevancy": 17.21508,
            "logical_agreement": 52.28235,
            "grammar_ref": 2.56565,
            "grammar_hyp": 2.5488,
            "nubia_score": 0.1375
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 986,
        "msttr-100": 0.44232,
        "msttr-100_nopunct": 0.44028,
        "total_length": 41880,
        "mean_pred_length": 42.47464503042596,
        "std_pred_length": 19.38360137218943,
        "median_pred_length": 40.0,
        "min_pred_length": 6,
        "max_pred_length": 87,
        "distinct-1": 0.052578796561604586,
        "vocab_size-1": 2202,
        "unique-1": 742,
        "entropy-1": 5.968777230114386,
        "distinct-2": 0.14877488140069448,
        "vocab_size-2": 6084,
        "unique-2": 2672,
        "entropy-2": 10.303504514629228,
        "cond_entropy-2": 4.3237684665502165,
        "distinct-3": 0.2733787711736995,
        "vocab_size-3": 10910,
        "unique-3": 5719,
        "entropy-3": 12.01961488864496,
        "cond_entropy-3": 1.759489935998431,
        "total_length-nopunct": 38614,
        "mean_pred_length-nopunct": 39.16227180527383,
        "std_pred_length-nopunct": 18.349824559661084,
        "median_pred_length-nopunct": 37.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 82,
        "distinct-1-nopunct": 0.05676697570829233,
        "vocab_size-1-nopunct": 2192,
        "unique-1-nopunct": 741,
        "entropy-1-nopunct": 5.880209015975455,
        "distinct-2-nopunct": 0.14935686191134262,
        "vocab_size-2-nopunct": 5620,
        "unique-2-nopunct": 2491,
        "entropy-2-nopunct": 10.169550889559865,
        "cond_entropy-2-nopunct": 4.3802314528832165,
        "distinct-3-nopunct": 0.2748758255553736,
        "vocab_size-3-nopunct": 10072,
        "unique-3-nopunct": 5383,
        "entropy-3-nopunct": 11.859275590915864,
        "cond_entropy-3-nopunct": 1.7296670833861405,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.2181044542677468,
        "bleu": 2.39831,
        "rouge1": {
            "precision": 0.46103,
            "recall": 0.43036,
            "fmeasure": 0.43631
        },
        "rouge2": {
            "precision": 0.23602,
            "recall": 0.22002,
            "fmeasure": 0.22295
        },
        "rougeL": {
            "precision": 0.44128,
            "recall": 0.41247,
            "fmeasure": 0.41749
        },
        "rougeLsum": {
            "precision": 0.44128,
            "recall": 0.41247,
            "fmeasure": 0.41749
        },
        "local_recall": {
            "1": 0.09145892930118513,
            "2": 0.1906839071506465,
            "3": 0.2756437315322921,
            "4": 0.19480519480519481,
            "5": 0.3783783783783784,
            "6": 0.15384615384615385,
            "7": 0.2222222222222222
        },
        "bertscore": {
            "precision": 0.86472,
            "recall": 0.87409,
            "f1": 0.86888
        },
        "bleurt": -0.45841,
        "meteor": 0.13354399600698885,
        "nubia": {
            "semantic_relation": 3.30238,
            "contradiction": 33.29573,
            "irrelevancy": 17.1785,
            "logical_agreement": 49.52576,
            "grammar_ref": 2.66553,
            "grammar_hyp": 2.68003,
            "nubia_score": 0.16307
        }
    },
    "totto_test_contrast_challenge_gender-male": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 300,
        "msttr-100": 0.72708,
        "msttr-100_nopunct": 0.77976,
        "total_length": 4808,
        "mean_pred_length": 16.026666666666667,
        "std_pred_length": 6.192411126173354,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 43,
        "distinct-1": 0.3847753743760399,
        "vocab_size-1": 1850,
        "unique-1": 1424,
        "entropy-1": 8.861936225629396,
        "distinct-2": 0.7834960070984915,
        "vocab_size-2": 3532,
        "unique-2": 3134,
        "entropy-2": 11.462717309347495,
        "cond_entropy-2": 2.278894039170215,
        "distinct-3": 0.9336977186311787,
        "vocab_size-3": 3929,
        "unique-3": 3748,
        "entropy-3": 11.880809669445462,
        "cond_entropy-3": 0.3981903543512461,
        "total_length-nopunct": 4204,
        "mean_pred_length-nopunct": 14.013333333333334,
        "std_pred_length-nopunct": 5.406769419492157,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.4379162702188392,
        "vocab_size-1-nopunct": 1841,
        "unique-1-nopunct": 1422,
        "entropy-1-nopunct": 9.245336678424234,
        "distinct-2-nopunct": 0.8109631147540983,
        "vocab_size-2-nopunct": 3166,
        "unique-2-nopunct": 2867,
        "entropy-2-nopunct": 11.323281388275289,
        "cond_entropy-2-nopunct": 2.1700598296043916,
        "distinct-3-nopunct": 0.9461709211986682,
        "vocab_size-3-nopunct": 3410,
        "unique-3-nopunct": 3278,
        "entropy-3-nopunct": 11.689596231163105,
        "cond_entropy-3-nopunct": 0.3873663756762687,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.557588728097912,
        "bleu": 46.07378,
        "rouge1": {
            "precision": 0.8038,
            "recall": 0.76993,
            "fmeasure": 0.77769
        },
        "rouge2": {
            "precision": 0.57064,
            "recall": 0.54706,
            "fmeasure": 0.5518
        },
        "rougeL": {
            "precision": 0.68653,
            "recall": 0.65992,
            "fmeasure": 0.66509
        },
        "rougeLsum": {
            "precision": 0.68653,
            "recall": 0.65992,
            "fmeasure": 0.66509
        },
        "local_recall": {
            "1": 0.1808634772462077,
            "2": 0.42765685019206146,
            "3": 0.8085365853658537
        },
        "bertscore": {
            "precision": 0.93996,
            "recall": 0.93788,
            "f1": 0.93775
        },
        "bleurt": 0.38375,
        "meteor": 0.41160990928239355,
        "nubia": {
            "semantic_relation": 4.4561,
            "contradiction": 4.71134,
            "irrelevancy": 22.64712,
            "logical_agreement": 72.64154,
            "grammar_ref": 4.83962,
            "grammar_hyp": 4.85169,
            "nubia_score": 0.80138
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 40,
        "msttr-100": 0.679,
        "msttr-100_nopunct": 0.74875,
        "total_length": 1035,
        "mean_pred_length": 25.875,
        "std_pred_length": 7.022063443176799,
        "median_pred_length": 25.0,
        "min_pred_length": 13,
        "max_pred_length": 46,
        "distinct-1": 0.47632850241545893,
        "vocab_size-1": 493,
        "unique-1": 382,
        "entropy-1": 7.713316659068921,
        "distinct-2": 0.8532663316582915,
        "vocab_size-2": 849,
        "unique-2": 783,
        "entropy-2": 9.544763182330627,
        "cond_entropy-2": 1.7100463342540535,
        "distinct-3": 0.9539267015706806,
        "vocab_size-3": 911,
        "unique-3": 880,
        "entropy-3": 9.793986042836112,
        "cond_entropy-3": 0.2338201970448869,
        "total_length-nopunct": 874,
        "mean_pred_length-nopunct": 21.85,
        "std_pred_length-nopunct": 5.646016294698413,
        "median_pred_length-nopunct": 21.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.5526315789473685,
        "vocab_size-1-nopunct": 483,
        "unique-1-nopunct": 378,
        "entropy-1-nopunct": 7.987053691063784,
        "distinct-2-nopunct": 0.8836930455635491,
        "vocab_size-2-nopunct": 737,
        "unique-2-nopunct": 693,
        "entropy-2-nopunct": 9.377182599757653,
        "cond_entropy-2-nopunct": 1.4327496857182183,
        "distinct-3-nopunct": 0.9659949622166247,
        "vocab_size-3-nopunct": 767,
        "unique-3-nopunct": 748,
        "entropy-3-nopunct": 9.555067863413978,
        "cond_entropy-3-nopunct": 0.1880475293331019,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.935602641883409,
        "bleu": 42.28145,
        "rouge1": {
            "precision": 0.76296,
            "recall": 0.69949,
            "fmeasure": 0.7195
        },
        "rouge2": {
            "precision": 0.51373,
            "recall": 0.4692,
            "fmeasure": 0.48348
        },
        "rougeL": {
            "precision": 0.61415,
            "recall": 0.56074,
            "fmeasure": 0.57779
        },
        "rougeLsum": {
            "precision": 0.61415,
            "recall": 0.56074,
            "fmeasure": 0.57779
        },
        "local_recall": {
            "1": 0.18493150684931506,
            "2": 0.4260355029585799,
            "3": 0.7686335403726708
        },
        "bertscore": {
            "precision": 0.92248,
            "recall": 0.91698,
            "f1": 0.91829
        },
        "bleurt": 0.17627,
        "meteor": 0.3669819201287735,
        "nubia": {
            "semantic_relation": 3.91731,
            "contradiction": 15.5775,
            "irrelevancy": 25.41811,
            "logical_agreement": 59.0044,
            "grammar_ref": 4.29053,
            "grammar_hyp": 4.13049,
            "nubia_score": 0.6692
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 143,
        "msttr-100": 0.44845,
        "msttr-100_nopunct": 0.44636,
        "total_length": 8458,
        "mean_pred_length": 59.14685314685315,
        "std_pred_length": 12.928505958582047,
        "median_pred_length": 60.0,
        "min_pred_length": 24,
        "max_pred_length": 87,
        "distinct-1": 0.1233152045400804,
        "vocab_size-1": 1043,
        "unique-1": 477,
        "entropy-1": 5.843059235102416,
        "distinct-2": 0.2946482260974143,
        "vocab_size-2": 2450,
        "unique-2": 1265,
        "entropy-2": 9.855362040979275,
        "cond_entropy-2": 4.0188788960075295,
        "distinct-3": 0.4700195790504161,
        "vocab_size-3": 3841,
        "unique-3": 2281,
        "entropy-3": 11.25089579436637,
        "cond_entropy-3": 1.4127607215344116,
        "total_length-nopunct": 7798,
        "mean_pred_length-nopunct": 54.53146853146853,
        "std_pred_length-nopunct": 12.511144232693008,
        "median_pred_length-nopunct": 56.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 80,
        "distinct-1-nopunct": 0.13298281610669402,
        "vocab_size-1-nopunct": 1037,
        "unique-1-nopunct": 477,
        "entropy-1-nopunct": 5.748436720085109,
        "distinct-2-nopunct": 0.2998040496407577,
        "vocab_size-2-nopunct": 2295,
        "unique-2-nopunct": 1195,
        "entropy-2-nopunct": 9.762988791425906,
        "cond_entropy-2-nopunct": 4.058144923917394,
        "distinct-3-nopunct": 0.470580404685836,
        "vocab_size-3-nopunct": 3535,
        "unique-3-nopunct": 2124,
        "entropy-3-nopunct": 11.112924995810081,
        "cond_entropy-3-nopunct": 1.3662436122776729,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.2808684954047644,
        "bleu": 2.66171,
        "rouge1": {
            "precision": 0.53959,
            "recall": 0.4555,
            "fmeasure": 0.47881
        },
        "rouge2": {
            "precision": 0.26561,
            "recall": 0.23697,
            "fmeasure": 0.24176
        },
        "rougeL": {
            "precision": 0.49467,
            "recall": 0.41408,
            "fmeasure": 0.43602
        },
        "rougeLsum": {
            "precision": 0.49467,
            "recall": 0.41408,
            "fmeasure": 0.43602
        },
        "local_recall": {
            "1": 0.0778767919411081,
            "2": 0.2038173142467621,
            "3": 0.2826086956521739
        },
        "bertscore": {
            "precision": 0.86371,
            "recall": 0.86907,
            "f1": 0.86614
        },
        "bleurt": -0.50051,
        "meteor": 0.12971065604141743,
        "nubia": {
            "semantic_relation": 3.28981,
            "contradiction": 32.09753,
            "irrelevancy": 17.92712,
            "logical_agreement": 49.97535,
            "grammar_ref": 2.5384,
            "grammar_hyp": 2.52112,
            "nubia_score": 0.13132
        }
    },
    "e2e_nlg_challenge_test_scramble_parent": {
        "predictions_file": "T5-base (Baseline)/e2e_nlg_test",
        "N": 500,
        "msttr-100": 0.51339,
        "msttr-100_nopunct": 0.52319,
        "total_length": 12741,
        "mean_pred_length": 25.482,
        "std_pred_length": 6.934383606348873,
        "median_pred_length": 26.0,
        "min_pred_length": 8,
        "max_pred_length": 51,
        "distinct-1": 0.020798995369280277,
        "vocab_size-1": 265,
        "unique-1": 69,
        "entropy-1": 6.075182686882918,
        "distinct-2": 0.08945347602320072,
        "vocab_size-2": 1095,
        "unique-2": 446,
        "entropy-2": 8.216571881757327,
        "cond_entropy-2": 2.0534283408176544,
        "distinct-3": 0.1824376117877523,
        "vocab_size-3": 2142,
        "unique-3": 1037,
        "entropy-3": 9.515600760144984,
        "cond_entropy-3": 1.309804381251406,
        "total_length-nopunct": 11671,
        "mean_pred_length-nopunct": 23.342,
        "std_pred_length-nopunct": 6.388195050246979,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.022448804729671836,
        "vocab_size-1-nopunct": 262,
        "unique-1-nopunct": 69,
        "entropy-1-nopunct": 6.119214327548701,
        "distinct-2-nopunct": 0.09596276071972071,
        "vocab_size-2-nopunct": 1072,
        "unique-2-nopunct": 464,
        "entropy-2-nopunct": 8.169642220464942,
        "cond_entropy-2-nopunct": 2.0918563214000634,
        "distinct-3-nopunct": 0.19220316746321806,
        "vocab_size-3-nopunct": 2051,
        "unique-3-nopunct": 1022,
        "entropy-3-nopunct": 9.503638960845263,
        "cond_entropy-3-nopunct": 1.3323730105529723,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 5.143061332945859,
        "bleu": 29.74679,
        "rouge1": {
            "precision": 0.72845,
            "recall": 0.70452,
            "fmeasure": 0.7052
        },
        "rouge2": {
            "precision": 0.42649,
            "recall": 0.41129,
            "fmeasure": 0.41197
        },
        "rougeL": {
            "precision": 0.50598,
            "recall": 0.48909,
            "fmeasure": 0.48961
        },
        "rougeLsum": {
            "precision": 0.50598,
            "recall": 0.48909,
            "fmeasure": 0.48961
        },
        "local_recall": {
            "1": 0.6987817353296755
        },
        "bertscore": {
            "precision": 0.91249,
            "recall": 0.90389,
            "f1": 0.90784
        },
        "bleurt": 0.16498,
        "meteor": 0.35917456708284,
        "nubia": {
            "semantic_relation": 4.25732,
            "contradiction": 3.11299,
            "irrelevancy": 27.15666,
            "logical_agreement": 69.73035,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.51849,
            "nubia_score": 0.76391
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 116,
        "msttr-100": 0.41949,
        "msttr-100_nopunct": 0.41685,
        "total_length": 5938,
        "mean_pred_length": 51.189655172413794,
        "std_pred_length": 13.972826950354111,
        "median_pred_length": 52.0,
        "min_pred_length": 21,
        "max_pred_length": 78,
        "distinct-1": 0.10643314247221286,
        "vocab_size-1": 632,
        "unique-1": 236,
        "entropy-1": 5.410713997174341,
        "distinct-2": 0.2617657162487118,
        "vocab_size-2": 1524,
        "unique-2": 694,
        "entropy-2": 9.30718210283249,
        "cond_entropy-2": 3.8966609723606127,
        "distinct-3": 0.4251664914125482,
        "vocab_size-3": 2426,
        "unique-3": 1303,
        "entropy-3": 10.582973846774577,
        "cond_entropy-3": 1.3114781525526804,
        "total_length-nopunct": 5499,
        "mean_pred_length-nopunct": 47.4051724137931,
        "std_pred_length-nopunct": 13.626152876423074,
        "median_pred_length-nopunct": 46.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 75,
        "distinct-1-nopunct": 0.11402073104200763,
        "vocab_size-1-nopunct": 627,
        "unique-1-nopunct": 236,
        "entropy-1-nopunct": 5.293000882538977,
        "distinct-2-nopunct": 0.2591491733234256,
        "vocab_size-2-nopunct": 1395,
        "unique-2-nopunct": 618,
        "entropy-2-nopunct": 9.171765562715922,
        "cond_entropy-2-nopunct": 3.951461452419508,
        "distinct-3-nopunct": 0.4199734194038352,
        "vocab_size-3-nopunct": 2212,
        "unique-3-nopunct": 1185,
        "entropy-3-nopunct": 10.439577019369722,
        "cond_entropy-3-nopunct": 1.2937796297241158,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.7829359233137869,
        "bleu": 0.39675,
        "rouge1": {
            "precision": 0.12716,
            "recall": 0.12823,
            "fmeasure": 0.12415
        },
        "rouge2": {
            "precision": 0.0546,
            "recall": 0.05275,
            "fmeasure": 0.05125
        },
        "rougeL": {
            "precision": 0.12572,
            "recall": 0.1268,
            "fmeasure": 0.12271
        },
        "rougeLsum": {
            "precision": 0.12572,
            "recall": 0.1268,
            "fmeasure": 0.12271
        },
        "local_recall": {
            "1": 0.07094594594594594,
            "2": 0.16745283018867924,
            "3": 0.18035426731078905
        },
        "bertscore": {
            "precision": 0.85477,
            "recall": 0.86638,
            "f1": 0.86012
        },
        "bleurt": -0.50643,
        "meteor": 0.09011676742055504,
        "nubia": {
            "semantic_relation": 3.31793,
            "contradiction": 32.90979,
            "irrelevancy": 16.35327,
            "logical_agreement": 50.73694,
            "grammar_ref": 2.53819,
            "grammar_hyp": 2.39584,
            "nubia_score": 0.14753
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_11": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.606,
        "msttr-100_nopunct": 0.7075,
        "total_length": 558,
        "mean_pred_length": 27.9,
        "std_pred_length": 11.978731151503483,
        "median_pred_length": 27.0,
        "min_pred_length": 13,
        "max_pred_length": 55,
        "distinct-1": 0.5017921146953405,
        "vocab_size-1": 280,
        "unique-1": 231,
        "entropy-1": 6.97792244965142,
        "distinct-2": 0.8066914498141264,
        "vocab_size-2": 434,
        "unique-2": 394,
        "entropy-2": 8.45916508045985,
        "cond_entropy-2": 1.4110072302287535,
        "distinct-3": 0.8957528957528957,
        "vocab_size-3": 464,
        "unique-3": 447,
        "entropy-3": 8.648731464851375,
        "cond_entropy-3": 0.20402788659197868,
        "total_length-nopunct": 437,
        "mean_pred_length-nopunct": 21.85,
        "std_pred_length-nopunct": 7.792785124716323,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.6292906178489702,
        "vocab_size-1-nopunct": 275,
        "unique-1-nopunct": 231,
        "entropy-1-nopunct": 7.423852783607106,
        "distinct-2-nopunct": 0.8633093525179856,
        "vocab_size-2-nopunct": 360,
        "unique-2-nopunct": 334,
        "entropy-2-nopunct": 8.283675448023267,
        "cond_entropy-2-nopunct": 0.908666240476472,
        "distinct-3-nopunct": 0.9193954659949622,
        "vocab_size-3-nopunct": 365,
        "unique-3-nopunct": 356,
        "entropy-3-nopunct": 8.342293219196772,
        "cond_entropy-3-nopunct": 0.07726906212666458,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.714958850590005,
        "bleu": 39.19397,
        "rouge1": {
            "precision": 0.70656,
            "recall": 0.61199,
            "fmeasure": 0.64346
        },
        "rouge2": {
            "precision": 0.44529,
            "recall": 0.38377,
            "fmeasure": 0.40165
        },
        "rougeL": {
            "precision": 0.56008,
            "recall": 0.5047,
            "fmeasure": 0.51469
        },
        "rougeLsum": {
            "precision": 0.56008,
            "recall": 0.5047,
            "fmeasure": 0.51469
        },
        "local_recall": {
            "1": 0.11494252873563218,
            "2": 0.42857142857142855,
            "3": 0.6686746987951807
        },
        "bertscore": {
            "precision": 0.91744,
            "recall": 0.90103,
            "f1": 0.90527
        },
        "bleurt": 0.0526,
        "meteor": 0.33823631556547695,
        "nubia": {
            "semantic_relation": 3.69352,
            "contradiction": 16.76126,
            "irrelevancy": 27.48634,
            "logical_agreement": 55.7524,
            "grammar_ref": 4.38156,
            "grammar_hyp": 4.3339,
            "nubia_score": 0.54969
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_12": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 158,
        "msttr-100": 0.71462,
        "msttr-100_nopunct": 0.77091,
        "total_length": 2603,
        "mean_pred_length": 16.474683544303797,
        "std_pred_length": 6.915126848455893,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 41,
        "distinct-1": 0.4156742220514791,
        "vocab_size-1": 1082,
        "unique-1": 849,
        "entropy-1": 8.431346242311136,
        "distinct-2": 0.8008179959100205,
        "vocab_size-2": 1958,
        "unique-2": 1748,
        "entropy-2": 10.670246929291391,
        "cond_entropy-2": 1.9552653298160798,
        "distinct-3": 0.9199825098382161,
        "vocab_size-3": 2104,
        "unique-3": 2003,
        "entropy-3": 10.956508054924086,
        "cond_entropy-3": 0.2912690771885767,
        "total_length-nopunct": 2247,
        "mean_pred_length-nopunct": 14.221518987341772,
        "std_pred_length-nopunct": 5.88994360476915,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.4766355140186916,
        "vocab_size-1-nopunct": 1071,
        "unique-1-nopunct": 846,
        "entropy-1-nopunct": 8.759029936152585,
        "distinct-2-nopunct": 0.8224030636668263,
        "vocab_size-2-nopunct": 1718,
        "unique-2-nopunct": 1557,
        "entropy-2-nopunct": 10.502234781055563,
        "cond_entropy-2-nopunct": 1.8560331099689154,
        "distinct-3-nopunct": 0.9249093733816676,
        "vocab_size-3-nopunct": 1786,
        "unique-3-nopunct": 1708,
        "entropy-3-nopunct": 10.725658079003598,
        "cond_entropy-3-nopunct": 0.2505250546901833,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.830680449907021,
        "bleu": 44.07846,
        "rouge1": {
            "precision": 0.7594,
            "recall": 0.72646,
            "fmeasure": 0.73029
        },
        "rouge2": {
            "precision": 0.51606,
            "recall": 0.49054,
            "fmeasure": 0.49466
        },
        "rougeL": {
            "precision": 0.64302,
            "recall": 0.61766,
            "fmeasure": 0.61938
        },
        "rougeLsum": {
            "precision": 0.64302,
            "recall": 0.61766,
            "fmeasure": 0.61938
        },
        "local_recall": {
            "1": 0.2332155477031802,
            "2": 0.466403162055336,
            "3": 0.7608015028177834
        },
        "bertscore": {
            "precision": 0.92889,
            "recall": 0.92329,
            "f1": 0.92407
        },
        "bleurt": 0.25188,
        "meteor": 0.3933984631583448,
        "nubia": {
            "semantic_relation": 4.20059,
            "contradiction": 5.61733,
            "irrelevancy": 30.69143,
            "logical_agreement": 63.69123,
            "grammar_ref": 4.68014,
            "grammar_hyp": 4.64516,
            "nubia_score": 0.73448
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_28": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 77,
        "msttr-100": 0.72917,
        "msttr-100_nopunct": 0.781,
        "total_length": 1204,
        "mean_pred_length": 15.636363636363637,
        "std_pred_length": 5.819602099374262,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.49667774086378735,
        "vocab_size-1": 598,
        "unique-1": 488,
        "entropy-1": 7.980978579610746,
        "distinct-2": 0.8828748890860693,
        "vocab_size-2": 995,
        "unique-2": 922,
        "entropy-2": 9.829626885862249,
        "cond_entropy-2": 1.571862367361387,
        "distinct-3": 0.9552380952380952,
        "vocab_size-3": 1003,
        "unique-3": 977,
        "entropy-3": 9.925060954934157,
        "cond_entropy-3": 0.08733977944848616,
        "total_length-nopunct": 1055,
        "mean_pred_length-nopunct": 13.7012987012987,
        "std_pred_length-nopunct": 5.357516712653536,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.557345971563981,
        "vocab_size-1-nopunct": 588,
        "unique-1-nopunct": 485,
        "entropy-1-nopunct": 8.203697687839487,
        "distinct-2-nopunct": 0.8946830265848671,
        "vocab_size-2-nopunct": 875,
        "unique-2-nopunct": 822,
        "entropy-2-nopunct": 9.64615115807664,
        "cond_entropy-2-nopunct": 1.535409040132409,
        "distinct-3-nopunct": 0.9589345172031076,
        "vocab_size-3-nopunct": 864,
        "unique-3-nopunct": 845,
        "entropy-3-nopunct": 9.712099555496303,
        "cond_entropy-3-nopunct": 0.0825639537547322,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.323697006194347,
        "bleu": 48.92168,
        "rouge1": {
            "precision": 0.78535,
            "recall": 0.72027,
            "fmeasure": 0.74028
        },
        "rouge2": {
            "precision": 0.55037,
            "recall": 0.49735,
            "fmeasure": 0.51454
        },
        "rougeL": {
            "precision": 0.69407,
            "recall": 0.63409,
            "fmeasure": 0.65311
        },
        "rougeLsum": {
            "precision": 0.69407,
            "recall": 0.63409,
            "fmeasure": 0.65311
        },
        "local_recall": {
            "1": 0.22568093385214008,
            "2": 0.4186046511627907,
            "3": 0.7867360208062418
        },
        "bertscore": {
            "precision": 0.9343,
            "recall": 0.92358,
            "f1": 0.92731
        },
        "bleurt": 0.26946,
        "meteor": 0.39577065655761756,
        "nubia": {
            "semantic_relation": 4.15056,
            "contradiction": 5.27034,
            "irrelevancy": 25.37494,
            "logical_agreement": 69.35472,
            "grammar_ref": 4.69344,
            "grammar_hyp": 4.8099,
            "nubia_score": 0.71097
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_29": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 7,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 94,
        "mean_pred_length": 13.428571428571429,
        "std_pred_length": 6.715805299167519,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.6808510638297872,
        "vocab_size-1": 64,
        "unique-1": 51,
        "entropy-1": 5.663371431349786,
        "distinct-2": 0.9885057471264368,
        "vocab_size-2": 86,
        "unique-2": 85,
        "entropy-2": 6.419954990101596,
        "cond_entropy-2": 0.5869113971689915,
        "distinct-3": 1.0,
        "vocab_size-3": 80,
        "unique-3": 80,
        "entropy-3": 6.321928094887356,
        "cond_entropy-3": -0.0960154009613662,
        "total_length-nopunct": 81,
        "mean_pred_length-nopunct": 11.571428571428571,
        "std_pred_length-nopunct": 5.972727131533392,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7530864197530864,
        "vocab_size-1-nopunct": 61,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.685287657098767,
        "distinct-2-nopunct": 0.9864864864864865,
        "vocab_size-2-nopunct": 73,
        "unique-2-nopunct": 72,
        "entropy-2-nopunct": 6.182426338601928,
        "cond_entropy-2-nopunct": 0.5590567412396471,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 67,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 6.066089190457767,
        "cond_entropy-3-nopunct": -0.11351342890252034,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5071968802821982,
        "bleu": 35.19496,
        "rouge1": {
            "precision": 0.81709,
            "recall": 0.70437,
            "fmeasure": 0.74017
        },
        "rouge2": {
            "precision": 0.59771,
            "recall": 0.51025,
            "fmeasure": 0.54011
        },
        "rougeL": {
            "precision": 0.71726,
            "recall": 0.62342,
            "fmeasure": 0.65371
        },
        "rougeLsum": {
            "precision": 0.71726,
            "recall": 0.62342,
            "fmeasure": 0.65371
        },
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.27586206896551724,
            "3": 0.711864406779661
        },
        "bertscore": {
            "precision": 0.90823,
            "recall": 0.89436,
            "f1": 0.90047
        },
        "bleurt": 0.08506,
        "meteor": 0.31103200524221336,
        "nubia": {
            "semantic_relation": 4.01987,
            "contradiction": 16.58084,
            "irrelevancy": 15.65074,
            "logical_agreement": 67.76842,
            "grammar_ref": 4.56703,
            "grammar_hyp": 4.82646,
            "nubia_score": 0.63504
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 56,
        "msttr-100": 0.44771,
        "msttr-100_nopunct": 0.44,
        "total_length": 3535,
        "mean_pred_length": 63.125,
        "std_pred_length": 8.78729297663068,
        "median_pred_length": 65.0,
        "min_pred_length": 42,
        "max_pred_length": 80,
        "distinct-1": 0.1669024045261669,
        "vocab_size-1": 590,
        "unique-1": 312,
        "entropy-1": 5.615325222952656,
        "distinct-2": 0.37683242311008913,
        "vocab_size-2": 1311,
        "unique-2": 785,
        "entropy-2": 9.233207729939679,
        "cond_entropy-2": 3.625390002941918,
        "distinct-3": 0.5568215016067777,
        "vocab_size-3": 1906,
        "unique-3": 1273,
        "entropy-3": 10.353773261455823,
        "cond_entropy-3": 1.124867497362132,
        "total_length-nopunct": 3288,
        "mean_pred_length-nopunct": 58.714285714285715,
        "std_pred_length-nopunct": 8.796741047753109,
        "median_pred_length-nopunct": 60.0,
        "min_pred_length-nopunct": 38,
        "max_pred_length-nopunct": 75,
        "distinct-1-nopunct": 0.17731143552311435,
        "vocab_size-1-nopunct": 583,
        "unique-1-nopunct": 310,
        "entropy-1-nopunct": 5.512098734270876,
        "distinct-2-nopunct": 0.38304455445544555,
        "vocab_size-2-nopunct": 1238,
        "unique-2-nopunct": 736,
        "entropy-2-nopunct": 9.161098444127393,
        "cond_entropy-2-nopunct": 3.6833230277390583,
        "distinct-3-nopunct": 0.5601385390428212,
        "vocab_size-3-nopunct": 1779,
        "unique-3-nopunct": 1191,
        "entropy-3-nopunct": 10.25789180557931,
        "cond_entropy-3-nopunct": 1.1023580876708732,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.3428118933951787,
        "bleu": 3.26501,
        "rouge1": {
            "precision": 0.75992,
            "recall": 0.617,
            "fmeasure": 0.64644
        },
        "rouge2": {
            "precision": 0.52535,
            "recall": 0.42789,
            "fmeasure": 0.4449
        },
        "rougeL": {
            "precision": 0.72063,
            "recall": 0.58135,
            "fmeasure": 0.60909
        },
        "rougeLsum": {
            "precision": 0.72063,
            "recall": 0.58135,
            "fmeasure": 0.60909
        },
        "local_recall": {
            "1": 0.08172635445362718,
            "2": 0.17647058823529413,
            "3": 0.30687830687830686
        },
        "bertscore": {
            "precision": 0.86548,
            "recall": 0.86808,
            "f1": 0.86637
        },
        "bleurt": -0.49047,
        "meteor": 0.13191266960002457,
        "nubia": {
            "semantic_relation": 3.25445,
            "contradiction": 32.71976,
            "irrelevancy": 20.97921,
            "logical_agreement": 46.30103,
            "grammar_ref": 2.50981,
            "grammar_hyp": 2.51269,
            "nubia_score": 0.15806
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 19,
        "msttr-100": 0.4425,
        "msttr-100_nopunct": 0.43455,
        "total_length": 1272,
        "mean_pred_length": 66.94736842105263,
        "std_pred_length": 5.576960917452465,
        "median_pred_length": 68.0,
        "min_pred_length": 54,
        "max_pred_length": 75,
        "distinct-1": 0.18081761006289307,
        "vocab_size-1": 230,
        "unique-1": 113,
        "entropy-1": 5.0338404998228405,
        "distinct-2": 0.4014365522745411,
        "vocab_size-2": 503,
        "unique-2": 284,
        "entropy-2": 8.247536507174669,
        "cond_entropy-2": 3.223790597104058,
        "distinct-3": 0.5640194489465153,
        "vocab_size-3": 696,
        "unique-3": 462,
        "entropy-3": 9.032331422262223,
        "cond_entropy-3": 0.7894776257431152,
        "total_length-nopunct": 1185,
        "mean_pred_length-nopunct": 62.36842105263158,
        "std_pred_length-nopunct": 5.2935961939705924,
        "median_pred_length-nopunct": 64.0,
        "min_pred_length-nopunct": 49,
        "max_pred_length-nopunct": 72,
        "distinct-1-nopunct": 0.189873417721519,
        "vocab_size-1-nopunct": 225,
        "unique-1-nopunct": 111,
        "entropy-1-nopunct": 4.899075905358003,
        "distinct-2-nopunct": 0.4090909090909091,
        "vocab_size-2-nopunct": 477,
        "unique-2-nopunct": 268,
        "entropy-2-nopunct": 8.188440838328473,
        "cond_entropy-2-nopunct": 3.3147881682911344,
        "distinct-3-nopunct": 0.5719267654751525,
        "vocab_size-3-nopunct": 656,
        "unique-3-nopunct": 439,
        "entropy-3-nopunct": 8.972786257647225,
        "cond_entropy-3-nopunct": 0.789696173793619,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.1867895350617252,
        "bleu": 1.50287,
        "rouge1": {
            "precision": 0.85833,
            "recall": 0.75681,
            "fmeasure": 0.78335
        },
        "rouge2": {
            "precision": 0.55702,
            "recall": 0.50353,
            "fmeasure": 0.5026
        },
        "rougeL": {
            "precision": 0.80219,
            "recall": 0.70819,
            "fmeasure": 0.73077
        },
        "rougeLsum": {
            "precision": 0.80219,
            "recall": 0.70819,
            "fmeasure": 0.73077
        },
        "local_recall": {
            "1": 0.1016949152542373,
            "2": 0.18796992481203006,
            "3": 0.2524752475247525
        },
        "bertscore": {
            "precision": 0.86672,
            "recall": 0.86809,
            "f1": 0.86698
        },
        "bleurt": -0.495,
        "meteor": 0.12509034071804914,
        "nubia": {
            "semantic_relation": 3.22246,
            "contradiction": 34.60032,
            "irrelevancy": 21.3979,
            "logical_agreement": 44.00178,
            "grammar_ref": 2.51721,
            "grammar_hyp": 2.4363,
            "nubia_score": 0.16354
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 12,
        "msttr-100": 0.44,
        "msttr-100_nopunct": 0.44429,
        "total_length": 812,
        "mean_pred_length": 67.66666666666667,
        "std_pred_length": 2.838231060987734,
        "median_pred_length": 67.0,
        "min_pred_length": 63,
        "max_pred_length": 73,
        "distinct-1": 0.2105911330049261,
        "vocab_size-1": 171,
        "unique-1": 89,
        "entropy-1": 4.85662355018526,
        "distinct-2": 0.4425,
        "vocab_size-2": 354,
        "unique-2": 200,
        "entropy-2": 7.9173831717209415,
        "cond_entropy-2": 3.0425867225455114,
        "distinct-3": 0.5989847715736041,
        "vocab_size-3": 472,
        "unique-3": 301,
        "entropy-3": 8.580262365018346,
        "cond_entropy-3": 0.6565227914625184,
        "total_length-nopunct": 749,
        "mean_pred_length-nopunct": 62.416666666666664,
        "std_pred_length-nopunct": 3.1479711279206843,
        "median_pred_length-nopunct": 62.0,
        "min_pred_length-nopunct": 58,
        "max_pred_length-nopunct": 68,
        "distinct-1-nopunct": 0.22429906542056074,
        "vocab_size-1-nopunct": 168,
        "unique-1-nopunct": 89,
        "entropy-1-nopunct": 4.713966794011963,
        "distinct-2-nopunct": 0.45454545454545453,
        "vocab_size-2-nopunct": 335,
        "unique-2-nopunct": 190,
        "entropy-2-nopunct": 7.84988548644606,
        "cond_entropy-2-nopunct": 3.1226687947352336,
        "distinct-3-nopunct": 0.6124137931034482,
        "vocab_size-3-nopunct": 444,
        "unique-3-nopunct": 287,
        "entropy-3-nopunct": 8.499989461210404,
        "cond_entropy-3-nopunct": 0.6423537720184778,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.170972716527334,
        "bleu": 0.74021,
        "rouge1": {
            "precision": 0.70278,
            "recall": 0.53079,
            "fmeasure": 0.59602
        },
        "rouge2": {
            "precision": 0.47222,
            "recall": 0.3463,
            "fmeasure": 0.38924
        },
        "rougeL": {
            "precision": 0.675,
            "recall": 0.5251,
            "fmeasure": 0.57941
        },
        "rougeLsum": {
            "precision": 0.675,
            "recall": 0.5251,
            "fmeasure": 0.57941
        },
        "local_recall": {
            "1": 0.10294117647058823,
            "2": 0.14367816091954022,
            "3": 0.24050632911392406
        },
        "bertscore": {
            "precision": 0.86195,
            "recall": 0.85852,
            "f1": 0.86
        },
        "bleurt": -0.49016,
        "meteor": 0.10169684520147637,
        "nubia": {
            "semantic_relation": 3.10161,
            "contradiction": 38.3432,
            "irrelevancy": 21.73859,
            "logical_agreement": 39.91821,
            "grammar_ref": 2.55511,
            "grammar_hyp": 2.48069,
            "nubia_score": 0.18535
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_47": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 5.0,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.78125,
        "vocab_size-1": 25,
        "unique-1": 18,
        "entropy-1": 4.5625,
        "distinct-2": 0.9666666666666667,
        "vocab_size-2": 29,
        "unique-2": 28,
        "entropy-2": 4.840223928941852,
        "cond_entropy-2": 0.24022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.02810710212234292,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.392747410448783,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.501629167387823,
        "cond_entropy-2-nopunct": 0.09285611591339743,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.03462179117476818,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9816040104196717,
        "bleu": 53.54769,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.8355,
            "fmeasure": 0.88645
        },
        "rouge2": {
            "precision": 0.76471,
            "recall": 0.675,
            "fmeasure": 0.71693
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.81169,
            "fmeasure": 0.86081
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.81169,
            "fmeasure": 0.86081
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8461538461538461
        },
        "bertscore": {
            "precision": 0.96303,
            "recall": 0.94979,
            "f1": 0.95636
        },
        "bleurt": 0.71317,
        "meteor": 0.4343509032313537,
        "nubia": {
            "semantic_relation": 4.93904,
            "contradiction": 0.25606,
            "irrelevancy": 0.48462,
            "logical_agreement": 99.25931,
            "grammar_ref": 5.14789,
            "grammar_hyp": 5.12738,
            "nubia_score": 0.99858
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation_parent": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72887,
        "msttr-100_nopunct": 0.76984,
        "total_length": 7160,
        "mean_pred_length": 19.944289693593316,
        "std_pred_length": 9.41268121583602,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 48,
        "distinct-1": 0.3741620111731844,
        "vocab_size-1": 2679,
        "unique-1": 1984,
        "entropy-1": 9.194120336853468,
        "distinct-2": 0.8406116747537127,
        "vocab_size-2": 5717,
        "unique-2": 5300,
        "entropy-2": 12.170006454560234,
        "cond_entropy-2": 2.710443523538477,
        "distinct-3": 0.9649177274138466,
        "vocab_size-3": 6216,
        "unique-3": 6107,
        "entropy-3": 12.534020277527619,
        "cond_entropy-3": 0.3791397457703247,
        "total_length-nopunct": 6345,
        "mean_pred_length-nopunct": 17.67409470752089,
        "std_pred_length-nopunct": 8.372735478286602,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.42048857368006304,
        "vocab_size-1-nopunct": 2668,
        "unique-1-nopunct": 1983,
        "entropy-1-nopunct": 9.54860391112204,
        "distinct-2-nopunct": 0.8591713999331774,
        "vocab_size-2-nopunct": 5143,
        "unique-2-nopunct": 4793,
        "entropy-2-nopunct": 12.065182536129276,
        "cond_entropy-2-nopunct": 2.6572962540486684,
        "distinct-3-nopunct": 0.9781411053847521,
        "vocab_size-3-nopunct": 5504,
        "unique-3-nopunct": 5417,
        "entropy-3-nopunct": 12.405641990946366,
        "cond_entropy-3-nopunct": 0.3650903204318789,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 13.27357163033192,
        "bleu": 85.75591,
        "rouge1": {
            "precision": 0.89371,
            "recall": 0.86896,
            "fmeasure": 0.87162
        },
        "rouge2": {
            "precision": 0.79569,
            "recall": 0.77545,
            "fmeasure": 0.7738
        },
        "rougeL": {
            "precision": 0.87917,
            "recall": 0.85515,
            "fmeasure": 0.85744
        },
        "rougeLsum": {
            "precision": 0.87917,
            "recall": 0.85515,
            "fmeasure": 0.85744
        },
        "local_recall": {
            "1": 0.030871003307607496,
            "2": 0.15498652291105122,
            "3": 0.3674698795180723,
            "4": 0.5565749235474006,
            "5": 0.6874051593323217,
            "6": 0.7633802816901408,
            "7": 0.825136612021858,
            "8": 0.864897466827503,
            "9": 0.8952380952380953,
            "10": 0.9441860465116279
        },
        "bertscore": {
            "precision": 0.96941,
            "recall": 0.96601,
            "f1": 0.96505
        },
        "bleurt": 0.23178,
        "meteor": 0.5255935126956474,
        "nubia": {
            "semantic_relation": 4.24493,
            "contradiction": 3.00277,
            "irrelevancy": 30.91127,
            "logical_agreement": 66.08596,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.82083,
            "nubia_score": 0.65288
        }
    },
    "wiki_auto_asset_turk_test_turk": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.73418,
        "msttr-100_nopunct": 0.77517,
        "total_length": 6745,
        "mean_pred_length": 18.788300835654596,
        "std_pred_length": 9.19760033853898,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 53,
        "distinct-1": 0.3654558932542624,
        "vocab_size-1": 2465,
        "unique-1": 1795,
        "entropy-1": 9.139203722771397,
        "distinct-2": 0.8429376761666145,
        "vocab_size-2": 5383,
        "unique-2": 4969,
        "entropy-2": 12.110166824203143,
        "cond_entropy-2": 2.6884442950359326,
        "distinct-3": 0.9668159946905591,
        "vocab_size-3": 5827,
        "unique-3": 5725,
        "entropy-3": 12.449683884252178,
        "cond_entropy-3": 0.3560208238505231,
        "total_length-nopunct": 6018,
        "mean_pred_length-nopunct": 16.76323119777159,
        "std_pred_length-nopunct": 8.256823741965132,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4076105018278498,
        "vocab_size-1-nopunct": 2453,
        "unique-1-nopunct": 1794,
        "entropy-1-nopunct": 9.470726780637374,
        "distinct-2-nopunct": 0.8598692348471462,
        "vocab_size-2-nopunct": 4866,
        "unique-2-nopunct": 4529,
        "entropy-2-nopunct": 11.998663240417565,
        "cond_entropy-2-nopunct": 2.669650936396991,
        "distinct-3-nopunct": 0.9794339622641509,
        "vocab_size-3-nopunct": 5191,
        "unique-3-nopunct": 5111,
        "entropy-3-nopunct": 12.323741327087413,
        "cond_entropy-3-nopunct": 0.3489702026540482,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 10.608691186882831,
        "bleu": 65.84823,
        "rouge1": {
            "precision": 0.84956,
            "recall": 0.76036,
            "fmeasure": 0.78668
        },
        "rouge2": {
            "precision": 0.7095,
            "recall": 0.63006,
            "fmeasure": 0.6513
        },
        "rougeL": {
            "precision": 0.82055,
            "recall": 0.73488,
            "fmeasure": 0.75967
        },
        "rougeLsum": {
            "precision": 0.82055,
            "recall": 0.73488,
            "fmeasure": 0.75967
        },
        "local_recall": {
            "1": 0.042232597623089986,
            "2": 0.1558109833971903,
            "3": 0.34573304157549234,
            "4": 0.49128367670364503,
            "5": 0.612668743509865,
            "6": 0.7373188405797102,
            "7": 0.8403970981290569
        },
        "sari": 47.01513,
        "bertscore": {
            "precision": 0.95412,
            "recall": 0.9357,
            "f1": 0.94232
        },
        "bleurt": 0.18045,
        "meteor": 0.44231752358001447,
        "nubia": {
            "semantic_relation": 4.20819,
            "contradiction": 4.57782,
            "irrelevancy": 15.16589,
            "logical_agreement": 80.25629,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.00327,
            "nubia_score": 0.6659
        }
    },
    "wiki_auto_asset_turk_challenge_train_sample": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_challenge_train_sample",
        "N": 500
    },
    "totto_test_contrast_challenge_table_size-table_size_13": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 35,
        "msttr-100": 0.604,
        "msttr-100_nopunct": 0.595,
        "total_length": 560,
        "mean_pred_length": 16.0,
        "std_pred_length": 5.923319532636602,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 37,
        "distinct-1": 0.3625,
        "vocab_size-1": 203,
        "unique-1": 157,
        "entropy-1": 6.488832226105295,
        "distinct-2": 0.6876190476190476,
        "vocab_size-2": 361,
        "unique-2": 308,
        "entropy-2": 8.109794458545588,
        "cond_entropy-2": 1.455040084033227,
        "distinct-3": 0.8142857142857143,
        "vocab_size-3": 399,
        "unique-3": 363,
        "entropy-3": 8.410673093261982,
        "cond_entropy-3": 0.3017424518394089,
        "total_length-nopunct": 477,
        "mean_pred_length-nopunct": 13.628571428571428,
        "std_pred_length-nopunct": 4.876097469351104,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.41509433962264153,
        "vocab_size-1-nopunct": 198,
        "unique-1-nopunct": 157,
        "entropy-1-nopunct": 6.559348706668946,
        "distinct-2-nopunct": 0.7194570135746606,
        "vocab_size-2-nopunct": 318,
        "unique-2-nopunct": 275,
        "entropy-2-nopunct": 7.9654222156334535,
        "cond_entropy-2-nopunct": 1.4710499491945095,
        "distinct-3-nopunct": 0.8230958230958231,
        "vocab_size-3-nopunct": 335,
        "unique-3-nopunct": 309,
        "entropy-3-nopunct": 8.162464507758994,
        "cond_entropy-3-nopunct": 0.24667828605869876,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.688384551213724,
        "bleu": 54.13315,
        "rouge1": {
            "precision": 0.80323,
            "recall": 0.78772,
            "fmeasure": 0.78876
        },
        "rouge2": {
            "precision": 0.59728,
            "recall": 0.58642,
            "fmeasure": 0.58591
        },
        "rougeL": {
            "precision": 0.71527,
            "recall": 0.70329,
            "fmeasure": 0.70262
        },
        "rougeLsum": {
            "precision": 0.71527,
            "recall": 0.70329,
            "fmeasure": 0.70262
        },
        "local_recall": {
            "1": 0.1724137931034483,
            "2": 0.4230769230769231,
            "3": 0.8213256484149856
        },
        "bertscore": {
            "precision": 0.94366,
            "recall": 0.94033,
            "f1": 0.94041
        },
        "bleurt": 0.48128,
        "meteor": 0.43775569637769157,
        "nubia": {
            "semantic_relation": 4.24122,
            "contradiction": 3.61159,
            "irrelevancy": 18.25638,
            "logical_agreement": 78.13203,
            "grammar_ref": 4.23324,
            "grammar_hyp": 4.06706,
            "nubia_score": 0.80063
        }
    },
    "wiki_auto_asset_turk_challenge_validation_sample": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_challenge_validation_sample",
        "N": 500
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02_parent": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72887,
        "msttr-100_nopunct": 0.76984,
        "total_length": 7160,
        "mean_pred_length": 19.944289693593316,
        "std_pred_length": 9.41268121583602,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 48,
        "distinct-1": 0.3741620111731844,
        "vocab_size-1": 2679,
        "unique-1": 1984,
        "entropy-1": 9.194120336853468,
        "distinct-2": 0.8406116747537127,
        "vocab_size-2": 5717,
        "unique-2": 5300,
        "entropy-2": 12.170006454560234,
        "cond_entropy-2": 2.710443523538477,
        "distinct-3": 0.9649177274138466,
        "vocab_size-3": 6216,
        "unique-3": 6107,
        "entropy-3": 12.534020277527619,
        "cond_entropy-3": 0.3791397457703247,
        "total_length-nopunct": 6345,
        "mean_pred_length-nopunct": 17.67409470752089,
        "std_pred_length-nopunct": 8.372735478286602,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.42048857368006304,
        "vocab_size-1-nopunct": 2668,
        "unique-1-nopunct": 1983,
        "entropy-1-nopunct": 9.54860391112204,
        "distinct-2-nopunct": 0.8591713999331774,
        "vocab_size-2-nopunct": 5143,
        "unique-2-nopunct": 4793,
        "entropy-2-nopunct": 12.065182536129276,
        "cond_entropy-2-nopunct": 2.6572962540486684,
        "distinct-3-nopunct": 0.9781411053847521,
        "vocab_size-3-nopunct": 5504,
        "unique-3-nopunct": 5417,
        "entropy-3-nopunct": 12.405641990946366,
        "cond_entropy-3-nopunct": 0.3650903204318789,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 13.27357163033192,
        "bleu": 85.75591,
        "rouge1": {
            "precision": 0.89371,
            "recall": 0.86896,
            "fmeasure": 0.87162
        },
        "rouge2": {
            "precision": 0.79569,
            "recall": 0.77545,
            "fmeasure": 0.7738
        },
        "rougeL": {
            "precision": 0.87917,
            "recall": 0.85515,
            "fmeasure": 0.85744
        },
        "rougeLsum": {
            "precision": 0.87917,
            "recall": 0.85515,
            "fmeasure": 0.85744
        },
        "local_recall": {
            "1": 0.030871003307607496,
            "2": 0.15498652291105122,
            "3": 0.3674698795180723,
            "4": 0.5565749235474006,
            "5": 0.6874051593323217,
            "6": 0.7633802816901408,
            "7": 0.825136612021858,
            "8": 0.864897466827503,
            "9": 0.8952380952380953,
            "10": 0.9441860465116279
        },
        "bertscore": {
            "precision": 0.96941,
            "recall": 0.96601,
            "f1": 0.96505
        },
        "bleurt": 0.23178,
        "meteor": 0.5255935126956474,
        "nubia": {
            "semantic_relation": 4.24493,
            "contradiction": 3.00277,
            "irrelevancy": 30.91127,
            "logical_agreement": 66.08596,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.82083,
            "nubia_score": 0.65288
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 642,
        "msttr-100": 0.44477,
        "msttr-100_nopunct": 0.43922,
        "total_length": 23786,
        "mean_pred_length": 37.04984423676012,
        "std_pred_length": 19.09675336470341,
        "median_pred_length": 33.0,
        "min_pred_length": 6,
        "max_pred_length": 87,
        "distinct-1": 0.07214327755822753,
        "vocab_size-1": 1716,
        "unique-1": 635,
        "entropy-1": 5.9956853723622,
        "distinct-2": 0.1943484272381611,
        "vocab_size-2": 4498,
        "unique-2": 2118,
        "entropy-2": 10.211238239685924,
        "cond_entropy-2": 4.193581758718637,
        "distinct-3": 0.3334370278197494,
        "vocab_size-3": 7503,
        "unique-3": 4134,
        "entropy-3": 11.74449001390245,
        "cond_entropy-3": 1.5745631979155699,
        "total_length-nopunct": 21902,
        "mean_pred_length-nopunct": 34.11526479750779,
        "std_pred_length-nopunct": 17.98941668816278,
        "median_pred_length-nopunct": 30.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 80,
        "distinct-1-nopunct": 0.07793808784585883,
        "vocab_size-1-nopunct": 1707,
        "unique-1-nopunct": 633,
        "entropy-1-nopunct": 5.906886882769564,
        "distinct-2-nopunct": 0.19308560677328315,
        "vocab_size-2-nopunct": 4105,
        "unique-2-nopunct": 1919,
        "entropy-2-nopunct": 10.057710731320407,
        "cond_entropy-2-nopunct": 4.25362919477803,
        "distinct-3-nopunct": 0.3317974585313804,
        "vocab_size-3-nopunct": 6841,
        "unique-3-nopunct": 3816,
        "entropy-3-nopunct": 11.574826924358046,
        "cond_entropy-3-nopunct": 1.5549019293526665,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.3781067112896723,
        "bleu": 3.17173,
        "rouge1": {
            "precision": 0.4949,
            "recall": 0.46127,
            "fmeasure": 0.46803
        },
        "rouge2": {
            "precision": 0.28923,
            "recall": 0.26944,
            "fmeasure": 0.27351
        },
        "rougeL": {
            "precision": 0.46838,
            "recall": 0.43704,
            "fmeasure": 0.44269
        },
        "rougeLsum": {
            "precision": 0.46838,
            "recall": 0.43704,
            "fmeasure": 0.44269
        },
        "local_recall": {
            "1": 0.09939891511508576,
            "2": 0.21553133514986375,
            "3": 0.3033589923023093,
            "4": 0.19736842105263158,
            "5": 0.36363636363636365,
            "6": 0.18181818181818182,
            "7": 0.25
        },
        "bertscore": {
            "precision": 0.86948,
            "recall": 0.87774,
            "f1": 0.87312
        },
        "bleurt": -0.42867,
        "meteor": 0.1475983270375038,
        "nubia": {
            "semantic_relation": 3.31157,
            "contradiction": 33.6319,
            "irrelevancy": 17.11018,
            "logical_agreement": 49.25792,
            "grammar_ref": 2.74601,
            "grammar_hyp": 2.7993,
            "nubia_score": 0.17589
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 251,
        "msttr-100": 0.50885,
        "msttr-100_nopunct": 0.51416,
        "total_length": 8731,
        "mean_pred_length": 34.78486055776892,
        "std_pred_length": 9.739307646171312,
        "median_pred_length": 34.0,
        "min_pred_length": 15,
        "max_pred_length": 63,
        "distinct-1": 0.12060474172488833,
        "vocab_size-1": 1053,
        "unique-1": 341,
        "entropy-1": 7.826139078760992,
        "distinct-2": 0.3403301886792453,
        "vocab_size-2": 2886,
        "unique-2": 1578,
        "entropy-2": 10.591433551156529,
        "cond_entropy-2": 2.654932574556018,
        "distinct-3": 0.5026127111435168,
        "vocab_size-3": 4136,
        "unique-3": 2786,
        "entropy-3": 11.429785957488185,
        "cond_entropy-3": 0.8719986623453441,
        "total_length-nopunct": 7758,
        "mean_pred_length-nopunct": 30.90836653386454,
        "std_pred_length-nopunct": 8.857187512893768,
        "median_pred_length-nopunct": 30.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 59,
        "distinct-1-nopunct": 0.13469966486207785,
        "vocab_size-1-nopunct": 1045,
        "unique-1-nopunct": 341,
        "entropy-1-nopunct": 8.058615110477435,
        "distinct-2-nopunct": 0.3535366990808579,
        "vocab_size-2-nopunct": 2654,
        "unique-2-nopunct": 1495,
        "entropy-2-nopunct": 10.49601089473531,
        "cond_entropy-2-nopunct": 2.521259131576697,
        "distinct-3-nopunct": 0.5148842337375965,
        "vocab_size-3-nopunct": 3736,
        "unique-3-nopunct": 2579,
        "entropy-3-nopunct": 11.281946418514037,
        "cond_entropy-3-nopunct": 0.8169277951635049,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.445602112045058,
        "bleu": 39.69415,
        "rouge1": {
            "precision": 0.67307,
            "recall": 0.6777,
            "fmeasure": 0.66936
        },
        "rouge2": {
            "precision": 0.39392,
            "recall": 0.39373,
            "fmeasure": 0.3899
        },
        "rougeL": {
            "precision": 0.49018,
            "recall": 0.49407,
            "fmeasure": 0.48695
        },
        "rougeLsum": {
            "precision": 0.49018,
            "recall": 0.49407,
            "fmeasure": 0.48695
        },
        "local_recall": {
            "1": 0.2409990269218294,
            "2": 0.5909952606635072,
            "3": 0.7997175141242938
        },
        "bertscore": {
            "precision": 0.89096,
            "recall": 0.89171,
            "f1": 0.89022
        },
        "bleurt": -0.07264,
        "meteor": 0.3429054489741062,
        "nubia": {
            "semantic_relation": 3.97657,
            "contradiction": 23.41059,
            "irrelevancy": 10.26754,
            "logical_agreement": 66.32187,
            "grammar_ref": 4.22372,
            "grammar_hyp": 4.34674,
            "nubia_score": 0.66487
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_48": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 114,
        "msttr-100": 0.72611,
        "msttr-100_nopunct": 0.784,
        "total_length": 1821,
        "mean_pred_length": 15.973684210526315,
        "std_pred_length": 5.381026652052708,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 33,
        "distinct-1": 0.47666117517847334,
        "vocab_size-1": 868,
        "unique-1": 698,
        "entropy-1": 8.322980894481622,
        "distinct-2": 0.8816637375512595,
        "vocab_size-2": 1505,
        "unique-2": 1391,
        "entropy-2": 10.420991225497499,
        "cond_entropy-2": 1.8091465055972813,
        "distinct-3": 0.9723791588198368,
        "vocab_size-3": 1549,
        "unique-3": 1509,
        "entropy-3": 10.58039335754609,
        "cond_entropy-3": 0.15062253216222277,
        "total_length-nopunct": 1588,
        "mean_pred_length-nopunct": 13.929824561403509,
        "std_pred_length-nopunct": 4.882333527215821,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.5409319899244333,
        "vocab_size-1-nopunct": 859,
        "unique-1-nopunct": 696,
        "entropy-1-nopunct": 8.628880082384967,
        "distinct-2-nopunct": 0.8968792401628223,
        "vocab_size-2-nopunct": 1322,
        "unique-2-nopunct": 1242,
        "entropy-2-nopunct": 10.241137564777878,
        "cond_entropy-2-nopunct": 1.721659092996576,
        "distinct-3-nopunct": 0.9816176470588235,
        "vocab_size-3-nopunct": 1335,
        "unique-3-nopunct": 1311,
        "entropy-3-nopunct": 10.372071165915544,
        "cond_entropy-3-nopunct": 0.14772384183709533,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.147566248947229,
        "bleu": 39.15863,
        "rouge1": {
            "precision": 0.74489,
            "recall": 0.69404,
            "fmeasure": 0.70456
        },
        "rouge2": {
            "precision": 0.49411,
            "recall": 0.45762,
            "fmeasure": 0.46539
        },
        "rougeL": {
            "precision": 0.63344,
            "recall": 0.59375,
            "fmeasure": 0.60117
        },
        "rougeLsum": {
            "precision": 0.63344,
            "recall": 0.59375,
            "fmeasure": 0.60117
        },
        "local_recall": {
            "1": 0.1691542288557214,
            "2": 0.44923857868020306,
            "3": 0.752414398595259
        },
        "bertscore": {
            "precision": 0.91749,
            "recall": 0.91525,
            "f1": 0.91489
        },
        "bleurt": 0.17631,
        "meteor": 0.36880874782479384,
        "nubia": {
            "semantic_relation": 4.14764,
            "contradiction": 8.52207,
            "irrelevancy": 35.8685,
            "logical_agreement": 55.60942,
            "grammar_ref": 4.6714,
            "grammar_hyp": 4.71692,
            "nubia_score": 0.70135
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_14": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 79,
        "msttr-100": 0.71571,
        "msttr-100_nopunct": 0.75833,
        "total_length": 1431,
        "mean_pred_length": 18.11392405063291,
        "std_pred_length": 8.440390149018553,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 50,
        "distinct-1": 0.4171907756813417,
        "vocab_size-1": 597,
        "unique-1": 457,
        "entropy-1": 7.894080796238276,
        "distinct-2": 0.7588757396449705,
        "vocab_size-2": 1026,
        "unique-2": 905,
        "entropy-2": 9.66668747834038,
        "cond_entropy-2": 1.555528846726516,
        "distinct-3": 0.8711704634721131,
        "vocab_size-3": 1109,
        "unique-3": 1040,
        "entropy-3": 9.93044708545076,
        "cond_entropy-3": 0.2870405471738139,
        "total_length-nopunct": 1248,
        "mean_pred_length-nopunct": 15.79746835443038,
        "std_pred_length-nopunct": 6.8793945620336245,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.47115384615384615,
        "vocab_size-1-nopunct": 588,
        "unique-1-nopunct": 454,
        "entropy-1-nopunct": 8.10136420179533,
        "distinct-2-nopunct": 0.7698887938408896,
        "vocab_size-2-nopunct": 900,
        "unique-2-nopunct": 798,
        "entropy-2-nopunct": 9.48787330068855,
        "cond_entropy-2-nopunct": 1.479776122143847,
        "distinct-3-nopunct": 0.8761467889908257,
        "vocab_size-3-nopunct": 955,
        "unique-3-nopunct": 897,
        "entropy-3-nopunct": 9.722314212047277,
        "cond_entropy-3-nopunct": 0.271434368700946,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.542405029616579,
        "bleu": 51.26808,
        "rouge1": {
            "precision": 0.77426,
            "recall": 0.75617,
            "fmeasure": 0.75642
        },
        "rouge2": {
            "precision": 0.56445,
            "recall": 0.55275,
            "fmeasure": 0.55317
        },
        "rougeL": {
            "precision": 0.67796,
            "recall": 0.66183,
            "fmeasure": 0.6626
        },
        "rougeLsum": {
            "precision": 0.67796,
            "recall": 0.66183,
            "fmeasure": 0.6626
        },
        "local_recall": {
            "1": 0.17408906882591094,
            "2": 0.45652173913043476,
            "3": 0.8213879408418657
        },
        "bertscore": {
            "precision": 0.93251,
            "recall": 0.93227,
            "f1": 0.93052
        },
        "bleurt": 0.28139,
        "meteor": 0.4008824337130225,
        "nubia": {
            "semantic_relation": 4.12604,
            "contradiction": 12.7911,
            "irrelevancy": 28.94677,
            "logical_agreement": 58.26213,
            "grammar_ref": 4.4104,
            "grammar_hyp": 4.43893,
            "nubia_score": 0.72155
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_49": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.72,
        "total_length": 329,
        "mean_pred_length": 18.27777777777778,
        "std_pred_length": 7.093076088345714,
        "median_pred_length": 16.5,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.574468085106383,
        "vocab_size-1": 189,
        "unique-1": 153,
        "entropy-1": 6.860921874085056,
        "distinct-2": 0.9003215434083601,
        "vocab_size-2": 280,
        "unique-2": 257,
        "entropy-2": 8.05767084091758,
        "cond_entropy-2": 1.037764076002043,
        "distinct-3": 0.9726962457337884,
        "vocab_size-3": 285,
        "unique-3": 277,
        "entropy-3": 8.14014934588987,
        "cond_entropy-3": 0.09618430267135189,
        "total_length-nopunct": 291,
        "mean_pred_length-nopunct": 16.166666666666668,
        "std_pred_length-nopunct": 6.048415770541351,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6288659793814433,
        "vocab_size-1-nopunct": 183,
        "unique-1-nopunct": 151,
        "entropy-1-nopunct": 6.928648334591615,
        "distinct-2-nopunct": 0.8974358974358975,
        "vocab_size-2-nopunct": 245,
        "unique-2-nopunct": 224,
        "entropy-2-nopunct": 7.863346186769304,
        "cond_entropy-2-nopunct": 1.0101999992462174,
        "distinct-3-nopunct": 0.9764705882352941,
        "vocab_size-3-nopunct": 249,
        "unique-3-nopunct": 243,
        "entropy-3-nopunct": 7.947294613329459,
        "cond_entropy-3-nopunct": 0.09622057234328318,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.435123186599543,
        "bleu": 36.06782,
        "rouge1": {
            "precision": 0.67702,
            "recall": 0.66377,
            "fmeasure": 0.65137
        },
        "rouge2": {
            "precision": 0.43563,
            "recall": 0.42735,
            "fmeasure": 0.42064
        },
        "rougeL": {
            "precision": 0.55544,
            "recall": 0.54022,
            "fmeasure": 0.53299
        },
        "rougeLsum": {
            "precision": 0.55544,
            "recall": 0.54022,
            "fmeasure": 0.53299
        },
        "local_recall": {
            "1": 0.23300970873786409,
            "2": 0.3409090909090909,
            "3": 0.6989795918367347
        },
        "bertscore": {
            "precision": 0.90496,
            "recall": 0.90378,
            "f1": 0.90236
        },
        "bleurt": 0.04604,
        "meteor": 0.3583246735263237,
        "nubia": {
            "semantic_relation": 3.92972,
            "contradiction": 7.05587,
            "irrelevancy": 54.95677,
            "logical_agreement": 37.98736,
            "grammar_ref": 4.5439,
            "grammar_hyp": 4.46221,
            "nubia_score": 0.6369
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_12": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 26,
        "msttr-100": 0.635,
        "msttr-100_nopunct": 0.70667,
        "total_length": 821,
        "mean_pred_length": 31.576923076923077,
        "std_pred_length": 9.996819020695753,
        "median_pred_length": 33.5,
        "min_pred_length": 14,
        "max_pred_length": 52,
        "distinct-1": 0.46041412911084045,
        "vocab_size-1": 378,
        "unique-1": 280,
        "entropy-1": 7.337282107798225,
        "distinct-2": 0.8075471698113208,
        "vocab_size-2": 642,
        "unique-2": 555,
        "entropy-2": 9.113675278864841,
        "cond_entropy-2": 1.6993257889681388,
        "distinct-3": 0.9284785435630689,
        "vocab_size-3": 714,
        "unique-3": 665,
        "entropy-3": 9.437269501864733,
        "cond_entropy-3": 0.31305852156903513,
        "total_length-nopunct": 665,
        "mean_pred_length-nopunct": 25.576923076923077,
        "std_pred_length-nopunct": 8.096405075583174,
        "median_pred_length-nopunct": 25.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.5578947368421052,
        "vocab_size-1-nopunct": 371,
        "unique-1-nopunct": 277,
        "entropy-1-nopunct": 7.709310861549213,
        "distinct-2-nopunct": 0.8748043818466353,
        "vocab_size-2-nopunct": 559,
        "unique-2-nopunct": 503,
        "entropy-2-nopunct": 9.025219886332916,
        "cond_entropy-2-nopunct": 1.3513287805961376,
        "distinct-3-nopunct": 0.9477977161500816,
        "vocab_size-3-nopunct": 581,
        "unique-3-nopunct": 554,
        "entropy-3-nopunct": 9.148381660906944,
        "cond_entropy-3-nopunct": 0.11933756266537217,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.667675895497738,
        "bleu": 39.86508,
        "rouge1": {
            "precision": 0.7529,
            "recall": 0.67876,
            "fmeasure": 0.70135
        },
        "rouge2": {
            "precision": 0.49805,
            "recall": 0.45257,
            "fmeasure": 0.46658
        },
        "rougeL": {
            "precision": 0.60062,
            "recall": 0.54046,
            "fmeasure": 0.55814
        },
        "rougeLsum": {
            "precision": 0.60062,
            "recall": 0.54046,
            "fmeasure": 0.55814
        },
        "local_recall": {
            "1": 0.14166666666666666,
            "2": 0.3697478991596639,
            "3": 0.762114537444934
        },
        "bertscore": {
            "precision": 0.9145,
            "recall": 0.90961,
            "f1": 0.91016
        },
        "bleurt": 0.0727,
        "meteor": 0.36149902879442647,
        "nubia": {
            "semantic_relation": 3.66929,
            "contradiction": 20.3882,
            "irrelevancy": 29.33041,
            "logical_agreement": 50.28139,
            "grammar_ref": 4.04917,
            "grammar_hyp": 3.97952,
            "nubia_score": 0.58844
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_13": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.60667,
        "msttr-100_nopunct": 0.705,
        "total_length": 308,
        "mean_pred_length": 30.8,
        "std_pred_length": 8.885943956609225,
        "median_pred_length": 29.5,
        "min_pred_length": 12,
        "max_pred_length": 41,
        "distinct-1": 0.5357142857142857,
        "vocab_size-1": 165,
        "unique-1": 131,
        "entropy-1": 6.58775615178308,
        "distinct-2": 0.8322147651006712,
        "vocab_size-2": 248,
        "unique-2": 219,
        "entropy-2": 7.81546461937557,
        "cond_entropy-2": 1.1725776720899646,
        "distinct-3": 0.9305555555555556,
        "vocab_size-3": 268,
        "unique-3": 252,
        "entropy-3": 8.01884939378837,
        "cond_entropy-3": 0.20089224492913674,
        "total_length-nopunct": 241,
        "mean_pred_length-nopunct": 24.1,
        "std_pred_length-nopunct": 7.244998274671983,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.6639004149377593,
        "vocab_size-1-nopunct": 160,
        "unique-1-nopunct": 131,
        "entropy-1-nopunct": 6.876042224833082,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 210,
        "unique-2-nopunct": 198,
        "entropy-2-nopunct": 7.634153099829492,
        "cond_entropy-2-nopunct": 0.7831477088200349,
        "distinct-3-nopunct": 0.9547511312217195,
        "vocab_size-3-nopunct": 211,
        "unique-3-nopunct": 203,
        "entropy-3-nopunct": 7.688355048079194,
        "cond_entropy-3-nopunct": 0.05952303157940244,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.434483642702795,
        "bleu": 41.22829,
        "rouge1": {
            "precision": 0.71307,
            "recall": 0.69067,
            "fmeasure": 0.68543
        },
        "rouge2": {
            "precision": 0.45442,
            "recall": 0.46044,
            "fmeasure": 0.44942
        },
        "rougeL": {
            "precision": 0.52639,
            "recall": 0.53605,
            "fmeasure": 0.52011
        },
        "rougeLsum": {
            "precision": 0.52639,
            "recall": 0.53605,
            "fmeasure": 0.52011
        },
        "local_recall": {
            "1": 0.1643835616438356,
            "2": 0.4067796610169492,
            "3": 0.7397260273972602
        },
        "bertscore": {
            "precision": 0.90956,
            "recall": 0.90998,
            "f1": 0.90651
        },
        "bleurt": 0.03467,
        "meteor": 0.3611213861444529,
        "nubia": {
            "semantic_relation": 3.6341,
            "contradiction": 4.18219,
            "irrelevancy": 44.59071,
            "logical_agreement": 51.2271,
            "grammar_ref": 4.57725,
            "grammar_hyp": 4.08564,
            "nubia_score": 0.62127
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_14": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.665,
        "msttr-100_nopunct": 0.77,
        "total_length": 409,
        "mean_pred_length": 29.214285714285715,
        "std_pred_length": 12.178309590817436,
        "median_pred_length": 28.5,
        "min_pred_length": 11,
        "max_pred_length": 51,
        "distinct-1": 0.5745721271393643,
        "vocab_size-1": 235,
        "unique-1": 191,
        "entropy-1": 7.002947083104031,
        "distinct-2": 0.8810126582278481,
        "vocab_size-2": 348,
        "unique-2": 321,
        "entropy-2": 8.328240600314212,
        "cond_entropy-2": 1.2428179204955456,
        "distinct-3": 0.9658792650918635,
        "vocab_size-3": 368,
        "unique-3": 357,
        "entropy-3": 8.501443053623724,
        "cond_entropy-3": 0.17888370107463258,
        "total_length-nopunct": 338,
        "mean_pred_length-nopunct": 24.142857142857142,
        "std_pred_length-nopunct": 9.326284996542551,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.6775147928994083,
        "vocab_size-1-nopunct": 229,
        "unique-1-nopunct": 191,
        "entropy-1-nopunct": 7.252696261664576,
        "distinct-2-nopunct": 0.9074074074074074,
        "vocab_size-2-nopunct": 294,
        "unique-2-nopunct": 277,
        "entropy-2-nopunct": 8.106745720676784,
        "cond_entropy-2-nopunct": 0.8833383539008686,
        "distinct-3-nopunct": 0.9774193548387097,
        "vocab_size-3-nopunct": 303,
        "unique-3-nopunct": 297,
        "entropy-3-nopunct": 8.228527993976908,
        "cond_entropy-3-nopunct": 0.12908375701273242,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.396605652647526,
        "bleu": 37.79933,
        "rouge1": {
            "precision": 0.66573,
            "recall": 0.64687,
            "fmeasure": 0.64005
        },
        "rouge2": {
            "precision": 0.41135,
            "recall": 0.41413,
            "fmeasure": 0.40375
        },
        "rougeL": {
            "precision": 0.57767,
            "recall": 0.56474,
            "fmeasure": 0.55781
        },
        "rougeLsum": {
            "precision": 0.57767,
            "recall": 0.56474,
            "fmeasure": 0.55781
        },
        "local_recall": {
            "1": 0.2571428571428571,
            "2": 0.463768115942029,
            "3": 0.673728813559322
        },
        "bertscore": {
            "precision": 0.89475,
            "recall": 0.89684,
            "f1": 0.89472
        },
        "bleurt": 0.01808,
        "meteor": 0.32996817053126226,
        "nubia": {
            "semantic_relation": 3.55158,
            "contradiction": 25.74914,
            "irrelevancy": 16.86049,
            "logical_agreement": 57.39037,
            "grammar_ref": 4.37064,
            "grammar_hyp": 4.08988,
            "nubia_score": 0.55768
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_30": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 122,
        "msttr-100": 0.724,
        "msttr-100_nopunct": 0.77294,
        "total_length": 2018,
        "mean_pred_length": 16.540983606557376,
        "std_pred_length": 6.572605268546462,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 41,
        "distinct-1": 0.45341922695738357,
        "vocab_size-1": 915,
        "unique-1": 729,
        "entropy-1": 8.341119643277159,
        "distinct-2": 0.8306962025316456,
        "vocab_size-2": 1575,
        "unique-2": 1407,
        "entropy-2": 10.431701575978687,
        "cond_entropy-2": 1.8143351628431912,
        "distinct-3": 0.9447576099210823,
        "vocab_size-3": 1676,
        "unique-3": 1603,
        "entropy-3": 10.663800014513159,
        "cond_entropy-3": 0.2249927768201869,
        "total_length-nopunct": 1782,
        "mean_pred_length-nopunct": 14.60655737704918,
        "std_pred_length-nopunct": 6.057859516268021,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.5078563411896745,
        "vocab_size-1-nopunct": 905,
        "unique-1-nopunct": 726,
        "entropy-1-nopunct": 8.609251703601688,
        "distinct-2-nopunct": 0.8451807228915663,
        "vocab_size-2-nopunct": 1403,
        "unique-2-nopunct": 1271,
        "entropy-2-nopunct": 10.275632837110512,
        "cond_entropy-2-nopunct": 1.7622146867515303,
        "distinct-3-nopunct": 0.9512353706111834,
        "vocab_size-3-nopunct": 1463,
        "unique-3-nopunct": 1408,
        "entropy-3-nopunct": 10.472940391414712,
        "cond_entropy-3-nopunct": 0.21685435669034125,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.630254175920071,
        "bleu": 46.13695,
        "rouge1": {
            "precision": 0.76185,
            "recall": 0.73476,
            "fmeasure": 0.73683
        },
        "rouge2": {
            "precision": 0.53303,
            "recall": 0.51123,
            "fmeasure": 0.51382
        },
        "rougeL": {
            "precision": 0.66195,
            "recall": 0.63338,
            "fmeasure": 0.63777
        },
        "rougeLsum": {
            "precision": 0.66195,
            "recall": 0.63338,
            "fmeasure": 0.63777
        },
        "local_recall": {
            "1": 0.18202247191011237,
            "2": 0.3857566765578635,
            "3": 0.7779422649888971
        },
        "bertscore": {
            "precision": 0.92909,
            "recall": 0.92526,
            "f1": 0.9251
        },
        "bleurt": 0.27264,
        "meteor": 0.39310623342300843,
        "nubia": {
            "semantic_relation": 4.25869,
            "contradiction": 7.78633,
            "irrelevancy": 27.94621,
            "logical_agreement": 64.26746,
            "grammar_ref": 4.69288,
            "grammar_hyp": 4.66594,
            "nubia_score": 0.74137
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_15": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.63667,
        "msttr-100_nopunct": 0.72333,
        "total_length": 388,
        "mean_pred_length": 27.714285714285715,
        "std_pred_length": 12.412140205854747,
        "median_pred_length": 23.0,
        "min_pred_length": 12,
        "max_pred_length": 50,
        "distinct-1": 0.5335051546391752,
        "vocab_size-1": 207,
        "unique-1": 168,
        "entropy-1": 6.80634873978553,
        "distinct-2": 0.8850267379679144,
        "vocab_size-2": 331,
        "unique-2": 306,
        "entropy-2": 8.264144176567124,
        "cond_entropy-2": 1.3824128927303188,
        "distinct-3": 0.9805555555555555,
        "vocab_size-3": 353,
        "unique-3": 347,
        "entropy-3": 8.450867297712534,
        "cond_entropy-3": 0.18451094465739204,
        "total_length-nopunct": 312,
        "mean_pred_length-nopunct": 22.285714285714285,
        "std_pred_length-nopunct": 9.11379309013519,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.6442307692307693,
        "vocab_size-1-nopunct": 201,
        "unique-1-nopunct": 168,
        "entropy-1-nopunct": 7.046883754760564,
        "distinct-2-nopunct": 0.9429530201342282,
        "vocab_size-2-nopunct": 281,
        "unique-2-nopunct": 269,
        "entropy-2-nopunct": 8.089118562401179,
        "cond_entropy-2-nopunct": 1.0797157925264567,
        "distinct-3-nopunct": 0.9929577464788732,
        "vocab_size-3-nopunct": 282,
        "unique-3-nopunct": 280,
        "entropy-3-nopunct": 8.13566261246245,
        "cond_entropy-3-nopunct": 0.045912709965631245,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.635958573933758,
        "bleu": 24.0722,
        "rouge1": {
            "precision": 0.64514,
            "recall": 0.54343,
            "fmeasure": 0.57568
        },
        "rouge2": {
            "precision": 0.32017,
            "recall": 0.26799,
            "fmeasure": 0.2827
        },
        "rougeL": {
            "precision": 0.47217,
            "recall": 0.40963,
            "fmeasure": 0.4294
        },
        "rougeLsum": {
            "precision": 0.47217,
            "recall": 0.40963,
            "fmeasure": 0.4294
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.17647058823529413,
            "3": 0.5741444866920152
        },
        "bertscore": {
            "precision": 0.88261,
            "recall": 0.87008,
            "f1": 0.87547
        },
        "bleurt": -0.04965,
        "meteor": 0.27433940052361044,
        "nubia": {
            "semantic_relation": 3.38471,
            "contradiction": 34.64114,
            "irrelevancy": 34.73083,
            "logical_agreement": 30.62802,
            "grammar_ref": 3.91022,
            "grammar_hyp": 4.02843,
            "nubia_score": 0.49127
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_16": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.7,
        "total_length": 198,
        "mean_pred_length": 28.285714285714285,
        "std_pred_length": 5.469768491164756,
        "median_pred_length": 27.0,
        "min_pred_length": 19,
        "max_pred_length": 37,
        "distinct-1": 0.5303030303030303,
        "vocab_size-1": 105,
        "unique-1": 76,
        "entropy-1": 5.967903479516196,
        "distinct-2": 0.8324607329842932,
        "vocab_size-2": 159,
        "unique-2": 138,
        "entropy-2": 7.183270647328188,
        "cond_entropy-2": 1.173370767443087,
        "distinct-3": 0.9347826086956522,
        "vocab_size-3": 172,
        "unique-3": 162,
        "entropy-3": 7.38492187451177,
        "cond_entropy-3": 0.2166463753626635,
        "total_length-nopunct": 156,
        "mean_pred_length-nopunct": 22.285714285714285,
        "std_pred_length-nopunct": 4.526565576501389,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.6474358974358975,
        "vocab_size-1-nopunct": 101,
        "unique-1-nopunct": 75,
        "entropy-1-nopunct": 6.341067363880519,
        "distinct-2-nopunct": 0.8993288590604027,
        "vocab_size-2-nopunct": 134,
        "unique-2-nopunct": 122,
        "entropy-2-nopunct": 7.002627161358205,
        "cond_entropy-2-nopunct": 0.6925017034164311,
        "distinct-3-nopunct": 0.9577464788732394,
        "vocab_size-3-nopunct": 136,
        "unique-3-nopunct": 131,
        "entropy-3-nopunct": 7.0599239680810015,
        "cond_entropy-3-nopunct": 0.06092912724200586,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.245093224504453,
        "bleu": 34.34891,
        "rouge1": {
            "precision": 0.75256,
            "recall": 0.64159,
            "fmeasure": 0.68682
        },
        "rouge2": {
            "precision": 0.43785,
            "recall": 0.39691,
            "fmeasure": 0.41289
        },
        "rougeL": {
            "precision": 0.60105,
            "recall": 0.53345,
            "fmeasure": 0.5592
        },
        "rougeLsum": {
            "precision": 0.60105,
            "recall": 0.53345,
            "fmeasure": 0.5592
        },
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.6166666666666667,
            "3": 0.6956521739130435
        },
        "bertscore": {
            "precision": 0.91603,
            "recall": 0.89486,
            "f1": 0.90378
        },
        "bleurt": 0.11131,
        "meteor": 0.3372426873010514,
        "nubia": {
            "semantic_relation": 3.27772,
            "contradiction": 25.67783,
            "irrelevancy": 42.53349,
            "logical_agreement": 31.78868,
            "grammar_ref": 3.5611,
            "grammar_hyp": 3.47571,
            "nubia_score": 0.49011
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_31": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 76,
        "mean_pred_length": 19.0,
        "std_pred_length": 11.640446726822816,
        "median_pred_length": 13.5,
        "min_pred_length": 10,
        "max_pred_length": 39,
        "distinct-1": 0.7631578947368421,
        "vocab_size-1": 58,
        "unique-1": 50,
        "entropy-1": 5.618002474220864,
        "distinct-2": 0.9722222222222222,
        "vocab_size-2": 70,
        "unique-2": 68,
        "entropy-2": 6.114369445886761,
        "cond_entropy-2": 0.4202516960671603,
        "distinct-3": 1.0,
        "vocab_size-3": 68,
        "unique-3": 68,
        "entropy-3": 6.087462841250345,
        "cond_entropy-3": -0.023638630780208267,
        "total_length-nopunct": 66,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 9.069178573608527,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.8484848484848485,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.675234604561488,
        "distinct-2-nopunct": 0.9838709677419355,
        "vocab_size-2-nopunct": 61,
        "unique-2-nopunct": 60,
        "entropy-2-nopunct": 5.921938245870744,
        "cond_entropy-2-nopunct": 0.2543913519413296,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.85798099512757,
        "cond_entropy-3-nopunct": -0.061732556638613253,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.624113067505857,
        "bleu": 80.30998,
        "rouge1": {
            "precision": 0.84147,
            "recall": 0.95377,
            "fmeasure": 0.88715
        },
        "rouge2": {
            "precision": 0.76088,
            "recall": 0.85129,
            "fmeasure": 0.79774
        },
        "rougeL": {
            "precision": 0.83552,
            "recall": 0.93618,
            "fmeasure": 0.87719
        },
        "rougeLsum": {
            "precision": 0.83552,
            "recall": 0.93618,
            "fmeasure": 0.87719
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.7272727272727273,
            "3": 0.9777777777777777
        },
        "bertscore": {
            "precision": 0.96815,
            "recall": 0.98454,
            "f1": 0.97616
        },
        "bleurt": 0.64445,
        "meteor": 0.5938853237867503,
        "nubia": {
            "semantic_relation": 4.57054,
            "contradiction": 1.36871,
            "irrelevancy": 25.89936,
            "logical_agreement": 72.73193,
            "grammar_ref": 4.43427,
            "grammar_hyp": 4.05607,
            "nubia_score": 0.87541
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_50": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 55,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.81,
        "total_length": 822,
        "mean_pred_length": 14.945454545454545,
        "std_pred_length": 5.199364233226219,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 31,
        "distinct-1": 0.5389294403892944,
        "vocab_size-1": 443,
        "unique-1": 362,
        "entropy-1": 7.798955515467471,
        "distinct-2": 0.9087353324641461,
        "vocab_size-2": 697,
        "unique-2": 652,
        "entropy-2": 9.361368148926225,
        "cond_entropy-2": 1.2829437475500454,
        "distinct-3": 0.9747191011235955,
        "vocab_size-3": 694,
        "unique-3": 680,
        "entropy-3": 9.420930692190028,
        "cond_entropy-3": 0.02386684599888622,
        "total_length-nopunct": 703,
        "mean_pred_length-nopunct": 12.781818181818181,
        "std_pred_length-nopunct": 4.438226136607893,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.620199146514936,
        "vocab_size-1-nopunct": 436,
        "unique-1-nopunct": 361,
        "entropy-1-nopunct": 8.059653767274744,
        "distinct-2-nopunct": 0.9320987654320988,
        "vocab_size-2-nopunct": 604,
        "unique-2-nopunct": 575,
        "entropy-2-nopunct": 9.17983366882328,
        "cond_entropy-2-nopunct": 1.1919366400296953,
        "distinct-3-nopunct": 0.9797639123102867,
        "vocab_size-3-nopunct": 581,
        "unique-3-nopunct": 572,
        "entropy-3-nopunct": 9.167597126744118,
        "cond_entropy-3-nopunct": -0.004140592039766737,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.794745158686099,
        "bleu": 46.70295,
        "rouge1": {
            "precision": 0.76652,
            "recall": 0.68418,
            "fmeasure": 0.71345
        },
        "rouge2": {
            "precision": 0.52779,
            "recall": 0.46848,
            "fmeasure": 0.48881
        },
        "rougeL": {
            "precision": 0.67586,
            "recall": 0.6095,
            "fmeasure": 0.63206
        },
        "rougeLsum": {
            "precision": 0.67586,
            "recall": 0.6095,
            "fmeasure": 0.63206
        },
        "local_recall": {
            "1": 0.27450980392156865,
            "2": 0.366120218579235,
            "3": 0.7342007434944238
        },
        "bertscore": {
            "precision": 0.9291,
            "recall": 0.91879,
            "f1": 0.92261
        },
        "bleurt": 0.20995,
        "meteor": 0.3818194418645055,
        "nubia": {
            "semantic_relation": 4.13253,
            "contradiction": 6.68474,
            "irrelevancy": 29.4001,
            "logical_agreement": 63.91516,
            "grammar_ref": 4.83026,
            "grammar_hyp": 4.9082,
            "nubia_score": 0.70589
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_17": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.77,
        "total_length": 234,
        "mean_pred_length": 39.0,
        "std_pred_length": 17.426034163476974,
        "median_pred_length": 30.0,
        "min_pred_length": 25,
        "max_pred_length": 73,
        "distinct-1": 0.5982905982905983,
        "vocab_size-1": 140,
        "unique-1": 116,
        "entropy-1": 6.5536831140119105,
        "distinct-2": 0.9035087719298246,
        "vocab_size-2": 206,
        "unique-2": 193,
        "entropy-2": 7.588804556031425,
        "cond_entropy-2": 1.0017456289892248,
        "distinct-3": 0.972972972972973,
        "vocab_size-3": 216,
        "unique-3": 210,
        "entropy-3": 7.74036181229604,
        "cond_entropy-3": 0.1581541605385322,
        "total_length-nopunct": 191,
        "mean_pred_length-nopunct": 31.833333333333332,
        "std_pred_length-nopunct": 11.567435132973754,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.7120418848167539,
        "vocab_size-1-nopunct": 136,
        "unique-1-nopunct": 116,
        "entropy-1-nopunct": 6.757175998190729,
        "distinct-2-nopunct": 0.9675675675675676,
        "vocab_size-2-nopunct": 179,
        "unique-2-nopunct": 173,
        "entropy-2-nopunct": 7.466516595651436,
        "cond_entropy-2-nopunct": 0.7305379865367712,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 179,
        "unique-3-nopunct": 179,
        "entropy-3-nopunct": 7.483815777264248,
        "cond_entropy-3-nopunct": 0.013886830714424607,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.966781572523755,
        "bleu": 44.18207,
        "rouge1": {
            "precision": 0.73735,
            "recall": 0.69125,
            "fmeasure": 0.70703
        },
        "rouge2": {
            "precision": 0.56402,
            "recall": 0.5133,
            "fmeasure": 0.53316
        },
        "rougeL": {
            "precision": 0.64901,
            "recall": 0.60125,
            "fmeasure": 0.61891
        },
        "rougeLsum": {
            "precision": 0.64901,
            "recall": 0.60125,
            "fmeasure": 0.61891
        },
        "local_recall": {
            "1": 0.24242424242424243,
            "2": 0.5277777777777778,
            "3": 0.6814159292035398
        },
        "bertscore": {
            "precision": 0.91885,
            "recall": 0.91685,
            "f1": 0.91527
        },
        "bleurt": 0.19159,
        "meteor": 0.3710214785263119,
        "nubia": {
            "semantic_relation": 3.62341,
            "contradiction": 14.97526,
            "irrelevancy": 24.69913,
            "logical_agreement": 60.32561,
            "grammar_ref": 3.81267,
            "grammar_hyp": 3.45089,
            "nubia_score": 0.61927
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 460,
        "msttr-100": 0.42783,
        "msttr-100_nopunct": 0.42054,
        "total_length": 24032,
        "mean_pred_length": 52.243478260869566,
        "std_pred_length": 15.108501093523662,
        "median_pred_length": 54.0,
        "min_pred_length": 11,
        "max_pred_length": 83,
        "distinct-1": 0.062375166444740344,
        "vocab_size-1": 1499,
        "unique-1": 502,
        "entropy-1": 5.720033632391877,
        "distinct-2": 0.1682080434413711,
        "vocab_size-2": 3965,
        "unique-2": 1698,
        "entropy-2": 9.948023832977864,
        "cond_entropy-2": 4.229822944588636,
        "distinct-3": 0.3055122879889235,
        "vocab_size-3": 7061,
        "unique-3": 3623,
        "entropy-3": 11.59835486761267,
        "cond_entropy-3": 1.6869433277792187,
        "total_length-nopunct": 22211,
        "mean_pred_length-nopunct": 48.28478260869565,
        "std_pred_length-nopunct": 14.672044808607438,
        "median_pred_length-nopunct": 49.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 82,
        "distinct-1-nopunct": 0.06712890009454775,
        "vocab_size-1-nopunct": 1491,
        "unique-1-nopunct": 501,
        "entropy-1-nopunct": 5.618993355967222,
        "distinct-2-nopunct": 0.16992322192083123,
        "vocab_size-2-nopunct": 3696,
        "unique-2-nopunct": 1587,
        "entropy-2-nopunct": 9.838689555725042,
        "cond_entropy-2-nopunct": 4.288217932990597,
        "distinct-3-nopunct": 0.3084871541966089,
        "vocab_size-3-nopunct": 6568,
        "unique-3-nopunct": 3455,
        "entropy-3-nopunct": 11.462494518539506,
        "cond_entropy-3-nopunct": 1.6562259211661503,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.915803862458855,
        "bleu": 1.07408,
        "rouge1": {
            "precision": 0.32957,
            "recall": 0.31105,
            "fmeasure": 0.31331
        },
        "rouge2": {
            "precision": 0.11601,
            "recall": 0.10888,
            "fmeasure": 0.1091
        },
        "rougeL": {
            "precision": 0.32387,
            "recall": 0.30615,
            "fmeasure": 0.308
        },
        "rougeLsum": {
            "precision": 0.32387,
            "recall": 0.30615,
            "fmeasure": 0.308
        },
        "local_recall": {
            "1": 0.07885952712100139,
            "2": 0.15985543508479289,
            "3": 0.22031187524990004,
            "4": 0.0,
            "5": 0.5,
            "6": 0.0,
            "7": 0.0
        },
        "bertscore": {
            "precision": 0.85558,
            "recall": 0.86706,
            "f1": 0.86076
        },
        "bleurt": -0.51203,
        "meteor": 0.10855759461407882,
        "nubia": {
            "semantic_relation": 3.29348,
            "contradiction": 32.72924,
            "irrelevancy": 17.06576,
            "logical_agreement": 50.205,
            "grammar_ref": 2.52111,
            "grammar_hyp": 2.4419,
            "nubia_score": 0.14126
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_18": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.68,
        "total_length": 132,
        "mean_pred_length": 26.4,
        "std_pred_length": 6.468384651518491,
        "median_pred_length": 23.0,
        "min_pred_length": 19,
        "max_pred_length": 36,
        "distinct-1": 0.5984848484848485,
        "vocab_size-1": 79,
        "unique-1": 60,
        "entropy-1": 5.878151216199807,
        "distinct-2": 0.905511811023622,
        "vocab_size-2": 115,
        "unique-2": 105,
        "entropy-2": 6.787820316659341,
        "cond_entropy-2": 0.8641696834623527,
        "distinct-3": 0.9672131147540983,
        "vocab_size-3": 118,
        "unique-3": 115,
        "entropy-3": 6.8589759645943476,
        "cond_entropy-3": 0.07938779425107644,
        "total_length-nopunct": 114,
        "mean_pred_length-nopunct": 22.8,
        "std_pred_length-nopunct": 3.655133376499413,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6578947368421053,
        "vocab_size-1-nopunct": 75,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.918147251555151,
        "distinct-2-nopunct": 0.9357798165137615,
        "vocab_size-2-nopunct": 102,
        "unique-2-nopunct": 97,
        "entropy-2-nopunct": 6.625892810975753,
        "cond_entropy-2-nopunct": 0.7221833008247261,
        "distinct-3-nopunct": 0.9615384615384616,
        "vocab_size-3-nopunct": 100,
        "unique-3-nopunct": 97,
        "entropy-3-nopunct": 6.6162581075433735,
        "cond_entropy-3-nopunct": -0.012409149884262434,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8854559986066066,
        "bleu": 29.01084,
        "rouge1": {
            "precision": 0.61098,
            "recall": 0.59509,
            "fmeasure": 0.5797
        },
        "rouge2": {
            "precision": 0.39541,
            "recall": 0.42228,
            "fmeasure": 0.39268
        },
        "rougeL": {
            "precision": 0.5006,
            "recall": 0.52544,
            "fmeasure": 0.49525
        },
        "rougeLsum": {
            "precision": 0.5006,
            "recall": 0.52544,
            "fmeasure": 0.49525
        },
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.5238095238095238,
            "3": 0.5733333333333334
        },
        "bertscore": {
            "precision": 0.86713,
            "recall": 0.87036,
            "f1": 0.86743
        },
        "bleurt": -0.29557,
        "meteor": 0.27841796019550885,
        "nubia": {
            "semantic_relation": 2.85415,
            "contradiction": 33.40318,
            "irrelevancy": 43.79868,
            "logical_agreement": 22.79814,
            "grammar_ref": 3.87874,
            "grammar_hyp": 3.7121,
            "nubia_score": 0.40739
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_19": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.79,
        "msttr-100_nopunct": NaN,
        "total_length": 113,
        "mean_pred_length": 22.6,
        "std_pred_length": 7.116178749862878,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 34,
        "distinct-1": 0.7433628318584071,
        "vocab_size-1": 84,
        "unique-1": 71,
        "entropy-1": 6.119661126166778,
        "distinct-2": 0.9629629629629629,
        "vocab_size-2": 104,
        "unique-2": 100,
        "entropy-2": 6.680813428089385,
        "cond_entropy-2": 0.48608701217082395,
        "distinct-3": 0.9902912621359223,
        "vocab_size-3": 102,
        "unique-3": 101,
        "entropy-3": 6.66708305145508,
        "cond_entropy-3": -0.029552023523939524,
        "total_length-nopunct": 95,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 4.857983120596447,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 80,
        "unique-1-nopunct": 71,
        "entropy-1-nopunct": 6.201228766134591,
        "distinct-2-nopunct": 0.9666666666666667,
        "vocab_size-2-nopunct": 87,
        "unique-2-nopunct": 84,
        "entropy-2-nopunct": 6.425186429662996,
        "cond_entropy-2-nopunct": 0.23332582142821423,
        "distinct-3-nopunct": 0.9882352941176471,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 83,
        "entropy-3-nopunct": 6.385861524373001,
        "cond_entropy-3-nopunct": -0.04716804254491415,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.542239444447269,
        "bleu": 18.42031,
        "rouge1": {
            "precision": 0.52971,
            "recall": 0.54941,
            "fmeasure": 0.52616
        },
        "rouge2": {
            "precision": 0.31425,
            "recall": 0.32832,
            "fmeasure": 0.31284
        },
        "rougeL": {
            "precision": 0.47026,
            "recall": 0.48184,
            "fmeasure": 0.46428
        },
        "rougeLsum": {
            "precision": 0.47026,
            "recall": 0.48184,
            "fmeasure": 0.46428
        },
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.45454545454545453,
            "3": 0.6857142857142857
        },
        "bertscore": {
            "precision": 0.86567,
            "recall": 0.8819,
            "f1": 0.87257
        },
        "bleurt": -0.11991,
        "meteor": 0.28747013183451964,
        "nubia": {
            "semantic_relation": 3.27126,
            "contradiction": 28.85444,
            "irrelevancy": 55.81079,
            "logical_agreement": 15.33477,
            "grammar_ref": 5.00025,
            "grammar_hyp": 4.64999,
            "nubia_score": 0.48717
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_20": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.57,
        "msttr-100_nopunct": 0.65,
        "total_length": 174,
        "mean_pred_length": 34.8,
        "std_pred_length": 8.255906976220118,
        "median_pred_length": 34.0,
        "min_pred_length": 24,
        "max_pred_length": 46,
        "distinct-1": 0.5689655172413793,
        "vocab_size-1": 99,
        "unique-1": 75,
        "entropy-1": 6.07745696350935,
        "distinct-2": 0.8757396449704142,
        "vocab_size-2": 148,
        "unique-2": 132,
        "entropy-2": 7.127124036835489,
        "cond_entropy-2": 1.0213699856767833,
        "distinct-3": 0.9634146341463414,
        "vocab_size-3": 158,
        "unique-3": 152,
        "entropy-3": 7.284381272910788,
        "cond_entropy-3": 0.16560343727791435,
        "total_length-nopunct": 140,
        "mean_pred_length-nopunct": 28.0,
        "std_pred_length-nopunct": 7.26636084983398,
        "median_pred_length-nopunct": 31.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.6785714285714286,
        "vocab_size-1-nopunct": 95,
        "unique-1-nopunct": 75,
        "entropy-1-nopunct": 6.257460785171323,
        "distinct-2-nopunct": 0.8888888888888888,
        "vocab_size-2-nopunct": 120,
        "unique-2-nopunct": 108,
        "entropy-2-nopunct": 6.834186800738532,
        "cond_entropy-2-nopunct": 0.594200913040292,
        "distinct-3-nopunct": 0.9538461538461539,
        "vocab_size-3-nopunct": 124,
        "unique-3-nopunct": 118,
        "entropy-3-nopunct": 6.930060120720763,
        "cond_entropy-3-nopunct": 0.0898205813788809,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6027487691831275,
        "bleu": 15.36376,
        "rouge1": {
            "precision": 0.48245,
            "recall": 0.47887,
            "fmeasure": 0.47216
        },
        "rouge2": {
            "precision": 0.1768,
            "recall": 0.17394,
            "fmeasure": 0.17163
        },
        "rougeL": {
            "precision": 0.32241,
            "recall": 0.31554,
            "fmeasure": 0.31097
        },
        "rougeLsum": {
            "precision": 0.32241,
            "recall": 0.31554,
            "fmeasure": 0.31097
        },
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.21875,
            "3": 0.5802469135802469
        },
        "bertscore": {
            "precision": 0.8378,
            "recall": 0.83718,
            "f1": 0.8354
        },
        "bleurt": -0.2144,
        "meteor": 0.2415924507356,
        "nubia": {
            "semantic_relation": 3.19253,
            "contradiction": 10.18377,
            "irrelevancy": 39.12342,
            "logical_agreement": 50.69281,
            "grammar_ref": 4.13756,
            "grammar_hyp": 3.34298,
            "nubia_score": 0.58187
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_21": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": 0.57,
        "msttr-100_nopunct": 0.63,
        "total_length": 136,
        "mean_pred_length": 34.0,
        "std_pred_length": 15.443445211480501,
        "median_pred_length": 36.5,
        "min_pred_length": 10,
        "max_pred_length": 53,
        "distinct-1": 0.5735294117647058,
        "vocab_size-1": 78,
        "unique-1": 60,
        "entropy-1": 5.856153194879735,
        "distinct-2": 0.8560606060606061,
        "vocab_size-2": 113,
        "unique-2": 103,
        "entropy-2": 6.6874288505799315,
        "cond_entropy-2": 0.8079820086205196,
        "distinct-3": 0.9453125,
        "vocab_size-3": 121,
        "unique-3": 117,
        "entropy-3": 6.869102441389348,
        "cond_entropy-3": 0.19282875545873565,
        "total_length-nopunct": 113,
        "mean_pred_length-nopunct": 28.25,
        "std_pred_length-nopunct": 11.299889379989523,
        "median_pred_length-nopunct": 33.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.6460176991150443,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 5.82691497164062,
        "distinct-2-nopunct": 0.8899082568807339,
        "vocab_size-2-nopunct": 97,
        "unique-2-nopunct": 91,
        "entropy-2-nopunct": 6.489610673615445,
        "cond_entropy-2-nopunct": 0.6991457566821713,
        "distinct-3-nopunct": 0.9619047619047619,
        "vocab_size-3-nopunct": 101,
        "unique-3-nopunct": 99,
        "entropy-3-nopunct": 6.619007422428018,
        "cond_entropy-3-nopunct": 0.14000907838062726,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.799331556437554,
        "bleu": 20.08188,
        "rouge1": {
            "precision": 0.64279,
            "recall": 0.6462,
            "fmeasure": 0.64246
        },
        "rouge2": {
            "precision": 0.35776,
            "recall": 0.36771,
            "fmeasure": 0.36172
        },
        "rougeL": {
            "precision": 0.53261,
            "recall": 0.53558,
            "fmeasure": 0.53285
        },
        "rougeLsum": {
            "precision": 0.53261,
            "recall": 0.53558,
            "fmeasure": 0.53285
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6309523809523809
        },
        "bertscore": {
            "precision": 0.87981,
            "recall": 0.87008,
            "f1": 0.87428
        },
        "bleurt": 0.05236,
        "meteor": 0.2797920462588792,
        "nubia": {
            "semantic_relation": 3.13745,
            "contradiction": 48.43056,
            "irrelevancy": 48.76943,
            "logical_agreement": 2.80001,
            "grammar_ref": 3.12827,
            "grammar_hyp": 3.04329,
            "nubia_score": 0.51033
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_22": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.37021006579631555,
        "bleu": 13.42826,
        "rouge1": {
            "precision": 0.51515,
            "recall": 0.36905,
            "fmeasure": 0.42753
        },
        "rouge2": {
            "precision": 0.26667,
            "recall": 0.18893,
            "fmeasure": 0.21989
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.24048,
            "fmeasure": 0.27785
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.24048,
            "fmeasure": 0.27785
        },
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.0,
            "3": 0.5555555555555556
        },
        "bertscore": {
            "precision": 0.91794,
            "recall": 0.89896,
            "f1": 0.90835
        },
        "bleurt": 0.16608,
        "meteor": 0.21919465372151856,
        "nubia": {
            "semantic_relation": 3.84515,
            "contradiction": 2.98936,
            "irrelevancy": 31.11697,
            "logical_agreement": 65.89367,
            "grammar_ref": 4.03834,
            "grammar_hyp": 4.27539,
            "nubia_score": 0.58292
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_23": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 65,
        "mean_pred_length": 32.5,
        "std_pred_length": 0.5,
        "median_pred_length": 32.5,
        "min_pred_length": 32,
        "max_pred_length": 33,
        "distinct-1": 0.6923076923076923,
        "vocab_size-1": 45,
        "unique-1": 34,
        "entropy-1": 5.222121467936095,
        "distinct-2": 0.9206349206349206,
        "vocab_size-2": 58,
        "unique-2": 53,
        "entropy-2": 5.8185497647697595,
        "cond_entropy-2": 0.5900869109635811,
        "distinct-3": 0.9672131147540983,
        "vocab_size-3": 59,
        "unique-3": 57,
        "entropy-3": 5.865163567071081,
        "cond_entropy-3": 0.051818069800674674,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 28.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 28.0,
        "min_pred_length-nopunct": 26,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.7678571428571429,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.265131208189746,
        "distinct-2-nopunct": 0.9259259259259259,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.60673935401532,
        "cond_entropy-2-nopunct": 0.3431719870799438,
        "distinct-3-nopunct": 0.9615384615384616,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.623516641218018,
        "cond_entropy-3-nopunct": 0.0032445236699311804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5719964331107197,
        "bleu": 13.08465,
        "rouge1": {
            "precision": 0.5872,
            "recall": 0.64778,
            "fmeasure": 0.60954
        },
        "rouge2": {
            "precision": 0.285,
            "recall": 0.33124,
            "fmeasure": 0.30316
        },
        "rougeL": {
            "precision": 0.3992,
            "recall": 0.49221,
            "fmeasure": 0.43972
        },
        "rougeLsum": {
            "precision": 0.3992,
            "recall": 0.49221,
            "fmeasure": 0.43972
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.7142857142857143,
            "3": 0.5789473684210527
        },
        "bertscore": {
            "precision": 0.89426,
            "recall": 0.8981,
            "f1": 0.89581
        },
        "bleurt": -0.00287,
        "meteor": 0.30007815198048293,
        "nubia": {
            "semantic_relation": 3.04723,
            "contradiction": 92.80748,
            "irrelevancy": 3.92135,
            "logical_agreement": 3.27117,
            "grammar_ref": 4.17,
            "grammar_hyp": 3.89322,
            "nubia_score": 0.4692
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_24": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": 0.62,
        "msttr-100_nopunct": NaN,
        "total_length": 125,
        "mean_pred_length": 31.25,
        "std_pred_length": 14.972892172189045,
        "median_pred_length": 33.0,
        "min_pred_length": 11,
        "max_pred_length": 48,
        "distinct-1": 0.584,
        "vocab_size-1": 73,
        "unique-1": 60,
        "entropy-1": 5.605065234478276,
        "distinct-2": 0.859504132231405,
        "vocab_size-2": 104,
        "unique-2": 98,
        "entropy-2": 6.503452803336662,
        "cond_entropy-2": 0.8772543143190087,
        "distinct-3": 0.9743589743589743,
        "vocab_size-3": 114,
        "unique-3": 111,
        "entropy-3": 6.819082668301334,
        "cond_entropy-3": 0.3298319310822324,
        "total_length-nopunct": 92,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 10.36822067666386,
        "median_pred_length-nopunct": 21.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.7391304347826086,
        "vocab_size-1-nopunct": 68,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 5.768301701107412,
        "distinct-2-nopunct": 0.9659090909090909,
        "vocab_size-2-nopunct": 85,
        "unique-2-nopunct": 83,
        "entropy-2-nopunct": 6.382671533385447,
        "cond_entropy-2-nopunct": 0.6109506609702077,
        "distinct-3-nopunct": 0.9880952380952381,
        "vocab_size-3-nopunct": 83,
        "unique-3-nopunct": 82,
        "entropy-3-nopunct": 6.368507898969236,
        "cond_entropy-3-nopunct": -0.010508392261352629,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.161156507427987,
        "bleu": 42.81342,
        "rouge1": {
            "precision": 0.7022,
            "recall": 0.53135,
            "fmeasure": 0.54961
        },
        "rouge2": {
            "precision": 0.47157,
            "recall": 0.37155,
            "fmeasure": 0.37475
        },
        "rougeL": {
            "precision": 0.6239,
            "recall": 0.51253,
            "fmeasure": 0.50739
        },
        "rougeLsum": {
            "precision": 0.6239,
            "recall": 0.51253,
            "fmeasure": 0.50739
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.4090909090909091,
            "3": 0.5263157894736842
        },
        "bertscore": {
            "precision": 0.86879,
            "recall": 0.86551,
            "f1": 0.86269
        },
        "bleurt": -0.25087,
        "meteor": 0.28656636315672235,
        "nubia": {
            "semantic_relation": 3.31617,
            "contradiction": 8.50603,
            "irrelevancy": 14.30522,
            "logical_agreement": 77.18875,
            "grammar_ref": 4.25341,
            "grammar_hyp": 4.37835,
            "nubia_score": 0.40882
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_25": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3096376853108196,
        "bleu": 22.49471,
        "rouge1": {
            "precision": 0.70588,
            "recall": 0.75,
            "fmeasure": 0.72727
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.4,
            "fmeasure": 0.3871
        },
        "rougeL": {
            "precision": 0.58824,
            "recall": 0.625,
            "fmeasure": 0.60606
        },
        "rougeLsum": {
            "precision": 0.58824,
            "recall": 0.625,
            "fmeasure": 0.60606
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.93155,
            "recall": 0.93446,
            "f1": 0.933
        },
        "bleurt": 0.2586,
        "meteor": 0.35191264374342507,
        "nubia": {
            "semantic_relation": 4.26743,
            "contradiction": 0.08616,
            "irrelevancy": 44.32118,
            "logical_agreement": 55.59267,
            "grammar_ref": 3.92881,
            "grammar_hyp": 3.39223,
            "nubia_score": 0.88674
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_32": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 49,
        "msttr-100": 0.7025,
        "msttr-100_nopunct": 0.75857,
        "total_length": 863,
        "mean_pred_length": 17.612244897959183,
        "std_pred_length": 7.053198222403421,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 34,
        "distinct-1": 0.5283893395133256,
        "vocab_size-1": 456,
        "unique-1": 372,
        "entropy-1": 7.7756141844968925,
        "distinct-2": 0.9103194103194103,
        "vocab_size-2": 741,
        "unique-2": 701,
        "entropy-2": 9.419858705988934,
        "cond_entropy-2": 1.4235486644533253,
        "distinct-3": 0.9777777777777777,
        "vocab_size-3": 748,
        "unique-3": 734,
        "entropy-3": 9.53191114998996,
        "cond_entropy-3": 0.10610133306416351,
        "total_length-nopunct": 746,
        "mean_pred_length-nopunct": 15.224489795918368,
        "std_pred_length-nopunct": 5.908365933572321,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.599195710455764,
        "vocab_size-1-nopunct": 447,
        "unique-1-nopunct": 369,
        "entropy-1-nopunct": 7.974473589229783,
        "distinct-2-nopunct": 0.9253945480631277,
        "vocab_size-2-nopunct": 645,
        "unique-2-nopunct": 618,
        "entropy-2-nopunct": 9.224515792053507,
        "cond_entropy-2-nopunct": 1.3259884593754563,
        "distinct-3-nopunct": 0.9845679012345679,
        "vocab_size-3-nopunct": 638,
        "unique-3-nopunct": 629,
        "entropy-3-nopunct": 9.307820855504675,
        "cond_entropy-3-nopunct": 0.0926408136592978,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.901476217950471,
        "bleu": 45.07704,
        "rouge1": {
            "precision": 0.78021,
            "recall": 0.70786,
            "fmeasure": 0.72939
        },
        "rouge2": {
            "precision": 0.54779,
            "recall": 0.49256,
            "fmeasure": 0.50881
        },
        "rougeL": {
            "precision": 0.68089,
            "recall": 0.61805,
            "fmeasure": 0.6353
        },
        "rougeLsum": {
            "precision": 0.68089,
            "recall": 0.61805,
            "fmeasure": 0.6353
        },
        "local_recall": {
            "1": 0.22164948453608246,
            "2": 0.4046242774566474,
            "3": 0.7741935483870968
        },
        "bertscore": {
            "precision": 0.93205,
            "recall": 0.91481,
            "f1": 0.92141
        },
        "bleurt": 0.23316,
        "meteor": 0.3741966911475459,
        "nubia": {
            "semantic_relation": 4.25649,
            "contradiction": 5.13113,
            "irrelevancy": 24.76329,
            "logical_agreement": 70.10558,
            "grammar_ref": 4.75318,
            "grammar_hyp": 4.90432,
            "nubia_score": 0.72981
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_27": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 26.5,
        "std_pred_length": 8.5,
        "median_pred_length": 26.5,
        "min_pred_length": 18,
        "max_pred_length": 35,
        "distinct-1": 0.7169811320754716,
        "vocab_size-1": 38,
        "unique-1": 31,
        "entropy-1": 4.874726474395771,
        "distinct-2": 0.9607843137254902,
        "vocab_size-2": 49,
        "unique-2": 47,
        "entropy-2": 5.59399396942248,
        "cond_entropy-2": 0.7135103962097394,
        "distinct-3": 1.0,
        "vocab_size-3": 49,
        "unique-3": 49,
        "entropy-3": 5.614709844115208,
        "cond_entropy-3": 0.023917155204937358,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 20.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 20.5,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8780487804878049,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.1136495655936915,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.285402218862247,
        "cond_entropy-2-nopunct": 0.18426047065442136,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.07594885323329875,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6650254927226276,
        "bleu": 15.80871,
        "rouge1": {
            "precision": 0.44853,
            "recall": 0.65656,
            "fmeasure": 0.52122
        },
        "rouge2": {
            "precision": 0.27355,
            "recall": 0.43803,
            "fmeasure": 0.32938
        },
        "rougeL": {
            "precision": 0.44158,
            "recall": 0.67323,
            "fmeasure": 0.51895
        },
        "rougeLsum": {
            "precision": 0.44158,
            "recall": 0.67323,
            "fmeasure": 0.51895
        },
        "local_recall": {
            "1": 0.36363636363636365,
            "2": 0.0,
            "3": 0.6111111111111112
        },
        "bertscore": {
            "precision": 0.81219,
            "recall": 0.90278,
            "f1": 0.83906
        },
        "bleurt": -0.10117,
        "meteor": 0.2728073053328462,
        "nubia": {
            "semantic_relation": 3.79287,
            "contradiction": 15.35285,
            "irrelevancy": 74.29729,
            "logical_agreement": 10.34986,
            "grammar_ref": 5.41182,
            "grammar_hyp": 4.62707,
            "nubia_score": 0.47615
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_51": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.78,
        "total_length": 169,
        "mean_pred_length": 15.363636363636363,
        "std_pred_length": 4.436885215240883,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.6627218934911243,
        "vocab_size-1": 112,
        "unique-1": 97,
        "entropy-1": 6.277446239963631,
        "distinct-2": 0.9556962025316456,
        "vocab_size-2": 151,
        "unique-2": 147,
        "entropy-2": 7.192327327452834,
        "cond_entropy-2": 0.752248285935347,
        "distinct-3": 1.0,
        "vocab_size-3": 147,
        "unique-3": 147,
        "entropy-3": 7.199672344836354,
        "cond_entropy-3": 0.015685069274477763,
        "total_length-nopunct": 148,
        "mean_pred_length-nopunct": 13.454545454545455,
        "std_pred_length-nopunct": 4.0757294129927075,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.722972972972973,
        "vocab_size-1-nopunct": 107,
        "unique-1-nopunct": 95,
        "entropy-1-nopunct": 6.302043315841803,
        "distinct-2-nopunct": 0.9562043795620438,
        "vocab_size-2-nopunct": 131,
        "unique-2-nopunct": 128,
        "entropy-2-nopunct": 6.984093101395279,
        "cond_entropy-2-nopunct": 0.7476082567042833,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 126,
        "unique-3-nopunct": 126,
        "entropy-3-nopunct": 6.977279923499926,
        "cond_entropy-3-nopunct": 0.003133876050793139,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.97295661863084,
        "bleu": 56.4178,
        "rouge1": {
            "precision": 0.73254,
            "recall": 0.74168,
            "fmeasure": 0.72518
        },
        "rouge2": {
            "precision": 0.59468,
            "recall": 0.60845,
            "fmeasure": 0.59001
        },
        "rougeL": {
            "precision": 0.66294,
            "recall": 0.6953,
            "fmeasure": 0.66488
        },
        "rougeLsum": {
            "precision": 0.66294,
            "recall": 0.6953,
            "fmeasure": 0.66488
        },
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.5806451612903226,
            "3": 0.7934782608695652
        },
        "bertscore": {
            "precision": 0.93163,
            "recall": 0.93943,
            "f1": 0.93341
        },
        "bleurt": 0.26851,
        "meteor": 0.4289256205771156,
        "nubia": {
            "semantic_relation": 4.09007,
            "contradiction": 17.77044,
            "irrelevancy": 35.70709,
            "logical_agreement": 46.52248,
            "grammar_ref": 4.58752,
            "grammar_hyp": 4.29432,
            "nubia_score": 0.72294
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 213,
        "msttr-100": 0.62775,
        "msttr-100_nopunct": 0.66222,
        "total_length": 8058,
        "mean_pred_length": 37.83098591549296,
        "std_pred_length": 8.155160667138563,
        "median_pred_length": 38.0,
        "min_pred_length": 17,
        "max_pred_length": 60,
        "distinct-1": 0.14271531397369075,
        "vocab_size-1": 1150,
        "unique-1": 425,
        "entropy-1": 7.8878115478983775,
        "distinct-2": 0.39451880178457616,
        "vocab_size-2": 3095,
        "unique-2": 1805,
        "entropy-2": 10.774621016896443,
        "cond_entropy-2": 2.7831332855222994,
        "distinct-3": 0.5826781970649895,
        "vocab_size-3": 4447,
        "unique-3": 3111,
        "entropy-3": 11.704802343170131,
        "cond_entropy-3": 0.9563472195443907,
        "total_length-nopunct": 7217,
        "mean_pred_length-nopunct": 33.882629107981224,
        "std_pred_length-nopunct": 7.4152696561694045,
        "median_pred_length-nopunct": 34.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 52,
        "distinct-1-nopunct": 0.1579603713454344,
        "vocab_size-1-nopunct": 1140,
        "unique-1-nopunct": 424,
        "entropy-1-nopunct": 8.11727884810681,
        "distinct-2-nopunct": 0.4133352370074243,
        "vocab_size-2-nopunct": 2895,
        "unique-2-nopunct": 1736,
        "entropy-2-nopunct": 10.728594819426144,
        "cond_entropy-2-nopunct": 2.6924335183356956,
        "distinct-3-nopunct": 0.6012369312325136,
        "vocab_size-3-nopunct": 4083,
        "unique-3-nopunct": 2919,
        "entropy-3-nopunct": 11.603135072706989,
        "cond_entropy-3-nopunct": 0.8999990076619878,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.184036821979787,
        "bleu": 36.41631,
        "rouge1": {
            "precision": 0.64441,
            "recall": 0.65487,
            "fmeasure": 0.64395
        },
        "rouge2": {
            "precision": 0.35801,
            "recall": 0.3582,
            "fmeasure": 0.35467
        },
        "rougeL": {
            "precision": 0.45984,
            "recall": 0.46576,
            "fmeasure": 0.45878
        },
        "rougeLsum": {
            "precision": 0.45984,
            "recall": 0.46576,
            "fmeasure": 0.45878
        },
        "local_recall": {
            "1": 0.21871750433275564,
            "2": 0.4990814451928965,
            "3": 0.7800518881522053
        },
        "bertscore": {
            "precision": 0.88238,
            "recall": 0.88429,
            "f1": 0.88213
        },
        "bleurt": -0.14061,
        "meteor": 0.3227796348932413,
        "nubia": {
            "semantic_relation": 3.81979,
            "contradiction": 28.66367,
            "irrelevancy": 12.42686,
            "logical_agreement": 58.90946,
            "grammar_ref": 4.14495,
            "grammar_hyp": 4.25852,
            "nubia_score": 0.63126
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05_parent": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72887,
        "msttr-100_nopunct": 0.76984,
        "total_length": 7160,
        "mean_pred_length": 19.944289693593316,
        "std_pred_length": 9.41268121583602,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 48,
        "distinct-1": 0.3741620111731844,
        "vocab_size-1": 2679,
        "unique-1": 1984,
        "entropy-1": 9.194120336853468,
        "distinct-2": 0.8406116747537127,
        "vocab_size-2": 5717,
        "unique-2": 5300,
        "entropy-2": 12.170006454560234,
        "cond_entropy-2": 2.710443523538477,
        "distinct-3": 0.9649177274138466,
        "vocab_size-3": 6216,
        "unique-3": 6107,
        "entropy-3": 12.534020277527619,
        "cond_entropy-3": 0.3791397457703247,
        "total_length-nopunct": 6345,
        "mean_pred_length-nopunct": 17.67409470752089,
        "std_pred_length-nopunct": 8.372735478286602,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.42048857368006304,
        "vocab_size-1-nopunct": 2668,
        "unique-1-nopunct": 1983,
        "entropy-1-nopunct": 9.54860391112204,
        "distinct-2-nopunct": 0.8591713999331774,
        "vocab_size-2-nopunct": 5143,
        "unique-2-nopunct": 4793,
        "entropy-2-nopunct": 12.065182536129276,
        "cond_entropy-2-nopunct": 2.6572962540486684,
        "distinct-3-nopunct": 0.9781411053847521,
        "vocab_size-3-nopunct": 5504,
        "unique-3-nopunct": 5417,
        "entropy-3-nopunct": 12.405641990946366,
        "cond_entropy-3-nopunct": 0.3650903204318789,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 13.27357163033192,
        "bleu": 85.75591,
        "rouge1": {
            "precision": 0.89371,
            "recall": 0.86896,
            "fmeasure": 0.87162
        },
        "rouge2": {
            "precision": 0.79569,
            "recall": 0.77545,
            "fmeasure": 0.7738
        },
        "rougeL": {
            "precision": 0.87917,
            "recall": 0.85515,
            "fmeasure": 0.85744
        },
        "rougeLsum": {
            "precision": 0.87917,
            "recall": 0.85515,
            "fmeasure": 0.85744
        },
        "local_recall": {
            "1": 0.030871003307607496,
            "2": 0.15498652291105122,
            "3": 0.3674698795180723,
            "4": 0.5565749235474006,
            "5": 0.6874051593323217,
            "6": 0.7633802816901408,
            "7": 0.825136612021858,
            "8": 0.864897466827503,
            "9": 0.8952380952380953,
            "10": 0.9441860465116279
        },
        "bertscore": {
            "precision": 0.96941,
            "recall": 0.96601,
            "f1": 0.96505
        },
        "bleurt": 0.23178,
        "meteor": 0.5255935126956474,
        "nubia": {
            "semantic_relation": 4.24493,
            "contradiction": 3.00277,
            "irrelevancy": 30.91127,
            "logical_agreement": 66.08596,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.82083,
            "nubia_score": 0.65288
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc_parent": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72887,
        "msttr-100_nopunct": 0.76984,
        "total_length": 7160,
        "mean_pred_length": 19.944289693593316,
        "std_pred_length": 9.41268121583602,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 48,
        "distinct-1": 0.3741620111731844,
        "vocab_size-1": 2679,
        "unique-1": 1984,
        "entropy-1": 9.194120336853468,
        "distinct-2": 0.8406116747537127,
        "vocab_size-2": 5717,
        "unique-2": 5300,
        "entropy-2": 12.170006454560234,
        "cond_entropy-2": 2.710443523538477,
        "distinct-3": 0.9649177274138466,
        "vocab_size-3": 6216,
        "unique-3": 6107,
        "entropy-3": 12.534020277527619,
        "cond_entropy-3": 0.3791397457703247,
        "total_length-nopunct": 6345,
        "mean_pred_length-nopunct": 17.67409470752089,
        "std_pred_length-nopunct": 8.372735478286602,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.42048857368006304,
        "vocab_size-1-nopunct": 2668,
        "unique-1-nopunct": 1983,
        "entropy-1-nopunct": 9.54860391112204,
        "distinct-2-nopunct": 0.8591713999331774,
        "vocab_size-2-nopunct": 5143,
        "unique-2-nopunct": 4793,
        "entropy-2-nopunct": 12.065182536129276,
        "cond_entropy-2-nopunct": 2.6572962540486684,
        "distinct-3-nopunct": 0.9781411053847521,
        "vocab_size-3-nopunct": 5504,
        "unique-3-nopunct": 5417,
        "entropy-3-nopunct": 12.405641990946366,
        "cond_entropy-3-nopunct": 0.3650903204318789,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "nist": 13.27357163033192,
        "bleu": 85.75591,
        "rouge1": {
            "precision": 0.89371,
            "recall": 0.86896,
            "fmeasure": 0.87162
        },
        "rouge2": {
            "precision": 0.79569,
            "recall": 0.77545,
            "fmeasure": 0.7738
        },
        "rougeL": {
            "precision": 0.87917,
            "recall": 0.85515,
            "fmeasure": 0.85744
        },
        "rougeLsum": {
            "precision": 0.87917,
            "recall": 0.85515,
            "fmeasure": 0.85744
        },
        "local_recall": {
            "1": 0.030871003307607496,
            "2": 0.15498652291105122,
            "3": 0.3674698795180723,
            "4": 0.5565749235474006,
            "5": 0.6874051593323217,
            "6": 0.7633802816901408,
            "7": 0.825136612021858,
            "8": 0.864897466827503,
            "9": 0.8952380952380953,
            "10": 0.9441860465116279
        },
        "bertscore": {
            "precision": 0.96941,
            "recall": 0.96601,
            "f1": 0.96505
        },
        "bleurt": 0.23178,
        "meteor": 0.5255935126956474,
        "nubia": {
            "semantic_relation": 4.24493,
            "contradiction": 3.00277,
            "irrelevancy": 30.91127,
            "logical_agreement": 66.08596,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.82083,
            "nubia_score": 0.65288
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_52": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 43,
        "msttr-100": 0.72667,
        "msttr-100_nopunct": 0.792,
        "total_length": 679,
        "mean_pred_length": 15.790697674418604,
        "std_pred_length": 5.372445372518204,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.5331369661266568,
        "vocab_size-1": 362,
        "unique-1": 289,
        "entropy-1": 7.511262425201642,
        "distinct-2": 0.8867924528301887,
        "vocab_size-2": 564,
        "unique-2": 512,
        "entropy-2": 9.050405444325817,
        "cond_entropy-2": 1.3004619580027241,
        "distinct-3": 0.9494097807757167,
        "vocab_size-3": 563,
        "unique-3": 537,
        "entropy-3": 9.103962493534153,
        "cond_entropy-3": 0.04433554072435352,
        "total_length-nopunct": 586,
        "mean_pred_length-nopunct": 13.627906976744185,
        "std_pred_length-nopunct": 4.635671877817554,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6040955631399317,
        "vocab_size-1-nopunct": 354,
        "unique-1-nopunct": 287,
        "entropy-1-nopunct": 7.703550697278259,
        "distinct-2-nopunct": 0.9023941068139963,
        "vocab_size-2-nopunct": 490,
        "unique-2-nopunct": 452,
        "entropy-2-nopunct": 8.855211639253609,
        "cond_entropy-2-nopunct": 1.212935784977227,
        "distinct-3-nopunct": 0.962,
        "vocab_size-3-nopunct": 481,
        "unique-3-nopunct": 464,
        "entropy-3-nopunct": 8.885784284662021,
        "cond_entropy-3-nopunct": 0.01963826577807027,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.12780469636881,
        "bleu": 55.96884,
        "rouge1": {
            "precision": 0.80161,
            "recall": 0.79144,
            "fmeasure": 0.78792
        },
        "rouge2": {
            "precision": 0.61027,
            "recall": 0.60514,
            "fmeasure": 0.60174
        },
        "rougeL": {
            "precision": 0.71431,
            "recall": 0.71648,
            "fmeasure": 0.70691
        },
        "rougeLsum": {
            "precision": 0.71431,
            "recall": 0.71648,
            "fmeasure": 0.70691
        },
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.44360902255639095,
            "3": 0.8443396226415094
        },
        "bertscore": {
            "precision": 0.93764,
            "recall": 0.94033,
            "f1": 0.93687
        },
        "bleurt": 0.34578,
        "meteor": 0.42894414322051777,
        "nubia": {
            "semantic_relation": 4.29632,
            "contradiction": 8.44989,
            "irrelevancy": 26.07058,
            "logical_agreement": 65.47953,
            "grammar_ref": 4.51918,
            "grammar_hyp": 4.46894,
            "nubia_score": 0.75716
        }
    },
    "totto_test_contrast_challenge_gender-female": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 300,
        "msttr-100": 0.69788,
        "msttr-100_nopunct": 0.7437,
        "total_length": 5292,
        "mean_pred_length": 17.64,
        "std_pred_length": 6.717916343629176,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 55,
        "distinct-1": 0.3592214663643235,
        "vocab_size-1": 1901,
        "unique-1": 1511,
        "entropy-1": 8.567181516474683,
        "distinct-2": 0.7293669871794872,
        "vocab_size-2": 3641,
        "unique-2": 3232,
        "entropy-2": 11.308944562611153,
        "cond_entropy-2": 2.474890560940633,
        "distinct-3": 0.8859761295822677,
        "vocab_size-3": 4157,
        "unique-3": 3901,
        "entropy-3": 11.884116497777548,
        "cond_entropy-3": 0.5598435943122737,
        "total_length-nopunct": 4606,
        "mean_pred_length-nopunct": 15.353333333333333,
        "std_pred_length-nopunct": 5.6992826059270145,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.41033434650455924,
        "vocab_size-1-nopunct": 1890,
        "unique-1-nopunct": 1506,
        "entropy-1-nopunct": 8.912541257016036,
        "distinct-2-nopunct": 0.7522062238736646,
        "vocab_size-2-nopunct": 3239,
        "unique-2-nopunct": 2925,
        "entropy-2-nopunct": 11.15922278616904,
        "cond_entropy-2-nopunct": 2.374818184783169,
        "distinct-3-nopunct": 0.899400898652022,
        "vocab_size-3-nopunct": 3603,
        "unique-3-nopunct": 3408,
        "entropy-3-nopunct": 11.693249894444868,
        "cond_entropy-3-nopunct": 0.5847092995235422,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.822518174468977,
        "bleu": 48.08351,
        "rouge1": {
            "precision": 0.81861,
            "recall": 0.77211,
            "fmeasure": 0.78561
        },
        "rouge2": {
            "precision": 0.58209,
            "recall": 0.54931,
            "fmeasure": 0.55862
        },
        "rougeL": {
            "precision": 0.70348,
            "recall": 0.66373,
            "fmeasure": 0.675
        },
        "rougeLsum": {
            "precision": 0.70348,
            "recall": 0.66373,
            "fmeasure": 0.675
        },
        "local_recall": {
            "1": 0.21906923950056753,
            "2": 0.365819209039548,
            "3": 0.804442036836403
        },
        "bertscore": {
            "precision": 0.94075,
            "recall": 0.93575,
            "f1": 0.9369
        },
        "bleurt": 0.3433,
        "meteor": 0.41167376773751324,
        "nubia": {
            "semantic_relation": 4.45084,
            "contradiction": 4.16264,
            "irrelevancy": 26.33823,
            "logical_agreement": 69.49914,
            "grammar_ref": 4.91577,
            "grammar_hyp": 4.95801,
            "nubia_score": 0.78253
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 349,
        "msttr-100": 0.63317,
        "msttr-100_nopunct": 0.68873,
        "total_length": 6375,
        "mean_pred_length": 18.266475644699142,
        "std_pred_length": 5.019793990294245,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 55,
        "distinct-1": 0.1700392156862745,
        "vocab_size-1": 1084,
        "unique-1": 485,
        "entropy-1": 7.708233135419424,
        "distinct-2": 0.4376037172253568,
        "vocab_size-2": 2637,
        "unique-2": 1634,
        "entropy-2": 10.59964112445751,
        "cond_entropy-2": 2.684426013078995,
        "distinct-3": 0.6279725206975515,
        "vocab_size-3": 3565,
        "unique-3": 2636,
        "entropy-3": 11.415590146960575,
        "cond_entropy-3": 0.8853576385021976,
        "total_length-nopunct": 5582,
        "mean_pred_length-nopunct": 15.994269340974212,
        "std_pred_length-nopunct": 4.4490070166969575,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.19276245073450377,
        "vocab_size-1-nopunct": 1076,
        "unique-1-nopunct": 484,
        "entropy-1-nopunct": 7.999913708574979,
        "distinct-2-nopunct": 0.4416204853812345,
        "vocab_size-2-nopunct": 2311,
        "unique-2-nopunct": 1446,
        "entropy-2-nopunct": 10.431066627500677,
        "cond_entropy-2-nopunct": 2.602664598843333,
        "distinct-3-nopunct": 0.6304258804258804,
        "vocab_size-3-nopunct": 3079,
        "unique-3-nopunct": 2291,
        "entropy-3-nopunct": 11.207651342418906,
        "cond_entropy-3-nopunct": 0.8401331394318089,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.36513283487409,
        "bleu": 39.63652,
        "rouge1": {
            "precision": 0.68314,
            "recall": 0.71185,
            "fmeasure": 0.69092
        },
        "rouge2": {
            "precision": 0.42955,
            "recall": 0.44798,
            "fmeasure": 0.43402
        },
        "rougeL": {
            "precision": 0.56104,
            "recall": 0.58381,
            "fmeasure": 0.56637
        },
        "rougeLsum": {
            "precision": 0.56104,
            "recall": 0.58381,
            "fmeasure": 0.56637
        },
        "local_recall": {
            "1": 0.23138191955396256,
            "2": 0.5464959568733153,
            "3": 0.7881066302118934,
            "4": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.89876,
            "recall": 0.90694,
            "f1": 0.90153
        },
        "bleurt": 0.01364,
        "meteor": 0.36553326996579244,
        "nubia": {
            "semantic_relation": 4.1506,
            "contradiction": 22.31843,
            "irrelevancy": 7.22671,
            "logical_agreement": 70.45486,
            "grammar_ref": 4.75348,
            "grammar_hyp": 4.82983,
            "nubia_score": 0.69274
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 158,
        "msttr-100": 0.53397,
        "msttr-100_nopunct": 0.54158,
        "total_length": 6391,
        "mean_pred_length": 40.449367088607595,
        "std_pred_length": 10.379841385799683,
        "median_pred_length": 40.0,
        "min_pred_length": 17,
        "max_pred_length": 70,
        "distinct-1": 0.14833359411672664,
        "vocab_size-1": 948,
        "unique-1": 345,
        "entropy-1": 7.7346847379860675,
        "distinct-2": 0.3759024546767207,
        "vocab_size-2": 2343,
        "unique-2": 1282,
        "entropy-2": 10.40104746369778,
        "cond_entropy-2": 2.575762706595823,
        "distinct-3": 0.5417283950617284,
        "vocab_size-3": 3291,
        "unique-3": 2182,
        "entropy-3": 11.21549488031444,
        "cond_entropy-3": 0.8417981967306941,
        "total_length-nopunct": 5700,
        "mean_pred_length-nopunct": 36.075949367088604,
        "std_pred_length-nopunct": 9.047374822969905,
        "median_pred_length-nopunct": 36.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.16456140350877194,
        "vocab_size-1-nopunct": 938,
        "unique-1-nopunct": 345,
        "entropy-1-nopunct": 7.9384165368508235,
        "distinct-2-nopunct": 0.3949837603753158,
        "vocab_size-2-nopunct": 2189,
        "unique-2-nopunct": 1239,
        "entropy-2-nopunct": 10.349236609023775,
        "cond_entropy-2-nopunct": 2.485984109903058,
        "distinct-3-nopunct": 0.5611069836552749,
        "vocab_size-3-nopunct": 3021,
        "unique-3-nopunct": 2055,
        "entropy-3-nopunct": 11.114173005131084,
        "cond_entropy-3-nopunct": 0.790635556303122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.034992025967347,
        "bleu": 38.49716,
        "rouge1": {
            "precision": 0.64401,
            "recall": 0.64843,
            "fmeasure": 0.64055
        },
        "rouge2": {
            "precision": 0.36605,
            "recall": 0.36147,
            "fmeasure": 0.36042
        },
        "rougeL": {
            "precision": 0.45948,
            "recall": 0.46343,
            "fmeasure": 0.45748
        },
        "rougeLsum": {
            "precision": 0.45948,
            "recall": 0.46343,
            "fmeasure": 0.45748
        },
        "local_recall": {
            "1": 0.22506738544474394,
            "2": 0.4691252144082333,
            "3": 0.7808170515097691
        },
        "bertscore": {
            "precision": 0.88031,
            "recall": 0.88069,
            "f1": 0.87915
        },
        "bleurt": -0.18335,
        "meteor": 0.3205323341331944,
        "nubia": {
            "semantic_relation": 3.72136,
            "contradiction": 29.9931,
            "irrelevancy": 12.18005,
            "logical_agreement": 57.82685,
            "grammar_ref": 4.0976,
            "grammar_hyp": 4.24056,
            "nubia_score": 0.61961
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_72": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 76,
        "msttr-100": 0.74273,
        "msttr-100_nopunct": 0.789,
        "total_length": 1185,
        "mean_pred_length": 15.592105263157896,
        "std_pred_length": 6.306174149987637,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 38,
        "distinct-1": 0.5223628691983122,
        "vocab_size-1": 619,
        "unique-1": 507,
        "entropy-1": 8.071744268987967,
        "distinct-2": 0.9044183949504058,
        "vocab_size-2": 1003,
        "unique-2": 943,
        "entropy-2": 9.866581155329072,
        "cond_entropy-2": 1.5132462340984838,
        "distinct-3": 0.9777347531461762,
        "vocab_size-3": 1010,
        "unique-3": 993,
        "entropy-3": 9.962407401419744,
        "cond_entropy-3": 0.09245608310012954,
        "total_length-nopunct": 1032,
        "mean_pred_length-nopunct": 13.578947368421053,
        "std_pred_length-nopunct": 5.596669963598036,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.5930232558139535,
        "vocab_size-1-nopunct": 612,
        "unique-1-nopunct": 506,
        "entropy-1-nopunct": 8.354576923429374,
        "distinct-2-nopunct": 0.9152719665271967,
        "vocab_size-2-nopunct": 875,
        "unique-2-nopunct": 828,
        "entropy-2-nopunct": 9.677743297717356,
        "cond_entropy-2-nopunct": 1.4083440583281375,
        "distinct-3-nopunct": 0.9806818181818182,
        "vocab_size-3-nopunct": 863,
        "unique-3-nopunct": 849,
        "entropy-3-nopunct": 9.740149869767217,
        "cond_entropy-3-nopunct": 0.07826723884548,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.800339846011382,
        "bleu": 40.49648,
        "rouge1": {
            "precision": 0.74272,
            "recall": 0.69802,
            "fmeasure": 0.70506
        },
        "rouge2": {
            "precision": 0.49817,
            "recall": 0.4699,
            "fmeasure": 0.47179
        },
        "rougeL": {
            "precision": 0.6405,
            "recall": 0.6105,
            "fmeasure": 0.61267
        },
        "rougeLsum": {
            "precision": 0.6405,
            "recall": 0.6105,
            "fmeasure": 0.61267
        },
        "local_recall": {
            "1": 0.17725752508361203,
            "2": 0.47560975609756095,
            "3": 0.7340720221606648
        },
        "bertscore": {
            "precision": 0.92275,
            "recall": 0.91897,
            "f1": 0.91888
        },
        "bleurt": 0.20475,
        "meteor": 0.3662418319378411,
        "nubia": {
            "semantic_relation": 4.07395,
            "contradiction": 4.58482,
            "irrelevancy": 32.49232,
            "logical_agreement": 62.92286,
            "grammar_ref": 4.73156,
            "grammar_hyp": 4.82092,
            "nubia_score": 0.67982
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_73": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 20,
        "unique-1": 14,
        "entropy-1": 4.23890125660263,
        "distinct-2": 0.92,
        "vocab_size-2": 23,
        "unique-2": 21,
        "entropy-2": 4.483856189774723,
        "cond_entropy-2": 0.26341647163363247,
        "distinct-3": 0.9583333333333334,
        "vocab_size-3": 23,
        "unique-3": 22,
        "entropy-3": 4.501629167387823,
        "cond_entropy-3": 0.024439644279765027,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8095238095238095,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.011365041826379,
        "distinct-2-nopunct": 0.95,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.221928094887362,
        "cond_entropy-2-nopunct": 0.22961067210860203,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": 0.031262576450960075,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.6848998841738156,
        "bleu": 14.15395,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.78947,
            "fmeasure": 0.75
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.33333,
            "fmeasure": 0.31579
        },
        "rougeL": {
            "precision": 0.47619,
            "recall": 0.52632,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.47619,
            "recall": 0.52632,
            "fmeasure": 0.5
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.7647058823529411
        },
        "bertscore": {
            "precision": 0.91525,
            "recall": 0.91022,
            "f1": 0.91241
        },
        "bleurt": 0.33673,
        "meteor": 0.3649228060146557,
        "nubia": {
            "semantic_relation": 4.48407,
            "contradiction": 0.43845,
            "irrelevancy": 20.24146,
            "logical_agreement": 79.32009,
            "grammar_ref": 4.70075,
            "grammar_hyp": 4.12573,
            "nubia_score": 0.86772
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_74": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.4612502980140876,
        "bleu": 42.7287,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.57778,
            "fmeasure": 0.61111
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.32143,
            "fmeasure": 0.34091
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.57778,
            "fmeasure": 0.61111
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.57778,
            "fmeasure": 0.61111
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.94285,
            "recall": 0.93976,
            "f1": 0.94045
        },
        "bleurt": 0.30275,
        "meteor": 0.32269103944577215,
        "nubia": {
            "semantic_relation": 4.0451,
            "contradiction": 0.05852,
            "irrelevancy": 34.13171,
            "logical_agreement": 65.80977,
            "grammar_ref": 4.68314,
            "grammar_hyp": 5.5372,
            "nubia_score": 0.64475
        }
    },
    "web_nlg_ru_challenge_test_scramble": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.4414,
        "msttr-100_nopunct": 0.43797,
        "total_length": 21438,
        "mean_pred_length": 42.876,
        "std_pred_length": 19.393004511936773,
        "median_pred_length": 41.0,
        "min_pred_length": 7,
        "max_pred_length": 87,
        "distinct-1": 0.0802780110084896,
        "vocab_size-1": 1721,
        "unique-1": 692,
        "entropy-1": 5.898855910129611,
        "distinct-2": 0.2114815168592989,
        "vocab_size-2": 4428,
        "unique-2": 2223,
        "entropy-2": 10.160783852663629,
        "cond_entropy-2": 4.251161812564712,
        "distinct-3": 0.37038849202465995,
        "vocab_size-3": 7570,
        "unique-3": 4455,
        "entropy-3": 11.77942462334974,
        "cond_entropy-3": 1.6628113243938403,
        "total_length-nopunct": 19795,
        "mean_pred_length-nopunct": 39.59,
        "std_pred_length-nopunct": 18.241762524493076,
        "median_pred_length-nopunct": 38.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 80,
        "distinct-1-nopunct": 0.08653700429401363,
        "vocab_size-1-nopunct": 1713,
        "unique-1-nopunct": 692,
        "entropy-1-nopunct": 5.8083908105559265,
        "distinct-2-nopunct": 0.21119461000259135,
        "vocab_size-2-nopunct": 4075,
        "unique-2-nopunct": 2027,
        "entropy-2-nopunct": 10.022987011902972,
        "cond_entropy-2-nopunct": 4.3113618983366715,
        "distinct-3-nopunct": 0.3694067571162543,
        "vocab_size-3-nopunct": 6943,
        "unique-3-nopunct": 4128,
        "entropy-3-nopunct": 11.621108419778999,
        "cond_entropy-3-nopunct": 1.6373560142365506,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_challenge_test_scramble.json",
        "nist": 1.1467650469317818,
        "bleu": 2.08484,
        "rouge1": {
            "precision": 0.4265,
            "recall": 0.39519,
            "fmeasure": 0.40199
        },
        "rouge2": {
            "precision": 0.21043,
            "recall": 0.19547,
            "fmeasure": 0.19918
        },
        "rougeL": {
            "precision": 0.40878,
            "recall": 0.37981,
            "fmeasure": 0.38538
        },
        "rougeLsum": {
            "precision": 0.40878,
            "recall": 0.37981,
            "fmeasure": 0.38538
        },
        "local_recall": {
            "1": 0.08735332464146023,
            "2": 0.18787878787878787,
            "3": 0.26331360946745563,
            "4": 0.15555555555555556,
            "5": 0.4,
            "6": 0.3333333333333333
        },
        "bertscore": {
            "precision": 0.86325,
            "recall": 0.87275,
            "f1": 0.86743
        },
        "bleurt": -0.46176,
        "meteor": 0.1264762855740017,
        "nubia": {
            "semantic_relation": 3.29329,
            "contradiction": 33.67046,
            "irrelevancy": 16.95164,
            "logical_agreement": 49.3779,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.66541,
            "nubia_score": 0.16142
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 136,
        "msttr-100": 0.66143,
        "msttr-100_nopunct": 0.70167,
        "total_length": 2176,
        "mean_pred_length": 16.0,
        "std_pred_length": 7.088723439378913,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 52,
        "distinct-1": 0.3772977941176471,
        "vocab_size-1": 821,
        "unique-1": 649,
        "entropy-1": 7.786707648041038,
        "distinct-2": 0.7063725490196079,
        "vocab_size-2": 1441,
        "unique-2": 1294,
        "entropy-2": 9.849194066606753,
        "cond_entropy-2": 1.8100392420293023,
        "distinct-3": 0.8098739495798319,
        "vocab_size-3": 1542,
        "unique-3": 1447,
        "entropy-3": 10.17245852543302,
        "cond_entropy-3": 0.35135112471304675,
        "total_length-nopunct": 1888,
        "mean_pred_length-nopunct": 13.882352941176471,
        "std_pred_length-nopunct": 5.92112224002468,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.430614406779661,
        "vocab_size-1-nopunct": 813,
        "unique-1-nopunct": 648,
        "entropy-1-nopunct": 8.046404039984495,
        "distinct-2-nopunct": 0.7197488584474886,
        "vocab_size-2-nopunct": 1261,
        "unique-2-nopunct": 1147,
        "entropy-2-nopunct": 9.658086235159526,
        "cond_entropy-2-nopunct": 1.7261930897542768,
        "distinct-3-nopunct": 0.8186881188118812,
        "vocab_size-3-nopunct": 1323,
        "unique-3-nopunct": 1254,
        "entropy-3-nopunct": 9.954850572337664,
        "cond_entropy-3-nopunct": 0.3448106261505515,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.776499188938019,
        "bleu": 51.90788,
        "rouge1": {
            "precision": 0.78047,
            "recall": 0.75001,
            "fmeasure": 0.75401
        },
        "rouge2": {
            "precision": 0.55709,
            "recall": 0.53759,
            "fmeasure": 0.5399
        },
        "rougeL": {
            "precision": 0.68514,
            "recall": 0.66093,
            "fmeasure": 0.66318
        },
        "rougeLsum": {
            "precision": 0.68514,
            "recall": 0.66093,
            "fmeasure": 0.66318
        },
        "local_recall": {
            "1": 0.23896103896103896,
            "2": 0.4805194805194805,
            "3": 0.7864619678995115
        },
        "bertscore": {
            "precision": 0.93348,
            "recall": 0.92735,
            "f1": 0.92893
        },
        "bleurt": 0.36022,
        "meteor": 0.40811412422553056,
        "nubia": {
            "semantic_relation": 4.21114,
            "contradiction": 6.7471,
            "irrelevancy": 25.82229,
            "logical_agreement": 67.43061,
            "grammar_ref": 4.4992,
            "grammar_hyp": 4.4761,
            "nubia_score": 0.75249
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_33": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 21,
        "msttr-100": 0.69667,
        "msttr-100_nopunct": 0.75,
        "total_length": 307,
        "mean_pred_length": 14.619047619047619,
        "std_pred_length": 6.2448164445645515,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.5798045602605864,
        "vocab_size-1": 178,
        "unique-1": 146,
        "entropy-1": 6.801259316308403,
        "distinct-2": 0.9055944055944056,
        "vocab_size-2": 259,
        "unique-2": 246,
        "entropy-2": 7.914281018745122,
        "cond_entropy-2": 0.8977730319189742,
        "distinct-3": 0.9886792452830189,
        "vocab_size-3": 262,
        "unique-3": 261,
        "entropy-3": 8.019659870205231,
        "cond_entropy-3": 0.07348359185364708,
        "total_length-nopunct": 257,
        "mean_pred_length-nopunct": 12.238095238095237,
        "std_pred_length-nopunct": 4.975222052041515,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6731517509727627,
        "vocab_size-1-nopunct": 173,
        "unique-1-nopunct": 146,
        "entropy-1-nopunct": 6.951612390323122,
        "distinct-2-nopunct": 0.9279661016949152,
        "vocab_size-2-nopunct": 219,
        "unique-2-nopunct": 212,
        "entropy-2-nopunct": 7.688260409612128,
        "cond_entropy-2-nopunct": 0.7770065568392581,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 215,
        "unique-3-nopunct": 215,
        "entropy-3-nopunct": 7.748192849589435,
        "cond_entropy-3-nopunct": 0.041709348976117416,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.711365475645085,
        "bleu": 41.87114,
        "rouge1": {
            "precision": 0.75259,
            "recall": 0.72276,
            "fmeasure": 0.72793
        },
        "rouge2": {
            "precision": 0.52693,
            "recall": 0.50055,
            "fmeasure": 0.50661
        },
        "rougeL": {
            "precision": 0.67192,
            "recall": 0.65034,
            "fmeasure": 0.65214
        },
        "rougeLsum": {
            "precision": 0.67192,
            "recall": 0.65034,
            "fmeasure": 0.65214
        },
        "local_recall": {
            "1": 0.18840579710144928,
            "2": 0.39622641509433965,
            "3": 0.776595744680851
        },
        "bertscore": {
            "precision": 0.92762,
            "recall": 0.92165,
            "f1": 0.92202
        },
        "bleurt": 0.23524,
        "meteor": 0.3931050312024063,
        "nubia": {
            "semantic_relation": 4.10964,
            "contradiction": 10.37966,
            "irrelevancy": 32.68132,
            "logical_agreement": 56.93902,
            "grammar_ref": 4.80447,
            "grammar_hyp": 4.93863,
            "nubia_score": 0.70015
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 369,
        "msttr-100": 0.61026,
        "msttr-100_nopunct": 0.66059,
        "total_length": 3944,
        "mean_pred_length": 10.688346883468835,
        "std_pred_length": 2.8999392067260805,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 24,
        "distinct-1": 0.22058823529411764,
        "vocab_size-1": 870,
        "unique-1": 514,
        "entropy-1": 7.3837757885282,
        "distinct-2": 0.5359440559440559,
        "vocab_size-2": 1916,
        "unique-2": 1371,
        "entropy-2": 10.301429778527865,
        "cond_entropy-2": 2.507511023757492,
        "distinct-3": 0.7230193387398628,
        "vocab_size-3": 2318,
        "unique-3": 1895,
        "entropy-3": 10.890958234850562,
        "cond_entropy-3": 0.6836972464068299,
        "total_length-nopunct": 3458,
        "mean_pred_length-nopunct": 9.371273712737127,
        "std_pred_length-nopunct": 2.630926913929072,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.2495662232504338,
        "vocab_size-1-nopunct": 863,
        "unique-1-nopunct": 513,
        "entropy-1-nopunct": 7.649954964388509,
        "distinct-2-nopunct": 0.5179669796050502,
        "vocab_size-2-nopunct": 1600,
        "unique-2-nopunct": 1125,
        "entropy-2-nopunct": 10.020938349360572,
        "cond_entropy-2-nopunct": 2.7037970328241823,
        "distinct-3-nopunct": 0.711764705882353,
        "vocab_size-3-nopunct": 1936,
        "unique-3-nopunct": 1563,
        "entropy-3-nopunct": 10.62687699579573,
        "cond_entropy-3-nopunct": 0.7437112404666112,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.48870617590583,
        "bleu": 43.99963,
        "rouge1": {
            "precision": 0.71006,
            "recall": 0.71689,
            "fmeasure": 0.70627
        },
        "rouge2": {
            "precision": 0.46228,
            "recall": 0.46768,
            "fmeasure": 0.45984
        },
        "rougeL": {
            "precision": 0.6257,
            "recall": 0.6341,
            "fmeasure": 0.62322
        },
        "rougeLsum": {
            "precision": 0.6257,
            "recall": 0.6341,
            "fmeasure": 0.62322
        },
        "local_recall": {
            "1": 0.2574152542372881,
            "2": 0.6068515497553018,
            "3": 0.7662682602921647,
            "4": 1.0
        },
        "bertscore": {
            "precision": 0.91531,
            "recall": 0.91937,
            "f1": 0.91656
        },
        "bleurt": 0.09683,
        "meteor": 0.3857291369151644,
        "nubia": {
            "semantic_relation": 4.05797,
            "contradiction": 27.24341,
            "irrelevancy": 7.88018,
            "logical_agreement": 64.87642,
            "grammar_ref": 5.18632,
            "grammar_hyp": 5.33971,
            "nubia_score": 0.64666
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_34": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "total_length": 100,
        "mean_pred_length": 14.285714285714286,
        "std_pred_length": 7.004371812646436,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 30,
        "distinct-1": 0.73,
        "vocab_size-1": 73,
        "unique-1": 61,
        "entropy-1": 5.9285983154214295,
        "distinct-2": 0.946236559139785,
        "vocab_size-2": 88,
        "unique-2": 84,
        "entropy-2": 6.423514859471871,
        "cond_entropy-2": 0.33744687379313193,
        "distinct-3": 0.9883720930232558,
        "vocab_size-3": 85,
        "unique-3": 84,
        "entropy-3": 6.40300894074861,
        "cond_entropy-3": -0.0110930389389163,
        "total_length-nopunct": 86,
        "mean_pred_length-nopunct": 12.285714285714286,
        "std_pred_length-nopunct": 6.452337023220695,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.813953488372093,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 5.9713878305304275,
        "distinct-2-nopunct": 0.9620253164556962,
        "vocab_size-2-nopunct": 76,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.2182758430864284,
        "cond_entropy-2-nopunct": 0.28719356279905905,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 72,
        "unique-3-nopunct": 72,
        "entropy-3-nopunct": 6.1699250014423175,
        "cond_entropy-3-nopunct": -0.04003786476029788,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.496087845645169,
        "bleu": 12.34674,
        "rouge1": {
            "precision": 0.60908,
            "recall": 0.53391,
            "fmeasure": 0.55225
        },
        "rouge2": {
            "precision": 0.23462,
            "recall": 0.23106,
            "fmeasure": 0.22223
        },
        "rougeL": {
            "precision": 0.47423,
            "recall": 0.42913,
            "fmeasure": 0.43436
        },
        "rougeLsum": {
            "precision": 0.47423,
            "recall": 0.42913,
            "fmeasure": 0.43436
        },
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.391304347826087,
            "3": 0.5789473684210527
        },
        "bertscore": {
            "precision": 0.89894,
            "recall": 0.87986,
            "f1": 0.88502
        },
        "bleurt": -0.0308,
        "meteor": 0.2636117030186572,
        "nubia": {
            "semantic_relation": 3.7647,
            "contradiction": 6.90242,
            "irrelevancy": 50.48333,
            "logical_agreement": 42.61425,
            "grammar_ref": 4.83605,
            "grammar_hyp": 4.72583,
            "nubia_score": 0.59931
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_75": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 44,
        "msttr-100": 0.73857,
        "msttr-100_nopunct": 0.78333,
        "total_length": 726,
        "mean_pred_length": 16.5,
        "std_pred_length": 5.89876720556546,
        "median_pred_length": 16.5,
        "min_pred_length": 7,
        "max_pred_length": 31,
        "distinct-1": 0.5179063360881543,
        "vocab_size-1": 376,
        "unique-1": 290,
        "entropy-1": 7.632343384314734,
        "distinct-2": 0.8695014662756598,
        "vocab_size-2": 593,
        "unique-2": 529,
        "entropy-2": 9.114246601304606,
        "cond_entropy-2": 1.25042261925071,
        "distinct-3": 0.95141065830721,
        "vocab_size-3": 607,
        "unique-3": 578,
        "entropy-3": 9.217867511877213,
        "cond_entropy-3": 0.0905535178066405,
        "total_length-nopunct": 624,
        "mean_pred_length-nopunct": 14.181818181818182,
        "std_pred_length-nopunct": 5.0644605172296995,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.592948717948718,
        "vocab_size-1-nopunct": 370,
        "unique-1-nopunct": 290,
        "entropy-1-nopunct": 7.86114362017394,
        "distinct-2-nopunct": 0.8948275862068965,
        "vocab_size-2-nopunct": 519,
        "unique-2-nopunct": 478,
        "entropy-2-nopunct": 8.93093731761167,
        "cond_entropy-2-nopunct": 1.121657124577103,
        "distinct-3-nopunct": 0.9682835820895522,
        "vocab_size-3-nopunct": 519,
        "unique-3-nopunct": 502,
        "entropy-3-nopunct": 9.0026563546369,
        "cond_entropy-3-nopunct": 0.07582327300206265,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.95638425428192,
        "bleu": 48.4519,
        "rouge1": {
            "precision": 0.79861,
            "recall": 0.77238,
            "fmeasure": 0.77567
        },
        "rouge2": {
            "precision": 0.57941,
            "recall": 0.56723,
            "fmeasure": 0.56632
        },
        "rougeL": {
            "precision": 0.72216,
            "recall": 0.69558,
            "fmeasure": 0.70036
        },
        "rougeLsum": {
            "precision": 0.72216,
            "recall": 0.69558,
            "fmeasure": 0.70036
        },
        "local_recall": {
            "1": 0.2079207920792079,
            "2": 0.504,
            "3": 0.7883369330453563
        },
        "bertscore": {
            "precision": 0.93284,
            "recall": 0.93038,
            "f1": 0.93045
        },
        "bleurt": 0.34853,
        "meteor": 0.4146145819635071,
        "nubia": {
            "semantic_relation": 4.37172,
            "contradiction": 5.5084,
            "irrelevancy": 25.7149,
            "logical_agreement": 68.7767,
            "grammar_ref": 4.70505,
            "grammar_hyp": 4.69091,
            "nubia_score": 0.79279
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 80,
        "msttr-100": 0.55471,
        "msttr-100_nopunct": 0.56067,
        "total_length": 3452,
        "mean_pred_length": 43.15,
        "std_pred_length": 9.368964724023675,
        "median_pred_length": 42.0,
        "min_pred_length": 24,
        "max_pred_length": 75,
        "distinct-1": 0.20683661645422943,
        "vocab_size-1": 714,
        "unique-1": 341,
        "entropy-1": 7.514391206513345,
        "distinct-2": 0.49228944246737844,
        "vocab_size-2": 1660,
        "unique-2": 1082,
        "entropy-2": 10.080052327767039,
        "cond_entropy-2": 2.483699996346915,
        "distinct-3": 0.6816524908869988,
        "vocab_size-3": 2244,
        "unique-3": 1709,
        "entropy-3": 10.841347178815822,
        "cond_entropy-3": 0.7769167187994318,
        "total_length-nopunct": 3061,
        "mean_pred_length-nopunct": 38.2625,
        "std_pred_length-nopunct": 8.795941891008603,
        "median_pred_length-nopunct": 37.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 65,
        "distinct-1-nopunct": 0.23031688990525973,
        "vocab_size-1-nopunct": 705,
        "unique-1-nopunct": 337,
        "entropy-1-nopunct": 7.7180369326497,
        "distinct-2-nopunct": 0.5176115397517611,
        "vocab_size-2-nopunct": 1543,
        "unique-2-nopunct": 1029,
        "entropy-2-nopunct": 10.03517582565898,
        "cond_entropy-2-nopunct": 2.378107582434209,
        "distinct-3-nopunct": 0.6997587038952086,
        "vocab_size-3-nopunct": 2030,
        "unique-3-nopunct": 1576,
        "entropy-3-nopunct": 10.7114115034673,
        "cond_entropy-3-nopunct": 0.6875095981794209,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.6207387000164095,
        "bleu": 32.38212,
        "rouge1": {
            "precision": 0.62779,
            "recall": 0.59689,
            "fmeasure": 0.60546
        },
        "rouge2": {
            "precision": 0.32519,
            "recall": 0.30904,
            "fmeasure": 0.31356
        },
        "rougeL": {
            "precision": 0.42844,
            "recall": 0.41494,
            "fmeasure": 0.41674
        },
        "rougeLsum": {
            "precision": 0.42844,
            "recall": 0.41494,
            "fmeasure": 0.41674
        },
        "local_recall": {
            "1": 0.208649468892261,
            "2": 0.5107238605898123,
            "3": 0.7031039136302294
        },
        "bertscore": {
            "precision": 0.866,
            "recall": 0.86304,
            "f1": 0.86339
        },
        "bleurt": -0.24355,
        "meteor": 0.28312356986218334,
        "nubia": {
            "semantic_relation": 3.56458,
            "contradiction": 28.3333,
            "irrelevancy": 14.57491,
            "logical_agreement": 57.0918,
            "grammar_ref": 4.0565,
            "grammar_hyp": 4.29681,
            "nubia_score": 0.57215
        }
    },
    "totto_test_contrast_challenge_ethnicity-african_american": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 128,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.74556,
        "total_length": 2075,
        "mean_pred_length": 16.2109375,
        "std_pred_length": 6.558215677384646,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 44,
        "distinct-1": 0.3812048192771084,
        "vocab_size-1": 791,
        "unique-1": 615,
        "entropy-1": 7.95294847241912,
        "distinct-2": 0.7483307652799178,
        "vocab_size-2": 1457,
        "unique-2": 1296,
        "entropy-2": 10.080990881910823,
        "cond_entropy-2": 1.8686711441292858,
        "distinct-3": 0.9131390874106652,
        "vocab_size-3": 1661,
        "unique-3": 1577,
        "entropy-3": 10.587543889856617,
        "cond_entropy-3": 0.4307742393643085,
        "total_length-nopunct": 1821,
        "mean_pred_length-nopunct": 14.2265625,
        "std_pred_length-nopunct": 5.888567901756228,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.42888522789676004,
        "vocab_size-1-nopunct": 781,
        "unique-1-nopunct": 612,
        "entropy-1-nopunct": 8.199416559955218,
        "distinct-2-nopunct": 0.7773183697578263,
        "vocab_size-2-nopunct": 1316,
        "unique-2-nopunct": 1188,
        "entropy-2-nopunct": 9.984982748437785,
        "cond_entropy-2-nopunct": 1.7897348611270056,
        "distinct-3-nopunct": 0.9252396166134186,
        "vocab_size-3-nopunct": 1448,
        "unique-3-nopunct": 1384,
        "entropy-3-nopunct": 10.416804867408725,
        "cond_entropy-3-nopunct": 0.4035632667187992,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.626258807460333,
        "bleu": 47.40638,
        "rouge1": {
            "precision": 0.80169,
            "recall": 0.77469,
            "fmeasure": 0.78005
        },
        "rouge2": {
            "precision": 0.56033,
            "recall": 0.54438,
            "fmeasure": 0.54635
        },
        "rougeL": {
            "precision": 0.6883,
            "recall": 0.67074,
            "fmeasure": 0.67188
        },
        "rougeLsum": {
            "precision": 0.6883,
            "recall": 0.67074,
            "fmeasure": 0.67188
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.33554817275747506,
            "3": 0.7935003385240352
        },
        "bertscore": {
            "precision": 0.93695,
            "recall": 0.93719,
            "f1": 0.9352
        },
        "bleurt": 0.37948,
        "meteor": 0.41019302076709957,
        "nubia": {
            "semantic_relation": 4.46084,
            "contradiction": 4.18504,
            "irrelevancy": 26.53677,
            "logical_agreement": 69.27818,
            "grammar_ref": 4.21731,
            "grammar_hyp": 4.20513,
            "nubia_score": 0.83028
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 350,
        "msttr-100": 0.63988,
        "msttr-100_nopunct": 0.67553,
        "total_length": 8632,
        "mean_pred_length": 24.662857142857142,
        "std_pred_length": 6.5216599865058775,
        "median_pred_length": 23.0,
        "min_pred_length": 9,
        "max_pred_length": 50,
        "distinct-1": 0.135194624652456,
        "vocab_size-1": 1167,
        "unique-1": 419,
        "entropy-1": 7.824342289931781,
        "distinct-2": 0.38529340738951945,
        "vocab_size-2": 3191,
        "unique-2": 1850,
        "entropy-2": 10.782588712459374,
        "cond_entropy-2": 2.804007653879611,
        "distinct-3": 0.5854765506807866,
        "vocab_size-3": 4644,
        "unique-3": 3339,
        "entropy-3": 11.724541679670043,
        "cond_entropy-3": 0.9940485462518367,
        "total_length-nopunct": 7651,
        "mean_pred_length-nopunct": 21.86,
        "std_pred_length-nopunct": 5.932992499573887,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.15148346621356684,
        "vocab_size-1-nopunct": 1159,
        "unique-1-nopunct": 419,
        "entropy-1-nopunct": 8.077048149471809,
        "distinct-2-nopunct": 0.39898644021366936,
        "vocab_size-2-nopunct": 2913,
        "unique-2-nopunct": 1765,
        "entropy-2-nopunct": 10.659181399778124,
        "cond_entropy-2-nopunct": 2.7090531160304234,
        "distinct-3-nopunct": 0.595453891526399,
        "vocab_size-3-nopunct": 4139,
        "unique-3-nopunct": 3046,
        "entropy-3-nopunct": 11.557654838818847,
        "cond_entropy-3-nopunct": 0.937624792472668,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.379111810278162,
        "bleu": 37.87917,
        "rouge1": {
            "precision": 0.67614,
            "recall": 0.70313,
            "fmeasure": 0.6831
        },
        "rouge2": {
            "precision": 0.41353,
            "recall": 0.43023,
            "fmeasure": 0.41771
        },
        "rougeL": {
            "precision": 0.53107,
            "recall": 0.55318,
            "fmeasure": 0.53624
        },
        "rougeLsum": {
            "precision": 0.53107,
            "recall": 0.55318,
            "fmeasure": 0.53624
        },
        "local_recall": {
            "1": 0.22860527095054783,
            "2": 0.5698982324584896,
            "3": 0.7892004153686397,
            "4": 0.3,
            "5": 0.7241379310344828
        },
        "bertscore": {
            "precision": 0.8927,
            "recall": 0.89804,
            "f1": 0.89384
        },
        "bleurt": -0.03928,
        "meteor": 0.3511810704920074,
        "nubia": {
            "semantic_relation": 4.05431,
            "contradiction": 24.29942,
            "irrelevancy": 10.73283,
            "logical_agreement": 64.96776,
            "grammar_ref": 4.50573,
            "grammar_hyp": 4.56549,
            "nubia_score": 0.67077
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_76": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 33,
        "msttr-100": 0.706,
        "msttr-100_nopunct": 0.7575,
        "total_length": 529,
        "mean_pred_length": 16.03030303030303,
        "std_pred_length": 5.446627249318712,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.5689981096408318,
        "vocab_size-1": 301,
        "unique-1": 260,
        "entropy-1": 7.2504796274818935,
        "distinct-2": 0.9274193548387096,
        "vocab_size-2": 460,
        "unique-2": 441,
        "entropy-2": 8.759230132152421,
        "cond_entropy-2": 1.2926703745376142,
        "distinct-3": 0.9913606911447084,
        "vocab_size-3": 459,
        "unique-3": 455,
        "entropy-3": 8.837589765549641,
        "cond_entropy-3": 0.06718089345608376,
        "total_length-nopunct": 452,
        "mean_pred_length-nopunct": 13.696969696969697,
        "std_pred_length-nopunct": 4.93278978466423,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6526548672566371,
        "vocab_size-1-nopunct": 295,
        "unique-1-nopunct": 259,
        "entropy-1-nopunct": 7.428911333580152,
        "distinct-2-nopunct": 0.9403341288782816,
        "vocab_size-2-nopunct": 394,
        "unique-2-nopunct": 382,
        "entropy-2-nopunct": 8.54293364986249,
        "cond_entropy-2-nopunct": 1.2007212882413378,
        "distinct-3-nopunct": 0.9974093264248705,
        "vocab_size-3-nopunct": 385,
        "unique-3-nopunct": 384,
        "entropy-3-nopunct": 8.587275690117798,
        "cond_entropy-3-nopunct": 0.05869385856260818,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.995799593101801,
        "bleu": 48.92539,
        "rouge1": {
            "precision": 0.87838,
            "recall": 0.77332,
            "fmeasure": 0.81386
        },
        "rouge2": {
            "precision": 0.65359,
            "recall": 0.56762,
            "fmeasure": 0.59865
        },
        "rougeL": {
            "precision": 0.75497,
            "recall": 0.66448,
            "fmeasure": 0.69825
        },
        "rougeLsum": {
            "precision": 0.75497,
            "recall": 0.66448,
            "fmeasure": 0.69825
        },
        "local_recall": {
            "1": 0.175,
            "2": 0.22388059701492538,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.9498,
            "recall": 0.93532,
            "f1": 0.9419
        },
        "bleurt": 0.35106,
        "meteor": 0.4206972686479473,
        "nubia": {
            "semantic_relation": 4.54405,
            "contradiction": 2.72338,
            "irrelevancy": 14.23866,
            "logical_agreement": 83.03796,
            "grammar_ref": 4.92209,
            "grammar_hyp": 5.22809,
            "nubia_score": 0.79977
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 114,
        "msttr-100": 0.62896,
        "msttr-100_nopunct": 0.66605,
        "total_length": 4866,
        "mean_pred_length": 42.68421052631579,
        "std_pred_length": 9.300363876557757,
        "median_pred_length": 42.0,
        "min_pred_length": 22,
        "max_pred_length": 61,
        "distinct-1": 0.16728318947801069,
        "vocab_size-1": 814,
        "unique-1": 326,
        "entropy-1": 7.693735494555732,
        "distinct-2": 0.4118265993265993,
        "vocab_size-2": 1957,
        "unique-2": 1136,
        "entropy-2": 10.244310508261622,
        "cond_entropy-2": 2.464089359285177,
        "distinct-3": 0.5752479517033204,
        "vocab_size-3": 2668,
        "unique-3": 1846,
        "entropy-3": 10.97732593558767,
        "cond_entropy-3": 0.7538702170250683,
        "total_length-nopunct": 4310,
        "mean_pred_length-nopunct": 37.80701754385965,
        "std_pred_length-nopunct": 8.34547591800119,
        "median_pred_length-nopunct": 37.5,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 56,
        "distinct-1-nopunct": 0.1865429234338747,
        "vocab_size-1-nopunct": 804,
        "unique-1-nopunct": 324,
        "entropy-1-nopunct": 7.905741732573934,
        "distinct-2-nopunct": 0.4299332697807436,
        "vocab_size-2-nopunct": 1804,
        "unique-2-nopunct": 1085,
        "entropy-2-nopunct": 10.16482824985188,
        "cond_entropy-2-nopunct": 2.3197555586494185,
        "distinct-3-nopunct": 0.5886820186183244,
        "vocab_size-3-nopunct": 2403,
        "unique-3-nopunct": 1710,
        "entropy-3-nopunct": 10.828862287556499,
        "cond_entropy-3-nopunct": 0.6800940078147848,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.1744974076525185,
        "bleu": 37.3388,
        "rouge1": {
            "precision": 0.67299,
            "recall": 0.63195,
            "fmeasure": 0.6455
        },
        "rouge2": {
            "precision": 0.37771,
            "recall": 0.3532,
            "fmeasure": 0.36157
        },
        "rougeL": {
            "precision": 0.46945,
            "recall": 0.44813,
            "fmeasure": 0.45354
        },
        "rougeLsum": {
            "precision": 0.46945,
            "recall": 0.44813,
            "fmeasure": 0.45354
        },
        "local_recall": {
            "1": 0.20951302378255945,
            "2": 0.5913978494623656,
            "3": 0.7513784461152883
        },
        "bertscore": {
            "precision": 0.88439,
            "recall": 0.87947,
            "f1": 0.88059
        },
        "bleurt": -0.13754,
        "meteor": 0.3131192834702574,
        "nubia": {
            "semantic_relation": 3.81847,
            "contradiction": 20.60289,
            "irrelevancy": 12.06471,
            "logical_agreement": 67.3324,
            "grammar_ref": 4.06233,
            "grammar_hyp": 4.2737,
            "nubia_score": 0.6332
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation_parent": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.73418,
        "msttr-100_nopunct": 0.77517,
        "total_length": 6745,
        "mean_pred_length": 18.788300835654596,
        "std_pred_length": 9.19760033853898,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 53,
        "distinct-1": 0.3654558932542624,
        "vocab_size-1": 2465,
        "unique-1": 1795,
        "entropy-1": 9.139203722771397,
        "distinct-2": 0.8429376761666145,
        "vocab_size-2": 5383,
        "unique-2": 4969,
        "entropy-2": 12.110166824203143,
        "cond_entropy-2": 2.6884442950359326,
        "distinct-3": 0.9668159946905591,
        "vocab_size-3": 5827,
        "unique-3": 5725,
        "entropy-3": 12.449683884252178,
        "cond_entropy-3": 0.3560208238505231,
        "total_length-nopunct": 6018,
        "mean_pred_length-nopunct": 16.76323119777159,
        "std_pred_length-nopunct": 8.256823741965132,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4076105018278498,
        "vocab_size-1-nopunct": 2453,
        "unique-1-nopunct": 1794,
        "entropy-1-nopunct": 9.470726780637374,
        "distinct-2-nopunct": 0.8598692348471462,
        "vocab_size-2-nopunct": 4866,
        "unique-2-nopunct": 4529,
        "entropy-2-nopunct": 11.998663240417565,
        "cond_entropy-2-nopunct": 2.669650936396991,
        "distinct-3-nopunct": 0.9794339622641509,
        "vocab_size-3-nopunct": 5191,
        "unique-3-nopunct": 5111,
        "entropy-3-nopunct": 12.323741327087413,
        "cond_entropy-3-nopunct": 0.3489702026540482,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 10.608691186882831,
        "bleu": 65.84823,
        "rouge1": {
            "precision": 0.84956,
            "recall": 0.76036,
            "fmeasure": 0.78668
        },
        "rouge2": {
            "precision": 0.7095,
            "recall": 0.63006,
            "fmeasure": 0.6513
        },
        "rougeL": {
            "precision": 0.82055,
            "recall": 0.73488,
            "fmeasure": 0.75967
        },
        "rougeLsum": {
            "precision": 0.82055,
            "recall": 0.73488,
            "fmeasure": 0.75967
        },
        "local_recall": {
            "1": 0.042232597623089986,
            "2": 0.1558109833971903,
            "3": 0.34573304157549234,
            "4": 0.49128367670364503,
            "5": 0.612668743509865,
            "6": 0.7373188405797102,
            "7": 0.8403970981290569
        },
        "bertscore": {
            "precision": 0.95412,
            "recall": 0.9357,
            "f1": 0.94232
        },
        "bleurt": 0.18045,
        "meteor": 0.44231752358001447,
        "nubia": {
            "semantic_relation": 4.20819,
            "contradiction": 4.57782,
            "irrelevancy": 15.16589,
            "logical_agreement": 80.25629,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.00327,
            "nubia_score": 0.6659
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_35": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 103,
        "msttr-100": 0.71471,
        "msttr-100_nopunct": 0.75133,
        "total_length": 1784,
        "mean_pred_length": 17.320388349514563,
        "std_pred_length": 6.000345608546243,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.4400224215246637,
        "vocab_size-1": 785,
        "unique-1": 613,
        "entropy-1": 8.12700062239399,
        "distinct-2": 0.8161808447352766,
        "vocab_size-2": 1372,
        "unique-2": 1262,
        "entropy-2": 10.126532546745738,
        "cond_entropy-2": 1.753667600310201,
        "distinct-3": 0.9119138149556401,
        "vocab_size-3": 1439,
        "unique-3": 1391,
        "entropy-3": 10.352358288528363,
        "cond_entropy-3": 0.2182703065430977,
        "total_length-nopunct": 1570,
        "mean_pred_length-nopunct": 15.242718446601941,
        "std_pred_length-nopunct": 5.776527695917208,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.4949044585987261,
        "vocab_size-1-nopunct": 777,
        "unique-1-nopunct": 611,
        "entropy-1-nopunct": 8.361660874744679,
        "distinct-2-nopunct": 0.8227675528289026,
        "vocab_size-2-nopunct": 1207,
        "unique-2-nopunct": 1121,
        "entropy-2-nopunct": 9.935784134888674,
        "cond_entropy-2-nopunct": 1.6792566306964682,
        "distinct-3-nopunct": 0.9046920821114369,
        "vocab_size-3-nopunct": 1234,
        "unique-3-nopunct": 1192,
        "entropy-3-nopunct": 10.115347891290153,
        "cond_entropy-3-nopunct": 0.21844609448132246,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.953312086083803,
        "bleu": 51.7594,
        "rouge1": {
            "precision": 0.76495,
            "recall": 0.75763,
            "fmeasure": 0.75124
        },
        "rouge2": {
            "precision": 0.54715,
            "recall": 0.54344,
            "fmeasure": 0.53788
        },
        "rougeL": {
            "precision": 0.67219,
            "recall": 0.67219,
            "fmeasure": 0.6631
        },
        "rougeLsum": {
            "precision": 0.67219,
            "recall": 0.67219,
            "fmeasure": 0.6631
        },
        "local_recall": {
            "1": 0.19207317073170732,
            "2": 0.4983164983164983,
            "3": 0.8167259786476868
        },
        "bertscore": {
            "precision": 0.93424,
            "recall": 0.93197,
            "f1": 0.93189
        },
        "bleurt": 0.3276,
        "meteor": 0.4178930386147912,
        "nubia": {
            "semantic_relation": 4.27118,
            "contradiction": 9.5536,
            "irrelevancy": 27.62015,
            "logical_agreement": 62.82625,
            "grammar_ref": 4.60982,
            "grammar_hyp": 4.53788,
            "nubia_score": 0.75601
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02_parent": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.73418,
        "msttr-100_nopunct": 0.77517,
        "total_length": 6745,
        "mean_pred_length": 18.788300835654596,
        "std_pred_length": 9.19760033853898,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 53,
        "distinct-1": 0.3654558932542624,
        "vocab_size-1": 2465,
        "unique-1": 1795,
        "entropy-1": 9.139203722771397,
        "distinct-2": 0.8429376761666145,
        "vocab_size-2": 5383,
        "unique-2": 4969,
        "entropy-2": 12.110166824203143,
        "cond_entropy-2": 2.6884442950359326,
        "distinct-3": 0.9668159946905591,
        "vocab_size-3": 5827,
        "unique-3": 5725,
        "entropy-3": 12.449683884252178,
        "cond_entropy-3": 0.3560208238505231,
        "total_length-nopunct": 6018,
        "mean_pred_length-nopunct": 16.76323119777159,
        "std_pred_length-nopunct": 8.256823741965132,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4076105018278498,
        "vocab_size-1-nopunct": 2453,
        "unique-1-nopunct": 1794,
        "entropy-1-nopunct": 9.470726780637374,
        "distinct-2-nopunct": 0.8598692348471462,
        "vocab_size-2-nopunct": 4866,
        "unique-2-nopunct": 4529,
        "entropy-2-nopunct": 11.998663240417565,
        "cond_entropy-2-nopunct": 2.669650936396991,
        "distinct-3-nopunct": 0.9794339622641509,
        "vocab_size-3-nopunct": 5191,
        "unique-3-nopunct": 5111,
        "entropy-3-nopunct": 12.323741327087413,
        "cond_entropy-3-nopunct": 0.3489702026540482,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 10.608691186882831,
        "bleu": 65.84823,
        "rouge1": {
            "precision": 0.84956,
            "recall": 0.76036,
            "fmeasure": 0.78668
        },
        "rouge2": {
            "precision": 0.7095,
            "recall": 0.63006,
            "fmeasure": 0.6513
        },
        "rougeL": {
            "precision": 0.82055,
            "recall": 0.73488,
            "fmeasure": 0.75967
        },
        "rougeLsum": {
            "precision": 0.82055,
            "recall": 0.73488,
            "fmeasure": 0.75967
        },
        "local_recall": {
            "1": 0.042232597623089986,
            "2": 0.1558109833971903,
            "3": 0.34573304157549234,
            "4": 0.49128367670364503,
            "5": 0.612668743509865,
            "6": 0.7373188405797102,
            "7": 0.8403970981290569
        },
        "bertscore": {
            "precision": 0.95412,
            "recall": 0.9357,
            "f1": 0.94232
        },
        "bleurt": 0.18045,
        "meteor": 0.44231752358001447,
        "nubia": {
            "semantic_relation": 4.20819,
            "contradiction": 4.57782,
            "irrelevancy": 15.16589,
            "logical_agreement": 80.25629,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.00327,
            "nubia_score": 0.6659
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_77": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 30,
        "msttr-100": 0.7375,
        "msttr-100_nopunct": 0.79,
        "total_length": 493,
        "mean_pred_length": 16.433333333333334,
        "std_pred_length": 5.529818160562686,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.5862068965517241,
        "vocab_size-1": 289,
        "unique-1": 231,
        "entropy-1": 7.421208407790781,
        "distinct-2": 0.9028077753779697,
        "vocab_size-2": 418,
        "unique-2": 388,
        "entropy-2": 8.6244078553893,
        "cond_entropy-2": 0.9809557619527695,
        "distinct-3": 0.9676674364896074,
        "vocab_size-3": 419,
        "unique-3": 406,
        "entropy-3": 8.69181469855547,
        "cond_entropy-3": 0.07875514763756107,
        "total_length-nopunct": 436,
        "mean_pred_length-nopunct": 14.533333333333333,
        "std_pred_length-nopunct": 4.9781745873585255,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6467889908256881,
        "vocab_size-1-nopunct": 282,
        "unique-1-nopunct": 230,
        "entropy-1-nopunct": 7.553133259786901,
        "distinct-2-nopunct": 0.896551724137931,
        "vocab_size-2-nopunct": 364,
        "unique-2-nopunct": 337,
        "entropy-2-nopunct": 8.417298418652523,
        "cond_entropy-2-nopunct": 0.9317797695791826,
        "distinct-3-nopunct": 0.9654255319148937,
        "vocab_size-3-nopunct": 363,
        "unique-3-nopunct": 351,
        "entropy-3-nopunct": 8.483432235980343,
        "cond_entropy-3-nopunct": 0.08326446880648751,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.431516625734721,
        "bleu": 47.19128,
        "rouge1": {
            "precision": 0.76795,
            "recall": 0.71775,
            "fmeasure": 0.73348
        },
        "rouge2": {
            "precision": 0.52931,
            "recall": 0.5048,
            "fmeasure": 0.51024
        },
        "rougeL": {
            "precision": 0.65316,
            "recall": 0.61397,
            "fmeasure": 0.62554
        },
        "rougeLsum": {
            "precision": 0.65316,
            "recall": 0.61397,
            "fmeasure": 0.62554
        },
        "local_recall": {
            "1": 0.1836734693877551,
            "2": 0.411214953271028,
            "3": 0.7910447761194029
        },
        "bertscore": {
            "precision": 0.92847,
            "recall": 0.91875,
            "f1": 0.92129
        },
        "bleurt": 0.23332,
        "meteor": 0.40182739140339624,
        "nubia": {
            "semantic_relation": 4.06979,
            "contradiction": 11.8736,
            "irrelevancy": 29.34659,
            "logical_agreement": 58.77981,
            "grammar_ref": 4.79957,
            "grammar_hyp": 4.79079,
            "nubia_score": 0.69503
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 41,
        "msttr-100": 0.55944,
        "msttr-100_nopunct": 0.5725,
        "total_length": 1883,
        "mean_pred_length": 45.926829268292686,
        "std_pred_length": 10.08352978243679,
        "median_pred_length": 46.0,
        "min_pred_length": 26,
        "max_pred_length": 66,
        "distinct-1": 0.27615507169410514,
        "vocab_size-1": 520,
        "unique-1": 278,
        "entropy-1": 7.356390079865545,
        "distinct-2": 0.5694896851248643,
        "vocab_size-2": 1049,
        "unique-2": 732,
        "entropy-2": 9.566017803648096,
        "cond_entropy-2": 2.1340284418425424,
        "distinct-3": 0.7390338700721821,
        "vocab_size-3": 1331,
        "unique-3": 1064,
        "entropy-3": 10.161847711319368,
        "cond_entropy-3": 0.6074028789284328,
        "total_length-nopunct": 1678,
        "mean_pred_length-nopunct": 40.926829268292686,
        "std_pred_length-nopunct": 9.656011002636948,
        "median_pred_length-nopunct": 41.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 60,
        "distinct-1-nopunct": 0.3063170441001192,
        "vocab_size-1-nopunct": 514,
        "unique-1-nopunct": 277,
        "entropy-1-nopunct": 7.538694591599922,
        "distinct-2-nopunct": 0.592547342700061,
        "vocab_size-2-nopunct": 970,
        "unique-2-nopunct": 688,
        "entropy-2-nopunct": 9.503976902109148,
        "cond_entropy-2-nopunct": 2.015396090980721,
        "distinct-3-nopunct": 0.7512531328320802,
        "vocab_size-3-nopunct": 1199,
        "unique-3-nopunct": 976,
        "entropy-3-nopunct": 10.015996252253494,
        "cond_entropy-3-nopunct": 0.5200536028839821,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.2161853023763785,
        "bleu": 31.00078,
        "rouge1": {
            "precision": 0.61728,
            "recall": 0.58877,
            "fmeasure": 0.59717
        },
        "rouge2": {
            "precision": 0.30865,
            "recall": 0.296,
            "fmeasure": 0.29911
        },
        "rougeL": {
            "precision": 0.40593,
            "recall": 0.38218,
            "fmeasure": 0.38976
        },
        "rougeLsum": {
            "precision": 0.40593,
            "recall": 0.38218,
            "fmeasure": 0.38976
        },
        "local_recall": {
            "1": 0.2175226586102719,
            "2": 0.3979591836734694,
            "3": 0.680089485458613
        },
        "bertscore": {
            "precision": 0.8625,
            "recall": 0.85601,
            "f1": 0.85781
        },
        "bleurt": -0.2502,
        "meteor": 0.27341696082269057,
        "nubia": {
            "semantic_relation": 3.38196,
            "contradiction": 32.3652,
            "irrelevancy": 9.07205,
            "logical_agreement": 58.56275,
            "grammar_ref": 3.92594,
            "grammar_hyp": 4.12216,
            "nubia_score": 0.56899
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_54": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 80,
        "msttr-100": 0.72462,
        "msttr-100_nopunct": 0.77273,
        "total_length": 1383,
        "mean_pred_length": 17.2875,
        "std_pred_length": 7.885419693966835,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 50,
        "distinct-1": 0.4671005061460593,
        "vocab_size-1": 646,
        "unique-1": 506,
        "entropy-1": 7.997799578620088,
        "distinct-2": 0.851880276285495,
        "vocab_size-2": 1110,
        "unique-2": 1010,
        "entropy-2": 9.948217477041915,
        "cond_entropy-2": 1.711821291677063,
        "distinct-3": 0.9582992641046607,
        "vocab_size-3": 1172,
        "unique-3": 1138,
        "entropy-3": 10.160710742886078,
        "cond_entropy-3": 0.20928640430768636,
        "total_length-nopunct": 1194,
        "mean_pred_length-nopunct": 14.925,
        "std_pred_length-nopunct": 6.433846050380752,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.5343383584589615,
        "vocab_size-1-nopunct": 638,
        "unique-1-nopunct": 503,
        "entropy-1-nopunct": 8.273243800112038,
        "distinct-2-nopunct": 0.8680430879712747,
        "vocab_size-2-nopunct": 967,
        "unique-2-nopunct": 894,
        "entropy-2-nopunct": 9.754917716451319,
        "cond_entropy-2-nopunct": 1.5716383268429268,
        "distinct-3-nopunct": 0.9622823984526112,
        "vocab_size-3-nopunct": 995,
        "unique-3-nopunct": 971,
        "entropy-3-nopunct": 9.925737866335028,
        "cond_entropy-3-nopunct": 0.18628379985319854,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.050543274132689,
        "bleu": 42.37567,
        "rouge1": {
            "precision": 0.72049,
            "recall": 0.67686,
            "fmeasure": 0.68403
        },
        "rouge2": {
            "precision": 0.48164,
            "recall": 0.45825,
            "fmeasure": 0.45782
        },
        "rougeL": {
            "precision": 0.62107,
            "recall": 0.59639,
            "fmeasure": 0.59361
        },
        "rougeLsum": {
            "precision": 0.62107,
            "recall": 0.59639,
            "fmeasure": 0.59361
        },
        "local_recall": {
            "1": 0.19491525423728814,
            "2": 0.4590643274853801,
            "3": 0.7347994825355757
        },
        "bertscore": {
            "precision": 0.91578,
            "recall": 0.9112,
            "f1": 0.91076
        },
        "bleurt": 0.15405,
        "meteor": 0.3558606967622991,
        "nubia": {
            "semantic_relation": 3.96752,
            "contradiction": 14.68663,
            "irrelevancy": 32.24965,
            "logical_agreement": 53.06372,
            "grammar_ref": 4.56456,
            "grammar_hyp": 4.50738,
            "nubia_score": 0.65402
        }
    },
    "totto_test_contrast_challenge_ethnicity-all_usa": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 128,
        "msttr-100": 0.6785,
        "msttr-100_nopunct": 0.73882,
        "total_length": 2028,
        "mean_pred_length": 15.84375,
        "std_pred_length": 5.792556511377338,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 42,
        "distinct-1": 0.41222879684418146,
        "vocab_size-1": 836,
        "unique-1": 651,
        "entropy-1": 8.137526424861925,
        "distinct-2": 0.8152631578947368,
        "vocab_size-2": 1549,
        "unique-2": 1397,
        "entropy-2": 10.33753442708512,
        "cond_entropy-2": 1.9165912831756677,
        "distinct-3": 0.948645598194131,
        "vocab_size-3": 1681,
        "unique-3": 1619,
        "entropy-3": 10.666149884337852,
        "cond_entropy-3": 0.2895254316735778,
        "total_length-nopunct": 1768,
        "mean_pred_length-nopunct": 13.8125,
        "std_pred_length-nopunct": 5.164103867080909,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.46945701357466063,
        "vocab_size-1-nopunct": 830,
        "unique-1-nopunct": 651,
        "entropy-1-nopunct": 8.451509397661624,
        "distinct-2-nopunct": 0.8341463414634146,
        "vocab_size-2-nopunct": 1368,
        "unique-2-nopunct": 1249,
        "entropy-2-nopunct": 10.179928200366613,
        "cond_entropy-2-nopunct": 1.7922051294306987,
        "distinct-3-nopunct": 0.9609788359788359,
        "vocab_size-3-nopunct": 1453,
        "unique-3-nopunct": 1407,
        "entropy-3-nopunct": 10.475282144157728,
        "cond_entropy-3-nopunct": 0.29347105050233463,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.9902352530827505,
        "bleu": 47.22044,
        "rouge1": {
            "precision": 0.82077,
            "recall": 0.7869,
            "fmeasure": 0.79544
        },
        "rouge2": {
            "precision": 0.57232,
            "recall": 0.55167,
            "fmeasure": 0.55523
        },
        "rougeL": {
            "precision": 0.69759,
            "recall": 0.67026,
            "fmeasure": 0.67605
        },
        "rougeLsum": {
            "precision": 0.69759,
            "recall": 0.67026,
            "fmeasure": 0.67605
        },
        "local_recall": {
            "1": 0.17699115044247787,
            "2": 0.3306122448979592,
            "3": 0.8225371120107963
        },
        "bertscore": {
            "precision": 0.93978,
            "recall": 0.93745,
            "f1": 0.9374
        },
        "bleurt": 0.40186,
        "meteor": 0.4187789036524529,
        "nubia": {
            "semantic_relation": 4.52449,
            "contradiction": 4.6586,
            "irrelevancy": 18.21767,
            "logical_agreement": 77.12373,
            "grammar_ref": 4.60573,
            "grammar_hyp": 4.57175,
            "nubia_score": 0.83066
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_78": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 66,
        "msttr-100": 0.72909,
        "msttr-100_nopunct": 0.78111,
        "total_length": 1112,
        "mean_pred_length": 16.848484848484848,
        "std_pred_length": 6.900246864803097,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 46,
        "distinct-1": 0.49280575539568344,
        "vocab_size-1": 548,
        "unique-1": 435,
        "entropy-1": 7.9160841360412295,
        "distinct-2": 0.8489483747609943,
        "vocab_size-2": 888,
        "unique-2": 804,
        "entropy-2": 9.610937229872542,
        "cond_entropy-2": 1.4524616463584115,
        "distinct-3": 0.9489795918367347,
        "vocab_size-3": 930,
        "unique-3": 893,
        "entropy-3": 9.812593527972632,
        "cond_entropy-3": 0.18215990882813587,
        "total_length-nopunct": 976,
        "mean_pred_length-nopunct": 14.787878787878787,
        "std_pred_length-nopunct": 6.255942996318494,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.5512295081967213,
        "vocab_size-1-nopunct": 538,
        "unique-1-nopunct": 430,
        "entropy-1-nopunct": 8.134655246828853,
        "distinct-2-nopunct": 0.8593406593406593,
        "vocab_size-2-nopunct": 782,
        "unique-2-nopunct": 711,
        "entropy-2-nopunct": 9.44447288639816,
        "cond_entropy-2-nopunct": 1.3607391623724308,
        "distinct-3-nopunct": 0.957345971563981,
        "vocab_size-3-nopunct": 808,
        "unique-3-nopunct": 776,
        "entropy-3-nopunct": 9.631632630645237,
        "cond_entropy-3-nopunct": 0.15749223639163554,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.926040560531705,
        "bleu": 42.6049,
        "rouge1": {
            "precision": 0.75723,
            "recall": 0.74791,
            "fmeasure": 0.74365
        },
        "rouge2": {
            "precision": 0.54001,
            "recall": 0.53926,
            "fmeasure": 0.5321
        },
        "rougeL": {
            "precision": 0.64696,
            "recall": 0.6425,
            "fmeasure": 0.6353
        },
        "rougeLsum": {
            "precision": 0.64696,
            "recall": 0.6425,
            "fmeasure": 0.6353
        },
        "local_recall": {
            "1": 0.24378109452736318,
            "2": 0.4387755102040816,
            "3": 0.7701149425287356
        },
        "bertscore": {
            "precision": 0.92174,
            "recall": 0.92517,
            "f1": 0.92193
        },
        "bleurt": 0.28296,
        "meteor": 0.40138788851464086,
        "nubia": {
            "semantic_relation": 4.32469,
            "contradiction": 5.11169,
            "irrelevancy": 31.6651,
            "logical_agreement": 63.22322,
            "grammar_ref": 4.35949,
            "grammar_hyp": 4.2316,
            "nubia_score": 0.79244
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_79": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8421052631578947,
        "vocab_size-1": 16,
        "unique-1": 13,
        "entropy-1": 3.9321380397593733,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.2553308213320601,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.734521664779752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.2875371587496606,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9139788199049113,
        "bleu": 39.42873,
        "rouge1": {
            "precision": 0.71667,
            "recall": 0.5119,
            "fmeasure": 0.59722
        },
        "rouge2": {
            "precision": 0.50877,
            "recall": 0.38827,
            "fmeasure": 0.4385
        },
        "rougeL": {
            "precision": 0.51667,
            "recall": 0.44841,
            "fmeasure": 0.47798
        },
        "rougeLsum": {
            "precision": 0.51667,
            "recall": 0.44841,
            "fmeasure": 0.47798
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.4,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.91896,
            "recall": 0.8754,
            "f1": 0.89665
        },
        "bleurt": -0.00711,
        "meteor": 0.25911971760264746,
        "nubia": {
            "semantic_relation": 4.04862,
            "contradiction": 0.12831,
            "irrelevancy": 62.41489,
            "logical_agreement": 37.4568,
            "grammar_ref": 3.5675,
            "grammar_hyp": 3.68857,
            "nubia_score": 0.73689
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05_parent": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.73418,
        "msttr-100_nopunct": 0.77517,
        "total_length": 6745,
        "mean_pred_length": 18.788300835654596,
        "std_pred_length": 9.19760033853898,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 53,
        "distinct-1": 0.3654558932542624,
        "vocab_size-1": 2465,
        "unique-1": 1795,
        "entropy-1": 9.139203722771397,
        "distinct-2": 0.8429376761666145,
        "vocab_size-2": 5383,
        "unique-2": 4969,
        "entropy-2": 12.110166824203143,
        "cond_entropy-2": 2.6884442950359326,
        "distinct-3": 0.9668159946905591,
        "vocab_size-3": 5827,
        "unique-3": 5725,
        "entropy-3": 12.449683884252178,
        "cond_entropy-3": 0.3560208238505231,
        "total_length-nopunct": 6018,
        "mean_pred_length-nopunct": 16.76323119777159,
        "std_pred_length-nopunct": 8.256823741965132,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4076105018278498,
        "vocab_size-1-nopunct": 2453,
        "unique-1-nopunct": 1794,
        "entropy-1-nopunct": 9.470726780637374,
        "distinct-2-nopunct": 0.8598692348471462,
        "vocab_size-2-nopunct": 4866,
        "unique-2-nopunct": 4529,
        "entropy-2-nopunct": 11.998663240417565,
        "cond_entropy-2-nopunct": 2.669650936396991,
        "distinct-3-nopunct": 0.9794339622641509,
        "vocab_size-3-nopunct": 5191,
        "unique-3-nopunct": 5111,
        "entropy-3-nopunct": 12.323741327087413,
        "cond_entropy-3-nopunct": 0.3489702026540482,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 10.608691186882831,
        "bleu": 65.84823,
        "rouge1": {
            "precision": 0.84956,
            "recall": 0.76036,
            "fmeasure": 0.78668
        },
        "rouge2": {
            "precision": 0.7095,
            "recall": 0.63006,
            "fmeasure": 0.6513
        },
        "rougeL": {
            "precision": 0.82055,
            "recall": 0.73488,
            "fmeasure": 0.75967
        },
        "rougeLsum": {
            "precision": 0.82055,
            "recall": 0.73488,
            "fmeasure": 0.75967
        },
        "local_recall": {
            "1": 0.042232597623089986,
            "2": 0.1558109833971903,
            "3": 0.34573304157549234,
            "4": 0.49128367670364503,
            "5": 0.612668743509865,
            "6": 0.7373188405797102,
            "7": 0.8403970981290569
        },
        "bertscore": {
            "precision": 0.95412,
            "recall": 0.9357,
            "f1": 0.94232
        },
        "bleurt": 0.18045,
        "meteor": 0.44231752358001447,
        "nubia": {
            "semantic_relation": 4.20819,
            "contradiction": 4.57782,
            "irrelevancy": 15.16589,
            "logical_agreement": 80.25629,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.00327,
            "nubia_score": 0.6659
        }
    },
    "totto_test_contrast_challenge_continent-africa": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 45,
        "msttr-100": 0.68571,
        "msttr-100_nopunct": 0.715,
        "total_length": 736,
        "mean_pred_length": 16.355555555555554,
        "std_pred_length": 4.926822530486924,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.452445652173913,
        "vocab_size-1": 333,
        "unique-1": 255,
        "entropy-1": 7.2364894095826715,
        "distinct-2": 0.768451519536903,
        "vocab_size-2": 531,
        "unique-2": 455,
        "entropy-2": 8.759780372475268,
        "cond_entropy-2": 1.3245981602460795,
        "distinct-3": 0.9241486068111455,
        "vocab_size-3": 597,
        "unique-3": 558,
        "entropy-3": 9.16662944136775,
        "cond_entropy-3": 0.4030490887114025,
        "total_length-nopunct": 671,
        "mean_pred_length-nopunct": 14.911111111111111,
        "std_pred_length-nopunct": 4.755451712261867,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.488822652757079,
        "vocab_size-1-nopunct": 328,
        "unique-1-nopunct": 252,
        "entropy-1-nopunct": 7.351403303504035,
        "distinct-2-nopunct": 0.7699680511182109,
        "vocab_size-2-nopunct": 482,
        "unique-2-nopunct": 413,
        "entropy-2-nopunct": 8.613670169084921,
        "cond_entropy-2-nopunct": 1.31400524164477,
        "distinct-3-nopunct": 0.919104991394148,
        "vocab_size-3-nopunct": 534,
        "unique-3-nopunct": 497,
        "entropy-3-nopunct": 9.001637812942082,
        "cond_entropy-3-nopunct": 0.42427718000212766,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.51416693831485,
        "bleu": 52.41471,
        "rouge1": {
            "precision": 0.8115,
            "recall": 0.78702,
            "fmeasure": 0.78954
        },
        "rouge2": {
            "precision": 0.60273,
            "recall": 0.58521,
            "fmeasure": 0.5855
        },
        "rougeL": {
            "precision": 0.678,
            "recall": 0.65891,
            "fmeasure": 0.65914
        },
        "rougeLsum": {
            "precision": 0.678,
            "recall": 0.65891,
            "fmeasure": 0.65914
        },
        "local_recall": {
            "1": 0.19333333333333333,
            "2": 0.515625,
            "3": 0.8340080971659919
        },
        "bertscore": {
            "precision": 0.94423,
            "recall": 0.9422,
            "f1": 0.9426
        },
        "bleurt": 0.39523,
        "meteor": 0.43063995190252574,
        "nubia": {
            "semantic_relation": 4.47413,
            "contradiction": 7.16916,
            "irrelevancy": 26.76969,
            "logical_agreement": 66.06115,
            "grammar_ref": 4.86201,
            "grammar_hyp": 4.83354,
            "nubia_score": 0.80048
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_55": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 73,
        "msttr-100": 0.70818,
        "msttr-100_nopunct": 0.77,
        "total_length": 1168,
        "mean_pred_length": 16.0,
        "std_pred_length": 6.550122868240038,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.4708904109589041,
        "vocab_size-1": 550,
        "unique-1": 421,
        "entropy-1": 7.878310693145805,
        "distinct-2": 0.8438356164383561,
        "vocab_size-2": 924,
        "unique-2": 819,
        "entropy-2": 9.705379548783398,
        "cond_entropy-2": 1.5659152006533055,
        "distinct-3": 0.9315068493150684,
        "vocab_size-3": 952,
        "unique-3": 891,
        "entropy-3": 9.852106425647651,
        "cond_entropy-3": 0.13101093629022906,
        "total_length-nopunct": 996,
        "mean_pred_length-nopunct": 13.643835616438356,
        "std_pred_length-nopunct": 5.527936182584913,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5441767068273092,
        "vocab_size-1-nopunct": 542,
        "unique-1-nopunct": 420,
        "entropy-1-nopunct": 8.161203906433991,
        "distinct-2-nopunct": 0.8634886240520043,
        "vocab_size-2-nopunct": 797,
        "unique-2-nopunct": 723,
        "entropy-2-nopunct": 9.499570764777074,
        "cond_entropy-2-nopunct": 1.4205723951430156,
        "distinct-3-nopunct": 0.9447058823529412,
        "vocab_size-3-nopunct": 803,
        "unique-3-nopunct": 763,
        "entropy-3-nopunct": 9.613360604546946,
        "cond_entropy-3-nopunct": 0.12272510249829856,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.60544592762572,
        "bleu": 52.31294,
        "rouge1": {
            "precision": 0.8192,
            "recall": 0.73376,
            "fmeasure": 0.76057
        },
        "rouge2": {
            "precision": 0.60462,
            "recall": 0.54597,
            "fmeasure": 0.56329
        },
        "rougeL": {
            "precision": 0.74536,
            "recall": 0.67475,
            "fmeasure": 0.69552
        },
        "rougeLsum": {
            "precision": 0.74536,
            "recall": 0.67475,
            "fmeasure": 0.69552
        },
        "local_recall": {
            "1": 0.26976744186046514,
            "2": 0.4457831325301205,
            "3": 0.7587878787878788
        },
        "bertscore": {
            "precision": 0.94115,
            "recall": 0.92562,
            "f1": 0.93158
        },
        "bleurt": 0.28395,
        "meteor": 0.4051233452547065,
        "nubia": {
            "semantic_relation": 4.24367,
            "contradiction": 7.05445,
            "irrelevancy": 30.48188,
            "logical_agreement": 62.46366,
            "grammar_ref": 4.56245,
            "grammar_hyp": 4.70057,
            "nubia_score": 0.74268
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 305,
        "msttr-100": 0.6251,
        "msttr-100_nopunct": 0.66694,
        "total_length": 9644,
        "mean_pred_length": 31.619672131147542,
        "std_pred_length": 7.457394166956342,
        "median_pred_length": 32.0,
        "min_pred_length": 15,
        "max_pred_length": 54,
        "distinct-1": 0.13417669017005393,
        "vocab_size-1": 1294,
        "unique-1": 507,
        "entropy-1": 7.86631467081676,
        "distinct-2": 0.38708641182139414,
        "vocab_size-2": 3615,
        "unique-2": 2161,
        "entropy-2": 10.905761702198566,
        "cond_entropy-2": 2.915480790148398,
        "distinct-3": 0.5924286030551251,
        "vocab_size-3": 5352,
        "unique-3": 3883,
        "entropy-3": 11.933244680616415,
        "cond_entropy-3": 1.0608162042554832,
        "total_length-nopunct": 8535,
        "mean_pred_length-nopunct": 27.983606557377048,
        "std_pred_length-nopunct": 6.879029199708983,
        "median_pred_length-nopunct": 28.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 48,
        "distinct-1-nopunct": 0.15055653192735793,
        "vocab_size-1-nopunct": 1285,
        "unique-1-nopunct": 505,
        "entropy-1-nopunct": 8.131278686684613,
        "distinct-2-nopunct": 0.4089914945321993,
        "vocab_size-2-nopunct": 3366,
        "unique-2-nopunct": 2096,
        "entropy-2-nopunct": 10.840247850685738,
        "cond_entropy-2-nopunct": 2.8059154334846284,
        "distinct-3-nopunct": 0.609589905362776,
        "vocab_size-3-nopunct": 4831,
        "unique-3-nopunct": 3596,
        "entropy-3-nopunct": 11.791255231781088,
        "cond_entropy-3-nopunct": 0.9819634414845485,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.113034579418808,
        "bleu": 35.13203,
        "rouge1": {
            "precision": 0.6446,
            "recall": 0.65878,
            "fmeasure": 0.64479
        },
        "rouge2": {
            "precision": 0.36643,
            "recall": 0.3774,
            "fmeasure": 0.36761
        },
        "rougeL": {
            "precision": 0.478,
            "recall": 0.49034,
            "fmeasure": 0.47854
        },
        "rougeLsum": {
            "precision": 0.478,
            "recall": 0.49034,
            "fmeasure": 0.47854
        },
        "local_recall": {
            "1": 0.20537213206491325,
            "2": 0.544263775971093,
            "3": 0.7661753684736448
        },
        "bertscore": {
            "precision": 0.88226,
            "recall": 0.88509,
            "f1": 0.88246
        },
        "bleurt": -0.11454,
        "meteor": 0.3241976138454004,
        "nubia": {
            "semantic_relation": 3.896,
            "contradiction": 25.82193,
            "irrelevancy": 13.43631,
            "logical_agreement": 60.74176,
            "grammar_ref": 4.27079,
            "grammar_hyp": 4.37411,
            "nubia_score": 0.63549
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_36": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 131,
        "msttr-100": 0.73762,
        "msttr-100_nopunct": 0.79222,
        "total_length": 2125,
        "mean_pred_length": 16.221374045801525,
        "std_pred_length": 6.964786101542703,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 44,
        "distinct-1": 0.4607058823529412,
        "vocab_size-1": 979,
        "unique-1": 782,
        "entropy-1": 8.400266239816109,
        "distinct-2": 0.8525576730190572,
        "vocab_size-2": 1700,
        "unique-2": 1558,
        "entropy-2": 10.54670762773861,
        "cond_entropy-2": 1.855808315136631,
        "distinct-3": 0.9608158883521203,
        "vocab_size-3": 1790,
        "unique-3": 1739,
        "entropy-3": 10.774617982558311,
        "cond_entropy-3": 0.22452979671381806,
        "total_length-nopunct": 1843,
        "mean_pred_length-nopunct": 14.068702290076336,
        "std_pred_length-nopunct": 6.011681808219493,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.5252306022788931,
        "vocab_size-1-nopunct": 968,
        "unique-1-nopunct": 780,
        "entropy-1-nopunct": 8.727522443716262,
        "distinct-2-nopunct": 0.8732476635514018,
        "vocab_size-2-nopunct": 1495,
        "unique-2-nopunct": 1393,
        "entropy-2-nopunct": 10.37202061522435,
        "cond_entropy-2-nopunct": 1.7315246300198073,
        "distinct-3-nopunct": 0.9690069576217584,
        "vocab_size-3-nopunct": 1532,
        "unique-3-nopunct": 1494,
        "entropy-3-nopunct": 10.559383345891957,
        "cond_entropy-3-nopunct": 0.20543089735002987,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.609893058244839,
        "bleu": 43.63458,
        "rouge1": {
            "precision": 0.77813,
            "recall": 0.71436,
            "fmeasure": 0.73277
        },
        "rouge2": {
            "precision": 0.54365,
            "recall": 0.49547,
            "fmeasure": 0.50885
        },
        "rougeL": {
            "precision": 0.67015,
            "recall": 0.61291,
            "fmeasure": 0.62949
        },
        "rougeLsum": {
            "precision": 0.67015,
            "recall": 0.61291,
            "fmeasure": 0.62949
        },
        "local_recall": {
            "1": 0.21220159151193635,
            "2": 0.4423076923076923,
            "3": 0.738429172510519
        },
        "bertscore": {
            "precision": 0.93157,
            "recall": 0.92117,
            "f1": 0.92496
        },
        "bleurt": 0.25918,
        "meteor": 0.37904107009674576,
        "nubia": {
            "semantic_relation": 4.1833,
            "contradiction": 12.70109,
            "irrelevancy": 25.98227,
            "logical_agreement": 61.31664,
            "grammar_ref": 4.61481,
            "grammar_hyp": 4.74356,
            "nubia_score": 0.69788
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 79,
        "msttr-100": 0.64949,
        "msttr-100_nopunct": 0.68706,
        "total_length": 3927,
        "mean_pred_length": 49.70886075949367,
        "std_pred_length": 10.99614650423672,
        "median_pred_length": 51.0,
        "min_pred_length": 26,
        "max_pred_length": 75,
        "distinct-1": 0.1751973516679399,
        "vocab_size-1": 688,
        "unique-1": 299,
        "entropy-1": 7.61019779454913,
        "distinct-2": 0.3996881496881497,
        "vocab_size-2": 1538,
        "unique-2": 894,
        "entropy-2": 9.935892697259357,
        "cond_entropy-2": 2.2549110646463078,
        "distinct-3": 0.541788272751393,
        "vocab_size-3": 2042,
        "unique-3": 1387,
        "entropy-3": 10.563302412635279,
        "cond_entropy-3": 0.6479125002177942,
        "total_length-nopunct": 3490,
        "mean_pred_length-nopunct": 44.177215189873415,
        "std_pred_length-nopunct": 10.009817324893794,
        "median_pred_length-nopunct": 45.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 65,
        "distinct-1-nopunct": 0.19455587392550144,
        "vocab_size-1-nopunct": 679,
        "unique-1-nopunct": 298,
        "entropy-1-nopunct": 7.8004676253201515,
        "distinct-2-nopunct": 0.4180592201700381,
        "vocab_size-2-nopunct": 1426,
        "unique-2-nopunct": 851,
        "entropy-2-nopunct": 9.86218629957374,
        "cond_entropy-2-nopunct": 2.1141800275623455,
        "distinct-3-nopunct": 0.554921968787515,
        "vocab_size-3-nopunct": 1849,
        "unique-3-nopunct": 1282,
        "entropy-3-nopunct": 10.422233904783038,
        "cond_entropy-3-nopunct": 0.5755053527654638,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.303424771790659,
        "bleu": 41.09196,
        "rouge1": {
            "precision": 0.69278,
            "recall": 0.65303,
            "fmeasure": 0.66807
        },
        "rouge2": {
            "precision": 0.39269,
            "recall": 0.37074,
            "fmeasure": 0.37879
        },
        "rougeL": {
            "precision": 0.44753,
            "recall": 0.42099,
            "fmeasure": 0.43099
        },
        "rougeLsum": {
            "precision": 0.44753,
            "recall": 0.42099,
            "fmeasure": 0.43099
        },
        "local_recall": {
            "1": 0.2710084033613445,
            "2": 0.4583883751651255,
            "3": 0.7913093196112064
        },
        "bertscore": {
            "precision": 0.88867,
            "recall": 0.88096,
            "f1": 0.88368
        },
        "bleurt": -0.15388,
        "meteor": 0.3217459699156594,
        "nubia": {
            "semantic_relation": 3.77998,
            "contradiction": 17.94249,
            "irrelevancy": 7.03398,
            "logical_agreement": 75.02353,
            "grammar_ref": 3.96506,
            "grammar_hyp": 4.07185,
            "nubia_score": 0.67714
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_56": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 64,
        "msttr-100": 0.731,
        "msttr-100_nopunct": 0.79444,
        "total_length": 1070,
        "mean_pred_length": 16.71875,
        "std_pred_length": 4.9100303906900615,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.5093457943925234,
        "vocab_size-1": 545,
        "unique-1": 431,
        "entropy-1": 7.936181319014839,
        "distinct-2": 0.9174950298210736,
        "vocab_size-2": 923,
        "unique-2": 865,
        "entropy-2": 9.773804711546953,
        "cond_entropy-2": 1.5898203515298786,
        "distinct-3": 0.9819532908704883,
        "vocab_size-3": 925,
        "unique-3": 909,
        "entropy-3": 9.842688464578446,
        "cond_entropy-3": 0.05543285834402414,
        "total_length-nopunct": 927,
        "mean_pred_length-nopunct": 14.484375,
        "std_pred_length-nopunct": 4.304765482505987,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5825242718446602,
        "vocab_size-1-nopunct": 540,
        "unique-1-nopunct": 431,
        "entropy-1-nopunct": 8.233842511545966,
        "distinct-2-nopunct": 0.9316338354577057,
        "vocab_size-2-nopunct": 804,
        "unique-2-nopunct": 766,
        "entropy-2-nopunct": 9.58136997916286,
        "cond_entropy-2-nopunct": 1.4287160511826353,
        "distinct-3-nopunct": 0.9849812265331664,
        "vocab_size-3-nopunct": 787,
        "unique-3-nopunct": 775,
        "entropy-3-nopunct": 9.612014145994301,
        "cond_entropy-3-nopunct": 0.037938620247589136,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.018186262170972,
        "bleu": 43.32874,
        "rouge1": {
            "precision": 0.76281,
            "recall": 0.71779,
            "fmeasure": 0.73203
        },
        "rouge2": {
            "precision": 0.51184,
            "recall": 0.48921,
            "fmeasure": 0.49514
        },
        "rougeL": {
            "precision": 0.63241,
            "recall": 0.60389,
            "fmeasure": 0.61123
        },
        "rougeLsum": {
            "precision": 0.63241,
            "recall": 0.60389,
            "fmeasure": 0.61123
        },
        "local_recall": {
            "1": 0.1752136752136752,
            "2": 0.45374449339207046,
            "3": 0.7538461538461538
        },
        "bertscore": {
            "precision": 0.93094,
            "recall": 0.92133,
            "f1": 0.92451
        },
        "bleurt": 0.27535,
        "meteor": 0.38810889929383047,
        "nubia": {
            "semantic_relation": 4.2629,
            "contradiction": 11.92631,
            "irrelevancy": 29.2653,
            "logical_agreement": 58.8084,
            "grammar_ref": 4.72038,
            "grammar_hyp": 4.68954,
            "nubia_score": 0.74187
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_57": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.79,
        "total_length": 168,
        "mean_pred_length": 14.0,
        "std_pred_length": 5.082650227325635,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.6547619047619048,
        "vocab_size-1": 110,
        "unique-1": 90,
        "entropy-1": 6.336329677052694,
        "distinct-2": 0.9487179487179487,
        "vocab_size-2": 148,
        "unique-2": 140,
        "entropy-2": 7.182838116298163,
        "cond_entropy-2": 0.643089056752007,
        "distinct-3": 0.9861111111111112,
        "vocab_size-3": 142,
        "unique-3": 140,
        "entropy-3": 7.142147223664553,
        "cond_entropy-3": -0.03214388408660251,
        "total_length-nopunct": 146,
        "mean_pred_length-nopunct": 12.166666666666666,
        "std_pred_length-nopunct": 4.579543888011362,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7191780821917808,
        "vocab_size-1-nopunct": 105,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.4104379154428885,
        "distinct-2-nopunct": 0.9477611940298507,
        "vocab_size-2-nopunct": 127,
        "unique-2-nopunct": 120,
        "entropy-2-nopunct": 6.961611578517481,
        "cond_entropy-2-nopunct": 0.5776310123222563,
        "distinct-3-nopunct": 0.9836065573770492,
        "vocab_size-3-nopunct": 120,
        "unique-3-nopunct": 118,
        "entropy-3-nopunct": 6.897950452316999,
        "cond_entropy-3-nopunct": -0.06158136109160752,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.925155402757683,
        "bleu": 41.36754,
        "rouge1": {
            "precision": 0.73149,
            "recall": 0.7494,
            "fmeasure": 0.73226
        },
        "rouge2": {
            "precision": 0.51688,
            "recall": 0.50387,
            "fmeasure": 0.504
        },
        "rougeL": {
            "precision": 0.62381,
            "recall": 0.63009,
            "fmeasure": 0.62144
        },
        "rougeLsum": {
            "precision": 0.62381,
            "recall": 0.63009,
            "fmeasure": 0.62144
        },
        "local_recall": {
            "1": 0.15151515151515152,
            "2": 0.6785714285714286,
            "3": 0.7608695652173914
        },
        "bertscore": {
            "precision": 0.90794,
            "recall": 0.92585,
            "f1": 0.91518
        },
        "bleurt": 0.20817,
        "meteor": 0.39526948729945255,
        "nubia": {
            "semantic_relation": 4.31665,
            "contradiction": 8.57588,
            "irrelevancy": 34.24852,
            "logical_agreement": 57.1756,
            "grammar_ref": 5.5602,
            "grammar_hyp": 5.12698,
            "nubia_score": 0.7881
        }
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 297,
        "msttr-100": 0.61,
        "msttr-100_nopunct": 0.65692,
        "total_length": 3054,
        "mean_pred_length": 10.282828282828282,
        "std_pred_length": 2.6465417522887273,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 22,
        "distinct-1": 0.23706614276358873,
        "vocab_size-1": 724,
        "unique-1": 420,
        "entropy-1": 7.282919162415774,
        "distinct-2": 0.5640188610808851,
        "vocab_size-2": 1555,
        "unique-2": 1126,
        "entropy-2": 10.06457116096691,
        "cond_entropy-2": 2.3592856876635167,
        "distinct-3": 0.7430894308943089,
        "vocab_size-3": 1828,
        "unique-3": 1501,
        "entropy-3": 10.584735906959958,
        "cond_entropy-3": 0.60465531810282,
        "total_length-nopunct": 2681,
        "mean_pred_length-nopunct": 9.026936026936028,
        "std_pred_length-nopunct": 2.4258599168078083,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.26743752331219695,
        "vocab_size-1-nopunct": 717,
        "unique-1-nopunct": 419,
        "entropy-1-nopunct": 7.550137076418014,
        "distinct-2-nopunct": 0.5440436241610739,
        "vocab_size-2-nopunct": 1297,
        "unique-2-nopunct": 916,
        "entropy-2-nopunct": 9.783006352873114,
        "cond_entropy-2-nopunct": 2.54812305773236,
        "distinct-3-nopunct": 0.7297556300910397,
        "vocab_size-3-nopunct": 1523,
        "unique-3-nopunct": 1233,
        "entropy-3-nopunct": 10.31357358656603,
        "cond_entropy-3-nopunct": 0.6570498025734017,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.823152652671333,
        "bleu": 48.65114,
        "rouge1": {
            "precision": 0.73663,
            "recall": 0.74157,
            "fmeasure": 0.7317
        },
        "rouge2": {
            "precision": 0.49563,
            "recall": 0.50007,
            "fmeasure": 0.49232
        },
        "rougeL": {
            "precision": 0.6548,
            "recall": 0.66116,
            "fmeasure": 0.6511
        },
        "rougeLsum": {
            "precision": 0.6548,
            "recall": 0.66116,
            "fmeasure": 0.6511
        },
        "local_recall": {
            "1": 0.253077975376197,
            "2": 0.6290155440414508,
            "3": 0.7952421410365336,
            "4": 1.0
        },
        "bertscore": {
            "precision": 0.92683,
            "recall": 0.9305,
            "f1": 0.92795
        },
        "bleurt": 0.2027,
        "meteor": 0.41075361947465255,
        "nubia": {
            "semantic_relation": 4.21393,
            "contradiction": 23.33893,
            "irrelevancy": 5.62347,
            "logical_agreement": 71.0376,
            "grammar_ref": 5.16054,
            "grammar_hyp": 5.30864,
            "nubia_score": 0.69541
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_58": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3087295760761384,
        "bleu": 33.59973,
        "rouge1": {
            "precision": 0.70588,
            "recall": 0.9011,
            "fmeasure": 0.7914
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.59829,
            "fmeasure": 0.51888
        },
        "rougeL": {
            "precision": 0.47059,
            "recall": 0.60073,
            "fmeasure": 0.5276
        },
        "rougeLsum": {
            "precision": 0.47059,
            "recall": 0.60073,
            "fmeasure": 0.5276
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.91447,
            "recall": 0.94417,
            "f1": 0.92731
        },
        "bleurt": 0.4749,
        "meteor": 0.49531957519660874,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.26246,
            "irrelevancy": 80.49629,
            "logical_agreement": 19.24126,
            "grammar_ref": 5.12321,
            "grammar_hyp": 3.81202,
            "nubia_score": 0.99861
        }
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 72,
        "msttr-100": 0.61,
        "msttr-100_nopunct": 0.64,
        "total_length": 890,
        "mean_pred_length": 12.36111111111111,
        "std_pred_length": 3.2757762250409,
        "median_pred_length": 12.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.3393258426966292,
        "vocab_size-1": 302,
        "unique-1": 201,
        "entropy-1": 6.645806665681276,
        "distinct-2": 0.6931540342298288,
        "vocab_size-2": 567,
        "unique-2": 447,
        "entropy-2": 8.837379832175047,
        "cond_entropy-2": 1.9224446916858968,
        "distinct-3": 0.8257372654155496,
        "vocab_size-3": 616,
        "unique-3": 533,
        "entropy-3": 9.130473127887441,
        "cond_entropy-3": 0.3596116213867767,
        "total_length-nopunct": 777,
        "mean_pred_length-nopunct": 10.791666666666666,
        "std_pred_length-nopunct": 2.9483399283890814,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.38223938223938225,
        "vocab_size-1-nopunct": 297,
        "unique-1-nopunct": 200,
        "entropy-1-nopunct": 6.7709551115904825,
        "distinct-2-nopunct": 0.6808510638297872,
        "vocab_size-2-nopunct": 480,
        "unique-2-nopunct": 372,
        "entropy-2-nopunct": 8.585696716485865,
        "cond_entropy-2-nopunct": 2.0628180818134503,
        "distinct-3-nopunct": 0.8230647709320695,
        "vocab_size-3-nopunct": 521,
        "unique-3-nopunct": 448,
        "entropy-3-nopunct": 8.890201563846459,
        "cond_entropy-3-nopunct": 0.38054204185344553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 5.132982888927994,
        "bleu": 27.91097,
        "rouge1": {
            "precision": 0.60042,
            "recall": 0.61509,
            "fmeasure": 0.60137
        },
        "rouge2": {
            "precision": 0.32471,
            "recall": 0.33409,
            "fmeasure": 0.32585
        },
        "rougeL": {
            "precision": 0.50567,
            "recall": 0.52248,
            "fmeasure": 0.50821
        },
        "rougeLsum": {
            "precision": 0.50567,
            "recall": 0.52248,
            "fmeasure": 0.50821
        },
        "local_recall": {
            "1": 0.27230046948356806,
            "2": 0.524904214559387,
            "3": 0.662613981762918
        },
        "bertscore": {
            "precision": 0.86778,
            "recall": 0.87347,
            "f1": 0.8696
        },
        "bleurt": -0.3399,
        "meteor": 0.30376060840241803,
        "nubia": {
            "semantic_relation": 3.41465,
            "contradiction": 43.34937,
            "irrelevancy": 17.18911,
            "logical_agreement": 39.46153,
            "grammar_ref": 5.29268,
            "grammar_hyp": 5.46788,
            "nubia_score": 0.44558
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_80": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 83,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.78667,
        "total_length": 1469,
        "mean_pred_length": 17.698795180722893,
        "std_pred_length": 6.751590512762528,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 40,
        "distinct-1": 0.49625595643294756,
        "vocab_size-1": 729,
        "unique-1": 595,
        "entropy-1": 8.191903890247351,
        "distinct-2": 0.8852813852813853,
        "vocab_size-2": 1227,
        "unique-2": 1141,
        "entropy-2": 10.115715796242242,
        "cond_entropy-2": 1.6814995357163942,
        "distinct-3": 0.9731389102072141,
        "vocab_size-3": 1268,
        "unique-3": 1241,
        "entropy-3": 10.288135739247737,
        "cond_entropy-3": 0.16212746342309164,
        "total_length-nopunct": 1257,
        "mean_pred_length-nopunct": 15.144578313253012,
        "std_pred_length-nopunct": 5.468711727153884,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.573587907716786,
        "vocab_size-1-nopunct": 721,
        "unique-1-nopunct": 594,
        "entropy-1-nopunct": 8.505966648249775,
        "distinct-2-nopunct": 0.8986371379897785,
        "vocab_size-2-nopunct": 1055,
        "unique-2-nopunct": 994,
        "entropy-2-nopunct": 9.906780532101477,
        "cond_entropy-2-nopunct": 1.4943530627759243,
        "distinct-3-nopunct": 0.9761686526122824,
        "vocab_size-3-nopunct": 1065,
        "unique-3-nopunct": 1046,
        "entropy-3-nopunct": 10.037581227293433,
        "cond_entropy-3-nopunct": 0.14777708278396065,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.769452143774587,
        "bleu": 49.15962,
        "rouge1": {
            "precision": 0.7753,
            "recall": 0.74473,
            "fmeasure": 0.74784
        },
        "rouge2": {
            "precision": 0.53885,
            "recall": 0.51571,
            "fmeasure": 0.51868
        },
        "rougeL": {
            "precision": 0.66468,
            "recall": 0.64384,
            "fmeasure": 0.6434
        },
        "rougeLsum": {
            "precision": 0.66468,
            "recall": 0.64384,
            "fmeasure": 0.6434
        },
        "local_recall": {
            "1": 0.23387096774193547,
            "2": 0.5487804878048781,
            "3": 0.7788461538461539
        },
        "bertscore": {
            "precision": 0.93411,
            "recall": 0.92962,
            "f1": 0.93056
        },
        "bleurt": 0.32667,
        "meteor": 0.40754954944984945,
        "nubia": {
            "semantic_relation": 4.31305,
            "contradiction": 5.39765,
            "irrelevancy": 31.78142,
            "logical_agreement": 62.82093,
            "grammar_ref": 4.65999,
            "grammar_hyp": 4.67745,
            "nubia_score": 0.74587
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc_parent": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.73418,
        "msttr-100_nopunct": 0.77517,
        "total_length": 6745,
        "mean_pred_length": 18.788300835654596,
        "std_pred_length": 9.19760033853898,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 53,
        "distinct-1": 0.3654558932542624,
        "vocab_size-1": 2465,
        "unique-1": 1795,
        "entropy-1": 9.139203722771397,
        "distinct-2": 0.8429376761666145,
        "vocab_size-2": 5383,
        "unique-2": 4969,
        "entropy-2": 12.110166824203143,
        "cond_entropy-2": 2.6884442950359326,
        "distinct-3": 0.9668159946905591,
        "vocab_size-3": 5827,
        "unique-3": 5725,
        "entropy-3": 12.449683884252178,
        "cond_entropy-3": 0.3560208238505231,
        "total_length-nopunct": 6018,
        "mean_pred_length-nopunct": 16.76323119777159,
        "std_pred_length-nopunct": 8.256823741965132,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4076105018278498,
        "vocab_size-1-nopunct": 2453,
        "unique-1-nopunct": 1794,
        "entropy-1-nopunct": 9.470726780637374,
        "distinct-2-nopunct": 0.8598692348471462,
        "vocab_size-2-nopunct": 4866,
        "unique-2-nopunct": 4529,
        "entropy-2-nopunct": 11.998663240417565,
        "cond_entropy-2-nopunct": 2.669650936396991,
        "distinct-3-nopunct": 0.9794339622641509,
        "vocab_size-3-nopunct": 5191,
        "unique-3-nopunct": 5111,
        "entropy-3-nopunct": 12.323741327087413,
        "cond_entropy-3-nopunct": 0.3489702026540482,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "nist": 10.608691186882831,
        "bleu": 65.84823,
        "rouge1": {
            "precision": 0.84956,
            "recall": 0.76036,
            "fmeasure": 0.78668
        },
        "rouge2": {
            "precision": 0.7095,
            "recall": 0.63006,
            "fmeasure": 0.6513
        },
        "rougeL": {
            "precision": 0.82055,
            "recall": 0.73488,
            "fmeasure": 0.75967
        },
        "rougeLsum": {
            "precision": 0.82055,
            "recall": 0.73488,
            "fmeasure": 0.75967
        },
        "local_recall": {
            "1": 0.042232597623089986,
            "2": 0.1558109833971903,
            "3": 0.34573304157549234,
            "4": 0.49128367670364503,
            "5": 0.612668743509865,
            "6": 0.7373188405797102,
            "7": 0.8403970981290569
        },
        "bertscore": {
            "precision": 0.95412,
            "recall": 0.9357,
            "f1": 0.94232
        },
        "bleurt": 0.18045,
        "meteor": 0.44231752358001447,
        "nubia": {
            "semantic_relation": 4.20819,
            "contradiction": 4.57782,
            "irrelevancy": 15.16589,
            "logical_agreement": 80.25629,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.00327,
            "nubia_score": 0.6659
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_37": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.7,
        "total_length": 136,
        "mean_pred_length": 13.6,
        "std_pred_length": 3.826225293941799,
        "median_pred_length": 13.0,
        "min_pred_length": 5,
        "max_pred_length": 19,
        "distinct-1": 0.6029411764705882,
        "vocab_size-1": 82,
        "unique-1": 58,
        "entropy-1": 6.016398481524245,
        "distinct-2": 0.8412698412698413,
        "vocab_size-2": 106,
        "unique-2": 94,
        "entropy-2": 6.611890240822879,
        "cond_entropy-2": 0.4168517803175677,
        "distinct-3": 0.8879310344827587,
        "vocab_size-3": 103,
        "unique-3": 96,
        "entropy-3": 6.5947971588087615,
        "cond_entropy-3": -0.002835350748836357,
        "total_length-nopunct": 123,
        "mean_pred_length-nopunct": 12.3,
        "std_pred_length-nopunct": 3.4942810419312296,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6504065040650406,
        "vocab_size-1-nopunct": 80,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 6.066981298252149,
        "distinct-2-nopunct": 0.831858407079646,
        "vocab_size-2-nopunct": 94,
        "unique-2-nopunct": 83,
        "entropy-2-nopunct": 6.4304524135894665,
        "cond_entropy-2-nopunct": 0.41440325755739277,
        "distinct-3-nopunct": 0.8737864077669902,
        "vocab_size-3-nopunct": 90,
        "unique-3-nopunct": 83,
        "entropy-3-nopunct": 6.39009931346497,
        "cond_entropy-3-nopunct": -0.002515571112290278,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.337850519596103,
        "bleu": 71.67807,
        "rouge1": {
            "precision": 0.90208,
            "recall": 0.93442,
            "fmeasure": 0.91431
        },
        "rouge2": {
            "precision": 0.80523,
            "recall": 0.83804,
            "fmeasure": 0.81709
        },
        "rougeL": {
            "precision": 0.83102,
            "recall": 0.85854,
            "fmeasure": 0.84137
        },
        "rougeLsum": {
            "precision": 0.83102,
            "recall": 0.85854,
            "fmeasure": 0.84137
        },
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.36363636363636365,
            "3": 0.9339622641509434
        },
        "bertscore": {
            "precision": 0.97464,
            "recall": 0.97628,
            "f1": 0.97522
        },
        "bleurt": 0.76541,
        "meteor": 0.5262027006466221,
        "nubia": {
            "semantic_relation": 4.9064,
            "contradiction": 0.26127,
            "irrelevancy": 10.19586,
            "logical_agreement": 89.54288,
            "grammar_ref": 5.03704,
            "grammar_hyp": 5.04466,
            "nubia_score": 0.94433
        }
    },
    "cs_restaurants_challenge_test_scramble_parent": {
        "predictions_file": "T5-base (Baseline)/cs_restaurants_test",
        "N": 500,
        "msttr-100": 0.54272,
        "msttr-100_nopunct": 0.55767,
        "total_length": 8141,
        "mean_pred_length": 16.282,
        "std_pred_length": 6.201167309466824,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 49,
        "distinct-1": 0.06866478319616755,
        "vocab_size-1": 559,
        "unique-1": 223,
        "entropy-1": 6.282551556069725,
        "distinct-2": 0.2010208087946604,
        "vocab_size-2": 1536,
        "unique-2": 832,
        "entropy-2": 8.87736997776701,
        "cond_entropy-2": 2.5172062134339757,
        "distinct-3": 0.31158101106287633,
        "vocab_size-3": 2225,
        "unique-3": 1424,
        "entropy-3": 9.532008957266477,
        "cond_entropy-3": 0.7324505682293081,
        "total_length-nopunct": 7320,
        "mean_pred_length-nopunct": 14.64,
        "std_pred_length-nopunct": 5.7711697254542775,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.07581967213114754,
        "vocab_size-1-nopunct": 555,
        "unique-1-nopunct": 223,
        "entropy-1-nopunct": 6.288275271254842,
        "distinct-2-nopunct": 0.19589442815249267,
        "vocab_size-2-nopunct": 1336,
        "unique-2-nopunct": 702,
        "entropy-2-nopunct": 8.705465517498435,
        "cond_entropy-2-nopunct": 2.600457107885541,
        "distinct-3-nopunct": 0.31123417721518987,
        "vocab_size-3-nopunct": 1967,
        "unique-3-nopunct": 1251,
        "entropy-3-nopunct": 9.3740752095465,
        "cond_entropy-3-nopunct": 0.7569701354652553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 1.5842501498222163,
        "bleu": 3.77038,
        "rouge1": {
            "precision": 0.43526,
            "recall": 0.42853,
            "fmeasure": 0.41858
        },
        "rouge2": {
            "precision": 0.23523,
            "recall": 0.23174,
            "fmeasure": 0.22631
        },
        "rougeL": {
            "precision": 0.38319,
            "recall": 0.37755,
            "fmeasure": 0.36897
        },
        "rougeLsum": {
            "precision": 0.38319,
            "recall": 0.37755,
            "fmeasure": 0.36897
        },
        "local_recall": {
            "1": 0.2818541812252504
        },
        "bertscore": {
            "precision": 0.82,
            "recall": 0.84793,
            "f1": 0.83339
        },
        "bleurt": -0.74015,
        "meteor": 0.13097734538684488,
        "nubia": {
            "semantic_relation": 2.74265,
            "contradiction": 33.37508,
            "irrelevancy": 25.63566,
            "logical_agreement": 40.98926,
            "grammar_ref": 6.87434,
            "grammar_hyp": 6.21197,
            "nubia_score": 0.34604
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_16": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 111,
        "msttr-100": 0.66111,
        "msttr-100_nopunct": 0.69562,
        "total_length": 1885,
        "mean_pred_length": 16.98198198198198,
        "std_pred_length": 7.772650112120133,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 52,
        "distinct-1": 0.3915119363395225,
        "vocab_size-1": 738,
        "unique-1": 599,
        "entropy-1": 7.732706742364205,
        "distinct-2": 0.7147688838782412,
        "vocab_size-2": 1268,
        "unique-2": 1142,
        "entropy-2": 9.705570710888768,
        "cond_entropy-2": 1.7446836461669295,
        "distinct-3": 0.814792543595911,
        "vocab_size-3": 1355,
        "unique-3": 1283,
        "entropy-3": 10.004286186138462,
        "cond_entropy-3": 0.33758635543109006,
        "total_length-nopunct": 1613,
        "mean_pred_length-nopunct": 14.531531531531531,
        "std_pred_length-nopunct": 6.469359270138185,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.4513329200247985,
        "vocab_size-1-nopunct": 728,
        "unique-1-nopunct": 596,
        "entropy-1-nopunct": 7.972411637549575,
        "distinct-2-nopunct": 0.7276964047936085,
        "vocab_size-2-nopunct": 1093,
        "unique-2-nopunct": 999,
        "entropy-2-nopunct": 9.486446214779635,
        "cond_entropy-2-nopunct": 1.6342992041442044,
        "distinct-3-nopunct": 0.8209920920201293,
        "vocab_size-3-nopunct": 1142,
        "unique-3-nopunct": 1087,
        "entropy-3-nopunct": 9.760394232898223,
        "cond_entropy-3-nopunct": 0.3324378688123626,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.685263677313681,
        "bleu": 52.69182,
        "rouge1": {
            "precision": 0.78977,
            "recall": 0.74778,
            "fmeasure": 0.75752
        },
        "rouge2": {
            "precision": 0.58497,
            "recall": 0.54838,
            "fmeasure": 0.5589
        },
        "rougeL": {
            "precision": 0.69858,
            "recall": 0.66262,
            "fmeasure": 0.6691
        },
        "rougeLsum": {
            "precision": 0.69858,
            "recall": 0.66262,
            "fmeasure": 0.6691
        },
        "local_recall": {
            "1": 0.1787878787878788,
            "2": 0.4222222222222222,
            "3": 0.7924980047885076
        },
        "bertscore": {
            "precision": 0.9393,
            "recall": 0.93039,
            "f1": 0.93298
        },
        "bleurt": 0.388,
        "meteor": 0.4087213194215408,
        "nubia": {
            "semantic_relation": 4.23147,
            "contradiction": 7.56327,
            "irrelevancy": 21.27343,
            "logical_agreement": 71.1633,
            "grammar_ref": 4.48776,
            "grammar_hyp": 4.47906,
            "nubia_score": 0.74598
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_81": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.7,
        "total_length": 199,
        "mean_pred_length": 16.583333333333332,
        "std_pred_length": 8.788802851102963,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 36,
        "distinct-1": 0.6130653266331658,
        "vocab_size-1": 122,
        "unique-1": 93,
        "entropy-1": 6.4653353427446145,
        "distinct-2": 0.93048128342246,
        "vocab_size-2": 174,
        "unique-2": 161,
        "entropy-2": 7.407857026732538,
        "cond_entropy-2": 0.7876335627309148,
        "distinct-3": 0.9942857142857143,
        "vocab_size-3": 174,
        "unique-3": 173,
        "entropy-3": 7.439782540403735,
        "cond_entropy-3": 0.030030937658977717,
        "total_length-nopunct": 170,
        "mean_pred_length-nopunct": 14.166666666666666,
        "std_pred_length-nopunct": 7.1860203791033666,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6941176470588235,
        "vocab_size-1-nopunct": 118,
        "unique-1-nopunct": 93,
        "entropy-1-nopunct": 6.571135092231697,
        "distinct-2-nopunct": 0.9620253164556962,
        "vocab_size-2-nopunct": 152,
        "unique-2-nopunct": 146,
        "entropy-2-nopunct": 7.22783138108851,
        "cond_entropy-2-nopunct": 0.6913425396552031,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 146,
        "unique-3-nopunct": 146,
        "entropy-3-nopunct": 7.18982455888002,
        "cond_entropy-3-nopunct": -0.0386137235436609,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.46833535068602,
        "bleu": 36.54129,
        "rouge1": {
            "precision": 0.78068,
            "recall": 0.67077,
            "fmeasure": 0.70457
        },
        "rouge2": {
            "precision": 0.53392,
            "recall": 0.45103,
            "fmeasure": 0.47557
        },
        "rougeL": {
            "precision": 0.65238,
            "recall": 0.56459,
            "fmeasure": 0.59071
        },
        "rougeLsum": {
            "precision": 0.65238,
            "recall": 0.56459,
            "fmeasure": 0.59071
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.35,
            "3": 0.7461538461538462
        },
        "bertscore": {
            "precision": 0.92825,
            "recall": 0.9111,
            "f1": 0.91876
        },
        "bleurt": 0.16157,
        "meteor": 0.34601087897099553,
        "nubia": {
            "semantic_relation": 4.00736,
            "contradiction": 2.52533,
            "irrelevancy": 31.17071,
            "logical_agreement": 66.30395,
            "grammar_ref": 4.67736,
            "grammar_hyp": 4.51044,
            "nubia_score": 0.71076
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_38": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 74,
        "mean_pred_length": 12.333333333333334,
        "std_pred_length": 3.543381937578216,
        "median_pred_length": 11.5,
        "min_pred_length": 9,
        "max_pred_length": 19,
        "distinct-1": 0.7027027027027027,
        "vocab_size-1": 52,
        "unique-1": 41,
        "entropy-1": 5.42545319764242,
        "distinct-2": 0.9264705882352942,
        "vocab_size-2": 63,
        "unique-2": 58,
        "entropy-2": 5.940404017720933,
        "cond_entropy-2": 0.33641951824871114,
        "distinct-3": 0.9354838709677419,
        "vocab_size-3": 58,
        "unique-3": 54,
        "entropy-3": 5.825164052322355,
        "cond_entropy-3": -0.10100846634733521,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 10.666666666666666,
        "std_pred_length-nopunct": 2.8087165910587863,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.40055425036562,
        "distinct-2-nopunct": 0.9137931034482759,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.685567202024122,
        "cond_entropy-2-nopunct": 0.31254182231033534,
        "distinct-3-nopunct": 0.9230769230769231,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.546593564294942,
        "cond_entropy-3-nopunct": -0.13831050775571072,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.655080079977369,
        "bleu": 54.55155,
        "rouge1": {
            "precision": 0.72467,
            "recall": 0.81706,
            "fmeasure": 0.75751
        },
        "rouge2": {
            "precision": 0.55425,
            "recall": 0.59105,
            "fmeasure": 0.56781
        },
        "rougeL": {
            "precision": 0.68096,
            "recall": 0.76687,
            "fmeasure": 0.70993
        },
        "rougeLsum": {
            "precision": 0.68096,
            "recall": 0.76687,
            "fmeasure": 0.70993
        },
        "local_recall": {
            "1": 0.23809523809523808,
            "2": 0.6666666666666666,
            "3": 0.9696969696969697
        },
        "bertscore": {
            "precision": 0.93094,
            "recall": 0.93731,
            "f1": 0.93408
        },
        "bleurt": 0.34609,
        "meteor": 0.4652464064289942,
        "nubia": {
            "semantic_relation": 4.19078,
            "contradiction": 4.45537,
            "irrelevancy": 28.2211,
            "logical_agreement": 67.32353,
            "grammar_ref": 5.1808,
            "grammar_hyp": 4.7065,
            "nubia_score": 0.74687
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_39": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 26,
        "msttr-100": 0.70667,
        "msttr-100_nopunct": 0.73667,
        "total_length": 389,
        "mean_pred_length": 14.961538461538462,
        "std_pred_length": 5.034349467032758,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.5861182519280206,
        "vocab_size-1": 228,
        "unique-1": 187,
        "entropy-1": 7.034302959080527,
        "distinct-2": 0.9090909090909091,
        "vocab_size-2": 330,
        "unique-2": 309,
        "entropy-2": 8.286141027228132,
        "cond_entropy-2": 1.0275707826431648,
        "distinct-3": 0.9703264094955489,
        "vocab_size-3": 327,
        "unique-3": 319,
        "entropy-3": 8.332777555649717,
        "cond_entropy-3": 0.06343119453425916,
        "total_length-nopunct": 332,
        "mean_pred_length-nopunct": 12.76923076923077,
        "std_pred_length-nopunct": 3.7242210575108317,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6686746987951807,
        "vocab_size-1-nopunct": 222,
        "unique-1-nopunct": 186,
        "entropy-1-nopunct": 7.210009750057563,
        "distinct-2-nopunct": 0.9150326797385621,
        "vocab_size-2-nopunct": 280,
        "unique-2-nopunct": 265,
        "entropy-2-nopunct": 8.047372605743371,
        "cond_entropy-2-nopunct": 0.9175454838274549,
        "distinct-3-nopunct": 0.975,
        "vocab_size-3-nopunct": 273,
        "unique-3-nopunct": 267,
        "entropy-3-nopunct": 8.076586990151538,
        "cond_entropy-3-nopunct": 0.03948379033662128,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.079162135486508,
        "bleu": 47.81106,
        "rouge1": {
            "precision": 0.75996,
            "recall": 0.72271,
            "fmeasure": 0.72881
        },
        "rouge2": {
            "precision": 0.50766,
            "recall": 0.47991,
            "fmeasure": 0.48397
        },
        "rougeL": {
            "precision": 0.67193,
            "recall": 0.6495,
            "fmeasure": 0.65003
        },
        "rougeLsum": {
            "precision": 0.67193,
            "recall": 0.6495,
            "fmeasure": 0.65003
        },
        "local_recall": {
            "1": 0.21839080459770116,
            "2": 0.4731182795698925,
            "3": 0.776824034334764
        },
        "bertscore": {
            "precision": 0.92569,
            "recall": 0.92392,
            "f1": 0.92247
        },
        "bleurt": 0.20145,
        "meteor": 0.3769883318624235,
        "nubia": {
            "semantic_relation": 4.05144,
            "contradiction": 4.6742,
            "irrelevancy": 37.97143,
            "logical_agreement": 57.35438,
            "grammar_ref": 4.64456,
            "grammar_hyp": 4.54415,
            "nubia_score": 0.71477
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_82": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322706,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.277613436819116,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.037503523749935014,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.103812131983694,
        "bleu": 42.7287,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.65873,
            "fmeasure": 0.62939
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.44762,
            "fmeasure": 0.40261
        },
        "rougeL": {
            "precision": 0.60606,
            "recall": 0.62698,
            "fmeasure": 0.58772
        },
        "rougeLsum": {
            "precision": 0.60606,
            "recall": 0.62698,
            "fmeasure": 0.58772
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.94636,
            "recall": 0.95128,
            "f1": 0.93033
        },
        "bleurt": 0.19516,
        "meteor": 0.38509330471364045,
        "nubia": {
            "semantic_relation": 4.24582,
            "contradiction": 0.1292,
            "irrelevancy": 66.59298,
            "logical_agreement": 33.27782,
            "grammar_ref": 5.89248,
            "grammar_hyp": 7.01071,
            "nubia_score": 0.58508
        }
    },
    "totto_test_contrast_challenge_continent-asia": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 150,
        "msttr-100": 0.71583,
        "msttr-100_nopunct": 0.75762,
        "total_length": 2496,
        "mean_pred_length": 16.64,
        "std_pred_length": 5.578864878569236,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 43,
        "distinct-1": 0.43189102564102566,
        "vocab_size-1": 1078,
        "unique-1": 854,
        "entropy-1": 8.425217062027789,
        "distinct-2": 0.7928388746803069,
        "vocab_size-2": 1860,
        "unique-2": 1660,
        "entropy-2": 10.542402192579065,
        "cond_entropy-2": 1.8378607358154084,
        "distinct-3": 0.9221311475409836,
        "vocab_size-3": 2025,
        "unique-3": 1928,
        "entropy-3": 10.90229697203734,
        "cond_entropy-3": 0.3546908885476339,
        "total_length-nopunct": 2197,
        "mean_pred_length-nopunct": 14.646666666666667,
        "std_pred_length-nopunct": 5.140864605189373,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.48702776513427404,
        "vocab_size-1-nopunct": 1070,
        "unique-1-nopunct": 852,
        "entropy-1-nopunct": 8.714151228060242,
        "distinct-2-nopunct": 0.8055691255495847,
        "vocab_size-2-nopunct": 1649,
        "unique-2-nopunct": 1496,
        "entropy-2-nopunct": 10.369186994907954,
        "cond_entropy-2-nopunct": 1.7548069156390316,
        "distinct-3-nopunct": 0.9351607801792303,
        "vocab_size-3-nopunct": 1774,
        "unique-3-nopunct": 1706,
        "entropy-3-nopunct": 10.719782505651866,
        "cond_entropy-3-nopunct": 0.3772336512939701,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.309902563004478,
        "bleu": 49.50198,
        "rouge1": {
            "precision": 0.82058,
            "recall": 0.78759,
            "fmeasure": 0.79513
        },
        "rouge2": {
            "precision": 0.59732,
            "recall": 0.5831,
            "fmeasure": 0.58341
        },
        "rougeL": {
            "precision": 0.69705,
            "recall": 0.67428,
            "fmeasure": 0.67803
        },
        "rougeLsum": {
            "precision": 0.69705,
            "recall": 0.67428,
            "fmeasure": 0.67803
        },
        "local_recall": {
            "1": 0.1951219512195122,
            "2": 0.45135135135135135,
            "3": 0.8029782359679267
        },
        "bertscore": {
            "precision": 0.94853,
            "recall": 0.94524,
            "f1": 0.94609
        },
        "bleurt": 0.39075,
        "meteor": 0.4188204541980657,
        "nubia": {
            "semantic_relation": 4.53442,
            "contradiction": 6.06142,
            "irrelevancy": 24.39025,
            "logical_agreement": 69.54833,
            "grammar_ref": 5.14336,
            "grammar_hyp": 5.17205,
            "nubia_score": 0.80218
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_60": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 114,
        "msttr-100": 0.73158,
        "msttr-100_nopunct": 0.77294,
        "total_length": 1953,
        "mean_pred_length": 17.13157894736842,
        "std_pred_length": 6.766160846051807,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 38,
        "distinct-1": 0.4608294930875576,
        "vocab_size-1": 900,
        "unique-1": 702,
        "entropy-1": 8.369815587053884,
        "distinct-2": 0.8548123980424144,
        "vocab_size-2": 1572,
        "unique-2": 1423,
        "entropy-2": 10.453678135252082,
        "cond_entropy-2": 1.8160039327069697,
        "distinct-3": 0.9623188405797102,
        "vocab_size-3": 1660,
        "unique-3": 1603,
        "entropy-3": 10.67323321176272,
        "cond_entropy-3": 0.21437674301492193,
        "total_length-nopunct": 1703,
        "mean_pred_length-nopunct": 14.93859649122807,
        "std_pred_length-nopunct": 5.938700146805856,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.5220199647680563,
        "vocab_size-1-nopunct": 889,
        "unique-1-nopunct": 697,
        "entropy-1-nopunct": 8.678940957131179,
        "distinct-2-nopunct": 0.8678414096916299,
        "vocab_size-2-nopunct": 1379,
        "unique-2-nopunct": 1266,
        "entropy-2-nopunct": 10.268289284403782,
        "cond_entropy-2-nopunct": 1.6722410998873942,
        "distinct-3-nopunct": 0.9606779661016949,
        "vocab_size-3-nopunct": 1417,
        "unique-3-nopunct": 1367,
        "entropy-3-nopunct": 10.443428510314044,
        "cond_entropy-3-nopunct": 0.19407151251505647,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.586959618462992,
        "bleu": 43.91492,
        "rouge1": {
            "precision": 0.74402,
            "recall": 0.74157,
            "fmeasure": 0.7301
        },
        "rouge2": {
            "precision": 0.50604,
            "recall": 0.50669,
            "fmeasure": 0.49723
        },
        "rougeL": {
            "precision": 0.6189,
            "recall": 0.62426,
            "fmeasure": 0.61041
        },
        "rougeLsum": {
            "precision": 0.6189,
            "recall": 0.62426,
            "fmeasure": 0.61041
        },
        "local_recall": {
            "1": 0.21333333333333335,
            "2": 0.5467980295566502,
            "3": 0.7865367581930912
        },
        "bertscore": {
            "precision": 0.92721,
            "recall": 0.92385,
            "f1": 0.9238
        },
        "bleurt": 0.2745,
        "meteor": 0.39634783162264614,
        "nubia": {
            "semantic_relation": 4.21481,
            "contradiction": 8.05224,
            "irrelevancy": 31.63005,
            "logical_agreement": 60.31771,
            "grammar_ref": 4.84845,
            "grammar_hyp": 4.73194,
            "nubia_score": 0.73366
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_17": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 48,
        "msttr-100": 0.54429,
        "msttr-100_nopunct": 0.56333,
        "total_length": 728,
        "mean_pred_length": 15.166666666666666,
        "std_pred_length": 5.7638721552635275,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 48,
        "distinct-1": 0.34065934065934067,
        "vocab_size-1": 248,
        "unique-1": 201,
        "entropy-1": 6.391083113502856,
        "distinct-2": 0.5941176470588235,
        "vocab_size-2": 404,
        "unique-2": 354,
        "entropy-2": 7.930023349367101,
        "cond_entropy-2": 1.362610942869871,
        "distinct-3": 0.7104430379746836,
        "vocab_size-3": 449,
        "unique-3": 409,
        "entropy-3": 8.322272456866852,
        "cond_entropy-3": 0.4283706813884875,
        "total_length-nopunct": 628,
        "mean_pred_length-nopunct": 13.083333333333334,
        "std_pred_length-nopunct": 4.631564410530085,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.3853503184713376,
        "vocab_size-1-nopunct": 242,
        "unique-1-nopunct": 200,
        "entropy-1-nopunct": 6.475474310098558,
        "distinct-2-nopunct": 0.6051724137931035,
        "vocab_size-2-nopunct": 351,
        "unique-2-nopunct": 310,
        "entropy-2-nopunct": 7.749372970183782,
        "cond_entropy-2-nopunct": 1.3600431774254265,
        "distinct-3-nopunct": 0.7161654135338346,
        "vocab_size-3-nopunct": 381,
        "unique-3-nopunct": 348,
        "entropy-3-nopunct": 8.092203501046665,
        "cond_entropy-3-nopunct": 0.4256090484745512,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.482692251064094,
        "bleu": 65.78801,
        "rouge1": {
            "precision": 0.83052,
            "recall": 0.80471,
            "fmeasure": 0.81013
        },
        "rouge2": {
            "precision": 0.66172,
            "recall": 0.64151,
            "fmeasure": 0.6462
        },
        "rougeL": {
            "precision": 0.77136,
            "recall": 0.74516,
            "fmeasure": 0.75168
        },
        "rougeLsum": {
            "precision": 0.77136,
            "recall": 0.74516,
            "fmeasure": 0.75168
        },
        "local_recall": {
            "1": 0.25675675675675674,
            "2": 0.5625,
            "3": 0.8382642998027613
        },
        "bertscore": {
            "precision": 0.95867,
            "recall": 0.95244,
            "f1": 0.9543
        },
        "bleurt": 0.60214,
        "meteor": 0.46441820341670825,
        "nubia": {
            "semantic_relation": 4.51452,
            "contradiction": 4.99791,
            "irrelevancy": 14.05495,
            "logical_agreement": 80.94714,
            "grammar_ref": 4.06325,
            "grammar_hyp": 4.06773,
            "nubia_score": 0.86597
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_61": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 57,
        "mean_pred_length": 14.25,
        "std_pred_length": 5.629165124598851,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.8070175438596491,
        "vocab_size-1": 46,
        "unique-1": 39,
        "entropy-1": 5.385350101808125,
        "distinct-2": 0.9811320754716981,
        "vocab_size-2": 52,
        "unique-2": 51,
        "entropy-2": 5.690184605506592,
        "cond_entropy-2": 0.18766770463104115,
        "distinct-3": 1.0,
        "vocab_size-3": 49,
        "unique-3": 49,
        "entropy-3": 5.614709844115208,
        "cond_entropy-3": -0.07239428391737843,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 5.244044240850758,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.363713275750191,
        "distinct-2-nopunct": 0.9791666666666666,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.543295834054494,
        "cond_entropy-2-nopunct": 0.20764309517020865,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.4594316186372955,
        "cond_entropy-3-nopunct": -0.08007633662931377,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.697780629898609,
        "bleu": 46.60897,
        "rouge1": {
            "precision": 0.67299,
            "recall": 0.80561,
            "fmeasure": 0.71216
        },
        "rouge2": {
            "precision": 0.46104,
            "recall": 0.58954,
            "fmeasure": 0.50151
        },
        "rougeL": {
            "precision": 0.61109,
            "recall": 0.76678,
            "fmeasure": 0.66679
        },
        "rougeLsum": {
            "precision": 0.61109,
            "recall": 0.76678,
            "fmeasure": 0.66679
        },
        "local_recall": {
            "1": 0.3684210526315789,
            "2": 0.7428571428571429,
            "3": 0.625
        },
        "bertscore": {
            "precision": 0.91345,
            "recall": 0.93564,
            "f1": 0.91954
        },
        "bleurt": 0.29195,
        "meteor": 0.4429686303824035,
        "nubia": {
            "semantic_relation": 4.24012,
            "contradiction": 0.57061,
            "irrelevancy": 80.7259,
            "logical_agreement": 18.70348,
            "grammar_ref": 5.36601,
            "grammar_hyp": 4.88578,
            "nubia_score": 0.75741
        }
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 1654,
        "msttr-100": 0.52222,
        "msttr-100_nopunct": 0.53684,
        "total_length": 41571,
        "mean_pred_length": 25.133615477629988,
        "std_pred_length": 13.100935265252293,
        "median_pred_length": 23.0,
        "min_pred_length": 5,
        "max_pred_length": 75,
        "distinct-1": 0.053450722859685836,
        "vocab_size-1": 2222,
        "unique-1": 687,
        "entropy-1": 8.078556041718839,
        "distinct-2": 0.19908810782373426,
        "vocab_size-2": 7947,
        "unique-2": 3794,
        "entropy-2": 11.47161903142674,
        "cond_entropy-2": 3.2249301893597804,
        "distinct-3": 0.3643728928730105,
        "vocab_size-3": 13942,
        "unique-3": 8508,
        "entropy-3": 12.78480331474387,
        "cond_entropy-3": 1.3723618901148922,
        "total_length-nopunct": 36788,
        "mean_pred_length-nopunct": 22.241837968561065,
        "std_pred_length-nopunct": 11.769071450752755,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 65,
        "distinct-1-nopunct": 0.06012830270740459,
        "vocab_size-1-nopunct": 2212,
        "unique-1-nopunct": 687,
        "entropy-1-nopunct": 8.366651063637708,
        "distinct-2-nopunct": 0.21474924574486254,
        "vocab_size-2-nopunct": 7545,
        "unique-2-nopunct": 3844,
        "entropy-2-nopunct": 11.392288692560015,
        "cond_entropy-2-nopunct": 3.1673493502071195,
        "distinct-3-nopunct": 0.3819295101553166,
        "vocab_size-3-nopunct": 12787,
        "unique-3-nopunct": 8115,
        "entropy-3-nopunct": 12.654051569806105,
        "cond_entropy-3-nopunct": 1.3199679494088241,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.871299178656471,
        "bleu": 39.41375,
        "rouge1": {
            "precision": 0.68393,
            "recall": 0.69472,
            "fmeasure": 0.6828
        },
        "rouge2": {
            "precision": 0.41842,
            "recall": 0.42507,
            "fmeasure": 0.41742
        },
        "rougeL": {
            "precision": 0.54018,
            "recall": 0.55018,
            "fmeasure": 0.53957
        },
        "rougeLsum": {
            "precision": 0.54018,
            "recall": 0.55018,
            "fmeasure": 0.53957
        },
        "local_recall": {
            "1": 0.23031904851802906,
            "2": 0.5581297388374052,
            "3": 0.7863636363636364,
            "4": 0.8545454545454545,
            "5": 0.7241379310344828
        },
        "bertscore": {
            "precision": 0.89774,
            "recall": 0.90141,
            "f1": 0.89842
        },
        "bleurt": -0.01273,
        "meteor": 0.3446032052617339,
        "nubia": {
            "semantic_relation": 4.03726,
            "contradiction": 23.5818,
            "irrelevancy": 9.69811,
            "logical_agreement": 66.7201,
            "grammar_ref": 4.57661,
            "grammar_hyp": 4.68006,
            "nubia_score": 0.66851
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_63": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 39,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.812,
        "total_length": 680,
        "mean_pred_length": 17.435897435897434,
        "std_pred_length": 8.538885028382929,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 44,
        "distinct-1": 0.5691176470588235,
        "vocab_size-1": 387,
        "unique-1": 327,
        "entropy-1": 7.621340596004302,
        "distinct-2": 0.9282371294851794,
        "vocab_size-2": 595,
        "unique-2": 562,
        "entropy-2": 9.156045698708015,
        "cond_entropy-2": 1.3175279343497275,
        "distinct-3": 0.9767441860465116,
        "vocab_size-3": 588,
        "unique-3": 574,
        "entropy-3": 9.187108048852751,
        "cond_entropy-3": 0.035310288796803875,
        "total_length-nopunct": 562,
        "mean_pred_length-nopunct": 14.41025641025641,
        "std_pred_length-nopunct": 5.763358835128949,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6797153024911032,
        "vocab_size-1-nopunct": 382,
        "unique-1-nopunct": 327,
        "entropy-1-nopunct": 7.992217839729034,
        "distinct-2-nopunct": 0.9483747609942639,
        "vocab_size-2-nopunct": 496,
        "unique-2-nopunct": 474,
        "entropy-2-nopunct": 8.919262427821566,
        "cond_entropy-2-nopunct": 0.9862437625446814,
        "distinct-3-nopunct": 0.981404958677686,
        "vocab_size-3-nopunct": 475,
        "unique-3-nopunct": 466,
        "entropy-3-nopunct": 8.881673154630013,
        "cond_entropy-3-nopunct": -0.030678563215135547,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.805455509180281,
        "bleu": 45.27815,
        "rouge1": {
            "precision": 0.78607,
            "recall": 0.68228,
            "fmeasure": 0.71956
        },
        "rouge2": {
            "precision": 0.51985,
            "recall": 0.45719,
            "fmeasure": 0.47829
        },
        "rougeL": {
            "precision": 0.6647,
            "recall": 0.58247,
            "fmeasure": 0.60965
        },
        "rougeLsum": {
            "precision": 0.6647,
            "recall": 0.58247,
            "fmeasure": 0.60965
        },
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.6084656084656085,
            "3": 0.739454094292804
        },
        "bertscore": {
            "precision": 0.93456,
            "recall": 0.91942,
            "f1": 0.92554
        },
        "bleurt": 0.33997,
        "meteor": 0.3896944844060915,
        "nubia": {
            "semantic_relation": 4.29301,
            "contradiction": 4.63057,
            "irrelevancy": 28.37441,
            "logical_agreement": 66.99502,
            "grammar_ref": 4.28467,
            "grammar_hyp": 4.44985,
            "nubia_score": 0.75106
        }
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 125,
        "msttr-100": 0.51,
        "msttr-100_nopunct": 0.515,
        "total_length": 3875,
        "mean_pred_length": 31.0,
        "std_pred_length": 10.067770358922575,
        "median_pred_length": 31.0,
        "min_pred_length": 11,
        "max_pred_length": 62,
        "distinct-1": 0.14580645161290323,
        "vocab_size-1": 565,
        "unique-1": 213,
        "entropy-1": 7.117024800396277,
        "distinct-2": 0.376,
        "vocab_size-2": 1410,
        "unique-2": 793,
        "entropy-2": 9.686248501487906,
        "cond_entropy-2": 2.471273328033145,
        "distinct-3": 0.5550344827586207,
        "vocab_size-3": 2012,
        "unique-3": 1389,
        "entropy-3": 10.52399905444515,
        "cond_entropy-3": 0.8719818398788112,
        "total_length-nopunct": 3455,
        "mean_pred_length-nopunct": 27.64,
        "std_pred_length-nopunct": 9.11736804127156,
        "median_pred_length-nopunct": 28.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 58,
        "distinct-1-nopunct": 0.16150506512301013,
        "vocab_size-1-nopunct": 558,
        "unique-1-nopunct": 211,
        "entropy-1-nopunct": 7.2534275457549615,
        "distinct-2-nopunct": 0.3918918918918919,
        "vocab_size-2-nopunct": 1305,
        "unique-2-nopunct": 764,
        "entropy-2-nopunct": 9.578644403367088,
        "cond_entropy-2-nopunct": 2.409805324424901,
        "distinct-3-nopunct": 0.568798751950078,
        "vocab_size-3-nopunct": 1823,
        "unique-3-nopunct": 1291,
        "entropy-3-nopunct": 10.382867422190104,
        "cond_entropy-3-nopunct": 0.8304550422230634,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 5.480205809753732,
        "bleu": 24.81142,
        "rouge1": {
            "precision": 0.56938,
            "recall": 0.59229,
            "fmeasure": 0.57327
        },
        "rouge2": {
            "precision": 0.28206,
            "recall": 0.29905,
            "fmeasure": 0.28597
        },
        "rougeL": {
            "precision": 0.41373,
            "recall": 0.4356,
            "fmeasure": 0.41837
        },
        "rougeLsum": {
            "precision": 0.41373,
            "recall": 0.4356,
            "fmeasure": 0.41837
        },
        "local_recall": {
            "1": 0.19570871261378414,
            "2": 0.43196004993757803,
            "3": 0.6803571428571429
        },
        "bertscore": {
            "precision": 0.85642,
            "recall": 0.85849,
            "f1": 0.8556
        },
        "bleurt": -0.35941,
        "meteor": 0.26782260435860283,
        "nubia": {
            "semantic_relation": 3.38516,
            "contradiction": 40.71753,
            "irrelevancy": 14.57427,
            "logical_agreement": 44.70819,
            "grammar_ref": 4.33462,
            "grammar_hyp": 4.50482,
            "nubia_score": 0.50717
        }
    },
    "totto_test_contrast_challenge_continent-europe": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 150,
        "msttr-100": 0.72261,
        "msttr-100_nopunct": 0.7655,
        "total_length": 2357,
        "mean_pred_length": 15.713333333333333,
        "std_pred_length": 6.38783914081193,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 41,
        "distinct-1": 0.4196011879507849,
        "vocab_size-1": 989,
        "unique-1": 777,
        "entropy-1": 8.307771817423934,
        "distinct-2": 0.8146805618486633,
        "vocab_size-2": 1798,
        "unique-2": 1617,
        "entropy-2": 10.542736426214363,
        "cond_entropy-2": 1.940411745310335,
        "distinct-3": 0.9470102090422946,
        "vocab_size-3": 1948,
        "unique-3": 1874,
        "entropy-3": 10.881588870230555,
        "cond_entropy-3": 0.3346162893028778,
        "total_length-nopunct": 2086,
        "mean_pred_length-nopunct": 13.906666666666666,
        "std_pred_length-nopunct": 5.670210656482604,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.4712368168744008,
        "vocab_size-1-nopunct": 983,
        "unique-1-nopunct": 776,
        "entropy-1-nopunct": 8.584104377403209,
        "distinct-2-nopunct": 0.8285123966942148,
        "vocab_size-2-nopunct": 1604,
        "unique-2-nopunct": 1463,
        "entropy-2-nopunct": 10.380501710508684,
        "cond_entropy-2-nopunct": 1.8990301222285637,
        "distinct-3-nopunct": 0.9540873460246361,
        "vocab_size-3-nopunct": 1704,
        "unique-3-nopunct": 1651,
        "entropy-3-nopunct": 10.69265079430115,
        "cond_entropy-3-nopunct": 0.3349247911929757,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.149287109981993,
        "bleu": 48.02056,
        "rouge1": {
            "precision": 0.80476,
            "recall": 0.75899,
            "fmeasure": 0.77259
        },
        "rouge2": {
            "precision": 0.5739,
            "recall": 0.54381,
            "fmeasure": 0.55127
        },
        "rougeL": {
            "precision": 0.69534,
            "recall": 0.66108,
            "fmeasure": 0.66984
        },
        "rougeLsum": {
            "precision": 0.69534,
            "recall": 0.66108,
            "fmeasure": 0.66984
        },
        "local_recall": {
            "1": 0.1788793103448276,
            "2": 0.4135135135135135,
            "3": 0.805304400241109
        },
        "bertscore": {
            "precision": 0.94104,
            "recall": 0.93649,
            "f1": 0.93766
        },
        "bleurt": 0.35709,
        "meteor": 0.416874955731331,
        "nubia": {
            "semantic_relation": 4.47284,
            "contradiction": 2.82091,
            "irrelevancy": 26.20745,
            "logical_agreement": 70.97164,
            "grammar_ref": 4.85127,
            "grammar_hyp": 4.92334,
            "nubia_score": 0.79664
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_64": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.68143,
        "msttr-100_nopunct": 0.74333,
        "total_length": 723,
        "mean_pred_length": 20.083333333333332,
        "std_pred_length": 8.13898369303905,
        "median_pred_length": 19.5,
        "min_pred_length": 9,
        "max_pred_length": 44,
        "distinct-1": 0.5435684647302904,
        "vocab_size-1": 393,
        "unique-1": 329,
        "entropy-1": 7.545188556580966,
        "distinct-2": 0.9184861717612809,
        "vocab_size-2": 631,
        "unique-2": 601,
        "entropy-2": 9.212081153015104,
        "cond_entropy-2": 1.498302462578711,
        "distinct-3": 0.989247311827957,
        "vocab_size-3": 644,
        "unique-3": 639,
        "entropy-3": 9.322689193988342,
        "cond_entropy-3": 0.10450270213246808,
        "total_length-nopunct": 612,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 6.213783960769083,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.630718954248366,
        "vocab_size-1-nopunct": 386,
        "unique-1-nopunct": 327,
        "entropy-1-nopunct": 7.813396128009831,
        "distinct-2-nopunct": 0.9392361111111112,
        "vocab_size-2-nopunct": 541,
        "unique-2-nopunct": 523,
        "entropy-2-nopunct": 9.005718277800025,
        "cond_entropy-2-nopunct": 1.2656360633777215,
        "distinct-3-nopunct": 0.9925925925925926,
        "vocab_size-3-nopunct": 536,
        "unique-3-nopunct": 534,
        "entropy-3-nopunct": 9.059204902598308,
        "cond_entropy-3-nopunct": 0.06258188785604481,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.427277762269485,
        "bleu": 36.70803,
        "rouge1": {
            "precision": 0.73483,
            "recall": 0.71014,
            "fmeasure": 0.71071
        },
        "rouge2": {
            "precision": 0.44777,
            "recall": 0.42755,
            "fmeasure": 0.43062
        },
        "rougeL": {
            "precision": 0.60092,
            "recall": 0.57908,
            "fmeasure": 0.58095
        },
        "rougeLsum": {
            "precision": 0.60092,
            "recall": 0.57908,
            "fmeasure": 0.58095
        },
        "local_recall": {
            "1": 0.26495726495726496,
            "2": 0.4852941176470588,
            "3": 0.7638190954773869
        },
        "bertscore": {
            "precision": 0.92158,
            "recall": 0.92194,
            "f1": 0.92063
        },
        "bleurt": 0.25088,
        "meteor": 0.36309973359925124,
        "nubia": {
            "semantic_relation": 4.19946,
            "contradiction": 12.1641,
            "irrelevancy": 26.11708,
            "logical_agreement": 61.71883,
            "grammar_ref": 4.71629,
            "grammar_hyp": 4.70966,
            "nubia_score": 0.72703
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_84": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 80,
        "msttr-100": 0.71692,
        "msttr-100_nopunct": 0.77636,
        "total_length": 1317,
        "mean_pred_length": 16.4625,
        "std_pred_length": 7.536484176988631,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 44,
        "distinct-1": 0.4996203492786636,
        "vocab_size-1": 658,
        "unique-1": 518,
        "entropy-1": 8.133864673952049,
        "distinct-2": 0.8932902182700081,
        "vocab_size-2": 1105,
        "unique-2": 1024,
        "entropy-2": 9.996117679710826,
        "cond_entropy-2": 1.5952601489557006,
        "distinct-3": 0.9792566983578219,
        "vocab_size-3": 1133,
        "unique-3": 1111,
        "entropy-3": 10.133381640893026,
        "cond_entropy-3": 0.12837424334693018,
        "total_length-nopunct": 1129,
        "mean_pred_length-nopunct": 14.1125,
        "std_pred_length-nopunct": 6.358053456050838,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.5766164747564216,
        "vocab_size-1-nopunct": 651,
        "unique-1-nopunct": 515,
        "entropy-1-nopunct": 8.476762844738081,
        "distinct-2-nopunct": 0.9161105815061964,
        "vocab_size-2-nopunct": 961,
        "unique-2-nopunct": 905,
        "entropy-2-nopunct": 9.814927290701712,
        "cond_entropy-2-nopunct": 1.4193836199185854,
        "distinct-3-nopunct": 0.9876160990712074,
        "vocab_size-3-nopunct": 957,
        "unique-3-nopunct": 945,
        "entropy-3-nopunct": 9.895585053557571,
        "cond_entropy-3-nopunct": 0.09674623937788304,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.33116063204182,
        "bleu": 45.03504,
        "rouge1": {
            "precision": 0.76892,
            "recall": 0.70078,
            "fmeasure": 0.72039
        },
        "rouge2": {
            "precision": 0.52491,
            "recall": 0.47719,
            "fmeasure": 0.49081
        },
        "rougeL": {
            "precision": 0.67812,
            "recall": 0.62268,
            "fmeasure": 0.63731
        },
        "rougeLsum": {
            "precision": 0.67812,
            "recall": 0.62268,
            "fmeasure": 0.63731
        },
        "local_recall": {
            "1": 0.22033898305084745,
            "2": 0.39436619718309857,
            "3": 0.7513873473917869
        },
        "bertscore": {
            "precision": 0.93089,
            "recall": 0.92221,
            "f1": 0.92422
        },
        "bleurt": 0.26755,
        "meteor": 0.38786443744208,
        "nubia": {
            "semantic_relation": 4.21805,
            "contradiction": 8.05766,
            "irrelevancy": 27.51513,
            "logical_agreement": 64.42721,
            "grammar_ref": 4.79239,
            "grammar_hyp": 4.82217,
            "nubia_score": 0.73018
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_40": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 110,
        "msttr-100": 0.73059,
        "msttr-100_nopunct": 0.77267,
        "total_length": 1730,
        "mean_pred_length": 15.727272727272727,
        "std_pred_length": 6.34451673194921,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 37,
        "distinct-1": 0.47803468208092487,
        "vocab_size-1": 827,
        "unique-1": 671,
        "entropy-1": 8.277305717897598,
        "distinct-2": 0.8567901234567902,
        "vocab_size-2": 1388,
        "unique-2": 1273,
        "entropy-2": 10.26484741519094,
        "cond_entropy-2": 1.6954231775533668,
        "distinct-3": 0.952317880794702,
        "vocab_size-3": 1438,
        "unique-3": 1387,
        "entropy-3": 10.451714775624229,
        "cond_entropy-3": 0.19070052076614016,
        "total_length-nopunct": 1517,
        "mean_pred_length-nopunct": 13.790909090909091,
        "std_pred_length-nopunct": 5.582595444846998,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.5385629531970996,
        "vocab_size-1-nopunct": 817,
        "unique-1-nopunct": 668,
        "entropy-1-nopunct": 8.54524535453172,
        "distinct-2-nopunct": 0.8635394456289979,
        "vocab_size-2-nopunct": 1215,
        "unique-2-nopunct": 1125,
        "entropy-2-nopunct": 10.069974337247384,
        "cond_entropy-2-nopunct": 1.628605863149744,
        "distinct-3-nopunct": 0.9537393986121819,
        "vocab_size-3-nopunct": 1237,
        "unique-3-nopunct": 1194,
        "entropy-3-nopunct": 10.236095170984063,
        "cond_entropy-3-nopunct": 0.19135410309589318,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.965368907639416,
        "bleu": 50.10108,
        "rouge1": {
            "precision": 0.79517,
            "recall": 0.73982,
            "fmeasure": 0.75441
        },
        "rouge2": {
            "precision": 0.57437,
            "recall": 0.53133,
            "fmeasure": 0.5416
        },
        "rougeL": {
            "precision": 0.69379,
            "recall": 0.64646,
            "fmeasure": 0.65838
        },
        "rougeLsum": {
            "precision": 0.69379,
            "recall": 0.64646,
            "fmeasure": 0.65838
        },
        "local_recall": {
            "1": 0.21693121693121692,
            "2": 0.5676392572944297,
            "3": 0.7943396226415095
        },
        "bertscore": {
            "precision": 0.93832,
            "recall": 0.92914,
            "f1": 0.93262
        },
        "bleurt": 0.29506,
        "meteor": 0.4126128296198896,
        "nubia": {
            "semantic_relation": 4.20939,
            "contradiction": 8.78645,
            "irrelevancy": 25.56383,
            "logical_agreement": 65.64972,
            "grammar_ref": 4.79734,
            "grammar_hyp": 4.76972,
            "nubia_score": 0.73011
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_41": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966059,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.60283922618523,
        "bleu": 45.83034,
        "rouge1": {
            "precision": 0.73684,
            "recall": 1.0,
            "fmeasure": 0.84848
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.76923,
            "fmeasure": 0.64516
        },
        "rougeL": {
            "precision": 0.68421,
            "recall": 0.92857,
            "fmeasure": 0.78788
        },
        "rougeLsum": {
            "precision": 0.68421,
            "recall": 0.92857,
            "fmeasure": 0.78788
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.91731,
            "recall": 0.96154,
            "f1": 0.9389
        },
        "bleurt": 0.33762,
        "meteor": 0.4840606541446009,
        "nubia": {
            "semantic_relation": 3.8007,
            "contradiction": 0.15758,
            "irrelevancy": 99.74505,
            "logical_agreement": 0.09738,
            "grammar_ref": 4.76643,
            "grammar_hyp": 3.7782,
            "nubia_score": 0.71692
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_85": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 25,
        "msttr-100": 0.70333,
        "msttr-100_nopunct": 0.76667,
        "total_length": 399,
        "mean_pred_length": 15.96,
        "std_pred_length": 5.226700680161434,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.5864661654135338,
        "vocab_size-1": 234,
        "unique-1": 188,
        "entropy-1": 7.213130060446468,
        "distinct-2": 0.93048128342246,
        "vocab_size-2": 348,
        "unique-2": 328,
        "entropy-2": 8.39443577002488,
        "cond_entropy-2": 0.9662828944715559,
        "distinct-3": 0.9856733524355301,
        "vocab_size-3": 344,
        "unique-3": 339,
        "entropy-3": 8.418429931080752,
        "cond_entropy-3": 0.01556029212857819,
        "total_length-nopunct": 344,
        "mean_pred_length-nopunct": 13.76,
        "std_pred_length-nopunct": 4.5279575969746,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6627906976744186,
        "vocab_size-1-nopunct": 228,
        "unique-1-nopunct": 188,
        "entropy-1-nopunct": 7.359404546060426,
        "distinct-2-nopunct": 0.9498432601880877,
        "vocab_size-2-nopunct": 303,
        "unique-2-nopunct": 292,
        "entropy-2-nopunct": 8.203730286158375,
        "cond_entropy-2-nopunct": 0.9102431351645563,
        "distinct-3-nopunct": 0.9931972789115646,
        "vocab_size-3-nopunct": 292,
        "unique-3-nopunct": 290,
        "entropy-3-nopunct": 8.186066902659448,
        "cond_entropy-3-nopunct": -0.00799651890642878,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.3598870169395125,
        "bleu": 44.38016,
        "rouge1": {
            "precision": 0.77487,
            "recall": 0.72186,
            "fmeasure": 0.73151
        },
        "rouge2": {
            "precision": 0.57144,
            "recall": 0.51971,
            "fmeasure": 0.53286
        },
        "rougeL": {
            "precision": 0.66165,
            "recall": 0.62925,
            "fmeasure": 0.63155
        },
        "rougeLsum": {
            "precision": 0.66165,
            "recall": 0.62925,
            "fmeasure": 0.63155
        },
        "local_recall": {
            "1": 0.14492753623188406,
            "2": 0.36231884057971014,
            "3": 0.7561837455830389
        },
        "bertscore": {
            "precision": 0.92732,
            "recall": 0.91821,
            "f1": 0.92151
        },
        "bleurt": 0.14732,
        "meteor": 0.3897417980861608,
        "nubia": {
            "semantic_relation": 4.01693,
            "contradiction": 6.29481,
            "irrelevancy": 28.59014,
            "logical_agreement": 65.11505,
            "grammar_ref": 4.78896,
            "grammar_hyp": 4.83063,
            "nubia_score": 0.65546
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_18": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 123,
        "msttr-100": 0.6435,
        "msttr-100_nopunct": 0.67588,
        "total_length": 2002,
        "mean_pred_length": 16.276422764227643,
        "std_pred_length": 8.314255377839741,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.3806193806193806,
        "vocab_size-1": 762,
        "unique-1": 623,
        "entropy-1": 7.6774299299588025,
        "distinct-2": 0.7104843001596594,
        "vocab_size-2": 1335,
        "unique-2": 1220,
        "entropy-2": 9.761639031880991,
        "cond_entropy-2": 1.844336192010018,
        "distinct-3": 0.8211845102505695,
        "vocab_size-3": 1442,
        "unique-3": 1379,
        "entropy-3": 10.104829125178211,
        "cond_entropy-3": 0.3524893074502805,
        "total_length-nopunct": 1736,
        "mean_pred_length-nopunct": 14.113821138211382,
        "std_pred_length-nopunct": 6.7849705405625125,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.4349078341013825,
        "vocab_size-1-nopunct": 755,
        "unique-1-nopunct": 622,
        "entropy-1-nopunct": 7.925377082052259,
        "distinct-2-nopunct": 0.7278363298202107,
        "vocab_size-2-nopunct": 1174,
        "unique-2-nopunct": 1082,
        "entropy-2-nopunct": 9.595880737282066,
        "cond_entropy-2-nopunct": 1.7706958246499052,
        "distinct-3-nopunct": 0.8315436241610739,
        "vocab_size-3-nopunct": 1239,
        "unique-3-nopunct": 1191,
        "entropy-3-nopunct": 9.89601676370104,
        "cond_entropy-3-nopunct": 0.35130529538364214,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.811286789246458,
        "bleu": 54.77522,
        "rouge1": {
            "precision": 0.77824,
            "recall": 0.76641,
            "fmeasure": 0.76096
        },
        "rouge2": {
            "precision": 0.57175,
            "recall": 0.56294,
            "fmeasure": 0.55954
        },
        "rougeL": {
            "precision": 0.68228,
            "recall": 0.66664,
            "fmeasure": 0.66418
        },
        "rougeLsum": {
            "precision": 0.68228,
            "recall": 0.66664,
            "fmeasure": 0.66418
        },
        "local_recall": {
            "1": 0.26855123674911663,
            "2": 0.411371237458194,
            "3": 0.7913779830638953
        },
        "bertscore": {
            "precision": 0.93586,
            "recall": 0.93169,
            "f1": 0.93225
        },
        "bleurt": 0.39611,
        "meteor": 0.42800503033666615,
        "nubia": {
            "semantic_relation": 4.28905,
            "contradiction": 6.41548,
            "irrelevancy": 25.27065,
            "logical_agreement": 68.31388,
            "grammar_ref": 4.71387,
            "grammar_hyp": 4.61435,
            "nubia_score": 0.7701
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_42": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 54,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.8025,
        "total_length": 904,
        "mean_pred_length": 16.74074074074074,
        "std_pred_length": 6.7964729011265534,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 34,
        "distinct-1": 0.5176991150442478,
        "vocab_size-1": 468,
        "unique-1": 372,
        "entropy-1": 7.825005130637862,
        "distinct-2": 0.8905882352941177,
        "vocab_size-2": 757,
        "unique-2": 706,
        "entropy-2": 9.447097883920524,
        "cond_entropy-2": 1.3815585913832118,
        "distinct-3": 0.9773869346733668,
        "vocab_size-3": 778,
        "unique-3": 763,
        "entropy-3": 9.588553436490338,
        "cond_entropy-3": 0.14566150978548287,
        "total_length-nopunct": 802,
        "mean_pred_length-nopunct": 14.851851851851851,
        "std_pred_length-nopunct": 6.263969299530412,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.57356608478803,
        "vocab_size-1-nopunct": 460,
        "unique-1-nopunct": 370,
        "entropy-1-nopunct": 8.035703215625235,
        "distinct-2-nopunct": 0.8943850267379679,
        "vocab_size-2-nopunct": 669,
        "unique-2-nopunct": 627,
        "entropy-2-nopunct": 9.26705045917576,
        "cond_entropy-2-nopunct": 1.289784710381063,
        "distinct-3-nopunct": 0.9769452449567724,
        "vocab_size-3-nopunct": 678,
        "unique-3-nopunct": 665,
        "entropy-3-nopunct": 9.38941914003281,
        "cond_entropy-3-nopunct": 0.1317730231304503,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.921298272608168,
        "bleu": 45.6599,
        "rouge1": {
            "precision": 0.77004,
            "recall": 0.71833,
            "fmeasure": 0.73109
        },
        "rouge2": {
            "precision": 0.53896,
            "recall": 0.51332,
            "fmeasure": 0.51513
        },
        "rougeL": {
            "precision": 0.66335,
            "recall": 0.62868,
            "fmeasure": 0.63405
        },
        "rougeLsum": {
            "precision": 0.66335,
            "recall": 0.62868,
            "fmeasure": 0.63405
        },
        "local_recall": {
            "1": 0.2569832402234637,
            "2": 0.3485714285714286,
            "3": 0.7548387096774194
        },
        "bertscore": {
            "precision": 0.93253,
            "recall": 0.92697,
            "f1": 0.92862
        },
        "bleurt": 0.26192,
        "meteor": 0.388382890033552,
        "nubia": {
            "semantic_relation": 4.1771,
            "contradiction": 10.22344,
            "irrelevancy": 26.58121,
            "logical_agreement": 63.19535,
            "grammar_ref": 4.68502,
            "grammar_hyp": 4.61885,
            "nubia_score": 0.72768
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_43": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "total_length": 101,
        "mean_pred_length": 16.833333333333332,
        "std_pred_length": 11.739061101960223,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 41,
        "distinct-1": 0.7227722772277227,
        "vocab_size-1": 73,
        "unique-1": 64,
        "entropy-1": 5.891043725767981,
        "distinct-2": 0.8631578947368421,
        "vocab_size-2": 82,
        "unique-2": 77,
        "entropy-2": 6.21712113460119,
        "cond_entropy-2": 0.2112693197550497,
        "distinct-3": 0.898876404494382,
        "vocab_size-3": 80,
        "unique-3": 76,
        "entropy-3": 6.225568683702472,
        "cond_entropy-3": -0.05766023918661141,
        "total_length-nopunct": 88,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 9.620579793107874,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.7840909090909091,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 5.887107437085029,
        "distinct-2-nopunct": 0.8780487804878049,
        "vocab_size-2-nopunct": 72,
        "unique-2-nopunct": 68,
        "entropy-2-nopunct": 6.046457187492148,
        "cond_entropy-2-nopunct": 0.10366615393533918,
        "distinct-3-nopunct": 0.9210526315789473,
        "vocab_size-3-nopunct": 70,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 6.060234585726612,
        "cond_entropy-3-nopunct": -0.06692564251875419,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.725667316374661,
        "bleu": 62.0575,
        "rouge1": {
            "precision": 0.90939,
            "recall": 0.94411,
            "fmeasure": 0.92528
        },
        "rouge2": {
            "precision": 0.84484,
            "recall": 0.87115,
            "fmeasure": 0.8569
        },
        "rougeL": {
            "precision": 0.84127,
            "recall": 0.86655,
            "fmeasure": 0.85282
        },
        "rougeLsum": {
            "precision": 0.84127,
            "recall": 0.86655,
            "fmeasure": 0.85282
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8918918918918919
        },
        "bertscore": {
            "precision": 0.9652,
            "recall": 0.97294,
            "f1": 0.96887
        },
        "bleurt": 0.60828,
        "meteor": 0.5063596314733821,
        "nubia": {
            "semantic_relation": 4.7127,
            "contradiction": 1.34384,
            "irrelevancy": 26.07896,
            "logical_agreement": 72.5772,
            "grammar_ref": 5.92578,
            "grammar_hyp": 5.8623,
            "nubia_score": 0.86119
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_86": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.418295834054489,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 22,
        "unique-2": 21,
        "entropy-2": 4.436605434317882,
        "cond_entropy-2": 0.025555977074987163,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": 0.026778753489375355,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.0224469564457176,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.1666666666666665,
        "bleu": 36.54749,
        "rouge1": {
            "precision": 0.52632,
            "recall": 0.76923,
            "fmeasure": 0.625
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.58333,
            "fmeasure": 0.46667
        },
        "rougeL": {
            "precision": 0.52632,
            "recall": 0.76923,
            "fmeasure": 0.625
        },
        "rougeLsum": {
            "precision": 0.52632,
            "recall": 0.76923,
            "fmeasure": 0.625
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7692307692307693
        },
        "bertscore": {
            "precision": 0.89487,
            "recall": 0.96861,
            "f1": 0.93028
        },
        "bleurt": 0.48873,
        "meteor": 0.49043277650662565,
        "nubia": {
            "semantic_relation": 3.78107,
            "contradiction": 0.17865,
            "irrelevancy": 99.69513,
            "logical_agreement": 0.12622,
            "grammar_ref": 3.82301,
            "grammar_hyp": 3.34564,
            "nubia_score": 0.78382
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_19": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.514,
        "msttr-100_nopunct": 0.53,
        "total_length": 508,
        "mean_pred_length": 17.517241379310345,
        "std_pred_length": 9.441729420978838,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 53,
        "distinct-1": 0.32086614173228345,
        "vocab_size-1": 163,
        "unique-1": 120,
        "entropy-1": 5.998293835531001,
        "distinct-2": 0.5657620041753654,
        "vocab_size-2": 271,
        "unique-2": 220,
        "entropy-2": 7.345658432452221,
        "cond_entropy-2": 1.2342954650367215,
        "distinct-3": 0.66,
        "vocab_size-3": 297,
        "unique-3": 255,
        "entropy-3": 7.624940302236935,
        "cond_entropy-3": 0.34945706647531755,
        "total_length-nopunct": 434,
        "mean_pred_length-nopunct": 14.96551724137931,
        "std_pred_length-nopunct": 7.690041740708608,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.35944700460829493,
        "vocab_size-1-nopunct": 156,
        "unique-1-nopunct": 118,
        "entropy-1-nopunct": 5.971607474368967,
        "distinct-2-nopunct": 0.5580246913580247,
        "vocab_size-2-nopunct": 226,
        "unique-2-nopunct": 185,
        "entropy-2-nopunct": 7.055441369179346,
        "cond_entropy-2-nopunct": 1.2180737958978685,
        "distinct-3-nopunct": 0.6542553191489362,
        "vocab_size-3-nopunct": 246,
        "unique-3-nopunct": 213,
        "entropy-3-nopunct": 7.337513975069163,
        "cond_entropy-3-nopunct": 0.3820294280419113,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.163159753141348,
        "bleu": 71.17287,
        "rouge1": {
            "precision": 0.8799,
            "recall": 0.86305,
            "fmeasure": 0.86793
        },
        "rouge2": {
            "precision": 0.75219,
            "recall": 0.73792,
            "fmeasure": 0.74195
        },
        "rougeL": {
            "precision": 0.83605,
            "recall": 0.82098,
            "fmeasure": 0.82549
        },
        "rougeLsum": {
            "precision": 0.83605,
            "recall": 0.82098,
            "fmeasure": 0.82549
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.45614035087719296,
            "3": 0.878698224852071
        },
        "bertscore": {
            "precision": 0.9529,
            "recall": 0.94955,
            "f1": 0.94959
        },
        "bleurt": 0.4472,
        "meteor": 0.45753391475026556,
        "nubia": {
            "semantic_relation": 4.34898,
            "contradiction": 5.6737,
            "irrelevancy": 13.35634,
            "logical_agreement": 80.96995,
            "grammar_ref": 4.31347,
            "grammar_hyp": 4.39924,
            "nubia_score": 0.7882
        }
    },
    "totto_test_contrast_challenge_continent-north_ameria": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 150,
        "msttr-100": 0.7008,
        "msttr-100_nopunct": 0.77476,
        "total_length": 2547,
        "mean_pred_length": 16.98,
        "std_pred_length": 6.426476484046293,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 42,
        "distinct-1": 0.42010208087946604,
        "vocab_size-1": 1070,
        "unique-1": 830,
        "entropy-1": 8.325011247370309,
        "distinct-2": 0.7993324989570296,
        "vocab_size-2": 1916,
        "unique-2": 1714,
        "entropy-2": 10.611467899160504,
        "cond_entropy-2": 2.018211820227833,
        "distinct-3": 0.9399198931909212,
        "vocab_size-3": 2112,
        "unique-3": 2015,
        "entropy-3": 10.997461742961995,
        "cond_entropy-3": 0.34773635465291486,
        "total_length-nopunct": 2169,
        "mean_pred_length-nopunct": 14.46,
        "std_pred_length-nopunct": 5.1879732715836795,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.48824343015214383,
        "vocab_size-1-nopunct": 1059,
        "unique-1-nopunct": 827,
        "entropy-1-nopunct": 8.693210880896055,
        "distinct-2-nopunct": 0.8385339276869738,
        "vocab_size-2-nopunct": 1693,
        "unique-2-nopunct": 1554,
        "entropy-2-nopunct": 10.482616270264465,
        "cond_entropy-2-nopunct": 1.8770682731147428,
        "distinct-3-nopunct": 0.956661316211878,
        "vocab_size-3-nopunct": 1788,
        "unique-3-nopunct": 1727,
        "entropy-3-nopunct": 10.770718909925584,
        "cond_entropy-3-nopunct": 0.31071188324303406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.363708730866254,
        "bleu": 50.86385,
        "rouge1": {
            "precision": 0.83142,
            "recall": 0.7802,
            "fmeasure": 0.79928
        },
        "rouge2": {
            "precision": 0.58743,
            "recall": 0.55182,
            "fmeasure": 0.56412
        },
        "rougeL": {
            "precision": 0.72058,
            "recall": 0.67434,
            "fmeasure": 0.69127
        },
        "rougeLsum": {
            "precision": 0.72058,
            "recall": 0.67434,
            "fmeasure": 0.69127
        },
        "local_recall": {
            "1": 0.16706443914081145,
            "2": 0.31095406360424027,
            "3": 0.8131041890440387
        },
        "bertscore": {
            "precision": 0.94414,
            "recall": 0.93977,
            "f1": 0.94095
        },
        "bleurt": 0.42621,
        "meteor": 0.42347761448834054,
        "nubia": {
            "semantic_relation": 4.54824,
            "contradiction": 2.6015,
            "irrelevancy": 17.66042,
            "logical_agreement": 79.73808,
            "grammar_ref": 4.5685,
            "grammar_hyp": 4.65066,
            "nubia_score": 0.8271
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_65": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 62,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.78889,
        "total_length": 1080,
        "mean_pred_length": 17.419354838709676,
        "std_pred_length": 7.671792462245502,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 45,
        "distinct-1": 0.462037037037037,
        "vocab_size-1": 499,
        "unique-1": 379,
        "entropy-1": 7.840365408437103,
        "distinct-2": 0.8231827111984283,
        "vocab_size-2": 838,
        "unique-2": 739,
        "entropy-2": 9.536854670560178,
        "cond_entropy-2": 1.4700646456691673,
        "distinct-3": 0.9205020920502092,
        "vocab_size-3": 880,
        "unique-3": 832,
        "entropy-3": 9.712500489952978,
        "cond_entropy-3": 0.1595158240031856,
        "total_length-nopunct": 911,
        "mean_pred_length-nopunct": 14.693548387096774,
        "std_pred_length-nopunct": 5.7067834838488185,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.5378704720087816,
        "vocab_size-1-nopunct": 490,
        "unique-1-nopunct": 375,
        "entropy-1-nopunct": 8.139757269382544,
        "distinct-2-nopunct": 0.8480565371024735,
        "vocab_size-2-nopunct": 720,
        "unique-2-nopunct": 649,
        "entropy-2-nopunct": 9.338398175507491,
        "cond_entropy-2-nopunct": 1.2551379044961877,
        "distinct-3-nopunct": 0.9339263024142312,
        "vocab_size-3-nopunct": 735,
        "unique-3-nopunct": 700,
        "entropy-3-nopunct": 9.469897382656399,
        "cond_entropy-3-nopunct": 0.11657646155652228,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.51680004426499,
        "bleu": 51.05784,
        "rouge1": {
            "precision": 0.79237,
            "recall": 0.77255,
            "fmeasure": 0.77253
        },
        "rouge2": {
            "precision": 0.58365,
            "recall": 0.56628,
            "fmeasure": 0.56753
        },
        "rougeL": {
            "precision": 0.70573,
            "recall": 0.68973,
            "fmeasure": 0.68847
        },
        "rougeLsum": {
            "precision": 0.70573,
            "recall": 0.68973,
            "fmeasure": 0.68847
        },
        "local_recall": {
            "1": 0.19186046511627908,
            "2": 0.4293785310734463,
            "3": 0.8236151603498543
        },
        "bertscore": {
            "precision": 0.93679,
            "recall": 0.9347,
            "f1": 0.93348
        },
        "bleurt": 0.35789,
        "meteor": 0.4166295847298857,
        "nubia": {
            "semantic_relation": 4.38939,
            "contradiction": 5.58588,
            "irrelevancy": 29.20362,
            "logical_agreement": 65.2105,
            "grammar_ref": 4.56742,
            "grammar_hyp": 4.46856,
            "nubia_score": 0.78893
        }
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 1510,
        "msttr-100": 0.51501,
        "msttr-100_nopunct": 0.52731,
        "total_length": 36511,
        "mean_pred_length": 24.179470198675496,
        "std_pred_length": 12.916603708984018,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 75,
        "distinct-1": 0.05584618334200652,
        "vocab_size-1": 2039,
        "unique-1": 645,
        "entropy-1": 8.041668406336946,
        "distinct-2": 0.20016570955115567,
        "vocab_size-2": 7006,
        "unique-2": 3332,
        "entropy-2": 11.339189541262215,
        "cond_entropy-2": 3.1230665181432418,
        "distinct-3": 0.3555880684362963,
        "vocab_size-3": 11909,
        "unique-3": 7156,
        "entropy-3": 12.561095880318263,
        "cond_entropy-3": 1.285353307559205,
        "total_length-nopunct": 32327,
        "mean_pred_length-nopunct": 21.40860927152318,
        "std_pred_length-nopunct": 11.597181893339382,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 65,
        "distinct-1-nopunct": 0.06276487146966932,
        "vocab_size-1-nopunct": 2029,
        "unique-1-nopunct": 645,
        "entropy-1-nopunct": 8.324891890475525,
        "distinct-2-nopunct": 0.2128695200700912,
        "vocab_size-2-nopunct": 6560,
        "unique-2-nopunct": 3277,
        "entropy-2-nopunct": 11.239545346459822,
        "cond_entropy-2-nopunct": 3.060667861281772,
        "distinct-3-nopunct": 0.3697410175043505,
        "vocab_size-3-nopunct": 10836,
        "unique-3-nopunct": 6710,
        "entropy-3-nopunct": 12.418067394500076,
        "cond_entropy-3-nopunct": 1.2400812970014483,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 8.051433566136716,
        "bleu": 41.82969,
        "rouge1": {
            "precision": 0.69455,
            "recall": 0.70423,
            "fmeasure": 0.6931
        },
        "rouge2": {
            "precision": 0.43326,
            "recall": 0.43929,
            "fmeasure": 0.43196
        },
        "rougeL": {
            "precision": 0.55411,
            "recall": 0.56408,
            "fmeasure": 0.55351
        },
        "rougeLsum": {
            "precision": 0.55411,
            "recall": 0.56408,
            "fmeasure": 0.55351
        },
        "local_recall": {
            "1": 0.23775974950185028,
            "2": 0.5677046473224817,
            "3": 0.8037656637618472,
            "4": 0.9019607843137255,
            "5": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.90228,
            "recall": 0.9059,
            "f1": 0.90291
        },
        "bleurt": 0.02676,
        "meteor": 0.3548846066393687,
        "nubia": {
            "semantic_relation": 4.09158,
            "contradiction": 22.85286,
            "irrelevancy": 8.65627,
            "logical_agreement": 68.49087,
            "grammar_ref": 4.59892,
            "grammar_hyp": 4.69274,
            "nubia_score": 0.68383
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_87": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 15.0,
        "std_pred_length": 8.640987597877148,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.8,
        "vocab_size-1": 36,
        "unique-1": 30,
        "entropy-1": 5.0306333740593745,
        "distinct-2": 0.9285714285714286,
        "vocab_size-2": 39,
        "unique-2": 36,
        "entropy-2": 5.249460279921619,
        "cond_entropy-2": 0.13855956454432378,
        "distinct-3": 0.9743589743589743,
        "vocab_size-3": 38,
        "unique-3": 37,
        "entropy-3": 5.234120167580196,
        "cond_entropy-3": -0.004351101352409327,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 8.178562764256865,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8292682926829268,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.967308102179057,
        "distinct-2-nopunct": 0.9210526315789473,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.090032776601483,
        "cond_entropy-2-nopunct": 0.15353340356234413,
        "distinct-3-nopunct": 0.9714285714285714,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.072140159802107,
        "cond_entropy-3-nopunct": -0.004358782212904644,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.7572277418123106,
        "bleu": 20.10009,
        "rouge1": {
            "precision": 0.65263,
            "recall": 0.65556,
            "fmeasure": 0.64945
        },
        "rouge2": {
            "precision": 0.47407,
            "recall": 0.49824,
            "fmeasure": 0.48198
        },
        "rougeL": {
            "precision": 0.6398,
            "recall": 0.64365,
            "fmeasure": 0.63711
        },
        "rougeLsum": {
            "precision": 0.6398,
            "recall": 0.64365,
            "fmeasure": 0.63711
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.2727272727272727,
            "3": 0.625
        },
        "bertscore": {
            "precision": 0.90334,
            "recall": 0.91283,
            "f1": 0.90797
        },
        "bleurt": 0.01304,
        "meteor": 0.2957510514743106,
        "nubia": {
            "semantic_relation": 3.77937,
            "contradiction": 28.89306,
            "irrelevancy": 10.54946,
            "logical_agreement": 60.55748,
            "grammar_ref": 5.04645,
            "grammar_hyp": 4.82592,
            "nubia_score": 0.56573
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_44": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 47,
        "msttr-100": 0.67429,
        "msttr-100_nopunct": 0.715,
        "total_length": 783,
        "mean_pred_length": 16.659574468085108,
        "std_pred_length": 7.244298112175638,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 51,
        "distinct-1": 0.5095785440613027,
        "vocab_size-1": 399,
        "unique-1": 313,
        "entropy-1": 7.536080568130954,
        "distinct-2": 0.8804347826086957,
        "vocab_size-2": 648,
        "unique-2": 595,
        "entropy-2": 9.216456954835142,
        "cond_entropy-2": 1.458288556054201,
        "distinct-3": 0.9593613933236574,
        "vocab_size-3": 661,
        "unique-3": 637,
        "entropy-3": 9.34127744411204,
        "cond_entropy-3": 0.09855722373924987,
        "total_length-nopunct": 669,
        "mean_pred_length-nopunct": 14.23404255319149,
        "std_pred_length-nopunct": 6.0113819912727,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.5829596412556054,
        "vocab_size-1-nopunct": 390,
        "unique-1-nopunct": 311,
        "entropy-1-nopunct": 7.72561829515087,
        "distinct-2-nopunct": 0.905144694533762,
        "vocab_size-2-nopunct": 563,
        "unique-2-nopunct": 524,
        "entropy-2-nopunct": 9.04421863522746,
        "cond_entropy-2-nopunct": 1.4104405046464372,
        "distinct-3-nopunct": 0.9721739130434782,
        "vocab_size-3-nopunct": 559,
        "unique-3-nopunct": 543,
        "entropy-3-nopunct": 9.111765971918564,
        "cond_entropy-3-nopunct": 0.07644811989203465,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.447295580147569,
        "bleu": 40.35216,
        "rouge1": {
            "precision": 0.77718,
            "recall": 0.6986,
            "fmeasure": 0.72799
        },
        "rouge2": {
            "precision": 0.52013,
            "recall": 0.47401,
            "fmeasure": 0.49056
        },
        "rougeL": {
            "precision": 0.66929,
            "recall": 0.61466,
            "fmeasure": 0.63422
        },
        "rougeLsum": {
            "precision": 0.66929,
            "recall": 0.61466,
            "fmeasure": 0.63422
        },
        "local_recall": {
            "1": 0.11504424778761062,
            "2": 0.48823529411764705,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.92662,
            "recall": 0.91474,
            "f1": 0.91934
        },
        "bleurt": 0.26149,
        "meteor": 0.36874839657477987,
        "nubia": {
            "semantic_relation": 4.24289,
            "contradiction": 9.40531,
            "irrelevancy": 35.36274,
            "logical_agreement": 55.23196,
            "grammar_ref": 4.69178,
            "grammar_hyp": 4.89621,
            "nubia_score": 0.70413
        }
    },
    "totto_test_contrast_challenge_continent-oceania": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 105,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.76786,
        "total_length": 1675,
        "mean_pred_length": 15.952380952380953,
        "std_pred_length": 7.572356936196352,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 55,
        "distinct-1": 0.4525373134328358,
        "vocab_size-1": 758,
        "unique-1": 599,
        "entropy-1": 7.976501405451837,
        "distinct-2": 0.8324840764331211,
        "vocab_size-2": 1307,
        "unique-2": 1183,
        "entropy-2": 10.127203510212421,
        "cond_entropy-2": 1.883555588596954,
        "distinct-3": 0.9426621160409556,
        "vocab_size-3": 1381,
        "unique-3": 1323,
        "entropy-3": 10.38398622712928,
        "cond_entropy-3": 0.2563780012674398,
        "total_length-nopunct": 1425,
        "mean_pred_length-nopunct": 13.571428571428571,
        "std_pred_length-nopunct": 5.665025772827756,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.5263157894736842,
        "vocab_size-1-nopunct": 750,
        "unique-1-nopunct": 597,
        "entropy-1-nopunct": 8.339415481595509,
        "distinct-2-nopunct": 0.8598484848484849,
        "vocab_size-2-nopunct": 1135,
        "unique-2-nopunct": 1046,
        "entropy-2-nopunct": 9.951834731426489,
        "cond_entropy-2-nopunct": 1.7297548890504253,
        "distinct-3-nopunct": 0.9662551440329218,
        "vocab_size-3-nopunct": 1174,
        "unique-3-nopunct": 1142,
        "entropy-3-nopunct": 10.172448695195623,
        "cond_entropy-3-nopunct": 0.2406561536410155,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.633161879423585,
        "bleu": 45.26719,
        "rouge1": {
            "precision": 0.81023,
            "recall": 0.7518,
            "fmeasure": 0.77161
        },
        "rouge2": {
            "precision": 0.5571,
            "recall": 0.51804,
            "fmeasure": 0.53024
        },
        "rougeL": {
            "precision": 0.6918,
            "recall": 0.64489,
            "fmeasure": 0.66021
        },
        "rougeLsum": {
            "precision": 0.6918,
            "recall": 0.64489,
            "fmeasure": 0.66021
        },
        "local_recall": {
            "1": 0.2088607594936709,
            "2": 0.3135593220338983,
            "3": 0.7813834329632793
        },
        "bertscore": {
            "precision": 0.93663,
            "recall": 0.93222,
            "f1": 0.93351
        },
        "bleurt": 0.35735,
        "meteor": 0.3952775964566611,
        "nubia": {
            "semantic_relation": 4.43958,
            "contradiction": 4.80975,
            "irrelevancy": 24.03046,
            "logical_agreement": 71.15979,
            "grammar_ref": 5.02637,
            "grammar_hyp": 5.07892,
            "nubia_score": 0.78583
        }
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 269,
        "msttr-100": 0.55079,
        "msttr-100_nopunct": 0.56405,
        "total_length": 8935,
        "mean_pred_length": 33.215613382899626,
        "std_pred_length": 10.557594638430288,
        "median_pred_length": 33.0,
        "min_pred_length": 11,
        "max_pred_length": 66,
        "distinct-1": 0.12076105204252938,
        "vocab_size-1": 1079,
        "unique-1": 442,
        "entropy-1": 7.547256683622152,
        "distinct-2": 0.36014308792984073,
        "vocab_size-2": 3121,
        "unique-2": 1862,
        "entropy-2": 10.59209994866139,
        "cond_entropy-2": 2.9405881459834697,
        "distinct-3": 0.5774681433845421,
        "vocab_size-3": 4849,
        "unique-3": 3513,
        "entropy-3": 11.738352417282593,
        "cond_entropy-3": 1.1819018875746756,
        "total_length-nopunct": 7916,
        "mean_pred_length-nopunct": 29.4275092936803,
        "std_pred_length-nopunct": 9.660758094281904,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 60,
        "distinct-1-nopunct": 0.1352956038403234,
        "vocab_size-1-nopunct": 1071,
        "unique-1-nopunct": 441,
        "entropy-1-nopunct": 7.754976687830152,
        "distinct-2-nopunct": 0.3814567804367726,
        "vocab_size-2-nopunct": 2917,
        "unique-2-nopunct": 1814,
        "entropy-2-nopunct": 10.525023448564129,
        "cond_entropy-2-nopunct": 2.867671348307198,
        "distinct-3-nopunct": 0.5979940363242071,
        "vocab_size-3-nopunct": 4412,
        "unique-3-nopunct": 3304,
        "entropy-3-nopunct": 11.610395117476557,
        "cond_entropy-3-nopunct": 1.1179777332098835,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 5.716967761150033,
        "bleu": 22.57959,
        "rouge1": {
            "precision": 0.57106,
            "recall": 0.59373,
            "fmeasure": 0.57409
        },
        "rouge2": {
            "precision": 0.27175,
            "recall": 0.28673,
            "fmeasure": 0.27474
        },
        "rougeL": {
            "precision": 0.40319,
            "recall": 0.4189,
            "fmeasure": 0.40497
        },
        "rougeLsum": {
            "precision": 0.40319,
            "recall": 0.4189,
            "fmeasure": 0.40497
        },
        "local_recall": {
            "1": 0.18359490672194256,
            "2": 0.45794392523364486,
            "3": 0.6668430801799418,
            "4": 0.25,
            "5": 0.875
        },
        "bertscore": {
            "precision": 0.85306,
            "recall": 0.85624,
            "f1": 0.85329
        },
        "bleurt": -0.3955,
        "meteor": 0.2687192685937092,
        "nubia": {
            "semantic_relation": 3.42934,
            "contradiction": 35.63631,
            "irrelevancy": 17.8122,
            "logical_agreement": 46.55149,
            "grammar_ref": 4.33889,
            "grammar_hyp": 4.52747,
            "nubia_score": 0.50754
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_challenge_test_asset_backtranslation",
        "N": 359,
        "msttr-100": 0.72404,
        "msttr-100_nopunct": 0.7692,
        "total_length": 5715,
        "mean_pred_length": 15.919220055710307,
        "std_pred_length": 7.68398424493222,
        "median_pred_length": 13.0,
        "min_pred_length": 5,
        "max_pred_length": 64,
        "distinct-1": 0.3825021872265967,
        "vocab_size-1": 2186,
        "unique-1": 1650,
        "entropy-1": 8.96749186859856,
        "distinct-2": 0.8412994772218073,
        "vocab_size-2": 4506,
        "unique-2": 4165,
        "entropy-2": 11.855785328858124,
        "cond_entropy-2": 2.546341004932336,
        "distinct-3": 0.9615769461677006,
        "vocab_size-3": 4805,
        "unique-3": 4716,
        "entropy-3": 12.160146213391807,
        "cond_entropy-3": 0.32356205735646376,
        "total_length-nopunct": 5080,
        "mean_pred_length-nopunct": 14.15041782729805,
        "std_pred_length-nopunct": 6.721245871486525,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.4283464566929134,
        "vocab_size-1-nopunct": 2176,
        "unique-1-nopunct": 1647,
        "entropy-1-nopunct": 9.318088384518404,
        "distinct-2-nopunct": 0.8568099978818047,
        "vocab_size-2-nopunct": 4045,
        "unique-2-nopunct": 3762,
        "entropy-2-nopunct": 11.736307980077777,
        "cond_entropy-2-nopunct": 2.583309434972273,
        "distinct-3-nopunct": 0.9777624942686841,
        "vocab_size-3-nopunct": 4265,
        "unique-3-nopunct": 4200,
        "entropy-3-nopunct": 12.038146328027425,
        "cond_entropy-3-nopunct": 0.32844709661944216,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_backtranslation.json",
        "nist": 8.16978417217441,
        "bleu": 42.90903,
        "rouge1": {
            "precision": 0.70261,
            "recall": 0.61577,
            "fmeasure": 0.6399
        },
        "rouge2": {
            "precision": 0.47377,
            "recall": 0.4154,
            "fmeasure": 0.42756
        },
        "rougeL": {
            "precision": 0.65242,
            "recall": 0.57906,
            "fmeasure": 0.59709
        },
        "rougeLsum": {
            "precision": 0.65242,
            "recall": 0.57906,
            "fmeasure": 0.59709
        },
        "local_recall": {
            "1": 0.04618357487922705,
            "2": 0.12087912087912088,
            "3": 0.19929660023446658,
            "4": 0.2747875354107649,
            "5": 0.3399734395750332,
            "6": 0.4248768472906404,
            "7": 0.4874429223744292,
            "8": 0.6051587301587301,
            "9": 0.7496402877697842
        },
        "sari": 44.42069,
        "bertscore": {
            "precision": 0.91148,
            "recall": 0.89766,
            "f1": 0.9
        },
        "bleurt": -0.18406,
        "meteor": 0.3300299888465099,
        "nubia": {
            "semantic_relation": 3.41422,
            "contradiction": 12.71315,
            "irrelevancy": 31.06809,
            "logical_agreement": 56.21876,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.2971,
            "nubia_score": 0.4494
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_88": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 35,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.744,
        "total_length": 645,
        "mean_pred_length": 18.428571428571427,
        "std_pred_length": 8.583325077599888,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 42,
        "distinct-1": 0.5193798449612403,
        "vocab_size-1": 335,
        "unique-1": 253,
        "entropy-1": 7.460774290471422,
        "distinct-2": 0.8639344262295082,
        "vocab_size-2": 527,
        "unique-2": 473,
        "entropy-2": 8.928053516928403,
        "cond_entropy-2": 1.2780758855453334,
        "distinct-3": 0.9408695652173913,
        "vocab_size-3": 541,
        "unique-3": 517,
        "entropy-3": 9.033471102338307,
        "cond_entropy-3": 0.10430700635486471,
        "total_length-nopunct": 561,
        "mean_pred_length-nopunct": 16.02857142857143,
        "std_pred_length-nopunct": 8.01600439936333,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.5828877005347594,
        "vocab_size-1-nopunct": 327,
        "unique-1-nopunct": 252,
        "entropy-1-nopunct": 7.590099341013551,
        "distinct-2-nopunct": 0.8840304182509505,
        "vocab_size-2-nopunct": 465,
        "unique-2-nopunct": 427,
        "entropy-2-nopunct": 8.757524942774534,
        "cond_entropy-2-nopunct": 1.2372232998073864,
        "distinct-3-nopunct": 0.955193482688391,
        "vocab_size-3-nopunct": 469,
        "unique-3-nopunct": 453,
        "entropy-3-nopunct": 8.839743063584285,
        "cond_entropy-3-nopunct": 0.09413012005231051,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.478311499741114,
        "bleu": 45.1073,
        "rouge1": {
            "precision": 0.77867,
            "recall": 0.75642,
            "fmeasure": 0.75697
        },
        "rouge2": {
            "precision": 0.5505,
            "recall": 0.53839,
            "fmeasure": 0.53646
        },
        "rougeL": {
            "precision": 0.69485,
            "recall": 0.67943,
            "fmeasure": 0.67606
        },
        "rougeLsum": {
            "precision": 0.69485,
            "recall": 0.67943,
            "fmeasure": 0.67606
        },
        "local_recall": {
            "1": 0.1595744680851064,
            "2": 0.5309734513274337,
            "3": 0.760705289672544
        },
        "bertscore": {
            "precision": 0.93076,
            "recall": 0.92453,
            "f1": 0.92578
        },
        "bleurt": 0.24946,
        "meteor": 0.37539398758732767,
        "nubia": {
            "semantic_relation": 4.12016,
            "contradiction": 11.87512,
            "irrelevancy": 31.59652,
            "logical_agreement": 56.52836,
            "grammar_ref": 4.59802,
            "grammar_hyp": 4.66475,
            "nubia_score": 0.67889
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_66": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 48,
        "msttr-100": 0.72857,
        "msttr-100_nopunct": 0.78667,
        "total_length": 796,
        "mean_pred_length": 16.583333333333332,
        "std_pred_length": 6.058167122891947,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 37,
        "distinct-1": 0.5364321608040201,
        "vocab_size-1": 427,
        "unique-1": 347,
        "entropy-1": 7.724614819281032,
        "distinct-2": 0.9050802139037433,
        "vocab_size-2": 677,
        "unique-2": 632,
        "entropy-2": 9.314666389162042,
        "cond_entropy-2": 1.3543540704506492,
        "distinct-3": 0.9814285714285714,
        "vocab_size-3": 687,
        "unique-3": 676,
        "entropy-3": 9.411911433254772,
        "cond_entropy-3": 0.10174068322810229,
        "total_length-nopunct": 690,
        "mean_pred_length-nopunct": 14.375,
        "std_pred_length-nopunct": 5.433787046495903,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.6101449275362318,
        "vocab_size-1-nopunct": 421,
        "unique-1-nopunct": 345,
        "entropy-1-nopunct": 7.974220132016243,
        "distinct-2-nopunct": 0.9112149532710281,
        "vocab_size-2-nopunct": 585,
        "unique-2-nopunct": 552,
        "entropy-2-nopunct": 9.101823845535957,
        "cond_entropy-2-nopunct": 1.19278293567333,
        "distinct-3-nopunct": 0.9831649831649831,
        "vocab_size-3-nopunct": 584,
        "unique-3-nopunct": 575,
        "entropy-3-nopunct": 9.179378232749956,
        "cond_entropy-3-nopunct": 0.08897033131520383,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.402916469495922,
        "bleu": 35.72817,
        "rouge1": {
            "precision": 0.75957,
            "recall": 0.68874,
            "fmeasure": 0.71366
        },
        "rouge2": {
            "precision": 0.5128,
            "recall": 0.46122,
            "fmeasure": 0.479
        },
        "rougeL": {
            "precision": 0.63946,
            "recall": 0.58227,
            "fmeasure": 0.60206
        },
        "rougeLsum": {
            "precision": 0.63946,
            "recall": 0.58227,
            "fmeasure": 0.60206
        },
        "local_recall": {
            "1": 0.1871345029239766,
            "2": 0.5512820512820513,
            "3": 0.7007722007722008
        },
        "bertscore": {
            "precision": 0.9256,
            "recall": 0.91032,
            "f1": 0.91584
        },
        "bleurt": 0.21178,
        "meteor": 0.3602017056881281,
        "nubia": {
            "semantic_relation": 4.11583,
            "contradiction": 7.49651,
            "irrelevancy": 31.67827,
            "logical_agreement": 60.82522,
            "grammar_ref": 4.63301,
            "grammar_hyp": 4.64103,
            "nubia_score": 0.71417
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_45": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 79,
        "msttr-100": 0.73833,
        "msttr-100_nopunct": 0.803,
        "total_length": 1240,
        "mean_pred_length": 15.69620253164557,
        "std_pred_length": 6.94709561456932,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 37,
        "distinct-1": 0.5193548387096775,
        "vocab_size-1": 644,
        "unique-1": 520,
        "entropy-1": 8.142673447562203,
        "distinct-2": 0.8863049095607235,
        "vocab_size-2": 1029,
        "unique-2": 949,
        "entropy-2": 9.89233787838635,
        "cond_entropy-2": 1.465895220275476,
        "distinct-3": 0.967652495378928,
        "vocab_size-3": 1047,
        "unique-3": 1013,
        "entropy-3": 10.014092096671288,
        "cond_entropy-3": 0.09614147418800052,
        "total_length-nopunct": 1062,
        "mean_pred_length-nopunct": 13.443037974683545,
        "std_pred_length-nopunct": 5.784630083340643,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.60075329566855,
        "vocab_size-1-nopunct": 638,
        "unique-1-nopunct": 520,
        "entropy-1-nopunct": 8.482699193236327,
        "distinct-2-nopunct": 0.9064089521871821,
        "vocab_size-2-nopunct": 891,
        "unique-2-nopunct": 832,
        "entropy-2-nopunct": 9.704776148163225,
        "cond_entropy-2-nopunct": 1.3032642538733505,
        "distinct-3-nopunct": 0.9723451327433629,
        "vocab_size-3-nopunct": 879,
        "unique-3-nopunct": 854,
        "entropy-3-nopunct": 9.764869227901775,
        "cond_entropy-3-nopunct": 0.07410352796457616,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.871127057719142,
        "bleu": 41.05953,
        "rouge1": {
            "precision": 0.74721,
            "recall": 0.68406,
            "fmeasure": 0.69794
        },
        "rouge2": {
            "precision": 0.50636,
            "recall": 0.4616,
            "fmeasure": 0.46829
        },
        "rougeL": {
            "precision": 0.64872,
            "recall": 0.59398,
            "fmeasure": 0.60529
        },
        "rougeLsum": {
            "precision": 0.64872,
            "recall": 0.59398,
            "fmeasure": 0.60529
        },
        "local_recall": {
            "1": 0.2090032154340836,
            "2": 0.4246575342465753,
            "3": 0.7430830039525692
        },
        "bertscore": {
            "precision": 0.92705,
            "recall": 0.91698,
            "f1": 0.91994
        },
        "bleurt": 0.1734,
        "meteor": 0.37285705013306325,
        "nubia": {
            "semantic_relation": 4.11388,
            "contradiction": 6.80899,
            "irrelevancy": 34.38272,
            "logical_agreement": 58.80829,
            "grammar_ref": 4.80224,
            "grammar_hyp": 4.98096,
            "nubia_score": 0.67878
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_46": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 12.0,
        "std_pred_length": 4.06201920231798,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 19,
        "distinct-1": 0.7916666666666666,
        "vocab_size-1": 38,
        "unique-1": 33,
        "entropy-1": 5.079448698502609,
        "distinct-2": 1.0,
        "vocab_size-2": 44,
        "unique-2": 44,
        "entropy-2": 5.4594316186372955,
        "cond_entropy-2": 0.2441205385181957,
        "distinct-3": 1.0,
        "vocab_size-3": 40,
        "unique-3": 40,
        "entropy-3": 5.3219280948873635,
        "cond_entropy-3": -0.13750352374993507,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 10.25,
        "std_pred_length-nopunct": 3.344772040064913,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8780487804878049,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.076825785000351,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.209453365628954,
        "cond_entropy-2-nopunct": 0.1629763611278102,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.16505924627049623,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.307580250215098,
        "bleu": 58.72175,
        "rouge1": {
            "precision": 0.85312,
            "recall": 0.80638,
            "fmeasure": 0.81925
        },
        "rouge2": {
            "precision": 0.67328,
            "recall": 0.65398,
            "fmeasure": 0.65824
        },
        "rougeL": {
            "precision": 0.75521,
            "recall": 0.74713,
            "fmeasure": 0.74203
        },
        "rougeLsum": {
            "precision": 0.75521,
            "recall": 0.74713,
            "fmeasure": 0.74203
        },
        "local_recall": {
            "1": 0.3076923076923077,
            "2": 0.1111111111111111,
            "3": 0.8333333333333334
        },
        "bertscore": {
            "precision": 0.95147,
            "recall": 0.96031,
            "f1": 0.95475
        },
        "bleurt": 0.30144,
        "meteor": 0.44008439941597877,
        "nubia": {
            "semantic_relation": 4.39983,
            "contradiction": 5.02357,
            "irrelevancy": 25.05043,
            "logical_agreement": 69.926,
            "grammar_ref": 6.02061,
            "grammar_hyp": 6.26579,
            "nubia_score": 0.67839
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_67": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.8345864788028046,
        "bleu": 18.57506,
        "rouge1": {
            "precision": 0.53333,
            "recall": 0.47037,
            "fmeasure": 0.48421
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.30263,
            "fmeasure": 0.30672
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.47037,
            "fmeasure": 0.48421
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.47037,
            "fmeasure": 0.48421
        },
        "local_recall": {
            "1": 0,
            "2": 0.1111111111111111,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.88906,
            "recall": 0.90281,
            "f1": 0.89588
        },
        "bleurt": -0.71217,
        "meteor": 0.21775330541887405,
        "nubia": {
            "semantic_relation": 2.79232,
            "contradiction": 95.69091,
            "irrelevancy": 3.0222,
            "logical_agreement": 1.28689,
            "grammar_ref": 4.8547,
            "grammar_hyp": 5.26993,
            "nubia_score": 0.19692
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_68": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.67333,
        "msttr-100_nopunct": 0.716,
        "total_length": 608,
        "mean_pred_length": 16.88888888888889,
        "std_pred_length": 6.995148230411711,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 38,
        "distinct-1": 0.5411184210526315,
        "vocab_size-1": 329,
        "unique-1": 271,
        "entropy-1": 7.292803717321404,
        "distinct-2": 0.9003496503496503,
        "vocab_size-2": 515,
        "unique-2": 478,
        "entropy-2": 8.914405651539687,
        "cond_entropy-2": 1.4192717884288633,
        "distinct-3": 0.9664179104477612,
        "vocab_size-3": 518,
        "unique-3": 500,
        "entropy-3": 8.998925011353322,
        "cond_entropy-3": 0.08234914464312722,
        "total_length-nopunct": 528,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 6.231639698613305,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6117424242424242,
        "vocab_size-1-nopunct": 323,
        "unique-1-nopunct": 271,
        "entropy-1-nopunct": 7.446985364899336,
        "distinct-2-nopunct": 0.9105691056910569,
        "vocab_size-2-nopunct": 448,
        "unique-2-nopunct": 422,
        "entropy-2-nopunct": 8.714046269655068,
        "cond_entropy-2-nopunct": 1.358365280080583,
        "distinct-3-nopunct": 0.9758771929824561,
        "vocab_size-3-nopunct": 445,
        "unique-3-nopunct": 434,
        "entropy-3-nopunct": 8.784644400129707,
        "cond_entropy-3-nopunct": 0.07986316662499016,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.639723088498042,
        "bleu": 44.98872,
        "rouge1": {
            "precision": 0.81987,
            "recall": 0.73014,
            "fmeasure": 0.76302
        },
        "rouge2": {
            "precision": 0.57721,
            "recall": 0.51316,
            "fmeasure": 0.53584
        },
        "rougeL": {
            "precision": 0.70042,
            "recall": 0.62905,
            "fmeasure": 0.65509
        },
        "rougeLsum": {
            "precision": 0.70042,
            "recall": 0.62905,
            "fmeasure": 0.65509
        },
        "local_recall": {
            "1": 0.20270270270270271,
            "2": 0.34831460674157305,
            "3": 0.7675544794188862
        },
        "bertscore": {
            "precision": 0.94237,
            "recall": 0.92225,
            "f1": 0.93041
        },
        "bleurt": 0.28836,
        "meteor": 0.3721281506355379,
        "nubia": {
            "semantic_relation": 4.3395,
            "contradiction": 6.55329,
            "irrelevancy": 21.07962,
            "logical_agreement": 72.36709,
            "grammar_ref": 4.82696,
            "grammar_hyp": 5.00862,
            "nubia_score": 0.74018
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_69": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 83,
        "mean_pred_length": 13.833333333333334,
        "std_pred_length": 5.112620550059322,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 23,
        "distinct-1": 0.7108433734939759,
        "vocab_size-1": 59,
        "unique-1": 47,
        "entropy-1": 5.641378551954385,
        "distinct-2": 0.974025974025974,
        "vocab_size-2": 75,
        "unique-2": 73,
        "entropy-2": 6.214838488746853,
        "cond_entropy-2": 0.4292026675980306,
        "distinct-3": 1.0,
        "vocab_size-3": 71,
        "unique-3": 71,
        "entropy-3": 6.149747119504677,
        "cond_entropy-3": -0.06070139302120503,
        "total_length-nopunct": 73,
        "mean_pred_length-nopunct": 12.166666666666666,
        "std_pred_length-nopunct": 4.561310727801336,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7671232876712328,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.633260305686999,
        "distinct-2-nopunct": 0.9701492537313433,
        "vocab_size-2-nopunct": 65,
        "unique-2-nopunct": 63,
        "entropy-2-nopunct": 6.006387697920453,
        "cond_entropy-2-nopunct": 0.3931182208776164,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 61,
        "unique-3-nopunct": 61,
        "entropy-3-nopunct": 5.930737337562883,
        "cond_entropy-3-nopunct": -0.08617152502603373,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.800212703258242,
        "bleu": 27.65578,
        "rouge1": {
            "precision": 0.72228,
            "recall": 0.54814,
            "fmeasure": 0.61414
        },
        "rouge2": {
            "precision": 0.38292,
            "recall": 0.29701,
            "fmeasure": 0.32985
        },
        "rougeL": {
            "precision": 0.55389,
            "recall": 0.42,
            "fmeasure": 0.46855
        },
        "rougeLsum": {
            "precision": 0.55389,
            "recall": 0.42,
            "fmeasure": 0.46855
        },
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.5,
            "3": 0.603448275862069
        },
        "bertscore": {
            "precision": 0.91503,
            "recall": 0.88185,
            "f1": 0.89781
        },
        "bleurt": 0.09004,
        "meteor": 0.2899746069978821,
        "nubia": {
            "semantic_relation": 3.76235,
            "contradiction": 16.25758,
            "irrelevancy": 34.60991,
            "logical_agreement": 49.13251,
            "grammar_ref": 3.92533,
            "grammar_hyp": 4.47181,
            "nubia_score": 0.62306
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_90": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 78,
        "msttr-100": 0.72385,
        "msttr-100_nopunct": 0.78,
        "total_length": 1305,
        "mean_pred_length": 16.73076923076923,
        "std_pred_length": 6.692270851652208,
        "median_pred_length": 15.5,
        "min_pred_length": 5,
        "max_pred_length": 37,
        "distinct-1": 0.47509578544061304,
        "vocab_size-1": 620,
        "unique-1": 457,
        "entropy-1": 8.088371362828976,
        "distinct-2": 0.8524857375713122,
        "vocab_size-2": 1046,
        "unique-2": 923,
        "entropy-2": 9.893219851283865,
        "cond_entropy-2": 1.5490479340633143,
        "distinct-3": 0.9460400348128808,
        "vocab_size-3": 1087,
        "unique-3": 1028,
        "entropy-3": 10.056272166626398,
        "cond_entropy-3": 0.15806902837069828,
        "total_length-nopunct": 1135,
        "mean_pred_length-nopunct": 14.551282051282051,
        "std_pred_length-nopunct": 5.873991863088215,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.5383259911894274,
        "vocab_size-1-nopunct": 611,
        "unique-1-nopunct": 456,
        "entropy-1-nopunct": 8.340369782529988,
        "distinct-2-nopunct": 0.859035004730369,
        "vocab_size-2-nopunct": 908,
        "unique-2-nopunct": 807,
        "entropy-2-nopunct": 9.690744180476054,
        "cond_entropy-2-nopunct": 1.428738664669736,
        "distinct-3-nopunct": 0.9499489274770173,
        "vocab_size-3-nopunct": 930,
        "unique-3-nopunct": 883,
        "entropy-3-nopunct": 9.833520744185623,
        "cond_entropy-3-nopunct": 0.1608472557532506,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.576587282908874,
        "bleu": 50.36852,
        "rouge1": {
            "precision": 0.78497,
            "recall": 0.73908,
            "fmeasure": 0.74987
        },
        "rouge2": {
            "precision": 0.56149,
            "recall": 0.5246,
            "fmeasure": 0.53426
        },
        "rougeL": {
            "precision": 0.70662,
            "recall": 0.66279,
            "fmeasure": 0.67404
        },
        "rougeLsum": {
            "precision": 0.70662,
            "recall": 0.66279,
            "fmeasure": 0.67404
        },
        "local_recall": {
            "1": 0.1888412017167382,
            "2": 0.4851063829787234,
            "3": 0.7931873479318735
        },
        "bertscore": {
            "precision": 0.93507,
            "recall": 0.93147,
            "f1": 0.93181
        },
        "bleurt": 0.32294,
        "meteor": 0.4170667074152063,
        "nubia": {
            "semantic_relation": 4.31949,
            "contradiction": 6.55785,
            "irrelevancy": 31.29974,
            "logical_agreement": 62.14241,
            "grammar_ref": 4.66269,
            "grammar_hyp": 4.67143,
            "nubia_score": 0.76238
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_91": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.75,
        "total_length": 260,
        "mean_pred_length": 14.444444444444445,
        "std_pred_length": 4.57313680605704,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.6230769230769231,
        "vocab_size-1": 162,
        "unique-1": 133,
        "entropy-1": 6.723402897059959,
        "distinct-2": 0.9380165289256198,
        "vocab_size-2": 227,
        "unique-2": 217,
        "entropy-2": 7.76900925997505,
        "cond_entropy-2": 0.8320638772186919,
        "distinct-3": 0.9821428571428571,
        "vocab_size-3": 220,
        "unique-3": 216,
        "entropy-3": 7.7716406363432835,
        "cond_entropy-3": 0.005744642401270366,
        "total_length-nopunct": 236,
        "mean_pred_length-nopunct": 13.11111111111111,
        "std_pred_length-nopunct": 4.581228472908512,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.673728813559322,
        "vocab_size-1-nopunct": 159,
        "unique-1-nopunct": 132,
        "entropy-1-nopunct": 6.818818525415172,
        "distinct-2-nopunct": 0.9357798165137615,
        "vocab_size-2-nopunct": 204,
        "unique-2-nopunct": 195,
        "entropy-2-nopunct": 7.611006973829713,
        "cond_entropy-2-nopunct": 0.8433299228688474,
        "distinct-3-nopunct": 0.985,
        "vocab_size-3-nopunct": 197,
        "unique-3-nopunct": 194,
        "entropy-3-nopunct": 7.613856189774742,
        "cond_entropy-3-nopunct": 0.0019951775302505144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.79160665610806,
        "bleu": 39.98359,
        "rouge1": {
            "precision": 0.74149,
            "recall": 0.70617,
            "fmeasure": 0.71516
        },
        "rouge2": {
            "precision": 0.51181,
            "recall": 0.49171,
            "fmeasure": 0.49516
        },
        "rougeL": {
            "precision": 0.63776,
            "recall": 0.60299,
            "fmeasure": 0.61249
        },
        "rougeLsum": {
            "precision": 0.63776,
            "recall": 0.60299,
            "fmeasure": 0.61249
        },
        "local_recall": {
            "1": 0.20408163265306123,
            "2": 0.5,
            "3": 0.7588235294117647
        },
        "bertscore": {
            "precision": 0.92143,
            "recall": 0.9146,
            "f1": 0.91688
        },
        "bleurt": 0.17154,
        "meteor": 0.36545016455441254,
        "nubia": {
            "semantic_relation": 4.2228,
            "contradiction": 1.52904,
            "irrelevancy": 35.8308,
            "logical_agreement": 62.64015,
            "grammar_ref": 4.90853,
            "grammar_hyp": 4.78718,
            "nubia_score": 0.73081
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_92": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 22,
        "msttr-100": 0.73333,
        "msttr-100_nopunct": 0.79,
        "total_length": 311,
        "mean_pred_length": 14.136363636363637,
        "std_pred_length": 5.446395426380265,
        "median_pred_length": 13.5,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.6270096463022508,
        "vocab_size-1": 195,
        "unique-1": 160,
        "entropy-1": 6.924718280803562,
        "distinct-2": 0.9619377162629758,
        "vocab_size-2": 278,
        "unique-2": 271,
        "entropy-2": 8.084960284576782,
        "cond_entropy-2": 0.9239986098465226,
        "distinct-3": 0.9962546816479401,
        "vocab_size-3": 266,
        "unique-3": 265,
        "entropy-3": 8.053205294983398,
        "cond_entropy-3": -0.024342110363686685,
        "total_length-nopunct": 271,
        "mean_pred_length-nopunct": 12.318181818181818,
        "std_pred_length-nopunct": 4.957880445552989,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6937269372693727,
        "vocab_size-1-nopunct": 188,
        "unique-1-nopunct": 158,
        "entropy-1-nopunct": 7.032682075959682,
        "distinct-2-nopunct": 0.9598393574297188,
        "vocab_size-2-nopunct": 239,
        "unique-2-nopunct": 233,
        "entropy-2-nopunct": 7.863616389899408,
        "cond_entropy-2-nopunct": 0.9035779815648881,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 227,
        "unique-3-nopunct": 227,
        "entropy-3-nopunct": 7.826548487290895,
        "cond_entropy-3-nopunct": -0.02772657253047028,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.654196938763532,
        "bleu": 39.80584,
        "rouge1": {
            "precision": 0.73631,
            "recall": 0.7273,
            "fmeasure": 0.72066
        },
        "rouge2": {
            "precision": 0.48356,
            "recall": 0.46621,
            "fmeasure": 0.46441
        },
        "rougeL": {
            "precision": 0.63772,
            "recall": 0.62544,
            "fmeasure": 0.62261
        },
        "rougeLsum": {
            "precision": 0.63772,
            "recall": 0.62544,
            "fmeasure": 0.62261
        },
        "local_recall": {
            "1": 0.14666666666666667,
            "2": 0.43636363636363634,
            "3": 0.7934782608695652
        },
        "bertscore": {
            "precision": 0.91488,
            "recall": 0.92545,
            "f1": 0.91921
        },
        "bleurt": 0.18185,
        "meteor": 0.36918955980366686,
        "nubia": {
            "semantic_relation": 4.30462,
            "contradiction": 4.7203,
            "irrelevancy": 36.93332,
            "logical_agreement": 58.34638,
            "grammar_ref": 5.03776,
            "grammar_hyp": 5.40657,
            "nubia_score": 0.70704
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_20": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 112,
        "msttr-100": 0.69529,
        "msttr-100_nopunct": 0.752,
        "total_length": 1776,
        "mean_pred_length": 15.857142857142858,
        "std_pred_length": 5.884084379033991,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 38,
        "distinct-1": 0.44256756756756754,
        "vocab_size-1": 786,
        "unique-1": 660,
        "entropy-1": 8.003256262797027,
        "distinct-2": 0.8076923076923077,
        "vocab_size-2": 1344,
        "unique-2": 1245,
        "entropy-2": 10.063730659790837,
        "cond_entropy-2": 1.7892904016860538,
        "distinct-3": 0.9104381443298969,
        "vocab_size-3": 1413,
        "unique-3": 1369,
        "entropy-3": 10.326415393309523,
        "cond_entropy-3": 0.25640429827939726,
        "total_length-nopunct": 1544,
        "mean_pred_length-nopunct": 13.785714285714286,
        "std_pred_length-nopunct": 5.092761970659527,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.5019430051813472,
        "vocab_size-1-nopunct": 775,
        "unique-1-nopunct": 655,
        "entropy-1-nopunct": 8.256212001016085,
        "distinct-2-nopunct": 0.8240223463687151,
        "vocab_size-2-nopunct": 1180,
        "unique-2-nopunct": 1109,
        "entropy-2-nopunct": 9.882257463989838,
        "cond_entropy-2-nopunct": 1.7258862248881508,
        "distinct-3-nopunct": 0.9174242424242425,
        "vocab_size-3-nopunct": 1211,
        "unique-3-nopunct": 1177,
        "entropy-3-nopunct": 10.114262036445252,
        "cond_entropy-3-nopunct": 0.25698499616318904,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.401815885267827,
        "bleu": 45.93584,
        "rouge1": {
            "precision": 0.75754,
            "recall": 0.71773,
            "fmeasure": 0.7254
        },
        "rouge2": {
            "precision": 0.52867,
            "recall": 0.4955,
            "fmeasure": 0.50442
        },
        "rougeL": {
            "precision": 0.65816,
            "recall": 0.62603,
            "fmeasure": 0.63201
        },
        "rougeLsum": {
            "precision": 0.65816,
            "recall": 0.62603,
            "fmeasure": 0.63201
        },
        "local_recall": {
            "1": 0.20771513353115728,
            "2": 0.41025641025641024,
            "3": 0.7909011373578303
        },
        "bertscore": {
            "precision": 0.92702,
            "recall": 0.92101,
            "f1": 0.92273
        },
        "bleurt": 0.31027,
        "meteor": 0.38319534638835606,
        "nubia": {
            "semantic_relation": 4.16445,
            "contradiction": 8.45851,
            "irrelevancy": 25.75628,
            "logical_agreement": 65.78521,
            "grammar_ref": 4.71051,
            "grammar_hyp": 4.60405,
            "nubia_score": 0.73733
        }
    },
    "web_nlg_en_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 1295,
        "msttr-100": 0.63288,
        "msttr-100_nopunct": 0.67158,
        "total_length": 39291,
        "mean_pred_length": 30.34054054054054,
        "std_pred_length": 11.674902019269942,
        "median_pred_length": 29.0,
        "min_pred_length": 7,
        "max_pred_length": 75,
        "distinct-1": 0.05278562520679036,
        "vocab_size-1": 2074,
        "unique-1": 654,
        "entropy-1": 8.041359035601108,
        "distinct-2": 0.19380987472365513,
        "vocab_size-2": 7364,
        "unique-2": 3490,
        "entropy-2": 11.363611582173418,
        "cond_entropy-2": 3.188305755770336,
        "distinct-3": 0.35601209776300374,
        "vocab_size-3": 13066,
        "unique-3": 7929,
        "entropy-3": 12.68696924397481,
        "cond_entropy-3": 1.3714044439016486,
        "total_length-nopunct": 34879,
        "mean_pred_length-nopunct": 26.933590733590734,
        "std_pred_length-nopunct": 10.52147239292707,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 65,
        "distinct-1-nopunct": 0.059176008486481836,
        "vocab_size-1-nopunct": 2064,
        "unique-1-nopunct": 654,
        "entropy-1-nopunct": 8.310323415349332,
        "distinct-2-nopunct": 0.21170795616960458,
        "vocab_size-2-nopunct": 7110,
        "unique-2-nopunct": 3633,
        "entropy-2-nopunct": 11.314771622291511,
        "cond_entropy-2-nopunct": 3.117650691603409,
        "distinct-3-nopunct": 0.37669175260924775,
        "vocab_size-3-nopunct": 12163,
        "unique-3-nopunct": 7708,
        "entropy-3-nopunct": 12.583669061145308,
        "cond_entropy-3-nopunct": 1.3113595470322659,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.576353762446612,
        "bleu": 37.29336,
        "rouge1": {
            "precision": 0.66233,
            "recall": 0.67502,
            "fmeasure": 0.66227
        },
        "rouge2": {
            "precision": 0.38877,
            "recall": 0.3959,
            "fmeasure": 0.38824
        },
        "rougeL": {
            "precision": 0.4974,
            "recall": 0.50816,
            "fmeasure": 0.49748
        },
        "rougeLsum": {
            "precision": 0.4974,
            "recall": 0.50816,
            "fmeasure": 0.49748
        },
        "local_recall": {
            "1": 0.22291737504250256,
            "2": 0.5391996255558156,
            "3": 0.7744038529308117,
            "4": 0.5294117647058824,
            "5": 0.7241379310344828
        },
        "bertscore": {
            "precision": 0.88747,
            "recall": 0.8904,
            "f1": 0.88762
        },
        "bleurt": -0.09147,
        "meteor": 0.33029211250733337,
        "nubia": {
            "semantic_relation": 3.93956,
            "contradiction": 25.05867,
            "irrelevancy": 11.10835,
            "logical_agreement": 63.83298,
            "grammar_ref": 4.37017,
            "grammar_hyp": 4.47595,
            "nubia_score": 0.65088
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_95": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.734,
        "msttr-100_nopunct": 0.795,
        "total_length": 563,
        "mean_pred_length": 18.161290322580644,
        "std_pred_length": 5.941091320372304,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.5950266429840142,
        "vocab_size-1": 335,
        "unique-1": 283,
        "entropy-1": 7.600276685534881,
        "distinct-2": 0.9135338345864662,
        "vocab_size-2": 486,
        "unique-2": 456,
        "entropy-2": 8.853432664852313,
        "cond_entropy-2": 1.0540169973641145,
        "distinct-3": 0.9760479041916168,
        "vocab_size-3": 489,
        "unique-3": 480,
        "entropy-3": 8.915263824128932,
        "cond_entropy-3": 0.060838056258744416,
        "total_length-nopunct": 484,
        "mean_pred_length-nopunct": 15.612903225806452,
        "std_pred_length-nopunct": 5.065235206810457,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6756198347107438,
        "vocab_size-1-nopunct": 327,
        "unique-1-nopunct": 279,
        "entropy-1-nopunct": 7.81902841532139,
        "distinct-2-nopunct": 0.9315673289183223,
        "vocab_size-2-nopunct": 422,
        "unique-2-nopunct": 402,
        "entropy-2-nopunct": 8.663037901231498,
        "cond_entropy-2-nopunct": 0.9056539770339985,
        "distinct-3-nopunct": 0.9881516587677726,
        "vocab_size-3-nopunct": 417,
        "unique-3-nopunct": 412,
        "entropy-3-nopunct": 8.697402506242714,
        "cond_entropy-3-nopunct": 0.036261013783339305,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.528311522177165,
        "bleu": 60.52456,
        "rouge1": {
            "precision": 0.80414,
            "recall": 0.80021,
            "fmeasure": 0.79415
        },
        "rouge2": {
            "precision": 0.62189,
            "recall": 0.61784,
            "fmeasure": 0.61345
        },
        "rougeL": {
            "precision": 0.71252,
            "recall": 0.71506,
            "fmeasure": 0.70693
        },
        "rougeLsum": {
            "precision": 0.71252,
            "recall": 0.71506,
            "fmeasure": 0.70693
        },
        "local_recall": {
            "1": 0.2743362831858407,
            "2": 0.5,
            "3": 0.8236914600550964
        },
        "bertscore": {
            "precision": 0.94398,
            "recall": 0.9414,
            "f1": 0.94194
        },
        "bleurt": 0.42317,
        "meteor": 0.4579694655565004,
        "nubia": {
            "semantic_relation": 4.32607,
            "contradiction": 10.98017,
            "irrelevancy": 18.18526,
            "logical_agreement": 70.83457,
            "grammar_ref": 4.87083,
            "grammar_hyp": 4.73151,
            "nubia_score": 0.77149
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_70": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 81,
        "msttr-100": 0.73462,
        "msttr-100_nopunct": 0.79091,
        "total_length": 1366,
        "mean_pred_length": 16.864197530864196,
        "std_pred_length": 6.552264873562976,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 36,
        "distinct-1": 0.47584187408491946,
        "vocab_size-1": 650,
        "unique-1": 513,
        "entropy-1": 8.105234500845025,
        "distinct-2": 0.8583657587548638,
        "vocab_size-2": 1103,
        "unique-2": 1000,
        "entropy-2": 9.970165121628634,
        "cond_entropy-2": 1.6054937675014376,
        "distinct-3": 0.9401993355481728,
        "vocab_size-3": 1132,
        "unique-3": 1079,
        "entropy-3": 10.102105671326884,
        "cond_entropy-3": 0.121287685750985,
        "total_length-nopunct": 1180,
        "mean_pred_length-nopunct": 14.567901234567902,
        "std_pred_length-nopunct": 5.60409522130956,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.5440677966101695,
        "vocab_size-1-nopunct": 642,
        "unique-1-nopunct": 511,
        "entropy-1-nopunct": 8.391077140896783,
        "distinct-2-nopunct": 0.8717015468607825,
        "vocab_size-2-nopunct": 958,
        "unique-2-nopunct": 880,
        "entropy-2-nopunct": 9.77468350413446,
        "cond_entropy-2-nopunct": 1.4654252025605363,
        "distinct-3-nopunct": 0.9469548133595285,
        "vocab_size-3-nopunct": 964,
        "unique-3-nopunct": 926,
        "entropy-3-nopunct": 9.873566836218577,
        "cond_entropy-3-nopunct": 0.11337820242786426,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.77850293863414,
        "bleu": 52.53166,
        "rouge1": {
            "precision": 0.78483,
            "recall": 0.74751,
            "fmeasure": 0.75223
        },
        "rouge2": {
            "precision": 0.57997,
            "recall": 0.54583,
            "fmeasure": 0.55272
        },
        "rougeL": {
            "precision": 0.67815,
            "recall": 0.63991,
            "fmeasure": 0.64621
        },
        "rougeLsum": {
            "precision": 0.67815,
            "recall": 0.63991,
            "fmeasure": 0.64621
        },
        "local_recall": {
            "1": 0.23890784982935154,
            "2": 0.46124031007751937,
            "3": 0.8079625292740047
        },
        "bertscore": {
            "precision": 0.93723,
            "recall": 0.93015,
            "f1": 0.93203
        },
        "bleurt": 0.31416,
        "meteor": 0.41683283590785974,
        "nubia": {
            "semantic_relation": 4.19525,
            "contradiction": 5.96421,
            "irrelevancy": 26.06534,
            "logical_agreement": 67.97045,
            "grammar_ref": 4.67017,
            "grammar_hyp": 4.63923,
            "nubia_score": 0.72704
        }
    },
    "web_nlg_en_test_contrast_challenge_combinations-seen": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 115,
        "msttr-100": 0.64455,
        "msttr-100_nopunct": 0.69211,
        "total_length": 2211,
        "mean_pred_length": 19.22608695652174,
        "std_pred_length": 6.671237248608475,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 55,
        "distinct-1": 0.25237449118046135,
        "vocab_size-1": 558,
        "unique-1": 281,
        "entropy-1": 7.343472217371137,
        "distinct-2": 0.5543893129770993,
        "vocab_size-2": 1162,
        "unique-2": 799,
        "entropy-2": 9.689515664851827,
        "cond_entropy-2": 2.168044946172385,
        "distinct-3": 0.7137809187279152,
        "vocab_size-3": 1414,
        "unique-3": 1108,
        "entropy-3": 10.218387869018033,
        "cond_entropy-3": 0.5723176358989875,
        "total_length-nopunct": 1906,
        "mean_pred_length-nopunct": 16.57391304347826,
        "std_pred_length-nopunct": 5.8176057671523065,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.28908709338929695,
        "vocab_size-1-nopunct": 551,
        "unique-1-nopunct": 281,
        "entropy-1-nopunct": 7.645432531615207,
        "distinct-2-nopunct": 0.5572305974316024,
        "vocab_size-2-nopunct": 998,
        "unique-2-nopunct": 681,
        "entropy-2-nopunct": 9.486171695375253,
        "cond_entropy-2-nopunct": 1.9658266016900512,
        "distinct-3-nopunct": 0.7177804295942721,
        "vocab_size-3-nopunct": 1203,
        "unique-3-nopunct": 946,
        "entropy-3-nopunct": 9.987670914534075,
        "cond_entropy-3-nopunct": 0.5395655876419986,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.288746736851007,
        "bleu": 45.59397,
        "rouge1": {
            "precision": 0.71877,
            "recall": 0.73409,
            "fmeasure": 0.71967
        },
        "rouge2": {
            "precision": 0.46336,
            "recall": 0.47995,
            "fmeasure": 0.46696
        },
        "rougeL": {
            "precision": 0.61008,
            "recall": 0.62958,
            "fmeasure": 0.61338
        },
        "rougeLsum": {
            "precision": 0.61008,
            "recall": 0.62958,
            "fmeasure": 0.61338
        },
        "local_recall": {
            "1": 0.23564593301435408,
            "2": 0.56,
            "3": 0.84400826446281
        },
        "bertscore": {
            "precision": 0.91218,
            "recall": 0.92115,
            "f1": 0.91528
        },
        "bleurt": 0.14564,
        "meteor": 0.3990228516585066,
        "nubia": {
            "semantic_relation": 4.3622,
            "contradiction": 13.82774,
            "irrelevancy": 4.9509,
            "logical_agreement": 81.22136,
            "grammar_ref": 4.68186,
            "grammar_hyp": 4.67145,
            "nubia_score": 0.76179
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_93": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 99,
        "mean_pred_length": 19.8,
        "std_pred_length": 9.042123644365853,
        "median_pred_length": 18.0,
        "min_pred_length": 11,
        "max_pred_length": 36,
        "distinct-1": 0.7070707070707071,
        "vocab_size-1": 70,
        "unique-1": 58,
        "entropy-1": 5.8108155853355985,
        "distinct-2": 0.9361702127659575,
        "vocab_size-2": 88,
        "unique-2": 83,
        "entropy-2": 6.4188985591014225,
        "cond_entropy-2": 0.5281155769496991,
        "distinct-3": 0.9662921348314607,
        "vocab_size-3": 86,
        "unique-3": 83,
        "entropy-3": 6.40831770062933,
        "cond_entropy-3": -0.002957808327380248,
        "total_length-nopunct": 74,
        "mean_pred_length-nopunct": 14.8,
        "std_pred_length-nopunct": 4.791659420284375,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8783783783783784,
        "vocab_size-1-nopunct": 65,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.956008939924043,
        "distinct-2-nopunct": 0.9710144927536232,
        "vocab_size-2-nopunct": 67,
        "unique-2-nopunct": 65,
        "entropy-2-nopunct": 6.05055344228541,
        "cond_entropy-2-nopunct": 0.09841728683274809,
        "distinct-3-nopunct": 0.984375,
        "vocab_size-3-nopunct": 63,
        "unique-3-nopunct": 62,
        "entropy-3-nopunct": 5.96875,
        "cond_entropy-3-nopunct": -0.09289945677816912,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.652332371889777,
        "bleu": 66.44514,
        "rouge1": {
            "precision": 0.75136,
            "recall": 0.84651,
            "fmeasure": 0.78667
        },
        "rouge2": {
            "precision": 0.61009,
            "recall": 0.67783,
            "fmeasure": 0.6328
        },
        "rougeL": {
            "precision": 0.72106,
            "recall": 0.81786,
            "fmeasure": 0.75715
        },
        "rougeLsum": {
            "precision": 0.72106,
            "recall": 0.81786,
            "fmeasure": 0.75715
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.7,
            "3": 0.9130434782608695
        },
        "bertscore": {
            "precision": 0.93211,
            "recall": 0.96095,
            "f1": 0.94534
        },
        "bleurt": 0.42034,
        "meteor": 0.46343739786938354,
        "nubia": {
            "semantic_relation": 4.1969,
            "contradiction": 8.72838,
            "irrelevancy": 27.76017,
            "logical_agreement": 63.51145,
            "grammar_ref": 4.96303,
            "grammar_hyp": 4.28545,
            "nubia_score": 0.78079
        }
    },
    "totto_test_contrast_challenge_continent-south_america": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 79,
        "msttr-100": 0.72077,
        "msttr-100_nopunct": 0.78364,
        "total_length": 1315,
        "mean_pred_length": 16.645569620253166,
        "std_pred_length": 5.663648183943114,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 36,
        "distinct-1": 0.45627376425855515,
        "vocab_size-1": 600,
        "unique-1": 465,
        "entropy-1": 7.918110303622173,
        "distinct-2": 0.8422330097087378,
        "vocab_size-2": 1041,
        "unique-2": 942,
        "entropy-2": 9.83699650916605,
        "cond_entropy-2": 1.672104269102339,
        "distinct-3": 0.9524632670700086,
        "vocab_size-3": 1102,
        "unique-3": 1058,
        "entropy-3": 10.072336532437449,
        "cond_entropy-3": 0.22569344723395485,
        "total_length-nopunct": 1147,
        "mean_pred_length-nopunct": 14.518987341772151,
        "std_pred_length-nopunct": 5.000913231774623,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.5170008718395815,
        "vocab_size-1-nopunct": 593,
        "unique-1-nopunct": 464,
        "entropy-1-nopunct": 8.184954971025697,
        "distinct-2-nopunct": 0.8614232209737828,
        "vocab_size-2-nopunct": 920,
        "unique-2-nopunct": 852,
        "entropy-2-nopunct": 9.659729207726848,
        "cond_entropy-2-nopunct": 1.5493324731472504,
        "distinct-3-nopunct": 0.961577350859454,
        "vocab_size-3-nopunct": 951,
        "unique-3-nopunct": 918,
        "entropy-3-nopunct": 9.868669316920364,
        "cond_entropy-3-nopunct": 0.21304044799995925,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.5465137869290215,
        "bleu": 44.87174,
        "rouge1": {
            "precision": 0.83437,
            "recall": 0.78293,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.60912,
            "recall": 0.57346,
            "fmeasure": 0.5849
        },
        "rougeL": {
            "precision": 0.70627,
            "recall": 0.65866,
            "fmeasure": 0.67499
        },
        "rougeLsum": {
            "precision": 0.70627,
            "recall": 0.65866,
            "fmeasure": 0.67499
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.44660194174757284,
            "3": 0.7918015102481122
        },
        "bertscore": {
            "precision": 0.93842,
            "recall": 0.93461,
            "f1": 0.93556
        },
        "bleurt": 0.34291,
        "meteor": 0.4049944495241763,
        "nubia": {
            "semantic_relation": 4.4216,
            "contradiction": 6.24767,
            "irrelevancy": 22.62335,
            "logical_agreement": 71.12898,
            "grammar_ref": 4.82253,
            "grammar_hyp": 4.95652,
            "nubia_score": 0.76421
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_94": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 51,
        "mean_pred_length": 25.5,
        "std_pred_length": 14.5,
        "median_pred_length": 25.5,
        "min_pred_length": 11,
        "max_pred_length": 40,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 34,
        "unique-1": 25,
        "entropy-1": 4.834600715438154,
        "distinct-2": 0.8775510204081632,
        "vocab_size-2": 43,
        "unique-2": 38,
        "entropy-2": 5.354406017540444,
        "cond_entropy-2": 0.513185899103653,
        "distinct-3": 0.9361702127659575,
        "vocab_size-3": 44,
        "unique-3": 41,
        "entropy-3": 5.426929277209555,
        "cond_entropy-3": 0.0836000182467583,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 8.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.815622570826658,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.087462841250338,
        "cond_entropy-2-nopunct": 0.2926815898716586,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.08746284125033942,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.528848691535131,
        "bleu": 71.50465,
        "rouge1": {
            "precision": 0.78077,
            "recall": 0.76932,
            "fmeasure": 0.77483
        },
        "rouge2": {
            "precision": 0.59333,
            "recall": 0.58346,
            "fmeasure": 0.58821
        },
        "rougeL": {
            "precision": 0.7359,
            "recall": 0.77841,
            "fmeasure": 0.75385
        },
        "rougeLsum": {
            "precision": 0.7359,
            "recall": 0.77841,
            "fmeasure": 0.75385
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.8148148148148148
        },
        "bertscore": {
            "precision": 0.9481,
            "recall": 0.91794,
            "f1": 0.93267
        },
        "bleurt": 0.39424,
        "meteor": 0.4789862473981244,
        "nubia": {
            "semantic_relation": 4.73753,
            "contradiction": 0.39689,
            "irrelevancy": 18.03222,
            "logical_agreement": 81.57089,
            "grammar_ref": 4.15024,
            "grammar_hyp": 4.28655,
            "nubia_score": 0.87676
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_124": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.595,
        "msttr-100_nopunct": 0.72,
        "total_length": 259,
        "mean_pred_length": 18.5,
        "std_pred_length": 11.745819925160003,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 55,
        "distinct-1": 0.528957528957529,
        "vocab_size-1": 137,
        "unique-1": 106,
        "entropy-1": 6.283015699816316,
        "distinct-2": 0.8244897959183674,
        "vocab_size-2": 202,
        "unique-2": 174,
        "entropy-2": 7.495756255610743,
        "cond_entropy-2": 1.0942512795551111,
        "distinct-3": 0.9047619047619048,
        "vocab_size-3": 209,
        "unique-3": 187,
        "entropy-3": 7.661272850939839,
        "cond_entropy-3": 0.13332050482286645,
        "total_length-nopunct": 206,
        "mean_pred_length-nopunct": 14.714285714285714,
        "std_pred_length-nopunct": 7.544426243720511,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.6407766990291263,
        "vocab_size-1-nopunct": 132,
        "unique-1-nopunct": 105,
        "entropy-1-nopunct": 6.452267034824617,
        "distinct-2-nopunct": 0.8802083333333334,
        "vocab_size-2-nopunct": 169,
        "unique-2-nopunct": 151,
        "entropy-2-nopunct": 7.30552768585449,
        "cond_entropy-2-nopunct": 0.924585163489749,
        "distinct-3-nopunct": 0.9269662921348315,
        "vocab_size-3-nopunct": 165,
        "unique-3-nopunct": 152,
        "entropy-3-nopunct": 7.32966601523604,
        "cond_entropy-3-nopunct": 0.03488039347222612,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.684032299659705,
        "bleu": 46.27263,
        "rouge1": {
            "precision": 0.78965,
            "recall": 0.69239,
            "fmeasure": 0.72895
        },
        "rouge2": {
            "precision": 0.55979,
            "recall": 0.48524,
            "fmeasure": 0.51485
        },
        "rougeL": {
            "precision": 0.6674,
            "recall": 0.59215,
            "fmeasure": 0.61995
        },
        "rougeLsum": {
            "precision": 0.6674,
            "recall": 0.59215,
            "fmeasure": 0.61995
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.2962962962962963,
            "3": 0.711764705882353
        },
        "bertscore": {
            "precision": 0.9445,
            "recall": 0.93792,
            "f1": 0.94046
        },
        "bleurt": 0.39248,
        "meteor": 0.39177368426737785,
        "nubia": {
            "semantic_relation": 4.47947,
            "contradiction": 12.43752,
            "irrelevancy": 15.67589,
            "logical_agreement": 71.88659,
            "grammar_ref": 4.7817,
            "grammar_hyp": 4.87738,
            "nubia_score": 0.79853
        }
    },
    "web_nlg_en_test_contrast_challenge_args-both_seen": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 518,
        "msttr-100": 0.65826,
        "msttr-100_nopunct": 0.69783,
        "total_length": 15568,
        "mean_pred_length": 30.054054054054053,
        "std_pred_length": 14.059888898659123,
        "median_pred_length": 27.0,
        "min_pred_length": 5,
        "max_pred_length": 75,
        "distinct-1": 0.06012332990750257,
        "vocab_size-1": 936,
        "unique-1": 245,
        "entropy-1": 7.729024769356926,
        "distinct-2": 0.18943521594684384,
        "vocab_size-2": 2851,
        "unique-2": 1244,
        "entropy-2": 10.270657385036266,
        "cond_entropy-2": 2.4151299127035157,
        "distinct-3": 0.3051885494082026,
        "vocab_size-3": 4435,
        "unique-3": 2428,
        "entropy-3": 11.119614064279261,
        "cond_entropy-3": 0.8859524187045059,
        "total_length-nopunct": 13802,
        "mean_pred_length-nopunct": 26.644787644787645,
        "std_pred_length-nopunct": 12.556485574164864,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 65,
        "distinct-1-nopunct": 0.06716417910447761,
        "vocab_size-1-nopunct": 927,
        "unique-1-nopunct": 245,
        "entropy-1-nopunct": 7.9557914684561695,
        "distinct-2-nopunct": 0.19956338452273412,
        "vocab_size-2-nopunct": 2651,
        "unique-2-nopunct": 1203,
        "entropy-2-nopunct": 10.150190829350416,
        "cond_entropy-2-nopunct": 2.2737949842855394,
        "distinct-3-nopunct": 0.31646561178129406,
        "vocab_size-3-nopunct": 4040,
        "unique-3-nopunct": 2274,
        "entropy-3-nopunct": 10.964732882038112,
        "cond_entropy-3-nopunct": 0.8379356655234423,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 8.937571157721605,
        "bleu": 56.24994,
        "rouge1": {
            "precision": 0.80471,
            "recall": 0.78642,
            "fmeasure": 0.79049
        },
        "rouge2": {
            "precision": 0.56726,
            "recall": 0.55598,
            "fmeasure": 0.55765
        },
        "rougeL": {
            "precision": 0.63142,
            "recall": 0.61813,
            "fmeasure": 0.62046
        },
        "rougeLsum": {
            "precision": 0.63142,
            "recall": 0.61813,
            "fmeasure": 0.62046
        },
        "local_recall": {
            "1": 0.2688604936110625,
            "2": 0.623627960716349,
            "3": 0.917833666761932,
            "4": 0.9736842105263158
        },
        "bertscore": {
            "precision": 0.93815,
            "recall": 0.9348,
            "f1": 0.9354
        },
        "bleurt": 0.28965,
        "meteor": 0.4132907327967039,
        "nubia": {
            "semantic_relation": 4.63545,
            "contradiction": 3.59937,
            "irrelevancy": 5.71869,
            "logical_agreement": 90.68194,
            "grammar_ref": 4.28317,
            "grammar_hyp": 4.26158,
            "nubia_score": 0.85914
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_125": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.64,
        "msttr-100_nopunct": 0.72,
        "total_length": 131,
        "mean_pred_length": 21.833333333333332,
        "std_pred_length": 8.70663859107265,
        "median_pred_length": 19.0,
        "min_pred_length": 13,
        "max_pred_length": 37,
        "distinct-1": 0.648854961832061,
        "vocab_size-1": 85,
        "unique-1": 69,
        "entropy-1": 5.995682060950116,
        "distinct-2": 0.928,
        "vocab_size-2": 116,
        "unique-2": 109,
        "entropy-2": 6.805784284662096,
        "cond_entropy-2": 0.73583558882555,
        "distinct-3": 0.9915966386554622,
        "vocab_size-3": 118,
        "unique-3": 117,
        "entropy-3": 6.878011040618867,
        "cond_entropy-3": 0.06348726015846144,
        "total_length-nopunct": 108,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 5.830951894845301,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7314814814814815,
        "vocab_size-1-nopunct": 79,
        "unique-1-nopunct": 68,
        "entropy-1-nopunct": 5.94734113861031,
        "distinct-2-nopunct": 0.9411764705882353,
        "vocab_size-2-nopunct": 96,
        "unique-2-nopunct": 92,
        "entropy-2-nopunct": 6.535170440010715,
        "cond_entropy-2-nopunct": 0.6197931806219424,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 96,
        "unique-3-nopunct": 96,
        "entropy-3-nopunct": 6.5849625007211605,
        "cond_entropy-3-nopunct": 0.058370492082994024,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.554627667874424,
        "bleu": 51.03338,
        "rouge1": {
            "precision": 0.81929,
            "recall": 0.82635,
            "fmeasure": 0.81237
        },
        "rouge2": {
            "precision": 0.61968,
            "recall": 0.62557,
            "fmeasure": 0.61256
        },
        "rougeL": {
            "precision": 0.76002,
            "recall": 0.76248,
            "fmeasure": 0.75108
        },
        "rougeLsum": {
            "precision": 0.76002,
            "recall": 0.76248,
            "fmeasure": 0.75108
        },
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.75,
            "3": 0.8765432098765432
        },
        "bertscore": {
            "precision": 0.94948,
            "recall": 0.95085,
            "f1": 0.94929
        },
        "bleurt": 0.45074,
        "meteor": 0.42543155079256245,
        "nubia": {
            "semantic_relation": 4.43028,
            "contradiction": 1.36698,
            "irrelevancy": 38.15275,
            "logical_agreement": 60.48027,
            "grammar_ref": 5.04309,
            "grammar_hyp": 4.76002,
            "nubia_score": 0.80724
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_96": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 50,
        "msttr-100": 0.68875,
        "msttr-100_nopunct": 0.73571,
        "total_length": 880,
        "mean_pred_length": 17.6,
        "std_pred_length": 10.972693379476162,
        "median_pred_length": 15.5,
        "min_pred_length": 5,
        "max_pred_length": 73,
        "distinct-1": 0.5022727272727273,
        "vocab_size-1": 442,
        "unique-1": 358,
        "entropy-1": 7.634534797636744,
        "distinct-2": 0.8783132530120482,
        "vocab_size-2": 729,
        "unique-2": 672,
        "entropy-2": 9.378152312496548,
        "cond_entropy-2": 1.5329529802881026,
        "distinct-3": 0.9705128205128205,
        "vocab_size-3": 757,
        "unique-3": 737,
        "entropy-3": 9.54482404772117,
        "cond_entropy-3": 0.17075618802576562,
        "total_length-nopunct": 766,
        "mean_pred_length-nopunct": 15.32,
        "std_pred_length-nopunct": 8.775967183165625,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.5704960835509139,
        "vocab_size-1-nopunct": 437,
        "unique-1-nopunct": 357,
        "entropy-1-nopunct": 7.869391197207958,
        "distinct-2-nopunct": 0.9078212290502793,
        "vocab_size-2-nopunct": 650,
        "unique-2-nopunct": 614,
        "entropy-2-nopunct": 9.23417565935699,
        "cond_entropy-2-nopunct": 1.4459027501819925,
        "distinct-3-nopunct": 0.9834834834834835,
        "vocab_size-3-nopunct": 655,
        "unique-3-nopunct": 647,
        "entropy-3-nopunct": 9.342208866317408,
        "cond_entropy-3-nopunct": 0.12377195455082446,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.560402736417845,
        "bleu": 40.5272,
        "rouge1": {
            "precision": 0.7844,
            "recall": 0.71121,
            "fmeasure": 0.73536
        },
        "rouge2": {
            "precision": 0.55138,
            "recall": 0.5085,
            "fmeasure": 0.52042
        },
        "rougeL": {
            "precision": 0.67118,
            "recall": 0.6134,
            "fmeasure": 0.63141
        },
        "rougeLsum": {
            "precision": 0.67118,
            "recall": 0.6134,
            "fmeasure": 0.63141
        },
        "local_recall": {
            "1": 0.24666666666666667,
            "2": 0.4779874213836478,
            "3": 0.7153284671532847
        },
        "bertscore": {
            "precision": 0.92804,
            "recall": 0.91422,
            "f1": 0.91995
        },
        "bleurt": 0.22048,
        "meteor": 0.36032426891532765,
        "nubia": {
            "semantic_relation": 4.19055,
            "contradiction": 8.47475,
            "irrelevancy": 25.88395,
            "logical_agreement": 65.64131,
            "grammar_ref": 4.7145,
            "grammar_hyp": 4.84395,
            "nubia_score": 0.70374
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_98": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.76,
        "total_length": 196,
        "mean_pred_length": 17.818181818181817,
        "std_pred_length": 6.042548857412315,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.6530612244897959,
        "vocab_size-1": 128,
        "unique-1": 103,
        "entropy-1": 6.573904685839937,
        "distinct-2": 0.9567567567567568,
        "vocab_size-2": 177,
        "unique-2": 170,
        "entropy-2": 7.440814501045146,
        "cond_entropy-2": 0.72309959323774,
        "distinct-3": 0.9885057471264368,
        "vocab_size-3": 172,
        "unique-3": 170,
        "entropy-3": 7.419954990101581,
        "cond_entropy-3": -0.026628266379287828,
        "total_length-nopunct": 172,
        "mean_pred_length-nopunct": 15.636363636363637,
        "std_pred_length-nopunct": 5.278993142166536,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7209302325581395,
        "vocab_size-1-nopunct": 124,
        "unique-1-nopunct": 103,
        "entropy-1-nopunct": 6.631015895642711,
        "distinct-2-nopunct": 0.9627329192546584,
        "vocab_size-2-nopunct": 155,
        "unique-2-nopunct": 150,
        "entropy-2-nopunct": 7.251693974374456,
        "cond_entropy-2-nopunct": 0.6357452175812157,
        "distinct-3-nopunct": 0.9933333333333333,
        "vocab_size-3-nopunct": 149,
        "unique-3-nopunct": 148,
        "entropy-3-nopunct": 7.215485357162528,
        "cond_entropy-3-nopunct": -0.04373227093764653,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.8187059720109415,
        "bleu": 44.80592,
        "rouge1": {
            "precision": 0.80538,
            "recall": 0.76654,
            "fmeasure": 0.77977
        },
        "rouge2": {
            "precision": 0.57521,
            "recall": 0.5529,
            "fmeasure": 0.55946
        },
        "rougeL": {
            "precision": 0.68282,
            "recall": 0.6452,
            "fmeasure": 0.65747
        },
        "rougeLsum": {
            "precision": 0.68282,
            "recall": 0.6452,
            "fmeasure": 0.65747
        },
        "local_recall": {
            "1": 0.3488372093023256,
            "2": 0.3684210526315789,
            "3": 0.7720588235294118
        },
        "bertscore": {
            "precision": 0.91873,
            "recall": 0.93314,
            "f1": 0.92332
        },
        "bleurt": 0.29995,
        "meteor": 0.4162445437793373,
        "nubia": {
            "semantic_relation": 4.4993,
            "contradiction": 3.16476,
            "irrelevancy": 26.07506,
            "logical_agreement": 70.76018,
            "grammar_ref": 4.3854,
            "grammar_hyp": 4.46416,
            "nubia_score": 0.7963
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_21": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 91,
        "msttr-100": 0.70357,
        "msttr-100_nopunct": 0.76583,
        "total_length": 1429,
        "mean_pred_length": 15.703296703296703,
        "std_pred_length": 6.797695966313048,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 48,
        "distinct-1": 0.4079776067179846,
        "vocab_size-1": 583,
        "unique-1": 454,
        "entropy-1": 7.732041607812364,
        "distinct-2": 0.7391629297458894,
        "vocab_size-2": 989,
        "unique-2": 875,
        "entropy-2": 9.558859093664795,
        "cond_entropy-2": 1.5690242647598192,
        "distinct-3": 0.8492381716118684,
        "vocab_size-3": 1059,
        "unique-3": 979,
        "entropy-3": 9.848778498065752,
        "cond_entropy-3": 0.2943369625189189,
        "total_length-nopunct": 1242,
        "mean_pred_length-nopunct": 13.648351648351648,
        "std_pred_length-nopunct": 5.958415650418877,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.463768115942029,
        "vocab_size-1-nopunct": 576,
        "unique-1-nopunct": 453,
        "entropy-1-nopunct": 7.9762496706419865,
        "distinct-2-nopunct": 0.7541268462206777,
        "vocab_size-2-nopunct": 868,
        "unique-2-nopunct": 774,
        "entropy-2-nopunct": 9.385946371033825,
        "cond_entropy-2-nopunct": 1.4996812390479124,
        "distinct-3-nopunct": 0.8575471698113207,
        "vocab_size-3-nopunct": 909,
        "unique-3-nopunct": 845,
        "entropy-3-nopunct": 9.639920087671708,
        "cond_entropy-3-nopunct": 0.28184313825507384,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.792376206256006,
        "bleu": 53.62322,
        "rouge1": {
            "precision": 0.80304,
            "recall": 0.75694,
            "fmeasure": 0.76856
        },
        "rouge2": {
            "precision": 0.59816,
            "recall": 0.5549,
            "fmeasure": 0.56768
        },
        "rougeL": {
            "precision": 0.71366,
            "recall": 0.67061,
            "fmeasure": 0.68174
        },
        "rougeLsum": {
            "precision": 0.71366,
            "recall": 0.67061,
            "fmeasure": 0.68174
        },
        "local_recall": {
            "1": 0.2882882882882883,
            "2": 0.45112781954887216,
            "3": 0.7846638655462185
        },
        "bertscore": {
            "precision": 0.93974,
            "recall": 0.92814,
            "f1": 0.9325
        },
        "bleurt": 0.34028,
        "meteor": 0.41980925355587684,
        "nubia": {
            "semantic_relation": 4.18718,
            "contradiction": 6.25397,
            "irrelevancy": 22.25618,
            "logical_agreement": 71.48985,
            "grammar_ref": 4.3909,
            "grammar_hyp": 4.36506,
            "nubia_score": 0.75206
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_99": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.78,
        "total_length": 257,
        "mean_pred_length": 18.357142857142858,
        "std_pred_length": 9.27059208200967,
        "median_pred_length": 15.5,
        "min_pred_length": 7,
        "max_pred_length": 42,
        "distinct-1": 0.6303501945525292,
        "vocab_size-1": 162,
        "unique-1": 135,
        "entropy-1": 6.760643648602439,
        "distinct-2": 0.9382716049382716,
        "vocab_size-2": 228,
        "unique-2": 214,
        "entropy-2": 7.798249180551593,
        "cond_entropy-2": 0.8899790451157495,
        "distinct-3": 0.982532751091703,
        "vocab_size-3": 225,
        "unique-3": 221,
        "entropy-3": 7.804269290280353,
        "cond_entropy-3": 0.013757605461309299,
        "total_length-nopunct": 220,
        "mean_pred_length-nopunct": 15.714285714285714,
        "std_pred_length-nopunct": 7.93210989251528,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.7045454545454546,
        "vocab_size-1-nopunct": 155,
        "unique-1-nopunct": 131,
        "entropy-1-nopunct": 6.894222194243098,
        "distinct-2-nopunct": 0.941747572815534,
        "vocab_size-2-nopunct": 194,
        "unique-2-nopunct": 183,
        "entropy-2-nopunct": 7.5663311703766,
        "cond_entropy-2-nopunct": 0.7149971449161209,
        "distinct-3-nopunct": 0.984375,
        "vocab_size-3-nopunct": 189,
        "unique-3-nopunct": 186,
        "entropy-3-nopunct": 7.553712500721178,
        "cond_entropy-3-nopunct": -0.012111333746216889,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.963320602875854,
        "bleu": 30.00984,
        "rouge1": {
            "precision": 0.71846,
            "recall": 0.66208,
            "fmeasure": 0.67206
        },
        "rouge2": {
            "precision": 0.44385,
            "recall": 0.41302,
            "fmeasure": 0.41396
        },
        "rougeL": {
            "precision": 0.62012,
            "recall": 0.57264,
            "fmeasure": 0.57922
        },
        "rougeLsum": {
            "precision": 0.62012,
            "recall": 0.57264,
            "fmeasure": 0.57922
        },
        "local_recall": {
            "1": 0.15254237288135594,
            "2": 0.21739130434782608,
            "3": 0.6727272727272727
        },
        "bertscore": {
            "precision": 0.8989,
            "recall": 0.89709,
            "f1": 0.89482
        },
        "bleurt": 0.08433,
        "meteor": 0.3281455682701348,
        "nubia": {
            "semantic_relation": 3.79605,
            "contradiction": 10.70196,
            "irrelevancy": 28.0179,
            "logical_agreement": 61.28014,
            "grammar_ref": 4.70274,
            "grammar_hyp": 4.5688,
            "nubia_score": 0.62668
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_152": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 24,
        "msttr-100": 0.72333,
        "msttr-100_nopunct": 0.76667,
        "total_length": 352,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 4.403281604540968,
        "median_pred_length": 14.5,
        "min_pred_length": 5,
        "max_pred_length": 25,
        "distinct-1": 0.6107954545454546,
        "vocab_size-1": 215,
        "unique-1": 184,
        "entropy-1": 7.008560691981154,
        "distinct-2": 0.9573170731707317,
        "vocab_size-2": 314,
        "unique-2": 304,
        "entropy-2": 8.258879663226018,
        "cond_entropy-2": 1.020995197532772,
        "distinct-3": 1.0,
        "vocab_size-3": 304,
        "unique-3": 304,
        "entropy-3": 8.247927513443585,
        "cond_entropy-3": -0.01880330540332433,
        "total_length-nopunct": 302,
        "mean_pred_length-nopunct": 12.583333333333334,
        "std_pred_length-nopunct": 3.6846151615723572,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6986754966887417,
        "vocab_size-1-nopunct": 211,
        "unique-1-nopunct": 184,
        "entropy-1-nopunct": 7.190904913999967,
        "distinct-2-nopunct": 0.9640287769784173,
        "vocab_size-2-nopunct": 268,
        "unique-2-nopunct": 261,
        "entropy-2-nopunct": 8.034014308426924,
        "cond_entropy-2-nopunct": 0.9155554225126517,
        "distinct-3-nopunct": 0.9960629921259843,
        "vocab_size-3-nopunct": 253,
        "unique-3-nopunct": 252,
        "entropy-3-nopunct": 7.980810671024097,
        "cond_entropy-3-nopunct": -0.045179061248834126,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.898399031001939,
        "bleu": 42.08064,
        "rouge1": {
            "precision": 0.79049,
            "recall": 0.72305,
            "fmeasure": 0.74472
        },
        "rouge2": {
            "precision": 0.54045,
            "recall": 0.49026,
            "fmeasure": 0.50761
        },
        "rougeL": {
            "precision": 0.72044,
            "recall": 0.65326,
            "fmeasure": 0.67475
        },
        "rougeLsum": {
            "precision": 0.72044,
            "recall": 0.65326,
            "fmeasure": 0.67475
        },
        "local_recall": {
            "1": 0.1276595744680851,
            "2": 0.313953488372093,
            "3": 0.7848101265822784
        },
        "bertscore": {
            "precision": 0.92938,
            "recall": 0.92544,
            "f1": 0.92585
        },
        "bleurt": 0.20891,
        "meteor": 0.384155327703506,
        "nubia": {
            "semantic_relation": 4.15335,
            "contradiction": 9.29349,
            "irrelevancy": 37.49357,
            "logical_agreement": 53.21294,
            "grammar_ref": 4.6818,
            "grammar_hyp": 4.795,
            "nubia_score": 0.70358
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_22": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.695,
        "total_length": 329,
        "mean_pred_length": 19.352941176470587,
        "std_pred_length": 11.029058817882174,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 53,
        "distinct-1": 0.5319148936170213,
        "vocab_size-1": 175,
        "unique-1": 133,
        "entropy-1": 6.6433938287834575,
        "distinct-2": 0.8589743589743589,
        "vocab_size-2": 268,
        "unique-2": 235,
        "entropy-2": 7.9519435649605805,
        "cond_entropy-2": 1.1749812234837798,
        "distinct-3": 0.9423728813559322,
        "vocab_size-3": 278,
        "unique-3": 262,
        "entropy-3": 8.08675796627572,
        "cond_entropy-3": 0.15403066272642732,
        "total_length-nopunct": 290,
        "mean_pred_length-nopunct": 17.058823529411764,
        "std_pred_length-nopunct": 9.364957135263818,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.5827586206896552,
        "vocab_size-1-nopunct": 169,
        "unique-1-nopunct": 132,
        "entropy-1-nopunct": 6.677098893979772,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 234,
        "unique-2-nopunct": 206,
        "entropy-2-nopunct": 7.748291573090853,
        "cond_entropy-2-nopunct": 1.148943027967203,
        "distinct-3-nopunct": 0.94921875,
        "vocab_size-3-nopunct": 243,
        "unique-3-nopunct": 231,
        "entropy-3-nopunct": 7.895488720694674,
        "cond_entropy-3-nopunct": 0.17007181421742984,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.243094148603303,
        "bleu": 57.09538,
        "rouge1": {
            "precision": 0.70425,
            "recall": 0.69342,
            "fmeasure": 0.68747
        },
        "rouge2": {
            "precision": 0.4698,
            "recall": 0.46331,
            "fmeasure": 0.46149
        },
        "rougeL": {
            "precision": 0.61861,
            "recall": 0.61748,
            "fmeasure": 0.6073
        },
        "rougeLsum": {
            "precision": 0.61861,
            "recall": 0.61748,
            "fmeasure": 0.6073
        },
        "local_recall": {
            "1": 0.13157894736842105,
            "2": 0.515625,
            "3": 0.8245614035087719
        },
        "bertscore": {
            "precision": 0.91717,
            "recall": 0.90825,
            "f1": 0.91148
        },
        "bleurt": 0.23019,
        "meteor": 0.4249052182682872,
        "nubia": {
            "semantic_relation": 4.03313,
            "contradiction": 10.68192,
            "irrelevancy": 22.42229,
            "logical_agreement": 66.8958,
            "grammar_ref": 4.31337,
            "grammar_hyp": 4.11823,
            "nubia_score": 0.70172
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_23": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.65,
        "msttr-100_nopunct": NaN,
        "total_length": 114,
        "mean_pred_length": 16.285714285714285,
        "std_pred_length": 7.38172039015075,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 32,
        "distinct-1": 0.6228070175438597,
        "vocab_size-1": 71,
        "unique-1": 53,
        "entropy-1": 5.780853528270914,
        "distinct-2": 0.8878504672897196,
        "vocab_size-2": 95,
        "unique-2": 86,
        "entropy-2": 6.4960028508264624,
        "cond_entropy-2": 0.6003154061710178,
        "distinct-3": 0.94,
        "vocab_size-3": 94,
        "unique-3": 89,
        "entropy-3": 6.516307314753104,
        "cond_entropy-3": 0.037486953416847095,
        "total_length-nopunct": 97,
        "mean_pred_length-nopunct": 13.857142857142858,
        "std_pred_length-nopunct": 6.957597521077669,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6804123711340206,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.7686840743202215,
        "distinct-2-nopunct": 0.8888888888888888,
        "vocab_size-2-nopunct": 80,
        "unique-2-nopunct": 73,
        "entropy-2-nopunct": 6.244467957368661,
        "cond_entropy-2-nopunct": 0.5228243149856481,
        "distinct-3-nopunct": 0.9397590361445783,
        "vocab_size-3-nopunct": 78,
        "unique-3-nopunct": 74,
        "entropy-3-nopunct": 6.24546247348954,
        "cond_entropy-3-nopunct": 0.002762389277560791,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.804204982165175,
        "bleu": 39.58611,
        "rouge1": {
            "precision": 0.79105,
            "recall": 0.7337,
            "fmeasure": 0.75526
        },
        "rouge2": {
            "precision": 0.56725,
            "recall": 0.50553,
            "fmeasure": 0.53053
        },
        "rougeL": {
            "precision": 0.65584,
            "recall": 0.60589,
            "fmeasure": 0.62576
        },
        "rougeLsum": {
            "precision": 0.65584,
            "recall": 0.60589,
            "fmeasure": 0.62576
        },
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.3076923076923077,
            "3": 0.7066666666666667
        },
        "bertscore": {
            "precision": 0.92768,
            "recall": 0.90879,
            "f1": 0.91485
        },
        "bleurt": 0.30095,
        "meteor": 0.3760476934998961,
        "nubia": {
            "semantic_relation": 4.21591,
            "contradiction": 0.23917,
            "irrelevancy": 29.01013,
            "logical_agreement": 70.7507,
            "grammar_ref": 4.51794,
            "grammar_hyp": 4.4958,
            "nubia_score": 0.77038
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_153": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.58,
        "msttr-100_nopunct": 0.61,
        "total_length": 145,
        "mean_pred_length": 13.181818181818182,
        "std_pred_length": 2.0368505911280073,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 17,
        "distinct-1": 0.593103448275862,
        "vocab_size-1": 86,
        "unique-1": 64,
        "entropy-1": 5.9921034809822835,
        "distinct-2": 0.8432835820895522,
        "vocab_size-2": 113,
        "unique-2": 96,
        "entropy-2": 6.73012239934842,
        "cond_entropy-2": 0.5515421563836695,
        "distinct-3": 0.8943089430894309,
        "vocab_size-3": 110,
        "unique-3": 98,
        "entropy-3": 6.7249950947525345,
        "cond_entropy-3": 0.008658343389519346,
        "total_length-nopunct": 131,
        "mean_pred_length-nopunct": 11.909090909090908,
        "std_pred_length-nopunct": 2.151301739308951,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.6259541984732825,
        "vocab_size-1-nopunct": 82,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 6.0091629595166465,
        "distinct-2-nopunct": 0.8333333333333334,
        "vocab_size-2-nopunct": 100,
        "unique-2-nopunct": 84,
        "entropy-2-nopunct": 6.548394345536415,
        "cond_entropy-2-nopunct": 0.598372514859645,
        "distinct-3-nopunct": 0.8807339449541285,
        "vocab_size-3-nopunct": 96,
        "unique-3-nopunct": 84,
        "entropy-3-nopunct": 6.522726641270829,
        "cond_entropy-3-nopunct": 0.0013365044573105094,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.932257913651882,
        "bleu": 41.04782,
        "rouge1": {
            "precision": 0.68769,
            "recall": 0.70571,
            "fmeasure": 0.68798
        },
        "rouge2": {
            "precision": 0.50341,
            "recall": 0.4965,
            "fmeasure": 0.49092
        },
        "rougeL": {
            "precision": 0.61589,
            "recall": 0.62106,
            "fmeasure": 0.60902
        },
        "rougeLsum": {
            "precision": 0.61589,
            "recall": 0.62106,
            "fmeasure": 0.60902
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.3103448275862069,
            "3": 0.7634408602150538
        },
        "bertscore": {
            "precision": 0.91472,
            "recall": 0.91949,
            "f1": 0.91467
        },
        "bleurt": 0.29282,
        "meteor": 0.3888805448081665,
        "nubia": {
            "semantic_relation": 4.14945,
            "contradiction": 11.93294,
            "irrelevancy": 49.65695,
            "logical_agreement": 38.41011,
            "grammar_ref": 5.00152,
            "grammar_hyp": 4.73985,
            "nubia_score": 0.7147
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_126": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 57,
        "msttr-100": 0.73556,
        "msttr-100_nopunct": 0.7675,
        "total_length": 913,
        "mean_pred_length": 16.017543859649123,
        "std_pred_length": 5.756738928436967,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.5125958378970427,
        "vocab_size-1": 468,
        "unique-1": 372,
        "entropy-1": 7.7693859364412505,
        "distinct-2": 0.8738317757009346,
        "vocab_size-2": 748,
        "unique-2": 685,
        "entropy-2": 9.422416925188388,
        "cond_entropy-2": 1.4021374381215101,
        "distinct-3": 0.951188986232791,
        "vocab_size-3": 760,
        "unique-3": 731,
        "entropy-3": 9.533754665377304,
        "cond_entropy-3": 0.1096807670785661,
        "total_length-nopunct": 810,
        "mean_pred_length-nopunct": 14.210526315789474,
        "std_pred_length-nopunct": 5.34670530492644,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5691358024691358,
        "vocab_size-1-nopunct": 461,
        "unique-1-nopunct": 369,
        "entropy-1-nopunct": 7.955028108919958,
        "distinct-2-nopunct": 0.8764940239043825,
        "vocab_size-2-nopunct": 660,
        "unique-2-nopunct": 607,
        "entropy-2-nopunct": 9.23931855149575,
        "cond_entropy-2-nopunct": 1.3688739786947068,
        "distinct-3-nopunct": 0.9511494252873564,
        "vocab_size-3-nopunct": 662,
        "unique-3-nopunct": 638,
        "entropy-3-nopunct": 9.33298756910603,
        "cond_entropy-3-nopunct": 0.10874764574282446,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.085705536196571,
        "bleu": 45.95309,
        "rouge1": {
            "precision": 0.78382,
            "recall": 0.74944,
            "fmeasure": 0.75481
        },
        "rouge2": {
            "precision": 0.5591,
            "recall": 0.54294,
            "fmeasure": 0.54314
        },
        "rougeL": {
            "precision": 0.65659,
            "recall": 0.63303,
            "fmeasure": 0.63596
        },
        "rougeLsum": {
            "precision": 0.65659,
            "recall": 0.63303,
            "fmeasure": 0.63596
        },
        "local_recall": {
            "1": 0.17972350230414746,
            "2": 0.5365853658536586,
            "3": 0.7988614800759013
        },
        "bertscore": {
            "precision": 0.92429,
            "recall": 0.92371,
            "f1": 0.92223
        },
        "bleurt": 0.21795,
        "meteor": 0.4012212769966796,
        "nubia": {
            "semantic_relation": 4.1689,
            "contradiction": 12.16899,
            "irrelevancy": 29.54431,
            "logical_agreement": 58.2867,
            "grammar_ref": 4.80748,
            "grammar_hyp": 4.81936,
            "nubia_score": 0.71228
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_127": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.7887305126316566,
        "bleu": 15.7278,
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.55556,
            "fmeasure": 0.52632
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.86901,
            "recall": 0.88984,
            "f1": 0.8793
        },
        "bleurt": -0.23503,
        "meteor": 0.32566666763832175,
        "nubia": {
            "semantic_relation": 3.86956,
            "contradiction": 0.38653,
            "irrelevancy": 97.71758,
            "logical_agreement": 1.8959,
            "grammar_ref": 6.33221,
            "grammar_hyp": 6.2266,
            "nubia_score": 0.5218
        }
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 1322,
        "msttr-100": 0.52476,
        "msttr-100_nopunct": 0.53871,
        "total_length": 30702,
        "mean_pred_length": 23.223903177004537,
        "std_pred_length": 12.219244161636981,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 66,
        "distinct-1": 0.06214578854797733,
        "vocab_size-1": 1908,
        "unique-1": 680,
        "entropy-1": 7.916095649562536,
        "distinct-2": 0.21626957113682777,
        "vocab_size-2": 6354,
        "unique-2": 3125,
        "entropy-2": 11.244577841701794,
        "cond_entropy-2": 3.1514935648538867,
        "distinct-3": 0.3878038349133937,
        "vocab_size-3": 10881,
        "unique-3": 6764,
        "entropy-3": 12.518660332916035,
        "cond_entropy-3": 1.3339517268678438,
        "total_length-nopunct": 27166,
        "mean_pred_length-nopunct": 20.549167927382754,
        "std_pred_length-nopunct": 11.033688753420254,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 60,
        "distinct-1-nopunct": 0.06986674519620113,
        "vocab_size-1-nopunct": 1898,
        "unique-1-nopunct": 679,
        "entropy-1-nopunct": 8.189755777541686,
        "distinct-2-nopunct": 0.23169787958520352,
        "vocab_size-2-nopunct": 5988,
        "unique-2-nopunct": 3124,
        "entropy-2-nopunct": 11.158057595294201,
        "cond_entropy-2-nopunct": 3.1212380347780893,
        "distinct-3-nopunct": 0.4059212136041106,
        "vocab_size-3-nopunct": 9954,
        "unique-3-nopunct": 6409,
        "entropy-3-nopunct": 12.389654098065494,
        "cond_entropy-3-nopunct": 1.2920739581948741,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.355871996857053,
        "bleu": 36.3186,
        "rouge1": {
            "precision": 0.67111,
            "recall": 0.68709,
            "fmeasure": 0.67237
        },
        "rouge2": {
            "precision": 0.40811,
            "recall": 0.41744,
            "fmeasure": 0.40833
        },
        "rougeL": {
            "precision": 0.53983,
            "recall": 0.55434,
            "fmeasure": 0.54115
        },
        "rougeLsum": {
            "precision": 0.53983,
            "recall": 0.55434,
            "fmeasure": 0.54115
        },
        "local_recall": {
            "1": 0.2240751714213155,
            "2": 0.5390021082220661,
            "3": 0.7557337730475191,
            "4": 0.9019607843137255,
            "5": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.89376,
            "recall": 0.8984,
            "f1": 0.89489
        },
        "bleurt": -0.03162,
        "meteor": 0.33130524274177997,
        "nubia": {
            "semantic_relation": 3.94556,
            "contradiction": 27.56939,
            "irrelevancy": 9.89197,
            "logical_agreement": 62.53864,
            "grammar_ref": 4.6229,
            "grammar_hyp": 4.75416,
            "nubia_score": 0.64272
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_128": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.72667,
        "msttr-100_nopunct": 0.77,
        "total_length": 300,
        "mean_pred_length": 15.0,
        "std_pred_length": 4.39317652729776,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.61,
        "vocab_size-1": 183,
        "unique-1": 150,
        "entropy-1": 6.846963556129233,
        "distinct-2": 0.9392857142857143,
        "vocab_size-2": 263,
        "unique-2": 250,
        "entropy-2": 7.988176677643812,
        "cond_entropy-2": 0.9261801009137424,
        "distinct-3": 0.9807692307692307,
        "vocab_size-3": 255,
        "unique-3": 250,
        "entropy-3": 7.983906274566915,
        "cond_entropy-3": -0.0011083769767932133,
        "total_length-nopunct": 258,
        "mean_pred_length-nopunct": 12.9,
        "std_pred_length-nopunct": 4.264973622427224,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.689922480620155,
        "vocab_size-1-nopunct": 178,
        "unique-1-nopunct": 150,
        "entropy-1-nopunct": 6.979195756870359,
        "distinct-2-nopunct": 0.9453781512605042,
        "vocab_size-2-nopunct": 225,
        "unique-2-nopunct": 216,
        "entropy-2-nopunct": 7.762423750684762,
        "cond_entropy-2-nopunct": 0.85314660713811,
        "distinct-3-nopunct": 0.9908256880733946,
        "vocab_size-3-nopunct": 216,
        "unique-3-nopunct": 214,
        "entropy-3-nopunct": 7.749835700923704,
        "cond_entropy-3-nopunct": -0.005028966034104902,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.88640083808093,
        "bleu": 47.76479,
        "rouge1": {
            "precision": 0.74268,
            "recall": 0.71963,
            "fmeasure": 0.72028
        },
        "rouge2": {
            "precision": 0.53446,
            "recall": 0.50112,
            "fmeasure": 0.51084
        },
        "rougeL": {
            "precision": 0.63951,
            "recall": 0.61282,
            "fmeasure": 0.61812
        },
        "rougeLsum": {
            "precision": 0.63951,
            "recall": 0.61282,
            "fmeasure": 0.61812
        },
        "local_recall": {
            "1": 0.24,
            "2": 0.4426229508196721,
            "3": 0.7591623036649214
        },
        "bertscore": {
            "precision": 0.92494,
            "recall": 0.92081,
            "f1": 0.92112
        },
        "bleurt": 0.33595,
        "meteor": 0.39275563132952435,
        "nubia": {
            "semantic_relation": 4.11138,
            "contradiction": 15.79746,
            "irrelevancy": 21.94101,
            "logical_agreement": 62.26153,
            "grammar_ref": 4.72495,
            "grammar_hyp": 4.64549,
            "nubia_score": 0.71077
        }
    },
    "web_nlg_en_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 1177,
        "msttr-100": 0.60941,
        "msttr-100_nopunct": 0.6442,
        "total_length": 28905,
        "mean_pred_length": 24.55819881053526,
        "std_pred_length": 11.952975811086686,
        "median_pred_length": 23.0,
        "min_pred_length": 5,
        "max_pred_length": 66,
        "distinct-1": 0.05884795018162948,
        "vocab_size-1": 1701,
        "unique-1": 600,
        "entropy-1": 7.6616398246233395,
        "distinct-2": 0.2150533756491633,
        "vocab_size-2": 5963,
        "unique-2": 3077,
        "entropy-2": 11.037520099471273,
        "cond_entropy-2": 3.2223637955009323,
        "distinct-3": 0.3982524198711913,
        "vocab_size-3": 10574,
        "unique-3": 6798,
        "entropy-3": 12.429670017130839,
        "cond_entropy-3": 1.4558449824089654,
        "total_length-nopunct": 25586,
        "mean_pred_length-nopunct": 21.738317757009344,
        "std_pred_length-nopunct": 10.802207280543442,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 60,
        "distinct-1-nopunct": 0.06612991479715469,
        "vocab_size-1-nopunct": 1692,
        "unique-1-nopunct": 598,
        "entropy-1-nopunct": 7.900664643307045,
        "distinct-2-nopunct": 0.2327420213855545,
        "vocab_size-2-nopunct": 5681,
        "unique-2-nopunct": 3123,
        "entropy-2-nopunct": 10.958901472710485,
        "cond_entropy-2-nopunct": 3.2111071694408375,
        "distinct-3-nopunct": 0.41864669421487605,
        "vocab_size-3-nopunct": 9726,
        "unique-3-nopunct": 6500,
        "entropy-3-nopunct": 12.306318589042027,
        "cond_entropy-3-nopunct": 1.4120700301695013,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.2374452394607465,
        "bleu": 26.84532,
        "rouge1": {
            "precision": 0.61428,
            "recall": 0.64005,
            "fmeasure": 0.61996
        },
        "rouge2": {
            "precision": 0.33286,
            "recall": 0.3485,
            "fmeasure": 0.33627
        },
        "rougeL": {
            "precision": 0.48042,
            "recall": 0.50261,
            "fmeasure": 0.48533
        },
        "rougeLsum": {
            "precision": 0.48042,
            "recall": 0.50261,
            "fmeasure": 0.48533
        },
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.5066422354557948,
            "3": 0.6944007939789927,
            "4": 0.3,
            "5": 0.7241379310344828
        },
        "bertscore": {
            "precision": 0.87382,
            "recall": 0.88068,
            "f1": 0.87597
        },
        "bleurt": -0.19849,
        "meteor": 0.29358353186561537,
        "nubia": {
            "semantic_relation": 3.68892,
            "contradiction": 34.92659,
            "irrelevancy": 12.3086,
            "logical_agreement": 52.76481,
            "grammar_ref": 4.6454,
            "grammar_hyp": 4.80939,
            "nubia_score": 0.56392
        }
    },
    "web_nlg_en_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 56,
        "msttr-100": 0.58,
        "msttr-100_nopunct": 0.612,
        "total_length": 673,
        "mean_pred_length": 12.017857142857142,
        "std_pred_length": 5.197839769106596,
        "median_pred_length": 10.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.3060921248142645,
        "vocab_size-1": 206,
        "unique-1": 126,
        "entropy-1": 6.223476929203275,
        "distinct-2": 0.6207455429497569,
        "vocab_size-2": 383,
        "unique-2": 279,
        "entropy-2": 8.216586288992032,
        "cond_entropy-2": 1.7492329694089652,
        "distinct-3": 0.7825311942959001,
        "vocab_size-3": 439,
        "unique-3": 366,
        "entropy-3": 8.596388199486887,
        "cond_entropy-3": 0.39487912688241755,
        "total_length-nopunct": 589,
        "mean_pred_length-nopunct": 10.517857142857142,
        "std_pred_length-nopunct": 4.697989963152066,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.34125636672325976,
        "vocab_size-1-nopunct": 201,
        "unique-1-nopunct": 125,
        "entropy-1-nopunct": 6.3191495343174,
        "distinct-2-nopunct": 0.6210131332082551,
        "vocab_size-2-nopunct": 331,
        "unique-2-nopunct": 240,
        "entropy-2-nopunct": 8.002787778542618,
        "cond_entropy-2-nopunct": 1.8354865090298056,
        "distinct-3-nopunct": 0.779874213836478,
        "vocab_size-3-nopunct": 372,
        "unique-3-nopunct": 308,
        "entropy-3-nopunct": 8.35510289838481,
        "cond_entropy-3-nopunct": 0.37983406201999687,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.008035473343651,
        "bleu": 38.50959,
        "rouge1": {
            "precision": 0.72558,
            "recall": 0.72962,
            "fmeasure": 0.71951
        },
        "rouge2": {
            "precision": 0.46345,
            "recall": 0.47336,
            "fmeasure": 0.46288
        },
        "rougeL": {
            "precision": 0.59463,
            "recall": 0.59893,
            "fmeasure": 0.58987
        },
        "rougeLsum": {
            "precision": 0.59463,
            "recall": 0.59893,
            "fmeasure": 0.58987
        },
        "local_recall": {
            "1": 0.2398843930635838,
            "2": 0.578125,
            "3": 0.7898550724637681
        },
        "bertscore": {
            "precision": 0.91727,
            "recall": 0.91868,
            "f1": 0.91697
        },
        "bleurt": 0.13618,
        "meteor": 0.3791118776428477,
        "nubia": {
            "semantic_relation": 4.2919,
            "contradiction": 8.20631,
            "irrelevancy": 5.11011,
            "logical_agreement": 86.68358,
            "grammar_ref": 5.25554,
            "grammar_hyp": 5.29436,
            "nubia_score": 0.73469
        }
    },
    "web_nlg_en_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 28,
        "msttr-100": 0.53667,
        "msttr-100_nopunct": 0.555,
        "total_length": 300,
        "mean_pred_length": 10.714285714285714,
        "std_pred_length": 3.759342104840219,
        "median_pred_length": 10.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.38666666666666666,
        "vocab_size-1": 116,
        "unique-1": 78,
        "entropy-1": 5.750098356686097,
        "distinct-2": 0.7352941176470589,
        "vocab_size-2": 200,
        "unique-2": 159,
        "entropy-2": 7.433002295410841,
        "cond_entropy-2": 1.4431915546404206,
        "distinct-3": 0.8524590163934426,
        "vocab_size-3": 208,
        "unique-3": 183,
        "entropy-3": 7.590083995436775,
        "cond_entropy-3": 0.20449976470360298,
        "total_length-nopunct": 266,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 3.267808352485107,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.42105263157894735,
        "vocab_size-1-nopunct": 112,
        "unique-1-nopunct": 76,
        "entropy-1-nopunct": 5.7958457350300545,
        "distinct-2-nopunct": 0.7016806722689075,
        "vocab_size-2-nopunct": 167,
        "unique-2-nopunct": 126,
        "entropy-2-nopunct": 7.158438011349223,
        "cond_entropy-2-nopunct": 1.550711496978244,
        "distinct-3-nopunct": 0.819047619047619,
        "vocab_size-3-nopunct": 172,
        "unique-3-nopunct": 145,
        "entropy-3-nopunct": 7.299391158243427,
        "cond_entropy-3-nopunct": 0.20499461381520437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.524884151427184,
        "bleu": 52.84059,
        "rouge1": {
            "precision": 0.78259,
            "recall": 0.76951,
            "fmeasure": 0.76959
        },
        "rouge2": {
            "precision": 0.5629,
            "recall": 0.56287,
            "fmeasure": 0.55647
        },
        "rougeL": {
            "precision": 0.69079,
            "recall": 0.6837,
            "fmeasure": 0.68104
        },
        "rougeLsum": {
            "precision": 0.69079,
            "recall": 0.6837,
            "fmeasure": 0.68104
        },
        "local_recall": {
            "1": 0.1360544217687075,
            "2": 0.6170212765957447,
            "3": 0.8814814814814815,
            "4": 1.0
        },
        "bertscore": {
            "precision": 0.9322,
            "recall": 0.92915,
            "f1": 0.92944
        },
        "bleurt": 0.35641,
        "meteor": 0.4134784285344096,
        "nubia": {
            "semantic_relation": 4.19329,
            "contradiction": 23.62017,
            "irrelevancy": 4.52797,
            "logical_agreement": 71.85186,
            "grammar_ref": 4.67502,
            "grammar_hyp": 4.97478,
            "nubia_score": 0.686
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_130": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.72333,
        "msttr-100_nopunct": 0.78,
        "total_length": 602,
        "mean_pred_length": 19.419354838709676,
        "std_pred_length": 7.827883138018643,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 40,
        "distinct-1": 0.5498338870431894,
        "vocab_size-1": 331,
        "unique-1": 255,
        "entropy-1": 7.574122760391973,
        "distinct-2": 0.8774080560420315,
        "vocab_size-2": 501,
        "unique-2": 453,
        "entropy-2": 8.872927271625692,
        "cond_entropy-2": 1.1199329154113018,
        "distinct-3": 0.9592592592592593,
        "vocab_size-3": 518,
        "unique-3": 500,
        "entropy-3": 8.988834532227946,
        "cond_entropy-3": 0.11602230147950289,
        "total_length-nopunct": 517,
        "mean_pred_length-nopunct": 16.677419354838708,
        "std_pred_length-nopunct": 7.04083525458493,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.6286266924564797,
        "vocab_size-1-nopunct": 325,
        "unique-1-nopunct": 255,
        "entropy-1-nopunct": 7.781683662288525,
        "distinct-2-nopunct": 0.8888888888888888,
        "vocab_size-2-nopunct": 432,
        "unique-2-nopunct": 395,
        "entropy-2-nopunct": 8.664258613722888,
        "cond_entropy-2-nopunct": 0.9316749330103934,
        "distinct-3-nopunct": 0.967032967032967,
        "vocab_size-3-nopunct": 440,
        "unique-3-nopunct": 428,
        "entropy-3-nopunct": 8.757733971345045,
        "cond_entropy-3-nopunct": 0.09804056770209653,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.149677880688824,
        "bleu": 52.40263,
        "rouge1": {
            "precision": 0.83746,
            "recall": 0.74606,
            "fmeasure": 0.77977
        },
        "rouge2": {
            "precision": 0.61339,
            "recall": 0.56554,
            "fmeasure": 0.58345
        },
        "rougeL": {
            "precision": 0.73872,
            "recall": 0.66176,
            "fmeasure": 0.68928
        },
        "rougeLsum": {
            "precision": 0.73872,
            "recall": 0.66176,
            "fmeasure": 0.68928
        },
        "local_recall": {
            "1": 0.2897196261682243,
            "2": 0.31645569620253167,
            "3": 0.7878787878787878
        },
        "bertscore": {
            "precision": 0.93847,
            "recall": 0.9282,
            "f1": 0.93194
        },
        "bleurt": 0.28655,
        "meteor": 0.4153231472307389,
        "nubia": {
            "semantic_relation": 4.31802,
            "contradiction": 4.07582,
            "irrelevancy": 17.44169,
            "logical_agreement": 78.4825,
            "grammar_ref": 4.57329,
            "grammar_hyp": 4.73114,
            "nubia_score": 0.75653
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_182": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.745,
        "total_length": 234,
        "mean_pred_length": 16.714285714285715,
        "std_pred_length": 5.364280958719597,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.6282051282051282,
        "vocab_size-1": 147,
        "unique-1": 118,
        "entropy-1": 6.677340644134651,
        "distinct-2": 0.9363636363636364,
        "vocab_size-2": 206,
        "unique-2": 196,
        "entropy-2": 7.638133463504977,
        "cond_entropy-2": 0.7944263109497721,
        "distinct-3": 0.9951456310679612,
        "vocab_size-3": 205,
        "unique-3": 204,
        "entropy-3": 7.67679178931914,
        "cond_entropy-3": 0.028974672902864398,
        "total_length-nopunct": 206,
        "mean_pred_length-nopunct": 14.714285714285714,
        "std_pred_length-nopunct": 4.7423407636279515,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6941747572815534,
        "vocab_size-1-nopunct": 143,
        "unique-1-nopunct": 118,
        "entropy-1-nopunct": 6.752738926494513,
        "distinct-2-nopunct": 0.953125,
        "vocab_size-2-nopunct": 183,
        "unique-2-nopunct": 177,
        "entropy-2-nopunct": 7.476864128314077,
        "cond_entropy-2-nopunct": 0.7509369200801483,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 178,
        "unique-3-nopunct": 178,
        "entropy-3-nopunct": 7.47573343096637,
        "cond_entropy-3-nopunct": -0.010437145593403526,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.747103229427379,
        "bleu": 44.33541,
        "rouge1": {
            "precision": 0.75764,
            "recall": 0.75419,
            "fmeasure": 0.74912
        },
        "rouge2": {
            "precision": 0.51847,
            "recall": 0.52281,
            "fmeasure": 0.5133
        },
        "rougeL": {
            "precision": 0.61606,
            "recall": 0.61278,
            "fmeasure": 0.6082
        },
        "rougeLsum": {
            "precision": 0.61606,
            "recall": 0.61278,
            "fmeasure": 0.6082
        },
        "local_recall": {
            "1": 0.14754098360655737,
            "2": 0.45714285714285713,
            "3": 0.7358490566037735
        },
        "bertscore": {
            "precision": 0.91932,
            "recall": 0.91743,
            "f1": 0.91701
        },
        "bleurt": 0.26578,
        "meteor": 0.4017248994426701,
        "nubia": {
            "semantic_relation": 4.24656,
            "contradiction": 3.13645,
            "irrelevancy": 35.23276,
            "logical_agreement": 61.63079,
            "grammar_ref": 4.54419,
            "grammar_hyp": 4.28601,
            "nubia_score": 0.77932
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_100": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 48,
        "msttr-100": 0.70571,
        "msttr-100_nopunct": 0.76333,
        "total_length": 775,
        "mean_pred_length": 16.145833333333332,
        "std_pred_length": 6.639495410462722,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 38,
        "distinct-1": 0.5277419354838709,
        "vocab_size-1": 409,
        "unique-1": 333,
        "entropy-1": 7.573198792601197,
        "distinct-2": 0.8858321870701513,
        "vocab_size-2": 644,
        "unique-2": 592,
        "entropy-2": 9.217609293296782,
        "cond_entropy-2": 1.409355174599845,
        "distinct-3": 0.9646539027982327,
        "vocab_size-3": 655,
        "unique-3": 634,
        "entropy-3": 9.332518298114833,
        "cond_entropy-3": 0.10949506299992517,
        "total_length-nopunct": 668,
        "mean_pred_length-nopunct": 13.916666666666666,
        "std_pred_length-nopunct": 5.641488180337603,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.6047904191616766,
        "vocab_size-1-nopunct": 404,
        "unique-1-nopunct": 332,
        "entropy-1-nopunct": 7.828377005553727,
        "distinct-2-nopunct": 0.8983870967741936,
        "vocab_size-2-nopunct": 557,
        "unique-2-nopunct": 519,
        "entropy-2-nopunct": 9.014812681938206,
        "cond_entropy-2-nopunct": 1.2730984139143673,
        "distinct-3-nopunct": 0.9755244755244755,
        "vocab_size-3-nopunct": 558,
        "unique-3-nopunct": 545,
        "entropy-3-nopunct": 9.109600554432003,
        "cond_entropy-3-nopunct": 0.10972312200446925,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.09078668591218,
        "bleu": 44.66672,
        "rouge1": {
            "precision": 0.7948,
            "recall": 0.74993,
            "fmeasure": 0.76131
        },
        "rouge2": {
            "precision": 0.54381,
            "recall": 0.5208,
            "fmeasure": 0.52436
        },
        "rougeL": {
            "precision": 0.65649,
            "recall": 0.61342,
            "fmeasure": 0.62532
        },
        "rougeLsum": {
            "precision": 0.65649,
            "recall": 0.61342,
            "fmeasure": 0.62532
        },
        "local_recall": {
            "1": 0.18791946308724833,
            "2": 0.375,
            "3": 0.80990099009901
        },
        "bertscore": {
            "precision": 0.93032,
            "recall": 0.92806,
            "f1": 0.92787
        },
        "bleurt": 0.29834,
        "meteor": 0.3958943271636011,
        "nubia": {
            "semantic_relation": 4.30684,
            "contradiction": 5.40416,
            "irrelevancy": 23.38079,
            "logical_agreement": 71.21505,
            "grammar_ref": 4.77611,
            "grammar_hyp": 4.87594,
            "nubia_score": 0.7579
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_183": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.7047785513541205,
        "bleu": 12.38076,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.625,
            "fmeasure": 0.76923
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.21429,
            "fmeasure": 0.28283
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.4213,
            "fmeasure": 0.5348
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.4213,
            "fmeasure": 0.5348
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.899,
            "recall": 0.88936,
            "f1": 0.89416
        },
        "bleurt": 0.08634,
        "meteor": 0.23499115295166703,
        "nubia": {
            "semantic_relation": 4.72339,
            "contradiction": 0.52718,
            "irrelevancy": 0.66594,
            "logical_agreement": 98.80688,
            "grammar_ref": 4.0172,
            "grammar_hyp": 4.735,
            "nubia_score": 0.93648
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_184": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.71667,
        "msttr-100_nopunct": 0.725,
        "total_length": 334,
        "mean_pred_length": 18.555555555555557,
        "std_pred_length": 9.610308251630538,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 52,
        "distinct-1": 0.5718562874251497,
        "vocab_size-1": 191,
        "unique-1": 156,
        "entropy-1": 6.820570651242104,
        "distinct-2": 0.8829113924050633,
        "vocab_size-2": 279,
        "unique-2": 256,
        "entropy-2": 8.020919741894675,
        "cond_entropy-2": 1.0474177941341352,
        "distinct-3": 0.9563758389261745,
        "vocab_size-3": 285,
        "unique-3": 275,
        "entropy-3": 8.122675609381046,
        "cond_entropy-3": 0.11213002222831595,
        "total_length-nopunct": 282,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 6.2182527020592095,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.6524822695035462,
        "vocab_size-1-nopunct": 184,
        "unique-1-nopunct": 154,
        "entropy-1-nopunct": 6.911383994458982,
        "distinct-2-nopunct": 0.8901515151515151,
        "vocab_size-2-nopunct": 235,
        "unique-2-nopunct": 218,
        "entropy-2-nopunct": 7.773999884565833,
        "cond_entropy-2-nopunct": 0.9305594031427579,
        "distinct-3-nopunct": 0.9552845528455285,
        "vocab_size-3-nopunct": 235,
        "unique-3-nopunct": 227,
        "entropy-3-nopunct": 7.841884881346743,
        "cond_entropy-3-nopunct": 0.08360490013969148,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.485881388168641,
        "bleu": 54.17957,
        "rouge1": {
            "precision": 0.77674,
            "recall": 0.75653,
            "fmeasure": 0.75823
        },
        "rouge2": {
            "precision": 0.57002,
            "recall": 0.55695,
            "fmeasure": 0.5556
        },
        "rougeL": {
            "precision": 0.71143,
            "recall": 0.68859,
            "fmeasure": 0.69225
        },
        "rougeLsum": {
            "precision": 0.71143,
            "recall": 0.68859,
            "fmeasure": 0.69225
        },
        "local_recall": {
            "1": 0.30303030303030304,
            "2": 0.20588235294117646,
            "3": 0.8078602620087336
        },
        "bertscore": {
            "precision": 0.93753,
            "recall": 0.93635,
            "f1": 0.93626
        },
        "bleurt": 0.35873,
        "meteor": 0.4252502565194597,
        "nubia": {
            "semantic_relation": 4.33834,
            "contradiction": 0.53851,
            "irrelevancy": 34.65565,
            "logical_agreement": 64.80584,
            "grammar_ref": 4.5077,
            "grammar_hyp": 4.43891,
            "nubia_score": 0.78394
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_185": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.77,
        "total_length": 128,
        "mean_pred_length": 16.0,
        "std_pred_length": 6.34428877022476,
        "median_pred_length": 13.5,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.65625,
        "vocab_size-1": 84,
        "unique-1": 67,
        "entropy-1": 6.013453664259099,
        "distinct-2": 0.95,
        "vocab_size-2": 114,
        "unique-2": 108,
        "entropy-2": 6.806890595608534,
        "cond_entropy-2": 0.6592066870654792,
        "distinct-3": 0.9910714285714286,
        "vocab_size-3": 111,
        "unique-3": 110,
        "entropy-3": 6.789497779200448,
        "cond_entropy-3": -0.01024995926520012,
        "total_length-nopunct": 105,
        "mean_pred_length-nopunct": 13.125,
        "std_pred_length-nopunct": 4.075460096725276,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7619047619047619,
        "vocab_size-1-nopunct": 80,
        "unique-1-nopunct": 67,
        "entropy-1-nopunct": 6.102447127594425,
        "distinct-2-nopunct": 0.9484536082474226,
        "vocab_size-2-nopunct": 92,
        "unique-2-nopunct": 87,
        "entropy-2-nopunct": 6.496820058681988,
        "cond_entropy-2-nopunct": 0.4242119735676797,
        "distinct-3-nopunct": 0.9887640449438202,
        "vocab_size-3-nopunct": 88,
        "unique-3-nopunct": 87,
        "entropy-3-nopunct": 6.453261520854051,
        "cond_entropy-3-nopunct": -0.056763680883651337,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.345675047758882,
        "bleu": 37.04592,
        "rouge1": {
            "precision": 0.72189,
            "recall": 0.73601,
            "fmeasure": 0.71386
        },
        "rouge2": {
            "precision": 0.49275,
            "recall": 0.51849,
            "fmeasure": 0.4905
        },
        "rougeL": {
            "precision": 0.5921,
            "recall": 0.60414,
            "fmeasure": 0.58579
        },
        "rougeLsum": {
            "precision": 0.5921,
            "recall": 0.60414,
            "fmeasure": 0.58579
        },
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.3,
            "3": 0.7738095238095238
        },
        "bertscore": {
            "precision": 0.91836,
            "recall": 0.92071,
            "f1": 0.91856
        },
        "bleurt": 0.26834,
        "meteor": 0.40124675171056023,
        "nubia": {
            "semantic_relation": 3.90254,
            "contradiction": 33.84534,
            "irrelevancy": 10.82454,
            "logical_agreement": 55.33012,
            "grammar_ref": 5.14697,
            "grammar_hyp": 4.86897,
            "nubia_score": 0.64682
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_132": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 43,
        "msttr-100": 0.70167,
        "msttr-100_nopunct": 0.752,
        "total_length": 681,
        "mean_pred_length": 15.837209302325581,
        "std_pred_length": 4.8557337603642745,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.5168869309838473,
        "vocab_size-1": 352,
        "unique-1": 275,
        "entropy-1": 7.406238219430804,
        "distinct-2": 0.8949843260188087,
        "vocab_size-2": 571,
        "unique-2": 527,
        "entropy-2": 9.04926620871845,
        "cond_entropy-2": 1.4102241796443957,
        "distinct-3": 0.9697478991596639,
        "vocab_size-3": 577,
        "unique-3": 559,
        "entropy-3": 9.156241656514629,
        "cond_entropy-3": 0.109547372866779,
        "total_length-nopunct": 596,
        "mean_pred_length-nopunct": 13.86046511627907,
        "std_pred_length-nopunct": 4.572828727862495,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5822147651006712,
        "vocab_size-1-nopunct": 347,
        "unique-1-nopunct": 274,
        "entropy-1-nopunct": 7.596120426222996,
        "distinct-2-nopunct": 0.9023508137432188,
        "vocab_size-2-nopunct": 499,
        "unique-2-nopunct": 466,
        "entropy-2-nopunct": 8.852406183038223,
        "cond_entropy-2-nopunct": 1.354000369021606,
        "distinct-3-nopunct": 0.9745098039215686,
        "vocab_size-3-nopunct": 497,
        "unique-3-nopunct": 484,
        "entropy-3-nopunct": 8.943373044701884,
        "cond_entropy-3-nopunct": 0.10575197038670442,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.562249914421767,
        "bleu": 52.28313,
        "rouge1": {
            "precision": 0.84192,
            "recall": 0.76663,
            "fmeasure": 0.79443
        },
        "rouge2": {
            "precision": 0.62223,
            "recall": 0.5648,
            "fmeasure": 0.58604
        },
        "rougeL": {
            "precision": 0.73222,
            "recall": 0.6737,
            "fmeasure": 0.69505
        },
        "rougeLsum": {
            "precision": 0.73222,
            "recall": 0.6737,
            "fmeasure": 0.69505
        },
        "local_recall": {
            "1": 0.2868217054263566,
            "2": 0.5517241379310345,
            "3": 0.8318777292576419
        },
        "bertscore": {
            "precision": 0.95191,
            "recall": 0.93878,
            "f1": 0.94481
        },
        "bleurt": 0.41997,
        "meteor": 0.43214384560502966,
        "nubia": {
            "semantic_relation": 4.53589,
            "contradiction": 1.83883,
            "irrelevancy": 15.57207,
            "logical_agreement": 82.5891,
            "grammar_ref": 4.66047,
            "grammar_hyp": 4.68086,
            "nubia_score": 0.82548
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_154": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.765,
        "total_length": 242,
        "mean_pred_length": 14.235294117647058,
        "std_pred_length": 4.236111032326784,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.6074380165289256,
        "vocab_size-1": 147,
        "unique-1": 119,
        "entropy-1": 6.583967115448868,
        "distinct-2": 0.9555555555555556,
        "vocab_size-2": 215,
        "unique-2": 208,
        "entropy-2": 7.70884945577505,
        "cond_entropy-2": 0.916910632636369,
        "distinct-3": 0.9903846153846154,
        "vocab_size-3": 206,
        "unique-3": 204,
        "entropy-3": 7.681208948910299,
        "cond_entropy-3": -0.019064355410383593,
        "total_length-nopunct": 216,
        "mean_pred_length-nopunct": 12.705882352941176,
        "std_pred_length-nopunct": 3.800382424756022,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6712962962962963,
        "vocab_size-1-nopunct": 145,
        "unique-1-nopunct": 119,
        "entropy-1-nopunct": 6.713088112498697,
        "distinct-2-nopunct": 0.949748743718593,
        "vocab_size-2-nopunct": 189,
        "unique-2-nopunct": 182,
        "entropy-2-nopunct": 7.517983211124378,
        "cond_entropy-2-nopunct": 0.8809032751260686,
        "distinct-3-nopunct": 0.989010989010989,
        "vocab_size-3-nopunct": 180,
        "unique-3-nopunct": 178,
        "entropy-3-nopunct": 7.485816618220692,
        "cond_entropy-3-nopunct": -0.026579208507387646,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.3559955353269,
        "bleu": 32.75358,
        "rouge1": {
            "precision": 0.69304,
            "recall": 0.66506,
            "fmeasure": 0.67238
        },
        "rouge2": {
            "precision": 0.40991,
            "recall": 0.3917,
            "fmeasure": 0.39661
        },
        "rougeL": {
            "precision": 0.54329,
            "recall": 0.53078,
            "fmeasure": 0.5318
        },
        "rougeLsum": {
            "precision": 0.54329,
            "recall": 0.53078,
            "fmeasure": 0.5318
        },
        "local_recall": {
            "1": 0.19444444444444445,
            "2": 0.4262295081967213,
            "3": 0.7018633540372671
        },
        "bertscore": {
            "precision": 0.91002,
            "recall": 0.90883,
            "f1": 0.90753
        },
        "bleurt": 0.23851,
        "meteor": 0.3388265968914228,
        "nubia": {
            "semantic_relation": 4.1024,
            "contradiction": 9.46718,
            "irrelevancy": 30.08797,
            "logical_agreement": 60.44485,
            "grammar_ref": 4.51289,
            "grammar_hyp": 4.50052,
            "nubia_score": 0.7145
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_186": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.745,
        "total_length": 242,
        "mean_pred_length": 17.285714285714285,
        "std_pred_length": 5.350948800093726,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.640495867768595,
        "vocab_size-1": 155,
        "unique-1": 128,
        "entropy-1": 6.643816684360714,
        "distinct-2": 0.9385964912280702,
        "vocab_size-2": 214,
        "unique-2": 207,
        "entropy-2": 7.6629124374009,
        "cond_entropy-2": 0.8636031338822074,
        "distinct-3": 0.9953271028037384,
        "vocab_size-3": 213,
        "unique-3": 212,
        "entropy-3": 7.732121192008589,
        "cond_entropy-3": 0.08032878299417859,
        "total_length-nopunct": 216,
        "mean_pred_length-nopunct": 15.428571428571429,
        "std_pred_length-nopunct": 4.995916700013061,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6944444444444444,
        "vocab_size-1-nopunct": 150,
        "unique-1-nopunct": 125,
        "entropy-1-nopunct": 6.7052163360367425,
        "distinct-2-nopunct": 0.9356435643564357,
        "vocab_size-2-nopunct": 189,
        "unique-2-nopunct": 183,
        "entropy-2-nopunct": 7.476256594127195,
        "cond_entropy-2-nopunct": 0.8231465517752873,
        "distinct-3-nopunct": 0.9946808510638298,
        "vocab_size-3-nopunct": 187,
        "unique-3-nopunct": 186,
        "entropy-3-nopunct": 7.543950553805318,
        "cond_entropy-3-nopunct": 0.0812437918096909,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.199378165653565,
        "bleu": 44.10269,
        "rouge1": {
            "precision": 0.70879,
            "recall": 0.74568,
            "fmeasure": 0.71315
        },
        "rouge2": {
            "precision": 0.49968,
            "recall": 0.51674,
            "fmeasure": 0.50042
        },
        "rougeL": {
            "precision": 0.62068,
            "recall": 0.65544,
            "fmeasure": 0.62638
        },
        "rougeLsum": {
            "precision": 0.62068,
            "recall": 0.65544,
            "fmeasure": 0.62638
        },
        "local_recall": {
            "1": 0.1891891891891892,
            "2": 0.40384615384615385,
            "3": 0.8095238095238095
        },
        "bertscore": {
            "precision": 0.89808,
            "recall": 0.91327,
            "f1": 0.90456
        },
        "bleurt": 0.03489,
        "meteor": 0.3944539902534409,
        "nubia": {
            "semantic_relation": 4.0613,
            "contradiction": 13.99831,
            "irrelevancy": 40.53305,
            "logical_agreement": 45.46865,
            "grammar_ref": 4.72137,
            "grammar_hyp": 4.75752,
            "nubia_score": 0.65604
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_133": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.76,
        "total_length": 157,
        "mean_pred_length": 14.272727272727273,
        "std_pred_length": 5.411954933140806,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.6624203821656051,
        "vocab_size-1": 104,
        "unique-1": 86,
        "entropy-1": 6.2962717380695175,
        "distinct-2": 0.9657534246575342,
        "vocab_size-2": 141,
        "unique-2": 136,
        "entropy-2": 7.121331408195089,
        "cond_entropy-2": 0.6396356380299019,
        "distinct-3": 1.0,
        "vocab_size-3": 135,
        "unique-3": 135,
        "entropy-3": 7.076815597050856,
        "cond_entropy-3": -0.038934887755112196,
        "total_length-nopunct": 140,
        "mean_pred_length-nopunct": 12.727272727272727,
        "std_pred_length-nopunct": 4.900666171615838,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7285714285714285,
        "vocab_size-1-nopunct": 102,
        "unique-1-nopunct": 86,
        "entropy-1-nopunct": 6.392302503446879,
        "distinct-2-nopunct": 0.9689922480620154,
        "vocab_size-2-nopunct": 125,
        "unique-2-nopunct": 121,
        "entropy-2-nopunct": 6.949211751547267,
        "cond_entropy-2-nopunct": 0.6120006097165326,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 118,
        "unique-3-nopunct": 118,
        "entropy-3-nopunct": 6.882643049361832,
        "cond_entropy-3-nopunct": -0.0607875958919212,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.363122600193184,
        "bleu": 42.44152,
        "rouge1": {
            "precision": 0.8096,
            "recall": 0.70681,
            "fmeasure": 0.73815
        },
        "rouge2": {
            "precision": 0.50272,
            "recall": 0.4656,
            "fmeasure": 0.47661
        },
        "rougeL": {
            "precision": 0.6547,
            "recall": 0.56738,
            "fmeasure": 0.59667
        },
        "rougeLsum": {
            "precision": 0.6547,
            "recall": 0.56738,
            "fmeasure": 0.59667
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.4090909090909091,
            "3": 0.7380952380952381
        },
        "bertscore": {
            "precision": 0.93361,
            "recall": 0.90632,
            "f1": 0.91748
        },
        "bleurt": 0.18482,
        "meteor": 0.403381984945719,
        "nubia": {
            "semantic_relation": 4.16823,
            "contradiction": 25.36207,
            "irrelevancy": 20.69511,
            "logical_agreement": 53.94282,
            "grammar_ref": 4.38413,
            "grammar_hyp": 4.65498,
            "nubia_score": 0.68282
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_187": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.7735572622751845,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.0433214693062285,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.418485886665368,
        "bleu": 23.96183,
        "rouge1": {
            "precision": 0.69231,
            "recall": 0.5875,
            "fmeasure": 0.63547
        },
        "rouge2": {
            "precision": 0.47222,
            "recall": 0.39683,
            "fmeasure": 0.43115
        },
        "rougeL": {
            "precision": 0.53846,
            "recall": 0.45694,
            "fmeasure": 0.49425
        },
        "rougeLsum": {
            "precision": 0.53846,
            "recall": 0.45694,
            "fmeasure": 0.49425
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6363636363636364
        },
        "bertscore": {
            "precision": 0.89306,
            "recall": 0.90653,
            "f1": 0.89975
        },
        "bleurt": 0.02025,
        "meteor": 0.3053804237840921,
        "nubia": {
            "semantic_relation": 2.99376,
            "contradiction": 99.75101,
            "irrelevancy": 0.16234,
            "logical_agreement": 0.08666,
            "grammar_ref": 5.18542,
            "grammar_hyp": 5.50926,
            "nubia_score": 0.29504
        }
    },
    "schema_guided_dialog_challenge_test_backtranslation_parent": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.67468,
        "msttr-100_nopunct": 0.70745,
        "total_length": 6288,
        "mean_pred_length": 12.576,
        "std_pred_length": 7.0359238199400655,
        "median_pred_length": 10.0,
        "min_pred_length": 4,
        "max_pred_length": 38,
        "distinct-1": 0.15235368956743003,
        "vocab_size-1": 958,
        "unique-1": 556,
        "entropy-1": 7.7552883517571045,
        "distinct-2": 0.45991706979958535,
        "vocab_size-2": 2662,
        "unique-2": 1836,
        "entropy-2": 10.521815324260835,
        "cond_entropy-2": 2.5160398362868945,
        "distinct-3": 0.6677382753403933,
        "vocab_size-3": 3531,
        "unique-3": 2852,
        "entropy-3": 11.310845816902091,
        "cond_entropy-3": 0.8103483374158351,
        "total_length-nopunct": 5507,
        "mean_pred_length-nopunct": 11.014,
        "std_pred_length-nopunct": 6.479336694446431,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.1715997820955148,
        "vocab_size-1-nopunct": 945,
        "unique-1-nopunct": 552,
        "entropy-1-nopunct": 7.936385527920332,
        "distinct-2-nopunct": 0.47833033752746157,
        "vocab_size-2-nopunct": 2395,
        "unique-2-nopunct": 1700,
        "entropy-2-nopunct": 10.36180468631392,
        "cond_entropy-2-nopunct": 2.5555165115939973,
        "distinct-3-nopunct": 0.686265808741957,
        "vocab_size-3-nopunct": 3093,
        "unique-3-nopunct": 2559,
        "entropy-3-nopunct": 11.114560638425079,
        "cond_entropy-3-nopunct": 0.7943513863901203,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.250247305288876,
        "bleu": 34.44,
        "rouge1": {
            "precision": 0.5801,
            "recall": 0.56886,
            "fmeasure": 0.56188
        },
        "rouge2": {
            "precision": 0.36855,
            "recall": 0.3668,
            "fmeasure": 0.35937
        },
        "rougeL": {
            "precision": 0.52904,
            "recall": 0.51884,
            "fmeasure": 0.5127
        },
        "rougeLsum": {
            "precision": 0.52904,
            "recall": 0.51884,
            "fmeasure": 0.5127
        },
        "local_recall": {
            "1": 0.5864243323442137
        },
        "bertscore": {
            "precision": 0.87751,
            "recall": 0.87319,
            "f1": 0.87481
        },
        "bleurt": -0.01635,
        "meteor": 0.32722312610683546,
        "nubia": {
            "semantic_relation": 3.66222,
            "contradiction": 7.41537,
            "irrelevancy": 21.99825,
            "logical_agreement": 70.58639,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.51033,
            "nubia_score": 0.66191
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_134": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.046930949929641655,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2822074660178386,
        "bleu": 34.23475,
        "rouge1": {
            "precision": 0.65385,
            "recall": 0.775,
            "fmeasure": 0.70783
        },
        "rouge2": {
            "precision": 0.29167,
            "recall": 0.35859,
            "fmeasure": 0.32091
        },
        "rougeL": {
            "precision": 0.38462,
            "recall": 0.45,
            "fmeasure": 0.41391
        },
        "rougeLsum": {
            "precision": 0.38462,
            "recall": 0.45,
            "fmeasure": 0.41391
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.875
        },
        "bertscore": {
            "precision": 0.89538,
            "recall": 0.90968,
            "f1": 0.90118
        },
        "bleurt": 0.08684,
        "meteor": 0.4340765084008706,
        "nubia": {
            "semantic_relation": 4.15434,
            "contradiction": 1.10509,
            "irrelevancy": 95.67297,
            "logical_agreement": 3.22193,
            "grammar_ref": 5.93899,
            "grammar_hyp": 5.36463,
            "nubia_score": 0.644
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_102": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 24,
        "msttr-100": 0.7025,
        "msttr-100_nopunct": 0.75667,
        "total_length": 435,
        "mean_pred_length": 18.125,
        "std_pred_length": 5.206666399914632,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.5793103448275863,
        "vocab_size-1": 252,
        "unique-1": 212,
        "entropy-1": 7.124932806929616,
        "distinct-2": 0.9148418491484185,
        "vocab_size-2": 376,
        "unique-2": 356,
        "entropy-2": 8.470624236929488,
        "cond_entropy-2": 1.1737192421508296,
        "distinct-3": 0.9844961240310077,
        "vocab_size-3": 381,
        "unique-3": 375,
        "entropy-3": 8.565182004206406,
        "cond_entropy-3": 0.10256006268273857,
        "total_length-nopunct": 379,
        "mean_pred_length-nopunct": 15.791666666666666,
        "std_pred_length-nopunct": 4.6005358987356635,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6464379947229552,
        "vocab_size-1-nopunct": 245,
        "unique-1-nopunct": 210,
        "entropy-1-nopunct": 7.271759952558868,
        "distinct-2-nopunct": 0.9098591549295775,
        "vocab_size-2-nopunct": 323,
        "unique-2-nopunct": 306,
        "entropy-2-nopunct": 8.242705601673373,
        "cond_entropy-2-nopunct": 1.0398980309566126,
        "distinct-3-nopunct": 0.9818731117824774,
        "vocab_size-3-nopunct": 325,
        "unique-3-nopunct": 319,
        "entropy-3-nopunct": 8.334433630372121,
        "cond_entropy-3-nopunct": 0.10833005499869074,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.632174623758336,
        "bleu": 47.24914,
        "rouge1": {
            "precision": 0.78379,
            "recall": 0.7879,
            "fmeasure": 0.77603
        },
        "rouge2": {
            "precision": 0.53559,
            "recall": 0.53018,
            "fmeasure": 0.52444
        },
        "rougeL": {
            "precision": 0.66758,
            "recall": 0.66234,
            "fmeasure": 0.65546
        },
        "rougeLsum": {
            "precision": 0.66758,
            "recall": 0.66234,
            "fmeasure": 0.65546
        },
        "local_recall": {
            "1": 0.13392857142857142,
            "2": 0.5053763440860215,
            "3": 0.8683127572016461
        },
        "bertscore": {
            "precision": 0.92714,
            "recall": 0.9309,
            "f1": 0.92653
        },
        "bleurt": 0.17538,
        "meteor": 0.4100530115002335,
        "nubia": {
            "semantic_relation": 4.23604,
            "contradiction": 4.17225,
            "irrelevancy": 39.10169,
            "logical_agreement": 56.72606,
            "grammar_ref": 4.72162,
            "grammar_hyp": 4.58395,
            "nubia_score": 0.74723
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_188": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 4.4969125210773475,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.7727272727272727,
        "vocab_size-1": 34,
        "unique-1": 29,
        "entropy-1": 4.888535812301757,
        "distinct-2": 1.0,
        "vocab_size-2": 41,
        "unique-2": 41,
        "entropy-2": 5.357552004618081,
        "cond_entropy-2": 0.39481619028811055,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.10962449117449787,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 4.027681991198191,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8378378378378378,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.787571190644174,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.087462841250338,
        "cond_entropy-2-nopunct": 0.33711654839894306,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.13326653086346418,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.760380600920732,
        "bleu": 55.36757,
        "rouge1": {
            "precision": 0.89074,
            "recall": 0.79516,
            "fmeasure": 0.83907
        },
        "rouge2": {
            "precision": 0.68795,
            "recall": 0.6094,
            "fmeasure": 0.64531
        },
        "rougeL": {
            "precision": 0.67963,
            "recall": 0.60596,
            "fmeasure": 0.63983
        },
        "rougeLsum": {
            "precision": 0.67963,
            "recall": 0.60596,
            "fmeasure": 0.63983
        },
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 0.8484848484848485
        },
        "bertscore": {
            "precision": 0.9694,
            "recall": 0.97025,
            "f1": 0.96979
        },
        "bleurt": 0.51666,
        "meteor": 0.48489446522038365,
        "nubia": {
            "semantic_relation": 4.80491,
            "contradiction": 1.11593,
            "irrelevancy": 19.15436,
            "logical_agreement": 79.72972,
            "grammar_ref": 5.15044,
            "grammar_hyp": 5.4539,
            "nubia_score": 0.89266
        }
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 457,
        "msttr-100": 0.5017,
        "msttr-100_nopunct": 0.509,
        "total_length": 14744,
        "mean_pred_length": 32.26258205689278,
        "std_pred_length": 12.846551883768173,
        "median_pred_length": 30.0,
        "min_pred_length": 10,
        "max_pred_length": 75,
        "distinct-1": 0.09352957135105806,
        "vocab_size-1": 1379,
        "unique-1": 553,
        "entropy-1": 7.83324235484207,
        "distinct-2": 0.28305452509274165,
        "vocab_size-2": 4044,
        "unique-2": 2282,
        "entropy-2": 10.75317789787296,
        "cond_entropy-2": 2.8020011307789296,
        "distinct-3": 0.44707158351409976,
        "vocab_size-3": 6183,
        "unique-3": 4224,
        "entropy-3": 11.762517914487287,
        "cond_entropy-3": 1.053773343208889,
        "total_length-nopunct": 13077,
        "mean_pred_length-nopunct": 28.61487964989059,
        "std_pred_length-nopunct": 11.442771582288172,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 65,
        "distinct-1-nopunct": 0.10468761948459127,
        "vocab_size-1-nopunct": 1369,
        "unique-1-nopunct": 552,
        "entropy-1-nopunct": 8.069457315228254,
        "distinct-2-nopunct": 0.2956418383518225,
        "vocab_size-2-nopunct": 3731,
        "unique-2-nopunct": 2180,
        "entropy-2-nopunct": 10.650615864833803,
        "cond_entropy-2-nopunct": 2.6750902845671005,
        "distinct-3-nopunct": 0.45827509660445614,
        "vocab_size-3-nopunct": 5574,
        "unique-3-nopunct": 3896,
        "entropy-3-nopunct": 11.611019056914307,
        "cond_entropy-3-nopunct": 0.9972188691869694,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.8118874009995745,
        "bleu": 42.06259,
        "rouge1": {
            "precision": 0.68967,
            "recall": 0.68877,
            "fmeasure": 0.68303
        },
        "rouge2": {
            "precision": 0.41095,
            "recall": 0.41269,
            "fmeasure": 0.40775
        },
        "rougeL": {
            "precision": 0.5066,
            "recall": 0.50681,
            "fmeasure": 0.50183
        },
        "rougeLsum": {
            "precision": 0.5066,
            "recall": 0.50681,
            "fmeasure": 0.50183
        },
        "local_recall": {
            "1": 0.23397435897435898,
            "2": 0.5691389063482086,
            "3": 0.8238064306593049,
            "4": 0.25,
            "5": 0.875
        },
        "bertscore": {
            "precision": 0.89798,
            "recall": 0.89838,
            "f1": 0.8969
        },
        "bleurt": -0.05291,
        "meteor": 0.3516674435454721,
        "nubia": {
            "semantic_relation": 4.12418,
            "contradiction": 16.73358,
            "irrelevancy": 10.47106,
            "logical_agreement": 72.79536,
            "grammar_ref": 4.37649,
            "grammar_hyp": 4.4178,
            "nubia_score": 0.69898
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_155": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.805,
        "total_length": 290,
        "mean_pred_length": 17.058823529411764,
        "std_pred_length": 7.066662314202921,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 35,
        "distinct-1": 0.6103448275862069,
        "vocab_size-1": 177,
        "unique-1": 143,
        "entropy-1": 6.869975661893543,
        "distinct-2": 0.9010989010989011,
        "vocab_size-2": 246,
        "unique-2": 225,
        "entropy-2": 7.878364009004141,
        "cond_entropy-2": 0.830293633753653,
        "distinct-3": 0.953125,
        "vocab_size-3": 244,
        "unique-3": 234,
        "entropy-3": 7.900352441389348,
        "cond_entropy-3": 0.028412976301451752,
        "total_length-nopunct": 239,
        "mean_pred_length-nopunct": 14.058823529411764,
        "std_pred_length-nopunct": 4.7088226108681175,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7196652719665272,
        "vocab_size-1-nopunct": 172,
        "unique-1-nopunct": 142,
        "entropy-1-nopunct": 7.087224861560381,
        "distinct-2-nopunct": 0.9324324324324325,
        "vocab_size-2-nopunct": 207,
        "unique-2-nopunct": 195,
        "entropy-2-nopunct": 7.64907954875329,
        "cond_entropy-2-nopunct": 0.6151515929999191,
        "distinct-3-nopunct": 0.9707317073170731,
        "vocab_size-3-nopunct": 199,
        "unique-3-nopunct": 193,
        "entropy-3-nopunct": 7.620943514139578,
        "cond_entropy-3-nopunct": -0.01608375461787756,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.837725171365669,
        "bleu": 60.81678,
        "rouge1": {
            "precision": 0.82938,
            "recall": 0.76794,
            "fmeasure": 0.78717
        },
        "rouge2": {
            "precision": 0.63556,
            "recall": 0.60994,
            "fmeasure": 0.61072
        },
        "rougeL": {
            "precision": 0.70797,
            "recall": 0.65624,
            "fmeasure": 0.67087
        },
        "rougeLsum": {
            "precision": 0.70797,
            "recall": 0.65624,
            "fmeasure": 0.67087
        },
        "local_recall": {
            "1": 0.14893617021276595,
            "2": 0.3157894736842105,
            "3": 0.815668202764977
        },
        "bertscore": {
            "precision": 0.95158,
            "recall": 0.93533,
            "f1": 0.94181
        },
        "bleurt": 0.38877,
        "meteor": 0.4639383616367553,
        "nubia": {
            "semantic_relation": 4.34202,
            "contradiction": 1.65349,
            "irrelevancy": 16.14687,
            "logical_agreement": 82.19964,
            "grammar_ref": 4.52442,
            "grammar_hyp": 4.54648,
            "nubia_score": 0.78445
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_189": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.74,
        "total_length": 284,
        "mean_pred_length": 15.777777777777779,
        "std_pred_length": 4.3018801516902085,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.5880281690140845,
        "vocab_size-1": 167,
        "unique-1": 134,
        "entropy-1": 6.683991183331042,
        "distinct-2": 0.9097744360902256,
        "vocab_size-2": 242,
        "unique-2": 226,
        "entropy-2": 7.8375525597084055,
        "cond_entropy-2": 0.9652941267876399,
        "distinct-3": 0.9919354838709677,
        "vocab_size-3": 246,
        "unique-3": 244,
        "entropy-3": 7.938067278128837,
        "cond_entropy-3": 0.10825317714735444,
        "total_length-nopunct": 254,
        "mean_pred_length-nopunct": 14.11111111111111,
        "std_pred_length-nopunct": 3.7548322774924,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6496062992125984,
        "vocab_size-1-nopunct": 165,
        "unique-1-nopunct": 134,
        "entropy-1-nopunct": 6.817384232784423,
        "distinct-2-nopunct": 0.9067796610169492,
        "vocab_size-2-nopunct": 214,
        "unique-2-nopunct": 200,
        "entropy-2-nopunct": 7.654184799527523,
        "cond_entropy-2-nopunct": 0.9067092348408025,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 218,
        "unique-3-nopunct": 218,
        "entropy-3-nopunct": 7.7681843247769145,
        "cond_entropy-3-nopunct": 0.12368873853844992,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.031265276922339,
        "bleu": 41.44108,
        "rouge1": {
            "precision": 0.71952,
            "recall": 0.72848,
            "fmeasure": 0.7077
        },
        "rouge2": {
            "precision": 0.4716,
            "recall": 0.46698,
            "fmeasure": 0.45798
        },
        "rougeL": {
            "precision": 0.57875,
            "recall": 0.57864,
            "fmeasure": 0.56557
        },
        "rougeLsum": {
            "precision": 0.57875,
            "recall": 0.57864,
            "fmeasure": 0.56557
        },
        "local_recall": {
            "1": 0.26136363636363635,
            "2": 0.4576271186440678,
            "3": 0.7639751552795031
        },
        "bertscore": {
            "precision": 0.9099,
            "recall": 0.91291,
            "f1": 0.90863
        },
        "bleurt": 0.16022,
        "meteor": 0.37525505839780926,
        "nubia": {
            "semantic_relation": 4.22422,
            "contradiction": 10.40186,
            "irrelevancy": 38.34038,
            "logical_agreement": 51.25776,
            "grammar_ref": 4.82101,
            "grammar_hyp": 4.6339,
            "nubia_score": 0.73719
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_135": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.81,
        "total_length": 392,
        "mean_pred_length": 17.043478260869566,
        "std_pred_length": 4.563353656835453,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.5790816326530612,
        "vocab_size-1": 227,
        "unique-1": 183,
        "entropy-1": 7.082064902992328,
        "distinct-2": 0.8997289972899729,
        "vocab_size-2": 332,
        "unique-2": 304,
        "entropy-2": 8.298016208057499,
        "cond_entropy-2": 1.0295255832671675,
        "distinct-3": 0.9508670520231214,
        "vocab_size-3": 329,
        "unique-3": 314,
        "entropy-3": 8.331998820109746,
        "cond_entropy-3": 0.026114399202716077,
        "total_length-nopunct": 346,
        "mean_pred_length-nopunct": 15.043478260869565,
        "std_pred_length-nopunct": 3.8727392941988437,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6416184971098265,
        "vocab_size-1-nopunct": 222,
        "unique-1-nopunct": 182,
        "entropy-1-nopunct": 7.199218045492029,
        "distinct-2-nopunct": 0.9071207430340558,
        "vocab_size-2-nopunct": 293,
        "unique-2-nopunct": 272,
        "entropy-2-nopunct": 8.116594582362499,
        "cond_entropy-2-nopunct": 0.9614771845109482,
        "distinct-3-nopunct": 0.9566666666666667,
        "vocab_size-3-nopunct": 287,
        "unique-3-nopunct": 276,
        "entropy-3-nopunct": 8.137119440481516,
        "cond_entropy-3-nopunct": 0.020066117326248908,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.232959999146467,
        "bleu": 48.12882,
        "rouge1": {
            "precision": 0.76017,
            "recall": 0.76578,
            "fmeasure": 0.75721
        },
        "rouge2": {
            "precision": 0.55291,
            "recall": 0.55884,
            "fmeasure": 0.55123
        },
        "rougeL": {
            "precision": 0.6766,
            "recall": 0.68766,
            "fmeasure": 0.67658
        },
        "rougeLsum": {
            "precision": 0.6766,
            "recall": 0.68766,
            "fmeasure": 0.67658
        },
        "local_recall": {
            "1": 0.2077922077922078,
            "2": 0.5362318840579711,
            "3": 0.8377192982456141
        },
        "bertscore": {
            "precision": 0.9331,
            "recall": 0.93833,
            "f1": 0.93507
        },
        "bleurt": 0.27613,
        "meteor": 0.4190395322061315,
        "nubia": {
            "semantic_relation": 4.35883,
            "contradiction": 2.37241,
            "irrelevancy": 33.8184,
            "logical_agreement": 63.80919,
            "grammar_ref": 4.82223,
            "grammar_hyp": 4.79858,
            "nubia_score": 0.77556
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_190": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.8,
        "total_length": 205,
        "mean_pred_length": 15.76923076923077,
        "std_pred_length": 3.092269421883351,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 20,
        "distinct-1": 0.6536585365853659,
        "vocab_size-1": 134,
        "unique-1": 114,
        "entropy-1": 6.589582397708918,
        "distinct-2": 0.9427083333333334,
        "vocab_size-2": 181,
        "unique-2": 174,
        "entropy-2": 7.44954583405451,
        "cond_entropy-2": 0.6832079873222295,
        "distinct-3": 1.0,
        "vocab_size-3": 179,
        "unique-3": 179,
        "entropy-3": 7.483815777264248,
        "cond_entropy-3": 0.03293148883360281,
        "total_length-nopunct": 180,
        "mean_pred_length-nopunct": 13.846153846153847,
        "std_pred_length-nopunct": 2.9048011674614163,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7166666666666667,
        "vocab_size-1-nopunct": 129,
        "unique-1-nopunct": 111,
        "entropy-1-nopunct": 6.676330943443714,
        "distinct-2-nopunct": 0.9461077844311377,
        "vocab_size-2-nopunct": 158,
        "unique-2-nopunct": 153,
        "entropy-2-nopunct": 7.251967765527921,
        "cond_entropy-2-nopunct": 0.6271445345843238,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 154,
        "unique-3-nopunct": 154,
        "entropy-3-nopunct": 7.2667865406949215,
        "cond_entropy-3-nopunct": 0.025939391077991834,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.527659718848384,
        "bleu": 59.58945,
        "rouge1": {
            "precision": 0.86252,
            "recall": 0.87666,
            "fmeasure": 0.86147
        },
        "rouge2": {
            "precision": 0.66088,
            "recall": 0.69955,
            "fmeasure": 0.66777
        },
        "rougeL": {
            "precision": 0.77165,
            "recall": 0.7841,
            "fmeasure": 0.76922
        },
        "rougeLsum": {
            "precision": 0.77165,
            "recall": 0.7841,
            "fmeasure": 0.76922
        },
        "local_recall": {
            "1": 0.37037037037037035,
            "2": 0.18181818181818182,
            "3": 0.9078947368421053
        },
        "bertscore": {
            "precision": 0.95708,
            "recall": 0.96553,
            "f1": 0.95968
        },
        "bleurt": 0.55099,
        "meteor": 0.49063043047893024,
        "nubia": {
            "semantic_relation": 4.71676,
            "contradiction": 2.56696,
            "irrelevancy": 19.05294,
            "logical_agreement": 78.3801,
            "grammar_ref": 5.1809,
            "grammar_hyp": 5.10012,
            "nubia_score": 0.87879
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_136": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.78667,
        "total_length": 400,
        "mean_pred_length": 17.391304347826086,
        "std_pred_length": 7.556967015449373,
        "median_pred_length": 17.0,
        "min_pred_length": 10,
        "max_pred_length": 45,
        "distinct-1": 0.6175,
        "vocab_size-1": 247,
        "unique-1": 215,
        "entropy-1": 7.202267416151739,
        "distinct-2": 0.946949602122016,
        "vocab_size-2": 357,
        "unique-2": 346,
        "entropy-2": 8.430397735797856,
        "cond_entropy-2": 1.0401054305321196,
        "distinct-3": 0.9858757062146892,
        "vocab_size-3": 349,
        "unique-3": 346,
        "entropy-3": 8.435092061370181,
        "cond_entropy-3": 0.007362485125529207,
        "total_length-nopunct": 338,
        "mean_pred_length-nopunct": 14.695652173913043,
        "std_pred_length-nopunct": 5.448851355690327,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.7159763313609467,
        "vocab_size-1-nopunct": 242,
        "unique-1-nopunct": 215,
        "entropy-1-nopunct": 7.423281115457023,
        "distinct-2-nopunct": 0.9714285714285714,
        "vocab_size-2-nopunct": 306,
        "unique-2-nopunct": 301,
        "entropy-2-nopunct": 8.230923018373497,
        "cond_entropy-2-nopunct": 0.8626096374483391,
        "distinct-3-nopunct": 0.9931506849315068,
        "vocab_size-3-nopunct": 290,
        "unique-3-nopunct": 289,
        "entropy-3-nopunct": 8.173540697571278,
        "cond_entropy-3-nopunct": -0.05200370778752372,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.214041869749135,
        "bleu": 42.94298,
        "rouge1": {
            "precision": 0.77846,
            "recall": 0.70381,
            "fmeasure": 0.72364
        },
        "rouge2": {
            "precision": 0.53342,
            "recall": 0.49715,
            "fmeasure": 0.50197
        },
        "rougeL": {
            "precision": 0.67237,
            "recall": 0.63402,
            "fmeasure": 0.63767
        },
        "rougeLsum": {
            "precision": 0.67237,
            "recall": 0.63402,
            "fmeasure": 0.63767
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3253012048192771,
            "3": 0.7448559670781894
        },
        "bertscore": {
            "precision": 0.92585,
            "recall": 0.91556,
            "f1": 0.9182
        },
        "bleurt": 0.1933,
        "meteor": 0.3686417190573541,
        "nubia": {
            "semantic_relation": 4.17663,
            "contradiction": 2.91784,
            "irrelevancy": 40.14362,
            "logical_agreement": 56.93854,
            "grammar_ref": 4.55066,
            "grammar_hyp": 4.48901,
            "nubia_score": 0.71611
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_156": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 32,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.734,
        "total_length": 634,
        "mean_pred_length": 19.8125,
        "std_pred_length": 7.9704042400621065,
        "median_pred_length": 18.5,
        "min_pred_length": 8,
        "max_pred_length": 41,
        "distinct-1": 0.4968454258675079,
        "vocab_size-1": 315,
        "unique-1": 234,
        "entropy-1": 7.378666250002986,
        "distinct-2": 0.8272425249169435,
        "vocab_size-2": 498,
        "unique-2": 434,
        "entropy-2": 8.797228662610701,
        "cond_entropy-2": 1.255355650089998,
        "distinct-3": 0.9087719298245615,
        "vocab_size-3": 518,
        "unique-3": 470,
        "entropy-3": 8.966204468693693,
        "cond_entropy-3": 0.17242231915797918,
        "total_length-nopunct": 555,
        "mean_pred_length-nopunct": 17.34375,
        "std_pred_length-nopunct": 6.292899644639187,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.5567567567567567,
        "vocab_size-1-nopunct": 309,
        "unique-1-nopunct": 233,
        "entropy-1-nopunct": 7.521387006399985,
        "distinct-2-nopunct": 0.8393881453154876,
        "vocab_size-2-nopunct": 439,
        "unique-2-nopunct": 386,
        "entropy-2-nopunct": 8.620642799705456,
        "cond_entropy-2-nopunct": 1.1499018272813608,
        "distinct-3-nopunct": 0.9164969450101833,
        "vocab_size-3-nopunct": 450,
        "unique-3-nopunct": 410,
        "entropy-3-nopunct": 8.771035655247196,
        "cond_entropy-3-nopunct": 0.1465655210597117,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.476212476667938,
        "bleu": 46.44223,
        "rouge1": {
            "precision": 0.75721,
            "recall": 0.74363,
            "fmeasure": 0.73948
        },
        "rouge2": {
            "precision": 0.54809,
            "recall": 0.54839,
            "fmeasure": 0.53815
        },
        "rougeL": {
            "precision": 0.66317,
            "recall": 0.65614,
            "fmeasure": 0.6499
        },
        "rougeLsum": {
            "precision": 0.66317,
            "recall": 0.65614,
            "fmeasure": 0.6499
        },
        "local_recall": {
            "1": 0.2653061224489796,
            "2": 0.4457831325301205,
            "3": 0.7780612244897959
        },
        "bertscore": {
            "precision": 0.92249,
            "recall": 0.92071,
            "f1": 0.9203
        },
        "bleurt": 0.22059,
        "meteor": 0.38598231351123363,
        "nubia": {
            "semantic_relation": 4.20648,
            "contradiction": 14.98354,
            "irrelevancy": 28.69011,
            "logical_agreement": 56.32635,
            "grammar_ref": 4.40347,
            "grammar_hyp": 4.262,
            "nubia_score": 0.73514
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_138": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 19,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.74,
        "total_length": 287,
        "mean_pred_length": 15.105263157894736,
        "std_pred_length": 5.139063367888061,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.5435540069686411,
        "vocab_size-1": 156,
        "unique-1": 116,
        "entropy-1": 6.670469726670163,
        "distinct-2": 0.8768656716417911,
        "vocab_size-2": 235,
        "unique-2": 213,
        "entropy-2": 7.781988572967375,
        "cond_entropy-2": 0.9163087121355739,
        "distinct-3": 0.9558232931726908,
        "vocab_size-3": 238,
        "unique-3": 229,
        "entropy-3": 7.865585164982432,
        "cond_entropy-3": 0.08617901864214475,
        "total_length-nopunct": 258,
        "mean_pred_length-nopunct": 13.578947368421053,
        "std_pred_length-nopunct": 5.019077179529323,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.5852713178294574,
        "vocab_size-1-nopunct": 151,
        "unique-1-nopunct": 113,
        "entropy-1-nopunct": 6.7378110957652915,
        "distinct-2-nopunct": 0.8786610878661087,
        "vocab_size-2-nopunct": 210,
        "unique-2-nopunct": 190,
        "entropy-2-nopunct": 7.622083584202171,
        "cond_entropy-2-nopunct": 0.9521767677206584,
        "distinct-3-nopunct": 0.9590909090909091,
        "vocab_size-3-nopunct": 211,
        "unique-3-nopunct": 203,
        "entropy-3-nopunct": 7.696110224878447,
        "cond_entropy-3-nopunct": 0.09355791909358036,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.165342216780799,
        "bleu": 45.75915,
        "rouge1": {
            "precision": 0.76733,
            "recall": 0.64887,
            "fmeasure": 0.69341
        },
        "rouge2": {
            "precision": 0.56294,
            "recall": 0.48103,
            "fmeasure": 0.51104
        },
        "rougeL": {
            "precision": 0.67598,
            "recall": 0.57576,
            "fmeasure": 0.61332
        },
        "rougeLsum": {
            "precision": 0.67598,
            "recall": 0.57576,
            "fmeasure": 0.61332
        },
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.2549019607843137,
            "3": 0.6724137931034483
        },
        "bertscore": {
            "precision": 0.92671,
            "recall": 0.90062,
            "f1": 0.91135
        },
        "bleurt": 0.15696,
        "meteor": 0.37842835262957664,
        "nubia": {
            "semantic_relation": 3.98774,
            "contradiction": 16.67467,
            "irrelevancy": 27.82016,
            "logical_agreement": 55.50517,
            "grammar_ref": 4.44575,
            "grammar_hyp": 4.67011,
            "nubia_score": 0.63547
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_159": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 7.5,
        "median_pred_length": 17.5,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.9714285714285714,
        "vocab_size-1": 34,
        "unique-1": 33,
        "entropy-1": 5.072140159802107,
        "distinct-2": 1.0,
        "vocab_size-2": 33,
        "unique-2": 33,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": -0.08488889758651327,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.09019780897157811,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 7.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.044394119358456,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": -0.09019780897157811,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.09621531525930291,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.1212957239525556,
        "bleu": 20.26829,
        "rouge1": {
            "precision": 0.67029,
            "recall": 0.54499,
            "fmeasure": 0.60026
        },
        "rouge2": {
            "precision": 0.43466,
            "recall": 0.35556,
            "fmeasure": 0.39065
        },
        "rougeL": {
            "precision": 0.63406,
            "recall": 0.51811,
            "fmeasure": 0.5694
        },
        "rougeLsum": {
            "precision": 0.63406,
            "recall": 0.51811,
            "fmeasure": 0.5694
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.6363636363636364,
            "3": 0.4230769230769231
        },
        "bertscore": {
            "precision": 0.88319,
            "recall": 0.85654,
            "f1": 0.86916
        },
        "bleurt": -0.13614,
        "meteor": 0.2456691230026495,
        "nubia": {
            "semantic_relation": 3.95499,
            "contradiction": 39.15745,
            "irrelevancy": 11.36752,
            "logical_agreement": 49.47503,
            "grammar_ref": 4.83168,
            "grammar_hyp": 4.86541,
            "nubia_score": 0.58795
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-base (Baseline)/e2e_nlg_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 92,
        "mean_pred_length": 18.4,
        "std_pred_length": 4.63033476111609,
        "median_pred_length": 21.0,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.4782608695652174,
        "vocab_size-1": 44,
        "unique-1": 20,
        "entropy-1": 5.107012837388967,
        "distinct-2": 0.6896551724137931,
        "vocab_size-2": 60,
        "unique-2": 36,
        "entropy-2": 5.780763720280493,
        "cond_entropy-2": 0.6260879622606014,
        "distinct-3": 0.7317073170731707,
        "vocab_size-3": 60,
        "unique-3": 38,
        "entropy-3": 5.820966638764418,
        "cond_entropy-3": 0.056189490164926234,
        "total_length-nopunct": 85,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 4.427188724235731,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.5058823529411764,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 5.107378765984091,
        "distinct-2-nopunct": 0.6875,
        "vocab_size-2-nopunct": 55,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.6518075889569035,
        "cond_entropy-2-nopunct": 0.6008045836074141,
        "distinct-3-nopunct": 0.7333333333333333,
        "vocab_size-3-nopunct": 55,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.695485357162547,
        "cond_entropy-3-nopunct": 0.06168580193434273,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 1.7014059381291942,
        "bleu": 6.36983,
        "rouge1": {
            "precision": 0.32821,
            "recall": 0.49759,
            "fmeasure": 0.3885
        },
        "rouge2": {
            "precision": 0.13357,
            "recall": 0.20985,
            "fmeasure": 0.1587
        },
        "rougeL": {
            "precision": 0.31571,
            "recall": 0.48092,
            "fmeasure": 0.37421
        },
        "rougeLsum": {
            "precision": 0.31571,
            "recall": 0.48092,
            "fmeasure": 0.37421
        },
        "local_recall": {
            "1": 0.5
        },
        "bertscore": {
            "precision": 0.81129,
            "recall": 0.83728,
            "f1": 0.82407
        },
        "bleurt": -0.58446,
        "meteor": 0.2145171548482202,
        "nubia": {
            "semantic_relation": 2.90044,
            "contradiction": 0.81157,
            "irrelevancy": 98.98342,
            "logical_agreement": 0.20502,
            "grammar_ref": 5.06674,
            "grammar_hyp": 4.24553,
            "nubia_score": 0.47526
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_104": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.80333,
        "total_length": 459,
        "mean_pred_length": 15.827586206896552,
        "std_pred_length": 6.011878847502761,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.6056644880174292,
        "vocab_size-1": 278,
        "unique-1": 233,
        "entropy-1": 7.353237870871535,
        "distinct-2": 0.9534883720930233,
        "vocab_size-2": 410,
        "unique-2": 398,
        "entropy-2": 8.62427607629846,
        "cond_entropy-2": 1.0405368901503933,
        "distinct-3": 0.9875311720698254,
        "vocab_size-3": 396,
        "unique-3": 391,
        "entropy-3": 8.62252077059449,
        "cond_entropy-3": 0.0022187252822785833,
        "total_length-nopunct": 394,
        "mean_pred_length-nopunct": 13.586206896551724,
        "std_pred_length-nopunct": 4.767108871389091,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6928934010152284,
        "vocab_size-1-nopunct": 273,
        "unique-1-nopunct": 232,
        "entropy-1-nopunct": 7.568150151936834,
        "distinct-2-nopunct": 0.958904109589041,
        "vocab_size-2-nopunct": 350,
        "unique-2-nopunct": 343,
        "entropy-2-nopunct": 8.393165770164254,
        "cond_entropy-2-nopunct": 0.8925670093574638,
        "distinct-3-nopunct": 0.9910714285714286,
        "vocab_size-3-nopunct": 333,
        "unique-3-nopunct": 330,
        "entropy-3-nopunct": 8.374460279921676,
        "cond_entropy-3-nopunct": -0.013187463088550396,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.067799157726914,
        "bleu": 40.54066,
        "rouge1": {
            "precision": 0.78365,
            "recall": 0.74653,
            "fmeasure": 0.75101
        },
        "rouge2": {
            "precision": 0.55354,
            "recall": 0.52217,
            "fmeasure": 0.52899
        },
        "rougeL": {
            "precision": 0.6707,
            "recall": 0.63564,
            "fmeasure": 0.64111
        },
        "rougeLsum": {
            "precision": 0.6707,
            "recall": 0.63564,
            "fmeasure": 0.64111
        },
        "local_recall": {
            "1": 0.1941747572815534,
            "2": 0.36046511627906974,
            "3": 0.7748344370860927
        },
        "bertscore": {
            "precision": 0.9278,
            "recall": 0.92331,
            "f1": 0.92428
        },
        "bleurt": 0.26505,
        "meteor": 0.3742401932977663,
        "nubia": {
            "semantic_relation": 4.24599,
            "contradiction": 8.64086,
            "irrelevancy": 29.67339,
            "logical_agreement": 61.68575,
            "grammar_ref": 4.69384,
            "grammar_hyp": 4.75001,
            "nubia_score": 0.72703
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_160": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.77333,
        "total_length": 450,
        "mean_pred_length": 15.517241379310345,
        "std_pred_length": 5.373117567112401,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.5822222222222222,
        "vocab_size-1": 262,
        "unique-1": 212,
        "entropy-1": 7.269228445744123,
        "distinct-2": 0.9263657957244655,
        "vocab_size-2": 390,
        "unique-2": 369,
        "entropy-2": 8.538318287664177,
        "cond_entropy-2": 1.0374798712456643,
        "distinct-3": 0.9846938775510204,
        "vocab_size-3": 386,
        "unique-3": 380,
        "entropy-3": 8.584097599217287,
        "cond_entropy-3": 0.041816297329841205,
        "total_length-nopunct": 387,
        "mean_pred_length-nopunct": 13.344827586206897,
        "std_pred_length-nopunct": 4.458822034550239,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.661498708010336,
        "vocab_size-1-nopunct": 256,
        "unique-1-nopunct": 211,
        "entropy-1-nopunct": 7.469098865322829,
        "distinct-2-nopunct": 0.9273743016759777,
        "vocab_size-2-nopunct": 332,
        "unique-2-nopunct": 315,
        "entropy-2-nopunct": 8.302936203235864,
        "cond_entropy-2-nopunct": 0.894411739683467,
        "distinct-3-nopunct": 0.9848024316109423,
        "vocab_size-3-nopunct": 324,
        "unique-3-nopunct": 319,
        "entropy-3-nopunct": 8.331548636957141,
        "cond_entropy-3-nopunct": 0.04151671228303138,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.281648423724149,
        "bleu": 57.73,
        "rouge1": {
            "precision": 0.85827,
            "recall": 0.79952,
            "fmeasure": 0.82324
        },
        "rouge2": {
            "precision": 0.64128,
            "recall": 0.61381,
            "fmeasure": 0.61842
        },
        "rougeL": {
            "precision": 0.74096,
            "recall": 0.69387,
            "fmeasure": 0.70774
        },
        "rougeLsum": {
            "precision": 0.74096,
            "recall": 0.69387,
            "fmeasure": 0.70774
        },
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.4489795918367347,
            "3": 0.8298507462686567
        },
        "bertscore": {
            "precision": 0.95505,
            "recall": 0.94858,
            "f1": 0.94973
        },
        "bleurt": 0.49767,
        "meteor": 0.44539040440938393,
        "nubia": {
            "semantic_relation": 4.61665,
            "contradiction": 3.32839,
            "irrelevancy": 14.03407,
            "logical_agreement": 82.63754,
            "grammar_ref": 4.52589,
            "grammar_hyp": 4.68321,
            "nubia_score": 0.86105
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_161": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.77,
        "total_length": 143,
        "mean_pred_length": 15.88888888888889,
        "std_pred_length": 7.593044250342172,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 36,
        "distinct-1": 0.6853146853146853,
        "vocab_size-1": 98,
        "unique-1": 84,
        "entropy-1": 6.189918718566943,
        "distinct-2": 0.9626865671641791,
        "vocab_size-2": 129,
        "unique-2": 126,
        "entropy-2": 6.97653695165181,
        "cond_entropy-2": 0.6286497309200653,
        "distinct-3": 0.992,
        "vocab_size-3": 124,
        "unique-3": 123,
        "entropy-3": 6.949784284662096,
        "cond_entropy-3": -0.020304905795685557,
        "total_length-nopunct": 127,
        "mean_pred_length-nopunct": 14.11111111111111,
        "std_pred_length-nopunct": 7.046582220314634,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.7401574803149606,
        "vocab_size-1-nopunct": 94,
        "unique-1-nopunct": 82,
        "entropy-1-nopunct": 6.221094580824405,
        "distinct-2-nopunct": 0.9576271186440678,
        "vocab_size-2-nopunct": 113,
        "unique-2-nopunct": 110,
        "entropy-2-nopunct": 6.780948134107595,
        "cond_entropy-2-nopunct": 0.5915347901652829,
        "distinct-3-nopunct": 0.9908256880733946,
        "vocab_size-3-nopunct": 108,
        "unique-3-nopunct": 107,
        "entropy-3-nopunct": 6.749835700923704,
        "cond_entropy-3-nopunct": -0.022715605318860087,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.042025356701165,
        "bleu": 29.68986,
        "rouge1": {
            "precision": 0.74378,
            "recall": 0.74018,
            "fmeasure": 0.73383
        },
        "rouge2": {
            "precision": 0.48306,
            "recall": 0.47739,
            "fmeasure": 0.47406
        },
        "rougeL": {
            "precision": 0.62246,
            "recall": 0.62746,
            "fmeasure": 0.61687
        },
        "rougeLsum": {
            "precision": 0.62246,
            "recall": 0.62746,
            "fmeasure": 0.61687
        },
        "local_recall": {
            "1": 0.1891891891891892,
            "2": 0.5909090909090909,
            "3": 0.7910447761194029
        },
        "bertscore": {
            "precision": 0.91555,
            "recall": 0.92599,
            "f1": 0.91891
        },
        "bleurt": 0.33984,
        "meteor": 0.3727055011877841,
        "nubia": {
            "semantic_relation": 4.36989,
            "contradiction": 0.65036,
            "irrelevancy": 32.30447,
            "logical_agreement": 67.04517,
            "grammar_ref": 5.14381,
            "grammar_hyp": 5.00404,
            "nubia_score": 0.78048
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_105": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.716,
        "msttr-100_nopunct": 0.7675,
        "total_length": 567,
        "mean_pred_length": 15.75,
        "std_pred_length": 4.098610875785979,
        "median_pred_length": 15.5,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.5714285714285714,
        "vocab_size-1": 324,
        "unique-1": 270,
        "entropy-1": 7.417056455811312,
        "distinct-2": 0.928436911487759,
        "vocab_size-2": 493,
        "unique-2": 472,
        "entropy-2": 8.864407216532586,
        "cond_entropy-2": 1.2141455720899823,
        "distinct-3": 0.9959595959595959,
        "vocab_size-3": 493,
        "unique-3": 491,
        "entropy-3": 8.943203906886195,
        "cond_entropy-3": 0.0788348772861956,
        "total_length-nopunct": 496,
        "mean_pred_length-nopunct": 13.777777777777779,
        "std_pred_length-nopunct": 3.6599264648890233,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6391129032258065,
        "vocab_size-1-nopunct": 317,
        "unique-1-nopunct": 268,
        "entropy-1-nopunct": 7.580916654779448,
        "distinct-2-nopunct": 0.9260869565217391,
        "vocab_size-2-nopunct": 426,
        "unique-2-nopunct": 408,
        "entropy-2-nopunct": 8.647319365083375,
        "cond_entropy-2-nopunct": 1.147420411609108,
        "distinct-3-nopunct": 0.9952830188679245,
        "vocab_size-3-nopunct": 422,
        "unique-3-nopunct": 420,
        "entropy-3-nopunct": 8.7184864922991,
        "cond_entropy-3-nopunct": 0.08799294016616241,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.649194268129126,
        "bleu": 46.65482,
        "rouge1": {
            "precision": 0.7413,
            "recall": 0.77537,
            "fmeasure": 0.74725
        },
        "rouge2": {
            "precision": 0.5258,
            "recall": 0.55064,
            "fmeasure": 0.52949
        },
        "rougeL": {
            "precision": 0.65376,
            "recall": 0.67914,
            "fmeasure": 0.65658
        },
        "rougeLsum": {
            "precision": 0.65376,
            "recall": 0.67914,
            "fmeasure": 0.65658
        },
        "local_recall": {
            "1": 0.12962962962962962,
            "2": 0.5508474576271186,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.93141,
            "recall": 0.93479,
            "f1": 0.93168
        },
        "bleurt": 0.29076,
        "meteor": 0.41997895268003305,
        "nubia": {
            "semantic_relation": 4.20922,
            "contradiction": 8.27655,
            "irrelevancy": 44.72516,
            "logical_agreement": 46.99829,
            "grammar_ref": 4.61474,
            "grammar_hyp": 4.46546,
            "nubia_score": 0.72796
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_106": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 5.5,
        "median_pred_length": 18.5,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.8108108108108109,
        "vocab_size-1": 30,
        "unique-1": 24,
        "entropy-1": 4.810672622327237,
        "distinct-2": 0.9714285714285714,
        "vocab_size-2": 34,
        "unique-2": 33,
        "entropy-2": 5.072140159802107,
        "cond_entropy-2": 0.22711215137783003,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.024282836980452634,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.75,
        "distinct-2-nopunct": 0.9666666666666667,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.840223928941852,
        "cond_entropy-2-nopunct": 0.10689059560851857,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.028107102122342936,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8613525947664415,
        "bleu": 43.32383,
        "rouge1": {
            "precision": 0.69841,
            "recall": 0.67949,
            "fmeasure": 0.68081
        },
        "rouge2": {
            "precision": 0.525,
            "recall": 0.49309,
            "fmeasure": 0.50177
        },
        "rougeL": {
            "precision": 0.61328,
            "recall": 0.59117,
            "fmeasure": 0.59515
        },
        "rougeLsum": {
            "precision": 0.61328,
            "recall": 0.59117,
            "fmeasure": 0.59515
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.25,
            "3": 0.8333333333333334
        },
        "bertscore": {
            "precision": 0.86934,
            "recall": 0.90673,
            "f1": 0.88431
        },
        "bleurt": 0.26864,
        "meteor": 0.31446324030436174,
        "nubia": {
            "semantic_relation": 4.15143,
            "contradiction": 0.29267,
            "irrelevancy": 50.10516,
            "logical_agreement": 49.60217,
            "grammar_ref": 4.99819,
            "grammar_hyp": 5.0941,
            "nubia_score": 0.72253
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_24": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 169,
        "msttr-100": 0.70448,
        "msttr-100_nopunct": 0.7508,
        "total_length": 2922,
        "mean_pred_length": 17.28994082840237,
        "std_pred_length": 7.34717789858268,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 55,
        "distinct-1": 0.3932238193018481,
        "vocab_size-1": 1149,
        "unique-1": 881,
        "entropy-1": 8.40953334139045,
        "distinct-2": 0.767889575009081,
        "vocab_size-2": 2114,
        "unique-2": 1880,
        "entropy-2": 10.667871724609405,
        "cond_entropy-2": 1.9966835798215783,
        "distinct-3": 0.8897058823529411,
        "vocab_size-3": 2299,
        "unique-3": 2171,
        "entropy-3": 11.005424497961718,
        "cond_entropy-3": 0.3445106180714034,
        "total_length-nopunct": 2547,
        "mean_pred_length-nopunct": 15.071005917159763,
        "std_pred_length-nopunct": 6.2298897427695765,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.44680015704750686,
        "vocab_size-1-nopunct": 1138,
        "unique-1-nopunct": 879,
        "entropy-1-nopunct": 8.706953972138006,
        "distinct-2-nopunct": 0.7880571909167368,
        "vocab_size-2-nopunct": 1874,
        "unique-2-nopunct": 1696,
        "entropy-2-nopunct": 10.505533597287346,
        "cond_entropy-2-nopunct": 1.909454254244333,
        "distinct-3-nopunct": 0.8995020371208692,
        "vocab_size-3-nopunct": 1987,
        "unique-3-nopunct": 1888,
        "entropy-3-nopunct": 10.808535655439911,
        "cond_entropy-3-nopunct": 0.3363000715105135,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.181272343276998,
        "bleu": 48.9563,
        "rouge1": {
            "precision": 0.78293,
            "recall": 0.7697,
            "fmeasure": 0.76809
        },
        "rouge2": {
            "precision": 0.56999,
            "recall": 0.55663,
            "fmeasure": 0.55738
        },
        "rougeL": {
            "precision": 0.69141,
            "recall": 0.67999,
            "fmeasure": 0.67804
        },
        "rougeLsum": {
            "precision": 0.69141,
            "recall": 0.67999,
            "fmeasure": 0.67804
        },
        "local_recall": {
            "1": 0.20292887029288703,
            "2": 0.449438202247191,
            "3": 0.813034188034188
        },
        "bertscore": {
            "precision": 0.93606,
            "recall": 0.93294,
            "f1": 0.93319
        },
        "bleurt": 0.34937,
        "meteor": 0.4123341046114587,
        "nubia": {
            "semantic_relation": 4.27723,
            "contradiction": 9.58111,
            "irrelevancy": 27.25586,
            "logical_agreement": 63.16304,
            "grammar_ref": 4.66226,
            "grammar_hyp": 4.62773,
            "nubia_score": 0.76106
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_140": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 42,
        "msttr-100": 0.71833,
        "msttr-100_nopunct": 0.772,
        "total_length": 652,
        "mean_pred_length": 15.523809523809524,
        "std_pred_length": 4.48934238072102,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.5475460122699386,
        "vocab_size-1": 357,
        "unique-1": 284,
        "entropy-1": 7.567889378620646,
        "distinct-2": 0.8918032786885246,
        "vocab_size-2": 544,
        "unique-2": 495,
        "entropy-2": 8.995168222919702,
        "cond_entropy-2": 1.1762823014762236,
        "distinct-3": 0.9683098591549296,
        "vocab_size-3": 550,
        "unique-3": 533,
        "entropy-3": 9.085037810521953,
        "cond_entropy-3": 0.08645408636664735,
        "total_length-nopunct": 580,
        "mean_pred_length-nopunct": 13.80952380952381,
        "std_pred_length-nopunct": 4.078036964953646,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6051724137931035,
        "vocab_size-1-nopunct": 351,
        "unique-1-nopunct": 284,
        "entropy-1-nopunct": 7.734580419420946,
        "distinct-2-nopunct": 0.8940520446096655,
        "vocab_size-2-nopunct": 481,
        "unique-2-nopunct": 439,
        "entropy-2-nopunct": 8.8157680822419,
        "cond_entropy-2-nopunct": 1.1617898081035527,
        "distinct-3-nopunct": 0.9737903225806451,
        "vocab_size-3-nopunct": 483,
        "unique-3-nopunct": 470,
        "entropy-3-nopunct": 8.901776955548055,
        "cond_entropy-3-nopunct": 0.09153137284907659,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.839234228714815,
        "bleu": 44.99912,
        "rouge1": {
            "precision": 0.78166,
            "recall": 0.75,
            "fmeasure": 0.75874
        },
        "rouge2": {
            "precision": 0.53798,
            "recall": 0.52774,
            "fmeasure": 0.52831
        },
        "rougeL": {
            "precision": 0.66841,
            "recall": 0.65313,
            "fmeasure": 0.65483
        },
        "rougeLsum": {
            "precision": 0.66841,
            "recall": 0.65313,
            "fmeasure": 0.65483
        },
        "local_recall": {
            "1": 0.2413793103448276,
            "2": 0.49056603773584906,
            "3": 0.7595505617977528
        },
        "bertscore": {
            "precision": 0.93422,
            "recall": 0.92945,
            "f1": 0.93032
        },
        "bleurt": 0.28483,
        "meteor": 0.3988916335913757,
        "nubia": {
            "semantic_relation": 4.27212,
            "contradiction": 12.78305,
            "irrelevancy": 24.2525,
            "logical_agreement": 62.96445,
            "grammar_ref": 4.66791,
            "grammar_hyp": 4.69932,
            "nubia_score": 0.74423
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_141": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 81,
        "mean_pred_length": 16.2,
        "std_pred_length": 7.0823724838503095,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 30,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 63,
        "unique-1": 58,
        "entropy-1": 5.693693256864402,
        "distinct-2": 1.0,
        "vocab_size-2": 76,
        "unique-2": 76,
        "entropy-2": 6.247927513443591,
        "cond_entropy-2": 0.44398614152212657,
        "distinct-3": 1.0,
        "vocab_size-3": 71,
        "unique-3": 71,
        "entropy-3": 6.149747119504677,
        "cond_entropy-3": -0.09818039393890347,
        "total_length-nopunct": 71,
        "mean_pred_length-nopunct": 14.2,
        "std_pred_length-nopunct": 6.046486583132389,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8591549295774648,
        "vocab_size-1-nopunct": 61,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.739614507127723,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 66,
        "unique-2-nopunct": 66,
        "entropy-2-nopunct": 6.044394119358462,
        "cond_entropy-2-nopunct": 0.33585026468352525,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 61,
        "unique-3-nopunct": 61,
        "entropy-3-nopunct": 5.930737337562883,
        "cond_entropy-3-nopunct": -0.11365678179556746,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5901516920210557,
        "bleu": 29.68761,
        "rouge1": {
            "precision": 0.79228,
            "recall": 0.67516,
            "fmeasure": 0.7224
        },
        "rouge2": {
            "precision": 0.48442,
            "recall": 0.41295,
            "fmeasure": 0.44101
        },
        "rougeL": {
            "precision": 0.64025,
            "recall": 0.55089,
            "fmeasure": 0.58681
        },
        "rougeLsum": {
            "precision": 0.64025,
            "recall": 0.55089,
            "fmeasure": 0.58681
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.6944444444444444
        },
        "bertscore": {
            "precision": 0.92175,
            "recall": 0.89588,
            "f1": 0.90843
        },
        "bleurt": 0.34304,
        "meteor": 0.34485387004297335,
        "nubia": {
            "semantic_relation": 4.27194,
            "contradiction": 0.24202,
            "irrelevancy": 20.62052,
            "logical_agreement": 79.13746,
            "grammar_ref": 4.6156,
            "grammar_hyp": 4.8511,
            "nubia_score": 0.76894
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_162": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 26,
        "msttr-100": 0.7325,
        "msttr-100_nopunct": 0.7575,
        "total_length": 453,
        "mean_pred_length": 17.423076923076923,
        "std_pred_length": 6.233736235647231,
        "median_pred_length": 16.5,
        "min_pred_length": 7,
        "max_pred_length": 33,
        "distinct-1": 0.5805739514348786,
        "vocab_size-1": 263,
        "unique-1": 213,
        "entropy-1": 7.304757662824807,
        "distinct-2": 0.9110070257611241,
        "vocab_size-2": 389,
        "unique-2": 360,
        "entropy-2": 8.537895670732054,
        "cond_entropy-2": 1.0393965941744547,
        "distinct-3": 0.970074812967581,
        "vocab_size-3": 389,
        "unique-3": 377,
        "entropy-3": 8.587608052390005,
        "cond_entropy-3": 0.05770517794506392,
        "total_length-nopunct": 401,
        "mean_pred_length-nopunct": 15.423076923076923,
        "std_pred_length-nopunct": 5.6376009417746324,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.6384039900249376,
        "vocab_size-1-nopunct": 256,
        "unique-1-nopunct": 211,
        "entropy-1-nopunct": 7.401346731807488,
        "distinct-2-nopunct": 0.912,
        "vocab_size-2-nopunct": 342,
        "unique-2-nopunct": 318,
        "entropy-2-nopunct": 8.34945626950227,
        "cond_entropy-2-nopunct": 1.0111602485178528,
        "distinct-3-nopunct": 0.9656160458452722,
        "vocab_size-3-nopunct": 337,
        "unique-3-nopunct": 325,
        "entropy-3-nopunct": 8.378315317900231,
        "cond_entropy-3-nopunct": 0.043854903449228995,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.46810903290961,
        "bleu": 49.63797,
        "rouge1": {
            "precision": 0.74991,
            "recall": 0.7163,
            "fmeasure": 0.72318
        },
        "rouge2": {
            "precision": 0.52443,
            "recall": 0.50463,
            "fmeasure": 0.50721
        },
        "rougeL": {
            "precision": 0.64039,
            "recall": 0.62123,
            "fmeasure": 0.62257
        },
        "rougeLsum": {
            "precision": 0.64039,
            "recall": 0.62123,
            "fmeasure": 0.62257
        },
        "local_recall": {
            "1": 0.18823529411764706,
            "2": 0.6044776119402985,
            "3": 0.7244094488188977
        },
        "bertscore": {
            "precision": 0.92696,
            "recall": 0.92472,
            "f1": 0.9234
        },
        "bleurt": 0.22595,
        "meteor": 0.40341600881138784,
        "nubia": {
            "semantic_relation": 4.21805,
            "contradiction": 7.27482,
            "irrelevancy": 38.34114,
            "logical_agreement": 54.38404,
            "grammar_ref": 4.52061,
            "grammar_hyp": 4.63237,
            "nubia_score": 0.73098
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_164": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.69,
        "total_length": 175,
        "mean_pred_length": 14.583333333333334,
        "std_pred_length": 5.55965126804031,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.5714285714285714,
        "vocab_size-1": 100,
        "unique-1": 70,
        "entropy-1": 6.132939275262337,
        "distinct-2": 0.8834355828220859,
        "vocab_size-2": 144,
        "unique-2": 131,
        "entropy-2": 7.084804534546104,
        "cond_entropy-2": 0.7849923269535903,
        "distinct-3": 0.9536423841059603,
        "vocab_size-3": 144,
        "unique-3": 138,
        "entropy-3": 7.140690252555766,
        "cond_entropy-3": 0.07685978050122284,
        "total_length-nopunct": 152,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 5.467073155618909,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.631578947368421,
        "vocab_size-1-nopunct": 96,
        "unique-1-nopunct": 70,
        "entropy-1-nopunct": 6.152147211388778,
        "distinct-2-nopunct": 0.8928571428571429,
        "vocab_size-2-nopunct": 125,
        "unique-2-nopunct": 114,
        "entropy-2-nopunct": 6.889927481199784,
        "cond_entropy-2-nopunct": 0.7918117064105314,
        "distinct-3-nopunct": 0.9609375,
        "vocab_size-3-nopunct": 123,
        "unique-3-nopunct": 118,
        "entropy-3-nopunct": 6.921875,
        "cond_entropy-3-nopunct": 0.03876210027633781,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.907860476768842,
        "bleu": 35.88085,
        "rouge1": {
            "precision": 0.77762,
            "recall": 0.71513,
            "fmeasure": 0.73233
        },
        "rouge2": {
            "precision": 0.49105,
            "recall": 0.43543,
            "fmeasure": 0.45059
        },
        "rougeL": {
            "precision": 0.65567,
            "recall": 0.60483,
            "fmeasure": 0.61836
        },
        "rougeLsum": {
            "precision": 0.65567,
            "recall": 0.60483,
            "fmeasure": 0.61836
        },
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.4523809523809524,
            "3": 0.6822429906542056
        },
        "bertscore": {
            "precision": 0.89646,
            "recall": 0.89338,
            "f1": 0.89218
        },
        "bleurt": 0.0229,
        "meteor": 0.35984262704933556,
        "nubia": {
            "semantic_relation": 4.11773,
            "contradiction": 14.99922,
            "irrelevancy": 19.50159,
            "logical_agreement": 65.49919,
            "grammar_ref": 4.9625,
            "grammar_hyp": 5.26261,
            "nubia_score": 0.6645
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_108": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 51,
        "msttr-100": 0.745,
        "msttr-100_nopunct": 0.79429,
        "total_length": 848,
        "mean_pred_length": 16.627450980392158,
        "std_pred_length": 6.302694053024345,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 37,
        "distinct-1": 0.5507075471698113,
        "vocab_size-1": 467,
        "unique-1": 392,
        "entropy-1": 7.765940450917246,
        "distinct-2": 0.9159347553324969,
        "vocab_size-2": 730,
        "unique-2": 687,
        "entropy-2": 9.415871198826968,
        "cond_entropy-2": 1.4107068514992507,
        "distinct-3": 0.985254691689008,
        "vocab_size-3": 735,
        "unique-3": 725,
        "entropy-3": 9.512529290091392,
        "cond_entropy-3": 0.09094919045867225,
        "total_length-nopunct": 739,
        "mean_pred_length-nopunct": 14.490196078431373,
        "std_pred_length-nopunct": 5.517787809846843,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6238159675236806,
        "vocab_size-1-nopunct": 461,
        "unique-1-nopunct": 390,
        "entropy-1-nopunct": 8.007422873226364,
        "distinct-2-nopunct": 0.9287790697674418,
        "vocab_size-2-nopunct": 639,
        "unique-2-nopunct": 608,
        "entropy-2-nopunct": 9.229302872428338,
        "cond_entropy-2-nopunct": 1.3090060046105096,
        "distinct-3-nopunct": 0.9921507064364207,
        "vocab_size-3-nopunct": 632,
        "unique-3-nopunct": 627,
        "entropy-3-nopunct": 9.299450975129231,
        "cond_entropy-3-nopunct": 0.08434756266303643,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.2728282426784645,
        "bleu": 48.87613,
        "rouge1": {
            "precision": 0.79349,
            "recall": 0.76002,
            "fmeasure": 0.76487
        },
        "rouge2": {
            "precision": 0.55217,
            "recall": 0.53012,
            "fmeasure": 0.53205
        },
        "rougeL": {
            "precision": 0.66021,
            "recall": 0.6418,
            "fmeasure": 0.64125
        },
        "rougeLsum": {
            "precision": 0.66021,
            "recall": 0.6418,
            "fmeasure": 0.64125
        },
        "local_recall": {
            "1": 0.21875,
            "2": 0.45652173913043476,
            "3": 0.8010849909584087
        },
        "bertscore": {
            "precision": 0.93711,
            "recall": 0.9327,
            "f1": 0.93306
        },
        "bleurt": 0.32598,
        "meteor": 0.4018432715556138,
        "nubia": {
            "semantic_relation": 4.27982,
            "contradiction": 3.70649,
            "irrelevancy": 29.90402,
            "logical_agreement": 66.38949,
            "grammar_ref": 4.80362,
            "grammar_hyp": 4.79456,
            "nubia_score": 0.73714
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_25": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 56,
        "msttr-100": 0.73875,
        "msttr-100_nopunct": 0.79286,
        "total_length": 899,
        "mean_pred_length": 16.053571428571427,
        "std_pred_length": 5.755182890407639,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.5116796440489433,
        "vocab_size-1": 460,
        "unique-1": 376,
        "entropy-1": 7.730687251212653,
        "distinct-2": 0.8873072360616845,
        "vocab_size-2": 748,
        "unique-2": 695,
        "entropy-2": 9.436638079575513,
        "cond_entropy-2": 1.4567475095580356,
        "distinct-3": 0.9644218551461246,
        "vocab_size-3": 759,
        "unique-3": 738,
        "entropy-3": 9.54110335472413,
        "cond_entropy-3": 0.11187828851155204,
        "total_length-nopunct": 784,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.102520385624567,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5778061224489796,
        "vocab_size-1-nopunct": 453,
        "unique-1-nopunct": 375,
        "entropy-1-nopunct": 7.9704767028000365,
        "distinct-2-nopunct": 0.896978021978022,
        "vocab_size-2-nopunct": 653,
        "unique-2-nopunct": 614,
        "entropy-2-nopunct": 9.242218644369787,
        "cond_entropy-2-nopunct": 1.3666769897095905,
        "distinct-3-nopunct": 0.9627976190476191,
        "vocab_size-3-nopunct": 647,
        "unique-3-nopunct": 628,
        "entropy-3-nopunct": 9.30971359092711,
        "cond_entropy-3-nopunct": 0.0857796091550753,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.636681000088457,
        "bleu": 42.28118,
        "rouge1": {
            "precision": 0.77228,
            "recall": 0.69215,
            "fmeasure": 0.71758
        },
        "rouge2": {
            "precision": 0.51842,
            "recall": 0.45332,
            "fmeasure": 0.47571
        },
        "rougeL": {
            "precision": 0.6782,
            "recall": 0.59938,
            "fmeasure": 0.62588
        },
        "rougeLsum": {
            "precision": 0.6782,
            "recall": 0.59938,
            "fmeasure": 0.62588
        },
        "local_recall": {
            "1": 0.17989417989417988,
            "2": 0.4050632911392405,
            "3": 0.7383177570093458
        },
        "bertscore": {
            "precision": 0.92584,
            "recall": 0.91218,
            "f1": 0.91712
        },
        "bleurt": 0.22703,
        "meteor": 0.37938776689031817,
        "nubia": {
            "semantic_relation": 4.19409,
            "contradiction": 7.69992,
            "irrelevancy": 28.76817,
            "logical_agreement": 63.53191,
            "grammar_ref": 4.75668,
            "grammar_hyp": 4.89624,
            "nubia_score": 0.70398
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_192": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.732,
        "msttr-100_nopunct": 0.79,
        "total_length": 538,
        "mean_pred_length": 17.35483870967742,
        "std_pred_length": 7.087236993341755,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.5724907063197026,
        "vocab_size-1": 308,
        "unique-1": 256,
        "entropy-1": 7.364312275478574,
        "distinct-2": 0.9132149901380671,
        "vocab_size-2": 463,
        "unique-2": 432,
        "entropy-2": 8.78164906237755,
        "cond_entropy-2": 1.2187994438563547,
        "distinct-3": 0.9663865546218487,
        "vocab_size-3": 460,
        "unique-3": 444,
        "entropy-3": 8.82759087255171,
        "cond_entropy-3": 0.055038404950255575,
        "total_length-nopunct": 475,
        "mean_pred_length-nopunct": 15.32258064516129,
        "std_pred_length-nopunct": 6.457739026955995,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6336842105263157,
        "vocab_size-1-nopunct": 301,
        "unique-1-nopunct": 253,
        "entropy-1-nopunct": 7.527420179625505,
        "distinct-2-nopunct": 0.9121621621621622,
        "vocab_size-2-nopunct": 405,
        "unique-2-nopunct": 378,
        "entropy-2-nopunct": 8.585472398032179,
        "cond_entropy-2-nopunct": 1.1394156063118444,
        "distinct-3-nopunct": 0.9661016949152542,
        "vocab_size-3-nopunct": 399,
        "unique-3-nopunct": 385,
        "entropy-3-nopunct": 8.62220136124996,
        "cond_entropy-3-nopunct": 0.04756975623923487,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.108949407503761,
        "bleu": 39.76044,
        "rouge1": {
            "precision": 0.75064,
            "recall": 0.69667,
            "fmeasure": 0.70824
        },
        "rouge2": {
            "precision": 0.49669,
            "recall": 0.45666,
            "fmeasure": 0.46738
        },
        "rougeL": {
            "precision": 0.58347,
            "recall": 0.55538,
            "fmeasure": 0.55894
        },
        "rougeLsum": {
            "precision": 0.58347,
            "recall": 0.55538,
            "fmeasure": 0.55894
        },
        "local_recall": {
            "1": 0.21518987341772153,
            "2": 0.43333333333333335,
            "3": 0.7267605633802817
        },
        "bertscore": {
            "precision": 0.92114,
            "recall": 0.90951,
            "f1": 0.91341
        },
        "bleurt": 0.20511,
        "meteor": 0.3732928948717541,
        "nubia": {
            "semantic_relation": 4.14626,
            "contradiction": 9.49878,
            "irrelevancy": 30.20121,
            "logical_agreement": 60.30001,
            "grammar_ref": 4.61479,
            "grammar_hyp": 4.69913,
            "nubia_score": 0.69106
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_165": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 19,
        "msttr-100": 0.69333,
        "msttr-100_nopunct": 0.74333,
        "total_length": 349,
        "mean_pred_length": 18.36842105263158,
        "std_pred_length": 6.975223266117606,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.5587392550143266,
        "vocab_size-1": 195,
        "unique-1": 153,
        "entropy-1": 6.92127334597434,
        "distinct-2": 0.9030303030303031,
        "vocab_size-2": 298,
        "unique-2": 272,
        "entropy-2": 8.15111145664388,
        "cond_entropy-2": 1.0688494861895428,
        "distinct-3": 0.9614147909967846,
        "vocab_size-3": 299,
        "unique-3": 287,
        "entropy-3": 8.203600352124186,
        "cond_entropy-3": 0.0439169240728585,
        "total_length-nopunct": 302,
        "mean_pred_length-nopunct": 15.894736842105264,
        "std_pred_length-nopunct": 5.79377830400949,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6291390728476821,
        "vocab_size-1-nopunct": 190,
        "unique-1-nopunct": 152,
        "entropy-1-nopunct": 7.029760910588605,
        "distinct-2-nopunct": 0.9151943462897526,
        "vocab_size-2-nopunct": 259,
        "unique-2-nopunct": 240,
        "entropy-2-nopunct": 7.95291031878066,
        "cond_entropy-2-nopunct": 0.9612918383848521,
        "distinct-3-nopunct": 0.9621212121212122,
        "vocab_size-3-nopunct": 254,
        "unique-3-nopunct": 244,
        "entropy-3-nopunct": 7.968636543600886,
        "cond_entropy-3-nopunct": 0.017518973136601647,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.649504866088473,
        "bleu": 35.25558,
        "rouge1": {
            "precision": 0.71841,
            "recall": 0.72484,
            "fmeasure": 0.71225
        },
        "rouge2": {
            "precision": 0.42274,
            "recall": 0.43489,
            "fmeasure": 0.42181
        },
        "rougeL": {
            "precision": 0.59849,
            "recall": 0.61416,
            "fmeasure": 0.59787
        },
        "rougeLsum": {
            "precision": 0.59849,
            "recall": 0.61416,
            "fmeasure": 0.59787
        },
        "local_recall": {
            "1": 0.19672131147540983,
            "2": 0.4067796610169492,
            "3": 0.7342995169082126
        },
        "bertscore": {
            "precision": 0.90764,
            "recall": 0.91383,
            "f1": 0.90848
        },
        "bleurt": 0.1478,
        "meteor": 0.36536104022597876,
        "nubia": {
            "semantic_relation": 3.96626,
            "contradiction": 13.15911,
            "irrelevancy": 43.60527,
            "logical_agreement": 43.23562,
            "grammar_ref": 4.52561,
            "grammar_hyp": 4.43239,
            "nubia_score": 0.67519
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_110": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.736,
        "msttr-100_nopunct": 0.82,
        "total_length": 580,
        "mean_pred_length": 18.70967741935484,
        "std_pred_length": 7.927874662867424,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 38,
        "distinct-1": 0.5586206896551724,
        "vocab_size-1": 324,
        "unique-1": 255,
        "entropy-1": 7.489342973699742,
        "distinct-2": 0.9198542805100182,
        "vocab_size-2": 505,
        "unique-2": 473,
        "entropy-2": 8.917548814391438,
        "cond_entropy-2": 1.2413343463487743,
        "distinct-3": 0.9633204633204633,
        "vocab_size-3": 499,
        "unique-3": 482,
        "entropy-3": 8.940534590766923,
        "cond_entropy-3": 0.014639288466401477,
        "total_length-nopunct": 497,
        "mean_pred_length-nopunct": 16.032258064516128,
        "std_pred_length-nopunct": 6.698501859312212,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.641851106639839,
        "vocab_size-1-nopunct": 319,
        "unique-1-nopunct": 254,
        "entropy-1-nopunct": 7.750754736008428,
        "distinct-2-nopunct": 0.9291845493562232,
        "vocab_size-2-nopunct": 433,
        "unique-2-nopunct": 409,
        "entropy-2-nopunct": 8.701580055575217,
        "cond_entropy-2-nopunct": 1.0042693396867313,
        "distinct-3-nopunct": 0.9632183908045977,
        "vocab_size-3-nopunct": 419,
        "unique-3-nopunct": 404,
        "entropy-3-nopunct": 8.689572998777054,
        "cond_entropy-3-nopunct": -0.005016737806341712,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.971107395317683,
        "bleu": 47.07316,
        "rouge1": {
            "precision": 0.78432,
            "recall": 0.74636,
            "fmeasure": 0.7567
        },
        "rouge2": {
            "precision": 0.54571,
            "recall": 0.51718,
            "fmeasure": 0.52564
        },
        "rougeL": {
            "precision": 0.67509,
            "recall": 0.64764,
            "fmeasure": 0.65539
        },
        "rougeLsum": {
            "precision": 0.67509,
            "recall": 0.64764,
            "fmeasure": 0.65539
        },
        "local_recall": {
            "1": 0.2702702702702703,
            "2": 0.43373493975903615,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.93478,
            "recall": 0.9328,
            "f1": 0.93307
        },
        "bleurt": 0.36719,
        "meteor": 0.4098248161800817,
        "nubia": {
            "semantic_relation": 4.34391,
            "contradiction": 8.45508,
            "irrelevancy": 27.42581,
            "logical_agreement": 64.11911,
            "grammar_ref": 4.88113,
            "grammar_hyp": 4.83059,
            "nubia_score": 0.78215
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_143": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.71,
        "total_length": 136,
        "mean_pred_length": 13.6,
        "std_pred_length": 3.5552777669262356,
        "median_pred_length": 11.5,
        "min_pred_length": 10,
        "max_pred_length": 20,
        "distinct-1": 0.5808823529411765,
        "vocab_size-1": 79,
        "unique-1": 58,
        "entropy-1": 5.822115029562894,
        "distinct-2": 0.873015873015873,
        "vocab_size-2": 110,
        "unique-2": 100,
        "entropy-2": 6.667600955177274,
        "cond_entropy-2": 0.6822652682175485,
        "distinct-3": 0.9310344827586207,
        "vocab_size-3": 108,
        "unique-3": 101,
        "entropy-3": 6.713542309764079,
        "cond_entropy-3": 0.031647407871853196,
        "total_length-nopunct": 121,
        "mean_pred_length-nopunct": 12.1,
        "std_pred_length-nopunct": 3.144837038703278,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6363636363636364,
        "vocab_size-1-nopunct": 77,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.8671410805293,
        "distinct-2-nopunct": 0.8738738738738738,
        "vocab_size-2-nopunct": 97,
        "unique-2-nopunct": 88,
        "entropy-2-nopunct": 6.485725213138495,
        "cond_entropy-2-nopunct": 0.6412618043880426,
        "distinct-3-nopunct": 0.9306930693069307,
        "vocab_size-3-nopunct": 94,
        "unique-3-nopunct": 88,
        "entropy-3-nopunct": 6.512123487680854,
        "cond_entropy-3-nopunct": 0.02725873525641078,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.340206413854045,
        "bleu": 29.0843,
        "rouge1": {
            "precision": 0.7045,
            "recall": 0.63424,
            "fmeasure": 0.64273
        },
        "rouge2": {
            "precision": 0.44397,
            "recall": 0.42828,
            "fmeasure": 0.41115
        },
        "rougeL": {
            "precision": 0.54301,
            "recall": 0.52377,
            "fmeasure": 0.51402
        },
        "rougeLsum": {
            "precision": 0.54301,
            "recall": 0.52377,
            "fmeasure": 0.51402
        },
        "local_recall": {
            "1": 0.1864406779661017,
            "2": 0.19230769230769232,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.91709,
            "recall": 0.9033,
            "f1": 0.90506
        },
        "bleurt": 0.17996,
        "meteor": 0.3193617333095598,
        "nubia": {
            "semantic_relation": 3.94366,
            "contradiction": 0.80763,
            "irrelevancy": 57.17019,
            "logical_agreement": 42.02218,
            "grammar_ref": 4.73444,
            "grammar_hyp": 4.67573,
            "nubia_score": 0.6303
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_111": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3407687512419906,
        "bleu": 54.99955,
        "rouge1": {
            "precision": 0.79167,
            "recall": 0.86905,
            "fmeasure": 0.82778
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.66154,
            "fmeasure": 0.62857
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.82143,
            "fmeasure": 0.78333
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.82143,
            "fmeasure": 0.78333
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.25,
            "3": 0.9166666666666666
        },
        "bertscore": {
            "precision": 0.94573,
            "recall": 0.98364,
            "f1": 0.96431
        },
        "bleurt": 0.52606,
        "meteor": 0.5123416903202861,
        "nubia": {
            "semantic_relation": 4.71228,
            "contradiction": 0.1415,
            "irrelevancy": 0.43508,
            "logical_agreement": 99.42343,
            "grammar_ref": 3.66146,
            "grammar_hyp": 3.38838,
            "nubia_score": 0.95081
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_194": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.9378301182341215,
        "bleu": 7.27072,
        "rouge1": {
            "precision": 0.375,
            "recall": 0.25,
            "fmeasure": 0.3
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.09091,
            "fmeasure": 0.11111
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.16667,
            "fmeasure": 0.2
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.16667,
            "fmeasure": 0.2
        },
        "local_recall": {
            "1": 0,
            "2": 0.375
        },
        "bertscore": {
            "precision": 0.82186,
            "recall": 0.82518,
            "f1": 0.82352
        },
        "bleurt": -0.95211,
        "meteor": 0.14214671908952747,
        "nubia": {
            "semantic_relation": 2.42136,
            "contradiction": 0.74708,
            "irrelevancy": 99.1604,
            "logical_agreement": 0.09251,
            "grammar_ref": 3.85254,
            "grammar_hyp": 5.89346,
            "nubia_score": 0.12041
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 898,
        "msttr-100": 0.7101,
        "msttr-100_nopunct": 0.7619,
        "total_length": 9743,
        "mean_pred_length": 10.849665924276168,
        "std_pred_length": 3.706477941424208,
        "median_pred_length": 10.0,
        "min_pred_length": 4,
        "max_pred_length": 37,
        "distinct-1": 0.33398337267781997,
        "vocab_size-1": 3254,
        "unique-1": 2442,
        "entropy-1": 9.047963333828982,
        "distinct-2": 0.6781232334652346,
        "vocab_size-2": 5998,
        "unique-2": 5195,
        "entropy-2": 11.859393764925406,
        "cond_entropy-2": 2.241543460072081,
        "distinct-3": 0.8277337360010066,
        "vocab_size-3": 6578,
        "unique-3": 6000,
        "entropy-3": 12.435763287116306,
        "cond_entropy-3": 0.5383660226708481,
        "total_length-nopunct": 8471,
        "mean_pred_length-nopunct": 9.433184855233852,
        "std_pred_length-nopunct": 3.2254712698110373,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.3825994569708417,
        "vocab_size-1-nopunct": 3241,
        "unique-1-nopunct": 2439,
        "entropy-1-nopunct": 9.534601549796097,
        "distinct-2-nopunct": 0.7031559487653506,
        "vocab_size-2-nopunct": 5325,
        "unique-2-nopunct": 4678,
        "entropy-2-nopunct": 11.719908930862983,
        "cond_entropy-2-nopunct": 2.377157247585958,
        "distinct-3-nopunct": 0.8361048689138577,
        "vocab_size-3-nopunct": 5581,
        "unique-3-nopunct": 5113,
        "entropy-3-nopunct": 12.208842095329029,
        "cond_entropy-3-nopunct": 0.5667389247945047,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.673396962134722,
        "bleu": 50.01615,
        "rouge1": {
            "precision": 0.7557,
            "recall": 0.71898,
            "fmeasure": 0.72064
        },
        "rouge2": {
            "precision": 0.56483,
            "recall": 0.539,
            "fmeasure": 0.53866
        },
        "rougeL": {
            "precision": 0.71763,
            "recall": 0.68638,
            "fmeasure": 0.68647
        },
        "rougeLsum": {
            "precision": 0.71763,
            "recall": 0.68638,
            "fmeasure": 0.68647
        },
        "local_recall": {
            "1": 0.22625698324022347,
            "2": 0.5287846481876333,
            "3": 0.7477344183465877
        },
        "bertscore": {
            "precision": 0.93129,
            "recall": 0.92506,
            "f1": 0.92652
        },
        "bleurt": 0.31085,
        "meteor": 0.40108017960539044,
        "nubia": {
            "semantic_relation": 4.10062,
            "contradiction": 9.9743,
            "irrelevancy": 30.00118,
            "logical_agreement": 60.02452,
            "grammar_ref": 5.09815,
            "grammar_hyp": 5.14217,
            "nubia_score": 0.70055
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_112": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 47,
        "msttr-100": 0.69875,
        "msttr-100_nopunct": 0.775,
        "total_length": 804,
        "mean_pred_length": 17.106382978723403,
        "std_pred_length": 5.199157225294048,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 32,
        "distinct-1": 0.5111940298507462,
        "vocab_size-1": 411,
        "unique-1": 316,
        "entropy-1": 7.623892447510638,
        "distinct-2": 0.8797886393659181,
        "vocab_size-2": 666,
        "unique-2": 603,
        "entropy-2": 9.269224283953767,
        "cond_entropy-2": 1.424437842940481,
        "distinct-3": 0.9507042253521126,
        "vocab_size-3": 675,
        "unique-3": 641,
        "entropy-3": 9.37202044326219,
        "cond_entropy-3": 0.09484082082841205,
        "total_length-nopunct": 695,
        "mean_pred_length-nopunct": 14.787234042553191,
        "std_pred_length-nopunct": 4.667388764758544,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.5827338129496403,
        "vocab_size-1-nopunct": 405,
        "unique-1-nopunct": 315,
        "entropy-1-nopunct": 7.861684942844335,
        "distinct-2-nopunct": 0.8873456790123457,
        "vocab_size-2-nopunct": 575,
        "unique-2-nopunct": 524,
        "entropy-2-nopunct": 9.0617036588143,
        "cond_entropy-2-nopunct": 1.2735212912730858,
        "distinct-3-nopunct": 0.9534109816971714,
        "vocab_size-3-nopunct": 573,
        "unique-3-nopunct": 545,
        "entropy-3-nopunct": 9.138043144105598,
        "cond_entropy-3-nopunct": 0.09143578840480893,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.700546688742538,
        "bleu": 46.64582,
        "rouge1": {
            "precision": 0.78473,
            "recall": 0.73647,
            "fmeasure": 0.74662
        },
        "rouge2": {
            "precision": 0.55084,
            "recall": 0.51731,
            "fmeasure": 0.52282
        },
        "rougeL": {
            "precision": 0.6856,
            "recall": 0.64781,
            "fmeasure": 0.65439
        },
        "rougeLsum": {
            "precision": 0.6856,
            "recall": 0.64781,
            "fmeasure": 0.65439
        },
        "local_recall": {
            "1": 0.1875,
            "2": 0.3488372093023256,
            "3": 0.7745454545454545
        },
        "bertscore": {
            "precision": 0.92698,
            "recall": 0.92229,
            "f1": 0.9227
        },
        "bleurt": 0.2722,
        "meteor": 0.3985141485406163,
        "nubia": {
            "semantic_relation": 4.17803,
            "contradiction": 8.31354,
            "irrelevancy": 30.81849,
            "logical_agreement": 60.86796,
            "grammar_ref": 4.39993,
            "grammar_hyp": 4.33667,
            "nubia_score": 0.7206
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_210": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.7775,
        "total_length": 476,
        "mean_pred_length": 15.35483870967742,
        "std_pred_length": 6.537970421472549,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 34,
        "distinct-1": 0.5462184873949579,
        "vocab_size-1": 260,
        "unique-1": 201,
        "entropy-1": 7.219956139388985,
        "distinct-2": 0.9011235955056179,
        "vocab_size-2": 401,
        "unique-2": 373,
        "entropy-2": 8.555247361851649,
        "cond_entropy-2": 1.1036523692975395,
        "distinct-3": 0.966183574879227,
        "vocab_size-3": 400,
        "unique-3": 389,
        "entropy-3": 8.620383907966769,
        "cond_entropy-3": 0.06396465984468842,
        "total_length-nopunct": 414,
        "mean_pred_length-nopunct": 13.35483870967742,
        "std_pred_length-nopunct": 5.550637203158049,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6159420289855072,
        "vocab_size-1-nopunct": 255,
        "unique-1-nopunct": 200,
        "entropy-1-nopunct": 7.40531249063669,
        "distinct-2-nopunct": 0.9060052219321149,
        "vocab_size-2-nopunct": 347,
        "unique-2-nopunct": 327,
        "entropy-2-nopunct": 8.341319895290637,
        "cond_entropy-2-nopunct": 0.9865680829291212,
        "distinct-3-nopunct": 0.9659090909090909,
        "vocab_size-3-nopunct": 340,
        "unique-3-nopunct": 331,
        "entropy-3-nopunct": 8.384816100152918,
        "cond_entropy-3-nopunct": 0.04993477385152928,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.219653809735197,
        "bleu": 41.5579,
        "rouge1": {
            "precision": 0.77237,
            "recall": 0.71174,
            "fmeasure": 0.72827
        },
        "rouge2": {
            "precision": 0.50522,
            "recall": 0.46311,
            "fmeasure": 0.4754
        },
        "rougeL": {
            "precision": 0.64042,
            "recall": 0.5879,
            "fmeasure": 0.60211
        },
        "rougeLsum": {
            "precision": 0.64042,
            "recall": 0.5879,
            "fmeasure": 0.60211
        },
        "local_recall": {
            "1": 0.23469387755102042,
            "2": 0.4329896907216495,
            "3": 0.785234899328859
        },
        "bertscore": {
            "precision": 0.92668,
            "recall": 0.92368,
            "f1": 0.92417
        },
        "bleurt": 0.27012,
        "meteor": 0.38030521416778934,
        "nubia": {
            "semantic_relation": 4.21719,
            "contradiction": 5.08945,
            "irrelevancy": 27.57529,
            "logical_agreement": 67.33525,
            "grammar_ref": 4.50561,
            "grammar_hyp": 4.45569,
            "nubia_score": 0.74497
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_168": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 44,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.77833,
        "total_length": 680,
        "mean_pred_length": 15.454545454545455,
        "std_pred_length": 5.454166653513397,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 33,
        "distinct-1": 0.5220588235294118,
        "vocab_size-1": 355,
        "unique-1": 282,
        "entropy-1": 7.563447742085336,
        "distinct-2": 0.8679245283018868,
        "vocab_size-2": 552,
        "unique-2": 502,
        "entropy-2": 8.992137126674928,
        "cond_entropy-2": 1.1786996193669363,
        "distinct-3": 0.9391891891891891,
        "vocab_size-3": 556,
        "unique-3": 531,
        "entropy-3": 9.0738051181225,
        "cond_entropy-3": 0.07720503360396508,
        "total_length-nopunct": 608,
        "mean_pred_length-nopunct": 13.818181818181818,
        "std_pred_length-nopunct": 5.1666444503210265,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.5740131578947368,
        "vocab_size-1-nopunct": 349,
        "unique-1-nopunct": 281,
        "entropy-1-nopunct": 7.722369104834466,
        "distinct-2-nopunct": 0.8723404255319149,
        "vocab_size-2-nopunct": 492,
        "unique-2-nopunct": 451,
        "entropy-2-nopunct": 8.825296991594898,
        "cond_entropy-2-nopunct": 1.1697132282460128,
        "distinct-3-nopunct": 0.9384615384615385,
        "vocab_size-3-nopunct": 488,
        "unique-3-nopunct": 467,
        "entropy-3-nopunct": 8.883322115867424,
        "cond_entropy-3-nopunct": 0.07467371441447856,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.970872328677514,
        "bleu": 50.35888,
        "rouge1": {
            "precision": 0.78527,
            "recall": 0.75016,
            "fmeasure": 0.75473
        },
        "rouge2": {
            "precision": 0.57733,
            "recall": 0.563,
            "fmeasure": 0.56119
        },
        "rougeL": {
            "precision": 0.70786,
            "recall": 0.68497,
            "fmeasure": 0.68447
        },
        "rougeLsum": {
            "precision": 0.70786,
            "recall": 0.68497,
            "fmeasure": 0.68447
        },
        "local_recall": {
            "1": 0.22857142857142856,
            "2": 0.6410256410256411,
            "3": 0.7560386473429952
        },
        "bertscore": {
            "precision": 0.93455,
            "recall": 0.93349,
            "f1": 0.93278
        },
        "bleurt": 0.31403,
        "meteor": 0.41465642289486876,
        "nubia": {
            "semantic_relation": 4.3162,
            "contradiction": 1.44439,
            "irrelevancy": 34.93692,
            "logical_agreement": 63.61869,
            "grammar_ref": 4.41204,
            "grammar_hyp": 4.56713,
            "nubia_score": 0.74877
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_169": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 43,
        "mean_pred_length": 14.333333333333334,
        "std_pred_length": 3.2998316455372216,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 18,
        "distinct-1": 0.7441860465116279,
        "vocab_size-1": 32,
        "unique-1": 25,
        "entropy-1": 4.833014173206122,
        "distinct-2": 0.975,
        "vocab_size-2": 39,
        "unique-2": 38,
        "entropy-2": 5.271928094887364,
        "cond_entropy-2": 0.36453552773935094,
        "distinct-3": 1.0,
        "vocab_size-3": 37,
        "unique-3": 37,
        "entropy-3": 5.209453365628954,
        "cond_entropy-3": -0.05842067520435856,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 2.943920288775949,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7692307692307693,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.753225616242672,
        "distinct-2-nopunct": 0.9722222222222222,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.114369445886754,
        "cond_entropy-2-nopunct": 0.4054918798623825,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.0649248214777985,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.372332381219589,
        "bleu": 22.89194,
        "rouge1": {
            "precision": 0.55484,
            "recall": 0.52386,
            "fmeasure": 0.52681
        },
        "rouge2": {
            "precision": 0.31917,
            "recall": 0.36182,
            "fmeasure": 0.32956
        },
        "rougeL": {
            "precision": 0.48921,
            "recall": 0.51002,
            "fmeasure": 0.48527
        },
        "rougeLsum": {
            "precision": 0.48921,
            "recall": 0.51002,
            "fmeasure": 0.48527
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.18181818181818182,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.8722,
            "recall": 0.87793,
            "f1": 0.8631
        },
        "bleurt": 0.06059,
        "meteor": 0.2354391736247315,
        "nubia": {
            "semantic_relation": 4.0643,
            "contradiction": 0.46998,
            "irrelevancy": 59.67619,
            "logical_agreement": 39.85383,
            "grammar_ref": 4.07664,
            "grammar_hyp": 3.86444,
            "nubia_score": 0.75905
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_195": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.8,
        "total_length": 224,
        "mean_pred_length": 14.933333333333334,
        "std_pred_length": 6.546924638501823,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.625,
        "vocab_size-1": 140,
        "unique-1": 113,
        "entropy-1": 6.614293235068462,
        "distinct-2": 0.9234449760765551,
        "vocab_size-2": 193,
        "unique-2": 181,
        "entropy-2": 7.537455902395125,
        "cond_entropy-2": 0.7283902576171003,
        "distinct-3": 0.979381443298969,
        "vocab_size-3": 190,
        "unique-3": 186,
        "entropy-3": 7.558675728785042,
        "cond_entropy-3": -0.027498996057018256,
        "total_length-nopunct": 187,
        "mean_pred_length-nopunct": 12.466666666666667,
        "std_pred_length-nopunct": 4.937835783237654,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7219251336898396,
        "vocab_size-1-nopunct": 135,
        "unique-1-nopunct": 113,
        "entropy-1-nopunct": 6.73607676500644,
        "distinct-2-nopunct": 0.9534883720930233,
        "vocab_size-2-nopunct": 164,
        "unique-2-nopunct": 158,
        "entropy-2-nopunct": 7.324463737235051,
        "cond_entropy-2-nopunct": 0.6164242711840557,
        "distinct-3-nopunct": 0.9872611464968153,
        "vocab_size-3-nopunct": 155,
        "unique-3-nopunct": 153,
        "entropy-3-nopunct": 7.269143041885253,
        "cond_entropy-3-nopunct": -0.06578508859464512,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.541298639388271,
        "bleu": 46.75195,
        "rouge1": {
            "precision": 0.82304,
            "recall": 0.72026,
            "fmeasure": 0.75642
        },
        "rouge2": {
            "precision": 0.56081,
            "recall": 0.50495,
            "fmeasure": 0.52474
        },
        "rougeL": {
            "precision": 0.69756,
            "recall": 0.60977,
            "fmeasure": 0.64084
        },
        "rougeLsum": {
            "precision": 0.69756,
            "recall": 0.60977,
            "fmeasure": 0.64084
        },
        "local_recall": {
            "1": 0.1346153846153846,
            "2": 0.3181818181818182,
            "3": 0.7834394904458599
        },
        "bertscore": {
            "precision": 0.92662,
            "recall": 0.91864,
            "f1": 0.92228
        },
        "bleurt": 0.26099,
        "meteor": 0.38919693203330546,
        "nubia": {
            "semantic_relation": 4.37266,
            "contradiction": 0.77597,
            "irrelevancy": 39.64754,
            "logical_agreement": 59.57649,
            "grammar_ref": 4.60593,
            "grammar_hyp": 4.90722,
            "nubia_score": 0.72884
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_170": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.77,
        "total_length": 273,
        "mean_pred_length": 18.2,
        "std_pred_length": 6.002221810851934,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.6007326007326007,
        "vocab_size-1": 164,
        "unique-1": 131,
        "entropy-1": 6.7799793506096115,
        "distinct-2": 0.9224806201550387,
        "vocab_size-2": 238,
        "unique-2": 219,
        "entropy-2": 7.8532625751822795,
        "cond_entropy-2": 0.9224627126367357,
        "distinct-3": 0.9753086419753086,
        "vocab_size-3": 237,
        "unique-3": 231,
        "entropy-3": 7.87542978755638,
        "cond_entropy-3": 0.023687665886903173,
        "total_length-nopunct": 237,
        "mean_pred_length-nopunct": 15.8,
        "std_pred_length-nopunct": 5.2687759489277965,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6751054852320675,
        "vocab_size-1-nopunct": 160,
        "unique-1-nopunct": 131,
        "entropy-1-nopunct": 6.875088806708713,
        "distinct-2-nopunct": 0.9414414414414415,
        "vocab_size-2-nopunct": 209,
        "unique-2-nopunct": 197,
        "entropy-2-nopunct": 7.673898355079089,
        "cond_entropy-2-nopunct": 0.8511512336502434,
        "distinct-3-nopunct": 0.9855072463768116,
        "vocab_size-3-nopunct": 204,
        "unique-3-nopunct": 201,
        "entropy-3-nopunct": 7.6645014502529225,
        "cond_entropy-3-nopunct": -0.005494669709894198,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.984461433399078,
        "bleu": 46.44591,
        "rouge1": {
            "precision": 0.77382,
            "recall": 0.73351,
            "fmeasure": 0.74296
        },
        "rouge2": {
            "precision": 0.54383,
            "recall": 0.51309,
            "fmeasure": 0.52059
        },
        "rougeL": {
            "precision": 0.69836,
            "recall": 0.67031,
            "fmeasure": 0.67298
        },
        "rougeLsum": {
            "precision": 0.69836,
            "recall": 0.67031,
            "fmeasure": 0.67298
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.4230769230769231,
            "3": 0.765625
        },
        "bertscore": {
            "precision": 0.9304,
            "recall": 0.92642,
            "f1": 0.92682
        },
        "bleurt": 0.32187,
        "meteor": 0.38246593084636654,
        "nubia": {
            "semantic_relation": 4.30316,
            "contradiction": 7.16954,
            "irrelevancy": 30.75894,
            "logical_agreement": 62.07153,
            "grammar_ref": 4.2734,
            "grammar_hyp": 4.33752,
            "nubia_score": 0.76083
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_114": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 28,
        "msttr-100": 0.745,
        "msttr-100_nopunct": 0.775,
        "total_length": 495,
        "mean_pred_length": 17.678571428571427,
        "std_pred_length": 5.3655885806057215,
        "median_pred_length": 16.5,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.5797979797979798,
        "vocab_size-1": 287,
        "unique-1": 232,
        "entropy-1": 7.329803542962884,
        "distinct-2": 0.9207708779443254,
        "vocab_size-2": 430,
        "unique-2": 406,
        "entropy-2": 8.66970986924617,
        "cond_entropy-2": 1.1488903412692961,
        "distinct-3": 0.9908883826879271,
        "vocab_size-3": 435,
        "unique-3": 431,
        "entropy-3": 8.759853894911144,
        "cond_entropy-3": 0.08907780328011719,
        "total_length-nopunct": 437,
        "mean_pred_length-nopunct": 15.607142857142858,
        "std_pred_length-nopunct": 4.482818674149794,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6475972540045767,
        "vocab_size-1-nopunct": 283,
        "unique-1-nopunct": 232,
        "entropy-1-nopunct": 7.516390230821423,
        "distinct-2-nopunct": 0.9315403422982885,
        "vocab_size-2-nopunct": 381,
        "unique-2-nopunct": 365,
        "entropy-2-nopunct": 8.496226531708714,
        "cond_entropy-2-nopunct": 1.0397358668853538,
        "distinct-3-nopunct": 0.9921259842519685,
        "vocab_size-3-nopunct": 378,
        "unique-3-nopunct": 375,
        "entropy-3-nopunct": 8.557899155997289,
        "cond_entropy-3-nopunct": 0.07225649314560718,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.637505370812247,
        "bleu": 47.40848,
        "rouge1": {
            "precision": 0.79519,
            "recall": 0.70999,
            "fmeasure": 0.74127
        },
        "rouge2": {
            "precision": 0.55786,
            "recall": 0.50901,
            "fmeasure": 0.52677
        },
        "rougeL": {
            "precision": 0.6795,
            "recall": 0.62279,
            "fmeasure": 0.64156
        },
        "rougeLsum": {
            "precision": 0.6795,
            "recall": 0.62279,
            "fmeasure": 0.64156
        },
        "local_recall": {
            "1": 0.20512820512820512,
            "2": 0.56,
            "3": 0.7339181286549707
        },
        "bertscore": {
            "precision": 0.93154,
            "recall": 0.92062,
            "f1": 0.92374
        },
        "bleurt": 0.26989,
        "meteor": 0.38967830471024134,
        "nubia": {
            "semantic_relation": 4.14296,
            "contradiction": 17.48734,
            "irrelevancy": 18.7316,
            "logical_agreement": 63.78106,
            "grammar_ref": 4.55489,
            "grammar_hyp": 4.59297,
            "nubia_score": 0.70907
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_196": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.765,
        "total_length": 265,
        "mean_pred_length": 14.722222222222221,
        "std_pred_length": 7.139915620070617,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 40,
        "distinct-1": 0.5962264150943396,
        "vocab_size-1": 158,
        "unique-1": 126,
        "entropy-1": 6.668299161386271,
        "distinct-2": 0.8987854251012146,
        "vocab_size-2": 222,
        "unique-2": 200,
        "entropy-2": 7.734784691090116,
        "cond_entropy-2": 0.8632840680001285,
        "distinct-3": 0.9475982532751092,
        "vocab_size-3": 217,
        "unique-3": 205,
        "entropy-3": 7.734400294647167,
        "cond_entropy-3": -0.013093574492100343,
        "total_length-nopunct": 228,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 6.000000000000001,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.6754385964912281,
        "vocab_size-1-nopunct": 154,
        "unique-1-nopunct": 126,
        "entropy-1-nopunct": 6.783313997282249,
        "distinct-2-nopunct": 0.8952380952380953,
        "vocab_size-2-nopunct": 188,
        "unique-2-nopunct": 168,
        "entropy-2-nopunct": 7.495197898618492,
        "cond_entropy-2-nopunct": 0.7827999408785865,
        "distinct-3-nopunct": 0.9375,
        "vocab_size-3-nopunct": 180,
        "unique-3-nopunct": 168,
        "entropy-3-nopunct": 7.459962500721177,
        "cond_entropy-3-nopunct": -0.019908016944966155,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.736790646430738,
        "bleu": 40.6447,
        "rouge1": {
            "precision": 0.80399,
            "recall": 0.74009,
            "fmeasure": 0.76006
        },
        "rouge2": {
            "precision": 0.55879,
            "recall": 0.51338,
            "fmeasure": 0.52509
        },
        "rougeL": {
            "precision": 0.69531,
            "recall": 0.651,
            "fmeasure": 0.66132
        },
        "rougeLsum": {
            "precision": 0.69531,
            "recall": 0.651,
            "fmeasure": 0.66132
        },
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.3448275862068966,
            "3": 0.7663043478260869
        },
        "bertscore": {
            "precision": 0.92149,
            "recall": 0.9185,
            "f1": 0.91945
        },
        "bleurt": 0.15167,
        "meteor": 0.40526025139181193,
        "nubia": {
            "semantic_relation": 4.27969,
            "contradiction": 6.01111,
            "irrelevancy": 33.21163,
            "logical_agreement": 60.77726,
            "grammar_ref": 4.68102,
            "grammar_hyp": 4.74913,
            "nubia_score": 0.73777
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_171": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 92,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 2.6874192494328497,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 20,
        "distinct-1": 0.7934782608695652,
        "vocab_size-1": 73,
        "unique-1": 63,
        "entropy-1": 6.004274591809008,
        "distinct-2": 1.0,
        "vocab_size-2": 86,
        "unique-2": 86,
        "entropy-2": 6.426264754702099,
        "cond_entropy-2": 0.27787329290660107,
        "distinct-3": 1.0,
        "vocab_size-3": 80,
        "unique-3": 80,
        "entropy-3": 6.321928094887356,
        "cond_entropy-3": -0.10433665981473575,
        "total_length-nopunct": 81,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 2.217355782608345,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8518518518518519,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 5.990903552187204,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 6.228818690495891,
        "cond_entropy-2-nopunct": 0.26583085436446174,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 69,
        "unique-3-nopunct": 69,
        "entropy-3-nopunct": 6.108524456778164,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.605799867307517,
        "bleu": 64.02659,
        "rouge1": {
            "precision": 0.87103,
            "recall": 0.87937,
            "fmeasure": 0.86419
        },
        "rouge2": {
            "precision": 0.7382,
            "recall": 0.7223,
            "fmeasure": 0.72112
        },
        "rougeL": {
            "precision": 0.81019,
            "recall": 0.81998,
            "fmeasure": 0.80494
        },
        "rougeLsum": {
            "precision": 0.81019,
            "recall": 0.81998,
            "fmeasure": 0.80494
        },
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.0,
            "3": 0.8589743589743589
        },
        "bertscore": {
            "precision": 0.96911,
            "recall": 0.96622,
            "f1": 0.96419
        },
        "bleurt": 0.58472,
        "meteor": 0.48197097032297237,
        "nubia": {
            "semantic_relation": 4.65808,
            "contradiction": 0.2195,
            "irrelevancy": 25.3762,
            "logical_agreement": 74.4043,
            "grammar_ref": 4.66241,
            "grammar_hyp": 4.67806,
            "nubia_score": 0.88507
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_115": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.70333,
        "msttr-100_nopunct": 0.75,
        "total_length": 345,
        "mean_pred_length": 17.25,
        "std_pred_length": 7.562241731127087,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 36,
        "distinct-1": 0.5739130434782609,
        "vocab_size-1": 198,
        "unique-1": 156,
        "entropy-1": 6.972685907372329,
        "distinct-2": 0.8646153846153846,
        "vocab_size-2": 281,
        "unique-2": 249,
        "entropy-2": 8.045653907835893,
        "cond_entropy-2": 0.8967119111962515,
        "distinct-3": 0.9311475409836065,
        "vocab_size-3": 284,
        "unique-3": 268,
        "entropy-3": 8.102585309463919,
        "cond_entropy-3": 0.05436731146223725,
        "total_length-nopunct": 296,
        "mean_pred_length-nopunct": 14.8,
        "std_pred_length-nopunct": 6.201612693485462,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.652027027027027,
        "vocab_size-1-nopunct": 193,
        "unique-1-nopunct": 156,
        "entropy-1-nopunct": 7.1426030075912115,
        "distinct-2-nopunct": 0.8913043478260869,
        "vocab_size-2-nopunct": 246,
        "unique-2-nopunct": 223,
        "entropy-2-nopunct": 7.871987454911669,
        "cond_entropy-2-nopunct": 0.7632141834101557,
        "distinct-3-nopunct": 0.953125,
        "vocab_size-3-nopunct": 244,
        "unique-3-nopunct": 235,
        "entropy-3-nopunct": 7.897403662084022,
        "cond_entropy-3-nopunct": 0.03217691044313515,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.729709866134347,
        "bleu": 59.37301,
        "rouge1": {
            "precision": 0.82507,
            "recall": 0.81214,
            "fmeasure": 0.81497
        },
        "rouge2": {
            "precision": 0.64855,
            "recall": 0.64384,
            "fmeasure": 0.64393
        },
        "rougeL": {
            "precision": 0.69619,
            "recall": 0.68728,
            "fmeasure": 0.68896
        },
        "rougeLsum": {
            "precision": 0.69619,
            "recall": 0.68728,
            "fmeasure": 0.68896
        },
        "local_recall": {
            "1": 0.09803921568627451,
            "2": 0.5,
            "3": 0.8888888888888888
        },
        "bertscore": {
            "precision": 0.94986,
            "recall": 0.94783,
            "f1": 0.94788
        },
        "bleurt": 0.49081,
        "meteor": 0.45874287878228154,
        "nubia": {
            "semantic_relation": 4.46527,
            "contradiction": 2.88856,
            "irrelevancy": 20.49706,
            "logical_agreement": 76.61438,
            "grammar_ref": 4.56897,
            "grammar_hyp": 4.62102,
            "nubia_score": 0.81642
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-base (Baseline)/e2e_nlg_test",
        "N": 120,
        "msttr-100": 0.31105,
        "msttr-100_nopunct": 0.32941,
        "total_length": 1930,
        "mean_pred_length": 16.083333333333332,
        "std_pred_length": 7.074111644267114,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.07046632124352331,
        "vocab_size-1": 136,
        "unique-1": 19,
        "entropy-1": 5.6878072032069875,
        "distinct-2": 0.14033149171270717,
        "vocab_size-2": 254,
        "unique-2": 55,
        "entropy-2": 6.951378988163939,
        "cond_entropy-2": 1.1447343784147013,
        "distinct-3": 0.19230769230769232,
        "vocab_size-3": 325,
        "unique-3": 83,
        "entropy-3": 7.537776658260096,
        "cond_entropy-3": 0.6419412647156896,
        "total_length-nopunct": 1769,
        "mean_pred_length-nopunct": 14.741666666666667,
        "std_pred_length-nopunct": 6.5771014808112005,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.07574901074053138,
        "vocab_size-1-nopunct": 134,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 5.741492127401387,
        "distinct-2-nopunct": 0.1406913280776228,
        "vocab_size-2-nopunct": 232,
        "unique-2-nopunct": 52,
        "entropy-2-nopunct": 6.800526149044448,
        "cond_entropy-2-nopunct": 1.1677705395439804,
        "distinct-3-nopunct": 0.19686069326357097,
        "vocab_size-3-nopunct": 301,
        "unique-3-nopunct": 79,
        "entropy-3-nopunct": 7.433043174226123,
        "cond_entropy-3-nopunct": 0.6836050125347509,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 3.643232710689379,
        "bleu": 21.79842,
        "rouge1": {
            "precision": 0.60924,
            "recall": 0.64698,
            "fmeasure": 0.59531
        },
        "rouge2": {
            "precision": 0.36419,
            "recall": 0.39029,
            "fmeasure": 0.35399
        },
        "rougeL": {
            "precision": 0.49346,
            "recall": 0.51934,
            "fmeasure": 0.47867
        },
        "rougeLsum": {
            "precision": 0.49346,
            "recall": 0.51934,
            "fmeasure": 0.47867
        },
        "local_recall": {
            "1": 0.6182544970019986
        },
        "bertscore": {
            "precision": 0.88528,
            "recall": 0.88399,
            "f1": 0.88369
        },
        "bleurt": -0.21854,
        "meteor": 0.30079692785516327,
        "nubia": {
            "semantic_relation": 3.69294,
            "contradiction": 10.83594,
            "irrelevancy": 49.84403,
            "logical_agreement": 39.32003,
            "grammar_ref": 5.42765,
            "grammar_hyp": 4.95444,
            "nubia_score": 0.59664
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_116": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.645,
        "msttr-100_nopunct": 0.725,
        "total_length": 279,
        "mean_pred_length": 16.41176470588235,
        "std_pred_length": 6.4357350101684005,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 37,
        "distinct-1": 0.5734767025089605,
        "vocab_size-1": 160,
        "unique-1": 125,
        "entropy-1": 6.626538525051579,
        "distinct-2": 0.8969465648854962,
        "vocab_size-2": 235,
        "unique-2": 212,
        "entropy-2": 7.815791131275442,
        "cond_entropy-2": 1.0212069538343842,
        "distinct-3": 0.9591836734693877,
        "vocab_size-3": 235,
        "unique-3": 225,
        "entropy-3": 7.855005285941374,
        "cond_entropy-3": 0.026744172185489332,
        "total_length-nopunct": 229,
        "mean_pred_length-nopunct": 13.470588235294118,
        "std_pred_length-nopunct": 4.5904971800298044,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6768558951965066,
        "vocab_size-1-nopunct": 155,
        "unique-1-nopunct": 124,
        "entropy-1-nopunct": 6.817469682092889,
        "distinct-2-nopunct": 0.9292452830188679,
        "vocab_size-2-nopunct": 197,
        "unique-2-nopunct": 185,
        "entropy-2-nopunct": 7.575728650287313,
        "cond_entropy-2-nopunct": 0.8213225521664375,
        "distinct-3-nopunct": 0.9794871794871794,
        "vocab_size-3-nopunct": 191,
        "unique-3-nopunct": 187,
        "entropy-3-nopunct": 7.566304672724007,
        "cond_entropy-3-nopunct": -0.011540589498253267,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.869471541488269,
        "bleu": 46.4261,
        "rouge1": {
            "precision": 0.83491,
            "recall": 0.74306,
            "fmeasure": 0.7814
        },
        "rouge2": {
            "precision": 0.56582,
            "recall": 0.47775,
            "fmeasure": 0.51299
        },
        "rougeL": {
            "precision": 0.74491,
            "recall": 0.65647,
            "fmeasure": 0.69316
        },
        "rougeLsum": {
            "precision": 0.74491,
            "recall": 0.65647,
            "fmeasure": 0.69316
        },
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.375,
            "3": 0.7511961722488039
        },
        "bertscore": {
            "precision": 0.94356,
            "recall": 0.93098,
            "f1": 0.9366
        },
        "bleurt": 0.33634,
        "meteor": 0.39189229149633104,
        "nubia": {
            "semantic_relation": 4.23476,
            "contradiction": 6.61099,
            "irrelevancy": 24.62879,
            "logical_agreement": 68.76022,
            "grammar_ref": 4.34644,
            "grammar_hyp": 4.70281,
            "nubia_score": 0.70269
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_117": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.77,
        "total_length": 147,
        "mean_pred_length": 18.375,
        "std_pred_length": 9.068317098558033,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 40,
        "distinct-1": 0.6598639455782312,
        "vocab_size-1": 97,
        "unique-1": 82,
        "entropy-1": 6.144458015333424,
        "distinct-2": 0.9136690647482014,
        "vocab_size-2": 127,
        "unique-2": 117,
        "entropy-2": 6.935417511541313,
        "cond_entropy-2": 0.6790293856756661,
        "distinct-3": 0.9541984732824428,
        "vocab_size-3": 125,
        "unique-3": 119,
        "entropy-3": 6.941819948102337,
        "cond_entropy-3": 0.017609982282087613,
        "total_length-nopunct": 122,
        "mean_pred_length-nopunct": 15.25,
        "std_pred_length-nopunct": 5.84700778176325,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.7622950819672131,
        "vocab_size-1-nopunct": 93,
        "unique-1-nopunct": 82,
        "entropy-1-nopunct": 6.221006342284611,
        "distinct-2-nopunct": 0.956140350877193,
        "vocab_size-2-nopunct": 109,
        "unique-2-nopunct": 104,
        "entropy-2-nopunct": 6.745170715919137,
        "cond_entropy-2-nopunct": 0.5651981276891428,
        "distinct-3-nopunct": 0.9716981132075472,
        "vocab_size-3-nopunct": 103,
        "unique-3-nopunct": 100,
        "entropy-3-nopunct": 6.67131668097828,
        "cond_entropy-3-nopunct": -0.07666767280908961,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.776768678267348,
        "bleu": 30.79013,
        "rouge1": {
            "precision": 0.77245,
            "recall": 0.70394,
            "fmeasure": 0.72403
        },
        "rouge2": {
            "precision": 0.53665,
            "recall": 0.48035,
            "fmeasure": 0.49658
        },
        "rougeL": {
            "precision": 0.65606,
            "recall": 0.59462,
            "fmeasure": 0.61347
        },
        "rougeLsum": {
            "precision": 0.65606,
            "recall": 0.59462,
            "fmeasure": 0.61347
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.5384615384615384,
            "3": 0.7126436781609196
        },
        "bertscore": {
            "precision": 0.91129,
            "recall": 0.90488,
            "f1": 0.90572
        },
        "bleurt": 0.09493,
        "meteor": 0.34115640629057015,
        "nubia": {
            "semantic_relation": 3.88512,
            "contradiction": 10.51287,
            "irrelevancy": 46.42109,
            "logical_agreement": 43.06604,
            "grammar_ref": 4.12019,
            "grammar_hyp": 4.44203,
            "nubia_score": 0.61487
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_212": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.63,
        "msttr-100_nopunct": 0.665,
        "total_length": 253,
        "mean_pred_length": 16.866666666666667,
        "std_pred_length": 7.172788083366808,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 36,
        "distinct-1": 0.541501976284585,
        "vocab_size-1": 137,
        "unique-1": 98,
        "entropy-1": 6.541161522734064,
        "distinct-2": 0.8235294117647058,
        "vocab_size-2": 196,
        "unique-2": 167,
        "entropy-2": 7.481629963191856,
        "cond_entropy-2": 0.7851076078748602,
        "distinct-3": 0.874439461883408,
        "vocab_size-3": 195,
        "unique-3": 174,
        "entropy-3": 7.514020220767678,
        "cond_entropy-3": 0.02430871946707098,
        "total_length-nopunct": 227,
        "mean_pred_length-nopunct": 15.133333333333333,
        "std_pred_length-nopunct": 6.820231341791534,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.5814977973568282,
        "vocab_size-1-nopunct": 132,
        "unique-1-nopunct": 97,
        "entropy-1-nopunct": 6.563683398271158,
        "distinct-2-nopunct": 0.8207547169811321,
        "vocab_size-2-nopunct": 174,
        "unique-2-nopunct": 147,
        "entropy-2-nopunct": 7.311228490281897,
        "cond_entropy-2-nopunct": 0.7930887899151913,
        "distinct-3-nopunct": 0.868020304568528,
        "vocab_size-3-nopunct": 171,
        "unique-3-nopunct": 152,
        "entropy-3-nopunct": 7.317614416151587,
        "cond_entropy-3-nopunct": 0.02796145614495534,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.567596756224035,
        "bleu": 46.43272,
        "rouge1": {
            "precision": 0.80561,
            "recall": 0.67748,
            "fmeasure": 0.72961
        },
        "rouge2": {
            "precision": 0.51891,
            "recall": 0.46104,
            "fmeasure": 0.48353
        },
        "rougeL": {
            "precision": 0.68615,
            "recall": 0.61629,
            "fmeasure": 0.64261
        },
        "rougeLsum": {
            "precision": 0.68615,
            "recall": 0.61629,
            "fmeasure": 0.64261
        },
        "local_recall": {
            "1": 0.24285714285714285,
            "2": 0.3375,
            "3": 0.7485380116959064
        },
        "bertscore": {
            "precision": 0.9249,
            "recall": 0.91985,
            "f1": 0.91981
        },
        "bleurt": 0.25737,
        "meteor": 0.3777190531705587,
        "nubia": {
            "semantic_relation": 4.20181,
            "contradiction": 15.15459,
            "irrelevancy": 25.66212,
            "logical_agreement": 59.18329,
            "grammar_ref": 4.73267,
            "grammar_hyp": 4.86396,
            "nubia_score": 0.6982
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_144": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 46,
        "msttr-100": 0.72857,
        "msttr-100_nopunct": 0.77,
        "total_length": 769,
        "mean_pred_length": 16.717391304347824,
        "std_pred_length": 6.445972937249309,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 39,
        "distinct-1": 0.5344603381014305,
        "vocab_size-1": 411,
        "unique-1": 322,
        "entropy-1": 7.723841965732403,
        "distinct-2": 0.9087136929460581,
        "vocab_size-2": 657,
        "unique-2": 613,
        "entropy-2": 9.26849058478537,
        "cond_entropy-2": 1.3117496561814366,
        "distinct-3": 0.9645494830132939,
        "vocab_size-3": 653,
        "unique-3": 631,
        "entropy-3": 9.329880893583258,
        "cond_entropy-3": 0.07106625798503233,
        "total_length-nopunct": 682,
        "mean_pred_length-nopunct": 14.826086956521738,
        "std_pred_length-nopunct": 5.880344369633639,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.593841642228739,
        "vocab_size-1-nopunct": 405,
        "unique-1-nopunct": 320,
        "entropy-1-nopunct": 7.926148830038602,
        "distinct-2-nopunct": 0.9072327044025157,
        "vocab_size-2-nopunct": 577,
        "unique-2-nopunct": 540,
        "entropy-2-nopunct": 9.074159393466877,
        "cond_entropy-2-nopunct": 1.216405572940594,
        "distinct-3-nopunct": 0.9677966101694915,
        "vocab_size-3-nopunct": 571,
        "unique-3-nopunct": 554,
        "entropy-3-nopunct": 9.137605423902983,
        "cond_entropy-3-nopunct": 0.07598216830515346,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.517575542806831,
        "bleu": 44.03666,
        "rouge1": {
            "precision": 0.76446,
            "recall": 0.73743,
            "fmeasure": 0.74216
        },
        "rouge2": {
            "precision": 0.53657,
            "recall": 0.53291,
            "fmeasure": 0.52604
        },
        "rougeL": {
            "precision": 0.67064,
            "recall": 0.66268,
            "fmeasure": 0.6574
        },
        "rougeLsum": {
            "precision": 0.67064,
            "recall": 0.66268,
            "fmeasure": 0.6574
        },
        "local_recall": {
            "1": 0.19090909090909092,
            "2": 0.39416058394160586,
            "3": 0.7509881422924901
        },
        "bertscore": {
            "precision": 0.92688,
            "recall": 0.92473,
            "f1": 0.92388
        },
        "bleurt": 0.31294,
        "meteor": 0.3786742270253106,
        "nubia": {
            "semantic_relation": 4.28228,
            "contradiction": 5.13946,
            "irrelevancy": 37.1618,
            "logical_agreement": 57.69874,
            "grammar_ref": 4.63942,
            "grammar_hyp": 4.69693,
            "nubia_score": 0.73853
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_198": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.68333,
        "msttr-100_nopunct": 0.73,
        "total_length": 346,
        "mean_pred_length": 19.22222222222222,
        "std_pred_length": 7.807087631373855,
        "median_pred_length": 19.5,
        "min_pred_length": 8,
        "max_pred_length": 36,
        "distinct-1": 0.5982658959537572,
        "vocab_size-1": 207,
        "unique-1": 169,
        "entropy-1": 7.0045862396944445,
        "distinct-2": 0.9390243902439024,
        "vocab_size-2": 308,
        "unique-2": 292,
        "entropy-2": 8.224900251556122,
        "cond_entropy-2": 1.0699545781939657,
        "distinct-3": 0.9870967741935484,
        "vocab_size-3": 306,
        "unique-3": 302,
        "entropy-3": 8.250317953661305,
        "cond_entropy-3": 0.03312006196043412,
        "total_length-nopunct": 299,
        "mean_pred_length-nopunct": 16.61111111111111,
        "std_pred_length-nopunct": 6.742393977157511,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6688963210702341,
        "vocab_size-1-nopunct": 200,
        "unique-1-nopunct": 164,
        "entropy-1-nopunct": 7.18822649766043,
        "distinct-2-nopunct": 0.9537366548042705,
        "vocab_size-2-nopunct": 268,
        "unique-2-nopunct": 257,
        "entropy-2-nopunct": 8.036526765045389,
        "cond_entropy-2-nopunct": 0.9039726986222081,
        "distinct-3-nopunct": 0.9923954372623575,
        "vocab_size-3-nopunct": 261,
        "unique-3-nopunct": 259,
        "entropy-3-nopunct": 8.023709863817043,
        "cond_entropy-3-nopunct": -0.009918832813312406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.94193090077976,
        "bleu": 27.7938,
        "rouge1": {
            "precision": 0.65066,
            "recall": 0.6677,
            "fmeasure": 0.64617
        },
        "rouge2": {
            "precision": 0.36703,
            "recall": 0.37542,
            "fmeasure": 0.36301
        },
        "rougeL": {
            "precision": 0.54923,
            "recall": 0.56344,
            "fmeasure": 0.54694
        },
        "rougeLsum": {
            "precision": 0.54923,
            "recall": 0.56344,
            "fmeasure": 0.54694
        },
        "local_recall": {
            "1": 0.19117647058823528,
            "2": 0.49295774647887325,
            "3": 0.6881720430107527
        },
        "bertscore": {
            "precision": 0.89743,
            "recall": 0.90656,
            "f1": 0.89977
        },
        "bleurt": 0.07466,
        "meteor": 0.3330413949369837,
        "nubia": {
            "semantic_relation": 3.79544,
            "contradiction": 19.59904,
            "irrelevancy": 39.30193,
            "logical_agreement": 41.09903,
            "grammar_ref": 4.71491,
            "grammar_hyp": 4.47155,
            "nubia_score": 0.60635
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_119": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.75,
        "msttr-100_nopunct": NaN,
        "total_length": 101,
        "mean_pred_length": 14.428571428571429,
        "std_pred_length": 3.155817433482074,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 19,
        "distinct-1": 0.7425742574257426,
        "vocab_size-1": 75,
        "unique-1": 61,
        "entropy-1": 6.005576364327093,
        "distinct-2": 0.9680851063829787,
        "vocab_size-2": 91,
        "unique-2": 88,
        "entropy-2": 6.490759064443582,
        "cond_entropy-2": 0.3247248423991448,
        "distinct-3": 0.9885057471264368,
        "vocab_size-3": 86,
        "unique-3": 85,
        "entropy-3": 6.419954990101596,
        "cond_entropy-3": -0.06566834433465615,
        "total_length-nopunct": 85,
        "mean_pred_length-nopunct": 12.142857142857142,
        "std_pred_length-nopunct": 2.899683304312063,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 6.00627725959076,
        "distinct-2-nopunct": 0.9743589743589743,
        "vocab_size-2-nopunct": 76,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.234120167580205,
        "cond_entropy-2-nopunct": 0.2640197763975005,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 71,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 6.149747119504677,
        "cond_entropy-3-nopunct": -0.07931707118855225,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.43949081378166,
        "bleu": 45.04881,
        "rouge1": {
            "precision": 0.78997,
            "recall": 0.77018,
            "fmeasure": 0.77704
        },
        "rouge2": {
            "precision": 0.5633,
            "recall": 0.5467,
            "fmeasure": 0.55231
        },
        "rougeL": {
            "precision": 0.70743,
            "recall": 0.6763,
            "fmeasure": 0.68951
        },
        "rougeLsum": {
            "precision": 0.70743,
            "recall": 0.6763,
            "fmeasure": 0.68951
        },
        "local_recall": {
            "1": 0.1794871794871795,
            "2": 0.5,
            "3": 0.8253968253968254
        },
        "bertscore": {
            "precision": 0.9446,
            "recall": 0.94833,
            "f1": 0.94486
        },
        "bleurt": 0.38117,
        "meteor": 0.42823593784186226,
        "nubia": {
            "semantic_relation": 4.46186,
            "contradiction": 3.19964,
            "irrelevancy": 14.98489,
            "logical_agreement": 81.81547,
            "grammar_ref": 4.57228,
            "grammar_hyp": 4.40341,
            "nubia_score": 0.83986
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_215": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "total_length": 103,
        "mean_pred_length": 17.166666666666668,
        "std_pred_length": 13.334374959313076,
        "median_pred_length": 11.5,
        "min_pred_length": 7,
        "max_pred_length": 46,
        "distinct-1": 0.7281553398058253,
        "vocab_size-1": 75,
        "unique-1": 59,
        "entropy-1": 6.017628168061084,
        "distinct-2": 0.9587628865979382,
        "vocab_size-2": 93,
        "unique-2": 89,
        "entropy-2": 6.517438615383018,
        "cond_entropy-2": 0.3812894076353953,
        "distinct-3": 0.989010989010989,
        "vocab_size-3": 90,
        "unique-3": 89,
        "entropy-3": 6.485816618220681,
        "cond_entropy-3": -0.02618413605436576,
        "total_length-nopunct": 89,
        "mean_pred_length-nopunct": 14.833333333333334,
        "std_pred_length-nopunct": 10.89979612449497,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.797752808988764,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 6.005235644663854,
        "distinct-2-nopunct": 0.9759036144578314,
        "vocab_size-2-nopunct": 81,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.326846660262595,
        "cond_entropy-2-nopunct": 0.3435747109941084,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 77,
        "unique-3-nopunct": 77,
        "entropy-3-nopunct": 6.266786540694905,
        "cond_entropy-3-nopunct": -0.056304838703971495,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.22696912445858,
        "bleu": 26.85914,
        "rouge1": {
            "precision": 0.76561,
            "recall": 0.52661,
            "fmeasure": 0.60258
        },
        "rouge2": {
            "precision": 0.37926,
            "recall": 0.28917,
            "fmeasure": 0.31313
        },
        "rougeL": {
            "precision": 0.64087,
            "recall": 0.45149,
            "fmeasure": 0.51376
        },
        "rougeLsum": {
            "precision": 0.64087,
            "recall": 0.45149,
            "fmeasure": 0.51376
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.3888888888888889,
            "3": 0.5844155844155844
        },
        "bertscore": {
            "precision": 0.90546,
            "recall": 0.84538,
            "f1": 0.87085
        },
        "bleurt": -0.08661,
        "meteor": 0.2787349130171125,
        "nubia": {
            "semantic_relation": 3.68072,
            "contradiction": 13.8148,
            "irrelevancy": 29.25572,
            "logical_agreement": 56.92949,
            "grammar_ref": 4.85958,
            "grammar_hyp": 5.33079,
            "nubia_score": 0.51916
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_172": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.72,
        "total_length": 194,
        "mean_pred_length": 19.4,
        "std_pred_length": 10.061808982484212,
        "median_pred_length": 14.5,
        "min_pred_length": 11,
        "max_pred_length": 42,
        "distinct-1": 0.5618556701030928,
        "vocab_size-1": 109,
        "unique-1": 81,
        "entropy-1": 6.200692875734333,
        "distinct-2": 0.8532608695652174,
        "vocab_size-2": 157,
        "unique-2": 138,
        "entropy-2": 7.1919339668795566,
        "cond_entropy-2": 0.8792730665699575,
        "distinct-3": 0.9137931034482759,
        "vocab_size-3": 159,
        "unique-3": 146,
        "entropy-3": 7.261852834904304,
        "cond_entropy-3": 0.0774836949889966,
        "total_length-nopunct": 170,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 9.777525249264253,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.6176470588235294,
        "vocab_size-1-nopunct": 105,
        "unique-1-nopunct": 81,
        "entropy-1-nopunct": 6.208016428913572,
        "distinct-2-nopunct": 0.84375,
        "vocab_size-2-nopunct": 135,
        "unique-2-nopunct": 118,
        "entropy-2-nopunct": 6.96555590733328,
        "cond_entropy-2-nopunct": 0.8138753851211987,
        "distinct-3-nopunct": 0.9,
        "vocab_size-3-nopunct": 135,
        "unique-3-nopunct": 122,
        "entropy-3-nopunct": 7.018753523800357,
        "cond_entropy-3-nopunct": 0.05695576230403147,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.2298647598922345,
        "bleu": 38.54266,
        "rouge1": {
            "precision": 0.73213,
            "recall": 0.7211,
            "fmeasure": 0.71455
        },
        "rouge2": {
            "precision": 0.5198,
            "recall": 0.50233,
            "fmeasure": 0.50083
        },
        "rougeL": {
            "precision": 0.63824,
            "recall": 0.61467,
            "fmeasure": 0.6158
        },
        "rougeLsum": {
            "precision": 0.63824,
            "recall": 0.61467,
            "fmeasure": 0.6158
        },
        "local_recall": {
            "1": 0.41935483870967744,
            "2": 0.325,
            "3": 0.7117117117117117
        },
        "bertscore": {
            "precision": 0.91843,
            "recall": 0.91699,
            "f1": 0.91647
        },
        "bleurt": 0.15269,
        "meteor": 0.3458816060205199,
        "nubia": {
            "semantic_relation": 3.97929,
            "contradiction": 22.0248,
            "irrelevancy": 46.93596,
            "logical_agreement": 31.03924,
            "grammar_ref": 4.7085,
            "grammar_hyp": 4.76395,
            "nubia_score": 0.62751
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_200": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 25,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.80333,
        "total_length": 428,
        "mean_pred_length": 17.12,
        "std_pred_length": 7.240552465109275,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 33,
        "distinct-1": 0.6144859813084113,
        "vocab_size-1": 263,
        "unique-1": 223,
        "entropy-1": 7.327406746488735,
        "distinct-2": 0.9156327543424317,
        "vocab_size-2": 369,
        "unique-2": 346,
        "entropy-2": 8.455780034762668,
        "cond_entropy-2": 0.9280137380342892,
        "distinct-3": 0.9841269841269841,
        "vocab_size-3": 372,
        "unique-3": 367,
        "entropy-3": 8.528499335591036,
        "cond_entropy-3": 0.07528914168584097,
        "total_length-nopunct": 376,
        "mean_pred_length-nopunct": 15.04,
        "std_pred_length-nopunct": 6.465168211268752,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6861702127659575,
        "vocab_size-1-nopunct": 258,
        "unique-1-nopunct": 223,
        "entropy-1-nopunct": 7.491296124534837,
        "distinct-2-nopunct": 0.9316239316239316,
        "vocab_size-2-nopunct": 327,
        "unique-2-nopunct": 313,
        "entropy-2-nopunct": 8.286141812939183,
        "cond_entropy-2-nopunct": 0.8591827772321159,
        "distinct-3-nopunct": 0.99079754601227,
        "vocab_size-3-nopunct": 323,
        "unique-3-nopunct": 321,
        "entropy-3-nopunct": 8.328007640420795,
        "cond_entropy-3-nopunct": 0.05484016853722443,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.362757475993538,
        "bleu": 65.07691,
        "rouge1": {
            "precision": 0.84272,
            "recall": 0.82433,
            "fmeasure": 0.82735
        },
        "rouge2": {
            "precision": 0.66829,
            "recall": 0.67477,
            "fmeasure": 0.66839
        },
        "rougeL": {
            "precision": 0.76648,
            "recall": 0.75313,
            "fmeasure": 0.75407
        },
        "rougeLsum": {
            "precision": 0.76648,
            "recall": 0.75313,
            "fmeasure": 0.75407
        },
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.32558139534883723,
            "3": 0.8863636363636364
        },
        "bertscore": {
            "precision": 0.95883,
            "recall": 0.95663,
            "f1": 0.95739
        },
        "bleurt": 0.51426,
        "meteor": 0.486524460846373,
        "nubia": {
            "semantic_relation": 4.50339,
            "contradiction": 5.05777,
            "irrelevancy": 21.37356,
            "logical_agreement": 73.56867,
            "grammar_ref": 4.85173,
            "grammar_hyp": 5.01024,
            "nubia_score": 0.80453
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_216": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 35,
        "msttr-100": 0.708,
        "msttr-100_nopunct": 0.756,
        "total_length": 598,
        "mean_pred_length": 17.085714285714285,
        "std_pred_length": 7.714074071170836,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 38,
        "distinct-1": 0.5501672240802675,
        "vocab_size-1": 329,
        "unique-1": 260,
        "entropy-1": 7.458286433821639,
        "distinct-2": 0.8774422735346359,
        "vocab_size-2": 494,
        "unique-2": 445,
        "entropy-2": 8.849693410549378,
        "cond_entropy-2": 1.182304184223408,
        "distinct-3": 0.9393939393939394,
        "vocab_size-3": 496,
        "unique-3": 467,
        "entropy-3": 8.918892864611225,
        "cond_entropy-3": 0.07166258294716431,
        "total_length-nopunct": 530,
        "mean_pred_length-nopunct": 15.142857142857142,
        "std_pred_length-nopunct": 6.854166020511519,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.6075471698113207,
        "vocab_size-1-nopunct": 322,
        "unique-1-nopunct": 257,
        "entropy-1-nopunct": 7.634449727789528,
        "distinct-2-nopunct": 0.8767676767676768,
        "vocab_size-2-nopunct": 434,
        "unique-2-nopunct": 392,
        "entropy-2-nopunct": 8.65836811201812,
        "cond_entropy-2-nopunct": 1.0877853463589078,
        "distinct-3-nopunct": 0.9391304347826087,
        "vocab_size-3-nopunct": 432,
        "unique-3-nopunct": 407,
        "entropy-3-nopunct": 8.71882774114768,
        "cond_entropy-3-nopunct": 0.0740511097887087,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.057822371638523,
        "bleu": 47.76279,
        "rouge1": {
            "precision": 0.75779,
            "recall": 0.70592,
            "fmeasure": 0.718
        },
        "rouge2": {
            "precision": 0.55133,
            "recall": 0.49766,
            "fmeasure": 0.51267
        },
        "rougeL": {
            "precision": 0.6616,
            "recall": 0.61888,
            "fmeasure": 0.62801
        },
        "rougeLsum": {
            "precision": 0.6616,
            "recall": 0.61888,
            "fmeasure": 0.62801
        },
        "local_recall": {
            "1": 0.30927835051546393,
            "2": 0.44144144144144143,
            "3": 0.7374301675977654
        },
        "bertscore": {
            "precision": 0.93777,
            "recall": 0.92032,
            "f1": 0.92783
        },
        "bleurt": 0.17988,
        "meteor": 0.3776745321808101,
        "nubia": {
            "semantic_relation": 3.99145,
            "contradiction": 11.01425,
            "irrelevancy": 35.08868,
            "logical_agreement": 53.89707,
            "grammar_ref": 4.80535,
            "grammar_hyp": 4.6839,
            "nubia_score": 0.66689
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_120": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 75,
        "msttr-100": 0.72917,
        "msttr-100_nopunct": 0.785,
        "total_length": 1271,
        "mean_pred_length": 16.946666666666665,
        "std_pred_length": 7.014068402543245,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 42,
        "distinct-1": 0.4822974036191975,
        "vocab_size-1": 613,
        "unique-1": 475,
        "entropy-1": 8.023567386743913,
        "distinct-2": 0.8586956521739131,
        "vocab_size-2": 1027,
        "unique-2": 932,
        "entropy-2": 9.851821882440005,
        "cond_entropy-2": 1.5799426278963489,
        "distinct-3": 0.935771632471008,
        "vocab_size-3": 1049,
        "unique-3": 998,
        "entropy-3": 9.984698088699599,
        "cond_entropy-3": 0.1288682780037339,
        "total_length-nopunct": 1090,
        "mean_pred_length-nopunct": 14.533333333333333,
        "std_pred_length-nopunct": 5.641118880348315,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.555045871559633,
        "vocab_size-1-nopunct": 605,
        "unique-1-nopunct": 474,
        "entropy-1-nopunct": 8.327099788028965,
        "distinct-2-nopunct": 0.8699507389162562,
        "vocab_size-2-nopunct": 883,
        "unique-2-nopunct": 812,
        "entropy-2-nopunct": 9.636558818492453,
        "cond_entropy-2-nopunct": 1.390041651019821,
        "distinct-3-nopunct": 0.9436170212765957,
        "vocab_size-3-nopunct": 887,
        "unique-3-nopunct": 852,
        "entropy-3-nopunct": 9.745912525319929,
        "cond_entropy-3-nopunct": 0.11995268503554128,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.412388753338206,
        "bleu": 45.86142,
        "rouge1": {
            "precision": 0.78551,
            "recall": 0.73747,
            "fmeasure": 0.75165
        },
        "rouge2": {
            "precision": 0.57544,
            "recall": 0.54009,
            "fmeasure": 0.54987
        },
        "rougeL": {
            "precision": 0.69085,
            "recall": 0.65248,
            "fmeasure": 0.66239
        },
        "rougeLsum": {
            "precision": 0.69085,
            "recall": 0.65248,
            "fmeasure": 0.66239
        },
        "local_recall": {
            "1": 0.2339622641509434,
            "2": 0.4212962962962963,
            "3": 0.7898089171974523
        },
        "bertscore": {
            "precision": 0.93098,
            "recall": 0.92456,
            "f1": 0.92567
        },
        "bleurt": 0.21193,
        "meteor": 0.39303322932791834,
        "nubia": {
            "semantic_relation": 4.13188,
            "contradiction": 8.2759,
            "irrelevancy": 30.41857,
            "logical_agreement": 61.30553,
            "grammar_ref": 4.90125,
            "grammar_hyp": 5.00548,
            "nubia_score": 0.69527
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_217": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 62,
        "mean_pred_length": 20.666666666666668,
        "std_pred_length": 4.496912521077347,
        "median_pred_length": 18.0,
        "min_pred_length": 17,
        "max_pred_length": 27,
        "distinct-1": 0.6935483870967742,
        "vocab_size-1": 43,
        "unique-1": 33,
        "entropy-1": 5.180419399886274,
        "distinct-2": 0.8813559322033898,
        "vocab_size-2": 52,
        "unique-2": 46,
        "entropy-2": 5.632560210342118,
        "cond_entropy-2": 0.4108940855293753,
        "distinct-3": 0.9464285714285714,
        "vocab_size-3": 53,
        "unique-3": 50,
        "entropy-3": 5.7002120649147505,
        "cond_entropy-3": 0.0810491495201104,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 18.333333333333332,
        "std_pred_length-nopunct": 4.784233364802441,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7454545454545455,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.141009150817864,
        "distinct-2-nopunct": 0.8653846153846154,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.416691881561029,
        "cond_entropy-2-nopunct": 0.31262603243778164,
        "distinct-3-nopunct": 0.9387755102040817,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.492260864523372,
        "cond_entropy-3-nopunct": 0.09294129948765639,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.570574264218091,
        "bleu": 23.84718,
        "rouge1": {
            "precision": 0.60141,
            "recall": 0.67715,
            "fmeasure": 0.63082
        },
        "rouge2": {
            "precision": 0.32234,
            "recall": 0.35992,
            "fmeasure": 0.33728
        },
        "rougeL": {
            "precision": 0.42383,
            "recall": 0.48601,
            "fmeasure": 0.44804
        },
        "rougeLsum": {
            "precision": 0.42383,
            "recall": 0.48601,
            "fmeasure": 0.44804
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.6,
            "3": 0.7222222222222222
        },
        "bertscore": {
            "precision": 0.88293,
            "recall": 0.92293,
            "f1": 0.90123
        },
        "bleurt": -0.00686,
        "meteor": 0.39002699350467007,
        "nubia": {
            "semantic_relation": 3.8828,
            "contradiction": 2.20483,
            "irrelevancy": 67.24491,
            "logical_agreement": 30.55026,
            "grammar_ref": 4.57112,
            "grammar_hyp": 4.22166,
            "nubia_score": 0.6538
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_203": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 91,
        "mean_pred_length": 18.2,
        "std_pred_length": 7.249827584156743,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 32,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 65,
        "unique-1": 54,
        "entropy-1": 5.743774998052213,
        "distinct-2": 0.9767441860465116,
        "vocab_size-2": 84,
        "unique-2": 82,
        "entropy-2": 6.379753126795122,
        "cond_entropy-2": 0.5454020559091419,
        "distinct-3": 1.0,
        "vocab_size-3": 81,
        "unique-3": 81,
        "entropy-3": 6.339850002884614,
        "cond_entropy-3": -0.03703203576809063,
        "total_length-nopunct": 77,
        "mean_pred_length-nopunct": 15.4,
        "std_pred_length-nopunct": 5.043808085167397,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7922077922077922,
        "vocab_size-1-nopunct": 61,
        "unique-1-nopunct": 53,
        "entropy-1-nopunct": 5.722420995748234,
        "distinct-2-nopunct": 0.9861111111111112,
        "vocab_size-2-nopunct": 71,
        "unique-2-nopunct": 70,
        "entropy-2-nopunct": 6.14214722366454,
        "cond_entropy-2-nopunct": 0.45752939075982285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 67,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 6.066089190457767,
        "cond_entropy-3-nopunct": -0.07398506471588322,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.319093343838162,
        "bleu": 30.69842,
        "rouge1": {
            "precision": 0.70001,
            "recall": 0.71549,
            "fmeasure": 0.69934
        },
        "rouge2": {
            "precision": 0.42063,
            "recall": 0.49848,
            "fmeasure": 0.44496
        },
        "rougeL": {
            "precision": 0.49395,
            "recall": 0.59344,
            "fmeasure": 0.52586
        },
        "rougeLsum": {
            "precision": 0.49395,
            "recall": 0.59344,
            "fmeasure": 0.52586
        },
        "local_recall": {
            "1": 0.2962962962962963,
            "2": 0.28125,
            "3": 0.775
        },
        "bertscore": {
            "precision": 0.9035,
            "recall": 0.91063,
            "f1": 0.89976
        },
        "bleurt": -0.01944,
        "meteor": 0.3745897352180726,
        "nubia": {
            "semantic_relation": 3.80493,
            "contradiction": 5.76137,
            "irrelevancy": 42.44331,
            "logical_agreement": 51.79532,
            "grammar_ref": 4.63083,
            "grammar_hyp": 4.0707,
            "nubia_score": 0.5979
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_219": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 2.5,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 16,
        "distinct-1": 0.8518518518518519,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.430632409490749,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.15916418769779478,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.303508854797679,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.18150945892357132,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.016137706633773,
        "bleu": 100.0,
        "rouge1": {
            "precision": 0.98333,
            "recall": 1.0,
            "fmeasure": 0.99123
        },
        "rouge2": {
            "precision": 0.96296,
            "recall": 0.97917,
            "fmeasure": 0.97059
        },
        "rougeL": {
            "precision": 0.98333,
            "recall": 1.0,
            "fmeasure": 0.99123
        },
        "rougeLsum": {
            "precision": 0.98333,
            "recall": 1.0,
            "fmeasure": 0.99123
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.95532,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.56394,
            "irrelevancy": 0.56148,
            "logical_agreement": 98.87458,
            "grammar_ref": 4.84371,
            "grammar_hyp": 4.6994,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_121": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 52,
        "mean_pred_length": 13.0,
        "std_pred_length": 3.082207001484488,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.7884615384615384,
        "vocab_size-1": 41,
        "unique-1": 36,
        "entropy-1": 5.154968026283396,
        "distinct-2": 1.0,
        "vocab_size-2": 48,
        "unique-2": 48,
        "entropy-2": 5.5849625007211605,
        "cond_entropy-2": 0.3087837820925703,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": -0.12553088208385924,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 11.75,
        "std_pred_length-nopunct": 3.2691742076555053,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8297872340425532,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.121301022388272,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.426264754702098,
        "cond_entropy-2-nopunct": 0.3452695768988856,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": -0.14086253583984967,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7008834254125405,
        "bleu": 27.32207,
        "rouge1": {
            "precision": 0.73657,
            "recall": 0.7352,
            "fmeasure": 0.7262
        },
        "rouge2": {
            "precision": 0.36131,
            "recall": 0.39678,
            "fmeasure": 0.37575
        },
        "rougeL": {
            "precision": 0.55972,
            "recall": 0.59931,
            "fmeasure": 0.57551
        },
        "rougeLsum": {
            "precision": 0.55972,
            "recall": 0.59931,
            "fmeasure": 0.57551
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.42857142857142855,
            "3": 0.6756756756756757
        },
        "bertscore": {
            "precision": 0.90463,
            "recall": 0.91018,
            "f1": 0.90557
        },
        "bleurt": 0.29408,
        "meteor": 0.34089566828399215,
        "nubia": {
            "semantic_relation": 3.77418,
            "contradiction": 26.70309,
            "irrelevancy": 33.28027,
            "logical_agreement": 40.01664,
            "grammar_ref": 5.13429,
            "grammar_hyp": 4.53996,
            "nubia_score": 0.63001
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_145": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.78,
        "total_length": 276,
        "mean_pred_length": 16.235294117647058,
        "std_pred_length": 5.651958658571441,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.5760869565217391,
        "vocab_size-1": 159,
        "unique-1": 121,
        "entropy-1": 6.60992624797785,
        "distinct-2": 0.8648648648648649,
        "vocab_size-2": 224,
        "unique-2": 198,
        "entropy-2": 7.706906115846794,
        "cond_entropy-2": 0.9270543900633466,
        "distinct-3": 0.9380165289256198,
        "vocab_size-3": 227,
        "unique-3": 214,
        "entropy-3": 7.786631832315918,
        "cond_entropy-3": 0.10149570374709128,
        "total_length-nopunct": 238,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.133511583357983,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6512605042016807,
        "vocab_size-1-nopunct": 155,
        "unique-1-nopunct": 121,
        "entropy-1-nopunct": 6.735098841504729,
        "distinct-2-nopunct": 0.8823529411764706,
        "vocab_size-2-nopunct": 195,
        "unique-2-nopunct": 175,
        "entropy-2-nopunct": 7.518627559371836,
        "cond_entropy-2-nopunct": 0.8591632050646819,
        "distinct-3-nopunct": 0.9509803921568627,
        "vocab_size-3-nopunct": 194,
        "unique-3-nopunct": 184,
        "entropy-3-nopunct": 7.574386126285222,
        "cond_entropy-3-nopunct": 0.06839422867970589,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.318710186599317,
        "bleu": 44.59028,
        "rouge1": {
            "precision": 0.82965,
            "recall": 0.7525,
            "fmeasure": 0.7827
        },
        "rouge2": {
            "precision": 0.57674,
            "recall": 0.53629,
            "fmeasure": 0.55189
        },
        "rougeL": {
            "precision": 0.66245,
            "recall": 0.61779,
            "fmeasure": 0.63259
        },
        "rougeLsum": {
            "precision": 0.66245,
            "recall": 0.61779,
            "fmeasure": 0.63259
        },
        "local_recall": {
            "1": 0.13846153846153847,
            "2": 0.5789473684210527,
            "3": 0.8023255813953488
        },
        "bertscore": {
            "precision": 0.94497,
            "recall": 0.93346,
            "f1": 0.93825
        },
        "bleurt": 0.20958,
        "meteor": 0.3999298828887175,
        "nubia": {
            "semantic_relation": 4.31244,
            "contradiction": 8.23956,
            "irrelevancy": 20.82483,
            "logical_agreement": 70.93561,
            "grammar_ref": 4.90086,
            "grammar_hyp": 4.95773,
            "nubia_score": 0.74398
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_146": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8421052631578947,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.8924071185928746,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 17,
        "unique-2": 16,
        "entropy-2": 4.058813890331201,
        "cond_entropy-2": 0.18615790478558614,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": 0.03518489863155644,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.794653473544342,
        "distinct-2-nopunct": 0.9411764705882353,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.969815782426811,
        "cond_entropy-2-nopunct": 0.19723710464117222,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": 0.037537158749660585,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.5652175776270818,
        "bleu": 16.19557,
        "rouge1": {
            "precision": 0.42593,
            "recall": 0.71818,
            "fmeasure": 0.53448
        },
        "rouge2": {
            "precision": 0.27451,
            "recall": 0.48148,
            "fmeasure": 0.34948
        },
        "rougeL": {
            "precision": 0.42593,
            "recall": 0.71818,
            "fmeasure": 0.53448
        },
        "rougeLsum": {
            "precision": 0.42593,
            "recall": 0.71818,
            "fmeasure": 0.53448
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6
        },
        "bertscore": {
            "precision": 0.85721,
            "recall": 0.91088,
            "f1": 0.88323
        },
        "bleurt": 0.18764,
        "meteor": 0.34268548401630916,
        "nubia": {
            "semantic_relation": 3.88405,
            "contradiction": 0.19921,
            "irrelevancy": 36.92861,
            "logical_agreement": 62.87218,
            "grammar_ref": 5.00001,
            "grammar_hyp": 4.04242,
            "nubia_score": 0.54152
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_174": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.76,
        "total_length": 201,
        "mean_pred_length": 18.272727272727273,
        "std_pred_length": 7.47226275928528,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 30,
        "distinct-1": 0.5870646766169154,
        "vocab_size-1": 118,
        "unique-1": 81,
        "entropy-1": 6.468423138131775,
        "distinct-2": 0.8947368421052632,
        "vocab_size-2": 170,
        "unique-2": 152,
        "entropy-2": 7.3513831083081795,
        "cond_entropy-2": 0.7511450558527648,
        "distinct-3": 0.9329608938547486,
        "vocab_size-3": 167,
        "unique-3": 155,
        "entropy-3": 7.349737564973744,
        "cond_entropy-3": 0.01178014102452032,
        "total_length-nopunct": 174,
        "mean_pred_length-nopunct": 15.818181818181818,
        "std_pred_length-nopunct": 6.235064799811727,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6494252873563219,
        "vocab_size-1-nopunct": 113,
        "unique-1-nopunct": 81,
        "entropy-1-nopunct": 6.488088229451352,
        "distinct-2-nopunct": 0.8895705521472392,
        "vocab_size-2-nopunct": 145,
        "unique-2-nopunct": 129,
        "entropy-2-nopunct": 7.118606835186142,
        "cond_entropy-2-nopunct": 0.6765517832217051,
        "distinct-3-nopunct": 0.9342105263157895,
        "vocab_size-3-nopunct": 142,
        "unique-3-nopunct": 132,
        "entropy-3-nopunct": 7.11634856607515,
        "cond_entropy-3-nopunct": 0.0012373526620275467,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.639685513175808,
        "bleu": 26.24867,
        "rouge1": {
            "precision": 0.65761,
            "recall": 0.66409,
            "fmeasure": 0.64631
        },
        "rouge2": {
            "precision": 0.39405,
            "recall": 0.4182,
            "fmeasure": 0.39571
        },
        "rougeL": {
            "precision": 0.5299,
            "recall": 0.5617,
            "fmeasure": 0.53512
        },
        "rougeLsum": {
            "precision": 0.5299,
            "recall": 0.5617,
            "fmeasure": 0.53512
        },
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.3333333333333333,
            "3": 0.6299212598425197
        },
        "bertscore": {
            "precision": 0.89931,
            "recall": 0.89986,
            "f1": 0.89745
        },
        "bleurt": 0.07943,
        "meteor": 0.29279378165633635,
        "nubia": {
            "semantic_relation": 3.96138,
            "contradiction": 14.92719,
            "irrelevancy": 36.97771,
            "logical_agreement": 48.0951,
            "grammar_ref": 4.8345,
            "grammar_hyp": 4.50021,
            "nubia_score": 0.65162
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_220": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 16,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.805,
        "total_length": 278,
        "mean_pred_length": 17.375,
        "std_pred_length": 5.18260311040697,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.6187050359712231,
        "vocab_size-1": 172,
        "unique-1": 140,
        "entropy-1": 6.854893950531992,
        "distinct-2": 0.9465648854961832,
        "vocab_size-2": 248,
        "unique-2": 238,
        "entropy-2": 7.9112855969573275,
        "cond_entropy-2": 0.8893105546507118,
        "distinct-3": 1.0,
        "vocab_size-3": 246,
        "unique-3": 246,
        "entropy-3": 7.942514505339281,
        "cond_entropy-3": 0.03104272331398446,
        "total_length-nopunct": 244,
        "mean_pred_length-nopunct": 15.25,
        "std_pred_length-nopunct": 4.602988159880492,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6844262295081968,
        "vocab_size-1-nopunct": 167,
        "unique-1-nopunct": 139,
        "entropy-1-nopunct": 6.947780054120661,
        "distinct-2-nopunct": 0.9517543859649122,
        "vocab_size-2-nopunct": 217,
        "unique-2-nopunct": 210,
        "entropy-2-nopunct": 7.718854926445475,
        "cond_entropy-2-nopunct": 0.8243308110719223,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 212,
        "unique-3-nopunct": 212,
        "entropy-3-nopunct": 7.727920454563212,
        "cond_entropy-3-nopunct": 0.01767194983241983,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.359813175797712,
        "bleu": 49.35475,
        "rouge1": {
            "precision": 0.79608,
            "recall": 0.79514,
            "fmeasure": 0.78522
        },
        "rouge2": {
            "precision": 0.56702,
            "recall": 0.57739,
            "fmeasure": 0.56342
        },
        "rougeL": {
            "precision": 0.68376,
            "recall": 0.68083,
            "fmeasure": 0.67276
        },
        "rougeLsum": {
            "precision": 0.68376,
            "recall": 0.68083,
            "fmeasure": 0.67276
        },
        "local_recall": {
            "1": 0.20454545454545456,
            "2": 0.35,
            "3": 0.8609625668449198
        },
        "bertscore": {
            "precision": 0.93648,
            "recall": 0.93942,
            "f1": 0.93657
        },
        "bleurt": 0.33317,
        "meteor": 0.4139264744328809,
        "nubia": {
            "semantic_relation": 4.38952,
            "contradiction": 1.613,
            "irrelevancy": 26.83182,
            "logical_agreement": 71.55518,
            "grammar_ref": 4.78068,
            "grammar_hyp": 4.70606,
            "nubia_score": 0.80277
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_204": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.76,
        "total_length": 257,
        "mean_pred_length": 21.416666666666668,
        "std_pred_length": 8.994983169646412,
        "median_pred_length": 20.5,
        "min_pred_length": 11,
        "max_pred_length": 37,
        "distinct-1": 0.6186770428015564,
        "vocab_size-1": 159,
        "unique-1": 132,
        "entropy-1": 6.680179472032691,
        "distinct-2": 0.963265306122449,
        "vocab_size-2": 236,
        "unique-2": 228,
        "entropy-2": 7.860087377769278,
        "cond_entropy-2": 1.0692376645826203,
        "distinct-3": 0.9957081545064378,
        "vocab_size-3": 232,
        "unique-3": 231,
        "entropy-3": 7.855602453667196,
        "cond_entropy-3": -0.0005424059269878666,
        "total_length-nopunct": 220,
        "mean_pred_length-nopunct": 18.333333333333332,
        "std_pred_length-nopunct": 7.586537784494028,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.7045454545454546,
        "vocab_size-1-nopunct": 155,
        "unique-1-nopunct": 132,
        "entropy-1-nopunct": 6.865990763781822,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 200,
        "unique-2-nopunct": 193,
        "entropy-2-nopunct": 7.619887374380666,
        "cond_entropy-2-nopunct": 0.8018986653917121,
        "distinct-3-nopunct": 0.9948979591836735,
        "vocab_size-3-nopunct": 195,
        "unique-3-nopunct": 194,
        "entropy-3-nopunct": 7.60450576248254,
        "cond_entropy-3-nopunct": -0.010449835749539576,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.474213989378374,
        "bleu": 33.63498,
        "rouge1": {
            "precision": 0.74351,
            "recall": 0.7158,
            "fmeasure": 0.72398
        },
        "rouge2": {
            "precision": 0.4706,
            "recall": 0.45937,
            "fmeasure": 0.46058
        },
        "rougeL": {
            "precision": 0.6425,
            "recall": 0.61768,
            "fmeasure": 0.62525
        },
        "rougeLsum": {
            "precision": 0.6425,
            "recall": 0.61768,
            "fmeasure": 0.62525
        },
        "local_recall": {
            "1": 0.14,
            "2": 0.19230769230769232,
            "3": 0.7470588235294118
        },
        "bertscore": {
            "precision": 0.91666,
            "recall": 0.91262,
            "f1": 0.91225
        },
        "bleurt": 0.30223,
        "meteor": 0.34551571986909074,
        "nubia": {
            "semantic_relation": 4.2342,
            "contradiction": 7.17582,
            "irrelevancy": 40.31126,
            "logical_agreement": 52.51293,
            "grammar_ref": 4.36261,
            "grammar_hyp": 4.20501,
            "nubia_score": 0.77007
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_205": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.64,
        "msttr-100_nopunct": 0.7,
        "total_length": 186,
        "mean_pred_length": 15.5,
        "std_pred_length": 2.5,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 19,
        "distinct-1": 0.6075268817204301,
        "vocab_size-1": 113,
        "unique-1": 93,
        "entropy-1": 6.263339942004642,
        "distinct-2": 0.9310344827586207,
        "vocab_size-2": 162,
        "unique-2": 153,
        "entropy-2": 7.289179774571909,
        "cond_entropy-2": 0.8665885476281372,
        "distinct-3": 0.9753086419753086,
        "vocab_size-3": 158,
        "unique-3": 154,
        "entropy-3": 7.290467286835223,
        "cond_entropy-3": 0.012677417543078478,
        "total_length-nopunct": 161,
        "mean_pred_length-nopunct": 13.416666666666666,
        "std_pred_length-nopunct": 2.4986107250941583,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6770186335403726,
        "vocab_size-1-nopunct": 109,
        "unique-1-nopunct": 93,
        "entropy-1-nopunct": 6.305317498078281,
        "distinct-2-nopunct": 0.9328859060402684,
        "vocab_size-2-nopunct": 139,
        "unique-2-nopunct": 132,
        "entropy-2-nopunct": 7.066451154675836,
        "cond_entropy-2-nopunct": 0.823598036197776,
        "distinct-3-nopunct": 0.9854014598540146,
        "vocab_size-3-nopunct": 135,
        "unique-3-nopunct": 133,
        "entropy-3-nopunct": 7.068835002668541,
        "cond_entropy-3-nopunct": 0.0011620114192665183,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.599894643913875,
        "bleu": 45.17973,
        "rouge1": {
            "precision": 0.83005,
            "recall": 0.77468,
            "fmeasure": 0.79281
        },
        "rouge2": {
            "precision": 0.61457,
            "recall": 0.55686,
            "fmeasure": 0.57764
        },
        "rougeL": {
            "precision": 0.7369,
            "recall": 0.68345,
            "fmeasure": 0.70208
        },
        "rougeLsum": {
            "precision": 0.7369,
            "recall": 0.68345,
            "fmeasure": 0.70208
        },
        "local_recall": {
            "1": 0.11428571428571428,
            "2": 0.3448275862068966,
            "3": 0.8099173553719008
        },
        "bertscore": {
            "precision": 0.93122,
            "recall": 0.92758,
            "f1": 0.92891
        },
        "bleurt": 0.27013,
        "meteor": 0.38858158027335565,
        "nubia": {
            "semantic_relation": 4.34286,
            "contradiction": 5.26355,
            "irrelevancy": 27.63396,
            "logical_agreement": 67.10249,
            "grammar_ref": 4.24445,
            "grammar_hyp": 4.28276,
            "nubia_score": 0.78549
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_221": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 69,
        "mean_pred_length": 13.8,
        "std_pred_length": 4.707440918375928,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.5942028985507246,
        "vocab_size-1": 41,
        "unique-1": 29,
        "entropy-1": 5.04919715344772,
        "distinct-2": 0.84375,
        "vocab_size-2": 54,
        "unique-2": 47,
        "entropy-2": 5.644454882778696,
        "cond_entropy-2": 0.4966170424905897,
        "distinct-3": 0.9491525423728814,
        "vocab_size-3": 56,
        "unique-3": 54,
        "entropy-3": 5.7681534306811,
        "cond_entropy-3": 0.07323817644381639,
        "total_length-nopunct": 62,
        "mean_pred_length-nopunct": 12.4,
        "std_pred_length-nopunct": 4.363484845854286,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6290322580645161,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.9947778675584225,
        "distinct-2-nopunct": 0.8596491228070176,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.517100540480526,
        "cond_entropy-2-nopunct": 0.5012190275561824,
        "distinct-3-nopunct": 0.9807692307692307,
        "vocab_size-3-nopunct": 51,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.661978179679557,
        "cond_entropy-3-nopunct": 0.059857396284042574,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.661601632057773,
        "bleu": 35.85496,
        "rouge1": {
            "precision": 0.75561,
            "recall": 0.73678,
            "fmeasure": 0.73927
        },
        "rouge2": {
            "precision": 0.61571,
            "recall": 0.61199,
            "fmeasure": 0.60798
        },
        "rougeL": {
            "precision": 0.65107,
            "recall": 0.64547,
            "fmeasure": 0.64231
        },
        "rougeLsum": {
            "precision": 0.65107,
            "recall": 0.64547,
            "fmeasure": 0.64231
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.7380952380952381
        },
        "bertscore": {
            "precision": 0.91421,
            "recall": 0.91378,
            "f1": 0.91317
        },
        "bleurt": 0.18102,
        "meteor": 0.35971600631331574,
        "nubia": {
            "semantic_relation": 4.36276,
            "contradiction": 5.3033,
            "irrelevancy": 16.33123,
            "logical_agreement": 78.36547,
            "grammar_ref": 3.91039,
            "grammar_hyp": 3.95661,
            "nubia_score": 0.79706
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_207": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 12.0,
        "std_pred_length": 4.242640687119285,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 15,
        "distinct-1": 0.8611111111111112,
        "vocab_size-1": 31,
        "unique-1": 28,
        "entropy-1": 4.850209029099895,
        "distinct-2": 1.0,
        "vocab_size-2": 33,
        "unique-2": 33,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": 0.07916267858776119,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.13750352374993471,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 10.666666666666666,
        "std_pred_length-nopunct": 4.027681991198191,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.90625,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.788909765557392,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.0909081503745883,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.15754127698647996,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.651985150766518,
        "bleu": 50.57498,
        "rouge1": {
            "precision": 0.67302,
            "recall": 0.69133,
            "fmeasure": 0.67818
        },
        "rouge2": {
            "precision": 0.45085,
            "recall": 0.43611,
            "fmeasure": 0.44182
        },
        "rougeL": {
            "precision": 0.60586,
            "recall": 0.62697,
            "fmeasure": 0.61257
        },
        "rougeLsum": {
            "precision": 0.60586,
            "recall": 0.62697,
            "fmeasure": 0.61257
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.4444444444444444,
            "3": 0.7727272727272727
        },
        "bertscore": {
            "precision": 0.8858,
            "recall": 0.88913,
            "f1": 0.88738
        },
        "bleurt": 0.03955,
        "meteor": 0.354561988745686,
        "nubia": {
            "semantic_relation": 4.04326,
            "contradiction": 1.16035,
            "irrelevancy": 45.83081,
            "logical_agreement": 53.00884,
            "grammar_ref": 5.944,
            "grammar_hyp": 6.38964,
            "nubia_score": 0.6359
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_challenge_test_asset_bfp02",
        "N": 359,
        "msttr-100": 0.73228,
        "msttr-100_nopunct": 0.7796,
        "total_length": 5704,
        "mean_pred_length": 15.88857938718663,
        "std_pred_length": 7.359745812699083,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 46,
        "distinct-1": 0.4107643758765778,
        "vocab_size-1": 2343,
        "unique-1": 1843,
        "entropy-1": 9.099247264775759,
        "distinct-2": 0.8512628624883068,
        "vocab_size-2": 4550,
        "unique-2": 4232,
        "entropy-2": 11.876357501863694,
        "cond_entropy-2": 2.4249248014321165,
        "distinct-3": 0.9598876855194545,
        "vocab_size-3": 4786,
        "unique-3": 4696,
        "entropy-3": 12.14753526533966,
        "cond_entropy-3": 0.29249938277610404,
        "total_length-nopunct": 5071,
        "mean_pred_length-nopunct": 14.125348189415043,
        "std_pred_length-nopunct": 6.575331490521254,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.4600670479195425,
        "vocab_size-1-nopunct": 2333,
        "unique-1-nopunct": 1841,
        "entropy-1-nopunct": 9.470960041646197,
        "distinct-2-nopunct": 0.865025466893039,
        "vocab_size-2-nopunct": 4076,
        "unique-2-nopunct": 3816,
        "entropy-2-nopunct": 11.752783078245454,
        "cond_entropy-2-nopunct": 2.447475180537976,
        "distinct-3-nopunct": 0.9735814380886745,
        "vocab_size-3-nopunct": 4238,
        "unique-3-nopunct": 4162,
        "entropy-3-nopunct": 12.02314022933918,
        "cond_entropy-3-nopunct": 0.2996336621843798,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp02.json",
        "nist": 9.07164268690971,
        "bleu": 51.18338,
        "rouge1": {
            "precision": 0.7451,
            "recall": 0.66193,
            "fmeasure": 0.68535
        },
        "rouge2": {
            "precision": 0.54789,
            "recall": 0.48054,
            "fmeasure": 0.49596
        },
        "rougeL": {
            "precision": 0.70864,
            "recall": 0.63534,
            "fmeasure": 0.65364
        },
        "rougeLsum": {
            "precision": 0.70864,
            "recall": 0.63534,
            "fmeasure": 0.65364
        },
        "local_recall": {
            "1": 0.04077294685990338,
            "2": 0.12637362637362637,
            "3": 0.205158264947245,
            "4": 0.3286118980169972,
            "5": 0.4169986719787517,
            "6": 0.4667487684729064,
            "7": 0.5810502283105022,
            "8": 0.6587301587301587,
            "9": 0.7733812949640287
        },
        "sari": 45.06948,
        "bertscore": {
            "precision": 0.90396,
            "recall": 0.90983,
            "f1": 0.90237
        },
        "bleurt": -0.42081,
        "meteor": 0.35010025182525656,
        "nubia": {
            "semantic_relation": 3.71869,
            "contradiction": 5.98927,
            "irrelevancy": 25.02242,
            "logical_agreement": 68.98831,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.85713,
            "nubia_score": 0.45672
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_222": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.79,
        "total_length": 228,
        "mean_pred_length": 20.727272727272727,
        "std_pred_length": 12.461510991783745,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 50,
        "distinct-1": 0.6359649122807017,
        "vocab_size-1": 145,
        "unique-1": 123,
        "entropy-1": 6.646062616273387,
        "distinct-2": 0.9262672811059908,
        "vocab_size-2": 201,
        "unique-2": 191,
        "entropy-2": 7.588695126433768,
        "cond_entropy-2": 0.8210680579432148,
        "distinct-3": 0.9805825242718447,
        "vocab_size-3": 202,
        "unique-3": 199,
        "entropy-3": 7.644001073289221,
        "cond_entropy-3": 0.06453612727351307,
        "total_length-nopunct": 192,
        "mean_pred_length-nopunct": 17.454545454545453,
        "std_pred_length-nopunct": 9.875254992000196,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.7291666666666666,
        "vocab_size-1-nopunct": 140,
        "unique-1-nopunct": 122,
        "entropy-1-nopunct": 6.771149482878088,
        "distinct-2-nopunct": 0.9447513812154696,
        "vocab_size-2-nopunct": 171,
        "unique-2-nopunct": 166,
        "entropy-2-nopunct": 7.363078552817081,
        "cond_entropy-2-nopunct": 0.619802288727245,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 170,
        "unique-3-nopunct": 170,
        "entropy-3-nopunct": 7.40939093613767,
        "cond_entropy-3-nopunct": 0.04583872553356872,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.893585891503966,
        "bleu": 35.89887,
        "rouge1": {
            "precision": 0.68378,
            "recall": 0.65522,
            "fmeasure": 0.63992
        },
        "rouge2": {
            "precision": 0.42202,
            "recall": 0.39206,
            "fmeasure": 0.38699
        },
        "rougeL": {
            "precision": 0.57103,
            "recall": 0.52633,
            "fmeasure": 0.5222
        },
        "rougeLsum": {
            "precision": 0.57103,
            "recall": 0.52633,
            "fmeasure": 0.5222
        },
        "local_recall": {
            "1": 0.16216216216216217,
            "2": 0.525,
            "3": 0.7394957983193278
        },
        "bertscore": {
            "precision": 0.89781,
            "recall": 0.89642,
            "f1": 0.89551
        },
        "bleurt": -0.09612,
        "meteor": 0.34853982059662264,
        "nubia": {
            "semantic_relation": 3.75106,
            "contradiction": 10.53369,
            "irrelevancy": 39.6076,
            "logical_agreement": 49.85871,
            "grammar_ref": 4.70623,
            "grammar_hyp": 5.02791,
            "nubia_score": 0.60194
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_123": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 70,
        "mean_pred_length": 17.5,
        "std_pred_length": 4.716990566028302,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 25,
        "distinct-1": 0.7857142857142857,
        "vocab_size-1": 55,
        "unique-1": 45,
        "entropy-1": 5.639787838280821,
        "distinct-2": 0.9696969696969697,
        "vocab_size-2": 64,
        "unique-2": 62,
        "entropy-2": 5.983788058752401,
        "cond_entropy-2": 0.25245447372394747,
        "distinct-3": 1.0,
        "vocab_size-3": 62,
        "unique-3": 62,
        "entropy-3": 5.954196310386873,
        "cond_entropy-3": -0.02568167993932008,
        "total_length-nopunct": 59,
        "mean_pred_length-nopunct": 14.75,
        "std_pred_length-nopunct": 4.264680527307995,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.864406779661017,
        "vocab_size-1-nopunct": 51,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.585867201830872,
        "distinct-2-nopunct": 0.9818181818181818,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 53,
        "entropy-2-nopunct": 5.744996077161019,
        "cond_entropy-2-nopunct": 0.18071257333239893,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 51,
        "unique-3-nopunct": 51,
        "entropy-3-nopunct": 5.6724253419715005,
        "cond_entropy-3-nopunct": -0.06971868527865421,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.545138793601276,
        "bleu": 54.0082,
        "rouge1": {
            "precision": 0.85928,
            "recall": 0.92288,
            "fmeasure": 0.88841
        },
        "rouge2": {
            "precision": 0.69028,
            "recall": 0.7325,
            "fmeasure": 0.70948
        },
        "rougeL": {
            "precision": 0.74564,
            "recall": 0.79421,
            "fmeasure": 0.76796
        },
        "rougeLsum": {
            "precision": 0.74564,
            "recall": 0.79421,
            "fmeasure": 0.76796
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.4,
            "3": 0.9387755102040817
        },
        "bertscore": {
            "precision": 0.95995,
            "recall": 0.95503,
            "f1": 0.95575
        },
        "bleurt": 0.49158,
        "meteor": 0.46514678013835953,
        "nubia": {
            "semantic_relation": 4.28422,
            "contradiction": 9.96064,
            "irrelevancy": 31.40134,
            "logical_agreement": 58.63802,
            "grammar_ref": 5.56433,
            "grammar_hyp": 4.81028,
            "nubia_score": 0.82905
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_175": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 21,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.78,
        "total_length": 328,
        "mean_pred_length": 15.619047619047619,
        "std_pred_length": 3.4430909490524226,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 21,
        "distinct-1": 0.6310975609756098,
        "vocab_size-1": 207,
        "unique-1": 174,
        "entropy-1": 7.050840179996413,
        "distinct-2": 0.9478827361563518,
        "vocab_size-2": 291,
        "unique-2": 282,
        "entropy-2": 8.130939592906003,
        "cond_entropy-2": 0.8690319289966182,
        "distinct-3": 0.9965034965034965,
        "vocab_size-3": 285,
        "unique-3": 284,
        "entropy-3": 8.152878329785432,
        "cond_entropy-3": 0.02457601066167309,
        "total_length-nopunct": 293,
        "mean_pred_length-nopunct": 13.952380952380953,
        "std_pred_length-nopunct": 3.1543800307960375,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.689419795221843,
        "vocab_size-1-nopunct": 202,
        "unique-1-nopunct": 173,
        "entropy-1-nopunct": 7.157782494065364,
        "distinct-2-nopunct": 0.9522058823529411,
        "vocab_size-2-nopunct": 259,
        "unique-2-nopunct": 252,
        "entropy-2-nopunct": 7.964265139028562,
        "cond_entropy-2-nopunct": 0.8623337444734186,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 251,
        "unique-3-nopunct": 251,
        "entropy-3-nopunct": 7.971543553950766,
        "cond_entropy-3-nopunct": 0.017585792398946486,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.30532017898352,
        "bleu": 45.6488,
        "rouge1": {
            "precision": 0.7404,
            "recall": 0.70182,
            "fmeasure": 0.71552
        },
        "rouge2": {
            "precision": 0.53099,
            "recall": 0.50968,
            "fmeasure": 0.51684
        },
        "rougeL": {
            "precision": 0.64147,
            "recall": 0.60452,
            "fmeasure": 0.61829
        },
        "rougeLsum": {
            "precision": 0.64147,
            "recall": 0.60452,
            "fmeasure": 0.61829
        },
        "local_recall": {
            "1": 0.22727272727272727,
            "2": 0.46808510638297873,
            "3": 0.7628865979381443
        },
        "bertscore": {
            "precision": 0.92856,
            "recall": 0.92378,
            "f1": 0.92406
        },
        "bleurt": 0.2465,
        "meteor": 0.3764556497288627,
        "nubia": {
            "semantic_relation": 4.11093,
            "contradiction": 9.04342,
            "irrelevancy": 28.45556,
            "logical_agreement": 62.50102,
            "grammar_ref": 4.90831,
            "grammar_hyp": 4.83174,
            "nubia_score": 0.68668
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_176": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.68333,
        "msttr-100_nopunct": 0.76333,
        "total_length": 372,
        "mean_pred_length": 16.17391304347826,
        "std_pred_length": 6.881937125630706,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 34,
        "distinct-1": 0.5698924731182796,
        "vocab_size-1": 212,
        "unique-1": 174,
        "entropy-1": 6.925472530848419,
        "distinct-2": 0.9054441260744985,
        "vocab_size-2": 316,
        "unique-2": 294,
        "entropy-2": 8.221664789352786,
        "cond_entropy-2": 1.1044239474919246,
        "distinct-3": 0.9785276073619632,
        "vocab_size-3": 319,
        "unique-3": 312,
        "entropy-3": 8.305783368955037,
        "cond_entropy-3": 0.07548245704920786,
        "total_length-nopunct": 311,
        "mean_pred_length-nopunct": 13.521739130434783,
        "std_pred_length-nopunct": 5.62501837846189,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.662379421221865,
        "vocab_size-1-nopunct": 206,
        "unique-1-nopunct": 172,
        "entropy-1-nopunct": 7.138678418872377,
        "distinct-2-nopunct": 0.9270833333333334,
        "vocab_size-2-nopunct": 267,
        "unique-2-nopunct": 253,
        "entropy-2-nopunct": 7.992281739432804,
        "cond_entropy-2-nopunct": 0.9268609562462221,
        "distinct-3-nopunct": 0.9924528301886792,
        "vocab_size-3-nopunct": 263,
        "unique-3-nopunct": 261,
        "entropy-3-nopunct": 8.034754209827872,
        "cond_entropy-3-nopunct": 0.05789056483364605,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.72889944890889,
        "bleu": 56.16144,
        "rouge1": {
            "precision": 0.80871,
            "recall": 0.73706,
            "fmeasure": 0.75653
        },
        "rouge2": {
            "precision": 0.60246,
            "recall": 0.54838,
            "fmeasure": 0.56351
        },
        "rougeL": {
            "precision": 0.69748,
            "recall": 0.66368,
            "fmeasure": 0.66748
        },
        "rougeLsum": {
            "precision": 0.69748,
            "recall": 0.66368,
            "fmeasure": 0.66748
        },
        "local_recall": {
            "1": 0.2328767123287671,
            "2": 0.29069767441860467,
            "3": 0.8247863247863247
        },
        "bertscore": {
            "precision": 0.94267,
            "recall": 0.92843,
            "f1": 0.93114
        },
        "bleurt": 0.34263,
        "meteor": 0.40693156494374183,
        "nubia": {
            "semantic_relation": 4.33878,
            "contradiction": 3.47492,
            "irrelevancy": 22.24111,
            "logical_agreement": 74.28397,
            "grammar_ref": 4.50686,
            "grammar_hyp": 4.62466,
            "nubia_score": 0.76284
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_224": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.69667,
        "msttr-100_nopunct": 0.745,
        "total_length": 310,
        "mean_pred_length": 17.22222222222222,
        "std_pred_length": 6.303046490525705,
        "median_pred_length": 16.5,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.6064516129032258,
        "vocab_size-1": 188,
        "unique-1": 156,
        "entropy-1": 6.904594811389059,
        "distinct-2": 0.9212328767123288,
        "vocab_size-2": 269,
        "unique-2": 253,
        "entropy-2": 8.007908752445934,
        "cond_entropy-2": 0.9308101145635683,
        "distinct-3": 0.9817518248175182,
        "vocab_size-3": 269,
        "unique-3": 264,
        "entropy-3": 8.061535732595523,
        "cond_entropy-3": 0.04822404954255448,
        "total_length-nopunct": 266,
        "mean_pred_length-nopunct": 14.777777777777779,
        "std_pred_length-nopunct": 4.98392477600129,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6842105263157895,
        "vocab_size-1-nopunct": 182,
        "unique-1-nopunct": 155,
        "entropy-1-nopunct": 7.014716545299232,
        "distinct-2-nopunct": 0.9314516129032258,
        "vocab_size-2-nopunct": 231,
        "unique-2-nopunct": 220,
        "entropy-2-nopunct": 7.791436116932863,
        "cond_entropy-2-nopunct": 0.8297245051937853,
        "distinct-3-nopunct": 0.9826086956521739,
        "vocab_size-3-nopunct": 226,
        "unique-3-nopunct": 222,
        "entropy-3-nopunct": 7.810707442248712,
        "cond_entropy-3-nopunct": 0.02766125349924041,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.018738975050465,
        "bleu": 41.03564,
        "rouge1": {
            "precision": 0.75154,
            "recall": 0.71563,
            "fmeasure": 0.71888
        },
        "rouge2": {
            "precision": 0.53778,
            "recall": 0.50924,
            "fmeasure": 0.50905
        },
        "rougeL": {
            "precision": 0.61635,
            "recall": 0.61917,
            "fmeasure": 0.60052
        },
        "rougeLsum": {
            "precision": 0.61635,
            "recall": 0.61917,
            "fmeasure": 0.60052
        },
        "local_recall": {
            "1": 0.25555555555555554,
            "2": 0.28,
            "3": 0.7525252525252525
        },
        "bertscore": {
            "precision": 0.91863,
            "recall": 0.92015,
            "f1": 0.91513
        },
        "bleurt": 0.18702,
        "meteor": 0.39862793767597343,
        "nubia": {
            "semantic_relation": 4.11845,
            "contradiction": 9.89453,
            "irrelevancy": 32.29368,
            "logical_agreement": 57.81179,
            "grammar_ref": 4.41455,
            "grammar_hyp": 4.18259,
            "nubia_score": 0.72624
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_177": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 12.666666666666666,
        "std_pred_length": 2.8674417556808756,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 34,
        "unique-1": 31,
        "entropy-1": 5.017535737070865,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": -0.00435878221290464,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.12928301694496638,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.943920288775949,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9393939393939394,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.923181998146335,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": -0.004170190416601396,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.15200309344505,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.654503820044667,
        "bleu": 41.65045,
        "rouge1": {
            "precision": 0.87778,
            "recall": 0.76129,
            "fmeasure": 0.80568
        },
        "rouge2": {
            "precision": 0.64153,
            "recall": 0.53214,
            "fmeasure": 0.57087
        },
        "rougeL": {
            "precision": 0.85556,
            "recall": 0.72216,
            "fmeasure": 0.77188
        },
        "rougeLsum": {
            "precision": 0.85556,
            "recall": 0.72216,
            "fmeasure": 0.77188
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.14285714285714285,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.93922,
            "recall": 0.93256,
            "f1": 0.93428
        },
        "bleurt": 0.27712,
        "meteor": 0.4213052093694034,
        "nubia": {
            "semantic_relation": 4.59503,
            "contradiction": 0.57707,
            "irrelevancy": 33.41662,
            "logical_agreement": 66.00631,
            "grammar_ref": 5.80868,
            "grammar_hyp": 6.34322,
            "nubia_score": 0.79027
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_245": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.79333,
        "msttr-100_nopunct": 0.82,
        "total_length": 322,
        "mean_pred_length": 16.1,
        "std_pred_length": 5.7,
        "median_pred_length": 14.5,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.65527950310559,
        "vocab_size-1": 211,
        "unique-1": 178,
        "entropy-1": 7.206313045336495,
        "distinct-2": 0.9635761589403974,
        "vocab_size-2": 291,
        "unique-2": 283,
        "entropy-2": 8.158058174734085,
        "cond_entropy-2": 0.7400018007810792,
        "distinct-3": 0.9893617021276596,
        "vocab_size-3": 279,
        "unique-3": 276,
        "entropy-3": 8.118274756654149,
        "cond_entropy-3": -0.050946383364842134,
        "total_length-nopunct": 278,
        "mean_pred_length-nopunct": 13.9,
        "std_pred_length-nopunct": 4.988987873306568,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.7338129496402878,
        "vocab_size-1-nopunct": 204,
        "unique-1-nopunct": 177,
        "entropy-1-nopunct": 7.323930864832249,
        "distinct-2-nopunct": 0.9651162790697675,
        "vocab_size-2-nopunct": 249,
        "unique-2-nopunct": 242,
        "entropy-2-nopunct": 7.935607972460713,
        "cond_entropy-2-nopunct": 0.6733058059146048,
        "distinct-3-nopunct": 0.9873949579831933,
        "vocab_size-3-nopunct": 235,
        "unique-3-nopunct": 232,
        "entropy-3-nopunct": 7.869607679274377,
        "cond_entropy-3-nopunct": -0.059645731592928616,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.453926269421241,
        "bleu": 54.16576,
        "rouge1": {
            "precision": 0.80882,
            "recall": 0.76691,
            "fmeasure": 0.77054
        },
        "rouge2": {
            "precision": 0.64224,
            "recall": 0.59772,
            "fmeasure": 0.60659
        },
        "rougeL": {
            "precision": 0.72438,
            "recall": 0.67194,
            "fmeasure": 0.68485
        },
        "rougeLsum": {
            "precision": 0.72438,
            "recall": 0.67194,
            "fmeasure": 0.68485
        },
        "local_recall": {
            "1": 0.20454545454545456,
            "2": 0.5303030303030303,
            "3": 0.8398058252427184
        },
        "bertscore": {
            "precision": 0.94068,
            "recall": 0.93239,
            "f1": 0.93416
        },
        "bleurt": 0.32242,
        "meteor": 0.4313390351633588,
        "nubia": {
            "semantic_relation": 4.24061,
            "contradiction": 17.54096,
            "irrelevancy": 21.77648,
            "logical_agreement": 60.68256,
            "grammar_ref": 4.67668,
            "grammar_hyp": 4.833,
            "nubia_score": 0.70361
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_147": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.775,
        "total_length": 262,
        "mean_pred_length": 15.411764705882353,
        "std_pred_length": 4.499134864934811,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.6221374045801527,
        "vocab_size-1": 163,
        "unique-1": 130,
        "entropy-1": 6.807282762104435,
        "distinct-2": 0.9428571428571428,
        "vocab_size-2": 231,
        "unique-2": 219,
        "entropy-2": 7.814188959410761,
        "cond_entropy-2": 0.8083654453434832,
        "distinct-3": 0.9868421052631579,
        "vocab_size-3": 225,
        "unique-3": 222,
        "entropy-3": 7.806574224691091,
        "cond_entropy-3": -0.007256696767653323,
        "total_length-nopunct": 233,
        "mean_pred_length-nopunct": 13.705882352941176,
        "std_pred_length-nopunct": 4.442637079646872,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6738197424892703,
        "vocab_size-1-nopunct": 157,
        "unique-1-nopunct": 128,
        "entropy-1-nopunct": 6.867396018363004,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 204,
        "unique-2-nopunct": 194,
        "entropy-2-nopunct": 7.634517131793093,
        "cond_entropy-2-nopunct": 0.8011973617922943,
        "distinct-3-nopunct": 0.9899497487437185,
        "vocab_size-3-nopunct": 197,
        "unique-3-nopunct": 195,
        "entropy-3-nopunct": 7.616524118031097,
        "cond_entropy-3-nopunct": -0.02278549468514629,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.116525271214895,
        "bleu": 49.75088,
        "rouge1": {
            "precision": 0.77433,
            "recall": 0.74901,
            "fmeasure": 0.75357
        },
        "rouge2": {
            "precision": 0.57968,
            "recall": 0.56502,
            "fmeasure": 0.56593
        },
        "rougeL": {
            "precision": 0.68825,
            "recall": 0.67466,
            "fmeasure": 0.67485
        },
        "rougeLsum": {
            "precision": 0.68825,
            "recall": 0.67466,
            "fmeasure": 0.67485
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.42857142857142855,
            "3": 0.7741935483870968
        },
        "bertscore": {
            "precision": 0.93798,
            "recall": 0.93385,
            "f1": 0.93439
        },
        "bleurt": 0.36047,
        "meteor": 0.39473032041838646,
        "nubia": {
            "semantic_relation": 4.34217,
            "contradiction": 16.46239,
            "irrelevancy": 19.32788,
            "logical_agreement": 64.20973,
            "grammar_ref": 4.21928,
            "grammar_hyp": 4.09126,
            "nubia_score": 0.7735
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_246": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 60,
        "mean_pred_length": 12.0,
        "std_pred_length": 3.847076812334269,
        "median_pred_length": 11.0,
        "min_pred_length": 8,
        "max_pred_length": 17,
        "distinct-1": 0.85,
        "vocab_size-1": 51,
        "unique-1": 45,
        "entropy-1": 5.54672992103457,
        "distinct-2": 1.0,
        "vocab_size-2": 55,
        "unique-2": 55,
        "entropy-2": 5.7813597135246555,
        "cond_entropy-2": 0.05628729973432302,
        "distinct-3": 1.0,
        "vocab_size-3": 50,
        "unique-3": 50,
        "entropy-3": 5.643856189774728,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 53,
        "mean_pred_length-nopunct": 10.6,
        "std_pred_length-nopunct": 3.6660605559646715,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9245283018867925,
        "vocab_size-1-nopunct": 49,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.576977058336781,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.5849625007211605,
        "cond_entropy-2-nopunct": 0.023708712824623574,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.426264754702098,
        "cond_entropy-3-nopunct": -0.1586977460190584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.529654389357397,
        "bleu": 52.05005,
        "rouge1": {
            "precision": 0.83397,
            "recall": 0.73767,
            "fmeasure": 0.77853
        },
        "rouge2": {
            "precision": 0.63333,
            "recall": 0.58212,
            "fmeasure": 0.60317
        },
        "rougeL": {
            "precision": 0.74952,
            "recall": 0.69571,
            "fmeasure": 0.71801
        },
        "rougeLsum": {
            "precision": 0.74952,
            "recall": 0.69571,
            "fmeasure": 0.71801
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.75,
            "3": 0.7346938775510204
        },
        "bertscore": {
            "precision": 0.95216,
            "recall": 0.949,
            "f1": 0.94957
        },
        "bleurt": 0.50401,
        "meteor": 0.41959577907637696,
        "nubia": {
            "semantic_relation": 4.59142,
            "contradiction": 38.87235,
            "irrelevancy": 22.58355,
            "logical_agreement": 38.5441,
            "grammar_ref": 5.41078,
            "grammar_hyp": 5.55627,
            "nubia_score": 0.76978
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_225": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.72,
        "total_length": 327,
        "mean_pred_length": 19.235294117647058,
        "std_pred_length": 9.944134610351417,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 52,
        "distinct-1": 0.5474006116207951,
        "vocab_size-1": 179,
        "unique-1": 136,
        "entropy-1": 6.859431376268439,
        "distinct-2": 0.8774193548387097,
        "vocab_size-2": 272,
        "unique-2": 242,
        "entropy-2": 8.008319405246292,
        "cond_entropy-2": 1.0243498439356096,
        "distinct-3": 0.9419795221843004,
        "vocab_size-3": 276,
        "unique-3": 261,
        "entropy-3": 8.073563083076467,
        "cond_entropy-3": 0.06712997476004716,
        "total_length-nopunct": 281,
        "mean_pred_length-nopunct": 16.529411764705884,
        "std_pred_length-nopunct": 7.814900150344954,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.6192170818505338,
        "vocab_size-1-nopunct": 174,
        "unique-1-nopunct": 136,
        "entropy-1-nopunct": 6.970782494079322,
        "distinct-2-nopunct": 0.8787878787878788,
        "vocab_size-2-nopunct": 232,
        "unique-2-nopunct": 208,
        "entropy-2-nopunct": 7.775380672355984,
        "cond_entropy-2-nopunct": 0.8605903943539593,
        "distinct-3-nopunct": 0.9433198380566802,
        "vocab_size-3-nopunct": 233,
        "unique-3-nopunct": 221,
        "entropy-3-nopunct": 7.828894458287838,
        "cond_entropy-3-nopunct": 0.05988313248665779,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.8252529109269515,
        "bleu": 42.78554,
        "rouge1": {
            "precision": 0.72569,
            "recall": 0.73132,
            "fmeasure": 0.71148
        },
        "rouge2": {
            "precision": 0.46481,
            "recall": 0.48847,
            "fmeasure": 0.46533
        },
        "rougeL": {
            "precision": 0.61258,
            "recall": 0.6321,
            "fmeasure": 0.60696
        },
        "rougeLsum": {
            "precision": 0.61258,
            "recall": 0.6321,
            "fmeasure": 0.60696
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.4523809523809524,
            "3": 0.7830188679245284
        },
        "bertscore": {
            "precision": 0.90587,
            "recall": 0.92026,
            "f1": 0.90946
        },
        "bleurt": 0.17373,
        "meteor": 0.4025587567144251,
        "nubia": {
            "semantic_relation": 4.05092,
            "contradiction": 18.52228,
            "irrelevancy": 40.00732,
            "logical_agreement": 41.4704,
            "grammar_ref": 4.59976,
            "grammar_hyp": 4.5368,
            "nubia_score": 0.68852
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_247": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 60,
        "mean_pred_length": 15.0,
        "std_pred_length": 2.345207879911715,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 19,
        "distinct-1": 0.7,
        "vocab_size-1": 42,
        "unique-1": 32,
        "entropy-1": 5.198068512058837,
        "distinct-2": 0.9285714285714286,
        "vocab_size-2": 52,
        "unique-2": 49,
        "entropy-2": 5.65101764523326,
        "cond_entropy-2": 0.3607221391422524,
        "distinct-3": 1.0,
        "vocab_size-3": 52,
        "unique-3": 52,
        "entropy-3": 5.700439718141095,
        "cond_entropy-3": 0.061448017278939115,
        "total_length-nopunct": 53,
        "mean_pred_length-nopunct": 13.25,
        "std_pred_length-nopunct": 1.6393596310755,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7547169811320755,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.166138614736456,
        "distinct-2-nopunct": 0.9387755102040817,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.47685499713228,
        "cond_entropy-2-nopunct": 0.3242299509383912,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 45,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.491853096329673,
        "cond_entropy-3-nopunct": -0.007969525531260022,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7782528688194623,
        "bleu": 35.75745,
        "rouge1": {
            "precision": 0.87083,
            "recall": 0.75154,
            "fmeasure": 0.77292
        },
        "rouge2": {
            "precision": 0.624,
            "recall": 0.58501,
            "fmeasure": 0.57686
        },
        "rougeL": {
            "precision": 0.84583,
            "recall": 0.73727,
            "fmeasure": 0.75394
        },
        "rougeLsum": {
            "precision": 0.84583,
            "recall": 0.73727,
            "fmeasure": 0.75394
        },
        "local_recall": {
            "1": 0.3,
            "2": 0.375,
            "3": 0.7068965517241379
        },
        "bertscore": {
            "precision": 0.94821,
            "recall": 0.93383,
            "f1": 0.93484
        },
        "bleurt": 0.31522,
        "meteor": 0.3782169339182412,
        "nubia": {
            "semantic_relation": 4.46805,
            "contradiction": 0.9332,
            "irrelevancy": 21.7443,
            "logical_agreement": 77.32249,
            "grammar_ref": 3.32258,
            "grammar_hyp": 3.46755,
            "nubia_score": 0.79842
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_208": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.69333,
        "msttr-100_nopunct": 0.75,
        "total_length": 381,
        "mean_pred_length": 16.565217391304348,
        "std_pred_length": 4.651564364780685,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.5564304461942258,
        "vocab_size-1": 212,
        "unique-1": 163,
        "entropy-1": 7.0709843048732335,
        "distinct-2": 0.8910614525139665,
        "vocab_size-2": 319,
        "unique-2": 298,
        "entropy-2": 8.205188386309354,
        "cond_entropy-2": 0.9361792456363464,
        "distinct-3": 0.9641791044776119,
        "vocab_size-3": 323,
        "unique-3": 316,
        "entropy-3": 8.29963029885431,
        "cond_entropy-3": 0.07294576185097054,
        "total_length-nopunct": 334,
        "mean_pred_length-nopunct": 14.521739130434783,
        "std_pred_length-nopunct": 3.7284985346988426,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6167664670658682,
        "vocab_size-1-nopunct": 206,
        "unique-1-nopunct": 162,
        "entropy-1-nopunct": 7.181740495311458,
        "distinct-2-nopunct": 0.8971061093247589,
        "vocab_size-2-nopunct": 279,
        "unique-2-nopunct": 262,
        "entropy-2-nopunct": 8.016658340910626,
        "cond_entropy-2-nopunct": 0.8591957550193506,
        "distinct-3-nopunct": 0.9791666666666666,
        "vocab_size-3-nopunct": 282,
        "unique-3-nopunct": 278,
        "entropy-3-nopunct": 8.12131389033117,
        "cond_entropy-3-nopunct": 0.07189447604466387,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.229844339243098,
        "bleu": 45.94593,
        "rouge1": {
            "precision": 0.75944,
            "recall": 0.7689,
            "fmeasure": 0.75756
        },
        "rouge2": {
            "precision": 0.53406,
            "recall": 0.5439,
            "fmeasure": 0.53497
        },
        "rougeL": {
            "precision": 0.63918,
            "recall": 0.65171,
            "fmeasure": 0.6398
        },
        "rougeLsum": {
            "precision": 0.63918,
            "recall": 0.65171,
            "fmeasure": 0.6398
        },
        "local_recall": {
            "1": 0.22666666666666666,
            "2": 0.6065573770491803,
            "3": 0.7754237288135594
        },
        "bertscore": {
            "precision": 0.91769,
            "recall": 0.92129,
            "f1": 0.91851
        },
        "bleurt": 0.26084,
        "meteor": 0.4081597561807849,
        "nubia": {
            "semantic_relation": 4.36747,
            "contradiction": 7.36198,
            "irrelevancy": 25.00237,
            "logical_agreement": 67.63565,
            "grammar_ref": 4.22562,
            "grammar_hyp": 4.13567,
            "nubia_score": 0.8035
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_148": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.72,
        "total_length": 131,
        "mean_pred_length": 13.1,
        "std_pred_length": 4.4821869662029945,
        "median_pred_length": 12.5,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.6335877862595419,
        "vocab_size-1": 83,
        "unique-1": 68,
        "entropy-1": 5.848741441837168,
        "distinct-2": 0.9173553719008265,
        "vocab_size-2": 111,
        "unique-2": 105,
        "entropy-2": 6.708038650461983,
        "cond_entropy-2": 0.6826652635680249,
        "distinct-3": 0.963963963963964,
        "vocab_size-3": 107,
        "unique-3": 103,
        "entropy-3": 6.722343794278049,
        "cond_entropy-3": 0.0332983498352136,
        "total_length-nopunct": 113,
        "mean_pred_length-nopunct": 11.3,
        "std_pred_length-nopunct": 3.796050579220461,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6991150442477876,
        "vocab_size-1-nopunct": 79,
        "unique-1-nopunct": 68,
        "entropy-1-nopunct": 5.846957693637646,
        "distinct-2-nopunct": 0.912621359223301,
        "vocab_size-2-nopunct": 94,
        "unique-2-nopunct": 89,
        "entropy-2-nopunct": 6.458250284422778,
        "cond_entropy-2-nopunct": 0.6960713547441146,
        "distinct-3-nopunct": 0.967741935483871,
        "vocab_size-3-nopunct": 90,
        "unique-3-nopunct": 87,
        "entropy-3-nopunct": 6.474642682075778,
        "cond_entropy-3-nopunct": 0.04093543450897348,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.245667145015541,
        "bleu": 41.15286,
        "rouge1": {
            "precision": 0.80197,
            "recall": 0.6906,
            "fmeasure": 0.73677
        },
        "rouge2": {
            "precision": 0.49445,
            "recall": 0.43343,
            "fmeasure": 0.45843
        },
        "rougeL": {
            "precision": 0.69821,
            "recall": 0.60543,
            "fmeasure": 0.64392
        },
        "rougeLsum": {
            "precision": 0.69821,
            "recall": 0.60543,
            "fmeasure": 0.64392
        },
        "local_recall": {
            "1": 0.2962962962962963,
            "2": 0.23529411764705882,
            "3": 0.7547169811320755
        },
        "bertscore": {
            "precision": 0.93453,
            "recall": 0.91985,
            "f1": 0.9266
        },
        "bleurt": 0.32959,
        "meteor": 0.37759924239350706,
        "nubia": {
            "semantic_relation": 4.57491,
            "contradiction": 0.87394,
            "irrelevancy": 23.42452,
            "logical_agreement": 75.70154,
            "grammar_ref": 5.26168,
            "grammar_hyp": 5.63251,
            "nubia_score": 0.77324
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_209": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.0052535157554314,
        "bleu": 16.51582,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.66667,
            "fmeasure": 0.72727
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.2,
            "fmeasure": 0.22222
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.33333,
            "fmeasure": 0.36364
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.33333,
            "fmeasure": 0.36364
        },
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.87519,
            "recall": 0.87347,
            "f1": 0.87433
        },
        "bleurt": -0.06824,
        "meteor": 0.31253823342571707,
        "nubia": {
            "semantic_relation": 3.12986,
            "contradiction": 71.68311,
            "irrelevancy": 20.1839,
            "logical_agreement": 8.133,
            "grammar_ref": 6.80479,
            "grammar_hyp": 6.78582,
            "nubia_score": 0.30685
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_276": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.745,
        "msttr-100_nopunct": 0.785,
        "total_length": 279,
        "mean_pred_length": 15.5,
        "std_pred_length": 6.422616289332565,
        "median_pred_length": 14.5,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.6272401433691757,
        "vocab_size-1": 175,
        "unique-1": 149,
        "entropy-1": 6.772160452927652,
        "distinct-2": 0.9425287356321839,
        "vocab_size-2": 246,
        "unique-2": 236,
        "entropy-2": 7.888960929495179,
        "cond_entropy-2": 0.9224581219095773,
        "distinct-3": 0.9835390946502057,
        "vocab_size-3": 239,
        "unique-3": 235,
        "entropy-3": 7.891890692906173,
        "cond_entropy-3": 0.0132219906017004,
        "total_length-nopunct": 246,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 5.676462121975467,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6910569105691057,
        "vocab_size-1-nopunct": 170,
        "unique-1-nopunct": 146,
        "entropy-1-nopunct": 6.88918572648189,
        "distinct-2-nopunct": 0.9342105263157895,
        "vocab_size-2-nopunct": 213,
        "unique-2-nopunct": 203,
        "entropy-2-nopunct": 7.673834476855605,
        "cond_entropy-2-nopunct": 0.8532364254813637,
        "distinct-3-nopunct": 0.9809523809523809,
        "vocab_size-3-nopunct": 206,
        "unique-3-nopunct": 202,
        "entropy-3-nopunct": 7.676150279570872,
        "cond_entropy-3-nopunct": 0.015949134484668448,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.64314653065768,
        "bleu": 43.7266,
        "rouge1": {
            "precision": 0.73073,
            "recall": 0.74307,
            "fmeasure": 0.72344
        },
        "rouge2": {
            "precision": 0.51242,
            "recall": 0.51079,
            "fmeasure": 0.50572
        },
        "rougeL": {
            "precision": 0.64626,
            "recall": 0.65152,
            "fmeasure": 0.6382
        },
        "rougeLsum": {
            "precision": 0.64626,
            "recall": 0.65152,
            "fmeasure": 0.6382
        },
        "local_recall": {
            "1": 0.1590909090909091,
            "2": 0.35714285714285715,
            "3": 0.7894736842105263
        },
        "bertscore": {
            "precision": 0.91642,
            "recall": 0.92006,
            "f1": 0.91662
        },
        "bleurt": 0.33693,
        "meteor": 0.3942153200364656,
        "nubia": {
            "semantic_relation": 4.22454,
            "contradiction": 5.96155,
            "irrelevancy": 27.76639,
            "logical_agreement": 66.27206,
            "grammar_ref": 5.08526,
            "grammar_hyp": 4.85568,
            "nubia_score": 0.74167
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_248": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.78,
        "total_length": 116,
        "mean_pred_length": 14.5,
        "std_pred_length": 4.9749371855331,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 21,
        "distinct-1": 0.7155172413793104,
        "vocab_size-1": 83,
        "unique-1": 68,
        "entropy-1": 6.069103624400604,
        "distinct-2": 0.9907407407407407,
        "vocab_size-2": 107,
        "unique-2": 106,
        "entropy-2": 6.736368983644939,
        "cond_entropy-2": 0.503478497816701,
        "distinct-3": 1.0,
        "vocab_size-3": 100,
        "unique-3": 100,
        "entropy-3": 6.6438561897747395,
        "cond_entropy-3": -0.091031312388744,
        "total_length-nopunct": 101,
        "mean_pred_length-nopunct": 12.625,
        "std_pred_length-nopunct": 4.553501400021746,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7821782178217822,
        "vocab_size-1-nopunct": 79,
        "unique-1-nopunct": 68,
        "entropy-1-nopunct": 6.076479923324421,
        "distinct-2-nopunct": 0.989247311827957,
        "vocab_size-2-nopunct": 92,
        "unique-2-nopunct": 91,
        "entropy-2-nopunct": 6.517653434763951,
        "cond_entropy-2-nopunct": 0.4697095595622956,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 85,
        "unique-3-nopunct": 85,
        "entropy-3-nopunct": 6.409390936137707,
        "cond_entropy-3-nopunct": -0.10623846320562354,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.517745140789926,
        "bleu": 44.17076,
        "rouge1": {
            "precision": 0.81756,
            "recall": 0.70676,
            "fmeasure": 0.75041
        },
        "rouge2": {
            "precision": 0.54726,
            "recall": 0.46269,
            "fmeasure": 0.4942
        },
        "rougeL": {
            "precision": 0.68637,
            "recall": 0.6084,
            "fmeasure": 0.63668
        },
        "rougeLsum": {
            "precision": 0.68637,
            "recall": 0.6084,
            "fmeasure": 0.63668
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.375,
            "3": 0.8421052631578947
        },
        "bertscore": {
            "precision": 0.92897,
            "recall": 0.91501,
            "f1": 0.91959
        },
        "bleurt": 0.298,
        "meteor": 0.398533765800325,
        "nubia": {
            "semantic_relation": 4.21873,
            "contradiction": 13.55049,
            "irrelevancy": 28.53388,
            "logical_agreement": 57.91563,
            "grammar_ref": 4.75129,
            "grammar_hyp": 5.1521,
            "nubia_score": 0.69636
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_228": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.79,
        "total_length": 187,
        "mean_pred_length": 17.0,
        "std_pred_length": 6.149648918286459,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.7112299465240641,
        "vocab_size-1": 133,
        "unique-1": 116,
        "entropy-1": 6.646956999580646,
        "distinct-2": 0.9772727272727273,
        "vocab_size-2": 172,
        "unique-2": 169,
        "entropy-2": 7.409687939647743,
        "cond_entropy-2": 0.6027625551714256,
        "distinct-3": 1.0,
        "vocab_size-3": 165,
        "unique-3": 165,
        "entropy-3": 7.366322214245809,
        "cond_entropy-3": -0.040049480135945295,
        "total_length-nopunct": 163,
        "mean_pred_length-nopunct": 14.818181818181818,
        "std_pred_length-nopunct": 5.685998462222505,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.7914110429447853,
        "vocab_size-1-nopunct": 129,
        "unique-1-nopunct": 116,
        "entropy-1-nopunct": 6.728646572552176,
        "distinct-2-nopunct": 0.9736842105263158,
        "vocab_size-2-nopunct": 148,
        "unique-2-nopunct": 145,
        "entropy-2-nopunct": 7.190329569350387,
        "cond_entropy-2-nopunct": 0.5065573217881695,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 141,
        "unique-3-nopunct": 141,
        "entropy-3-nopunct": 7.139551352398772,
        "cond_entropy-3-nopunct": -0.04628476032022827,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.640860922361878,
        "bleu": 47.15809,
        "rouge1": {
            "precision": 0.78176,
            "recall": 0.78439,
            "fmeasure": 0.77025
        },
        "rouge2": {
            "precision": 0.55157,
            "recall": 0.57438,
            "fmeasure": 0.55357
        },
        "rougeL": {
            "precision": 0.69218,
            "recall": 0.69056,
            "fmeasure": 0.67893
        },
        "rougeLsum": {
            "precision": 0.69218,
            "recall": 0.69056,
            "fmeasure": 0.67893
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.42105263157894735,
            "3": 0.7928571428571428
        },
        "bertscore": {
            "precision": 0.91351,
            "recall": 0.92606,
            "f1": 0.91825
        },
        "bleurt": 0.19336,
        "meteor": 0.43013263331127544,
        "nubia": {
            "semantic_relation": 4.13043,
            "contradiction": 9.19262,
            "irrelevancy": 45.59042,
            "logical_agreement": 45.21696,
            "grammar_ref": 4.46209,
            "grammar_hyp": 4.65497,
            "nubia_score": 0.69746
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_180": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 42,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.81,
        "total_length": 656,
        "mean_pred_length": 15.619047619047619,
        "std_pred_length": 4.990239907165362,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.5853658536585366,
        "vocab_size-1": 384,
        "unique-1": 323,
        "entropy-1": 7.712927276062911,
        "distinct-2": 0.9364820846905537,
        "vocab_size-2": 575,
        "unique-2": 549,
        "entropy-2": 9.11389660683651,
        "cond_entropy-2": 1.1446125015269926,
        "distinct-3": 0.986013986013986,
        "vocab_size-3": 564,
        "unique-3": 557,
        "entropy-3": 9.130579575411025,
        "cond_entropy-3": 0.007268083161865198,
        "total_length-nopunct": 571,
        "mean_pred_length-nopunct": 13.595238095238095,
        "std_pred_length-nopunct": 4.342807539399258,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6637478108581436,
        "vocab_size-1-nopunct": 379,
        "unique-1-nopunct": 323,
        "entropy-1-nopunct": 7.95017370390885,
        "distinct-2-nopunct": 0.9376181474480151,
        "vocab_size-2-nopunct": 496,
        "unique-2-nopunct": 473,
        "entropy-2-nopunct": 8.904620929155152,
        "cond_entropy-2-nopunct": 1.0310660356803203,
        "distinct-3-nopunct": 0.9835728952772074,
        "vocab_size-3-nopunct": 479,
        "unique-3-nopunct": 472,
        "entropy-3-nopunct": 8.89337367563026,
        "cond_entropy-3-nopunct": 0.0010425314531021211,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.041825271768709,
        "bleu": 50.47886,
        "rouge1": {
            "precision": 0.81722,
            "recall": 0.76124,
            "fmeasure": 0.77904
        },
        "rouge2": {
            "precision": 0.61625,
            "recall": 0.58147,
            "fmeasure": 0.59159
        },
        "rougeL": {
            "precision": 0.72428,
            "recall": 0.67332,
            "fmeasure": 0.69005
        },
        "rougeLsum": {
            "precision": 0.72428,
            "recall": 0.67332,
            "fmeasure": 0.69005
        },
        "local_recall": {
            "1": 0.1565217391304348,
            "2": 0.5161290322580645,
            "3": 0.7727272727272727
        },
        "bertscore": {
            "precision": 0.94159,
            "recall": 0.93661,
            "f1": 0.93794
        },
        "bleurt": 0.37375,
        "meteor": 0.4231819865468294,
        "nubia": {
            "semantic_relation": 4.37016,
            "contradiction": 9.16341,
            "irrelevancy": 20.7184,
            "logical_agreement": 70.1182,
            "grammar_ref": 4.60727,
            "grammar_hyp": 4.74199,
            "nubia_score": 0.76612
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_230": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.8,
        "total_length": 193,
        "mean_pred_length": 19.3,
        "std_pred_length": 6.067124524847006,
        "median_pred_length": 19.5,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.7046632124352331,
        "vocab_size-1": 136,
        "unique-1": 116,
        "entropy-1": 6.7105243978454485,
        "distinct-2": 0.9781420765027322,
        "vocab_size-2": 179,
        "unique-2": 176,
        "entropy-2": 7.4678589229716685,
        "cond_entropy-2": 0.6240014401281345,
        "distinct-3": 1.0,
        "vocab_size-3": 173,
        "unique-3": 173,
        "entropy-3": 7.4346282276367255,
        "cond_entropy-3": -0.030465324507644453,
        "total_length-nopunct": 171,
        "mean_pred_length-nopunct": 17.1,
        "std_pred_length-nopunct": 5.61159513863928,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7602339181286549,
        "vocab_size-1-nopunct": 130,
        "unique-1-nopunct": 114,
        "entropy-1-nopunct": 6.730811909883763,
        "distinct-2-nopunct": 0.9751552795031055,
        "vocab_size-2-nopunct": 157,
        "unique-2-nopunct": 154,
        "entropy-2-nopunct": 7.276538694871351,
        "cond_entropy-2-nopunct": 0.5821889343666119,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 151,
        "unique-3-nopunct": 151,
        "entropy-3-nopunct": 7.238404739325059,
        "cond_entropy-3-nopunct": -0.0345327513579921,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.130352390421062,
        "bleu": 45.70421,
        "rouge1": {
            "precision": 0.6925,
            "recall": 0.72178,
            "fmeasure": 0.69012
        },
        "rouge2": {
            "precision": 0.46762,
            "recall": 0.4656,
            "fmeasure": 0.4592
        },
        "rougeL": {
            "precision": 0.56591,
            "recall": 0.58647,
            "fmeasure": 0.56563
        },
        "rougeLsum": {
            "precision": 0.56591,
            "recall": 0.58647,
            "fmeasure": 0.56563
        },
        "local_recall": {
            "1": 0.21212121212121213,
            "2": 0.631578947368421,
            "3": 0.8118811881188119
        },
        "bertscore": {
            "precision": 0.91146,
            "recall": 0.91707,
            "f1": 0.91271
        },
        "bleurt": 0.30008,
        "meteor": 0.4056920969909206,
        "nubia": {
            "semantic_relation": 4.30899,
            "contradiction": 5.91006,
            "irrelevancy": 36.05621,
            "logical_agreement": 58.03373,
            "grammar_ref": 5.06465,
            "grammar_hyp": 4.54853,
            "nubia_score": 0.7479
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_304": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.71,
        "msttr-100_nopunct": NaN,
        "total_length": 108,
        "mean_pred_length": 18.0,
        "std_pred_length": 3.265986323710904,
        "median_pred_length": 17.0,
        "min_pred_length": 15,
        "max_pred_length": 25,
        "distinct-1": 0.6574074074074074,
        "vocab_size-1": 71,
        "unique-1": 55,
        "entropy-1": 5.812531599285523,
        "distinct-2": 0.8921568627450981,
        "vocab_size-2": 91,
        "unique-2": 80,
        "entropy-2": 6.4567390674616965,
        "cond_entropy-2": 0.5475835506559726,
        "distinct-3": 0.90625,
        "vocab_size-3": 87,
        "unique-3": 78,
        "entropy-3": 6.39746250072116,
        "cond_entropy-3": -0.06662950791700596,
        "total_length-nopunct": 99,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 2.565800719723442,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6767676767676768,
        "vocab_size-1-nopunct": 67,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 5.7579963927413305,
        "distinct-2-nopunct": 0.8924731182795699,
        "vocab_size-2-nopunct": 83,
        "unique-2-nopunct": 73,
        "entropy-2-nopunct": 6.324105047667179,
        "cond_entropy-2-nopunct": 0.600820067442297,
        "distinct-3-nopunct": 0.9080459770114943,
        "vocab_size-3-nopunct": 79,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 6.2590354498717105,
        "cond_entropy-3-nopunct": -0.07322680951217667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.538117622040158,
        "bleu": 54.50772,
        "rouge1": {
            "precision": 0.75587,
            "recall": 0.80984,
            "fmeasure": 0.7791
        },
        "rouge2": {
            "precision": 0.57683,
            "recall": 0.62779,
            "fmeasure": 0.59793
        },
        "rougeL": {
            "precision": 0.62048,
            "recall": 0.67602,
            "fmeasure": 0.64453
        },
        "rougeLsum": {
            "precision": 0.62048,
            "recall": 0.67602,
            "fmeasure": 0.64453
        },
        "local_recall": {
            "1": 0.3157894736842105,
            "2": 0.75,
            "3": 0.8611111111111112
        },
        "bertscore": {
            "precision": 0.91726,
            "recall": 0.93107,
            "f1": 0.92275
        },
        "bleurt": 0.30838,
        "meteor": 0.44233695268404166,
        "nubia": {
            "semantic_relation": 4.14689,
            "contradiction": 30.34504,
            "irrelevancy": 25.84684,
            "logical_agreement": 43.80812,
            "grammar_ref": 4.63046,
            "grammar_hyp": 4.29267,
            "nubia_score": 0.73412
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_305": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.113283334294875,
        "bleu": 37.70064,
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.875,
            "fmeasure": 0.73684
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.57143,
            "fmeasure": 0.47059
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.875,
            "fmeasure": 0.73684
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.875,
            "fmeasure": 0.73684
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.92189,
            "recall": 0.96274,
            "f1": 0.94187
        },
        "bleurt": 0.68967,
        "meteor": 0.4776740326875079,
        "nubia": {
            "semantic_relation": 4.43705,
            "contradiction": 0.07529,
            "irrelevancy": 99.69939,
            "logical_agreement": 0.22532,
            "grammar_ref": 5.02153,
            "grammar_hyp": 4.41048,
            "nubia_score": 0.91331
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_279": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 5.0,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 20,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 25,
        "unique-1": 22,
        "entropy-1": 4.523231428797621,
        "distinct-2": 0.9642857142857143,
        "vocab_size-2": 27,
        "unique-2": 26,
        "entropy-2": 4.735926350629034,
        "cond_entropy-2": 0.168670576603619,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.02999212699343525,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.467720100474501,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.623516641218013,
        "cond_entropy-2-nopunct": 0.18192229624990847,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.03214388408660255,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.383618161542536,
        "bleu": 28.13209,
        "rouge1": {
            "precision": 0.92105,
            "recall": 0.62958,
            "fmeasure": 0.70705
        },
        "rouge2": {
            "precision": 0.74306,
            "recall": 0.47432,
            "fmeasure": 0.5422
        },
        "rougeL": {
            "precision": 0.67544,
            "recall": 0.4834,
            "fmeasure": 0.53388
        },
        "rougeLsum": {
            "precision": 0.67544,
            "recall": 0.4834,
            "fmeasure": 0.53388
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.16666666666666666,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.96854,
            "recall": 0.93573,
            "f1": 0.94994
        },
        "bleurt": 0.2743,
        "meteor": 0.3450939493585644,
        "nubia": {
            "semantic_relation": 4.18916,
            "contradiction": 0.18465,
            "irrelevancy": 19.14486,
            "logical_agreement": 80.6705,
            "grammar_ref": 3.10743,
            "grammar_hyp": 3.70744,
            "nubia_score": 0.71987
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_231": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 16,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.77,
        "total_length": 219,
        "mean_pred_length": 13.6875,
        "std_pred_length": 3.512811374099099,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.6210045662100456,
        "vocab_size-1": 136,
        "unique-1": 109,
        "entropy-1": 6.540938501019482,
        "distinct-2": 0.9458128078817734,
        "vocab_size-2": 192,
        "unique-2": 183,
        "entropy-2": 7.54710931619996,
        "cond_entropy-2": 0.7881490266943019,
        "distinct-3": 0.9679144385026738,
        "vocab_size-3": 181,
        "unique-3": 175,
        "entropy-3": 7.482723336892962,
        "cond_entropy-3": -0.054270334302887156,
        "total_length-nopunct": 192,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.082207001484488,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6875,
        "vocab_size-1-nopunct": 132,
        "unique-1-nopunct": 109,
        "entropy-1-nopunct": 6.634122136788943,
        "distinct-2-nopunct": 0.9431818181818182,
        "vocab_size-2-nopunct": 166,
        "unique-2-nopunct": 158,
        "entropy-2-nopunct": 7.334431618637307,
        "cond_entropy-2-nopunct": 0.7640222422058427,
        "distinct-3-nopunct": 0.96875,
        "vocab_size-3-nopunct": 155,
        "unique-3-nopunct": 150,
        "entropy-3-nopunct": 7.259428094887367,
        "cond_entropy-3-nopunct": -0.0687535237499352,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.277971784418562,
        "bleu": 50.26324,
        "rouge1": {
            "precision": 0.82085,
            "recall": 0.778,
            "fmeasure": 0.79508
        },
        "rouge2": {
            "precision": 0.60375,
            "recall": 0.57599,
            "fmeasure": 0.58644
        },
        "rougeL": {
            "precision": 0.71624,
            "recall": 0.68613,
            "fmeasure": 0.69775
        },
        "rougeLsum": {
            "precision": 0.71624,
            "recall": 0.68613,
            "fmeasure": 0.69775
        },
        "local_recall": {
            "1": 0.21951219512195122,
            "2": 0.43478260869565216,
            "3": 0.7926829268292683
        },
        "bertscore": {
            "precision": 0.93347,
            "recall": 0.93232,
            "f1": 0.93246
        },
        "bleurt": 0.36907,
        "meteor": 0.41723374068269736,
        "nubia": {
            "semantic_relation": 4.5179,
            "contradiction": 0.44171,
            "irrelevancy": 23.63937,
            "logical_agreement": 75.91891,
            "grammar_ref": 4.58203,
            "grammar_hyp": 4.58704,
            "nubia_score": 0.82323
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_250": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 16,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.79,
        "total_length": 288,
        "mean_pred_length": 18.0,
        "std_pred_length": 8.54400374531753,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 43,
        "distinct-1": 0.5833333333333334,
        "vocab_size-1": 168,
        "unique-1": 137,
        "entropy-1": 6.749917244823416,
        "distinct-2": 0.8897058823529411,
        "vocab_size-2": 242,
        "unique-2": 229,
        "entropy-2": 7.789691817501486,
        "cond_entropy-2": 0.8880103230673873,
        "distinct-3": 0.94921875,
        "vocab_size-3": 243,
        "unique-3": 238,
        "entropy-3": 7.862424683793463,
        "cond_entropy-3": 0.09134355527629111,
        "total_length-nopunct": 239,
        "mean_pred_length-nopunct": 14.9375,
        "std_pred_length-nopunct": 5.695049933933855,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6861924686192469,
        "vocab_size-1-nopunct": 164,
        "unique-1-nopunct": 137,
        "entropy-1-nopunct": 6.941451640842086,
        "distinct-2-nopunct": 0.905829596412556,
        "vocab_size-2-nopunct": 202,
        "unique-2-nopunct": 193,
        "entropy-2-nopunct": 7.546509514479952,
        "cond_entropy-2-nopunct": 0.669410531369811,
        "distinct-3-nopunct": 0.9468599033816425,
        "vocab_size-3-nopunct": 196,
        "unique-3-nopunct": 193,
        "entropy-3-nopunct": 7.542669175137591,
        "cond_entropy-3-nopunct": 0.01582268561924742,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.398342318115612,
        "bleu": 53.46421,
        "rouge1": {
            "precision": 0.75639,
            "recall": 0.7704,
            "fmeasure": 0.75462
        },
        "rouge2": {
            "precision": 0.55822,
            "recall": 0.56829,
            "fmeasure": 0.5568
        },
        "rougeL": {
            "precision": 0.69412,
            "recall": 0.70366,
            "fmeasure": 0.69258
        },
        "rougeLsum": {
            "precision": 0.69412,
            "recall": 0.70366,
            "fmeasure": 0.69258
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.2682926829268293,
            "3": 0.827027027027027
        },
        "bertscore": {
            "precision": 0.94044,
            "recall": 0.94552,
            "f1": 0.94153
        },
        "bleurt": 0.45665,
        "meteor": 0.43467778232840387,
        "nubia": {
            "semantic_relation": 4.45135,
            "contradiction": 1.15069,
            "irrelevancy": 37.39177,
            "logical_agreement": 61.45754,
            "grammar_ref": 4.44923,
            "grammar_hyp": 4.21468,
            "nubia_score": 0.85197
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_150": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 37,
        "msttr-100": 0.71333,
        "msttr-100_nopunct": 0.756,
        "total_length": 663,
        "mean_pred_length": 17.91891891891892,
        "std_pred_length": 7.401162722307523,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 41,
        "distinct-1": 0.5686274509803921,
        "vocab_size-1": 377,
        "unique-1": 313,
        "entropy-1": 7.628687825241928,
        "distinct-2": 0.9121405750798722,
        "vocab_size-2": 571,
        "unique-2": 539,
        "entropy-2": 9.06608784139354,
        "cond_entropy-2": 1.2303093447345759,
        "distinct-3": 0.9762308998302207,
        "vocab_size-3": 575,
        "unique-3": 565,
        "entropy-3": 9.147794452013878,
        "cond_entropy-3": 0.08898241232633762,
        "total_length-nopunct": 581,
        "mean_pred_length-nopunct": 15.702702702702704,
        "std_pred_length-nopunct": 6.61229348470185,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.6385542168674698,
        "vocab_size-1-nopunct": 371,
        "unique-1-nopunct": 311,
        "entropy-1-nopunct": 7.84204668846209,
        "distinct-2-nopunct": 0.9080882352941176,
        "vocab_size-2-nopunct": 494,
        "unique-2-nopunct": 467,
        "entropy-2-nopunct": 8.848159882670593,
        "cond_entropy-2-nopunct": 1.0756682973347602,
        "distinct-3-nopunct": 0.9763313609467456,
        "vocab_size-3-nopunct": 495,
        "unique-3-nopunct": 487,
        "entropy-3-nopunct": 8.930615112545862,
        "cond_entropy-3-nopunct": 0.09597438069853179,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.624359484096657,
        "bleu": 42.51742,
        "rouge1": {
            "precision": 0.7432,
            "recall": 0.75669,
            "fmeasure": 0.73354
        },
        "rouge2": {
            "precision": 0.51688,
            "recall": 0.53331,
            "fmeasure": 0.51267
        },
        "rougeL": {
            "precision": 0.64767,
            "recall": 0.66671,
            "fmeasure": 0.64334
        },
        "rougeLsum": {
            "precision": 0.64767,
            "recall": 0.66671,
            "fmeasure": 0.64334
        },
        "local_recall": {
            "1": 0.3088235294117647,
            "2": 0.37755102040816324,
            "3": 0.7729468599033816
        },
        "bertscore": {
            "precision": 0.92781,
            "recall": 0.92965,
            "f1": 0.92703
        },
        "bleurt": 0.23334,
        "meteor": 0.40413345929647837,
        "nubia": {
            "semantic_relation": 4.14258,
            "contradiction": 9.19138,
            "irrelevancy": 32.47303,
            "logical_agreement": 58.3356,
            "grammar_ref": 4.9523,
            "grammar_hyp": 4.79826,
            "nubia_score": 0.71837
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_340": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.76,
        "total_length": 153,
        "mean_pred_length": 19.125,
        "std_pred_length": 6.392133837772798,
        "median_pred_length": 19.5,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.6535947712418301,
        "vocab_size-1": 100,
        "unique-1": 75,
        "entropy-1": 6.336029104714024,
        "distinct-2": 0.9103448275862069,
        "vocab_size-2": 132,
        "unique-2": 121,
        "entropy-2": 6.9868056417390925,
        "cond_entropy-2": 0.5360928811893724,
        "distinct-3": 0.9708029197080292,
        "vocab_size-3": 133,
        "unique-3": 129,
        "entropy-3": 7.039637922376571,
        "cond_entropy-3": 0.0641083944054463,
        "total_length-nopunct": 133,
        "mean_pred_length-nopunct": 16.625,
        "std_pred_length-nopunct": 5.633327169621874,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7142857142857143,
        "vocab_size-1-nopunct": 95,
        "unique-1-nopunct": 74,
        "entropy-1-nopunct": 6.334617236764622,
        "distinct-2-nopunct": 0.912,
        "vocab_size-2-nopunct": 114,
        "unique-2-nopunct": 105,
        "entropy-2-nopunct": 6.773784284662096,
        "cond_entropy-2-nopunct": 0.46460992061084205,
        "distinct-3-nopunct": 0.9743589743589743,
        "vocab_size-3-nopunct": 114,
        "unique-3-nopunct": 111,
        "entropy-3-nopunct": 6.819082668301332,
        "cond_entropy-3-nopunct": 0.0584265887674713,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.399715892288166,
        "bleu": 46.86394,
        "rouge1": {
            "precision": 0.82719,
            "recall": 0.85631,
            "fmeasure": 0.83245
        },
        "rouge2": {
            "precision": 0.607,
            "recall": 0.64364,
            "fmeasure": 0.61513
        },
        "rougeL": {
            "precision": 0.62009,
            "recall": 0.69654,
            "fmeasure": 0.64784
        },
        "rougeLsum": {
            "precision": 0.62009,
            "recall": 0.69654,
            "fmeasure": 0.64784
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.5,
            "3": 0.8514851485148515
        },
        "bertscore": {
            "precision": 0.93453,
            "recall": 0.9447,
            "f1": 0.93843
        },
        "bleurt": 0.41138,
        "meteor": 0.43641095112945766,
        "nubia": {
            "semantic_relation": 4.55471,
            "contradiction": 3.17347,
            "irrelevancy": 32.46151,
            "logical_agreement": 64.36502,
            "grammar_ref": 4.58534,
            "grammar_hyp": 4.59153,
            "nubia_score": 0.84662
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_252": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 19,
        "msttr-100": 0.69333,
        "msttr-100_nopunct": 0.75,
        "total_length": 355,
        "mean_pred_length": 18.68421052631579,
        "std_pred_length": 8.663611934127264,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 45,
        "distinct-1": 0.5859154929577465,
        "vocab_size-1": 208,
        "unique-1": 168,
        "entropy-1": 6.968191436063897,
        "distinct-2": 0.9315476190476191,
        "vocab_size-2": 313,
        "unique-2": 297,
        "entropy-2": 8.231680016674542,
        "cond_entropy-2": 1.1082968217797018,
        "distinct-3": 0.9936908517350158,
        "vocab_size-3": 315,
        "unique-3": 313,
        "entropy-3": 8.295720733609489,
        "cond_entropy-3": 0.06735967818410817,
        "total_length-nopunct": 304,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 6.6332495807108,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.6677631578947368,
        "vocab_size-1-nopunct": 203,
        "unique-1-nopunct": 167,
        "entropy-1-nopunct": 7.137505895930917,
        "distinct-2-nopunct": 0.9438596491228071,
        "vocab_size-2-nopunct": 269,
        "unique-2-nopunct": 259,
        "entropy-2-nopunct": 8.017206596950809,
        "cond_entropy-2-nopunct": 0.9396937211347557,
        "distinct-3-nopunct": 0.9924812030075187,
        "vocab_size-3-nopunct": 264,
        "unique-3-nopunct": 262,
        "entropy-3-nopunct": 8.04024484151628,
        "cond_entropy-3-nopunct": 0.029108239790715633,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.098277902324614,
        "bleu": 37.17952,
        "rouge1": {
            "precision": 0.6762,
            "recall": 0.65801,
            "fmeasure": 0.65545
        },
        "rouge2": {
            "precision": 0.44011,
            "recall": 0.43781,
            "fmeasure": 0.43199
        },
        "rougeL": {
            "precision": 0.59585,
            "recall": 0.59346,
            "fmeasure": 0.58363
        },
        "rougeLsum": {
            "precision": 0.59585,
            "recall": 0.59346,
            "fmeasure": 0.58363
        },
        "local_recall": {
            "1": 0.16176470588235295,
            "2": 0.42857142857142855,
            "3": 0.7514450867052023
        },
        "bertscore": {
            "precision": 0.89173,
            "recall": 0.90528,
            "f1": 0.89556
        },
        "bleurt": 0.06788,
        "meteor": 0.3322299286926191,
        "nubia": {
            "semantic_relation": 3.88779,
            "contradiction": 13.7133,
            "irrelevancy": 44.58844,
            "logical_agreement": 41.69826,
            "grammar_ref": 4.62734,
            "grammar_hyp": 4.70188,
            "nubia_score": 0.61625
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_232": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.78,
        "total_length": 174,
        "mean_pred_length": 19.333333333333332,
        "std_pred_length": 7.302967433402215,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 33,
        "distinct-1": 0.632183908045977,
        "vocab_size-1": 110,
        "unique-1": 91,
        "entropy-1": 6.22602997310525,
        "distinct-2": 0.9212121212121213,
        "vocab_size-2": 152,
        "unique-2": 140,
        "entropy-2": 7.204171380899365,
        "cond_entropy-2": 0.8716135089559938,
        "distinct-3": 0.9743589743589743,
        "vocab_size-3": 152,
        "unique-3": 148,
        "entropy-3": 7.2341201675802145,
        "cond_entropy-3": 0.03930364245081374,
        "total_length-nopunct": 157,
        "mean_pred_length-nopunct": 17.444444444444443,
        "std_pred_length-nopunct": 7.009693464705558,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6815286624203821,
        "vocab_size-1-nopunct": 107,
        "unique-1-nopunct": 90,
        "entropy-1-nopunct": 6.252823656598763,
        "distinct-2-nopunct": 0.918918918918919,
        "vocab_size-2-nopunct": 136,
        "unique-2-nopunct": 125,
        "entropy-2-nopunct": 7.042190612235952,
        "cond_entropy-2-nopunct": 0.8459627247631061,
        "distinct-3-nopunct": 0.9712230215827338,
        "vocab_size-3-nopunct": 135,
        "unique-3-nopunct": 131,
        "entropy-3-nopunct": 7.061387115888991,
        "cond_entropy-3-nopunct": 0.030026466102927866,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.486640297027571,
        "bleu": 33.07406,
        "rouge1": {
            "precision": 0.76261,
            "recall": 0.77322,
            "fmeasure": 0.76223
        },
        "rouge2": {
            "precision": 0.49236,
            "recall": 0.50318,
            "fmeasure": 0.4932
        },
        "rougeL": {
            "precision": 0.61279,
            "recall": 0.62799,
            "fmeasure": 0.61571
        },
        "rougeLsum": {
            "precision": 0.61279,
            "recall": 0.62799,
            "fmeasure": 0.61571
        },
        "local_recall": {
            "1": 0.36363636363636365,
            "2": 0.3125,
            "3": 0.7652173913043478
        },
        "bertscore": {
            "precision": 0.92806,
            "recall": 0.92704,
            "f1": 0.92736
        },
        "bleurt": 0.29344,
        "meteor": 0.37237301135954215,
        "nubia": {
            "semantic_relation": 4.36827,
            "contradiction": 0.68371,
            "irrelevancy": 25.83713,
            "logical_agreement": 73.47916,
            "grammar_ref": 4.7133,
            "grammar_hyp": 4.35094,
            "nubia_score": 0.82065
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_253": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 22.0,
        "std_pred_length": 8.0,
        "median_pred_length": 22.0,
        "min_pred_length": 14,
        "max_pred_length": 30,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 36,
        "unique-1": 32,
        "entropy-1": 4.970573095811684,
        "distinct-2": 1.0,
        "vocab_size-2": 42,
        "unique-2": 42,
        "entropy-2": 5.3923174227787625,
        "cond_entropy-2": 0.3974042566254381,
        "distinct-3": 1.0,
        "vocab_size-3": 40,
        "unique-3": 40,
        "entropy-3": 5.3219280948873635,
        "cond_entropy-3": -0.07038932789139805,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.9428571428571428,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.01499730265925,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.03632322362560795,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.09019780897157811,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.693153263245519,
        "bleu": 45.77446,
        "rouge1": {
            "precision": 0.83036,
            "recall": 0.7132,
            "fmeasure": 0.74483
        },
        "rouge2": {
            "precision": 0.5903,
            "recall": 0.5268,
            "fmeasure": 0.53981
        },
        "rougeL": {
            "precision": 0.70536,
            "recall": 0.63967,
            "fmeasure": 0.65234
        },
        "rougeLsum": {
            "precision": 0.70536,
            "recall": 0.63967,
            "fmeasure": 0.65234
        },
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.6578947368421053
        },
        "bertscore": {
            "precision": 0.95634,
            "recall": 0.92987,
            "f1": 0.94199
        },
        "bleurt": 0.01256,
        "meteor": 0.3524323508426865,
        "nubia": {
            "semantic_relation": 3.66731,
            "contradiction": 19.26605,
            "irrelevancy": 67.83781,
            "logical_agreement": 12.89614,
            "grammar_ref": 4.45404,
            "grammar_hyp": 4.45237,
            "nubia_score": 0.46808
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_306": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.81,
        "total_length": 165,
        "mean_pred_length": 13.75,
        "std_pred_length": 3.2691742076555053,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.6848484848484848,
        "vocab_size-1": 113,
        "unique-1": 101,
        "entropy-1": 6.322116496634666,
        "distinct-2": 0.9803921568627451,
        "vocab_size-2": 150,
        "unique-2": 147,
        "entropy-2": 7.218172156418122,
        "cond_entropy-2": 0.6967806179709215,
        "distinct-3": 1.0,
        "vocab_size-3": 141,
        "unique-3": 141,
        "entropy-3": 7.139551352398772,
        "cond_entropy-3": -0.07528329880449619,
        "total_length-nopunct": 144,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.943920288775949,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7638888888888888,
        "vocab_size-1-nopunct": 110,
        "unique-1-nopunct": 101,
        "entropy-1-nopunct": 6.422543689339676,
        "distinct-2-nopunct": 0.9772727272727273,
        "vocab_size-2-nopunct": 129,
        "unique-2-nopunct": 126,
        "entropy-2-nopunct": 6.998939573903899,
        "cond_entropy-2-nopunct": 0.6443396402099412,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 120,
        "unique-3-nopunct": 120,
        "entropy-3-nopunct": 6.906890595608536,
        "cond_entropy-3-nopunct": -0.08750352374993492,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.007718175487461,
        "bleu": 34.27604,
        "rouge1": {
            "precision": 0.71424,
            "recall": 0.68085,
            "fmeasure": 0.67973
        },
        "rouge2": {
            "precision": 0.4819,
            "recall": 0.47424,
            "fmeasure": 0.4656
        },
        "rougeL": {
            "precision": 0.62341,
            "recall": 0.63137,
            "fmeasure": 0.61211
        },
        "rougeLsum": {
            "precision": 0.62341,
            "recall": 0.63137,
            "fmeasure": 0.61211
        },
        "local_recall": {
            "1": 0.17105263157894737,
            "2": 0.45161290322580644,
            "3": 0.6346153846153846
        },
        "bertscore": {
            "precision": 0.91533,
            "recall": 0.91963,
            "f1": 0.91077
        },
        "bleurt": 0.18843,
        "meteor": 0.3700093163239951,
        "nubia": {
            "semantic_relation": 4.0334,
            "contradiction": 9.81401,
            "irrelevancy": 37.46111,
            "logical_agreement": 52.72488,
            "grammar_ref": 4.84087,
            "grammar_hyp": 4.70991,
            "nubia_score": 0.69572
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_234": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.69,
        "total_length": 188,
        "mean_pred_length": 13.428571428571429,
        "std_pred_length": 4.670795064077661,
        "median_pred_length": 13.5,
        "min_pred_length": 5,
        "max_pred_length": 23,
        "distinct-1": 0.5904255319148937,
        "vocab_size-1": 111,
        "unique-1": 86,
        "entropy-1": 6.210200105995394,
        "distinct-2": 0.9137931034482759,
        "vocab_size-2": 159,
        "unique-2": 146,
        "entropy-2": 7.259035449871697,
        "cond_entropy-2": 0.8506656515242936,
        "distinct-3": 0.975,
        "vocab_size-3": 156,
        "unique-3": 152,
        "entropy-3": 7.271928094887367,
        "cond_entropy-3": 0.003984599038633839,
        "total_length-nopunct": 172,
        "mean_pred_length-nopunct": 12.285714285714286,
        "std_pred_length-nopunct": 4.542318027309899,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6337209302325582,
        "vocab_size-1-nopunct": 109,
        "unique-1-nopunct": 86,
        "entropy-1-nopunct": 6.278345479821513,
        "distinct-2-nopunct": 0.9177215189873418,
        "vocab_size-2-nopunct": 145,
        "unique-2-nopunct": 134,
        "entropy-2-nopunct": 7.1265655583036995,
        "cond_entropy-2-nopunct": 0.896818511555248,
        "distinct-3-nopunct": 0.9791666666666666,
        "vocab_size-3-nopunct": 141,
        "unique-3-nopunct": 138,
        "entropy-3-nopunct": 7.128258334775665,
        "cond_entropy-3-nopunct": -0.00191130229034602,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.98736228836889,
        "bleu": 36.3242,
        "rouge1": {
            "precision": 0.73291,
            "recall": 0.70222,
            "fmeasure": 0.70071
        },
        "rouge2": {
            "precision": 0.4893,
            "recall": 0.48601,
            "fmeasure": 0.47455
        },
        "rougeL": {
            "precision": 0.6521,
            "recall": 0.64396,
            "fmeasure": 0.62794
        },
        "rougeLsum": {
            "precision": 0.6521,
            "recall": 0.64396,
            "fmeasure": 0.62794
        },
        "local_recall": {
            "1": 0.24324324324324326,
            "2": 0.4,
            "3": 0.703125
        },
        "bertscore": {
            "precision": 0.9285,
            "recall": 0.91773,
            "f1": 0.92161
        },
        "bleurt": 0.31179,
        "meteor": 0.3961414223771516,
        "nubia": {
            "semantic_relation": 4.25744,
            "contradiction": 5.82774,
            "irrelevancy": 18.80526,
            "logical_agreement": 75.367,
            "grammar_ref": 4.23107,
            "grammar_hyp": 4.19394,
            "nubia_score": 0.78339
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_308": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.7,
        "total_length": 152,
        "mean_pred_length": 19.0,
        "std_pred_length": 5.766281297335398,
        "median_pred_length": 16.5,
        "min_pred_length": 13,
        "max_pred_length": 31,
        "distinct-1": 0.631578947368421,
        "vocab_size-1": 96,
        "unique-1": 76,
        "entropy-1": 6.169719806540469,
        "distinct-2": 0.9305555555555556,
        "vocab_size-2": 134,
        "unique-2": 125,
        "entropy-2": 7.025793838232862,
        "cond_entropy-2": 0.7493077931869809,
        "distinct-3": 0.9779411764705882,
        "vocab_size-3": 133,
        "unique-3": 130,
        "entropy-3": 7.043345194191505,
        "cond_entropy-3": 0.026029659676876052,
        "total_length-nopunct": 134,
        "mean_pred_length-nopunct": 16.75,
        "std_pred_length-nopunct": 4.351723796382303,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6865671641791045,
        "vocab_size-1-nopunct": 92,
        "unique-1-nopunct": 76,
        "entropy-1-nopunct": 6.152822052808933,
        "distinct-2-nopunct": 0.9365079365079365,
        "vocab_size-2-nopunct": 118,
        "unique-2-nopunct": 111,
        "entropy-2-nopunct": 6.844304625863708,
        "cond_entropy-2-nopunct": 0.7289522127410368,
        "distinct-3-nopunct": 0.9915254237288136,
        "vocab_size-3-nopunct": 117,
        "unique-3-nopunct": 116,
        "entropy-3-nopunct": 6.865693896819459,
        "cond_entropy-3-nopunct": 0.03040454537178474,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.79643215471471,
        "bleu": 44.64161,
        "rouge1": {
            "precision": 0.81669,
            "recall": 0.76459,
            "fmeasure": 0.77593
        },
        "rouge2": {
            "precision": 0.53731,
            "recall": 0.50896,
            "fmeasure": 0.51359
        },
        "rougeL": {
            "precision": 0.73455,
            "recall": 0.69801,
            "fmeasure": 0.70403
        },
        "rougeLsum": {
            "precision": 0.73455,
            "recall": 0.69801,
            "fmeasure": 0.70403
        },
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.64,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.94787,
            "recall": 0.93438,
            "f1": 0.93974
        },
        "bleurt": 0.21967,
        "meteor": 0.37809546527874865,
        "nubia": {
            "semantic_relation": 4.24953,
            "contradiction": 0.9054,
            "irrelevancy": 34.43746,
            "logical_agreement": 64.65714,
            "grammar_ref": 4.94279,
            "grammar_hyp": 4.89193,
            "nubia_score": 0.72297
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_255": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.72,
        "msttr-100_nopunct": NaN,
        "total_length": 100,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 4.384315479321969,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 25,
        "distinct-1": 0.72,
        "vocab_size-1": 72,
        "unique-1": 62,
        "entropy-1": 5.852501910677062,
        "distinct-2": 0.9787234042553191,
        "vocab_size-2": 92,
        "unique-2": 90,
        "entropy-2": 6.512035660188262,
        "cond_entropy-2": 0.5450481183437664,
        "distinct-3": 1.0,
        "vocab_size-3": 88,
        "unique-3": 88,
        "entropy-3": 6.459431618637305,
        "cond_entropy-3": -0.049702687585794894,
        "total_length-nopunct": 87,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 3.685557397915997,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7816091954022989,
        "vocab_size-1-nopunct": 68,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 5.845058295492363,
        "distinct-2-nopunct": 0.9753086419753086,
        "vocab_size-2-nopunct": 79,
        "unique-2-nopunct": 77,
        "entropy-2-nopunct": 6.290467286835232,
        "cond_entropy-2-nopunct": 0.4773511049495204,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 75,
        "unique-3-nopunct": 75,
        "entropy-3-nopunct": 6.228818690495891,
        "cond_entropy-3-nopunct": -0.05769797905541065,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.633141972004776,
        "bleu": 32.21567,
        "rouge1": {
            "precision": 0.75066,
            "recall": 0.74293,
            "fmeasure": 0.73911
        },
        "rouge2": {
            "precision": 0.47166,
            "recall": 0.47498,
            "fmeasure": 0.46787
        },
        "rougeL": {
            "precision": 0.52407,
            "recall": 0.55002,
            "fmeasure": 0.53145
        },
        "rougeLsum": {
            "precision": 0.52407,
            "recall": 0.55002,
            "fmeasure": 0.53145
        },
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.3333333333333333,
            "3": 0.7571428571428571
        },
        "bertscore": {
            "precision": 0.92042,
            "recall": 0.92184,
            "f1": 0.91998
        },
        "bleurt": 0.24003,
        "meteor": 0.37134285656517463,
        "nubia": {
            "semantic_relation": 4.15313,
            "contradiction": 19.02785,
            "irrelevancy": 35.67961,
            "logical_agreement": 45.29253,
            "grammar_ref": 5.40206,
            "grammar_hyp": 4.87828,
            "nubia_score": 0.73693
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_309": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 11,
        "unique-1": 9,
        "entropy-1": 3.392747410448785,
        "distinct-2": 0.9166666666666666,
        "vocab_size-2": 11,
        "unique-2": 10,
        "entropy-2": 3.4182958340544896,
        "cond_entropy-2": 0.05118944924673078,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": 0.05628729973432271,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.095795255000934,
        "distinct-2-nopunct": 0.9,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.1219280948873624,
        "cond_entropy-2-nopunct": -0.037503523749935014,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.04089198233393864,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2968631512928868,
        "bleu": 66.5205,
        "rouge1": {
            "precision": 0.77273,
            "recall": 0.78333,
            "fmeasure": 0.7764
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.71717,
            "fmeasure": 0.70677
        },
        "rougeL": {
            "precision": 0.77273,
            "recall": 0.78333,
            "fmeasure": 0.7764
        },
        "rougeLsum": {
            "precision": 0.77273,
            "recall": 0.78333,
            "fmeasure": 0.7764
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.875
        },
        "bertscore": {
            "precision": 0.93882,
            "recall": 0.93959,
            "f1": 0.93921
        },
        "bleurt": 0.66261,
        "meteor": 0.4856604859161882,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 5.94782,
            "irrelevancy": 2.60471,
            "logical_agreement": 91.44748,
            "grammar_ref": 4.59758,
            "grammar_hyp": 4.11205,
            "nubia_score": 0.9489
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_342": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 51,
        "mean_pred_length": 10.2,
        "std_pred_length": 2.227105745132009,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 12,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 42,
        "unique-1": 36,
        "entropy-1": 5.248706901296267,
        "distinct-2": 1.0,
        "vocab_size-2": 46,
        "unique-2": 46,
        "entropy-2": 5.5235619560570095,
        "cond_entropy-2": 0.06852791843334335,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.1660099514389293,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 2.0976176963403033,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.269630874107451,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.3219280948873635,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.1926450779423959,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.430174345439115,
        "bleu": 43.6598,
        "rouge1": {
            "precision": 0.77636,
            "recall": 0.78444,
            "fmeasure": 0.77776
        },
        "rouge2": {
            "precision": 0.48981,
            "recall": 0.46261,
            "fmeasure": 0.4745
        },
        "rougeL": {
            "precision": 0.75212,
            "recall": 0.75852,
            "fmeasure": 0.75283
        },
        "rougeLsum": {
            "precision": 0.75212,
            "recall": 0.75852,
            "fmeasure": 0.75283
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8157894736842105
        },
        "bertscore": {
            "precision": 0.93869,
            "recall": 0.93191,
            "f1": 0.93489
        },
        "bleurt": 0.41005,
        "meteor": 0.41915768811216064,
        "nubia": {
            "semantic_relation": 4.39958,
            "contradiction": 0.51112,
            "irrelevancy": 46.79547,
            "logical_agreement": 52.69341,
            "grammar_ref": 5.90284,
            "grammar_hyp": 5.31808,
            "nubia_score": 0.85098
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_310": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.8,
        "total_length": 206,
        "mean_pred_length": 14.714285714285714,
        "std_pred_length": 4.7423407636279515,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 21,
        "distinct-1": 0.6504854368932039,
        "vocab_size-1": 134,
        "unique-1": 110,
        "entropy-1": 6.583712358018649,
        "distinct-2": 0.9270833333333334,
        "vocab_size-2": 178,
        "unique-2": 167,
        "entropy-2": 7.424780794980743,
        "cond_entropy-2": 0.6438604445636219,
        "distinct-3": 0.9719101123595506,
        "vocab_size-3": 173,
        "unique-3": 168,
        "entropy-3": 7.419553655685473,
        "cond_entropy-3": 0.007371421830429659,
        "total_length-nopunct": 177,
        "mean_pred_length-nopunct": 12.642857142857142,
        "std_pred_length-nopunct": 4.010827183247559,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7231638418079096,
        "vocab_size-1-nopunct": 128,
        "unique-1-nopunct": 107,
        "entropy-1-nopunct": 6.6733276889307405,
        "distinct-2-nopunct": 0.9263803680981595,
        "vocab_size-2-nopunct": 151,
        "unique-2-nopunct": 142,
        "entropy-2-nopunct": 7.184587740107398,
        "cond_entropy-2-nopunct": 0.5672102969197811,
        "distinct-3-nopunct": 0.9798657718120806,
        "vocab_size-3-nopunct": 146,
        "unique-3-nopunct": 143,
        "entropy-3-nopunct": 7.1789000640863305,
        "cond_entropy-3-nopunct": 0.009734913225469885,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.309668635184951,
        "bleu": 65.40453,
        "rouge1": {
            "precision": 0.87276,
            "recall": 0.81207,
            "fmeasure": 0.8384
        },
        "rouge2": {
            "precision": 0.73237,
            "recall": 0.68448,
            "fmeasure": 0.70505
        },
        "rougeL": {
            "precision": 0.78509,
            "recall": 0.73052,
            "fmeasure": 0.75409
        },
        "rougeLsum": {
            "precision": 0.78509,
            "recall": 0.73052,
            "fmeasure": 0.75409
        },
        "local_recall": {
            "1": 0.08823529411764706,
            "2": 0.46875,
            "3": 0.8653846153846154
        },
        "bertscore": {
            "precision": 0.95188,
            "recall": 0.9367,
            "f1": 0.94396
        },
        "bleurt": 0.44385,
        "meteor": 0.4646605139300753,
        "nubia": {
            "semantic_relation": 4.22936,
            "contradiction": 7.36738,
            "irrelevancy": 18.96094,
            "logical_agreement": 73.67168,
            "grammar_ref": 4.89936,
            "grammar_hyp": 4.92129,
            "nubia_score": 0.73149
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_235": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.75,
        "msttr-100_nopunct": NaN,
        "total_length": 109,
        "mean_pred_length": 15.571428571428571,
        "std_pred_length": 3.4166459266003995,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 21,
        "distinct-1": 0.7064220183486238,
        "vocab_size-1": 77,
        "unique-1": 64,
        "entropy-1": 5.942349348345695,
        "distinct-2": 0.9313725490196079,
        "vocab_size-2": 95,
        "unique-2": 89,
        "entropy-2": 6.527769582146368,
        "cond_entropy-2": 0.44943357086551794,
        "distinct-3": 0.968421052631579,
        "vocab_size-3": 92,
        "unique-3": 89,
        "entropy-3": 6.5066977135941055,
        "cond_entropy-3": -0.03146565467040605,
        "total_length-nopunct": 96,
        "mean_pred_length-nopunct": 13.714285714285714,
        "std_pred_length-nopunct": 3.614031611621005,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7604166666666666,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 5.935332000964908,
        "distinct-2-nopunct": 0.9325842696629213,
        "vocab_size-2-nopunct": 83,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.33242008824547,
        "cond_entropy-2-nopunct": 0.4257107108568907,
        "distinct-3-nopunct": 0.975609756097561,
        "vocab_size-3-nopunct": 80,
        "unique-3-nopunct": 78,
        "entropy-3-nopunct": 6.3087715168132075,
        "cond_entropy-3-nopunct": -0.03580474949266216,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.165360396313315,
        "bleu": 46.0429,
        "rouge1": {
            "precision": 0.72491,
            "recall": 0.71622,
            "fmeasure": 0.71209
        },
        "rouge2": {
            "precision": 0.48679,
            "recall": 0.49009,
            "fmeasure": 0.4783
        },
        "rougeL": {
            "precision": 0.65253,
            "recall": 0.62733,
            "fmeasure": 0.62922
        },
        "rougeLsum": {
            "precision": 0.65253,
            "recall": 0.62733,
            "fmeasure": 0.62922
        },
        "local_recall": {
            "1": 0.22857142857142856,
            "2": 0.35,
            "3": 0.8307692307692308
        },
        "bertscore": {
            "precision": 0.89535,
            "recall": 0.91066,
            "f1": 0.9
        },
        "bleurt": 0.10637,
        "meteor": 0.3658653399690987,
        "nubia": {
            "semantic_relation": 4.06766,
            "contradiction": 4.87313,
            "irrelevancy": 53.16063,
            "logical_agreement": 41.96624,
            "grammar_ref": 5.24762,
            "grammar_hyp": 4.9335,
            "nubia_score": 0.67953
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_280": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 25,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.80333,
        "total_length": 422,
        "mean_pred_length": 16.88,
        "std_pred_length": 6.71309168714386,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.6137440758293838,
        "vocab_size-1": 259,
        "unique-1": 218,
        "entropy-1": 7.333484207951546,
        "distinct-2": 0.9596977329974811,
        "vocab_size-2": 381,
        "unique-2": 371,
        "entropy-2": 8.536359106521818,
        "cond_entropy-2": 0.994258731228575,
        "distinct-3": 1.0,
        "vocab_size-3": 372,
        "unique-3": 372,
        "entropy-3": 8.539158811108075,
        "cond_entropy-3": 0.003917721429052686,
        "total_length-nopunct": 367,
        "mean_pred_length-nopunct": 14.68,
        "std_pred_length-nopunct": 5.7807957929683,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6893732970027248,
        "vocab_size-1-nopunct": 253,
        "unique-1-nopunct": 218,
        "entropy-1-nopunct": 7.483568615615065,
        "distinct-2-nopunct": 0.956140350877193,
        "vocab_size-2-nopunct": 327,
        "unique-2-nopunct": 318,
        "entropy-2-nopunct": 8.311523485714543,
        "cond_entropy-2-nopunct": 0.8978428552769313,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 317,
        "unique-3-nopunct": 317,
        "entropy-3-nopunct": 8.308339030139457,
        "cond_entropy-3-nopunct": 0.0052011145487785015,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.858585864530785,
        "bleu": 50.97935,
        "rouge1": {
            "precision": 0.79594,
            "recall": 0.7845,
            "fmeasure": 0.78142
        },
        "rouge2": {
            "precision": 0.57679,
            "recall": 0.56401,
            "fmeasure": 0.56215
        },
        "rougeL": {
            "precision": 0.67291,
            "recall": 0.65874,
            "fmeasure": 0.65857
        },
        "rougeLsum": {
            "precision": 0.67291,
            "recall": 0.65874,
            "fmeasure": 0.65857
        },
        "local_recall": {
            "1": 0.1956521739130435,
            "2": 0.46875,
            "3": 0.8172043010752689
        },
        "bertscore": {
            "precision": 0.94089,
            "recall": 0.9405,
            "f1": 0.93868
        },
        "bleurt": 0.34777,
        "meteor": 0.4313348247565029,
        "nubia": {
            "semantic_relation": 4.32578,
            "contradiction": 5.81386,
            "irrelevancy": 27.86108,
            "logical_agreement": 66.32506,
            "grammar_ref": 4.76367,
            "grammar_hyp": 4.75238,
            "nubia_score": 0.75586
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_238": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.69,
        "total_length": 120,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 4.242640687119285,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.6333333333333333,
        "vocab_size-1": 76,
        "unique-1": 52,
        "entropy-1": 5.971025907910209,
        "distinct-2": 0.8648648648648649,
        "vocab_size-2": 96,
        "unique-2": 81,
        "entropy-2": 6.52414559607985,
        "cond_entropy-2": 0.37197966273093314,
        "distinct-3": 0.8823529411764706,
        "vocab_size-3": 90,
        "unique-3": 78,
        "entropy-3": 6.437131224324442,
        "cond_entropy-3": -0.06316699496684561,
        "total_length-nopunct": 107,
        "mean_pred_length-nopunct": 11.88888888888889,
        "std_pred_length-nopunct": 4.408185427750527,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6915887850467289,
        "vocab_size-1-nopunct": 74,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 6.033294673215932,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 70,
        "entropy-2-nopunct": 6.328995558400932,
        "cond_entropy-2-nopunct": 0.34032895476321795,
        "distinct-3-nopunct": 0.8764044943820225,
        "vocab_size-3-nopunct": 78,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 6.22854241973045,
        "cond_entropy-3-nopunct": -0.09403259292409145,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.894612894930432,
        "bleu": 62.28819,
        "rouge1": {
            "precision": 0.90323,
            "recall": 0.8074,
            "fmeasure": 0.84398
        },
        "rouge2": {
            "precision": 0.7116,
            "recall": 0.64831,
            "fmeasure": 0.67084
        },
        "rougeL": {
            "precision": 0.83509,
            "recall": 0.76937,
            "fmeasure": 0.79094
        },
        "rougeLsum": {
            "precision": 0.83509,
            "recall": 0.76937,
            "fmeasure": 0.79094
        },
        "local_recall": {
            "1": 0.32432432432432434,
            "2": 0.6,
            "3": 0.8588235294117647
        },
        "bertscore": {
            "precision": 0.96766,
            "recall": 0.93816,
            "f1": 0.95103
        },
        "bleurt": 0.3847,
        "meteor": 0.42887948034293727,
        "nubia": {
            "semantic_relation": 4.31932,
            "contradiction": 0.46141,
            "irrelevancy": 16.29212,
            "logical_agreement": 83.24646,
            "grammar_ref": 4.78166,
            "grammar_hyp": 5.13365,
            "nubia_score": 0.7568
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_312": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.735,
        "total_length": 255,
        "mean_pred_length": 18.214285714285715,
        "std_pred_length": 4.6164081805875785,
        "median_pred_length": 17.5,
        "min_pred_length": 12,
        "max_pred_length": 31,
        "distinct-1": 0.6196078431372549,
        "vocab_size-1": 158,
        "unique-1": 130,
        "entropy-1": 6.696988350237052,
        "distinct-2": 0.941908713692946,
        "vocab_size-2": 227,
        "unique-2": 218,
        "entropy-2": 7.775464375737197,
        "cond_entropy-2": 0.9326674873420244,
        "distinct-3": 0.9823788546255506,
        "vocab_size-3": 223,
        "unique-3": 219,
        "entropy-3": 7.7913061965419965,
        "cond_entropy-3": 0.024317369029075612,
        "total_length-nopunct": 227,
        "mean_pred_length-nopunct": 16.214285714285715,
        "std_pred_length-nopunct": 4.4106781375036945,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6740088105726872,
        "vocab_size-1-nopunct": 153,
        "unique-1-nopunct": 127,
        "entropy-1-nopunct": 6.771608485640042,
        "distinct-2-nopunct": 0.9389671361502347,
        "vocab_size-2-nopunct": 200,
        "unique-2-nopunct": 192,
        "entropy-2-nopunct": 7.588609078072057,
        "cond_entropy-2-nopunct": 0.8695085620206549,
        "distinct-3-nopunct": 0.9849246231155779,
        "vocab_size-3-nopunct": 196,
        "unique-3-nopunct": 193,
        "entropy-3-nopunct": 7.606473866774815,
        "cond_entropy-3-nopunct": 0.02311809317591976,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.817956143099618,
        "bleu": 43.03446,
        "rouge1": {
            "precision": 0.71861,
            "recall": 0.76054,
            "fmeasure": 0.72974
        },
        "rouge2": {
            "precision": 0.46516,
            "recall": 0.5166,
            "fmeasure": 0.48486
        },
        "rougeL": {
            "precision": 0.62362,
            "recall": 0.66599,
            "fmeasure": 0.63814
        },
        "rougeLsum": {
            "precision": 0.62362,
            "recall": 0.66599,
            "fmeasure": 0.63814
        },
        "local_recall": {
            "1": 0.2413793103448276,
            "2": 0.5581395348837209,
            "3": 0.8029197080291971
        },
        "bertscore": {
            "precision": 0.92959,
            "recall": 0.93859,
            "f1": 0.93334
        },
        "bleurt": 0.33629,
        "meteor": 0.4192459393468149,
        "nubia": {
            "semantic_relation": 4.3084,
            "contradiction": 7.94852,
            "irrelevancy": 27.11666,
            "logical_agreement": 64.93481,
            "grammar_ref": 4.5978,
            "grammar_hyp": 4.28845,
            "nubia_score": 0.77886
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_282": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.0136660282620062,
        "bleu": 7.20006,
        "rouge1": {
            "precision": 0.73684,
            "recall": 0.76413,
            "fmeasure": 0.75012
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.46187,
            "fmeasure": 0.45291
        },
        "rougeL": {
            "precision": 0.47368,
            "recall": 0.49123,
            "fmeasure": 0.48222
        },
        "rougeLsum": {
            "precision": 0.47368,
            "recall": 0.49123,
            "fmeasure": 0.48222
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6153846153846154
        },
        "bertscore": {
            "precision": 0.86346,
            "recall": 0.87342,
            "f1": 0.86842
        },
        "bleurt": 0.20222,
        "meteor": 0.3020836561998712,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.16698,
            "irrelevancy": 0.70855,
            "logical_agreement": 99.12447,
            "grammar_ref": 4.92793,
            "grammar_hyp": 4.81359,
            "nubia_score": 0.95291
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_343": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 95,
        "mean_pred_length": 15.833333333333334,
        "std_pred_length": 4.179978734661484,
        "median_pred_length": 17.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.7263157894736842,
        "vocab_size-1": 69,
        "unique-1": 59,
        "entropy-1": 5.797391629538798,
        "distinct-2": 0.9887640449438202,
        "vocab_size-2": 88,
        "unique-2": 87,
        "entropy-2": 6.45326152085405,
        "cond_entropy-2": 0.5336789797245189,
        "distinct-3": 1.0,
        "vocab_size-3": 83,
        "unique-3": 83,
        "entropy-3": 6.375039431346932,
        "cond_entropy-3": -0.07659761407730431,
        "total_length-nopunct": 82,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 3.197221015541813,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7926829268292683,
        "vocab_size-1-nopunct": 65,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 5.758534742681943,
        "distinct-2-nopunct": 0.9868421052631579,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.221611723969907,
        "cond_entropy-2-nopunct": 0.49720992301976163,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 70,
        "unique-3-nopunct": 70,
        "entropy-3-nopunct": 6.129283016944973,
        "cond_entropy-3-nopunct": -0.09007306792719047,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.029803347368143,
        "bleu": 33.6619,
        "rouge1": {
            "precision": 0.63357,
            "recall": 0.6593,
            "fmeasure": 0.63652
        },
        "rouge2": {
            "precision": 0.39782,
            "recall": 0.3934,
            "fmeasure": 0.38881
        },
        "rougeL": {
            "precision": 0.56737,
            "recall": 0.5829,
            "fmeasure": 0.56563
        },
        "rougeLsum": {
            "precision": 0.56737,
            "recall": 0.5829,
            "fmeasure": 0.56563
        },
        "local_recall": {
            "1": 0.3,
            "2": 0.4166666666666667,
            "3": 0.7708333333333334
        },
        "bertscore": {
            "precision": 0.86936,
            "recall": 0.89421,
            "f1": 0.88126
        },
        "bleurt": 0.02756,
        "meteor": 0.36143920599886326,
        "nubia": {
            "semantic_relation": 3.99889,
            "contradiction": 12.75641,
            "irrelevancy": 46.30276,
            "logical_agreement": 40.94083,
            "grammar_ref": 4.25456,
            "grammar_hyp": 4.21031,
            "nubia_score": 0.71168
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_284": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.8260869565217391,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.142914673354254,
        "distinct-2": 0.9090909090909091,
        "vocab_size-2": 20,
        "unique-2": 18,
        "entropy-2": 4.277613436819114,
        "cond_entropy-2": 0.15200091267862392,
        "distinct-3": 0.9523809523809523,
        "vocab_size-3": 20,
        "unique-3": 19,
        "entropy-3": 4.297079327540665,
        "cond_entropy-3": 0.02812389937955851,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8095238095238095,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.9754180179138325,
        "distinct-2-nopunct": 0.9,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.1219280948873624,
        "cond_entropy-2-nopunct": 0.16735504721677544,
        "distinct-3-nopunct": 0.9473684210526315,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.142664355548846,
        "cond_entropy-3-nopunct": 0.03126257645096008,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.2459338655691528,
        "bleu": 14.10805,
        "rouge1": {
            "precision": 0.54667,
            "recall": 0.51235,
            "fmeasure": 0.52891
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.24,
            "fmeasure": 0.2449
        },
        "rougeL": {
            "precision": 0.48,
            "recall": 0.46154,
            "fmeasure": 0.47059
        },
        "rougeLsum": {
            "precision": 0.48,
            "recall": 0.46154,
            "fmeasure": 0.47059
        },
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.47058823529411764
        },
        "bertscore": {
            "precision": 0.87038,
            "recall": 0.86977,
            "f1": 0.86991
        },
        "bleurt": -0.50071,
        "meteor": 0.26295677420991714,
        "nubia": {
            "semantic_relation": 3.15589,
            "contradiction": 6.00018,
            "irrelevancy": 89.95403,
            "logical_agreement": 4.04578,
            "grammar_ref": 4.71547,
            "grammar_hyp": 5.04386,
            "nubia_score": 0.35509
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_256": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.72,
        "total_length": 153,
        "mean_pred_length": 15.3,
        "std_pred_length": 4.796873982084582,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 22,
        "distinct-1": 0.6797385620915033,
        "vocab_size-1": 104,
        "unique-1": 85,
        "entropy-1": 6.28789974609234,
        "distinct-2": 0.951048951048951,
        "vocab_size-2": 136,
        "unique-2": 130,
        "entropy-2": 7.056690305294736,
        "cond_entropy-2": 0.6042842656158671,
        "distinct-3": 0.9849624060150376,
        "vocab_size-3": 131,
        "unique-3": 129,
        "entropy-3": 7.025207247531274,
        "cond_entropy-3": -0.023725085471459316,
        "total_length-nopunct": 135,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 4.341658669218482,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7333333333333333,
        "vocab_size-1-nopunct": 99,
        "unique-1-nopunct": 84,
        "entropy-1-nopunct": 6.2889821872078215,
        "distinct-2-nopunct": 0.944,
        "vocab_size-2-nopunct": 118,
        "unique-2-nopunct": 112,
        "entropy-2-nopunct": 6.847745184644788,
        "cond_entropy-2-nopunct": 0.6137896702244168,
        "distinct-3-nopunct": 0.9826086956521739,
        "vocab_size-3-nopunct": 113,
        "unique-3-nopunct": 111,
        "entropy-3-nopunct": 6.810707442248738,
        "cond_entropy-3-nopunct": -0.026773472829333775,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.175612448777019,
        "bleu": 54.45687,
        "rouge1": {
            "precision": 0.78879,
            "recall": 0.72274,
            "fmeasure": 0.73289
        },
        "rouge2": {
            "precision": 0.53569,
            "recall": 0.51146,
            "fmeasure": 0.50404
        },
        "rougeL": {
            "precision": 0.68493,
            "recall": 0.63619,
            "fmeasure": 0.63912
        },
        "rougeLsum": {
            "precision": 0.68493,
            "recall": 0.63619,
            "fmeasure": 0.63912
        },
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.41935483870967744,
            "3": 0.8367346938775511
        },
        "bertscore": {
            "precision": 0.9282,
            "recall": 0.91669,
            "f1": 0.91843
        },
        "bleurt": 0.29607,
        "meteor": 0.4145889010061934,
        "nubia": {
            "semantic_relation": 4.24195,
            "contradiction": 8.21013,
            "irrelevancy": 33.07618,
            "logical_agreement": 58.7137,
            "grammar_ref": 4.57625,
            "grammar_hyp": 4.88481,
            "nubia_score": 0.69346
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_344": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.75,
        "msttr-100_nopunct": NaN,
        "total_length": 104,
        "mean_pred_length": 14.857142857142858,
        "std_pred_length": 5.248906591678239,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.7307692307692307,
        "vocab_size-1": 76,
        "unique-1": 66,
        "entropy-1": 5.908877036242441,
        "distinct-2": 0.9690721649484536,
        "vocab_size-2": 94,
        "unique-2": 91,
        "entropy-2": 6.538057172084048,
        "cond_entropy-2": 0.48371059273734685,
        "distinct-3": 1.0,
        "vocab_size-3": 90,
        "unique-3": 90,
        "entropy-3": 6.491853096329662,
        "cond_entropy-3": -0.041393079190786546,
        "total_length-nopunct": 91,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 4.242640687119285,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8131868131868132,
        "vocab_size-1-nopunct": 74,
        "unique-1-nopunct": 66,
        "entropy-1-nopunct": 5.989539041751113,
        "distinct-2-nopunct": 0.9642857142857143,
        "vocab_size-2-nopunct": 81,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.320888851350189,
        "cond_entropy-2-nopunct": 0.37453777613637534,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 77,
        "unique-3-nopunct": 77,
        "entropy-3-nopunct": 6.266786540694905,
        "cond_entropy-3-nopunct": -0.047608804161781246,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.805039317161913,
        "bleu": 39.59391,
        "rouge1": {
            "precision": 0.69994,
            "recall": 0.66999,
            "fmeasure": 0.6708
        },
        "rouge2": {
            "precision": 0.48519,
            "recall": 0.44017,
            "fmeasure": 0.44648
        },
        "rougeL": {
            "precision": 0.65727,
            "recall": 0.63575,
            "fmeasure": 0.63439
        },
        "rougeLsum": {
            "precision": 0.65727,
            "recall": 0.63575,
            "fmeasure": 0.63439
        },
        "local_recall": {
            "1": 0.46153846153846156,
            "2": 0.6296296296296297,
            "3": 0.6307692307692307
        },
        "bertscore": {
            "precision": 0.93062,
            "recall": 0.92344,
            "f1": 0.92676
        },
        "bleurt": 0.27187,
        "meteor": 0.35045070327931077,
        "nubia": {
            "semantic_relation": 4.15084,
            "contradiction": 20.23839,
            "irrelevancy": 36.91443,
            "logical_agreement": 42.84717,
            "grammar_ref": 4.57813,
            "grammar_hyp": 4.17635,
            "nubia_score": 0.71824
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_285": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.84,
        "total_length": 138,
        "mean_pred_length": 19.714285714285715,
        "std_pred_length": 4.977500397195527,
        "median_pred_length": 17.0,
        "min_pred_length": 14,
        "max_pred_length": 26,
        "distinct-1": 0.7318840579710145,
        "vocab_size-1": 101,
        "unique-1": 86,
        "entropy-1": 6.351065579872509,
        "distinct-2": 0.9923664122137404,
        "vocab_size-2": 130,
        "unique-2": 129,
        "entropy-2": 7.018155825964931,
        "cond_entropy-2": 0.5472598044003573,
        "distinct-3": 1.0,
        "vocab_size-3": 124,
        "unique-3": 124,
        "entropy-3": 6.954196310386861,
        "cond_entropy-3": -0.06309765889251046,
        "total_length-nopunct": 121,
        "mean_pred_length-nopunct": 17.285714285714285,
        "std_pred_length-nopunct": 4.164965639175215,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7933884297520661,
        "vocab_size-1-nopunct": 96,
        "unique-1-nopunct": 83,
        "entropy-1-nopunct": 6.381511584310518,
        "distinct-2-nopunct": 0.9912280701754386,
        "vocab_size-2-nopunct": 113,
        "unique-2-nopunct": 112,
        "entropy-2-nopunct": 6.815346154515631,
        "cond_entropy-2-nopunct": 0.4580579173169349,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 107,
        "unique-3-nopunct": 107,
        "entropy-3-nopunct": 6.741466986401138,
        "cond_entropy-3-nopunct": -0.07273143897854792,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.791440645270226,
        "bleu": 47.34899,
        "rouge1": {
            "precision": 0.79053,
            "recall": 0.76553,
            "fmeasure": 0.7709
        },
        "rouge2": {
            "precision": 0.51519,
            "recall": 0.49896,
            "fmeasure": 0.50281
        },
        "rougeL": {
            "precision": 0.69881,
            "recall": 0.68257,
            "fmeasure": 0.68477
        },
        "rougeLsum": {
            "precision": 0.69881,
            "recall": 0.68257,
            "fmeasure": 0.68477
        },
        "local_recall": {
            "1": 0.4117647058823529,
            "2": 0.8064516129032258,
            "3": 0.7654320987654321
        },
        "bertscore": {
            "precision": 0.93201,
            "recall": 0.92452,
            "f1": 0.92704
        },
        "bleurt": 0.31407,
        "meteor": 0.4117425875612028,
        "nubia": {
            "semantic_relation": 4.34749,
            "contradiction": 0.77903,
            "irrelevancy": 27.68315,
            "logical_agreement": 71.53782,
            "grammar_ref": 4.72263,
            "grammar_hyp": 4.44388,
            "nubia_score": 0.79251
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_258": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.72,
        "total_length": 142,
        "mean_pred_length": 15.777777777777779,
        "std_pred_length": 3.7940824619919713,
        "median_pred_length": 17.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.6690140845070423,
        "vocab_size-1": 95,
        "unique-1": 81,
        "entropy-1": 6.14006924015754,
        "distinct-2": 0.9624060150375939,
        "vocab_size-2": 128,
        "unique-2": 125,
        "entropy-2": 6.965056871591423,
        "cond_entropy-2": 0.66851957173567,
        "distinct-3": 1.0,
        "vocab_size-3": 124,
        "unique-3": 124,
        "entropy-3": 6.954196310386861,
        "cond_entropy-3": -0.004311931565927152,
        "total_length-nopunct": 127,
        "mean_pred_length-nopunct": 14.11111111111111,
        "std_pred_length-nopunct": 3.1778554769055756,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7165354330708661,
        "vocab_size-1-nopunct": 91,
        "unique-1-nopunct": 79,
        "entropy-1-nopunct": 6.158762714990598,
        "distinct-2-nopunct": 0.9576271186440678,
        "vocab_size-2-nopunct": 113,
        "unique-2-nopunct": 110,
        "entropy-2-nopunct": 6.780948134107595,
        "cond_entropy-2-nopunct": 0.6770099762867733,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 109,
        "unique-3-nopunct": 109,
        "entropy-3-nopunct": 6.7681843247769145,
        "cond_entropy-3-nopunct": -0.013541293392254558,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.693889415401056,
        "bleu": 36.80219,
        "rouge1": {
            "precision": 0.67396,
            "recall": 0.72678,
            "fmeasure": 0.68323
        },
        "rouge2": {
            "precision": 0.45202,
            "recall": 0.51037,
            "fmeasure": 0.46809
        },
        "rougeL": {
            "precision": 0.63524,
            "recall": 0.69763,
            "fmeasure": 0.64994
        },
        "rougeLsum": {
            "precision": 0.63524,
            "recall": 0.69763,
            "fmeasure": 0.64994
        },
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.32142857142857145,
            "3": 0.7792207792207793
        },
        "bertscore": {
            "precision": 0.9212,
            "recall": 0.91617,
            "f1": 0.9169
        },
        "bleurt": 0.27637,
        "meteor": 0.3600658931553465,
        "nubia": {
            "semantic_relation": 4.05393,
            "contradiction": 26.7728,
            "irrelevancy": 24.99267,
            "logical_agreement": 48.23453,
            "grammar_ref": 5.16318,
            "grammar_hyp": 4.75885,
            "nubia_score": 0.6803
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_286": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 11.0,
        "std_pred_length": 3.6742346141747673,
        "median_pred_length": 10.5,
        "min_pred_length": 7,
        "max_pred_length": 16,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 32,
        "unique-1": 26,
        "entropy-1": 4.7998963911678905,
        "distinct-2": 0.9,
        "vocab_size-2": 36,
        "unique-2": 33,
        "entropy-2": 5.103055907333277,
        "cond_entropy-2": 0.16911303891232493,
        "distinct-3": 0.9444444444444444,
        "vocab_size-3": 34,
        "unique-3": 32,
        "entropy-3": 5.058813890331199,
        "cond_entropy-3": -0.07547844060717561,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 9.75,
        "std_pred_length-nopunct": 3.344772040064913,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7692307692307693,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.746439398127532,
        "distinct-2-nopunct": 0.9142857142857143,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.9362862311688644,
        "cond_entropy-2-nopunct": 0.16087329822694926,
        "distinct-3-nopunct": 0.967741935483871,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.889680181354619,
        "cond_entropy-3-nopunct": -0.12395888395418314,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4963961751273023,
        "bleu": 40.1428,
        "rouge1": {
            "precision": 0.83053,
            "recall": 0.7066,
            "fmeasure": 0.74579
        },
        "rouge2": {
            "precision": 0.6044,
            "recall": 0.52505,
            "fmeasure": 0.54692
        },
        "rougeL": {
            "precision": 0.77925,
            "recall": 0.66146,
            "fmeasure": 0.69797
        },
        "rougeLsum": {
            "precision": 0.77925,
            "recall": 0.66146,
            "fmeasure": 0.69797
        },
        "local_recall": {
            "1": 0.3,
            "2": 0.42857142857142855,
            "3": 0.7096774193548387
        },
        "bertscore": {
            "precision": 0.94478,
            "recall": 0.92985,
            "f1": 0.93483
        },
        "bleurt": 0.35495,
        "meteor": 0.3624733847150543,
        "nubia": {
            "semantic_relation": 4.36361,
            "contradiction": 0.54265,
            "irrelevancy": 29.94929,
            "logical_agreement": 69.50806,
            "grammar_ref": 4.09757,
            "grammar_hyp": 3.82893,
            "nubia_score": 0.89614
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_259": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 76,
        "mean_pred_length": 15.2,
        "std_pred_length": 4.166533331199932,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 56,
        "unique-1": 48,
        "entropy-1": 5.519189645216562,
        "distinct-2": 0.971830985915493,
        "vocab_size-2": 69,
        "unique-2": 67,
        "entropy-2": 6.093409091335662,
        "cond_entropy-2": 0.4620229512838756,
        "distinct-3": 1.0,
        "vocab_size-3": 66,
        "unique-3": 66,
        "entropy-3": 6.044394119358462,
        "cond_entropy-3": -0.0447469395401679,
        "total_length-nopunct": 67,
        "mean_pred_length-nopunct": 13.4,
        "std_pred_length-nopunct": 3.7202150475476548,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7910447761194029,
        "vocab_size-1-nopunct": 53,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.483707847045024,
        "distinct-2-nopunct": 0.967741935483871,
        "vocab_size-2-nopunct": 60,
        "unique-2-nopunct": 58,
        "entropy-2-nopunct": 5.889680181354614,
        "cond_entropy-2-nopunct": 0.45293857168158513,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 57,
        "unique-3-nopunct": 57,
        "entropy-3-nopunct": 5.832890014164737,
        "cond_entropy-3-nopunct": -0.05113085762564231,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.952362637587828,
        "bleu": 63.34522,
        "rouge1": {
            "precision": 0.82606,
            "recall": 0.82364,
            "fmeasure": 0.81823
        },
        "rouge2": {
            "precision": 0.64563,
            "recall": 0.64528,
            "fmeasure": 0.63895
        },
        "rougeL": {
            "precision": 0.76,
            "recall": 0.78672,
            "fmeasure": 0.76683
        },
        "rougeLsum": {
            "precision": 0.76,
            "recall": 0.78672,
            "fmeasure": 0.76683
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.2222222222222222,
            "3": 0.86
        },
        "bertscore": {
            "precision": 0.96848,
            "recall": 0.95686,
            "f1": 0.96258
        },
        "bleurt": 0.48403,
        "meteor": 0.49428289199897807,
        "nubia": {
            "semantic_relation": 4.67665,
            "contradiction": 1.34826,
            "irrelevancy": 15.08821,
            "logical_agreement": 83.56354,
            "grammar_ref": 4.84964,
            "grammar_hyp": 4.85624,
            "nubia_score": 0.86007
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_345": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 8,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 93,
        "mean_pred_length": 11.625,
        "std_pred_length": 3.07967124868873,
        "median_pred_length": 10.5,
        "min_pred_length": 9,
        "max_pred_length": 19,
        "distinct-1": 0.5591397849462365,
        "vocab_size-1": 52,
        "unique-1": 39,
        "entropy-1": 5.267323596726375,
        "distinct-2": 0.7294117647058823,
        "vocab_size-2": 62,
        "unique-2": 52,
        "entropy-2": 5.708101048203156,
        "cond_entropy-2": 0.27812664812445975,
        "distinct-3": 0.7792207792207793,
        "vocab_size-3": 60,
        "unique-3": 53,
        "entropy-3": 5.695357969266331,
        "cond_entropy-3": 0.03414418214728801,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 10.375,
        "std_pred_length-nopunct": 2.496873044429772,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.6024096385542169,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.263224070654232,
        "distinct-2-nopunct": 0.7066666666666667,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.46069015083673,
        "cond_entropy-2-nopunct": 0.2584340107245524,
        "distinct-3-nopunct": 0.7611940298507462,
        "vocab_size-3-nopunct": 51,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.439223518815977,
        "cond_entropy-3-nopunct": 0.040399462266918734,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.391890539400546,
        "bleu": 71.85561,
        "rouge1": {
            "precision": 0.87847,
            "recall": 0.82189,
            "fmeasure": 0.83941
        },
        "rouge2": {
            "precision": 0.79505,
            "recall": 0.73925,
            "fmeasure": 0.75648
        },
        "rougeL": {
            "precision": 0.87153,
            "recall": 0.80105,
            "fmeasure": 0.82651
        },
        "rougeLsum": {
            "precision": 0.87153,
            "recall": 0.80105,
            "fmeasure": 0.82651
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.8888888888888888
        },
        "bertscore": {
            "precision": 0.96559,
            "recall": 0.95586,
            "f1": 0.96005
        },
        "bleurt": 0.68216,
        "meteor": 0.5331292416384904,
        "nubia": {
            "semantic_relation": 4.59085,
            "contradiction": 0.26987,
            "irrelevancy": 13.22015,
            "logical_agreement": 86.50998,
            "grammar_ref": 5.07225,
            "grammar_hyp": 4.88176,
            "nubia_score": 0.91572
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_287": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 58,
        "mean_pred_length": 14.5,
        "std_pred_length": 3.2015621187164243,
        "median_pred_length": 14.5,
        "min_pred_length": 10,
        "max_pred_length": 19,
        "distinct-1": 0.8620689655172413,
        "vocab_size-1": 50,
        "unique-1": 45,
        "entropy-1": 5.5346208657799245,
        "distinct-2": 0.9814814814814815,
        "vocab_size-2": 53,
        "unique-2": 52,
        "entropy-2": 5.717850465126429,
        "cond_entropy-2": 0.05903405337225713,
        "distinct-3": 1.0,
        "vocab_size-3": 50,
        "unique-3": 50,
        "entropy-3": 5.643856189774728,
        "cond_entropy-3": -0.07103131238874397,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 12.25,
        "std_pred_length-nopunct": 2.165063509461097,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9387755102040817,
        "vocab_size-1-nopunct": 46,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.492260864523372,
        "distinct-2-nopunct": 0.9777777777777777,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.447408651885229,
        "cond_entropy-2-nopunct": -0.033967858896644734,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.08552060390671314,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9010741406202802,
        "bleu": 50.89581,
        "rouge1": {
            "precision": 0.84243,
            "recall": 0.70747,
            "fmeasure": 0.76213
        },
        "rouge2": {
            "precision": 0.64583,
            "recall": 0.56927,
            "fmeasure": 0.6009
        },
        "rougeL": {
            "precision": 0.74275,
            "recall": 0.64124,
            "fmeasure": 0.68283
        },
        "rougeLsum": {
            "precision": 0.74275,
            "recall": 0.64124,
            "fmeasure": 0.68283
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "bertscore": {
            "precision": 0.94521,
            "recall": 0.91806,
            "f1": 0.93102
        },
        "bleurt": 0.48144,
        "meteor": 0.4011336247863583,
        "nubia": {
            "semantic_relation": 4.22065,
            "contradiction": 2.26059,
            "irrelevancy": 18.84367,
            "logical_agreement": 78.89574,
            "grammar_ref": 4.68915,
            "grammar_hyp": 4.88308,
            "nubia_score": 0.69834
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_288": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.76,
        "total_length": 207,
        "mean_pred_length": 17.25,
        "std_pred_length": 5.889609494694874,
        "median_pred_length": 15.5,
        "min_pred_length": 11,
        "max_pred_length": 31,
        "distinct-1": 0.6135265700483091,
        "vocab_size-1": 127,
        "unique-1": 98,
        "entropy-1": 6.472543446514994,
        "distinct-2": 0.9435897435897436,
        "vocab_size-2": 184,
        "unique-2": 174,
        "entropy-2": 7.490638582969321,
        "cond_entropy-2": 0.8726170447781626,
        "distinct-3": 0.994535519125683,
        "vocab_size-3": 182,
        "unique-3": 181,
        "entropy-3": 7.504770876535403,
        "cond_entropy-3": 0.021784210338603706,
        "total_length-nopunct": 181,
        "mean_pred_length-nopunct": 15.083333333333334,
        "std_pred_length-nopunct": 5.589548779244668,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6740331491712708,
        "vocab_size-1-nopunct": 122,
        "unique-1-nopunct": 95,
        "entropy-1-nopunct": 6.551436997800924,
        "distinct-2-nopunct": 0.9408284023668639,
        "vocab_size-2-nopunct": 159,
        "unique-2-nopunct": 150,
        "entropy-2-nopunct": 7.278069451062274,
        "cond_entropy-2-nopunct": 0.7821407767606724,
        "distinct-3-nopunct": 0.9936305732484076,
        "vocab_size-3-nopunct": 156,
        "unique-3-nopunct": 155,
        "entropy-3-nopunct": 7.281881895388437,
        "cond_entropy-3-nopunct": 0.013199194788827799,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.249452980014054,
        "bleu": 43.23494,
        "rouge1": {
            "precision": 0.67808,
            "recall": 0.69399,
            "fmeasure": 0.66807
        },
        "rouge2": {
            "precision": 0.52037,
            "recall": 0.54572,
            "fmeasure": 0.5198
        },
        "rougeL": {
            "precision": 0.59089,
            "recall": 0.62782,
            "fmeasure": 0.59323
        },
        "rougeLsum": {
            "precision": 0.59089,
            "recall": 0.62782,
            "fmeasure": 0.59323
        },
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.41935483870967744,
            "3": 0.7022900763358778
        },
        "bertscore": {
            "precision": 0.90052,
            "recall": 0.916,
            "f1": 0.90692
        },
        "bleurt": -0.03468,
        "meteor": 0.36380784234813685,
        "nubia": {
            "semantic_relation": 3.55277,
            "contradiction": 15.13449,
            "irrelevancy": 49.90143,
            "logical_agreement": 34.96407,
            "grammar_ref": 4.5489,
            "grammar_hyp": 4.52148,
            "nubia_score": 0.53607
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_240": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.722,
        "msttr-100_nopunct": 0.8,
        "total_length": 593,
        "mean_pred_length": 19.129032258064516,
        "std_pred_length": 8.690899710222928,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 42,
        "distinct-1": 0.5413153456998314,
        "vocab_size-1": 321,
        "unique-1": 253,
        "entropy-1": 7.484800948291497,
        "distinct-2": 0.8629893238434164,
        "vocab_size-2": 485,
        "unique-2": 433,
        "entropy-2": 8.807649201908268,
        "cond_entropy-2": 1.1448404637801675,
        "distinct-3": 0.9397363465160076,
        "vocab_size-3": 499,
        "unique-3": 470,
        "entropy-3": 8.92685263177942,
        "cond_entropy-3": 0.12932622302657606,
        "total_length-nopunct": 506,
        "mean_pred_length-nopunct": 16.322580645161292,
        "std_pred_length-nopunct": 7.109226611783445,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.6245059288537549,
        "vocab_size-1-nopunct": 316,
        "unique-1-nopunct": 253,
        "entropy-1-nopunct": 7.727387067142291,
        "distinct-2-nopunct": 0.8842105263157894,
        "vocab_size-2-nopunct": 420,
        "unique-2-nopunct": 382,
        "entropy-2-nopunct": 8.615395887396883,
        "cond_entropy-2-nopunct": 0.9476695344302468,
        "distinct-3-nopunct": 0.9504504504504504,
        "vocab_size-3-nopunct": 422,
        "unique-3-nopunct": 400,
        "entropy-3-nopunct": 8.695316767251024,
        "cond_entropy-3-nopunct": 0.09020921834608411,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.116272293587062,
        "bleu": 55.7941,
        "rouge1": {
            "precision": 0.79969,
            "recall": 0.8179,
            "fmeasure": 0.79694
        },
        "rouge2": {
            "precision": 0.59722,
            "recall": 0.61123,
            "fmeasure": 0.59732
        },
        "rougeL": {
            "precision": 0.67988,
            "recall": 0.70347,
            "fmeasure": 0.68065
        },
        "rougeLsum": {
            "precision": 0.67988,
            "recall": 0.70347,
            "fmeasure": 0.68065
        },
        "local_recall": {
            "1": 0.25925925925925924,
            "2": 0.3125,
            "3": 0.8783783783783784
        },
        "bertscore": {
            "precision": 0.93996,
            "recall": 0.94366,
            "f1": 0.94035
        },
        "bleurt": 0.41819,
        "meteor": 0.4505969686521731,
        "nubia": {
            "semantic_relation": 4.44336,
            "contradiction": 3.24088,
            "irrelevancy": 19.31211,
            "logical_agreement": 77.44701,
            "grammar_ref": 4.66938,
            "grammar_hyp": 4.52439,
            "nubia_score": 0.79042
        }
    },
    "schema_guided_dialog_challenge_test_bfp02_parent": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.69262,
        "msttr-100_nopunct": 0.71246,
        "total_length": 6541,
        "mean_pred_length": 13.082,
        "std_pred_length": 7.499285032588107,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 40,
        "distinct-1": 0.14768384039137747,
        "vocab_size-1": 966,
        "unique-1": 526,
        "entropy-1": 7.802019453910254,
        "distinct-2": 0.4534017546763781,
        "vocab_size-2": 2739,
        "unique-2": 1845,
        "entropy-2": 10.597982795043508,
        "cond_entropy-2": 2.5698899222642213,
        "distinct-3": 0.6616134271792096,
        "vocab_size-3": 3666,
        "unique-3": 2908,
        "entropy-3": 11.417796269097154,
        "cond_entropy-3": 0.8446354115858539,
        "total_length-nopunct": 5746,
        "mean_pred_length-nopunct": 11.492,
        "std_pred_length-nopunct": 6.8607533114083035,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.16568047337278108,
        "vocab_size-1-nopunct": 952,
        "unique-1-nopunct": 522,
        "entropy-1-nopunct": 7.971390216085853,
        "distinct-2-nopunct": 0.4708349218452154,
        "vocab_size-2-nopunct": 2470,
        "unique-2-nopunct": 1706,
        "entropy-2-nopunct": 10.441432531694236,
        "cond_entropy-2-nopunct": 2.5975869554139415,
        "distinct-3-nopunct": 0.6776163402821647,
        "vocab_size-3-nopunct": 3218,
        "unique-3-nopunct": 2602,
        "entropy-3-nopunct": 11.229145988246287,
        "cond_entropy-3-nopunct": 0.8219731968311706,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.305405141046564,
        "bleu": 33.39069,
        "rouge1": {
            "precision": 0.59372,
            "recall": 0.56907,
            "fmeasure": 0.57057
        },
        "rouge2": {
            "precision": 0.37951,
            "recall": 0.36495,
            "fmeasure": 0.36421
        },
        "rougeL": {
            "precision": 0.53714,
            "recall": 0.5141,
            "fmeasure": 0.5157
        },
        "rougeLsum": {
            "precision": 0.53714,
            "recall": 0.5141,
            "fmeasure": 0.5157
        },
        "local_recall": {
            "1": 0.5790482830747777
        },
        "bertscore": {
            "precision": 0.87715,
            "recall": 0.86905,
            "f1": 0.87263
        },
        "bleurt": -0.04356,
        "meteor": 0.3246074785734023,
        "nubia": {
            "semantic_relation": 3.68658,
            "contradiction": 7.03005,
            "irrelevancy": 20.32618,
            "logical_agreement": 72.64376,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.61263,
            "nubia_score": 0.66025
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_289": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.7916666666666666,
        "vocab_size-1": 19,
        "unique-1": 14,
        "entropy-1": 4.16829583405449,
        "distinct-2": 0.9130434782608695,
        "vocab_size-2": 21,
        "unique-2": 19,
        "entropy-2": 4.349648912578752,
        "cond_entropy-2": 0.19946902055324797,
        "distinct-3": 0.9545454545454546,
        "vocab_size-3": 21,
        "unique-3": 20,
        "entropy-3": 4.368522527728205,
        "cond_entropy-3": 0.026778753489375355,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.782608695652174,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.088779347361362,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.277613436819114,
        "cond_entropy-2-nopunct": 0.20859693530755724,
        "distinct-3-nopunct": 0.9523809523809523,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.297079327540665,
        "cond_entropy-3-nopunct": 0.02812389937955851,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.710909349073911,
        "bleu": 37.01632,
        "rouge1": {
            "precision": 0.64,
            "recall": 0.76316,
            "fmeasure": 0.69125
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.54321,
            "fmeasure": 0.48553
        },
        "rougeL": {
            "precision": 0.46667,
            "recall": 0.54073,
            "fmeasure": 0.49686
        },
        "rougeLsum": {
            "precision": 0.46667,
            "recall": 0.54073,
            "fmeasure": 0.49686
        },
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.92716,
            "recall": 0.93529,
            "f1": 0.93121
        },
        "bleurt": -0.05528,
        "meteor": 0.4423351198823151,
        "nubia": {
            "semantic_relation": 4.1101,
            "contradiction": 28.57621,
            "irrelevancy": 64.57991,
            "logical_agreement": 6.84388,
            "grammar_ref": 3.99891,
            "grammar_hyp": 4.4557,
            "nubia_score": 0.66323
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_260": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 22,
        "msttr-100": 0.69333,
        "msttr-100_nopunct": 0.77333,
        "total_length": 341,
        "mean_pred_length": 15.5,
        "std_pred_length": 5.852349955359813,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 36,
        "distinct-1": 0.5894428152492669,
        "vocab_size-1": 201,
        "unique-1": 161,
        "entropy-1": 6.971606703890062,
        "distinct-2": 0.8871473354231975,
        "vocab_size-2": 283,
        "unique-2": 260,
        "entropy-2": 8.047384508788697,
        "cond_entropy-2": 0.8676805363811222,
        "distinct-3": 0.9528619528619529,
        "vocab_size-3": 283,
        "unique-3": 271,
        "entropy-3": 8.114959609001714,
        "cond_entropy-3": 0.08084317532913081,
        "total_length-nopunct": 302,
        "mean_pred_length-nopunct": 13.727272727272727,
        "std_pred_length-nopunct": 5.118432094639727,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6490066225165563,
        "vocab_size-1-nopunct": 196,
        "unique-1-nopunct": 159,
        "entropy-1-nopunct": 7.1009344551367555,
        "distinct-2-nopunct": 0.8892857142857142,
        "vocab_size-2-nopunct": 249,
        "unique-2-nopunct": 230,
        "entropy-2-nopunct": 7.860054166997643,
        "cond_entropy-2-nopunct": 0.8228855020419695,
        "distinct-3-nopunct": 0.9612403100775194,
        "vocab_size-3-nopunct": 248,
        "unique-3-nopunct": 239,
        "entropy-3-nopunct": 7.93078195502724,
        "cond_entropy-3-nopunct": 0.07979008337119231,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.6982065080463835,
        "bleu": 60.66911,
        "rouge1": {
            "precision": 0.8445,
            "recall": 0.85653,
            "fmeasure": 0.84335
        },
        "rouge2": {
            "precision": 0.70683,
            "recall": 0.70999,
            "fmeasure": 0.70275
        },
        "rougeL": {
            "precision": 0.77088,
            "recall": 0.78036,
            "fmeasure": 0.76949
        },
        "rougeLsum": {
            "precision": 0.77088,
            "recall": 0.78036,
            "fmeasure": 0.76949
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.8616600790513834
        },
        "bertscore": {
            "precision": 0.95464,
            "recall": 0.9522,
            "f1": 0.9522
        },
        "bleurt": 0.4695,
        "meteor": 0.48620489522124805,
        "nubia": {
            "semantic_relation": 4.47377,
            "contradiction": 0.50376,
            "irrelevancy": 30.4315,
            "logical_agreement": 69.06474,
            "grammar_ref": 4.36588,
            "grammar_hyp": 4.31096,
            "nubia_score": 0.83632
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_243": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.0,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 20,
        "distinct-1": 0.78125,
        "vocab_size-1": 25,
        "unique-1": 19,
        "entropy-1": 4.538909765557392,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.3320535123473008,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.392747410448783,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.21785611591339737,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9083912058664922,
        "bleu": 30.99425,
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.84788,
            "fmeasure": 0.77302
        },
        "rouge2": {
            "precision": 0.45625,
            "recall": 0.48162,
            "fmeasure": 0.46465
        },
        "rougeL": {
            "precision": 0.50267,
            "recall": 0.547,
            "fmeasure": 0.51895
        },
        "rougeLsum": {
            "precision": 0.50267,
            "recall": 0.547,
            "fmeasure": 0.51895
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8421052631578947
        },
        "bertscore": {
            "precision": 0.90622,
            "recall": 0.94179,
            "f1": 0.92361
        },
        "bleurt": -0.15371,
        "meteor": 0.40049159435932963,
        "nubia": {
            "semantic_relation": 4.31285,
            "contradiction": 1.07887,
            "irrelevancy": 47.72001,
            "logical_agreement": 51.20111,
            "grammar_ref": 5.56806,
            "grammar_hyp": 5.35044,
            "nubia_score": 0.73497
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_315": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.7,
        "total_length": 211,
        "mean_pred_length": 16.23076923076923,
        "std_pred_length": 5.686067265408101,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 29,
        "distinct-1": 0.5829383886255924,
        "vocab_size-1": 123,
        "unique-1": 87,
        "entropy-1": 6.486855154154424,
        "distinct-2": 0.898989898989899,
        "vocab_size-2": 178,
        "unique-2": 163,
        "entropy-2": 7.4057977185316615,
        "cond_entropy-2": 0.7570206255558124,
        "distinct-3": 0.9567567567567568,
        "vocab_size-3": 177,
        "unique-3": 170,
        "entropy-3": 7.440814501045147,
        "cond_entropy-3": 0.025024232340288943,
        "total_length-nopunct": 183,
        "mean_pred_length-nopunct": 14.076923076923077,
        "std_pred_length-nopunct": 4.953033856001615,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6502732240437158,
        "vocab_size-1-nopunct": 119,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.550299343746346,
        "distinct-2-nopunct": 0.9235294117647059,
        "vocab_size-2-nopunct": 157,
        "unique-2-nopunct": 147,
        "entropy-2-nopunct": 7.240244539066122,
        "cond_entropy-2-nopunct": 0.710828762549158,
        "distinct-3-nopunct": 0.9745222929936306,
        "vocab_size-3-nopunct": 153,
        "unique-3-nopunct": 149,
        "entropy-3-nopunct": 7.243665334878884,
        "cond_entropy-3-nopunct": -0.020790012073058937,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.972963386755779,
        "bleu": 33.86881,
        "rouge1": {
            "precision": 0.70354,
            "recall": 0.66345,
            "fmeasure": 0.67055
        },
        "rouge2": {
            "precision": 0.41648,
            "recall": 0.40424,
            "fmeasure": 0.40233
        },
        "rougeL": {
            "precision": 0.5782,
            "recall": 0.54885,
            "fmeasure": 0.55236
        },
        "rougeLsum": {
            "precision": 0.5782,
            "recall": 0.54885,
            "fmeasure": 0.55236
        },
        "local_recall": {
            "1": 0.15492957746478872,
            "2": 0.49056603773584906,
            "3": 0.7063492063492064
        },
        "bertscore": {
            "precision": 0.91232,
            "recall": 0.90308,
            "f1": 0.90636
        },
        "bleurt": 0.18625,
        "meteor": 0.3526999678184627,
        "nubia": {
            "semantic_relation": 3.88639,
            "contradiction": 30.15938,
            "irrelevancy": 24.10958,
            "logical_agreement": 45.73104,
            "grammar_ref": 4.70766,
            "grammar_hyp": 4.23793,
            "nubia_score": 0.63827
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_290": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.72,
        "total_length": 198,
        "mean_pred_length": 15.23076923076923,
        "std_pred_length": 4.7741909689793545,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.6161616161616161,
        "vocab_size-1": 122,
        "unique-1": 99,
        "entropy-1": 6.36493973230451,
        "distinct-2": 0.9297297297297298,
        "vocab_size-2": 172,
        "unique-2": 165,
        "entropy-2": 7.345401071561887,
        "cond_entropy-2": 0.8017683963077956,
        "distinct-3": 0.9883720930232558,
        "vocab_size-3": 170,
        "unique-3": 168,
        "entropy-3": 7.4030089407485775,
        "cond_entropy-3": 0.07166452649140655,
        "total_length-nopunct": 167,
        "mean_pred_length-nopunct": 12.846153846153847,
        "std_pred_length-nopunct": 3.7794210758579223,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7005988023952096,
        "vocab_size-1-nopunct": 117,
        "unique-1-nopunct": 96,
        "entropy-1-nopunct": 6.522934196894066,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 143,
        "unique-2-nopunct": 138,
        "entropy-2-nopunct": 7.06934256695098,
        "cond_entropy-2-nopunct": 0.6060837677357049,
        "distinct-3-nopunct": 0.9929078014184397,
        "vocab_size-3-nopunct": 140,
        "unique-3-nopunct": 139,
        "entropy-3-nopunct": 7.125366955235652,
        "cond_entropy-3-nopunct": 0.07422844260152847,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.696863248566955,
        "bleu": 50.50552,
        "rouge1": {
            "precision": 0.77043,
            "recall": 0.74672,
            "fmeasure": 0.75493
        },
        "rouge2": {
            "precision": 0.58423,
            "recall": 0.57666,
            "fmeasure": 0.57855
        },
        "rougeL": {
            "precision": 0.65576,
            "recall": 0.63546,
            "fmeasure": 0.64305
        },
        "rougeLsum": {
            "precision": 0.65576,
            "recall": 0.63546,
            "fmeasure": 0.64305
        },
        "local_recall": {
            "1": 0.1388888888888889,
            "2": 0.11764705882352941,
            "3": 0.803921568627451
        },
        "bertscore": {
            "precision": 0.9405,
            "recall": 0.93359,
            "f1": 0.93661
        },
        "bleurt": 0.48124,
        "meteor": 0.43037048800572947,
        "nubia": {
            "semantic_relation": 4.39267,
            "contradiction": 1.2758,
            "irrelevancy": 25.49951,
            "logical_agreement": 73.22469,
            "grammar_ref": 4.72277,
            "grammar_hyp": 4.61672,
            "nubia_score": 0.80712
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_244": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.76,
        "total_length": 116,
        "mean_pred_length": 19.333333333333332,
        "std_pred_length": 8.055363982396383,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 36,
        "distinct-1": 0.6896551724137931,
        "vocab_size-1": 80,
        "unique-1": 66,
        "entropy-1": 5.980278085402345,
        "distinct-2": 0.9636363636363636,
        "vocab_size-2": 106,
        "unique-2": 102,
        "entropy-2": 6.708632440797395,
        "cond_entropy-2": 0.6352311049770718,
        "distinct-3": 0.9903846153846154,
        "vocab_size-3": 103,
        "unique-3": 102,
        "entropy-3": 6.681208948910331,
        "cond_entropy-3": -0.023227687691259796,
        "total_length-nopunct": 100,
        "mean_pred_length-nopunct": 16.666666666666668,
        "std_pred_length-nopunct": 5.21749194749951,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.76,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 66,
        "entropy-1-nopunct": 5.960818564536754,
        "distinct-2-nopunct": 0.9787234042553191,
        "vocab_size-2-nopunct": 92,
        "unique-2-nopunct": 90,
        "entropy-2-nopunct": 6.512035660188261,
        "cond_entropy-2-nopunct": 0.5841769440709768,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 88,
        "unique-3-nopunct": 88,
        "entropy-3-nopunct": 6.459431618637305,
        "cond_entropy-3-nopunct": -0.049702687585794866,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.325550500223542,
        "bleu": 48.05851,
        "rouge1": {
            "precision": 0.79278,
            "recall": 0.81905,
            "fmeasure": 0.7987
        },
        "rouge2": {
            "precision": 0.55108,
            "recall": 0.57599,
            "fmeasure": 0.55965
        },
        "rougeL": {
            "precision": 0.68724,
            "recall": 0.72964,
            "fmeasure": 0.69887
        },
        "rougeLsum": {
            "precision": 0.68724,
            "recall": 0.72964,
            "fmeasure": 0.69887
        },
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.3333333333333333,
            "3": 0.8194444444444444
        },
        "bertscore": {
            "precision": 0.92338,
            "recall": 0.94009,
            "f1": 0.92968
        },
        "bleurt": 0.02302,
        "meteor": 0.41802558789947347,
        "nubia": {
            "semantic_relation": 4.51378,
            "contradiction": 12.48083,
            "irrelevancy": 33.57079,
            "logical_agreement": 53.94838,
            "grammar_ref": 4.74863,
            "grammar_hyp": 5.25494,
            "nubia_score": 0.68103
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_318": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 73,
        "mean_pred_length": 14.6,
        "std_pred_length": 5.122499389946279,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 22,
        "distinct-1": 0.7534246575342466,
        "vocab_size-1": 55,
        "unique-1": 46,
        "entropy-1": 5.5600414294137614,
        "distinct-2": 0.9852941176470589,
        "vocab_size-2": 67,
        "unique-2": 66,
        "entropy-2": 6.058051076544463,
        "cond_entropy-2": 0.37358722320267945,
        "distinct-3": 1.0,
        "vocab_size-3": 63,
        "unique-3": 63,
        "entropy-3": 5.97727992349992,
        "cond_entropy-3": -0.07843688600439111,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 12.8,
        "std_pred_length-nopunct": 4.749736834815167,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.828125,
        "vocab_size-1-nopunct": 53,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.58805425036562,
        "distinct-2-nopunct": 0.9830508474576272,
        "vocab_size-2-nopunct": 58,
        "unique-2-nopunct": 57,
        "entropy-2-nopunct": 5.848744744277091,
        "cond_entropy-2-nopunct": 0.2956011506601509,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 54,
        "unique-3-nopunct": 54,
        "entropy-3-nopunct": 5.7548875021634665,
        "cond_entropy-3-nopunct": -0.09071851016133553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.079353966635953,
        "bleu": 46.3038,
        "rouge1": {
            "precision": 0.87442,
            "recall": 0.73058,
            "fmeasure": 0.79239
        },
        "rouge2": {
            "precision": 0.72384,
            "recall": 0.57972,
            "fmeasure": 0.6413
        },
        "rougeL": {
            "precision": 0.74754,
            "recall": 0.62118,
            "fmeasure": 0.67503
        },
        "rougeLsum": {
            "precision": 0.74754,
            "recall": 0.62118,
            "fmeasure": 0.67503
        },
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.4,
            "3": 0.8035714285714286
        },
        "bertscore": {
            "precision": 0.95384,
            "recall": 0.92769,
            "f1": 0.94046
        },
        "bleurt": 0.3752,
        "meteor": 0.42395886187953374,
        "nubia": {
            "semantic_relation": 4.56266,
            "contradiction": 2.08055,
            "irrelevancy": 14.42503,
            "logical_agreement": 83.49441,
            "grammar_ref": 4.74509,
            "grammar_hyp": 4.88962,
            "nubia_score": 0.83384
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_348": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 12.0,
        "std_pred_length": 4.96655480858378,
        "median_pred_length": 9.0,
        "min_pred_length": 8,
        "max_pred_length": 19,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 32,
        "unique-1": 29,
        "entropy-1": 4.92673368193777,
        "distinct-2": 1.0,
        "vocab_size-2": 33,
        "unique-2": 33,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": -0.004318760871737897,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.13750352374993471,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 10.666666666666666,
        "std_pred_length-nopunct": 4.496912521077347,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": -0.004087970389669248,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.15754127698647996,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.798154730051143,
        "bleu": 42.88895,
        "rouge1": {
            "precision": 0.68575,
            "recall": 0.58846,
            "fmeasure": 0.62504
        },
        "rouge2": {
            "precision": 0.41865,
            "recall": 0.39352,
            "fmeasure": 0.40064
        },
        "rougeL": {
            "precision": 0.58158,
            "recall": 0.5127,
            "fmeasure": 0.53732
        },
        "rougeLsum": {
            "precision": 0.58158,
            "recall": 0.5127,
            "fmeasure": 0.53732
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.5,
            "3": 0.9333333333333333
        },
        "bertscore": {
            "precision": 0.89102,
            "recall": 0.88043,
            "f1": 0.88533
        },
        "bleurt": -0.00731,
        "meteor": 0.35535969071610785,
        "nubia": {
            "semantic_relation": 3.34007,
            "contradiction": 16.43139,
            "irrelevancy": 35.18704,
            "logical_agreement": 48.38157,
            "grammar_ref": 4.86076,
            "grammar_hyp": 5.71188,
            "nubia_score": 0.41013
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_375": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.7,
        "msttr-100_nopunct": NaN,
        "total_length": 110,
        "mean_pred_length": 13.75,
        "std_pred_length": 3.418698582794336,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 20,
        "distinct-1": 0.6909090909090909,
        "vocab_size-1": 76,
        "unique-1": 56,
        "entropy-1": 6.00068423187987,
        "distinct-2": 0.9215686274509803,
        "vocab_size-2": 94,
        "unique-2": 87,
        "entropy-2": 6.508161739009113,
        "cond_entropy-2": 0.3334128390229515,
        "distinct-3": 0.9574468085106383,
        "vocab_size-3": 90,
        "unique-3": 86,
        "entropy-3": 6.4694824686989,
        "cond_entropy-3": -0.024699389207012642,
        "total_length-nopunct": 96,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.122498999199199,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 72,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 6.002938511336501,
        "distinct-2-nopunct": 0.9318181818181818,
        "vocab_size-2-nopunct": 82,
        "unique-2-nopunct": 77,
        "entropy-2-nopunct": 6.31448971520363,
        "cond_entropy-2-nopunct": 0.34173520290209275,
        "distinct-3-nopunct": 0.9625,
        "vocab_size-3-nopunct": 77,
        "unique-3-nopunct": 74,
        "entropy-3-nopunct": 6.246928094887356,
        "cond_entropy-3-nopunct": -0.05306742997289166,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.3814022698408825,
        "bleu": 48.62672,
        "rouge1": {
            "precision": 0.83993,
            "recall": 0.77499,
            "fmeasure": 0.78744
        },
        "rouge2": {
            "precision": 0.60174,
            "recall": 0.55975,
            "fmeasure": 0.56546
        },
        "rougeL": {
            "precision": 0.76748,
            "recall": 0.71259,
            "fmeasure": 0.72095
        },
        "rougeLsum": {
            "precision": 0.76748,
            "recall": 0.71259,
            "fmeasure": 0.72095
        },
        "local_recall": {
            "1": 0.2702702702702703,
            "2": 0.6666666666666666,
            "3": 0.8333333333333334
        },
        "bertscore": {
            "precision": 0.94436,
            "recall": 0.93374,
            "f1": 0.93548
        },
        "bleurt": 0.36596,
        "meteor": 0.4176385166965863,
        "nubia": {
            "semantic_relation": 4.34076,
            "contradiction": 6.03152,
            "irrelevancy": 9.26758,
            "logical_agreement": 84.7009,
            "grammar_ref": 5.34109,
            "grammar_hyp": 5.1482,
            "nubia_score": 0.75911
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_291": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.017856925246208095,
        "bleu": 4.97827,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.32099,
            "fmeasure": 0.44522
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.13846,
            "fmeasure": 0.19507
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.22046,
            "fmeasure": 0.30514
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.22046,
            "fmeasure": 0.30514
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.14285714285714285,
            "3": 0.3888888888888889
        },
        "bertscore": {
            "precision": 0.84004,
            "recall": 0.7715,
            "f1": 0.80431
        },
        "bleurt": -0.77368,
        "meteor": 0.16914738517935843,
        "nubia": {
            "semantic_relation": 2.43848,
            "contradiction": 0.40179,
            "irrelevancy": 99.51727,
            "logical_agreement": 0.08095,
            "grammar_ref": 3.87789,
            "grammar_hyp": 5.04779,
            "nubia_score": 0.10855
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_320": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.685,
        "msttr-100_nopunct": 0.76,
        "total_length": 223,
        "mean_pred_length": 15.928571428571429,
        "std_pred_length": 6.088212096388581,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 33,
        "distinct-1": 0.5964125560538116,
        "vocab_size-1": 133,
        "unique-1": 106,
        "entropy-1": 6.470994159943183,
        "distinct-2": 0.9186602870813397,
        "vocab_size-2": 192,
        "unique-2": 178,
        "entropy-2": 7.53149842632892,
        "cond_entropy-2": 0.8945507326578426,
        "distinct-3": 0.9743589743589743,
        "vocab_size-3": 190,
        "unique-3": 185,
        "entropy-3": 7.556048262467595,
        "cond_entropy-3": 0.03717573296187388,
        "total_length-nopunct": 196,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.916079783099616,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6581632653061225,
        "vocab_size-1-nopunct": 129,
        "unique-1-nopunct": 104,
        "entropy-1-nopunct": 6.567708500742337,
        "distinct-2-nopunct": 0.9175824175824175,
        "vocab_size-2-nopunct": 167,
        "unique-2-nopunct": 155,
        "entropy-2-nopunct": 7.327822730846166,
        "cond_entropy-2-nopunct": 0.8154606933263301,
        "distinct-3-nopunct": 0.9761904761904762,
        "vocab_size-3-nopunct": 164,
        "unique-3-nopunct": 160,
        "entropy-3-nopunct": 7.344698375159742,
        "cond_entropy-3-nopunct": 0.01996854152151339,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.607879515955795,
        "bleu": 63.91051,
        "rouge1": {
            "precision": 0.86917,
            "recall": 0.82891,
            "fmeasure": 0.84427
        },
        "rouge2": {
            "precision": 0.71966,
            "recall": 0.69638,
            "fmeasure": 0.70528
        },
        "rougeL": {
            "precision": 0.77819,
            "recall": 0.75333,
            "fmeasure": 0.76246
        },
        "rougeLsum": {
            "precision": 0.77819,
            "recall": 0.75333,
            "fmeasure": 0.76246
        },
        "local_recall": {
            "1": 0.24242424242424243,
            "2": 0.5454545454545454,
            "3": 0.8785714285714286
        },
        "bertscore": {
            "precision": 0.96596,
            "recall": 0.95179,
            "f1": 0.95606
        },
        "bleurt": 0.50669,
        "meteor": 0.46324921673621106,
        "nubia": {
            "semantic_relation": 4.49678,
            "contradiction": 8.14667,
            "irrelevancy": 18.06655,
            "logical_agreement": 73.78678,
            "grammar_ref": 4.83858,
            "grammar_hyp": 4.77632,
            "nubia_score": 0.81182
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_376": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.82,
        "total_length": 117,
        "mean_pred_length": 14.625,
        "std_pred_length": 3.4977671449083054,
        "median_pred_length": 14.5,
        "min_pred_length": 10,
        "max_pred_length": 19,
        "distinct-1": 0.7521367521367521,
        "vocab_size-1": 88,
        "unique-1": 76,
        "entropy-1": 6.170250164042921,
        "distinct-2": 0.9908256880733946,
        "vocab_size-2": 108,
        "unique-2": 107,
        "entropy-2": 6.749835700923703,
        "cond_entropy-2": 0.3983150454384432,
        "distinct-3": 1.0,
        "vocab_size-3": 101,
        "unique-3": 101,
        "entropy-3": 6.658211482751779,
        "cond_entropy-3": -0.0901708618271116,
        "total_length-nopunct": 103,
        "mean_pred_length-nopunct": 12.875,
        "std_pred_length-nopunct": 3.4072532926097527,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8155339805825242,
        "vocab_size-1-nopunct": 84,
        "unique-1-nopunct": 74,
        "entropy-1-nopunct": 6.214372464240604,
        "distinct-2-nopunct": 0.9894736842105263,
        "vocab_size-2-nopunct": 94,
        "unique-2-nopunct": 93,
        "entropy-2-nopunct": 6.548802976752,
        "cond_entropy-2-nopunct": 0.3741886651802624,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 87,
        "unique-3-nopunct": 87,
        "entropy-3-nopunct": 6.442943495848723,
        "cond_entropy-3-nopunct": -0.1039236067350933,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.02890208047988,
        "bleu": 44.10341,
        "rouge1": {
            "precision": 0.72271,
            "recall": 0.68897,
            "fmeasure": 0.69262
        },
        "rouge2": {
            "precision": 0.48453,
            "recall": 0.47583,
            "fmeasure": 0.47335
        },
        "rougeL": {
            "precision": 0.65327,
            "recall": 0.62579,
            "fmeasure": 0.62895
        },
        "rougeLsum": {
            "precision": 0.65327,
            "recall": 0.62579,
            "fmeasure": 0.62895
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.6,
            "3": 0.6986301369863014
        },
        "bertscore": {
            "precision": 0.91964,
            "recall": 0.91784,
            "f1": 0.91778
        },
        "bleurt": 0.28116,
        "meteor": 0.3930507828193165,
        "nubia": {
            "semantic_relation": 4.24285,
            "contradiction": 2.93967,
            "irrelevancy": 28.5365,
            "logical_agreement": 68.52383,
            "grammar_ref": 4.8199,
            "grammar_hyp": 5.09077,
            "nubia_score": 0.69363
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_261": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 1.0,
        "median_pred_length": 15.0,
        "min_pred_length": 14,
        "max_pred_length": 16,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 26,
        "unique-1": 23,
        "entropy-1": 4.61506101220307,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": 0.09992727290341258,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.546593564294937,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673076,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8477212702405565,
        "bleu": 23.57832,
        "rouge1": {
            "precision": 0.58617,
            "recall": 0.61367,
            "fmeasure": 0.58557
        },
        "rouge2": {
            "precision": 0.33889,
            "recall": 0.36966,
            "fmeasure": 0.33906
        },
        "rougeL": {
            "precision": 0.56061,
            "recall": 0.5978,
            "fmeasure": 0.5537
        },
        "rougeLsum": {
            "precision": 0.56061,
            "recall": 0.5978,
            "fmeasure": 0.5537
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.7058823529411765
        },
        "bertscore": {
            "precision": 0.89526,
            "recall": 0.89745,
            "f1": 0.89501
        },
        "bleurt": 0.29279,
        "meteor": 0.3734966631895361,
        "nubia": {
            "semantic_relation": 4.03841,
            "contradiction": 4.55343,
            "irrelevancy": 59.31699,
            "logical_agreement": 36.12958,
            "grammar_ref": 5.15434,
            "grammar_hyp": 4.72206,
            "nubia_score": 0.63554
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_322": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 2.0,
        "median_pred_length": 16.0,
        "min_pred_length": 14,
        "max_pred_length": 18,
        "distinct-1": 0.90625,
        "vocab_size-1": 29,
        "unique-1": 26,
        "entropy-1": 4.8125,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.04022392894185192,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9642857142857143,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.735926350629034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": -0.02999212699343526,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0815569349708025,
        "bleu": 19.82425,
        "rouge1": {
            "precision": 0.65351,
            "recall": 0.61751,
            "fmeasure": 0.63482
        },
        "rouge2": {
            "precision": 0.39394,
            "recall": 0.37208,
            "fmeasure": 0.38256
        },
        "rougeL": {
            "precision": 0.46053,
            "recall": 0.43779,
            "fmeasure": 0.44873
        },
        "rougeLsum": {
            "precision": 0.46053,
            "recall": 0.43779,
            "fmeasure": 0.44873
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5862068965517241
        },
        "bertscore": {
            "precision": 0.90665,
            "recall": 0.91358,
            "f1": 0.91001
        },
        "bleurt": 0.3243,
        "meteor": 0.3243454901411182,
        "nubia": {
            "semantic_relation": 4.25743,
            "contradiction": 18.48707,
            "irrelevancy": 59.45571,
            "logical_agreement": 22.05721,
            "grammar_ref": 4.49155,
            "grammar_hyp": 4.27538,
            "nubia_score": 0.75471
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_350": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.82,
        "msttr-100_nopunct": NaN,
        "total_length": 109,
        "mean_pred_length": 15.571428571428571,
        "std_pred_length": 6.0676458804558004,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.8073394495412844,
        "vocab_size-1": 88,
        "unique-1": 78,
        "entropy-1": 6.258773430874802,
        "distinct-2": 1.0,
        "vocab_size-2": 102,
        "unique-2": 102,
        "entropy-2": 6.6724253419715,
        "cond_entropy-2": 0.25594986994875735,
        "distinct-3": 1.0,
        "vocab_size-3": 95,
        "unique-3": 95,
        "entropy-3": 6.569855608330948,
        "cond_entropy-3": -0.10256973364054793,
        "total_length-nopunct": 96,
        "mean_pred_length-nopunct": 13.714285714285714,
        "std_pred_length-nopunct": 5.2020404160094635,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8854166666666666,
        "vocab_size-1-nopunct": 85,
        "unique-1-nopunct": 77,
        "entropy-1-nopunct": 6.332205599611885,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 89,
        "unique-2-nopunct": 89,
        "entropy-2-nopunct": 6.47573343096641,
        "cond_entropy-2-nopunct": 0.16340758762153798,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 82,
        "unique-3-nopunct": 82,
        "entropy-3-nopunct": 6.357552004618087,
        "cond_entropy-3-nopunct": -0.11818142634831395,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.31231693173857,
        "bleu": 53.74383,
        "rouge1": {
            "precision": 0.82011,
            "recall": 0.80962,
            "fmeasure": 0.80612
        },
        "rouge2": {
            "precision": 0.63316,
            "recall": 0.63916,
            "fmeasure": 0.63118
        },
        "rougeL": {
            "precision": 0.72983,
            "recall": 0.74076,
            "fmeasure": 0.73093
        },
        "rougeLsum": {
            "precision": 0.72983,
            "recall": 0.74076,
            "fmeasure": 0.73093
        },
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.4375,
            "3": 0.810126582278481
        },
        "bertscore": {
            "precision": 0.94613,
            "recall": 0.94133,
            "f1": 0.94279
        },
        "bleurt": 0.3321,
        "meteor": 0.42104791547230036,
        "nubia": {
            "semantic_relation": 4.37118,
            "contradiction": 1.30031,
            "irrelevancy": 28.94078,
            "logical_agreement": 69.75891,
            "grammar_ref": 4.69419,
            "grammar_hyp": 4.90477,
            "nubia_score": 0.73889
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_264": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.7,
        "msttr-100_nopunct": NaN,
        "total_length": 108,
        "mean_pred_length": 18.0,
        "std_pred_length": 7.3484692283495345,
        "median_pred_length": 20.5,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.6944444444444444,
        "vocab_size-1": 75,
        "unique-1": 63,
        "entropy-1": 5.901748932835522,
        "distinct-2": 0.9705882352941176,
        "vocab_size-2": 99,
        "unique-2": 96,
        "entropy-2": 6.613601812559735,
        "cond_entropy-2": 0.6099808837598969,
        "distinct-3": 1.0,
        "vocab_size-3": 96,
        "unique-3": 96,
        "entropy-3": 6.5849625007211605,
        "cond_entropy-3": -0.045796174583672584,
        "total_length-nopunct": 87,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 5.188127472091127,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8045977011494253,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 5.924329524828451,
        "distinct-2-nopunct": 0.9876543209876543,
        "vocab_size-2-nopunct": 80,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.315158644859922,
        "cond_entropy-2-nopunct": 0.42924496973668397,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 75,
        "unique-3-nopunct": 75,
        "entropy-3-nopunct": 6.228818690495891,
        "cond_entropy-3-nopunct": -0.08436464572207733,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.206783407210003,
        "bleu": 42.28164,
        "rouge1": {
            "precision": 0.85219,
            "recall": 0.64447,
            "fmeasure": 0.72061
        },
        "rouge2": {
            "precision": 0.54969,
            "recall": 0.41901,
            "fmeasure": 0.46625
        },
        "rougeL": {
            "precision": 0.75353,
            "recall": 0.56813,
            "fmeasure": 0.63686
        },
        "rougeLsum": {
            "precision": 0.75353,
            "recall": 0.56813,
            "fmeasure": 0.63686
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.2553191489361702,
            "3": 0.8225806451612904
        },
        "bertscore": {
            "precision": 0.93674,
            "recall": 0.89406,
            "f1": 0.9142
        },
        "bleurt": 0.12066,
        "meteor": 0.36120531330731437,
        "nubia": {
            "semantic_relation": 3.89941,
            "contradiction": 3.08689,
            "irrelevancy": 26.17295,
            "logical_agreement": 70.74017,
            "grammar_ref": 4.79112,
            "grammar_hyp": 4.67098,
            "nubia_score": 0.64144
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_292": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 3.5,
        "median_pred_length": 15.5,
        "min_pred_length": 12,
        "max_pred_length": 19,
        "distinct-1": 0.8387096774193549,
        "vocab_size-1": 26,
        "unique-1": 22,
        "entropy-1": 4.607264455478377,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.20567735722909258,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.363713275750188,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.24930976183687525,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.990474333082978,
        "bleu": 32.03456,
        "rouge1": {
            "precision": 0.68449,
            "recall": 0.7576,
            "fmeasure": 0.7133
        },
        "rouge2": {
            "precision": 0.32292,
            "recall": 0.34755,
            "fmeasure": 0.33159
        },
        "rougeL": {
            "precision": 0.40463,
            "recall": 0.41752,
            "fmeasure": 0.40822
        },
        "rougeLsum": {
            "precision": 0.40463,
            "recall": 0.41752,
            "fmeasure": 0.40822
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.2,
            "3": 0.6842105263157895
        },
        "bertscore": {
            "precision": 0.90743,
            "recall": 0.91738,
            "f1": 0.9087
        },
        "bleurt": 0.13516,
        "meteor": 0.3810440995539408,
        "nubia": {
            "semantic_relation": 4.19236,
            "contradiction": 14.5794,
            "irrelevancy": 43.92541,
            "logical_agreement": 41.49519,
            "grammar_ref": 4.97036,
            "grammar_hyp": 4.62631,
            "nubia_score": 0.68883
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_378": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.69,
        "total_length": 131,
        "mean_pred_length": 18.714285714285715,
        "std_pred_length": 5.547567953985029,
        "median_pred_length": 20.0,
        "min_pred_length": 12,
        "max_pred_length": 26,
        "distinct-1": 0.6030534351145038,
        "vocab_size-1": 79,
        "unique-1": 57,
        "entropy-1": 5.871934620480802,
        "distinct-2": 0.8870967741935484,
        "vocab_size-2": 110,
        "unique-2": 96,
        "entropy-2": 6.728389858773959,
        "cond_entropy-2": 0.7635434174302127,
        "distinct-3": 0.9316239316239316,
        "vocab_size-3": 109,
        "unique-3": 101,
        "entropy-3": 6.733612582831249,
        "cond_entropy-3": 0.018732511760631513,
        "total_length-nopunct": 122,
        "mean_pred_length-nopunct": 17.428571428571427,
        "std_pred_length-nopunct": 5.576920370269467,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6229508196721312,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 55,
        "entropy-1-nopunct": 5.8446431288414376,
        "distinct-2-nopunct": 0.8782608695652174,
        "vocab_size-2-nopunct": 101,
        "unique-2-nopunct": 87,
        "entropy-2-nopunct": 6.602011790074823,
        "cond_entropy-2-nopunct": 0.8147830913294708,
        "distinct-3-nopunct": 0.9259259259259259,
        "vocab_size-3-nopunct": 100,
        "unique-3-nopunct": 92,
        "entropy-3-nopunct": 6.60673935401531,
        "cond_entropy-3-nopunct": 0.020508562330204642,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.59620910925408,
        "bleu": 46.92276,
        "rouge1": {
            "precision": 0.78801,
            "recall": 0.7579,
            "fmeasure": 0.76148
        },
        "rouge2": {
            "precision": 0.60138,
            "recall": 0.58208,
            "fmeasure": 0.5835
        },
        "rougeL": {
            "precision": 0.68892,
            "recall": 0.70233,
            "fmeasure": 0.68465
        },
        "rougeLsum": {
            "precision": 0.68892,
            "recall": 0.70233,
            "fmeasure": 0.68465
        },
        "local_recall": {
            "1": 0.19230769230769232,
            "2": 0.42857142857142855,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.94206,
            "recall": 0.93169,
            "f1": 0.9354
        },
        "bleurt": 0.24601,
        "meteor": 0.41380276067469207,
        "nubia": {
            "semantic_relation": 4.09138,
            "contradiction": 28.02422,
            "irrelevancy": 30.4419,
            "logical_agreement": 41.53389,
            "grammar_ref": 4.76973,
            "grammar_hyp": 4.45038,
            "nubia_score": 0.72264
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_324": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.83,
        "total_length": 205,
        "mean_pred_length": 18.636363636363637,
        "std_pred_length": 8.741465731814994,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 42,
        "distinct-1": 0.6536585365853659,
        "vocab_size-1": 134,
        "unique-1": 110,
        "entropy-1": 6.6023209283328255,
        "distinct-2": 0.9329896907216495,
        "vocab_size-2": 181,
        "unique-2": 171,
        "entropy-2": 7.451691772588327,
        "cond_entropy-2": 0.7142935405332875,
        "distinct-3": 0.9781420765027322,
        "vocab_size-3": 179,
        "unique-3": 175,
        "entropy-3": 7.471983991289503,
        "cond_entropy-3": 0.029201681901086657,
        "total_length-nopunct": 182,
        "mean_pred_length-nopunct": 16.545454545454547,
        "std_pred_length-nopunct": 8.752803565026117,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.7142857142857143,
        "vocab_size-1-nopunct": 130,
        "unique-1-nopunct": 110,
        "entropy-1-nopunct": 6.641067539777163,
        "distinct-2-nopunct": 0.9239766081871345,
        "vocab_size-2-nopunct": 158,
        "unique-2-nopunct": 148,
        "entropy-2-nopunct": 7.249695278031136,
        "cond_entropy-2-nopunct": 0.6492653733646082,
        "distinct-3-nopunct": 0.975,
        "vocab_size-3-nopunct": 156,
        "unique-3-nopunct": 152,
        "entropy-3-nopunct": 7.271928094887367,
        "cond_entropy-3-nopunct": 0.02754362688998606,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.5300386188453805,
        "bleu": 39.87417,
        "rouge1": {
            "precision": 0.75153,
            "recall": 0.73865,
            "fmeasure": 0.73725
        },
        "rouge2": {
            "precision": 0.52607,
            "recall": 0.50384,
            "fmeasure": 0.50821
        },
        "rougeL": {
            "precision": 0.66033,
            "recall": 0.65325,
            "fmeasure": 0.65083
        },
        "rougeLsum": {
            "precision": 0.66033,
            "recall": 0.65325,
            "fmeasure": 0.65083
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.44,
            "3": 0.75177304964539
        },
        "bertscore": {
            "precision": 0.92438,
            "recall": 0.92749,
            "f1": 0.92543
        },
        "bleurt": 0.28537,
        "meteor": 0.4041510558496617,
        "nubia": {
            "semantic_relation": 4.4885,
            "contradiction": 0.86544,
            "irrelevancy": 36.64444,
            "logical_agreement": 62.49012,
            "grammar_ref": 4.70918,
            "grammar_hyp": 4.76037,
            "nubia_score": 0.81101
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_351": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 10,
        "unique-1": 8,
        "entropy-1": 3.2516291673878226,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.2381054815525046,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.0957952550009344,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.262496476250065,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.306664886548115,
        "bleu": 27.09199,
        "rouge1": {
            "precision": 0.75758,
            "recall": 0.93939,
            "fmeasure": 0.83413
        },
        "rouge2": {
            "precision": 0.63333,
            "recall": 0.80476,
            "fmeasure": 0.70392
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.82576,
            "fmeasure": 0.73365
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.82576,
            "fmeasure": 0.73365
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.94572,
            "recall": 0.94055,
            "f1": 0.94053
        },
        "bleurt": 0.67831,
        "meteor": 0.4912092865802179,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20045,
            "irrelevancy": 22.76085,
            "logical_agreement": 77.0387,
            "grammar_ref": 3.38649,
            "grammar_hyp": 3.17028,
            "nubia_score": 0.92133
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_352": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 10.5,
        "median_pred_length": 18.5,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.8378378378378378,
        "vocab_size-1": 31,
        "unique-1": 26,
        "entropy-1": 4.8647266763812915,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.22711215137782997,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.08488889758651327,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 10.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.8529411764705882,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.7711426205984715,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.24862739319226906,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.09310940439148141,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9392122146743693,
        "bleu": 25.96945,
        "rouge1": {
            "precision": 0.55665,
            "recall": 0.49411,
            "fmeasure": 0.51596
        },
        "rouge2": {
            "precision": 0.27976,
            "recall": 0.28682,
            "fmeasure": 0.28323
        },
        "rougeL": {
            "precision": 0.47044,
            "recall": 0.40771,
            "fmeasure": 0.4297
        },
        "rougeLsum": {
            "precision": 0.47044,
            "recall": 0.40771,
            "fmeasure": 0.4297
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6176470588235294
        },
        "bertscore": {
            "precision": 0.88213,
            "recall": 0.87589,
            "f1": 0.87899
        },
        "bleurt": -0.04804,
        "meteor": 0.3098323552633541,
        "nubia": {
            "semantic_relation": 3.15572,
            "contradiction": 2.76631,
            "irrelevancy": 32.06166,
            "logical_agreement": 65.17203,
            "grammar_ref": 4.82994,
            "grammar_hyp": 5.0108,
            "nubia_score": 0.48671
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-base (Baseline)/e2e_nlg_test",
        "N": 389,
        "msttr-100": 0.2984,
        "msttr-100_nopunct": 0.30116,
        "total_length": 7528,
        "mean_pred_length": 19.35218508997429,
        "std_pred_length": 5.537149750463491,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 35,
        "distinct-1": 0.027497343251859725,
        "vocab_size-1": 207,
        "unique-1": 29,
        "entropy-1": 6.084098518275446,
        "distinct-2": 0.07830228323294579,
        "vocab_size-2": 559,
        "unique-2": 119,
        "entropy-2": 7.750504952647091,
        "cond_entropy-2": 1.5652092243426017,
        "distinct-3": 0.12459259259259259,
        "vocab_size-3": 841,
        "unique-3": 219,
        "entropy-3": 8.603672537173498,
        "cond_entropy-3": 0.867980755092484,
        "total_length-nopunct": 6950,
        "mean_pred_length-nopunct": 17.866323907455012,
        "std_pred_length-nopunct": 5.1153905693089525,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.029496402877697843,
        "vocab_size-1-nopunct": 205,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 6.1461323178314196,
        "distinct-2-nopunct": 0.08062795305593659,
        "vocab_size-2-nopunct": 529,
        "unique-2-nopunct": 112,
        "entropy-2-nopunct": 7.69731168957001,
        "cond_entropy-2-nopunct": 1.620291710953133,
        "distinct-3-nopunct": 0.12929358392741414,
        "vocab_size-3-nopunct": 798,
        "unique-3-nopunct": 206,
        "entropy-3-nopunct": 8.585644634262875,
        "cond_entropy-3-nopunct": 0.877077190493853,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 4.276436473600283,
        "bleu": 27.11561,
        "rouge1": {
            "precision": 0.64924,
            "recall": 0.67886,
            "fmeasure": 0.64697
        },
        "rouge2": {
            "precision": 0.38722,
            "recall": 0.40504,
            "fmeasure": 0.38513
        },
        "rougeL": {
            "precision": 0.50539,
            "recall": 0.52533,
            "fmeasure": 0.50205
        },
        "rougeLsum": {
            "precision": 0.50539,
            "recall": 0.52533,
            "fmeasure": 0.50205
        },
        "local_recall": {
            "1": 0.6565295169946332
        },
        "bertscore": {
            "precision": 0.89985,
            "recall": 0.89768,
            "f1": 0.89833
        },
        "bleurt": 0.07471,
        "meteor": 0.3376304961643059,
        "nubia": {
            "semantic_relation": 4.01093,
            "contradiction": 2.63425,
            "irrelevancy": 43.85574,
            "logical_agreement": 53.51001,
            "grammar_ref": 5.31197,
            "grammar_hyp": 4.73517,
            "nubia_score": 0.70737
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_294": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.8,
        "total_length": 120,
        "mean_pred_length": 15.0,
        "std_pred_length": 3.427827300200522,
        "median_pred_length": 14.5,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.725,
        "vocab_size-1": 87,
        "unique-1": 74,
        "entropy-1": 6.104900337629134,
        "distinct-2": 0.9732142857142857,
        "vocab_size-2": 109,
        "unique-2": 106,
        "entropy-2": 6.753783493486163,
        "cond_entropy-2": 0.49188245999843916,
        "distinct-3": 1.0,
        "vocab_size-3": 104,
        "unique-3": 104,
        "entropy-3": 6.7004397181411,
        "cond_entropy-3": -0.04922289622420451,
        "total_length-nopunct": 105,
        "mean_pred_length-nopunct": 13.125,
        "std_pred_length-nopunct": 2.9341736485763756,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7904761904761904,
        "vocab_size-1-nopunct": 83,
        "unique-1-nopunct": 74,
        "entropy-1-nopunct": 6.109636532376934,
        "distinct-2-nopunct": 0.979381443298969,
        "vocab_size-2-nopunct": 95,
        "unique-2-nopunct": 93,
        "entropy-2-nopunct": 6.5586757287850785,
        "cond_entropy-2-nopunct": 0.4989038549886751,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 89,
        "unique-3-nopunct": 89,
        "entropy-3-nopunct": 6.47573343096641,
        "cond_entropy-3-nopunct": -0.0792355909960109,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.610255617398237,
        "bleu": 30.73828,
        "rouge1": {
            "precision": 0.7437,
            "recall": 0.64657,
            "fmeasure": 0.67206
        },
        "rouge2": {
            "precision": 0.51935,
            "recall": 0.45159,
            "fmeasure": 0.47314
        },
        "rougeL": {
            "precision": 0.67322,
            "recall": 0.58995,
            "fmeasure": 0.61358
        },
        "rougeLsum": {
            "precision": 0.67322,
            "recall": 0.58995,
            "fmeasure": 0.61358
        },
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.3958333333333333,
            "3": 0.6901408450704225
        },
        "bertscore": {
            "precision": 0.92182,
            "recall": 0.90083,
            "f1": 0.90776
        },
        "bleurt": 0.25785,
        "meteor": 0.3178148752766896,
        "nubia": {
            "semantic_relation": 4.03814,
            "contradiction": 20.83988,
            "irrelevancy": 37.65696,
            "logical_agreement": 41.50316,
            "grammar_ref": 4.54831,
            "grammar_hyp": 4.37286,
            "nubia_score": 0.68354
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_354": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1221860348123966,
        "bleu": 58.59059,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.97545,
            "recall": 0.97545,
            "f1": 0.97545
        },
        "bleurt": 0.76706,
        "meteor": 0.4076949933266327,
        "nubia": {
            "semantic_relation": 4.90953,
            "contradiction": 0.355,
            "irrelevancy": 0.51033,
            "logical_agreement": 99.13468,
            "grammar_ref": 5.11392,
            "grammar_hyp": 4.76303,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_380": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.8,
        "total_length": 145,
        "mean_pred_length": 18.125,
        "std_pred_length": 6.9899481400079075,
        "median_pred_length": 14.5,
        "min_pred_length": 12,
        "max_pred_length": 33,
        "distinct-1": 0.7103448275862069,
        "vocab_size-1": 103,
        "unique-1": 90,
        "entropy-1": 6.332365276293699,
        "distinct-2": 0.9635036496350365,
        "vocab_size-2": 132,
        "unique-2": 129,
        "entropy-2": 7.010440842084599,
        "cond_entropy-2": 0.5523846935994681,
        "distinct-3": 1.0,
        "vocab_size-3": 129,
        "unique-3": 129,
        "entropy-3": 7.011227255423235,
        "cond_entropy-3": 0.006218428276680688,
        "total_length-nopunct": 122,
        "mean_pred_length-nopunct": 15.25,
        "std_pred_length-nopunct": 4.380353866983808,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7950819672131147,
        "vocab_size-1-nopunct": 97,
        "unique-1-nopunct": 88,
        "entropy-1-nopunct": 6.346440513668273,
        "distinct-2-nopunct": 0.956140350877193,
        "vocab_size-2-nopunct": 109,
        "unique-2-nopunct": 106,
        "entropy-2-nopunct": 6.7276268562700166,
        "cond_entropy-2-nopunct": 0.42218962848908625,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 106,
        "unique-3-nopunct": 106,
        "entropy-3-nopunct": 6.727920454563184,
        "cond_entropy-3-nopunct": 0.008237987568268872,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.760678859485756,
        "bleu": 54.44029,
        "rouge1": {
            "precision": 0.86846,
            "recall": 0.86716,
            "fmeasure": 0.86208
        },
        "rouge2": {
            "precision": 0.70136,
            "recall": 0.69796,
            "fmeasure": 0.6948
        },
        "rougeL": {
            "precision": 0.73253,
            "recall": 0.71532,
            "fmeasure": 0.71826
        },
        "rougeLsum": {
            "precision": 0.73253,
            "recall": 0.71532,
            "fmeasure": 0.71826
        },
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.375,
            "3": 0.9375
        },
        "bertscore": {
            "precision": 0.9447,
            "recall": 0.95225,
            "f1": 0.94765
        },
        "bleurt": 0.36785,
        "meteor": 0.47321092862702174,
        "nubia": {
            "semantic_relation": 4.32566,
            "contradiction": 7.05597,
            "irrelevancy": 9.43167,
            "logical_agreement": 83.51237,
            "grammar_ref": 4.87577,
            "grammar_hyp": 5.09595,
            "nubia_score": 0.7336
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_295": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.8,
        "msttr-100_nopunct": 0.81,
        "total_length": 182,
        "mean_pred_length": 16.545454545454547,
        "std_pred_length": 7.901250031869369,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.6428571428571429,
        "vocab_size-1": 117,
        "unique-1": 92,
        "entropy-1": 6.468381655123025,
        "distinct-2": 0.9064327485380117,
        "vocab_size-2": 155,
        "unique-2": 141,
        "entropy-2": 7.219022105529165,
        "cond_entropy-2": 0.5949667371361124,
        "distinct-3": 0.94375,
        "vocab_size-3": 151,
        "unique-3": 142,
        "entropy-3": 7.209428094887366,
        "cond_entropy-3": 0.004075580001464392,
        "total_length-nopunct": 158,
        "mean_pred_length-nopunct": 14.363636363636363,
        "std_pred_length-nopunct": 6.785984584189645,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6962025316455697,
        "vocab_size-1-nopunct": 110,
        "unique-1-nopunct": 89,
        "entropy-1-nopunct": 6.470808340111058,
        "distinct-2-nopunct": 0.891156462585034,
        "vocab_size-2-nopunct": 131,
        "unique-2-nopunct": 117,
        "entropy-2-nopunct": 6.968379827829554,
        "cond_entropy-2-nopunct": 0.5462973141724375,
        "distinct-3-nopunct": 0.9338235294117647,
        "vocab_size-3-nopunct": 127,
        "unique-3-nopunct": 118,
        "entropy-3-nopunct": 6.955109900073857,
        "cond_entropy-3-nopunct": -0.0019153859389660654,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.4824106122178,
        "bleu": 66.77084,
        "rouge1": {
            "precision": 0.87741,
            "recall": 0.89318,
            "fmeasure": 0.88224
        },
        "rouge2": {
            "precision": 0.75066,
            "recall": 0.75566,
            "fmeasure": 0.7506
        },
        "rougeL": {
            "precision": 0.80652,
            "recall": 0.81856,
            "fmeasure": 0.80971
        },
        "rougeLsum": {
            "precision": 0.80652,
            "recall": 0.81856,
            "fmeasure": 0.80971
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.375,
            "3": 0.9349593495934959
        },
        "bertscore": {
            "precision": 0.96735,
            "recall": 0.96782,
            "f1": 0.96734
        },
        "bleurt": 0.59001,
        "meteor": 0.4995717439511453,
        "nubia": {
            "semantic_relation": 4.77395,
            "contradiction": 0.60348,
            "irrelevancy": 12.50191,
            "logical_agreement": 86.89461,
            "grammar_ref": 4.24853,
            "grammar_hyp": 4.14028,
            "nubia_score": 0.93865
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_296": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.67,
        "msttr-100_nopunct": NaN,
        "total_length": 112,
        "mean_pred_length": 16.0,
        "std_pred_length": 6.391959234627741,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.625,
        "vocab_size-1": 70,
        "unique-1": 55,
        "entropy-1": 5.7286942082140735,
        "distinct-2": 0.9428571428571428,
        "vocab_size-2": 99,
        "unique-2": 94,
        "entropy-2": 6.59277039859789,
        "cond_entropy-2": 0.7488299098362137,
        "distinct-3": 0.9795918367346939,
        "vocab_size-3": 96,
        "unique-3": 94,
        "entropy-3": 6.573893517584606,
        "cond_entropy-3": -0.010200086794144015,
        "total_length-nopunct": 96,
        "mean_pred_length-nopunct": 13.714285714285714,
        "std_pred_length-nopunct": 5.443588252359328,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6770833333333334,
        "vocab_size-1-nopunct": 65,
        "unique-1-nopunct": 53,
        "entropy-1-nopunct": 5.672995052579131,
        "distinct-2-nopunct": 0.9325842696629213,
        "vocab_size-2-nopunct": 83,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.3324200882454695,
        "cond_entropy-2-nopunct": 0.7021082900064777,
        "distinct-3-nopunct": 0.975609756097561,
        "vocab_size-3-nopunct": 80,
        "unique-3-nopunct": 78,
        "entropy-3-nopunct": 6.30877151681321,
        "cond_entropy-3-nopunct": -0.030743316574627474,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7527744314548315,
        "bleu": 22.66664,
        "rouge1": {
            "precision": 0.62152,
            "recall": 0.62516,
            "fmeasure": 0.61801
        },
        "rouge2": {
            "precision": 0.34969,
            "recall": 0.35727,
            "fmeasure": 0.35051
        },
        "rougeL": {
            "precision": 0.53596,
            "recall": 0.5386,
            "fmeasure": 0.53286
        },
        "rougeLsum": {
            "precision": 0.53596,
            "recall": 0.5386,
            "fmeasure": 0.53286
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.47058823529411764,
            "3": 0.6231884057971014
        },
        "bertscore": {
            "precision": 0.89068,
            "recall": 0.89254,
            "f1": 0.89006
        },
        "bleurt": 0.07926,
        "meteor": 0.34523375010037727,
        "nubia": {
            "semantic_relation": 3.90079,
            "contradiction": 1.68389,
            "irrelevancy": 64.94775,
            "logical_agreement": 33.36835,
            "grammar_ref": 4.06397,
            "grammar_hyp": 4.1917,
            "nubia_score": 0.69563
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_382": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.04978793508525296,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1986532337201607,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.99035,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20913,
            "irrelevancy": 0.49456,
            "logical_agreement": 99.29631,
            "grammar_ref": 4.69221,
            "grammar_hyp": 4.84818,
            "nubia_score": 0.99204
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_297": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 1.5,
        "median_pred_length": 12.5,
        "min_pred_length": 11,
        "max_pred_length": 14,
        "distinct-1": 0.84,
        "vocab_size-1": 21,
        "unique-1": 18,
        "entropy-1": 4.293660689688184,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.17339652724591728,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.070656113151927,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.2111304855155341,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.639887954233972,
        "bleu": 44.55844,
        "rouge1": {
            "precision": 0.61218,
            "recall": 0.81944,
            "fmeasure": 0.68214
        },
        "rouge2": {
            "precision": 0.49242,
            "recall": 0.63636,
            "fmeasure": 0.53972
        },
        "rougeL": {
            "precision": 0.61218,
            "recall": 0.81944,
            "fmeasure": 0.68214
        },
        "rougeLsum": {
            "precision": 0.61218,
            "recall": 0.81944,
            "fmeasure": 0.68214
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "bertscore": {
            "precision": 0.88479,
            "recall": 0.91629,
            "f1": 0.90003
        },
        "bleurt": 0.28636,
        "meteor": 0.4403973759786798,
        "nubia": {
            "semantic_relation": 3.91019,
            "contradiction": 1.57566,
            "irrelevancy": 46.92407,
            "logical_agreement": 51.50026,
            "grammar_ref": 3.61093,
            "grammar_hyp": 3.88935,
            "nubia_score": 0.62749
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_299": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9319229794768673,
        "bleu": 70.71068,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.90909,
            "fmeasure": 0.90909
        },
        "rouge2": {
            "precision": 0.76667,
            "recall": 0.79259,
            "fmeasure": 0.77895
        },
        "rougeL": {
            "precision": 0.87879,
            "recall": 0.90606,
            "fmeasure": 0.89177
        },
        "rougeLsum": {
            "precision": 0.87879,
            "recall": 0.90606,
            "fmeasure": 0.89177
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.99214,
            "recall": 0.99214,
            "f1": 0.99214
        },
        "bleurt": 0.62958,
        "meteor": 0.5023397349274512,
        "nubia": {
            "semantic_relation": 3.63608,
            "contradiction": 98.85014,
            "irrelevancy": 0.58732,
            "logical_agreement": 0.56253,
            "grammar_ref": 3.16175,
            "grammar_hyp": 3.05889,
            "nubia_score": 0.64216
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_325": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 59,
        "mean_pred_length": 11.8,
        "std_pred_length": 3.4871191548325386,
        "median_pred_length": 12.0,
        "min_pred_length": 8,
        "max_pred_length": 18,
        "distinct-1": 0.7966101694915254,
        "vocab_size-1": 47,
        "unique-1": 40,
        "entropy-1": 5.38078473623579,
        "distinct-2": 0.9814814814814815,
        "vocab_size-2": 53,
        "unique-2": 52,
        "entropy-2": 5.717850465126429,
        "cond_entropy-2": 0.16854074909792344,
        "distinct-3": 1.0,
        "vocab_size-3": 49,
        "unique-3": 49,
        "entropy-3": 5.614709844115208,
        "cond_entropy-3": -0.09936133151764791,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 2.449489742783178,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.86,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.323856189774728,
        "distinct-2-nopunct": 0.9777777777777777,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.447408651885229,
        "cond_entropy-2-nopunct": 0.1591080176660609,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.11992500144231241,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.1195754019671735,
        "bleu": 63.31288,
        "rouge1": {
            "precision": 0.84724,
            "recall": 0.85654,
            "fmeasure": 0.84876
        },
        "rouge2": {
            "precision": 0.63729,
            "recall": 0.63476,
            "fmeasure": 0.63385
        },
        "rougeL": {
            "precision": 0.80406,
            "recall": 0.81492,
            "fmeasure": 0.80647
        },
        "rougeLsum": {
            "precision": 0.80406,
            "recall": 0.81492,
            "fmeasure": 0.80647
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.875,
            "3": 0.868421052631579
        },
        "bertscore": {
            "precision": 0.95756,
            "recall": 0.96489,
            "f1": 0.96113
        },
        "bleurt": 0.48478,
        "meteor": 0.4955368800916532,
        "nubia": {
            "semantic_relation": 4.62104,
            "contradiction": 3.17667,
            "irrelevancy": 13.93892,
            "logical_agreement": 82.88441,
            "grammar_ref": 5.12632,
            "grammar_hyp": 4.9961,
            "nubia_score": 0.86691
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_328": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 95,
        "mean_pred_length": 15.833333333333334,
        "std_pred_length": 4.297932319409209,
        "median_pred_length": 16.5,
        "min_pred_length": 9,
        "max_pred_length": 22,
        "distinct-1": 0.7894736842105263,
        "vocab_size-1": 75,
        "unique-1": 68,
        "entropy-1": 5.985814098274484,
        "distinct-2": 1.0,
        "vocab_size-2": 89,
        "unique-2": 89,
        "entropy-2": 6.47573343096641,
        "cond_entropy-2": 0.3550257827594619,
        "distinct-3": 1.0,
        "vocab_size-3": 83,
        "unique-3": 83,
        "entropy-3": 6.375039431346932,
        "cond_entropy-3": -0.10069399961947309,
        "total_length-nopunct": 85,
        "mean_pred_length-nopunct": 14.166666666666666,
        "std_pred_length-nopunct": 4.13991411612474,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 64,
        "entropy-1-nopunct": 5.939106601419623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 79,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.303780748177105,
        "cond_entropy-2-nopunct": 0.40039194433101033,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 73,
        "entropy-3-nopunct": 6.189824558880028,
        "cond_entropy-3-nopunct": -0.11395618929708562,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.254417041515023,
        "bleu": 61.24246,
        "rouge1": {
            "precision": 0.77471,
            "recall": 0.72946,
            "fmeasure": 0.74943
        },
        "rouge2": {
            "precision": 0.60062,
            "recall": 0.57801,
            "fmeasure": 0.58845
        },
        "rougeL": {
            "precision": 0.72858,
            "recall": 0.68704,
            "fmeasure": 0.70527
        },
        "rougeLsum": {
            "precision": 0.72858,
            "recall": 0.68704,
            "fmeasure": 0.70527
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.45454545454545453,
            "3": 0.7971014492753623
        },
        "bertscore": {
            "precision": 0.94783,
            "recall": 0.93121,
            "f1": 0.93899
        },
        "bleurt": 0.33786,
        "meteor": 0.4594151974830934,
        "nubia": {
            "semantic_relation": 4.37997,
            "contradiction": 0.58497,
            "irrelevancy": 32.84451,
            "logical_agreement": 66.57052,
            "grammar_ref": 4.71157,
            "grammar_hyp": 4.87684,
            "nubia_score": 0.78452
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_300": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.7325,
        "msttr-100_nopunct": 0.79667,
        "total_length": 473,
        "mean_pred_length": 16.310344827586206,
        "std_pred_length": 4.955689508210093,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.5539112050739958,
        "vocab_size-1": 262,
        "unique-1": 201,
        "entropy-1": 7.311926457120266,
        "distinct-2": 0.8986486486486487,
        "vocab_size-2": 399,
        "unique-2": 369,
        "entropy-2": 8.557572362980592,
        "cond_entropy-2": 1.0311366236793866,
        "distinct-3": 0.9686746987951808,
        "vocab_size-3": 402,
        "unique-3": 391,
        "entropy-3": 8.630678911766065,
        "cond_entropy-3": 0.052284106841814004,
        "total_length-nopunct": 398,
        "mean_pred_length-nopunct": 13.724137931034482,
        "std_pred_length-nopunct": 3.8942623729341728,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6407035175879398,
        "vocab_size-1-nopunct": 255,
        "unique-1-nopunct": 199,
        "entropy-1-nopunct": 7.5262258375151365,
        "distinct-2-nopunct": 0.9214092140921409,
        "vocab_size-2-nopunct": 340,
        "unique-2-nopunct": 319,
        "entropy-2-nopunct": 8.350284382794092,
        "cond_entropy-2-nopunct": 0.8833043845877784,
        "distinct-3-nopunct": 0.9823529411764705,
        "vocab_size-3-nopunct": 334,
        "unique-3-nopunct": 328,
        "entropy-3-nopunct": 8.37409681849062,
        "cond_entropy-3-nopunct": 0.03892592415158288,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.1034238246291315,
        "bleu": 56.59604,
        "rouge1": {
            "precision": 0.86792,
            "recall": 0.81372,
            "fmeasure": 0.82893
        },
        "rouge2": {
            "precision": 0.6878,
            "recall": 0.6482,
            "fmeasure": 0.66001
        },
        "rougeL": {
            "precision": 0.78837,
            "recall": 0.73116,
            "fmeasure": 0.74946
        },
        "rougeLsum": {
            "precision": 0.78837,
            "recall": 0.73116,
            "fmeasure": 0.74946
        },
        "local_recall": {
            "1": 0.18421052631578946,
            "2": 0.417910447761194,
            "3": 0.8259587020648967
        },
        "bertscore": {
            "precision": 0.95452,
            "recall": 0.94357,
            "f1": 0.94809
        },
        "bleurt": 0.45514,
        "meteor": 0.4390015611036327,
        "nubia": {
            "semantic_relation": 4.33309,
            "contradiction": 8.55947,
            "irrelevancy": 15.56476,
            "logical_agreement": 75.87577,
            "grammar_ref": 4.69712,
            "grammar_hyp": 4.7222,
            "nubia_score": 0.78816
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_329": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.8,
        "total_length": 126,
        "mean_pred_length": 21.0,
        "std_pred_length": 5.916079783099616,
        "median_pred_length": 23.0,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.7380952380952381,
        "vocab_size-1": 93,
        "unique-1": 80,
        "entropy-1": 6.241668440213728,
        "distinct-2": 0.9916666666666667,
        "vocab_size-2": 119,
        "unique-2": 118,
        "entropy-2": 6.890223928941869,
        "cond_entropy-2": 0.5449683167895599,
        "distinct-3": 1.0,
        "vocab_size-3": 114,
        "unique-3": 114,
        "entropy-3": 6.832890014164754,
        "cond_entropy-3": -0.056456721794653844,
        "total_length-nopunct": 114,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 5.354126134736337,
        "median_pred_length-nopunct": 20.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7982456140350878,
        "vocab_size-1-nopunct": 91,
        "unique-1-nopunct": 80,
        "entropy-1-nopunct": 6.294066137276851,
        "distinct-2-nopunct": 0.9907407407407407,
        "vocab_size-2-nopunct": 107,
        "unique-2-nopunct": 106,
        "entropy-2-nopunct": 6.736368983644939,
        "cond_entropy-2-nopunct": 0.4722375061952149,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 102,
        "unique-3-nopunct": 102,
        "entropy-3-nopunct": 6.6724253419715,
        "cond_entropy-3-nopunct": -0.06285431705471797,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.682935150766044,
        "bleu": 32.87183,
        "rouge1": {
            "precision": 0.5701,
            "recall": 0.62324,
            "fmeasure": 0.58424
        },
        "rouge2": {
            "precision": 0.35213,
            "recall": 0.35592,
            "fmeasure": 0.34486
        },
        "rougeL": {
            "precision": 0.42997,
            "recall": 0.46297,
            "fmeasure": 0.4377
        },
        "rougeLsum": {
            "precision": 0.42997,
            "recall": 0.46297,
            "fmeasure": 0.4377
        },
        "local_recall": {
            "1": 0.3584905660377358,
            "2": 0.5405405405405406,
            "3": 0.7380952380952381
        },
        "bertscore": {
            "precision": 0.89335,
            "recall": 0.9142,
            "f1": 0.90337
        },
        "bleurt": 0.03422,
        "meteor": 0.37022037689819015,
        "nubia": {
            "semantic_relation": 3.81985,
            "contradiction": 13.59759,
            "irrelevancy": 53.87528,
            "logical_agreement": 32.52712,
            "grammar_ref": 4.80564,
            "grammar_hyp": 4.52009,
            "nubia_score": 0.63269
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_384": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.78,
        "msttr-100_nopunct": 0.81,
        "total_length": 147,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 6.236095644623235,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 105,
        "unique-1": 93,
        "entropy-1": 6.298317108245305,
        "distinct-2": 0.9855072463768116,
        "vocab_size-2": 136,
        "unique-2": 135,
        "entropy-2": 7.074068750240751,
        "cond_entropy-2": 0.6278014399399232,
        "distinct-3": 1.0,
        "vocab_size-3": 129,
        "unique-3": 129,
        "entropy-3": 7.011227255423235,
        "cond_entropy-3": -0.06043760831488812,
        "total_length-nopunct": 134,
        "mean_pred_length-nopunct": 14.88888888888889,
        "std_pred_length-nopunct": 6.099989880582579,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7686567164179104,
        "vocab_size-1-nopunct": 103,
        "unique-1-nopunct": 93,
        "entropy-1-nopunct": 6.349895945936107,
        "distinct-2-nopunct": 0.984,
        "vocab_size-2-nopunct": 123,
        "unique-2-nopunct": 122,
        "entropy-2-nopunct": 6.927745184644788,
        "cond_entropy-2-nopunct": 0.6294151523142387,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 116,
        "unique-3-nopunct": 116,
        "entropy-3-nopunct": 6.857980995127556,
        "cond_entropy-3-nopunct": -0.06681288003310551,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.387608491761635,
        "bleu": 29.50456,
        "rouge1": {
            "precision": 0.62335,
            "recall": 0.5815,
            "fmeasure": 0.59251
        },
        "rouge2": {
            "precision": 0.33087,
            "recall": 0.32036,
            "fmeasure": 0.31905
        },
        "rougeL": {
            "precision": 0.54765,
            "recall": 0.51065,
            "fmeasure": 0.52061
        },
        "rougeLsum": {
            "precision": 0.54765,
            "recall": 0.51065,
            "fmeasure": 0.52061
        },
        "local_recall": {
            "1": 0.18867924528301888,
            "2": 0.30612244897959184,
            "3": 0.7323943661971831
        },
        "bertscore": {
            "precision": 0.8904,
            "recall": 0.88237,
            "f1": 0.88341
        },
        "bleurt": 0.01628,
        "meteor": 0.3179716830943365,
        "nubia": {
            "semantic_relation": 3.6141,
            "contradiction": 3.87676,
            "irrelevancy": 49.81851,
            "logical_agreement": 46.30473,
            "grammar_ref": 4.84583,
            "grammar_hyp": 4.87955,
            "nubia_score": 0.56445
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_355": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 70,
        "mean_pred_length": 17.5,
        "std_pred_length": 4.031128874149275,
        "median_pred_length": 17.5,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.7857142857142857,
        "vocab_size-1": 55,
        "unique-1": 45,
        "entropy-1": 5.632784624056919,
        "distinct-2": 0.9545454545454546,
        "vocab_size-2": 63,
        "unique-2": 60,
        "entropy-2": 5.9534850284493706,
        "cond_entropy-2": 0.22957909487050895,
        "distinct-3": 0.9838709677419355,
        "vocab_size-3": 61,
        "unique-3": 60,
        "entropy-3": 5.921938245870743,
        "cond_entropy-3": -0.02568167993932006,
        "total_length-nopunct": 62,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 3.0413812651491097,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8548387096774194,
        "vocab_size-1-nopunct": 53,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.651698124868108,
        "distinct-2-nopunct": 0.9482758620689655,
        "vocab_size-2-nopunct": 55,
        "unique-2-nopunct": 52,
        "entropy-2-nopunct": 5.754532719265501,
        "cond_entropy-2-nopunct": 0.1064551589159293,
        "distinct-3-nopunct": 0.9814814814814815,
        "vocab_size-3-nopunct": 53,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 5.717850465126429,
        "cond_entropy-3-nopunct": -0.029019418890029278,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.915521232866949,
        "bleu": 70.15507,
        "rouge1": {
            "precision": 0.84413,
            "recall": 0.87792,
            "fmeasure": 0.85617
        },
        "rouge2": {
            "precision": 0.70602,
            "recall": 0.72475,
            "fmeasure": 0.71229
        },
        "rougeL": {
            "precision": 0.75574,
            "recall": 0.82372,
            "fmeasure": 0.78089
        },
        "rougeLsum": {
            "precision": 0.75574,
            "recall": 0.82372,
            "fmeasure": 0.78089
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.6666666666666666,
            "3": 0.9574468085106383
        },
        "bertscore": {
            "precision": 0.97331,
            "recall": 0.97017,
            "f1": 0.97012
        },
        "bleurt": 0.61805,
        "meteor": 0.5259426311685924,
        "nubia": {
            "semantic_relation": 4.79314,
            "contradiction": 1.86099,
            "irrelevancy": 24.63026,
            "logical_agreement": 73.50875,
            "grammar_ref": 4.25492,
            "grammar_hyp": 4.21875,
            "nubia_score": 0.91293
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_385": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 2.5,
        "median_pred_length": 17.5,
        "min_pred_length": 15,
        "max_pred_length": 20,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 25,
        "unique-1": 18,
        "entropy-1": 4.454721860532484,
        "distinct-2": 0.9393939393939394,
        "vocab_size-2": 31,
        "unique-2": 29,
        "entropy-2": 4.923181998146335,
        "cond_entropy-2": 0.44873657133581435,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": 0.03883444909293795,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7586206896551724,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.250752013250441,
        "distinct-2-nopunct": 0.9629629629629629,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.680813428089397,
        "cond_entropy-2-nopunct": 0.4750413394224453,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.03103131238874396,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.090020433380662,
        "bleu": 67.98531,
        "rouge1": {
            "precision": 0.83977,
            "recall": 0.87315,
            "fmeasure": 0.85543
        },
        "rouge2": {
            "precision": 0.67989,
            "recall": 0.69972,
            "fmeasure": 0.68918
        },
        "rougeL": {
            "precision": 0.83977,
            "recall": 0.87315,
            "fmeasure": 0.85543
        },
        "rougeLsum": {
            "precision": 0.83977,
            "recall": 0.87315,
            "fmeasure": 0.85543
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.6666666666666666,
            "3": 0.8947368421052632
        },
        "bertscore": {
            "precision": 0.97407,
            "recall": 0.98427,
            "f1": 0.97912
        },
        "bleurt": 0.71816,
        "meteor": 0.5692607104513367,
        "nubia": {
            "semantic_relation": 4.53562,
            "contradiction": 7.71077,
            "irrelevancy": 24.0774,
            "logical_agreement": 68.21183,
            "grammar_ref": 3.86772,
            "grammar_hyp": 3.81859,
            "nubia_score": 0.83603
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_265": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.74,
        "msttr-100_nopunct": NaN,
        "total_length": 101,
        "mean_pred_length": 16.833333333333332,
        "std_pred_length": 6.094168432927407,
        "median_pred_length": 14.5,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.7326732673267327,
        "vocab_size-1": 74,
        "unique-1": 61,
        "entropy-1": 5.959901334108409,
        "distinct-2": 0.9894736842105263,
        "vocab_size-2": 94,
        "unique-2": 93,
        "entropy-2": 6.548802976752,
        "cond_entropy-2": 0.4697446519860363,
        "distinct-3": 1.0,
        "vocab_size-3": 89,
        "unique-3": 89,
        "entropy-3": 6.47573343096641,
        "cond_entropy-3": -0.07165026725219041,
        "total_length-nopunct": 86,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 5.467073155618908,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8023255813953488,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 5.926037429020077,
        "distinct-2-nopunct": 0.9875,
        "vocab_size-2-nopunct": 79,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.296928094887356,
        "cond_entropy-2-nopunct": 0.4084077152934377,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 74,
        "unique-3-nopunct": 74,
        "entropy-3-nopunct": 6.2094533656289554,
        "cond_entropy-3-nopunct": -0.08544770223138574,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.509119404332447,
        "bleu": 60.22543,
        "rouge1": {
            "precision": 0.83723,
            "recall": 0.69379,
            "fmeasure": 0.7483
        },
        "rouge2": {
            "precision": 0.65851,
            "recall": 0.54888,
            "fmeasure": 0.58923
        },
        "rougeL": {
            "precision": 0.78453,
            "recall": 0.6447,
            "fmeasure": 0.69747
        },
        "rougeLsum": {
            "precision": 0.78453,
            "recall": 0.6447,
            "fmeasure": 0.69747
        },
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.16666666666666666,
            "3": 0.7692307692307693
        },
        "bertscore": {
            "precision": 0.94115,
            "recall": 0.91738,
            "f1": 0.92829
        },
        "bleurt": 0.21371,
        "meteor": 0.40721293467567415,
        "nubia": {
            "semantic_relation": 4.0556,
            "contradiction": 16.64926,
            "irrelevancy": 19.93359,
            "logical_agreement": 63.41715,
            "grammar_ref": 4.20009,
            "grammar_hyp": 4.24981,
            "nubia_score": 0.69392
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_301": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 0.5,
        "median_pred_length": 15.5,
        "min_pred_length": 15,
        "max_pred_length": 16,
        "distinct-1": 0.8709677419354839,
        "vocab_size-1": 27,
        "unique-1": 24,
        "entropy-1": 4.6717805845106355,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 28,
        "unique-2": 27,
        "entropy-2": 4.789015477886192,
        "cond_entropy-2": 0.06774632274633388,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.02901941889002935,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.896551724137931,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.625053839880556,
        "distinct-2-nopunct": 0.9629629629629629,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.6808134280893965,
        "cond_entropy-2-nopunct": 0.0730134515604695,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.031031312388743938,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.942597123095626,
        "bleu": 67.63818,
        "rouge1": {
            "precision": 0.75972,
            "recall": 0.80096,
            "fmeasure": 0.77149
        },
        "rouge2": {
            "precision": 0.67619,
            "recall": 0.65,
            "fmeasure": 0.65793
        },
        "rougeL": {
            "precision": 0.72847,
            "recall": 0.76272,
            "fmeasure": 0.73779
        },
        "rougeLsum": {
            "precision": 0.72847,
            "recall": 0.76272,
            "fmeasure": 0.73779
        },
        "local_recall": {
            "1": 0.375,
            "2": 0.5,
            "3": 0.8888888888888888
        },
        "bertscore": {
            "precision": 0.94665,
            "recall": 0.95589,
            "f1": 0.94643
        },
        "bleurt": 0.34254,
        "meteor": 0.5006906498880889,
        "nubia": {
            "semantic_relation": 4.09868,
            "contradiction": 42.81902,
            "irrelevancy": 14.41539,
            "logical_agreement": 42.7656,
            "grammar_ref": 4.37461,
            "grammar_hyp": 4.21449,
            "nubia_score": 0.6789
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_266": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.72,
        "msttr-100_nopunct": NaN,
        "total_length": 107,
        "mean_pred_length": 13.375,
        "std_pred_length": 1.9324531042175384,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.7289719626168224,
        "vocab_size-1": 78,
        "unique-1": 66,
        "entropy-1": 5.982950542861606,
        "distinct-2": 0.9191919191919192,
        "vocab_size-2": 91,
        "unique-2": 85,
        "entropy-2": 6.452490205894499,
        "cond_entropy-2": 0.2884096786724349,
        "distinct-3": 0.945054945054945,
        "vocab_size-3": 86,
        "unique-3": 82,
        "entropy-3": 6.389609063251852,
        "cond_entropy-3": -0.06931046886812793,
        "total_length-nopunct": 96,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.0615528128088303,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7708333333333334,
        "vocab_size-1-nopunct": 74,
        "unique-1-nopunct": 63,
        "entropy-1-nopunct": 5.989532714692721,
        "distinct-2-nopunct": 0.9204545454545454,
        "vocab_size-2-nopunct": 81,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 6.2831841754063165,
        "cond_entropy-2-nopunct": 0.32505416853435964,
        "distinct-3-nopunct": 0.95,
        "vocab_size-3-nopunct": 76,
        "unique-3-nopunct": 73,
        "entropy-3-nopunct": 6.212492001110313,
        "cond_entropy-3-nopunct": -0.07806742997289173,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.225663043103951,
        "bleu": 44.48916,
        "rouge1": {
            "precision": 0.76583,
            "recall": 0.71148,
            "fmeasure": 0.7307
        },
        "rouge2": {
            "precision": 0.51532,
            "recall": 0.49547,
            "fmeasure": 0.50018
        },
        "rougeL": {
            "precision": 0.63276,
            "recall": 0.609,
            "fmeasure": 0.61543
        },
        "rougeLsum": {
            "precision": 0.63276,
            "recall": 0.609,
            "fmeasure": 0.61543
        },
        "local_recall": {
            "1": 0.22857142857142856,
            "2": 0.3142857142857143,
            "3": 0.8405797101449275
        },
        "bertscore": {
            "precision": 0.92313,
            "recall": 0.93526,
            "f1": 0.92888
        },
        "bleurt": 0.25427,
        "meteor": 0.4088646239077971,
        "nubia": {
            "semantic_relation": 4.23342,
            "contradiction": 23.46462,
            "irrelevancy": 17.31947,
            "logical_agreement": 59.21591,
            "grammar_ref": 4.49967,
            "grammar_hyp": 4.57574,
            "nubia_score": 0.73384
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_357": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 8,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 96,
        "mean_pred_length": 12.0,
        "std_pred_length": 1.8708286933869707,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 15,
        "distinct-1": 0.6354166666666666,
        "vocab_size-1": 61,
        "unique-1": 48,
        "entropy-1": 5.570109146916778,
        "distinct-2": 0.8068181818181818,
        "vocab_size-2": 71,
        "unique-2": 63,
        "entropy-2": 5.990292840056121,
        "cond_entropy-2": 0.23971581621246266,
        "distinct-3": 0.85,
        "vocab_size-3": 68,
        "unique-3": 62,
        "entropy-3": 5.965311532225098,
        "cond_entropy-3": 0.02193257002710835,
        "total_length-nopunct": 82,
        "mean_pred_length-nopunct": 10.25,
        "std_pred_length-nopunct": 2.1065374432940898,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.6829268292682927,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.520100364824705,
        "distinct-2-nopunct": 0.7972972972972973,
        "vocab_size-2-nopunct": 59,
        "unique-2-nopunct": 52,
        "entropy-2-nopunct": 5.715813838426509,
        "cond_entropy-2-nopunct": 0.28624878601189724,
        "distinct-3-nopunct": 0.8484848484848485,
        "vocab_size-3-nopunct": 56,
        "unique-3-nopunct": 51,
        "entropy-3-nopunct": 5.684175369194562,
        "cond_entropy-3-nopunct": 0.028196624974404824,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7260225362497628,
        "bleu": 46.4259,
        "rouge1": {
            "precision": 0.88075,
            "recall": 0.74846,
            "fmeasure": 0.78581
        },
        "rouge2": {
            "precision": 0.7293,
            "recall": 0.65426,
            "fmeasure": 0.66969
        },
        "rougeL": {
            "precision": 0.84405,
            "recall": 0.72088,
            "fmeasure": 0.75443
        },
        "rougeLsum": {
            "precision": 0.84405,
            "recall": 0.72088,
            "fmeasure": 0.75443
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.125,
            "3": 0.7021276595744681
        },
        "bertscore": {
            "precision": 0.95934,
            "recall": 0.91888,
            "f1": 0.937
        },
        "bleurt": 0.5412,
        "meteor": 0.37795665792464156,
        "nubia": {
            "semantic_relation": 4.36857,
            "contradiction": 5.01543,
            "irrelevancy": 13.67737,
            "logical_agreement": 81.3072,
            "grammar_ref": 4.5568,
            "grammar_hyp": 4.87256,
            "nubia_score": 0.77175
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_302": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7913310434313825,
        "bleu": 59.11603,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.74074,
            "fmeasure": 0.7395
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.55,
            "fmeasure": 0.55556
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.74074,
            "fmeasure": 0.7395
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.74074,
            "fmeasure": 0.7395
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.96286,
            "recall": 0.94809,
            "f1": 0.95542
        },
        "bleurt": 0.29208,
        "meteor": 0.5566661162140665,
        "nubia": {
            "semantic_relation": 4.0584,
            "contradiction": 0.41127,
            "irrelevancy": 35.16538,
            "logical_agreement": 64.42336,
            "grammar_ref": 4.09688,
            "grammar_hyp": 4.65525,
            "nubia_score": 0.68652
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_387": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 78,
        "mean_pred_length": 19.5,
        "std_pred_length": 6.726812023536855,
        "median_pred_length": 19.5,
        "min_pred_length": 10,
        "max_pred_length": 29,
        "distinct-1": 0.7051282051282052,
        "vocab_size-1": 55,
        "unique-1": 41,
        "entropy-1": 5.564060391855966,
        "distinct-2": 0.9864864864864865,
        "vocab_size-2": 73,
        "unique-2": 72,
        "entropy-2": 6.182426338601928,
        "cond_entropy-2": 0.5492492887463016,
        "distinct-3": 1.0,
        "vocab_size-3": 70,
        "unique-3": 70,
        "entropy-3": 6.129283016944973,
        "cond_entropy-3": -0.0515989201125547,
        "total_length-nopunct": 66,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 6.020797289396148,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7575757575757576,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.434323475320726,
        "distinct-2-nopunct": 0.9838709677419355,
        "vocab_size-2-nopunct": 61,
        "unique-2-nopunct": 60,
        "entropy-2-nopunct": 5.921938245870744,
        "cond_entropy-2-nopunct": 0.5269741669395571,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.85798099512757,
        "cond_entropy-3-nopunct": -0.0617325566386132,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.481332273107216,
        "bleu": 48.06886,
        "rouge1": {
            "precision": 0.71296,
            "recall": 0.79523,
            "fmeasure": 0.74483
        },
        "rouge2": {
            "precision": 0.46385,
            "recall": 0.52708,
            "fmeasure": 0.48793
        },
        "rougeL": {
            "precision": 0.62407,
            "recall": 0.69632,
            "fmeasure": 0.65257
        },
        "rougeLsum": {
            "precision": 0.62407,
            "recall": 0.69632,
            "fmeasure": 0.65257
        },
        "local_recall": {
            "1": 0.4074074074074074,
            "2": 0.4,
            "3": 0.8205128205128205
        },
        "bertscore": {
            "precision": 0.94487,
            "recall": 0.94574,
            "f1": 0.93893
        },
        "bleurt": 0.36719,
        "meteor": 0.425476328956356,
        "nubia": {
            "semantic_relation": 4.18691,
            "contradiction": 14.10954,
            "irrelevancy": 47.57942,
            "logical_agreement": 38.31103,
            "grammar_ref": 4.83213,
            "grammar_hyp": 4.2337,
            "nubia_score": 0.76685
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_410": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.69,
        "total_length": 156,
        "mean_pred_length": 15.6,
        "std_pred_length": 5.624944444170093,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.6217948717948718,
        "vocab_size-1": 97,
        "unique-1": 78,
        "entropy-1": 6.130830847461907,
        "distinct-2": 0.9041095890410958,
        "vocab_size-2": 132,
        "unique-2": 121,
        "entropy-2": 6.982532349931455,
        "cond_entropy-2": 0.7032524118197614,
        "distinct-3": 0.9779411764705882,
        "vocab_size-3": 133,
        "unique-3": 130,
        "entropy-3": 7.043345194191503,
        "cond_entropy-3": 0.0760549184474573,
        "total_length-nopunct": 137,
        "mean_pred_length-nopunct": 13.7,
        "std_pred_length-nopunct": 5.404627646748664,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6861313868613139,
        "vocab_size-1-nopunct": 94,
        "unique-1-nopunct": 77,
        "entropy-1-nopunct": 6.2009966596789035,
        "distinct-2-nopunct": 0.905511811023622,
        "vocab_size-2-nopunct": 115,
        "unique-2-nopunct": 106,
        "entropy-2-nopunct": 6.781876320579311,
        "cond_entropy-2-nopunct": 0.6436383556469993,
        "distinct-3-nopunct": 0.9743589743589743,
        "vocab_size-3-nopunct": 114,
        "unique-3-nopunct": 111,
        "entropy-3-nopunct": 6.819082668301332,
        "cond_entropy-3-nopunct": 0.054882276456455686,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.45921106032724,
        "bleu": 65.72842,
        "rouge1": {
            "precision": 0.90883,
            "recall": 0.84969,
            "fmeasure": 0.8693
        },
        "rouge2": {
            "precision": 0.73478,
            "recall": 0.69806,
            "fmeasure": 0.70932
        },
        "rougeL": {
            "precision": 0.78186,
            "recall": 0.74307,
            "fmeasure": 0.75571
        },
        "rougeLsum": {
            "precision": 0.78186,
            "recall": 0.74307,
            "fmeasure": 0.75571
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6153846153846154,
            "3": 0.8807339449541285
        },
        "bertscore": {
            "precision": 0.97044,
            "recall": 0.96537,
            "f1": 0.96698
        },
        "bleurt": 0.5596,
        "meteor": 0.48685415586068903,
        "nubia": {
            "semantic_relation": 4.45254,
            "contradiction": 4.16512,
            "irrelevancy": 19.16158,
            "logical_agreement": 76.6733,
            "grammar_ref": 4.86973,
            "grammar_hyp": 4.9942,
            "nubia_score": 0.79864
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_268": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.69,
        "total_length": 114,
        "mean_pred_length": 22.8,
        "std_pred_length": 10.979981785048645,
        "median_pred_length": 22.0,
        "min_pred_length": 8,
        "max_pred_length": 42,
        "distinct-1": 0.6491228070175439,
        "vocab_size-1": 74,
        "unique-1": 58,
        "entropy-1": 5.773811884174176,
        "distinct-2": 0.926605504587156,
        "vocab_size-2": 101,
        "unique-2": 95,
        "entropy-2": 6.607544187122541,
        "cond_entropy-2": 0.7758034054760488,
        "distinct-3": 1.0,
        "vocab_size-3": 104,
        "unique-3": 104,
        "entropy-3": 6.7004397181411,
        "cond_entropy-3": 0.10061861455961711,
        "total_length-nopunct": 101,
        "mean_pred_length-nopunct": 20.2,
        "std_pred_length-nopunct": 9.744742172063866,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.693069306930693,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.731325429878905,
        "distinct-2-nopunct": 0.9270833333333334,
        "vocab_size-2-nopunct": 89,
        "unique-2-nopunct": 84,
        "entropy-2-nopunct": 6.423402344426088,
        "cond_entropy-2-nopunct": 0.719518896467635,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 91,
        "unique-3-nopunct": 91,
        "entropy-3-nopunct": 6.507794640198703,
        "cond_entropy-3-nopunct": 0.09326922743717636,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.264510053014981,
        "bleu": 65.90539,
        "rouge1": {
            "precision": 0.83967,
            "recall": 0.84754,
            "fmeasure": 0.84155
        },
        "rouge2": {
            "precision": 0.67174,
            "recall": 0.68892,
            "fmeasure": 0.67835
        },
        "rougeL": {
            "precision": 0.75661,
            "recall": 0.78924,
            "fmeasure": 0.77127
        },
        "rougeLsum": {
            "precision": 0.75661,
            "recall": 0.78924,
            "fmeasure": 0.77127
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 0.9206349206349206
        },
        "bertscore": {
            "precision": 0.95885,
            "recall": 0.9604,
            "f1": 0.95654
        },
        "bleurt": 0.25526,
        "meteor": 0.502348554677475,
        "nubia": {
            "semantic_relation": 4.38923,
            "contradiction": 17.01104,
            "irrelevancy": 32.27527,
            "logical_agreement": 50.7137,
            "grammar_ref": 4.37077,
            "grammar_hyp": 4.2594,
            "nubia_score": 0.80501
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_413": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.470218226166574,
        "bleu": 30.89576,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.59028,
            "fmeasure": 0.69048
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.33929,
            "fmeasure": 0.40385
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.53472,
            "fmeasure": 0.62381
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.53472,
            "fmeasure": 0.62381
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.9462,
            "recall": 0.89276,
            "f1": 0.9187
        },
        "bleurt": 0.37093,
        "meteor": 0.3752796835792663,
        "nubia": {
            "semantic_relation": 3.81065,
            "contradiction": 0.40163,
            "irrelevancy": 0.51603,
            "logical_agreement": 99.08234,
            "grammar_ref": 6.12307,
            "grammar_hyp": 6.87381,
            "nubia_score": 0.60164
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_390": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.82,
        "total_length": 131,
        "mean_pred_length": 16.375,
        "std_pred_length": 5.8081300777444715,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.7022900763358778,
        "vocab_size-1": 92,
        "unique-1": 74,
        "entropy-1": 6.231944234669582,
        "distinct-2": 0.959349593495935,
        "vocab_size-2": 118,
        "unique-2": 113,
        "entropy-2": 6.8612136923311,
        "cond_entropy-2": 0.48627620672610655,
        "distinct-3": 0.9652173913043478,
        "vocab_size-3": 111,
        "unique-3": 107,
        "entropy-3": 6.775924833553082,
        "cond_entropy-3": -0.0796331500470382,
        "total_length-nopunct": 117,
        "mean_pred_length-nopunct": 14.625,
        "std_pred_length-nopunct": 4.794202227691277,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7606837606837606,
        "vocab_size-1-nopunct": 89,
        "unique-1-nopunct": 73,
        "entropy-1-nopunct": 6.277338412017119,
        "distinct-2-nopunct": 0.9541284403669725,
        "vocab_size-2-nopunct": 104,
        "unique-2-nopunct": 99,
        "entropy-2-nopunct": 6.676441205510862,
        "cond_entropy-2-nopunct": 0.44262766010411,
        "distinct-3-nopunct": 0.9603960396039604,
        "vocab_size-3-nopunct": 97,
        "unique-3-nopunct": 93,
        "entropy-3-nopunct": 6.579003561959703,
        "cond_entropy-3-nopunct": -0.09017086182711156,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.633266494603222,
        "bleu": 42.80162,
        "rouge1": {
            "precision": 0.82356,
            "recall": 0.7111,
            "fmeasure": 0.75884
        },
        "rouge2": {
            "precision": 0.56798,
            "recall": 0.49157,
            "fmeasure": 0.52399
        },
        "rougeL": {
            "precision": 0.64546,
            "recall": 0.55931,
            "fmeasure": 0.5961
        },
        "rougeLsum": {
            "precision": 0.64546,
            "recall": 0.55931,
            "fmeasure": 0.5961
        },
        "local_recall": {
            "1": 0.13043478260869565,
            "2": 0.34615384615384615,
            "3": 0.7692307692307693
        },
        "bertscore": {
            "precision": 0.94092,
            "recall": 0.92392,
            "f1": 0.93194
        },
        "bleurt": 0.33247,
        "meteor": 0.38246571271607144,
        "nubia": {
            "semantic_relation": 4.36213,
            "contradiction": 2.00618,
            "irrelevancy": 11.72357,
            "logical_agreement": 86.27025,
            "grammar_ref": 4.47406,
            "grammar_hyp": 4.81486,
            "nubia_score": 0.76613
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_414": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 1.0,
        "median_pred_length": 15.0,
        "min_pred_length": 14,
        "max_pred_length": 16,
        "distinct-1": 0.7666666666666667,
        "vocab_size-1": 23,
        "unique-1": 18,
        "entropy-1": 4.389898095464288,
        "distinct-2": 0.9642857142857143,
        "vocab_size-2": 27,
        "unique-2": 26,
        "entropy-2": 4.735926350629034,
        "cond_entropy-2": 0.31152771946076185,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.029992126993435266,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8076923076923077,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.257756064128516,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.501629167387823,
        "cond_entropy-2-nopunct": 0.2807634077603531,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.0346217911747682,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.127738449418232,
        "bleu": 9.88272,
        "rouge1": {
            "precision": 0.60833,
            "recall": 0.54224,
            "fmeasure": 0.55321
        },
        "rouge2": {
            "precision": 0.22186,
            "recall": 0.22664,
            "fmeasure": 0.22139
        },
        "rougeL": {
            "precision": 0.53889,
            "recall": 0.5555,
            "fmeasure": 0.53591
        },
        "rougeLsum": {
            "precision": 0.53889,
            "recall": 0.5555,
            "fmeasure": 0.53591
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.36363636363636365,
            "3": 0.6111111111111112
        },
        "bertscore": {
            "precision": 0.89282,
            "recall": 0.87136,
            "f1": 0.87829
        },
        "bleurt": 0.13517,
        "meteor": 0.2747932136886418,
        "nubia": {
            "semantic_relation": 3.4778,
            "contradiction": 0.25659,
            "irrelevancy": 48.44987,
            "logical_agreement": 51.29354,
            "grammar_ref": 4.46073,
            "grammar_hyp": 4.19271,
            "nubia_score": 0.56602
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_330": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.67,
        "total_length": 131,
        "mean_pred_length": 18.714285714285715,
        "std_pred_length": 8.378787599208675,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 36,
        "distinct-1": 0.6030534351145038,
        "vocab_size-1": 79,
        "unique-1": 61,
        "entropy-1": 5.902149551931439,
        "distinct-2": 0.9274193548387096,
        "vocab_size-2": 115,
        "unique-2": 107,
        "entropy-2": 6.802947217627478,
        "cond_entropy-2": 0.806180163218947,
        "distinct-3": 0.9658119658119658,
        "vocab_size-3": 113,
        "unique-3": 109,
        "entropy-3": 6.801988651207317,
        "cond_entropy-3": 0.0080905245996355,
        "total_length-nopunct": 118,
        "mean_pred_length-nopunct": 16.857142857142858,
        "std_pred_length-nopunct": 7.881779556647841,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.652542372881356,
        "vocab_size-1-nopunct": 77,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 5.924714554110501,
        "distinct-2-nopunct": 0.918918918918919,
        "vocab_size-2-nopunct": 102,
        "unique-2-nopunct": 94,
        "entropy-2-nopunct": 6.625452915880179,
        "cond_entropy-2-nopunct": 0.7251122308395617,
        "distinct-3-nopunct": 0.9615384615384616,
        "vocab_size-3-nopunct": 100,
        "unique-3-nopunct": 96,
        "entropy-3-nopunct": 6.623516641218023,
        "cond_entropy-3-nopunct": -0.0001791529959034681,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.316113433909048,
        "bleu": 51.77768,
        "rouge1": {
            "precision": 0.7439,
            "recall": 0.67943,
            "fmeasure": 0.69424
        },
        "rouge2": {
            "precision": 0.51466,
            "recall": 0.45351,
            "fmeasure": 0.46669
        },
        "rougeL": {
            "precision": 0.58811,
            "recall": 0.53203,
            "fmeasure": 0.54201
        },
        "rougeLsum": {
            "precision": 0.58811,
            "recall": 0.53203,
            "fmeasure": 0.54201
        },
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.7428571428571429,
            "3": 0.7246376811594203
        },
        "bertscore": {
            "precision": 0.91265,
            "recall": 0.89784,
            "f1": 0.90368
        },
        "bleurt": 0.05792,
        "meteor": 0.38336084028369943,
        "nubia": {
            "semantic_relation": 4.21843,
            "contradiction": 2.17226,
            "irrelevancy": 23.79771,
            "logical_agreement": 74.03004,
            "grammar_ref": 5.20043,
            "grammar_hyp": 4.57434,
            "nubia_score": 0.75625
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_416": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 49,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 4.109609335312651,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.673469387755102,
        "vocab_size-1": 33,
        "unique-1": 25,
        "entropy-1": 4.749273681736296,
        "distinct-2": 0.8913043478260869,
        "vocab_size-2": 41,
        "unique-2": 37,
        "entropy-2": 5.289760053836066,
        "cond_entropy-2": 0.4935607413383209,
        "distinct-3": 0.9767441860465116,
        "vocab_size-3": 42,
        "unique-3": 41,
        "entropy-3": 5.379753126795121,
        "cond_entropy-3": 0.1063048335791191,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 4.109609335312651,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6956521739130435,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.70505142443955,
        "distinct-2-nopunct": 0.8837209302325582,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.176151091861087,
        "cond_entropy-2-nopunct": 0.5049492393948467,
        "distinct-3-nopunct": 0.975,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.271928094887364,
        "cond_entropy-3-nopunct": 0.1145355277393509,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.080761424186523,
        "bleu": 39.29834,
        "rouge1": {
            "precision": 0.85238,
            "recall": 0.78315,
            "fmeasure": 0.81325
        },
        "rouge2": {
            "precision": 0.58749,
            "recall": 0.52855,
            "fmeasure": 0.554
        },
        "rougeL": {
            "precision": 0.69127,
            "recall": 0.64629,
            "fmeasure": 0.66655
        },
        "rougeLsum": {
            "precision": 0.69127,
            "recall": 0.64629,
            "fmeasure": 0.66655
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.3333333333333333,
            "3": 0.7352941176470589
        },
        "bertscore": {
            "precision": 0.9285,
            "recall": 0.92839,
            "f1": 0.92804
        },
        "bleurt": 0.26213,
        "meteor": 0.3733601146645876,
        "nubia": {
            "semantic_relation": 4.61165,
            "contradiction": 0.7596,
            "irrelevancy": 0.7575,
            "logical_agreement": 98.4829,
            "grammar_ref": 4.67072,
            "grammar_hyp": 4.47039,
            "nubia_score": 0.86893
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_392": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.75,
        "total_length": 201,
        "mean_pred_length": 15.461538461538462,
        "std_pred_length": 4.533896008705039,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.6368159203980099,
        "vocab_size-1": 128,
        "unique-1": 96,
        "entropy-1": 6.587135038729244,
        "distinct-2": 0.8776595744680851,
        "vocab_size-2": 165,
        "unique-2": 142,
        "entropy-2": 7.309908000613821,
        "cond_entropy-2": 0.5404601967037814,
        "distinct-3": 0.9257142857142857,
        "vocab_size-3": 162,
        "unique-3": 149,
        "entropy-3": 7.30263968326088,
        "cond_entropy-3": -0.0005205969881657458,
        "total_length-nopunct": 179,
        "mean_pred_length-nopunct": 13.76923076923077,
        "std_pred_length-nopunct": 4.281513861561768,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6927374301675978,
        "vocab_size-1-nopunct": 124,
        "unique-1-nopunct": 95,
        "entropy-1-nopunct": 6.647270912423166,
        "distinct-2-nopunct": 0.8795180722891566,
        "vocab_size-2-nopunct": 146,
        "unique-2-nopunct": 126,
        "entropy-2-nopunct": 7.134075575925226,
        "cond_entropy-2-nopunct": 0.5282208276161239,
        "distinct-3-nopunct": 0.934640522875817,
        "vocab_size-3-nopunct": 143,
        "unique-3-nopunct": 133,
        "entropy-3-nopunct": 7.126668888444267,
        "cond_entropy-3-nopunct": -0.0065404775431617415,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.803006252974011,
        "bleu": 42.64512,
        "rouge1": {
            "precision": 0.77445,
            "recall": 0.72377,
            "fmeasure": 0.73263
        },
        "rouge2": {
            "precision": 0.52267,
            "recall": 0.48869,
            "fmeasure": 0.49487
        },
        "rougeL": {
            "precision": 0.64275,
            "recall": 0.60291,
            "fmeasure": 0.6087
        },
        "rougeLsum": {
            "precision": 0.64275,
            "recall": 0.60291,
            "fmeasure": 0.6087
        },
        "local_recall": {
            "1": 0.3235294117647059,
            "2": 0.49019607843137253,
            "3": 0.7886178861788617
        },
        "bertscore": {
            "precision": 0.91498,
            "recall": 0.90399,
            "f1": 0.90746
        },
        "bleurt": 0.17736,
        "meteor": 0.4052642984878358,
        "nubia": {
            "semantic_relation": 4.35598,
            "contradiction": 0.6217,
            "irrelevancy": 36.64857,
            "logical_agreement": 62.72972,
            "grammar_ref": 4.86507,
            "grammar_hyp": 4.97428,
            "nubia_score": 0.76315
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_332": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.554592403885422,
        "bleu": 22.08959,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.83333,
            "fmeasure": 0.77143
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.32727,
            "fmeasure": 0.2963
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.55556,
            "fmeasure": 0.51429
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.55556,
            "fmeasure": 0.51429
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.94148,
            "recall": 0.94092,
            "f1": 0.9412
        },
        "bleurt": 0.1802,
        "meteor": 0.40844766518295833,
        "nubia": {
            "semantic_relation": 4.0325,
            "contradiction": 0.30839,
            "irrelevancy": 33.40733,
            "logical_agreement": 66.28428,
            "grammar_ref": 6.47099,
            "grammar_hyp": 6.4091,
            "nubia_score": 0.71955
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_395": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.260329933156776,
        "bleu": 100.0,
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.94737
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.88151,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.5469,
            "irrelevancy": 1.17376,
            "logical_agreement": 98.27934,
            "grammar_ref": 4.07798,
            "grammar_hyp": 4.24873,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_270": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.7925,
        "total_length": 470,
        "mean_pred_length": 15.161290322580646,
        "std_pred_length": 4.66349428864547,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.5680851063829787,
        "vocab_size-1": 267,
        "unique-1": 211,
        "entropy-1": 7.280730348268387,
        "distinct-2": 0.9362186788154897,
        "vocab_size-2": 411,
        "unique-2": 388,
        "entropy-2": 8.638852948490275,
        "cond_entropy-2": 1.1145990622881814,
        "distinct-3": 0.9852941176470589,
        "vocab_size-3": 402,
        "unique-3": 396,
        "entropy-3": 8.643013577265707,
        "cond_entropy-3": 0.004935015080166251,
        "total_length-nopunct": 402,
        "mean_pred_length-nopunct": 12.96774193548387,
        "std_pred_length-nopunct": 3.560390255591707,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6517412935323383,
        "vocab_size-1-nopunct": 262,
        "unique-1-nopunct": 210,
        "entropy-1-nopunct": 7.543232630012469,
        "distinct-2-nopunct": 0.9460916442048517,
        "vocab_size-2-nopunct": 351,
        "unique-2-nopunct": 336,
        "entropy-2-nopunct": 8.41365970147582,
        "cond_entropy-2-nopunct": 0.936039984930122,
        "distinct-3-nopunct": 0.9911764705882353,
        "vocab_size-3-nopunct": 337,
        "unique-3-nopunct": 334,
        "entropy-3-nopunct": 8.39174387731415,
        "cond_entropy-3-nopunct": -0.0225920420161493,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.849876527996823,
        "bleu": 54.45309,
        "rouge1": {
            "precision": 0.81898,
            "recall": 0.77211,
            "fmeasure": 0.78846
        },
        "rouge2": {
            "precision": 0.62309,
            "recall": 0.59299,
            "fmeasure": 0.60336
        },
        "rougeL": {
            "precision": 0.70832,
            "recall": 0.68083,
            "fmeasure": 0.68842
        },
        "rougeLsum": {
            "precision": 0.70832,
            "recall": 0.68083,
            "fmeasure": 0.68842
        },
        "local_recall": {
            "1": 0.17333333333333334,
            "2": 0.5063291139240507,
            "3": 0.81875
        },
        "bertscore": {
            "precision": 0.94302,
            "recall": 0.93901,
            "f1": 0.93972
        },
        "bleurt": 0.40366,
        "meteor": 0.4325800573863607,
        "nubia": {
            "semantic_relation": 4.38568,
            "contradiction": 4.55328,
            "irrelevancy": 22.67356,
            "logical_agreement": 72.77316,
            "grammar_ref": 4.63543,
            "grammar_hyp": 4.60829,
            "nubia_score": 0.79359
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_333": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": 0.0930692077718899,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.5216406363433186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": 0.11094091199688534,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.9472807507835431,
        "bleu": 47.87975,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.69801,
            "fmeasure": 0.81667
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.44444,
            "fmeasure": 0.5291
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.69801,
            "fmeasure": 0.81667
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.69801,
            "fmeasure": 0.81667
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.9769,
            "recall": 0.93775,
            "f1": 0.95692
        },
        "bleurt": 0.78138,
        "meteor": 0.4180407844493463,
        "nubia": {
            "semantic_relation": 4.92558,
            "contradiction": 0.44819,
            "irrelevancy": 0.47684,
            "logical_agreement": 99.07497,
            "grammar_ref": 3.61542,
            "grammar_hyp": 4.58816,
            "nubia_score": 0.99864
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_335": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 55,
        "mean_pred_length": 13.75,
        "std_pred_length": 2.680951323690902,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 18,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 40,
        "unique-1": 34,
        "entropy-1": 5.070097613910771,
        "distinct-2": 0.9803921568627451,
        "vocab_size-2": 50,
        "unique-2": 49,
        "entropy-2": 5.63320965569699,
        "cond_entropy-2": 0.4620345594029882,
        "distinct-3": 1.0,
        "vocab_size-3": 47,
        "unique-3": 47,
        "entropy-3": 5.55458885167764,
        "cond_entropy-3": -0.07528329880449636,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.9154759474226504,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 4.936641344913579,
        "distinct-2-nopunct": 0.9772727272727273,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.413977073182751,
        "cond_entropy-2-nopunct": 0.49081946970622636,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.08750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.186770240568895,
        "bleu": 46.28141,
        "rouge1": {
            "precision": 0.69098,
            "recall": 0.77368,
            "fmeasure": 0.71878
        },
        "rouge2": {
            "precision": 0.46771,
            "recall": 0.51111,
            "fmeasure": 0.47947
        },
        "rougeL": {
            "precision": 0.65784,
            "recall": 0.72217,
            "fmeasure": 0.67604
        },
        "rougeLsum": {
            "precision": 0.65784,
            "recall": 0.72217,
            "fmeasure": 0.67604
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.7692307692307693,
            "3": 0.8333333333333334
        },
        "bertscore": {
            "precision": 0.93734,
            "recall": 0.94307,
            "f1": 0.93815
        },
        "bleurt": 0.43869,
        "meteor": 0.41372450787290577,
        "nubia": {
            "semantic_relation": 4.21322,
            "contradiction": 11.67529,
            "irrelevancy": 36.36121,
            "logical_agreement": 51.9635,
            "grammar_ref": 5.05046,
            "grammar_hyp": 5.20572,
            "nubia_score": 0.68209
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_272": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 7,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 84,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.8284271247461903,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 16,
        "distinct-1": 0.6547619047619048,
        "vocab_size-1": 55,
        "unique-1": 42,
        "entropy-1": 5.454070471431934,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 66,
        "unique-2": 55,
        "entropy-2": 5.981072254980619,
        "cond_entropy-2": 0.35708287712042913,
        "distinct-3": 0.8714285714285714,
        "vocab_size-3": 61,
        "unique-3": 52,
        "entropy-3": 5.872140159802115,
        "cond_entropy-3": -0.10893209517850606,
        "total_length-nopunct": 73,
        "mean_pred_length-nopunct": 10.428571428571429,
        "std_pred_length-nopunct": 2.6649654437396615,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.726027397260274,
        "vocab_size-1-nopunct": 53,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.4889853882124875,
        "distinct-2-nopunct": 0.8636363636363636,
        "vocab_size-2-nopunct": 57,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.771666846631187,
        "cond_entropy-2-nopunct": 0.3267098553076811,
        "distinct-3-nopunct": 0.8813559322033898,
        "vocab_size-3-nopunct": 52,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.6453549137686165,
        "cond_entropy-3-nopunct": -0.12785276491186626,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.5721956073640255,
        "bleu": 46.67968,
        "rouge1": {
            "precision": 0.86121,
            "recall": 0.80206,
            "fmeasure": 0.82749
        },
        "rouge2": {
            "precision": 0.67559,
            "recall": 0.62676,
            "fmeasure": 0.64716
        },
        "rougeL": {
            "precision": 0.79771,
            "recall": 0.7362,
            "fmeasure": 0.76141
        },
        "rougeLsum": {
            "precision": 0.79771,
            "recall": 0.7362,
            "fmeasure": 0.76141
        },
        "local_recall": {
            "1": 0.1875,
            "2": 0.46153846153846156,
            "3": 0.8214285714285714
        },
        "bertscore": {
            "precision": 0.92879,
            "recall": 0.94909,
            "f1": 0.93547
        },
        "bleurt": 0.27613,
        "meteor": 0.43047031962229004,
        "nubia": {
            "semantic_relation": 4.42943,
            "contradiction": 15.53501,
            "irrelevancy": 17.43132,
            "logical_agreement": 67.03367,
            "grammar_ref": 5.14386,
            "grammar_hyp": 5.74636,
            "nubia_score": 0.66252
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_336": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.755,
        "total_length": 295,
        "mean_pred_length": 17.352941176470587,
        "std_pred_length": 5.335135220410932,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.6203389830508474,
        "vocab_size-1": 183,
        "unique-1": 150,
        "entropy-1": 6.874453483836381,
        "distinct-2": 0.9244604316546763,
        "vocab_size-2": 257,
        "unique-2": 243,
        "entropy-2": 7.939177876856423,
        "cond_entropy-2": 0.8817719563795178,
        "distinct-3": 0.9731800766283525,
        "vocab_size-3": 254,
        "unique-3": 247,
        "entropy-3": 7.974266149826556,
        "cond_entropy-3": 0.04679698687717042,
        "total_length-nopunct": 256,
        "mean_pred_length-nopunct": 15.058823529411764,
        "std_pred_length-nopunct": 4.344984779439856,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.69921875,
        "vocab_size-1-nopunct": 179,
        "unique-1-nopunct": 150,
        "entropy-1-nopunct": 7.016045312035097,
        "distinct-2-nopunct": 0.9163179916317992,
        "vocab_size-2-nopunct": 219,
        "unique-2-nopunct": 206,
        "entropy-2-nopunct": 7.700138069691937,
        "cond_entropy-2-nopunct": 0.7331606643321231,
        "distinct-3-nopunct": 0.972972972972973,
        "vocab_size-3-nopunct": 216,
        "unique-3-nopunct": 210,
        "entropy-3-nopunct": 7.740361812296039,
        "cond_entropy-3-nopunct": 0.04658585319384874,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.978801779580473,
        "bleu": 44.59319,
        "rouge1": {
            "precision": 0.77192,
            "recall": 0.71286,
            "fmeasure": 0.7305
        },
        "rouge2": {
            "precision": 0.55459,
            "recall": 0.50466,
            "fmeasure": 0.52116
        },
        "rougeL": {
            "precision": 0.66726,
            "recall": 0.63257,
            "fmeasure": 0.6393
        },
        "rougeLsum": {
            "precision": 0.66726,
            "recall": 0.63257,
            "fmeasure": 0.6393
        },
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.4823529411764706,
            "3": 0.7377049180327869
        },
        "bertscore": {
            "precision": 0.93336,
            "recall": 0.92333,
            "f1": 0.92575
        },
        "bleurt": 0.20958,
        "meteor": 0.38685482313279457,
        "nubia": {
            "semantic_relation": 4.13414,
            "contradiction": 11.67584,
            "irrelevancy": 29.30671,
            "logical_agreement": 59.01745,
            "grammar_ref": 4.33068,
            "grammar_hyp": 4.37376,
            "nubia_score": 0.71267
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_273": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.76,
        "total_length": 224,
        "mean_pred_length": 16.0,
        "std_pred_length": 7.54983443527075,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.5758928571428571,
        "vocab_size-1": 129,
        "unique-1": 99,
        "entropy-1": 6.385976989630594,
        "distinct-2": 0.9,
        "vocab_size-2": 189,
        "unique-2": 171,
        "entropy-2": 7.501127005751047,
        "cond_entropy-2": 0.9494491719083409,
        "distinct-3": 0.9489795918367347,
        "vocab_size-3": 186,
        "unique-3": 176,
        "entropy-3": 7.512669027788665,
        "cond_entropy-3": 0.016560691256042377,
        "total_length-nopunct": 194,
        "mean_pred_length-nopunct": 13.857142857142858,
        "std_pred_length-nopunct": 6.322941707523065,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.634020618556701,
        "vocab_size-1-nopunct": 123,
        "unique-1-nopunct": 95,
        "entropy-1-nopunct": 6.456966707524708,
        "distinct-2-nopunct": 0.9,
        "vocab_size-2-nopunct": 162,
        "unique-2-nopunct": 147,
        "entropy-2-nopunct": 7.276548165762088,
        "cond_entropy-2-nopunct": 0.8830052548182318,
        "distinct-3-nopunct": 0.9457831325301205,
        "vocab_size-3-nopunct": 157,
        "unique-3-nopunct": 148,
        "entropy-3-nopunct": 7.266605696407153,
        "cond_entropy-3-nopunct": -0.015880607740801217,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.239105891922916,
        "bleu": 35.12455,
        "rouge1": {
            "precision": 0.72434,
            "recall": 0.63523,
            "fmeasure": 0.66531
        },
        "rouge2": {
            "precision": 0.48045,
            "recall": 0.41107,
            "fmeasure": 0.4329
        },
        "rougeL": {
            "precision": 0.60593,
            "recall": 0.52926,
            "fmeasure": 0.55461
        },
        "rougeLsum": {
            "precision": 0.60593,
            "recall": 0.52926,
            "fmeasure": 0.55461
        },
        "local_recall": {
            "1": 0.2328767123287671,
            "2": 0.5076923076923077,
            "3": 0.7043478260869566
        },
        "bertscore": {
            "precision": 0.92187,
            "recall": 0.90484,
            "f1": 0.9118
        },
        "bleurt": 0.08195,
        "meteor": 0.35574656084988965,
        "nubia": {
            "semantic_relation": 3.7964,
            "contradiction": 3.51625,
            "irrelevancy": 52.74204,
            "logical_agreement": 43.74171,
            "grammar_ref": 4.00042,
            "grammar_hyp": 4.21306,
            "nubia_score": 0.64904
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_339": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.1176878443984663,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.129610672108602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.1401596872370687,
        "bleu": 9.38687,
        "rouge1": {
            "precision": 0.47619,
            "recall": 0.47619,
            "fmeasure": 0.47619
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.2,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.42857,
            "fmeasure": 0.42857
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.42857,
            "fmeasure": 0.42857
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5333333333333333
        },
        "bertscore": {
            "precision": 0.86491,
            "recall": 0.84055,
            "f1": 0.85255
        },
        "bleurt": -0.04942,
        "meteor": 0.2643140757098528,
        "nubia": {
            "semantic_relation": 3.49212,
            "contradiction": 0.61367,
            "irrelevancy": 99.13436,
            "logical_agreement": 0.25197,
            "grammar_ref": 3.42286,
            "grammar_hyp": 4.51296,
            "nubia_score": 0.48562
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_445": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 1.0,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 15,
        "distinct-1": 0.7857142857142857,
        "vocab_size-1": 22,
        "unique-1": 16,
        "entropy-1": 4.378783493486177,
        "distinct-2": 0.9615384615384616,
        "vocab_size-2": 25,
        "unique-2": 24,
        "entropy-2": 4.623516641218013,
        "cond_entropy-2": 0.2007771037757955,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.03214388408660255,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.251629167387823,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.368522527728205,
        "cond_entropy-2-nopunct": 0.14719639064341364,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.037503523749935014,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.468263072158616,
        "bleu": 57.29001,
        "rouge1": {
            "precision": 0.90793,
            "recall": 0.74987,
            "fmeasure": 0.81319
        },
        "rouge2": {
            "precision": 0.69167,
            "recall": 0.58494,
            "fmeasure": 0.62695
        },
        "rougeL": {
            "precision": 0.72611,
            "recall": 0.63176,
            "fmeasure": 0.66974
        },
        "rougeLsum": {
            "precision": 0.72611,
            "recall": 0.63176,
            "fmeasure": 0.66974
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.2,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.9709,
            "recall": 0.93549,
            "f1": 0.95266
        },
        "bleurt": 0.6327,
        "meteor": 0.44022812605440603,
        "nubia": {
            "semantic_relation": 4.96047,
            "contradiction": 0.38405,
            "irrelevancy": 0.57426,
            "logical_agreement": 99.0417,
            "grammar_ref": 5.26806,
            "grammar_hyp": 4.97586,
            "nubia_score": 0.96899
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_420": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.79,
        "msttr-100_nopunct": 0.82,
        "total_length": 158,
        "mean_pred_length": 14.363636363636363,
        "std_pred_length": 5.56405227203613,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 26,
        "distinct-1": 0.7088607594936709,
        "vocab_size-1": 112,
        "unique-1": 94,
        "entropy-1": 6.44863898975324,
        "distinct-2": 0.9591836734693877,
        "vocab_size-2": 141,
        "unique-2": 137,
        "entropy-2": 7.107769113514402,
        "cond_entropy-2": 0.4642512906839877,
        "distinct-3": 1.0,
        "vocab_size-3": 136,
        "unique-3": 136,
        "entropy-3": 7.0874628412503275,
        "cond_entropy-3": -0.012872922671856265,
        "total_length-nopunct": 142,
        "mean_pred_length-nopunct": 12.909090909090908,
        "std_pred_length-nopunct": 5.2475889780588405,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7676056338028169,
        "vocab_size-1-nopunct": 109,
        "unique-1-nopunct": 93,
        "entropy-1-nopunct": 6.522573527772563,
        "distinct-2-nopunct": 0.9541984732824428,
        "vocab_size-2-nopunct": 125,
        "unique-2-nopunct": 121,
        "entropy-2-nopunct": 6.930294948069306,
        "cond_entropy-2-nopunct": 0.4603848516635677,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 120,
        "unique-3-nopunct": 120,
        "entropy-3-nopunct": 6.906890595608536,
        "cond_entropy-3-nopunct": -0.01395094755954078,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.081717290668063,
        "bleu": 56.6415,
        "rouge1": {
            "precision": 0.8165,
            "recall": 0.75551,
            "fmeasure": 0.77737
        },
        "rouge2": {
            "precision": 0.62433,
            "recall": 0.57945,
            "fmeasure": 0.59547
        },
        "rougeL": {
            "precision": 0.75708,
            "recall": 0.69257,
            "fmeasure": 0.71637
        },
        "rougeLsum": {
            "precision": 0.75708,
            "recall": 0.69257,
            "fmeasure": 0.71637
        },
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.631578947368421,
            "3": 0.8225806451612904
        },
        "bertscore": {
            "precision": 0.95215,
            "recall": 0.93926,
            "f1": 0.94439
        },
        "bleurt": 0.54138,
        "meteor": 0.4441865504697608,
        "nubia": {
            "semantic_relation": 4.64651,
            "contradiction": 2.07748,
            "irrelevancy": 9.0871,
            "logical_agreement": 88.83542,
            "grammar_ref": 4.45431,
            "grammar_hyp": 4.53532,
            "nubia_score": 0.87531
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_396": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.61,
        "msttr-100_nopunct": 0.65,
        "total_length": 125,
        "mean_pred_length": 15.625,
        "std_pred_length": 3.0388114452858046,
        "median_pred_length": 17.0,
        "min_pred_length": 10,
        "max_pred_length": 19,
        "distinct-1": 0.584,
        "vocab_size-1": 73,
        "unique-1": 49,
        "entropy-1": 5.807617085196758,
        "distinct-2": 0.8376068376068376,
        "vocab_size-2": 98,
        "unique-2": 80,
        "entropy-2": 6.539126364864044,
        "cond_entropy-2": 0.6055719941606632,
        "distinct-3": 0.8623853211009175,
        "vocab_size-3": 94,
        "unique-3": 79,
        "entropy-3": 6.49295496697875,
        "cond_entropy-3": -0.04020894983250148,
        "total_length-nopunct": 107,
        "mean_pred_length-nopunct": 13.375,
        "std_pred_length-nopunct": 3.3517719194479807,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6355140186915887,
        "vocab_size-1-nopunct": 68,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.79642572024447,
        "distinct-2-nopunct": 0.8282828282828283,
        "vocab_size-2-nopunct": 82,
        "unique-2-nopunct": 66,
        "entropy-2-nopunct": 6.278297150360794,
        "cond_entropy-2-nopunct": 0.5178343607148294,
        "distinct-3-nopunct": 0.8461538461538461,
        "vocab_size-3-nopunct": 77,
        "unique-3-nopunct": 63,
        "entropy-3-nopunct": 6.2001023325063915,
        "cond_entropy-3-nopunct": -0.06931046886812793,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.9700865116158415,
        "bleu": 50.14661,
        "rouge1": {
            "precision": 0.69487,
            "recall": 0.76948,
            "fmeasure": 0.72127
        },
        "rouge2": {
            "precision": 0.52165,
            "recall": 0.6025,
            "fmeasure": 0.54549
        },
        "rougeL": {
            "precision": 0.61009,
            "recall": 0.68349,
            "fmeasure": 0.63707
        },
        "rougeLsum": {
            "precision": 0.61009,
            "recall": 0.68349,
            "fmeasure": 0.63707
        },
        "local_recall": {
            "1": 0.3170731707317073,
            "2": 0.7142857142857143,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.92195,
            "recall": 0.94112,
            "f1": 0.92667
        },
        "bleurt": 0.27986,
        "meteor": 0.4509944613868265,
        "nubia": {
            "semantic_relation": 3.87536,
            "contradiction": 30.81697,
            "irrelevancy": 24.62695,
            "logical_agreement": 44.55608,
            "grammar_ref": 5.12618,
            "grammar_hyp": 4.66594,
            "nubia_score": 0.66675
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_423": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 2.0,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 17,
        "distinct-1": 0.9,
        "vocab_size-1": 27,
        "unique-1": 24,
        "entropy-1": 4.7068905956085185,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": 0.0433214693062285,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.546593564294937,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.051189449246730766,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6429832731933574,
        "bleu": 40.61004,
        "rouge1": {
            "precision": 0.6265,
            "recall": 0.68333,
            "fmeasure": 0.64411
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33085
        },
        "rougeL": {
            "precision": 0.45214,
            "recall": 0.46465,
            "fmeasure": 0.45149
        },
        "rougeLsum": {
            "precision": 0.45214,
            "recall": 0.46465,
            "fmeasure": 0.45149
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.1,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.91691,
            "recall": 0.91506,
            "f1": 0.9111
        },
        "bleurt": 0.32048,
        "meteor": 0.3814421933773468,
        "nubia": {
            "semantic_relation": 4.2586,
            "contradiction": 0.5376,
            "irrelevancy": 5.70956,
            "logical_agreement": 93.75284,
            "grammar_ref": 4.57807,
            "grammar_hyp": 3.81347,
            "nubia_score": 0.79598
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_448": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 13.25,
        "std_pred_length": 0.4330127018922193,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 14,
        "distinct-1": 0.8301886792452831,
        "vocab_size-1": 44,
        "unique-1": 37,
        "entropy-1": 5.350561963997159,
        "distinct-2": 0.9387755102040817,
        "vocab_size-2": 46,
        "unique-2": 43,
        "entropy-2": 5.492260864523372,
        "cond_entropy-2": 0.009238369143845945,
        "distinct-3": 0.9555555555555556,
        "vocab_size-3": 43,
        "unique-3": 41,
        "entropy-3": 5.402964207440784,
        "cond_entropy-3": -0.07841230334108928,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.7071067811865476,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.334962500721158,
        "distinct-2-nopunct": 0.9318181818181818,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.323067982273659,
        "cond_entropy-2-nopunct": 0.010832754279777283,
        "distinct-3-nopunct": 0.95,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.221928094887364,
        "cond_entropy-3-nopunct": -0.08750352374993503,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.352120808578938,
        "bleu": 71.64036,
        "rouge1": {
            "precision": 0.88337,
            "recall": 0.79516,
            "fmeasure": 0.83566
        },
        "rouge2": {
            "precision": 0.69066,
            "recall": 0.62605,
            "fmeasure": 0.65576
        },
        "rougeL": {
            "precision": 0.81855,
            "recall": 0.74403,
            "fmeasure": 0.77852
        },
        "rougeLsum": {
            "precision": 0.81855,
            "recall": 0.74403,
            "fmeasure": 0.77852
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.2222222222222222,
            "3": 0.8478260869565217
        },
        "bertscore": {
            "precision": 0.97323,
            "recall": 0.95762,
            "f1": 0.96214
        },
        "bleurt": 0.53575,
        "meteor": 0.4841365428931994,
        "nubia": {
            "semantic_relation": 4.79311,
            "contradiction": 0.382,
            "irrelevancy": 0.61528,
            "logical_agreement": 99.00272,
            "grammar_ref": 4.9146,
            "grammar_hyp": 4.69371,
            "nubia_score": 0.93582
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_450": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 13.25,
        "std_pred_length": 2.384848003542364,
        "median_pred_length": 13.5,
        "min_pred_length": 10,
        "max_pred_length": 16,
        "distinct-1": 0.8490566037735849,
        "vocab_size-1": 45,
        "unique-1": 40,
        "entropy-1": 5.374054652635584,
        "distinct-2": 1.0,
        "vocab_size-2": 49,
        "unique-2": 49,
        "entropy-2": 5.614709844115208,
        "cond_entropy-2": 0.10627688959616174,
        "distinct-3": 1.0,
        "vocab_size-3": 45,
        "unique-3": 45,
        "entropy-3": 5.491853096329673,
        "cond_entropy-3": -0.12285674778553377,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.1213203435596424,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8958333333333334,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.360902344426088,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.4594316186372955,
        "cond_entropy-2-nopunct": 0.11889837932894702,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.13750352374993507,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.4052050036170876,
        "bleu": 49.33804,
        "rouge1": {
            "precision": 0.71935,
            "recall": 0.86806,
            "fmeasure": 0.7816
        },
        "rouge2": {
            "precision": 0.59163,
            "recall": 0.71228,
            "fmeasure": 0.64117
        },
        "rougeL": {
            "precision": 0.6499,
            "recall": 0.77533,
            "fmeasure": 0.70213
        },
        "rougeLsum": {
            "precision": 0.6499,
            "recall": 0.77533,
            "fmeasure": 0.70213
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.6875,
            "3": 0.9047619047619048
        },
        "bertscore": {
            "precision": 0.91934,
            "recall": 0.93776,
            "f1": 0.9256
        },
        "bleurt": 0.16386,
        "meteor": 0.4166953263394887,
        "nubia": {
            "semantic_relation": 3.78492,
            "contradiction": 1.6172,
            "irrelevancy": 56.72793,
            "logical_agreement": 41.65488,
            "grammar_ref": 4.75156,
            "grammar_hyp": 5.1343,
            "nubia_score": 0.54817
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_424": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 57,
        "mean_pred_length": 14.25,
        "std_pred_length": 5.717298313014636,
        "median_pred_length": 13.5,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 38,
        "unique-1": 26,
        "entropy-1": 5.056316987735082,
        "distinct-2": 0.9433962264150944,
        "vocab_size-2": 50,
        "unique-2": 47,
        "entropy-2": 5.614712907393385,
        "cond_entropy-2": 0.466061808445446,
        "distinct-3": 0.9591836734693877,
        "vocab_size-3": 47,
        "unique-3": 45,
        "entropy-3": 5.533077191053984,
        "cond_entropy-3": -0.07239428391737851,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 5.408326913195984,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.72,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 5.013660689688187,
        "distinct-2-nopunct": 0.9347826086956522,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.393127173448315,
        "cond_entropy-2-nopunct": 0.4125269620285259,
        "distinct-3-nopunct": 0.9523809523809523,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.297079327540667,
        "cond_entropy-3-nopunct": -0.10743500946872869,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.397665590177789,
        "bleu": 42.69597,
        "rouge1": {
            "precision": 0.71997,
            "recall": 0.74766,
            "fmeasure": 0.72226
        },
        "rouge2": {
            "precision": 0.50341,
            "recall": 0.52356,
            "fmeasure": 0.50311
        },
        "rougeL": {
            "precision": 0.6314,
            "recall": 0.66315,
            "fmeasure": 0.63592
        },
        "rougeLsum": {
            "precision": 0.6314,
            "recall": 0.66315,
            "fmeasure": 0.63592
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0,
            "3": 0.775
        },
        "bertscore": {
            "precision": 0.9249,
            "recall": 0.93391,
            "f1": 0.92849
        },
        "bleurt": 0.21163,
        "meteor": 0.43894279861554575,
        "nubia": {
            "semantic_relation": 4.62711,
            "contradiction": 0.2744,
            "irrelevancy": 25.82267,
            "logical_agreement": 73.90293,
            "grammar_ref": 4.90076,
            "grammar_hyp": 4.84169,
            "nubia_score": 0.85415
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_275": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.77,
        "total_length": 133,
        "mean_pred_length": 16.625,
        "std_pred_length": 7.712611425451175,
        "median_pred_length": 14.5,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.6691729323308271,
        "vocab_size-1": 89,
        "unique-1": 74,
        "entropy-1": 6.058417226343368,
        "distinct-2": 0.944,
        "vocab_size-2": 118,
        "unique-2": 114,
        "entropy-2": 6.835666984610172,
        "cond_entropy-2": 0.6196455080601154,
        "distinct-3": 0.9658119658119658,
        "vocab_size-3": 113,
        "unique-3": 111,
        "entropy-3": 6.789084591341274,
        "cond_entropy-3": -0.037685483863610175,
        "total_length-nopunct": 110,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 5.2141634036535525,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7454545454545455,
        "vocab_size-1-nopunct": 82,
        "unique-1-nopunct": 71,
        "entropy-1-nopunct": 6.051680963465662,
        "distinct-2-nopunct": 0.9509803921568627,
        "vocab_size-2-nopunct": 97,
        "unique-2-nopunct": 94,
        "entropy-2-nopunct": 6.559584410556529,
        "cond_entropy-2-nopunct": 0.5397903833629373,
        "distinct-3-nopunct": 0.9787234042553191,
        "vocab_size-3-nopunct": 92,
        "unique-3-nopunct": 91,
        "entropy-3-nopunct": 6.50400494208014,
        "cond_entropy-3-nopunct": -0.04597598495169349,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.459719814156158,
        "bleu": 38.29316,
        "rouge1": {
            "precision": 0.7092,
            "recall": 0.6153,
            "fmeasure": 0.6498
        },
        "rouge2": {
            "precision": 0.42961,
            "recall": 0.38522,
            "fmeasure": 0.40261
        },
        "rougeL": {
            "precision": 0.59189,
            "recall": 0.52966,
            "fmeasure": 0.5536
        },
        "rougeLsum": {
            "precision": 0.59189,
            "recall": 0.52966,
            "fmeasure": 0.5536
        },
        "local_recall": {
            "1": 0.04,
            "2": 0.36363636363636365,
            "3": 0.6382978723404256
        },
        "bertscore": {
            "precision": 0.9272,
            "recall": 0.91282,
            "f1": 0.91808
        },
        "bleurt": 0.20042,
        "meteor": 0.3451900908126844,
        "nubia": {
            "semantic_relation": 3.82819,
            "contradiction": 35.88603,
            "irrelevancy": 8.34119,
            "logical_agreement": 55.77278,
            "grammar_ref": 5.01189,
            "grammar_hyp": 4.9952,
            "nubia_score": 0.60785
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_425": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.7735572622751845,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.0433214693062285,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.5487341045797267,
        "bleu": 38.50323,
        "rouge1": {
            "precision": 0.45238,
            "recall": 0.43732,
            "fmeasure": 0.44213
        },
        "rouge2": {
            "precision": 0.35897,
            "recall": 0.44444,
            "fmeasure": 0.39365
        },
        "rougeL": {
            "precision": 0.40476,
            "recall": 0.49288,
            "fmeasure": 0.44122
        },
        "rougeLsum": {
            "precision": 0.40476,
            "recall": 0.49288,
            "fmeasure": 0.44122
        },
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 1.0,
            "3": 0.5714285714285714
        },
        "bertscore": {
            "precision": 0.85689,
            "recall": 0.8779,
            "f1": 0.85463
        },
        "bleurt": -0.25457,
        "meteor": 0.2946488264204917,
        "nubia": {
            "semantic_relation": 1.39508,
            "contradiction": 96.31516,
            "irrelevancy": 3.35884,
            "logical_agreement": 0.326,
            "grammar_ref": 4.13721,
            "grammar_hyp": 3.57103,
            "nubia_score": 0.11606
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_485": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.043321469306228495,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.685626501798519,
        "bleu": 29.70518,
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.80828,
            "fmeasure": 0.86616
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.42892,
            "fmeasure": 0.46165
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.63508,
            "fmeasure": 0.68056
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.63508,
            "fmeasure": 0.68056
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.96128,
            "recall": 0.93692,
            "f1": 0.94894
        },
        "bleurt": 0.46477,
        "meteor": 0.41081248021664324,
        "nubia": {
            "semantic_relation": 4.87694,
            "contradiction": 0.09518,
            "irrelevancy": 0.57155,
            "logical_agreement": 99.33328,
            "grammar_ref": 3.15249,
            "grammar_hyp": 3.4232,
            "nubia_score": 0.97292
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_360": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.68667,
        "msttr-100_nopunct": 0.73,
        "total_length": 339,
        "mean_pred_length": 16.95,
        "std_pred_length": 6.192535829528966,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 33,
        "distinct-1": 0.5427728613569321,
        "vocab_size-1": 184,
        "unique-1": 137,
        "entropy-1": 6.816090348801607,
        "distinct-2": 0.877742946708464,
        "vocab_size-2": 280,
        "unique-2": 252,
        "entropy-2": 8.043794392714318,
        "cond_entropy-2": 1.047742883768322,
        "distinct-3": 0.959866220735786,
        "vocab_size-3": 287,
        "unique-3": 276,
        "entropy-3": 8.141209408304539,
        "cond_entropy-3": 0.1090282745234716,
        "total_length-nopunct": 295,
        "mean_pred_length-nopunct": 14.75,
        "std_pred_length-nopunct": 5.620275793944635,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.6101694915254238,
        "vocab_size-1-nopunct": 180,
        "unique-1-nopunct": 137,
        "entropy-1-nopunct": 6.979072221796619,
        "distinct-2-nopunct": 0.8872727272727273,
        "vocab_size-2-nopunct": 244,
        "unique-2-nopunct": 223,
        "entropy-2-nopunct": 7.846817535637551,
        "cond_entropy-2-nopunct": 0.9250365536477569,
        "distinct-3-nopunct": 0.9686274509803922,
        "vocab_size-3-nopunct": 247,
        "unique-3-nopunct": 240,
        "entropy-3-nopunct": 7.9286479956739155,
        "cond_entropy-3-nopunct": 0.08167155985614935,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.3389208918177875,
        "bleu": 54.46116,
        "rouge1": {
            "precision": 0.81805,
            "recall": 0.8176,
            "fmeasure": 0.81155
        },
        "rouge2": {
            "precision": 0.65555,
            "recall": 0.66381,
            "fmeasure": 0.65296
        },
        "rougeL": {
            "precision": 0.74567,
            "recall": 0.75357,
            "fmeasure": 0.74283
        },
        "rougeLsum": {
            "precision": 0.74567,
            "recall": 0.75357,
            "fmeasure": 0.74283
        },
        "local_recall": {
            "1": 0.20270270270270271,
            "2": 0.6307692307692307,
            "3": 0.8263157894736842
        },
        "bertscore": {
            "precision": 0.94822,
            "recall": 0.94602,
            "f1": 0.94625
        },
        "bleurt": 0.42669,
        "meteor": 0.4416322296278391,
        "nubia": {
            "semantic_relation": 4.30572,
            "contradiction": 7.72429,
            "irrelevancy": 25.90275,
            "logical_agreement": 66.37297,
            "grammar_ref": 4.44035,
            "grammar_hyp": 4.40265,
            "nubia_score": 0.76707
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_486": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 62,
        "mean_pred_length": 15.5,
        "std_pred_length": 10.062305898749054,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.7419354838709677,
        "vocab_size-1": 46,
        "unique-1": 36,
        "entropy-1": 5.316941874833215,
        "distinct-2": 0.9827586206896551,
        "vocab_size-2": 57,
        "unique-2": 56,
        "entropy-2": 5.823498236506881,
        "cond_entropy-2": 0.4125739089532305,
        "distinct-3": 1.0,
        "vocab_size-3": 54,
        "unique-3": 54,
        "entropy-3": 5.7548875021634665,
        "cond_entropy-3": -0.10309349296410344,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 7.713624310270756,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.334962500721159,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.4594316186372955,
        "cond_entropy-2-nopunct": 0.07901457246159543,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.13750352374993507,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.823842316181383,
        "bleu": 41.18823,
        "rouge1": {
            "precision": 0.59722,
            "recall": 0.44761,
            "fmeasure": 0.46494
        },
        "rouge2": {
            "precision": 0.44215,
            "recall": 0.30787,
            "fmeasure": 0.31704
        },
        "rougeL": {
            "precision": 0.57639,
            "recall": 0.44761,
            "fmeasure": 0.45244
        },
        "rougeLsum": {
            "precision": 0.57639,
            "recall": 0.44761,
            "fmeasure": 0.45244
        },
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.21052631578947367,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.84061,
            "recall": 0.83334,
            "f1": 0.82444
        },
        "bleurt": -0.31424,
        "meteor": 0.29391047426000627,
        "nubia": {
            "semantic_relation": 3.40871,
            "contradiction": 27.17316,
            "irrelevancy": 50.6673,
            "logical_agreement": 22.15954,
            "grammar_ref": 4.83501,
            "grammar_hyp": 5.22661,
            "nubia_score": 0.48298
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_364": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 62,
        "mean_pred_length": 15.5,
        "std_pred_length": 7.399324293474371,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.6774193548387096,
        "vocab_size-1": 42,
        "unique-1": 33,
        "entropy-1": 5.111217882862836,
        "distinct-2": 0.8620689655172413,
        "vocab_size-2": 50,
        "unique-2": 44,
        "entropy-2": 5.556088322639174,
        "cond_entropy-2": 0.3650758485711016,
        "distinct-3": 0.9074074074074074,
        "vocab_size-3": 49,
        "unique-3": 45,
        "entropy-3": 5.555722918790069,
        "cond_entropy-3": 0.021997016335220082,
        "total_length-nopunct": 57,
        "mean_pred_length-nopunct": 14.25,
        "std_pred_length-nopunct": 7.013380069552769,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7017543859649122,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.056316987735084,
        "distinct-2-nopunct": 0.8490566037735849,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.397547341274009,
        "cond_entropy-2-nopunct": 0.36210378949588135,
        "distinct-3-nopunct": 0.8979591836734694,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.395222344071056,
        "cond_entropy-3-nopunct": 0.02464423653493714,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.100452078917137,
        "bleu": 32.01317,
        "rouge1": {
            "precision": 0.62678,
            "recall": 0.6064,
            "fmeasure": 0.6046
        },
        "rouge2": {
            "precision": 0.39071,
            "recall": 0.37694,
            "fmeasure": 0.37642
        },
        "rougeL": {
            "precision": 0.56078,
            "recall": 0.54937,
            "fmeasure": 0.54478
        },
        "rougeLsum": {
            "precision": 0.56078,
            "recall": 0.54937,
            "fmeasure": 0.54478
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.08333333333333333,
            "3": 0.7
        },
        "bertscore": {
            "precision": 0.93508,
            "recall": 0.92209,
            "f1": 0.92795
        },
        "bleurt": 0.28211,
        "meteor": 0.3121999607450881,
        "nubia": {
            "semantic_relation": 4.31485,
            "contradiction": 10.52786,
            "irrelevancy": 35.74656,
            "logical_agreement": 53.72559,
            "grammar_ref": 4.84918,
            "grammar_hyp": 4.62038,
            "nubia_score": 0.77135
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_488": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966058,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185188,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.6144838329894124,
        "bleu": 78.93575,
        "rouge1": {
            "precision": 0.9375,
            "recall": 0.96078,
            "fmeasure": 0.94819
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.7619,
            "fmeasure": 0.769
        },
        "rougeL": {
            "precision": 0.89583,
            "recall": 0.87712,
            "fmeasure": 0.88563
        },
        "rougeLsum": {
            "precision": 0.89583,
            "recall": 0.87712,
            "fmeasure": 0.88563
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.97737,
            "recall": 0.97443,
            "f1": 0.97475
        },
        "bleurt": 0.73059,
        "meteor": 0.5305475968023703,
        "nubia": {
            "semantic_relation": 4.80996,
            "contradiction": 0.22818,
            "irrelevancy": 0.49433,
            "logical_agreement": 99.27749,
            "grammar_ref": 4.24096,
            "grammar_hyp": 3.78167,
            "nubia_score": 0.97089
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_365": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 58,
        "mean_pred_length": 19.333333333333332,
        "std_pred_length": 6.182412330330469,
        "median_pred_length": 16.0,
        "min_pred_length": 14,
        "max_pred_length": 28,
        "distinct-1": 0.6206896551724138,
        "vocab_size-1": 36,
        "unique-1": 20,
        "entropy-1": 4.998079219594343,
        "distinct-2": 0.7818181818181819,
        "vocab_size-2": 43,
        "unique-2": 31,
        "entropy-2": 5.344996077161022,
        "cond_entropy-2": 0.30736809073824656,
        "distinct-3": 0.8076923076923077,
        "vocab_size-3": 42,
        "unique-3": 32,
        "entropy-3": 5.315824333525707,
        "cond_entropy-3": -0.04245845692202902,
        "total_length-nopunct": 51,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 4.320493798938574,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6274509803921569,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.826946607093774,
        "distinct-2-nopunct": 0.7708333333333334,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 5.126629167387822,
        "cond_entropy-2-nopunct": 0.31085831455723884,
        "distinct-3-nopunct": 0.8,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 5.091853096329676,
        "cond_entropy-3-nopunct": -0.04866495994703732,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.701340977269565,
        "bleu": 52.64334,
        "rouge1": {
            "precision": 0.66102,
            "recall": 0.87885,
            "fmeasure": 0.74841
        },
        "rouge2": {
            "precision": 0.56599,
            "recall": 0.76826,
            "fmeasure": 0.64589
        },
        "rougeL": {
            "precision": 0.66102,
            "recall": 0.87885,
            "fmeasure": 0.74841
        },
        "rougeLsum": {
            "precision": 0.66102,
            "recall": 0.87885,
            "fmeasure": 0.74841
        },
        "local_recall": {
            "1": 0.7142857142857143,
            "2": 0.6,
            "3": 0.896551724137931
        },
        "bertscore": {
            "precision": 0.92731,
            "recall": 0.96698,
            "f1": 0.94647
        },
        "bleurt": 0.28567,
        "meteor": 0.5085312425673553,
        "nubia": {
            "semantic_relation": 4.50773,
            "contradiction": 0.47577,
            "irrelevancy": 41.70919,
            "logical_agreement": 57.81504,
            "grammar_ref": 4.37436,
            "grammar_hyp": 4.1063,
            "nubia_score": 0.74725
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_426": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 80,
        "mean_pred_length": 26.666666666666668,
        "std_pred_length": 5.185449728701348,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 34,
        "distinct-1": 0.7,
        "vocab_size-1": 56,
        "unique-1": 40,
        "entropy-1": 5.623499307625768,
        "distinct-2": 0.8961038961038961,
        "vocab_size-2": 69,
        "unique-2": 61,
        "entropy-2": 6.058994332902697,
        "cond_entropy-2": 0.40095475072654924,
        "distinct-3": 0.9054054054054054,
        "vocab_size-3": 67,
        "unique-3": 60,
        "entropy-3": 6.020264176439766,
        "cond_entropy-3": -0.0303061480389246,
        "total_length-nopunct": 71,
        "mean_pred_length-nopunct": 23.666666666666668,
        "std_pred_length-nopunct": 5.185449728701348,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.7464788732394366,
        "vocab_size-1-nopunct": 53,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.570600422620681,
        "distinct-2-nopunct": 0.8970588235294118,
        "vocab_size-2-nopunct": 61,
        "unique-2-nopunct": 54,
        "entropy-2-nopunct": 5.881580488309168,
        "cond_entropy-2-nopunct": 0.3218247729039478,
        "distinct-3-nopunct": 0.9076923076923077,
        "vocab_size-3-nopunct": 59,
        "unique-3-nopunct": 53,
        "entropy-3-nopunct": 5.837752428413074,
        "cond_entropy-3-nopunct": -0.0343257974526542,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9549727091493203,
        "bleu": 23.50193,
        "rouge1": {
            "precision": 0.50049,
            "recall": 0.52975,
            "fmeasure": 0.51339
        },
        "rouge2": {
            "precision": 0.31323,
            "recall": 0.33077,
            "fmeasure": 0.32123
        },
        "rougeL": {
            "precision": 0.36119,
            "recall": 0.44768,
            "fmeasure": 0.39569
        },
        "rougeLsum": {
            "precision": 0.36119,
            "recall": 0.44768,
            "fmeasure": 0.39569
        },
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.3548387096774194,
            "3": 0.64
        },
        "bertscore": {
            "precision": 0.86507,
            "recall": 0.8645,
            "f1": 0.86368
        },
        "bleurt": -0.05373,
        "meteor": 0.23026542556309257,
        "nubia": {
            "semantic_relation": 3.71777,
            "contradiction": 2.42956,
            "irrelevancy": 65.53436,
            "logical_agreement": 32.03608,
            "grammar_ref": 3.62435,
            "grammar_hyp": 3.0559,
            "nubia_score": 0.71847
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_490": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 84,
        "mean_pred_length": 16.8,
        "std_pred_length": 3.6,
        "median_pred_length": 17.0,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.6428571428571429,
        "vocab_size-1": 54,
        "unique-1": 42,
        "entropy-1": 5.388477911856613,
        "distinct-2": 0.9367088607594937,
        "vocab_size-2": 74,
        "unique-2": 70,
        "entropy-2": 6.167642931694023,
        "cond_entropy-2": 0.6650184748288347,
        "distinct-3": 0.972972972972973,
        "vocab_size-3": 72,
        "unique-3": 70,
        "entropy-3": 6.155399311574901,
        "cond_entropy-3": -0.0030451190054035203,
        "total_length-nopunct": 72,
        "mean_pred_length-nopunct": 14.4,
        "std_pred_length-nopunct": 3.261901286060018,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7083333333333334,
        "vocab_size-1-nopunct": 51,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.365534071429903,
        "distinct-2-nopunct": 0.9552238805970149,
        "vocab_size-2-nopunct": 64,
        "unique-2-nopunct": 62,
        "entropy-2-nopunct": 5.965269974007566,
        "cond_entropy-2-nopunct": 0.6299143301905372,
        "distinct-3-nopunct": 0.9838709677419355,
        "vocab_size-3-nopunct": 61,
        "unique-3-nopunct": 60,
        "entropy-3-nopunct": 5.921938245870745,
        "cond_entropy-3-nopunct": -0.05133017842309928,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.848018994519774,
        "bleu": 33.28434,
        "rouge1": {
            "precision": 0.70961,
            "recall": 0.76729,
            "fmeasure": 0.72902
        },
        "rouge2": {
            "precision": 0.43052,
            "recall": 0.48476,
            "fmeasure": 0.45063
        },
        "rougeL": {
            "precision": 0.58676,
            "recall": 0.62574,
            "fmeasure": 0.59803
        },
        "rougeLsum": {
            "precision": 0.58676,
            "recall": 0.62574,
            "fmeasure": 0.59803
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.125,
            "3": 0.7857142857142857
        },
        "bertscore": {
            "precision": 0.91732,
            "recall": 0.92611,
            "f1": 0.92055
        },
        "bleurt": 0.16737,
        "meteor": 0.3680806828797976,
        "nubia": {
            "semantic_relation": 4.01736,
            "contradiction": 24.50277,
            "irrelevancy": 53.81506,
            "logical_agreement": 21.68217,
            "grammar_ref": 4.31899,
            "grammar_hyp": 4.21216,
            "nubia_score": 0.65886
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_452": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.8,
        "vocab_size-1": 16,
        "unique-1": 12,
        "entropy-1": 3.921928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.34705205013517054,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7894736842105263,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.826874881864637,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.3108863768876157,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.294668703177415,
        "bleu": 27.76977,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.58333,
            "fmeasure": 0.63636
        },
        "rouge2": {
            "precision": 0.52632,
            "recall": 0.43478,
            "fmeasure": 0.47619
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.5,
            "fmeasure": 0.54545
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.5,
            "fmeasure": 0.54545
        },
        "local_recall": {
            "1": 0,
            "2": 0.75,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.89219,
            "recall": 0.86886,
            "f1": 0.88037
        },
        "bleurt": -0.24395,
        "meteor": 0.29043716945773146,
        "nubia": {
            "semantic_relation": 3.04197,
            "contradiction": 97.41937,
            "irrelevancy": 1.42046,
            "logical_agreement": 1.16018,
            "grammar_ref": 4.791,
            "grammar_hyp": 4.48714,
            "nubia_score": 0.4164
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_492": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 1.247219128924647,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 15,
        "distinct-1": 0.825,
        "vocab_size-1": 33,
        "unique-1": 28,
        "entropy-1": 4.93418371977919,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.17819790593519452,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.12199052437861026,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.816496580927726,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8611111111111112,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.871178126382214,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.20037479979988243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.13750352374993471,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.4761202293525235,
        "bleu": 49.53607,
        "rouge1": {
            "precision": 0.84274,
            "recall": 0.78093,
            "fmeasure": 0.80562
        },
        "rouge2": {
            "precision": 0.56728,
            "recall": 0.50588,
            "fmeasure": 0.53144
        },
        "rougeL": {
            "precision": 0.69701,
            "recall": 0.63837,
            "fmeasure": 0.66252
        },
        "rougeLsum": {
            "precision": 0.69701,
            "recall": 0.63837,
            "fmeasure": 0.66252
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.8571428571428571,
            "3": 0.7272727272727273
        },
        "bertscore": {
            "precision": 0.93899,
            "recall": 0.92681,
            "f1": 0.93273
        },
        "bleurt": 0.32122,
        "meteor": 0.39793613761111674,
        "nubia": {
            "semantic_relation": 4.25148,
            "contradiction": 0.43821,
            "irrelevancy": 33.64516,
            "logical_agreement": 65.91664,
            "grammar_ref": 3.54742,
            "grammar_hyp": 3.56086,
            "nubia_score": 0.85967
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_427": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 42,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.320493798938574,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 20,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 30,
        "unique-1": 23,
        "entropy-1": 4.69899800661772,
        "distinct-2": 0.9487179487179487,
        "vocab_size-2": 37,
        "unique-2": 35,
        "entropy-2": 5.182838116298145,
        "cond_entropy-2": 0.41525218009887993,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.0043661063088247885,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 3.858612300930075,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7368421052631579,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.6067557245856845,
        "distinct-2-nopunct": 0.9428571428571428,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 5.014997302659249,
        "cond_entropy-2-nopunct": 0.46319915997567457,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.00428301694496647,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.215331170156148,
        "bleu": 38.55409,
        "rouge1": {
            "precision": 0.70455,
            "recall": 0.70302,
            "fmeasure": 0.69542
        },
        "rouge2": {
            "precision": 0.44678,
            "recall": 0.43843,
            "fmeasure": 0.43598
        },
        "rougeL": {
            "precision": 0.57121,
            "recall": 0.5963,
            "fmeasure": 0.57253
        },
        "rougeLsum": {
            "precision": 0.57121,
            "recall": 0.5963,
            "fmeasure": 0.57253
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.15384615384615385,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.90079,
            "recall": 0.93628,
            "f1": 0.91705
        },
        "bleurt": 0.30869,
        "meteor": 0.408328110820181,
        "nubia": {
            "semantic_relation": 4.2214,
            "contradiction": 1.135,
            "irrelevancy": 56.31031,
            "logical_agreement": 42.55468,
            "grammar_ref": 4.38609,
            "grammar_hyp": 4.42824,
            "nubia_score": 0.67256
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_455": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 1.5,
        "median_pred_length": 11.5,
        "min_pred_length": 10,
        "max_pred_length": 13,
        "distinct-1": 0.8695652173913043,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.229871195093384,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.09517868111048412,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.14438990933517493,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 3.9976702764876113,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.1192345926398991,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.18057224564182078,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.654881186650527,
        "bleu": 58.8878,
        "rouge1": {
            "precision": 0.9623,
            "recall": 0.74997,
            "fmeasure": 0.83862
        },
        "rouge2": {
            "precision": 0.73232,
            "recall": 0.53558,
            "fmeasure": 0.61552
        },
        "rougeL": {
            "precision": 0.95238,
            "recall": 0.70808,
            "fmeasure": 0.80905
        },
        "rougeLsum": {
            "precision": 0.95238,
            "recall": 0.70808,
            "fmeasure": 0.80905
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.9411764705882353
        },
        "bertscore": {
            "precision": 0.9497,
            "recall": 0.93341,
            "f1": 0.94148
        },
        "bleurt": 0.37749,
        "meteor": 0.432144060866998,
        "nubia": {
            "semantic_relation": 4.37411,
            "contradiction": 0.80155,
            "irrelevancy": 27.03344,
            "logical_agreement": 72.16501,
            "grammar_ref": 5.06568,
            "grammar_hyp": 5.64337,
            "nubia_score": 0.71669
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_428": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.8521687236032816,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.16253715874966054,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.3186384774502833,
        "bleu": 10.93488,
        "rouge1": {
            "precision": 0.35294,
            "recall": 0.675,
            "fmeasure": 0.46222
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.25397,
            "fmeasure": 0.16696
        },
        "rougeL": {
            "precision": 0.29412,
            "recall": 0.5625,
            "fmeasure": 0.38519
        },
        "rougeLsum": {
            "precision": 0.29412,
            "recall": 0.5625,
            "fmeasure": 0.38519
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.75
        },
        "bertscore": {
            "precision": 0.78995,
            "recall": 0.9029,
            "f1": 0.84266
        },
        "bleurt": 0.1862,
        "meteor": 0.3231967797614317,
        "nubia": {
            "semantic_relation": 4.71405,
            "contradiction": 0.15602,
            "irrelevancy": 64.79196,
            "logical_agreement": 35.05202,
            "grammar_ref": 6.57359,
            "grammar_hyp": 4.90195,
            "nubia_score": 0.67942
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_495": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 78,
        "mean_pred_length": 19.5,
        "std_pred_length": 3.905124837953327,
        "median_pred_length": 21.0,
        "min_pred_length": 13,
        "max_pred_length": 23,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 60,
        "unique-1": 51,
        "entropy-1": 5.711621609860159,
        "distinct-2": 1.0,
        "vocab_size-2": 74,
        "unique-2": 74,
        "entropy-2": 6.2094533656289554,
        "cond_entropy-2": 0.420738815714857,
        "distinct-3": 1.0,
        "vocab_size-3": 70,
        "unique-3": 70,
        "entropy-3": 6.129283016944973,
        "cond_entropy-3": -0.08017034868398337,
        "total_length-nopunct": 69,
        "mean_pred_length-nopunct": 17.25,
        "std_pred_length-nopunct": 3.2691742076555053,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8115942028985508,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.644756340836136,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 65,
        "unique-2-nopunct": 65,
        "entropy-2-nopunct": 6.022367813028458,
        "cond_entropy-2-nopunct": 0.4061510485579777,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 61,
        "unique-3-nopunct": 61,
        "entropy-3-nopunct": 5.930737337562883,
        "cond_entropy-3-nopunct": -0.09163047546556848,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.6962795687283965,
        "bleu": 54.36956,
        "rouge1": {
            "precision": 0.83472,
            "recall": 0.78788,
            "fmeasure": 0.80797
        },
        "rouge2": {
            "precision": 0.58802,
            "recall": 0.57016,
            "fmeasure": 0.57771
        },
        "rougeL": {
            "precision": 0.72083,
            "recall": 0.68617,
            "fmeasure": 0.70084
        },
        "rougeLsum": {
            "precision": 0.72083,
            "recall": 0.68617,
            "fmeasure": 0.70084
        },
        "local_recall": {
            "1": 0.16,
            "2": 0.9,
            "3": 0.8333333333333334
        },
        "bertscore": {
            "precision": 0.94941,
            "recall": 0.94992,
            "f1": 0.9488
        },
        "bleurt": 0.39268,
        "meteor": 0.4646247820948649,
        "nubia": {
            "semantic_relation": 4.35416,
            "contradiction": 3.87125,
            "irrelevancy": 47.60874,
            "logical_agreement": 48.52002,
            "grammar_ref": 4.35502,
            "grammar_hyp": 4.54087,
            "nubia_score": 0.73231
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_429": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 12.666666666666666,
        "std_pred_length": 4.784233364802441,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 17,
        "distinct-1": 0.8157894736842105,
        "vocab_size-1": 31,
        "unique-1": 26,
        "entropy-1": 4.83977553964551,
        "distinct-2": 0.9714285714285714,
        "vocab_size-2": 34,
        "unique-2": 33,
        "entropy-2": 5.072140159802107,
        "cond_entropy-2": 0.13149514642033722,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.06678301694496638,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 4.242640687119285,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8787878787878788,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.779094498080775,
        "distinct-2-nopunct": 0.9666666666666667,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.840223928941852,
        "cond_entropy-2-nopunct": 0.08765939298884756,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.07792901937097599,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9755792254832487,
        "bleu": 28.68123,
        "rouge1": {
            "precision": 0.80159,
            "recall": 0.8049,
            "fmeasure": 0.77622
        },
        "rouge2": {
            "precision": 0.51197,
            "recall": 0.45503,
            "fmeasure": 0.4605
        },
        "rougeL": {
            "precision": 0.63004,
            "recall": 0.6011,
            "fmeasure": 0.59212
        },
        "rougeLsum": {
            "precision": 0.63004,
            "recall": 0.6011,
            "fmeasure": 0.59212
        },
        "local_recall": {
            "1": 0.6,
            "2": 0.16666666666666666,
            "3": 0.8181818181818182
        },
        "bertscore": {
            "precision": 0.92855,
            "recall": 0.91888,
            "f1": 0.92326
        },
        "bleurt": -0.13873,
        "meteor": 0.39278166770517664,
        "nubia": {
            "semantic_relation": 3.67208,
            "contradiction": 6.8852,
            "irrelevancy": 32.45098,
            "logical_agreement": 60.66382,
            "grammar_ref": 5.1114,
            "grammar_hyp": 4.82324,
            "nubia_score": 0.58071
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_456": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 3.5,
        "median_pred_length": 14.5,
        "min_pred_length": 11,
        "max_pred_length": 18,
        "distinct-1": 0.7241379310344828,
        "vocab_size-1": 21,
        "unique-1": 16,
        "entropy-1": 4.181786496009061,
        "distinct-2": 0.9259259259259259,
        "vocab_size-2": 25,
        "unique-2": 23,
        "entropy-2": 4.606739354015323,
        "cond_entropy-2": 0.4009672653483712,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": 0.04896868761125605,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7407407407407407,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.102678595702847,
        "distinct-2-nopunct": 0.92,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.4838561897747224,
        "cond_entropy-2-nopunct": 0.4333543065887286,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": 0.05361880976054911,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.465908221010026,
        "bleu": 39.92538,
        "rouge1": {
            "precision": 0.80294,
            "recall": 0.91154,
            "fmeasure": 0.85
        },
        "rouge2": {
            "precision": 0.56597,
            "recall": 0.63889,
            "fmeasure": 0.59585
        },
        "rougeL": {
            "precision": 0.76373,
            "recall": 0.86026,
            "fmeasure": 0.80556
        },
        "rougeLsum": {
            "precision": 0.76373,
            "recall": 0.86026,
            "fmeasure": 0.80556
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.95512,
            "recall": 0.95247,
            "f1": 0.95379
        },
        "bleurt": 0.55086,
        "meteor": 0.45984765979970293,
        "nubia": {
            "semantic_relation": 4.74082,
            "contradiction": 2.83489,
            "irrelevancy": 9.34192,
            "logical_agreement": 87.82318,
            "grammar_ref": 3.96214,
            "grammar_hyp": 3.67241,
            "nubia_score": 0.85273
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_366": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 52,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 6.342099196813483,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 26,
        "distinct-1": 0.8653846153846154,
        "vocab_size-1": 45,
        "unique-1": 41,
        "entropy-1": 5.3782303430994896,
        "distinct-2": 1.0,
        "vocab_size-2": 49,
        "unique-2": 49,
        "entropy-2": 5.614709844115208,
        "cond_entropy-2": 0.15916808515778993,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": -0.09114788805819536,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 5.436502143433364,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8936170212765957,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.299269702741469,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.4594316186372955,
        "cond_entropy-2-nopunct": 0.17757003968693236,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.10187961401921372,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.457434441757827,
        "bleu": 50.87131,
        "rouge1": {
            "precision": 0.84603,
            "recall": 0.78366,
            "fmeasure": 0.80365
        },
        "rouge2": {
            "precision": 0.65375,
            "recall": 0.60079,
            "fmeasure": 0.61734
        },
        "rougeL": {
            "precision": 0.72698,
            "recall": 0.66824,
            "fmeasure": 0.68632
        },
        "rougeLsum": {
            "precision": 0.72698,
            "recall": 0.66824,
            "fmeasure": 0.68632
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.4,
            "3": 0.8285714285714286
        },
        "bertscore": {
            "precision": 0.93568,
            "recall": 0.94113,
            "f1": 0.93825
        },
        "bleurt": 0.22287,
        "meteor": 0.443021310081185,
        "nubia": {
            "semantic_relation": 4.5222,
            "contradiction": 1.35881,
            "irrelevancy": 11.75748,
            "logical_agreement": 86.88371,
            "grammar_ref": 5.35172,
            "grammar_hyp": 5.07823,
            "nubia_score": 0.79369
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_399": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1975130101153098,
        "bleu": 49.47995,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rouge2": {
            "precision": 0.63636,
            "recall": 0.7,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.72727,
            "fmeasure": 0.69565
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.72727,
            "fmeasure": 0.69565
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "bertscore": {
            "precision": 0.88044,
            "recall": 0.93027,
            "f1": 0.90467
        },
        "bleurt": 0.30288,
        "meteor": 0.4618659327219916,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.10882,
            "irrelevancy": 95.57685,
            "logical_agreement": 4.31433,
            "grammar_ref": 4.20968,
            "grammar_hyp": 3.88261,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_459": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 5.5,
        "median_pred_length": 17.5,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.7714285714285715,
        "vocab_size-1": 27,
        "unique-1": 20,
        "entropy-1": 4.65057194545458,
        "distinct-2": 0.9696969696969697,
        "vocab_size-2": 32,
        "unique-2": 31,
        "entropy-2": 4.9837880587523955,
        "cond_entropy-2": 0.3016228449032889,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.025681679939320093,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.481727678869737,
        "distinct-2-nopunct": 0.9642857142857143,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.735926350629034,
        "cond_entropy-2-nopunct": 0.24885316581206662,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.02999212699343525,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.2554159741812,
        "bleu": 90.71221,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.90455,
            "fmeasure": 0.94987
        },
        "rouge2": {
            "precision": 0.91503,
            "recall": 0.82105,
            "fmeasure": 0.8655
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.90455,
            "fmeasure": 0.94987
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.90455,
            "fmeasure": 0.94987
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.9583333333333334
        },
        "bertscore": {
            "precision": 0.99403,
            "recall": 0.98475,
            "f1": 0.98936
        },
        "bleurt": 0.79193,
        "meteor": 0.5473198792718016,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.51628,
            "irrelevancy": 0.65538,
            "logical_agreement": 98.82834,
            "grammar_ref": 3.53925,
            "grammar_hyp": 3.52589,
            "nubia_score": 0.98378
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_496": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 61,
        "mean_pred_length": 20.333333333333332,
        "std_pred_length": 4.109609335312651,
        "median_pred_length": 21.0,
        "min_pred_length": 15,
        "max_pred_length": 25,
        "distinct-1": 0.7540983606557377,
        "vocab_size-1": 46,
        "unique-1": 37,
        "entropy-1": 5.348609878475558,
        "distinct-2": 0.9827586206896551,
        "vocab_size-2": 57,
        "unique-2": 56,
        "entropy-2": 5.823498236506881,
        "cond_entropy-2": 0.4230175800157798,
        "distinct-3": 1.0,
        "vocab_size-3": 55,
        "unique-3": 55,
        "entropy-3": 5.7813597135246555,
        "cond_entropy-3": -0.04025764523927595,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 18.666666666666668,
        "std_pred_length-nopunct": 3.39934634239519,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7678571428571429,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.258160502376118,
        "distinct-2-nopunct": 0.9811320754716981,
        "vocab_size-2-nopunct": 52,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 5.690184605506592,
        "cond_entropy-2-nopunct": 0.46311057971622627,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.643856189774728,
        "cond_entropy-3-nopunct": -0.0440642647884745,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.898719118026372,
        "bleu": 52.74644,
        "rouge1": {
            "precision": 0.74846,
            "recall": 0.79963,
            "fmeasure": 0.77251
        },
        "rouge2": {
            "precision": 0.53795,
            "recall": 0.58108,
            "fmeasure": 0.55818
        },
        "rougeL": {
            "precision": 0.57122,
            "recall": 0.61815,
            "fmeasure": 0.59324
        },
        "rougeLsum": {
            "precision": 0.57122,
            "recall": 0.61815,
            "fmeasure": 0.59324
        },
        "local_recall": {
            "1": 0.6,
            "2": 0.16666666666666666,
            "3": 0.8095238095238095
        },
        "bertscore": {
            "precision": 0.93871,
            "recall": 0.9498,
            "f1": 0.94408
        },
        "bleurt": 0.42493,
        "meteor": 0.4622647681248007,
        "nubia": {
            "semantic_relation": 4.73664,
            "contradiction": 1.04231,
            "irrelevancy": 63.42618,
            "logical_agreement": 35.53152,
            "grammar_ref": 4.0888,
            "grammar_hyp": 3.98103,
            "nubia_score": 0.90036
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_368": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.78,
        "msttr-100_nopunct": 0.8,
        "total_length": 119,
        "mean_pred_length": 17.0,
        "std_pred_length": 6.0,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.7394957983193278,
        "vocab_size-1": 88,
        "unique-1": 78,
        "entropy-1": 6.1011583349560565,
        "distinct-2": 0.9642857142857143,
        "vocab_size-2": 108,
        "unique-2": 105,
        "entropy-2": 6.729186283645419,
        "cond_entropy-2": 0.5021719803327656,
        "distinct-3": 0.9904761904761905,
        "vocab_size-3": 104,
        "unique-3": 103,
        "entropy-3": 6.695197898618494,
        "cond_entropy-3": -0.02877714246611547,
        "total_length-nopunct": 107,
        "mean_pred_length-nopunct": 15.285714285714286,
        "std_pred_length-nopunct": 5.495824017620384,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7850467289719626,
        "vocab_size-1-nopunct": 84,
        "unique-1-nopunct": 76,
        "entropy-1-nopunct": 6.086895958202002,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 96,
        "unique-2-nopunct": 93,
        "entropy-2-nopunct": 6.556307314753104,
        "cond_entropy-2-nopunct": 0.5152313285250201,
        "distinct-3-nopunct": 0.989247311827957,
        "vocab_size-3-nopunct": 92,
        "unique-3-nopunct": 91,
        "entropy-3-nopunct": 6.51765343476395,
        "cond_entropy-3-nopunct": -0.03206417971869934,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.9545321721131526,
        "bleu": 57.63977,
        "rouge1": {
            "precision": 0.81224,
            "recall": 0.86039,
            "fmeasure": 0.83096
        },
        "rouge2": {
            "precision": 0.6226,
            "recall": 0.68298,
            "fmeasure": 0.64504
        },
        "rougeL": {
            "precision": 0.73641,
            "recall": 0.79645,
            "fmeasure": 0.75881
        },
        "rougeLsum": {
            "precision": 0.73641,
            "recall": 0.79645,
            "fmeasure": 0.75881
        },
        "local_recall": {
            "1": 0.21212121212121213,
            "2": 0.4,
            "3": 0.935064935064935
        },
        "bertscore": {
            "precision": 0.94926,
            "recall": 0.95596,
            "f1": 0.9508
        },
        "bleurt": 0.50799,
        "meteor": 0.48418105150962165,
        "nubia": {
            "semantic_relation": 4.47521,
            "contradiction": 2.75705,
            "irrelevancy": 27.98433,
            "logical_agreement": 69.25863,
            "grammar_ref": 4.94315,
            "grammar_hyp": 4.62669,
            "nubia_score": 0.83493
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_430": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.72,
        "msttr-100_nopunct": NaN,
        "total_length": 115,
        "mean_pred_length": 14.375,
        "std_pred_length": 6.243746871871088,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.7043478260869566,
        "vocab_size-1": 81,
        "unique-1": 64,
        "entropy-1": 6.048520620906097,
        "distinct-2": 0.9345794392523364,
        "vocab_size-2": 100,
        "unique-2": 93,
        "entropy-2": 6.610625864905812,
        "cond_entropy-2": 0.39739267802128797,
        "distinct-3": 0.9696969696969697,
        "vocab_size-3": 96,
        "unique-3": 93,
        "entropy-3": 6.56875055947356,
        "cond_entropy-3": -0.03130228551345663,
        "total_length-nopunct": 99,
        "mean_pred_length-nopunct": 12.375,
        "std_pred_length-nopunct": 4.871793817476269,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7878787878787878,
        "vocab_size-1-nopunct": 78,
        "unique-1-nopunct": 63,
        "entropy-1-nopunct": 6.144508135231134,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 77,
        "entropy-2-nopunct": 6.353948486352548,
        "cond_entropy-2-nopunct": 0.2520643937454604,
        "distinct-3-nopunct": 0.963855421686747,
        "vocab_size-3-nopunct": 80,
        "unique-3-nopunct": 77,
        "entropy-3-nopunct": 6.302750274720426,
        "cond_entropy-3-nopunct": -0.036369666683096664,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.938503235975633,
        "bleu": 70.54579,
        "rouge1": {
            "precision": 0.95312,
            "recall": 0.85156,
            "fmeasure": 0.89205
        },
        "rouge2": {
            "precision": 0.87479,
            "recall": 0.79491,
            "fmeasure": 0.82635
        },
        "rougeL": {
            "precision": 0.92188,
            "recall": 0.83092,
            "fmeasure": 0.86729
        },
        "rougeLsum": {
            "precision": 0.92188,
            "recall": 0.83092,
            "fmeasure": 0.86729
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8584905660377359
        },
        "bertscore": {
            "precision": 0.97862,
            "recall": 0.9527,
            "f1": 0.96481
        },
        "bleurt": 0.62227,
        "meteor": 0.4967723100056429,
        "nubia": {
            "semantic_relation": 4.43968,
            "contradiction": 1.02325,
            "irrelevancy": 4.37496,
            "logical_agreement": 94.6018,
            "grammar_ref": 5.14689,
            "grammar_hyp": 5.24711,
            "nubia_score": 0.80777
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_498": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.1375509032153534,
        "bleu": 6.63816,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.27561,
            "fmeasure": 0.38996
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.16032,
            "fmeasure": 0.23153
        },
        "rougeL": {
            "precision": 0.40741,
            "recall": 0.16883,
            "fmeasure": 0.23871
        },
        "rougeLsum": {
            "precision": 0.40741,
            "recall": 0.16883,
            "fmeasure": 0.23871
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.25,
            "3": 0.21428571428571427
        },
        "bertscore": {
            "precision": 0.87011,
            "recall": 0.72529,
            "f1": 0.79113
        },
        "bleurt": -0.97714,
        "meteor": 0.15481429865007057,
        "nubia": {
            "semantic_relation": 2.51898,
            "contradiction": 0.21951,
            "irrelevancy": 75.2903,
            "logical_agreement": 24.4902,
            "grammar_ref": 4.70322,
            "grammar_hyp": 7.31316,
            "nubia_score": 0.09564
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_369": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 11.75,
        "std_pred_length": 1.479019945774904,
        "median_pred_length": 11.5,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.6595744680851063,
        "vocab_size-1": 31,
        "unique-1": 22,
        "entropy-1": 4.740447096220397,
        "distinct-2": 0.8372093023255814,
        "vocab_size-2": 36,
        "unique-2": 30,
        "entropy-2": 5.083127836047133,
        "cond_entropy-2": 0.2323683449855521,
        "distinct-3": 0.9230769230769231,
        "vocab_size-3": 36,
        "unique-3": 33,
        "entropy-3": 5.131556065016094,
        "cond_entropy-3": 0.08362175908741874,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 1.6583123951777,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.6904761904761905,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.671730220243275,
        "distinct-2-nopunct": 0.8157894736842105,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.859641000228759,
        "cond_entropy-2-nopunct": 0.23744627498921828,
        "distinct-3-nopunct": 0.9117647058823529,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.910992253015044,
        "cond_entropy-3-nopunct": 0.06762025434097352,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.168766950987358,
        "bleu": 45.73683,
        "rouge1": {
            "precision": 0.81494,
            "recall": 0.763,
            "fmeasure": 0.77237
        },
        "rouge2": {
            "precision": 0.63958,
            "recall": 0.55567,
            "fmeasure": 0.57937
        },
        "rougeL": {
            "precision": 0.7487,
            "recall": 0.69196,
            "fmeasure": 0.70478
        },
        "rougeLsum": {
            "precision": 0.7487,
            "recall": 0.69196,
            "fmeasure": 0.70478
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.2727272727272727,
            "3": 0.8611111111111112
        },
        "bertscore": {
            "precision": 0.947,
            "recall": 0.94002,
            "f1": 0.94218
        },
        "bleurt": 0.4425,
        "meteor": 0.422488253352417,
        "nubia": {
            "semantic_relation": 4.40378,
            "contradiction": 0.36727,
            "irrelevancy": 14.66612,
            "logical_agreement": 84.9666,
            "grammar_ref": 5.27719,
            "grammar_hyp": 5.12942,
            "nubia_score": 0.81181
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_370": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.72,
        "msttr-100_nopunct": NaN,
        "total_length": 106,
        "mean_pred_length": 15.142857142857142,
        "std_pred_length": 1.9587584572574412,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.7169811320754716,
        "vocab_size-1": 76,
        "unique-1": 64,
        "entropy-1": 5.959751379419598,
        "distinct-2": 0.9595959595959596,
        "vocab_size-2": 95,
        "unique-2": 92,
        "entropy-2": 6.540923412987058,
        "cond_entropy-2": 0.43698717570483353,
        "distinct-3": 0.9891304347826086,
        "vocab_size-3": 91,
        "unique-3": 90,
        "entropy-3": 6.501822825622244,
        "cond_entropy-3": -0.03237197378168939,
        "total_length-nopunct": 92,
        "mean_pred_length-nopunct": 13.142857142857142,
        "std_pred_length-nopunct": 1.2453996981544782,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7717391304347826,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 5.925523369006437,
        "distinct-2-nopunct": 0.9529411764705882,
        "vocab_size-2-nopunct": 81,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.306392259641666,
        "cond_entropy-2-nopunct": 0.43011912721587037,
        "distinct-3-nopunct": 0.9871794871794872,
        "vocab_size-3-nopunct": 77,
        "unique-3-nopunct": 76,
        "entropy-3-nopunct": 6.25976119322123,
        "cond_entropy-3-nopunct": -0.03738759545284465,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.957299413862522,
        "bleu": 60.83671,
        "rouge1": {
            "precision": 0.90739,
            "recall": 0.85125,
            "fmeasure": 0.87496
        },
        "rouge2": {
            "precision": 0.69407,
            "recall": 0.65724,
            "fmeasure": 0.67252
        },
        "rougeL": {
            "precision": 0.78715,
            "recall": 0.74415,
            "fmeasure": 0.76226
        },
        "rougeLsum": {
            "precision": 0.78715,
            "recall": 0.74415,
            "fmeasure": 0.76226
        },
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.16666666666666666,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.97891,
            "recall": 0.97152,
            "f1": 0.9751
        },
        "bleurt": 0.59656,
        "meteor": 0.45739150409320717,
        "nubia": {
            "semantic_relation": 4.7099,
            "contradiction": 2.08343,
            "irrelevancy": 5.79761,
            "logical_agreement": 92.11895,
            "grammar_ref": 4.9924,
            "grammar_hyp": 5.29188,
            "nubia_score": 0.85285
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_432": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 88,
        "mean_pred_length": 17.6,
        "std_pred_length": 9.891410415102591,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 35,
        "distinct-1": 0.7159090909090909,
        "vocab_size-1": 63,
        "unique-1": 53,
        "entropy-1": 5.686522386466808,
        "distinct-2": 0.9759036144578314,
        "vocab_size-2": 81,
        "unique-2": 79,
        "entropy-2": 6.326846660262595,
        "cond_entropy-2": 0.5470098844754908,
        "distinct-3": 1.0,
        "vocab_size-3": 78,
        "unique-3": 78,
        "entropy-3": 6.285402218862257,
        "cond_entropy-3": -0.06399618684365069,
        "total_length-nopunct": 70,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 7.238784428341543,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8142857142857143,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.61997609616778,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 65,
        "unique-2-nopunct": 65,
        "entropy-2-nopunct": 6.022367813028458,
        "cond_entropy-2-nopunct": 0.4415691723050761,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 60,
        "unique-3-nopunct": 60,
        "entropy-3-nopunct": 5.906890595608517,
        "cond_entropy-3-nopunct": -0.11547721741993579,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.661129933148911,
        "bleu": 56.93364,
        "rouge1": {
            "precision": 0.919,
            "recall": 0.73887,
            "fmeasure": 0.81497
        },
        "rouge2": {
            "precision": 0.7664,
            "recall": 0.62237,
            "fmeasure": 0.68288
        },
        "rougeL": {
            "precision": 0.7638,
            "recall": 0.62308,
            "fmeasure": 0.68239
        },
        "rougeLsum": {
            "precision": 0.7638,
            "recall": 0.62308,
            "fmeasure": 0.68239
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.125,
            "3": 0.7662337662337663
        },
        "bertscore": {
            "precision": 0.96827,
            "recall": 0.94207,
            "f1": 0.95494
        },
        "bleurt": 0.49544,
        "meteor": 0.4272483136231518,
        "nubia": {
            "semantic_relation": 4.47215,
            "contradiction": 2.87416,
            "irrelevancy": 8.05949,
            "logical_agreement": 89.06636,
            "grammar_ref": 4.65184,
            "grammar_hyp": 4.97374,
            "nubia_score": 0.80724
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_460": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 59,
        "mean_pred_length": 14.75,
        "std_pred_length": 4.656984002549289,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.7627118644067796,
        "vocab_size-1": 45,
        "unique-1": 37,
        "entropy-1": 5.314680761152906,
        "distinct-2": 0.8909090909090909,
        "vocab_size-2": 49,
        "unique-2": 44,
        "entropy-2": 5.549452668030774,
        "cond_entropy-2": 0.13062370965669967,
        "distinct-3": 0.9411764705882353,
        "vocab_size-3": 48,
        "unique-3": 45,
        "entropy-3": 5.55477828314797,
        "cond_entropy-3": 0.023514402999060872,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 4.06201920231798,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7884615384615384,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.209867121904038,
        "distinct-2-nopunct": 0.875,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.319235677759421,
        "cond_entropy-2-nopunct": 0.11722955344344557,
        "distinct-3-nopunct": 0.9318181818181818,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.323067982273659,
        "cond_entropy-3-nopunct": 0.027989288419856116,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.1973283495828335,
        "bleu": 83.48706,
        "rouge1": {
            "precision": 0.90625,
            "recall": 0.94231,
            "fmeasure": 0.92241
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.89583,
            "fmeasure": 0.87963
        },
        "rougeL": {
            "precision": 0.90625,
            "recall": 0.94231,
            "fmeasure": 0.92241
        },
        "rougeLsum": {
            "precision": 0.90625,
            "recall": 0.94231,
            "fmeasure": 0.92241
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9387755102040817
        },
        "bertscore": {
            "precision": 0.98222,
            "recall": 0.98973,
            "f1": 0.98592
        },
        "bleurt": 0.93252,
        "meteor": 0.6278177294276763,
        "nubia": {
            "semantic_relation": 4.98481,
            "contradiction": 0.21704,
            "irrelevancy": 12.58312,
            "logical_agreement": 87.19984,
            "grammar_ref": 5.0449,
            "grammar_hyp": 4.86298,
            "nubia_score": 0.99912
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_434": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 0.5,
        "median_pred_length": 14.5,
        "min_pred_length": 14,
        "max_pred_length": 15,
        "distinct-1": 0.896551724137931,
        "vocab_size-1": 26,
        "unique-1": 23,
        "entropy-1": 4.651084443403434,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.045054655184044716,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.92,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.4838561897747224,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.05361880976054911,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1459233373537883,
        "bleu": 13.92252,
        "rouge1": {
            "precision": 0.61026,
            "recall": 0.74847,
            "fmeasure": 0.6696
        },
        "rouge2": {
            "precision": 0.3254,
            "recall": 0.41404,
            "fmeasure": 0.36306
        },
        "rougeL": {
            "precision": 0.43162,
            "recall": 0.53276,
            "fmeasure": 0.47518
        },
        "rougeLsum": {
            "precision": 0.43162,
            "recall": 0.53276,
            "fmeasure": 0.47518
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.8469,
            "recall": 0.90807,
            "f1": 0.87624
        },
        "bleurt": -0.08139,
        "meteor": 0.36376021366960215,
        "nubia": {
            "semantic_relation": 3.57927,
            "contradiction": 0.27719,
            "irrelevancy": 75.26086,
            "logical_agreement": 24.46195,
            "grammar_ref": 4.76014,
            "grammar_hyp": 4.67049,
            "nubia_score": 0.53509
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_371": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.1365257343456969,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966058,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.992592389176222,
        "bleu": 22.01225,
        "rouge1": {
            "precision": 0.58824,
            "recall": 0.71795,
            "fmeasure": 0.64583
        },
        "rouge2": {
            "precision": 0.34375,
            "recall": 0.42262,
            "fmeasure": 0.37857
        },
        "rougeL": {
            "precision": 0.32353,
            "recall": 0.40256,
            "fmeasure": 0.35833
        },
        "rougeLsum": {
            "precision": 0.32353,
            "recall": 0.40256,
            "fmeasure": 0.35833
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.7272727272727273
        },
        "bertscore": {
            "precision": 0.85432,
            "recall": 0.84473,
            "f1": 0.8495
        },
        "bleurt": 0.02311,
        "meteor": 0.3927973725881091,
        "nubia": {
            "semantic_relation": 3.60112,
            "contradiction": 0.11638,
            "irrelevancy": 99.76884,
            "logical_agreement": 0.11479,
            "grammar_ref": 4.56931,
            "grammar_hyp": 3.56356,
            "nubia_score": 0.70088
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_462": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 96,
        "mean_pred_length": 24.0,
        "std_pred_length": 8.602325267042627,
        "median_pred_length": 25.0,
        "min_pred_length": 12,
        "max_pred_length": 34,
        "distinct-1": 0.78125,
        "vocab_size-1": 75,
        "unique-1": 65,
        "entropy-1": 6.019705599611885,
        "distinct-2": 0.967391304347826,
        "vocab_size-2": 89,
        "unique-2": 86,
        "entropy-2": 6.458344564752679,
        "cond_entropy-2": 0.37625883040640473,
        "distinct-3": 1.0,
        "vocab_size-3": 88,
        "unique-3": 88,
        "entropy-3": 6.459431618637305,
        "cond_entropy-3": 0.004051480762102636,
        "total_length-nopunct": 84,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 8.276472678623424,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.8452380952380952,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 63,
        "entropy-1-nopunct": 6.026187809657766,
        "distinct-2-nopunct": 0.9625,
        "vocab_size-2-nopunct": 77,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.246928094887356,
        "cond_entropy-2-nopunct": 0.22654676588564532,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 76,
        "unique-3-nopunct": 76,
        "entropy-3-nopunct": 6.247927513443591,
        "cond_entropy-3-nopunct": -0.008211107759566242,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.813140315223503,
        "bleu": 40.92377,
        "rouge1": {
            "precision": 0.77316,
            "recall": 0.75856,
            "fmeasure": 0.76404
        },
        "rouge2": {
            "precision": 0.56502,
            "recall": 0.55566,
            "fmeasure": 0.55907
        },
        "rougeL": {
            "precision": 0.64463,
            "recall": 0.63422,
            "fmeasure": 0.63803
        },
        "rougeLsum": {
            "precision": 0.64463,
            "recall": 0.63422,
            "fmeasure": 0.63803
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.8055555555555556
        },
        "bertscore": {
            "precision": 0.93833,
            "recall": 0.9259,
            "f1": 0.93202
        },
        "bleurt": 0.38266,
        "meteor": 0.3548234016920826,
        "nubia": {
            "semantic_relation": 4.06093,
            "contradiction": 44.68673,
            "irrelevancy": 20.27683,
            "logical_agreement": 35.03643,
            "grammar_ref": 4.59177,
            "grammar_hyp": 4.03886,
            "nubia_score": 0.73201
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_372": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 46,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 5.557777333511022,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.8913043478260869,
        "vocab_size-1": 41,
        "unique-1": 37,
        "entropy-1": 5.289760053836066,
        "distinct-2": 1.0,
        "vocab_size-2": 43,
        "unique-2": 43,
        "entropy-2": 5.426264754702098,
        "cond_entropy-2": 0.042237682366015064,
        "distinct-3": 1.0,
        "vocab_size-3": 40,
        "unique-3": 40,
        "entropy-3": 5.3219280948873635,
        "cond_entropy-3": -0.1043366598147359,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 4.96655480858378,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.131556065016093,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.1699250014423095,
        "cond_entropy-2-nopunct": 0.05118944924673087,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.310079769003258,
        "bleu": 59.36504,
        "rouge1": {
            "precision": 0.82222,
            "recall": 0.72132,
            "fmeasure": 0.75692
        },
        "rouge2": {
            "precision": 0.60185,
            "recall": 0.56157,
            "fmeasure": 0.57528
        },
        "rougeL": {
            "precision": 0.71481,
            "recall": 0.64755,
            "fmeasure": 0.67128
        },
        "rougeLsum": {
            "precision": 0.71481,
            "recall": 0.64755,
            "fmeasure": 0.67128
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.46153846153846156,
            "3": 0.9629629629629629
        },
        "bertscore": {
            "precision": 0.92081,
            "recall": 0.90825,
            "f1": 0.91352
        },
        "bleurt": 0.3199,
        "meteor": 0.43709395004554263,
        "nubia": {
            "semantic_relation": 4.4985,
            "contradiction": 24.04554,
            "irrelevancy": 3.96767,
            "logical_agreement": 71.98679,
            "grammar_ref": 4.97796,
            "grammar_hyp": 6.06551,
            "nubia_score": 0.69948
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_400": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.8,
        "msttr-100_nopunct": 0.79,
        "total_length": 159,
        "mean_pred_length": 15.9,
        "std_pred_length": 7.23118247591637,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.7169811320754716,
        "vocab_size-1": 114,
        "unique-1": 95,
        "entropy-1": 6.518199251770868,
        "distinct-2": 0.9664429530201343,
        "vocab_size-2": 144,
        "unique-2": 139,
        "entropy-2": 7.1520544265024375,
        "cond_entropy-2": 0.4642414571896666,
        "distinct-3": 0.9784172661870504,
        "vocab_size-3": 136,
        "unique-3": 133,
        "entropy-3": 7.075775605097623,
        "cond_entropy-3": -0.07145046932138795,
        "total_length-nopunct": 142,
        "mean_pred_length-nopunct": 14.2,
        "std_pred_length-nopunct": 6.838128398911504,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.7746478873239436,
        "vocab_size-1-nopunct": 110,
        "unique-1-nopunct": 93,
        "entropy-1-nopunct": 6.575621855875598,
        "distinct-2-nopunct": 0.9621212121212122,
        "vocab_size-2-nopunct": 127,
        "unique-2-nopunct": 122,
        "entropy-2-nopunct": 6.9686365436008675,
        "cond_entropy-2-nopunct": 0.41692597663111375,
        "distinct-3-nopunct": 0.9754098360655737,
        "vocab_size-3-nopunct": 119,
        "unique-3-nopunct": 116,
        "entropy-3-nopunct": 6.881557009694049,
        "cond_entropy-3-nopunct": -0.08906661786114127,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.5395062421233785,
        "bleu": 48.27755,
        "rouge1": {
            "precision": 0.77984,
            "recall": 0.75145,
            "fmeasure": 0.73258
        },
        "rouge2": {
            "precision": 0.54802,
            "recall": 0.4933,
            "fmeasure": 0.5027
        },
        "rougeL": {
            "precision": 0.68891,
            "recall": 0.62695,
            "fmeasure": 0.63358
        },
        "rougeLsum": {
            "precision": 0.68891,
            "recall": 0.62695,
            "fmeasure": 0.63358
        },
        "local_recall": {
            "1": 0.21739130434782608,
            "2": 0.7037037037037037,
            "3": 0.7789473684210526
        },
        "bertscore": {
            "precision": 0.93485,
            "recall": 0.92478,
            "f1": 0.92829
        },
        "bleurt": 0.37283,
        "meteor": 0.4143671353550882,
        "nubia": {
            "semantic_relation": 4.38517,
            "contradiction": 0.37848,
            "irrelevancy": 28.49115,
            "logical_agreement": 71.13037,
            "grammar_ref": 5.10223,
            "grammar_hyp": 5.31453,
            "nubia_score": 0.72894
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_528": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 7.0,
        "median_pred_length": 19.0,
        "min_pred_length": 12,
        "max_pred_length": 26,
        "distinct-1": 0.7894736842105263,
        "vocab_size-1": 30,
        "unique-1": 22,
        "entropy-1": 4.826874881864638,
        "distinct-2": 0.8611111111111112,
        "vocab_size-2": 31,
        "unique-2": 26,
        "entropy-2": 4.892147223664533,
        "cond_entropy-2": 0.033108599109837954,
        "distinct-3": 0.9117647058823529,
        "vocab_size-3": 31,
        "unique-3": 28,
        "entropy-3": 4.910992253015044,
        "cond_entropy-3": 0.03518489863155644,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 7.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7878787878787878,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.620151695116031,
        "distinct-2-nopunct": 0.8387096774193549,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.631615665225586,
        "cond_entropy-2-nopunct": 0.0065763845768089454,
        "distinct-3-nopunct": 0.896551724137931,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.651084443403434,
        "cond_entropy-3-nopunct": 0.0072329606027659935,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5773802397961703,
        "bleu": 40.78527,
        "rouge1": {
            "precision": 0.80303,
            "recall": 0.75758,
            "fmeasure": 0.77758
        },
        "rouge2": {
            "precision": 0.63492,
            "recall": 0.61376,
            "fmeasure": 0.62302
        },
        "rougeL": {
            "precision": 0.7197,
            "recall": 0.68427,
            "fmeasure": 0.7
        },
        "rougeLsum": {
            "precision": 0.7197,
            "recall": 0.68427,
            "fmeasure": 0.7
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.6923076923076923
        },
        "bertscore": {
            "precision": 0.90645,
            "recall": 0.90288,
            "f1": 0.90341
        },
        "bleurt": 0.18896,
        "meteor": 0.32797499975673094,
        "nubia": {
            "semantic_relation": 4.00284,
            "contradiction": 23.97549,
            "irrelevancy": 14.2684,
            "logical_agreement": 61.75612,
            "grammar_ref": 4.36539,
            "grammar_hyp": 3.98839,
            "nubia_score": 0.73006
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_529": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432272,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9778957842950224,
        "bleu": 22.82484,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.71667,
            "fmeasure": 0.68889
        },
        "rouge2": {
            "precision": 0.2963,
            "recall": 0.31746,
            "fmeasure": 0.30556
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.71667,
            "fmeasure": 0.68889
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.71667,
            "fmeasure": 0.68889
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.92132,
            "recall": 0.92079,
            "f1": 0.91622
        },
        "bleurt": 0.41278,
        "meteor": 0.34272262745996446,
        "nubia": {
            "semantic_relation": 4.17196,
            "contradiction": 0.3361,
            "irrelevancy": 10.00749,
            "logical_agreement": 89.65641,
            "grammar_ref": 5.68329,
            "grammar_hyp": 5.16124,
            "nubia_score": 0.75011
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_402": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 69,
        "mean_pred_length": 23.0,
        "std_pred_length": 6.48074069840786,
        "median_pred_length": 26.0,
        "min_pred_length": 14,
        "max_pred_length": 29,
        "distinct-1": 0.7681159420289855,
        "vocab_size-1": 53,
        "unique-1": 44,
        "entropy-1": 5.524978623350768,
        "distinct-2": 0.9696969696969697,
        "vocab_size-2": 64,
        "unique-2": 62,
        "entropy-2": 5.983788058752401,
        "cond_entropy-2": 0.4132904959791777,
        "distinct-3": 1.0,
        "vocab_size-3": 63,
        "unique-3": 63,
        "entropy-3": 5.97727992349992,
        "cond_entropy-3": -0.003622132366473239,
        "total_length-nopunct": 60,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 4.96655480858378,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 51,
        "unique-1-nopunct": 44,
        "entropy-1-nopunct": 5.573557262275184,
        "distinct-2-nopunct": 0.9824561403508771,
        "vocab_size-2-nopunct": 56,
        "unique-2-nopunct": 55,
        "entropy-2-nopunct": 5.797802294866491,
        "cond_entropy-2-nopunct": 0.24178889224043357,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 54,
        "unique-3-nopunct": 54,
        "entropy-3-nopunct": 5.7548875021634665,
        "cond_entropy-3-nopunct": -0.04096547496423611,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.182377066013324,
        "bleu": 55.89345,
        "rouge1": {
            "precision": 0.89847,
            "recall": 0.75858,
            "fmeasure": 0.82105
        },
        "rouge2": {
            "precision": 0.69924,
            "recall": 0.59162,
            "fmeasure": 0.63922
        },
        "rougeL": {
            "precision": 0.82601,
            "recall": 0.69527,
            "fmeasure": 0.75348
        },
        "rougeLsum": {
            "precision": 0.82601,
            "recall": 0.69527,
            "fmeasure": 0.75348
        },
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.95551,
            "recall": 0.92179,
            "f1": 0.93727
        },
        "bleurt": 0.33215,
        "meteor": 0.42036841077689485,
        "nubia": {
            "semantic_relation": 4.10432,
            "contradiction": 0.38437,
            "irrelevancy": 35.05341,
            "logical_agreement": 64.56221,
            "grammar_ref": 3.87101,
            "grammar_hyp": 3.66776,
            "nubia_score": 0.75521
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_530": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 94,
        "mean_pred_length": 18.8,
        "std_pred_length": 3.370459909270543,
        "median_pred_length": 21.0,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.6063829787234043,
        "vocab_size-1": 57,
        "unique-1": 37,
        "entropy-1": 5.507741745359464,
        "distinct-2": 0.7865168539325843,
        "vocab_size-2": 70,
        "unique-2": 55,
        "entropy-2": 6.009331464625651,
        "cond_entropy-2": 0.4299559558634151,
        "distinct-3": 0.8690476190476191,
        "vocab_size-3": 73,
        "unique-3": 62,
        "entropy-3": 6.130412660873999,
        "cond_entropy-3": 0.12503369424482597,
        "total_length-nopunct": 85,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 3.286335345030997,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6352941176470588,
        "vocab_size-1-nopunct": 54,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.435344024143925,
        "distinct-2-nopunct": 0.7875,
        "vocab_size-2-nopunct": 63,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.853055907333273,
        "cond_entropy-2-nopunct": 0.4535898151889638,
        "distinct-3-nopunct": 0.88,
        "vocab_size-3-nopunct": 66,
        "unique-3-nopunct": 57,
        "entropy-3-nopunct": 5.9888186904958856,
        "cond_entropy-3-nopunct": 0.14035426233287782,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.558387865439956,
        "bleu": 70.68301,
        "rouge1": {
            "precision": 0.87123,
            "recall": 0.91157,
            "fmeasure": 0.88543
        },
        "rouge2": {
            "precision": 0.74304,
            "recall": 0.76165,
            "fmeasure": 0.74801
        },
        "rougeL": {
            "precision": 0.82873,
            "recall": 0.86731,
            "fmeasure": 0.8427
        },
        "rougeLsum": {
            "precision": 0.82873,
            "recall": 0.86731,
            "fmeasure": 0.8427
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.5714285714285714,
            "3": 0.890625
        },
        "bertscore": {
            "precision": 0.96266,
            "recall": 0.97636,
            "f1": 0.9685
        },
        "bleurt": 0.66683,
        "meteor": 0.529620560176364,
        "nubia": {
            "semantic_relation": 4.6112,
            "contradiction": 10.85201,
            "irrelevancy": 9.61284,
            "logical_agreement": 79.53514,
            "grammar_ref": 3.93665,
            "grammar_hyp": 3.58502,
            "nubia_score": 0.887
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_464": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.85,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 3.9841837197791885,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.28151981340693205,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6901165175936654,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.3347176276348775,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4107918909526207,
        "bleu": 39.67088,
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.81319,
            "fmeasure": 0.69758
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.67949,
            "fmeasure": 0.57586
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.81319,
            "fmeasure": 0.69758
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.81319,
            "fmeasure": 0.69758
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.875
        },
        "bertscore": {
            "precision": 0.9163,
            "recall": 0.97263,
            "f1": 0.94362
        },
        "bleurt": 0.42203,
        "meteor": 0.40718621833397906,
        "nubia": {
            "semantic_relation": 2.90015,
            "contradiction": 87.85394,
            "irrelevancy": 11.61692,
            "logical_agreement": 0.52915,
            "grammar_ref": 3.57757,
            "grammar_hyp": 2.90156,
            "nubia_score": 0.5017
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_531": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.978953565626596,
        "bleu": 60.06007,
        "rouge1": {
            "precision": 0.84444,
            "recall": 0.85205,
            "fmeasure": 0.83974
        },
        "rouge2": {
            "precision": 0.64286,
            "recall": 0.65,
            "fmeasure": 0.63889
        },
        "rougeL": {
            "precision": 0.68889,
            "recall": 0.82175,
            "fmeasure": 0.74199
        },
        "rougeLsum": {
            "precision": 0.68889,
            "recall": 0.82175,
            "fmeasure": 0.74199
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.93422,
            "recall": 0.96252,
            "f1": 0.93969
        },
        "bleurt": 0.39336,
        "meteor": 0.5603000267655747,
        "nubia": {
            "semantic_relation": 4.63138,
            "contradiction": 9.71338,
            "irrelevancy": 52.29425,
            "logical_agreement": 37.99237,
            "grammar_ref": 5.72031,
            "grammar_hyp": 4.93733,
            "nubia_score": 0.88443
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_403": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 49,
        "mean_pred_length": 24.5,
        "std_pred_length": 12.5,
        "median_pred_length": 24.5,
        "min_pred_length": 12,
        "max_pred_length": 37,
        "distinct-1": 0.7346938775510204,
        "vocab_size-1": 36,
        "unique-1": 28,
        "entropy-1": 4.997063670513365,
        "distinct-2": 0.9361702127659575,
        "vocab_size-2": 44,
        "unique-2": 42,
        "entropy-2": 5.41086784099331,
        "cond_entropy-2": 0.39753379488853424,
        "distinct-3": 0.9777777777777777,
        "vocab_size-3": 44,
        "unique-3": 43,
        "entropy-3": 5.447408651885229,
        "cond_entropy-3": 0.0429284113667809,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 9.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.8157894736842105,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.80700942128139,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.1699250014423095,
        "cond_entropy-2-nopunct": 0.3596332519477119,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.1969276213357567,
        "bleu": 17.32583,
        "rouge1": {
            "precision": 0.62576,
            "recall": 0.57868,
            "fmeasure": 0.58992
        },
        "rouge2": {
            "precision": 0.43621,
            "recall": 0.35157,
            "fmeasure": 0.3816
        },
        "rougeL": {
            "precision": 0.59242,
            "recall": 0.52404,
            "fmeasure": 0.54418
        },
        "rougeLsum": {
            "precision": 0.59242,
            "recall": 0.52404,
            "fmeasure": 0.54418
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5357142857142857
        },
        "bertscore": {
            "precision": 0.88397,
            "recall": 0.87111,
            "f1": 0.87477
        },
        "bleurt": -0.03348,
        "meteor": 0.2736706888247812,
        "nubia": {
            "semantic_relation": 3.24243,
            "contradiction": 47.75337,
            "irrelevancy": 45.11025,
            "logical_agreement": 7.13638,
            "grammar_ref": 3.82725,
            "grammar_hyp": 4.19194,
            "nubia_score": 0.47422
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_435": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 81,
        "mean_pred_length": 20.25,
        "std_pred_length": 7.495832175282475,
        "median_pred_length": 20.5,
        "min_pred_length": 10,
        "max_pred_length": 30,
        "distinct-1": 0.7530864197530864,
        "vocab_size-1": 61,
        "unique-1": 51,
        "entropy-1": 5.718065706877208,
        "distinct-2": 0.974025974025974,
        "vocab_size-2": 75,
        "unique-2": 73,
        "entropy-2": 6.214838488746852,
        "cond_entropy-2": 0.4251771608830072,
        "distinct-3": 1.0,
        "vocab_size-3": 73,
        "unique-3": 73,
        "entropy-3": 6.189824558880028,
        "cond_entropy-3": -0.02216746126693865,
        "total_length-nopunct": 71,
        "mean_pred_length-nopunct": 17.75,
        "std_pred_length-nopunct": 6.53356717268599,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8028169014084507,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.665739683214536,
        "distinct-2-nopunct": 0.9701492537313433,
        "vocab_size-2-nopunct": 65,
        "unique-2-nopunct": 63,
        "entropy-2-nopunct": 6.006387697920454,
        "cond_entropy-2-nopunct": 0.36954398105160213,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 63,
        "unique-3-nopunct": 63,
        "entropy-3-nopunct": 5.97727992349992,
        "cond_entropy-3-nopunct": -0.025317203465792585,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.622872503014511,
        "bleu": 40.32236,
        "rouge1": {
            "precision": 0.80003,
            "recall": 0.79017,
            "fmeasure": 0.78852
        },
        "rouge2": {
            "precision": 0.53449,
            "recall": 0.53878,
            "fmeasure": 0.5322
        },
        "rougeL": {
            "precision": 0.64445,
            "recall": 0.63361,
            "fmeasure": 0.63412
        },
        "rougeLsum": {
            "precision": 0.64445,
            "recall": 0.63361,
            "fmeasure": 0.63412
        },
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.6,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.90985,
            "recall": 0.90943,
            "f1": 0.90935
        },
        "bleurt": 0.08865,
        "meteor": 0.37302422750616815,
        "nubia": {
            "semantic_relation": 4.33771,
            "contradiction": 0.67921,
            "irrelevancy": 31.05263,
            "logical_agreement": 68.26816,
            "grammar_ref": 4.16687,
            "grammar_hyp": 4.57766,
            "nubia_score": 0.74224
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_436": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.01117167855772,
        "bleu": 100.0,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.86667,
            "fmeasure": 0.86667
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.77386,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.66362,
            "contradiction": 2.49017,
            "irrelevancy": 1.24853,
            "logical_agreement": 96.2613,
            "grammar_ref": 6.06085,
            "grammar_hyp": 5.70692,
            "nubia_score": 0.90186
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_404": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 3.5,
        "median_pred_length": 15.5,
        "min_pred_length": 12,
        "max_pred_length": 19,
        "distinct-1": 0.9354838709677419,
        "vocab_size-1": 29,
        "unique-1": 27,
        "entropy-1": 4.825164052322361,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": -0.02724979801792366,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9642857142857143,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.735926350629034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": -0.029992126993435272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.8635519527028785,
        "bleu": 60.99637,
        "rouge1": {
            "precision": 0.92593,
            "recall": 0.88871,
            "fmeasure": 0.90517
        },
        "rouge2": {
            "precision": 0.74314,
            "recall": 0.70844,
            "fmeasure": 0.72383
        },
        "rougeL": {
            "precision": 0.76094,
            "recall": 0.74733,
            "fmeasure": 0.75188
        },
        "rougeLsum": {
            "precision": 0.76094,
            "recall": 0.74733,
            "fmeasure": 0.75188
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.5,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.95098,
            "recall": 0.96026,
            "f1": 0.95351
        },
        "bleurt": 0.54177,
        "meteor": 0.5005363918384912,
        "nubia": {
            "semantic_relation": 4.88198,
            "contradiction": 0.27502,
            "irrelevancy": 19.63633,
            "logical_agreement": 80.08865,
            "grammar_ref": 4.70227,
            "grammar_hyp": 4.26107,
            "nubia_score": 0.98127
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_405": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9898332363522426,
        "bleu": 61.0195,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.99622,
            "recall": 0.98673,
            "f1": 0.99146
        },
        "bleurt": 0.83294,
        "meteor": 0.5064321156600579,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.30005,
            "irrelevancy": 0.4565,
            "logical_agreement": 99.24345,
            "grammar_ref": 4.34196,
            "grammar_hyp": 4.46114,
            "nubia_score": 0.99737
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_500": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 8.5,
        "median_pred_length": 18.5,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.8648648648648649,
        "vocab_size-1": 32,
        "unique-1": 27,
        "entropy-1": 4.939183095358683,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.14840107988744514,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.08488889758651327,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9354838709677419,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.825164052322361,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.04171571922345566,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.10309349296410335,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.939905020114009,
        "bleu": 70.44666,
        "rouge1": {
            "precision": 0.87727,
            "recall": 0.71101,
            "fmeasure": 0.78005
        },
        "rouge2": {
            "precision": 0.63492,
            "recall": 0.52043,
            "fmeasure": 0.56791
        },
        "rougeL": {
            "precision": 0.77727,
            "recall": 0.63896,
            "fmeasure": 0.69694
        },
        "rougeLsum": {
            "precision": 0.77727,
            "recall": 0.63896,
            "fmeasure": 0.69694
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.8064516129032258
        },
        "bertscore": {
            "precision": 0.96316,
            "recall": 0.93748,
            "f1": 0.94624
        },
        "bleurt": 0.30951,
        "meteor": 0.43029707005813983,
        "nubia": {
            "semantic_relation": 3.50541,
            "contradiction": 45.61437,
            "irrelevancy": 1.49551,
            "logical_agreement": 52.89012,
            "grammar_ref": 5.38335,
            "grammar_hyp": 5.92126,
            "nubia_score": 0.50161
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_406": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 16.0,
        "min_pred_length": 15,
        "max_pred_length": 16,
        "distinct-1": 0.7659574468085106,
        "vocab_size-1": 36,
        "unique-1": 30,
        "entropy-1": 4.985335926099693,
        "distinct-2": 1.0,
        "vocab_size-2": 44,
        "unique-2": 44,
        "entropy-2": 5.4594316186372955,
        "cond_entropy-2": 0.4048427669596596,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.10187961401921372,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 0.9428090415820634,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7906976744186046,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.914636847725354,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.3219280948873635,
        "cond_entropy-2-nopunct": 0.44566334018526427,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.11247472925841272,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9689882585461778,
        "bleu": 35.88706,
        "rouge1": {
            "precision": 0.67725,
            "recall": 0.57753,
            "fmeasure": 0.61983
        },
        "rouge2": {
            "precision": 0.3431,
            "recall": 0.28982,
            "fmeasure": 0.31211
        },
        "rougeL": {
            "precision": 0.59259,
            "recall": 0.50487,
            "fmeasure": 0.54186
        },
        "rougeLsum": {
            "precision": 0.59259,
            "recall": 0.50487,
            "fmeasure": 0.54186
        },
        "local_recall": {
            "1": 0.8333333333333334,
            "2": 0.5238095238095238,
            "3": 0.5454545454545454
        },
        "bertscore": {
            "precision": 0.89654,
            "recall": 0.86978,
            "f1": 0.88191
        },
        "bleurt": 0.19665,
        "meteor": 0.29466080736042954,
        "nubia": {
            "semantic_relation": 4.24138,
            "contradiction": 0.57013,
            "irrelevancy": 6.63417,
            "logical_agreement": 92.7957,
            "grammar_ref": 4.68806,
            "grammar_hyp": 4.95748,
            "nubia_score": 0.72331
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_407": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.241334850220957,
        "bleu": 23.3569,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.53788,
            "fmeasure": 0.55702
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.35238,
            "fmeasure": 0.36415
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.53788,
            "fmeasure": 0.55702
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.53788,
            "fmeasure": 0.55702
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.88137,
            "recall": 0.89394,
            "f1": 0.88761
        },
        "bleurt": 0.03026,
        "meteor": 0.3036740373763213,
        "nubia": {
            "semantic_relation": 3.68414,
            "contradiction": 0.55593,
            "irrelevancy": 93.27096,
            "logical_agreement": 6.17311,
            "grammar_ref": 4.68733,
            "grammar_hyp": 4.64497,
            "nubia_score": 0.63771
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_504": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 94,
        "mean_pred_length": 18.8,
        "std_pred_length": 5.1146847410177685,
        "median_pred_length": 19.0,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.7127659574468085,
        "vocab_size-1": 67,
        "unique-1": 54,
        "entropy-1": 5.771091612403751,
        "distinct-2": 0.9550561797752809,
        "vocab_size-2": 85,
        "unique-2": 81,
        "entropy-2": 6.385845790516971,
        "cond_entropy-2": 0.5283254783596335,
        "distinct-3": 0.9880952380952381,
        "vocab_size-3": 83,
        "unique-3": 82,
        "entropy-3": 6.368507898969236,
        "cond_entropy-3": -0.011987436759066031,
        "total_length-nopunct": 84,
        "mean_pred_length-nopunct": 16.8,
        "std_pred_length-nopunct": 4.664761515876241,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7380952380952381,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.677566232096525,
        "distinct-2-nopunct": 0.9493670886075949,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 71,
        "entropy-2-nopunct": 6.202514925392295,
        "cond_entropy-2-nopunct": 0.557527882579454,
        "distinct-3-nopunct": 0.9864864864864865,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 72,
        "entropy-3-nopunct": 6.182426338601928,
        "cond_entropy-3-nopunct": -0.026759814980585547,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.938987491189822,
        "bleu": 43.36424,
        "rouge1": {
            "precision": 0.77052,
            "recall": 0.73733,
            "fmeasure": 0.75217
        },
        "rouge2": {
            "precision": 0.5872,
            "recall": 0.54456,
            "fmeasure": 0.56288
        },
        "rougeL": {
            "precision": 0.67149,
            "recall": 0.65238,
            "fmeasure": 0.65914
        },
        "rougeLsum": {
            "precision": 0.67149,
            "recall": 0.65238,
            "fmeasure": 0.65914
        },
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.0,
            "3": 0.7857142857142857
        },
        "bertscore": {
            "precision": 0.92398,
            "recall": 0.92421,
            "f1": 0.92157
        },
        "bleurt": 0.37176,
        "meteor": 0.39114951012286386,
        "nubia": {
            "semantic_relation": 4.47181,
            "contradiction": 0.53245,
            "irrelevancy": 47.91859,
            "logical_agreement": 51.54896,
            "grammar_ref": 4.46418,
            "grammar_hyp": 4.44538,
            "nubia_score": 0.80917
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_505": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 75,
        "mean_pred_length": 15.0,
        "std_pred_length": 5.830951894845301,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.6533333333333333,
        "vocab_size-1": 49,
        "unique-1": 37,
        "entropy-1": 5.345634277728851,
        "distinct-2": 0.8285714285714286,
        "vocab_size-2": 58,
        "unique-2": 50,
        "entropy-2": 5.736286231168872,
        "cond_entropy-2": 0.287884547574282,
        "distinct-3": 0.8923076923076924,
        "vocab_size-3": 58,
        "unique-3": 52,
        "entropy-3": 5.795369543764403,
        "cond_entropy-3": 0.08931383457831044,
        "total_length-nopunct": 67,
        "mean_pred_length-nopunct": 13.4,
        "std_pred_length-nopunct": 5.122499389946279,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7014925373134329,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.321696608652886,
        "distinct-2-nopunct": 0.8064516129032258,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.510490261929986,
        "cond_entropy-2-nopunct": 0.21656724858394596,
        "distinct-3-nopunct": 0.8771929824561403,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.574032338688186,
        "cond_entropy-3-nopunct": 0.1024636599561729,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.938078084436401,
        "bleu": 60.75563,
        "rouge1": {
            "precision": 0.86841,
            "recall": 0.89298,
            "fmeasure": 0.88028
        },
        "rouge2": {
            "precision": 0.74532,
            "recall": 0.76565,
            "fmeasure": 0.75512
        },
        "rougeL": {
            "precision": 0.85788,
            "recall": 0.88187,
            "fmeasure": 0.86947
        },
        "rougeLsum": {
            "precision": 0.85788,
            "recall": 0.88187,
            "fmeasure": 0.86947
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.847457627118644
        },
        "bertscore": {
            "precision": 0.98351,
            "recall": 0.98181,
            "f1": 0.98264
        },
        "bleurt": 0.82864,
        "meteor": 0.48437661317829817,
        "nubia": {
            "semantic_relation": 4.62933,
            "contradiction": 0.48127,
            "irrelevancy": 0.83024,
            "logical_agreement": 98.6885,
            "grammar_ref": 4.79762,
            "grammar_hyp": 4.78637,
            "nubia_score": 0.86163
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_438": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.112834334934429,
        "bleu": 26.91109,
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.67879,
            "fmeasure": 0.65657
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.42963,
            "fmeasure": 0.41404
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.48485,
            "fmeasure": 0.46898
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.48485,
            "fmeasure": 0.46898
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.94413,
            "recall": 0.95434,
            "f1": 0.94454
        },
        "bleurt": 0.13166,
        "meteor": 0.38452544569607966,
        "nubia": {
            "semantic_relation": 4.45707,
            "contradiction": 0.1688,
            "irrelevancy": 0.44279,
            "logical_agreement": 99.38841,
            "grammar_ref": 5.84412,
            "grammar_hyp": 6.07692,
            "nubia_score": 0.75512
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_510": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 2.5,
        "median_pred_length": 11.5,
        "min_pred_length": 9,
        "max_pred_length": 14,
        "distinct-1": 0.8695652173913043,
        "vocab_size-1": 20,
        "unique-1": 17,
        "entropy-1": 4.2626923908396215,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.05923165719793806,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.14438990933517493,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.1219280948873624,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717248,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.5497870659381796,
        "bleu": 18.58905,
        "rouge1": {
            "precision": 0.76389,
            "recall": 0.58216,
            "fmeasure": 0.66002
        },
        "rouge2": {
            "precision": 0.41477,
            "recall": 0.30833,
            "fmeasure": 0.35328
        },
        "rougeL": {
            "precision": 0.56944,
            "recall": 0.44332,
            "fmeasure": 0.49796
        },
        "rougeLsum": {
            "precision": 0.56944,
            "recall": 0.44332,
            "fmeasure": 0.49796
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.2,
            "3": 0.65
        },
        "bertscore": {
            "precision": 0.92426,
            "recall": 0.88569,
            "f1": 0.90452
        },
        "bleurt": 0.09192,
        "meteor": 0.3444389145832237,
        "nubia": {
            "semantic_relation": 2.9938,
            "contradiction": 50.14404,
            "irrelevancy": 31.09121,
            "logical_agreement": 18.76475,
            "grammar_ref": 5.35082,
            "grammar_hyp": 5.53198,
            "nubia_score": 0.42079
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_512": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9545454545454546,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.368522527728204,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.02812389937955851,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.03126257645096008,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.5071839678315351,
        "bleu": 7.43854,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.3761,
            "fmeasure": 0.51134
        },
        "rouge2": {
            "precision": 0.35088,
            "recall": 0.1537,
            "fmeasure": 0.21363
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.24072,
            "fmeasure": 0.33151
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.24072,
            "fmeasure": 0.33151
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.16666666666666666,
            "3": 0.46153846153846156
        },
        "bertscore": {
            "precision": 0.88562,
            "recall": 0.81887,
            "f1": 0.85094
        },
        "bleurt": -0.53259,
        "meteor": 0.1923866320105847,
        "nubia": {
            "semantic_relation": 3.39983,
            "contradiction": 5.86719,
            "irrelevancy": 93.12143,
            "logical_agreement": 1.01139,
            "grammar_ref": 4.78179,
            "grammar_hyp": 4.42122,
            "nubia_score": 0.29721
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_513": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.4168422047045828,
        "bleu": 6.2285,
        "rouge1": {
            "precision": 0.375,
            "recall": 0.54762,
            "fmeasure": 0.44
        },
        "rouge2": {
            "precision": 0.13333,
            "recall": 0.20192,
            "fmeasure": 0.15839
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.54762,
            "fmeasure": 0.44
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.54762,
            "fmeasure": 0.44
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.7142857142857143
        },
        "bertscore": {
            "precision": 0.81467,
            "recall": 0.89398,
            "f1": 0.85249
        },
        "bleurt": 0.28561,
        "meteor": 0.31276434594629526,
        "nubia": {
            "semantic_relation": 3.00705,
            "contradiction": 47.46182,
            "irrelevancy": 52.16453,
            "logical_agreement": 0.37366,
            "grammar_ref": 5.58883,
            "grammar_hyp": 4.24692,
            "nubia_score": 0.43825
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_465": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 1.5,
        "median_pred_length": 12.5,
        "min_pred_length": 11,
        "max_pred_length": 14,
        "distinct-1": 0.92,
        "vocab_size-1": 23,
        "unique-1": 21,
        "entropy-1": 4.483856189774723,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": -0.03333771197858132,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9545454545454546,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.368522527728205,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": -0.037503523749935014,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.977027025176735,
        "bleu": 37.70244,
        "rouge1": {
            "precision": 0.67778,
            "recall": 0.70862,
            "fmeasure": 0.68384
        },
        "rouge2": {
            "precision": 0.48316,
            "recall": 0.51496,
            "fmeasure": 0.49013
        },
        "rougeL": {
            "precision": 0.66389,
            "recall": 0.6958,
            "fmeasure": 0.67051
        },
        "rougeLsum": {
            "precision": 0.66389,
            "recall": 0.6958,
            "fmeasure": 0.67051
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.125,
            "3": 0.8125
        },
        "bertscore": {
            "precision": 0.9105,
            "recall": 0.92949,
            "f1": 0.9172
        },
        "bleurt": -0.16007,
        "meteor": 0.3895284087997485,
        "nubia": {
            "semantic_relation": 3.57752,
            "contradiction": 61.96139,
            "irrelevancy": 31.93781,
            "logical_agreement": 6.1008,
            "grammar_ref": 5.19402,
            "grammar_hyp": 6.17586,
            "nubia_score": 0.36049
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_408": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.79,
        "total_length": 222,
        "mean_pred_length": 14.8,
        "std_pred_length": 5.833238094460629,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 25,
        "distinct-1": 0.6531531531531531,
        "vocab_size-1": 145,
        "unique-1": 120,
        "entropy-1": 6.6581357576430875,
        "distinct-2": 0.961352657004831,
        "vocab_size-2": 199,
        "unique-2": 192,
        "entropy-2": 7.612545471981603,
        "cond_entropy-2": 0.753640838476105,
        "distinct-3": 1.0,
        "vocab_size-3": 192,
        "unique-3": 192,
        "entropy-3": 7.584962500721179,
        "cond_entropy-3": -0.0316760843710675,
        "total_length-nopunct": 196,
        "mean_pred_length-nopunct": 13.066666666666666,
        "std_pred_length-nopunct": 5.157087894883658,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7091836734693877,
        "vocab_size-1-nopunct": 139,
        "unique-1-nopunct": 118,
        "entropy-1-nopunct": 6.706336452664219,
        "distinct-2-nopunct": 0.9613259668508287,
        "vocab_size-2-nopunct": 174,
        "unique-2-nopunct": 168,
        "entropy-2-nopunct": 7.418327171601613,
        "cond_entropy-2-nopunct": 0.7642320220883635,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 166,
        "unique-3-nopunct": 166,
        "entropy-3-nopunct": 7.375039431346908,
        "cond_entropy-3-nopunct": -0.03592159126541637,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.700470302634777,
        "bleu": 61.73829,
        "rouge1": {
            "precision": 0.84805,
            "recall": 0.79112,
            "fmeasure": 0.80877
        },
        "rouge2": {
            "precision": 0.69765,
            "recall": 0.63513,
            "fmeasure": 0.65465
        },
        "rougeL": {
            "precision": 0.78683,
            "recall": 0.74027,
            "fmeasure": 0.75349
        },
        "rougeLsum": {
            "precision": 0.78683,
            "recall": 0.74027,
            "fmeasure": 0.75349
        },
        "local_recall": {
            "1": 0.23404255319148937,
            "2": 0.48148148148148145,
            "3": 0.8516129032258064
        },
        "bertscore": {
            "precision": 0.95794,
            "recall": 0.95266,
            "f1": 0.95362
        },
        "bleurt": 0.33632,
        "meteor": 0.46898514403868996,
        "nubia": {
            "semantic_relation": 4.38838,
            "contradiction": 4.40433,
            "irrelevancy": 25.20989,
            "logical_agreement": 70.38577,
            "grammar_ref": 4.56596,
            "grammar_hyp": 4.80407,
            "nubia_score": 0.7928
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_440": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.81,
        "msttr-100_nopunct": NaN,
        "total_length": 108,
        "mean_pred_length": 13.5,
        "std_pred_length": 3.840572873934304,
        "median_pred_length": 13.5,
        "min_pred_length": 6,
        "max_pred_length": 19,
        "distinct-1": 0.7870370370370371,
        "vocab_size-1": 85,
        "unique-1": 77,
        "entropy-1": 6.135499974482155,
        "distinct-2": 1.0,
        "vocab_size-2": 100,
        "unique-2": 100,
        "entropy-2": 6.6438561897747395,
        "cond_entropy-2": 0.30431321739168204,
        "distinct-3": 1.0,
        "vocab_size-3": 92,
        "unique-3": 92,
        "entropy-3": 6.523561956057027,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 94,
        "mean_pred_length-nopunct": 11.75,
        "std_pred_length-nopunct": 3.3819373146171707,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8829787234042553,
        "vocab_size-1-nopunct": 83,
        "unique-1-nopunct": 77,
        "entropy-1-nopunct": 6.269962388888654,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 86,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.426264754702099,
        "cond_entropy-2-nopunct": 0.18277924607287296,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 78,
        "unique-3-nopunct": 78,
        "entropy-3-nopunct": 6.285402218862257,
        "cond_entropy-3-nopunct": -0.14086253583984976,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.368410479474786,
        "bleu": 42.15824,
        "rouge1": {
            "precision": 0.76379,
            "recall": 0.67134,
            "fmeasure": 0.70784
        },
        "rouge2": {
            "precision": 0.46356,
            "recall": 0.4188,
            "fmeasure": 0.43752
        },
        "rougeL": {
            "precision": 0.64505,
            "recall": 0.55351,
            "fmeasure": 0.58923
        },
        "rougeLsum": {
            "precision": 0.64505,
            "recall": 0.55351,
            "fmeasure": 0.58923
        },
        "local_recall": {
            "1": 0.21951219512195122,
            "2": 0.28,
            "3": 0.8260869565217391
        },
        "bertscore": {
            "precision": 0.90809,
            "recall": 0.89843,
            "f1": 0.90173
        },
        "bleurt": 0.00592,
        "meteor": 0.3620850575218279,
        "nubia": {
            "semantic_relation": 3.55031,
            "contradiction": 4.47999,
            "irrelevancy": 36.14232,
            "logical_agreement": 59.37769,
            "grammar_ref": 4.83092,
            "grammar_hyp": 5.13135,
            "nubia_score": 0.55124
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_515": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 46,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 2.494438257849294,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.782608695652174,
        "vocab_size-1": 36,
        "unique-1": 28,
        "entropy-1": 5.055958151615122,
        "distinct-2": 0.9302325581395349,
        "vocab_size-2": 40,
        "unique-2": 37,
        "entropy-2": 5.286729870981167,
        "cond_entropy-2": 0.15281646148609582,
        "distinct-3": 1.0,
        "vocab_size-3": 40,
        "unique-3": 40,
        "entropy-3": 5.3219280948873635,
        "cond_entropy-3": 0.04566334018526421,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 2.160246899469287,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8095238095238095,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.993391529870107,
        "distinct-2-nopunct": 0.8974358974358975,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 5.0802740137340425,
        "cond_entropy-2-nopunct": 0.11756909101075651,
        "distinct-3-nopunct": 0.9722222222222222,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.114369445886754,
        "cond_entropy-3-nopunct": 0.051189449246730793,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.187199069971218,
        "bleu": 82.12549,
        "rouge1": {
            "precision": 0.88287,
            "recall": 0.97454,
            "fmeasure": 0.92251
        },
        "rouge2": {
            "precision": 0.85132,
            "recall": 0.96498,
            "fmeasure": 0.8981
        },
        "rougeL": {
            "precision": 0.87546,
            "recall": 0.97596,
            "fmeasure": 0.91763
        },
        "rougeLsum": {
            "precision": 0.87546,
            "recall": 0.97596,
            "fmeasure": 0.91763
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.97094,
            "recall": 0.98603,
            "f1": 0.97676
        },
        "bleurt": 0.65616,
        "meteor": 0.5890646732423985,
        "nubia": {
            "semantic_relation": 4.54485,
            "contradiction": 0.53232,
            "irrelevancy": 47.15769,
            "logical_agreement": 52.30999,
            "grammar_ref": 4.92539,
            "grammar_hyp": 4.74708,
            "nubia_score": 0.85186
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_468": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 87,
        "mean_pred_length": 14.5,
        "std_pred_length": 6.211548384528075,
        "median_pred_length": 12.5,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.6781609195402298,
        "vocab_size-1": 59,
        "unique-1": 47,
        "entropy-1": 5.5274407315758,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 72,
        "unique-2": 63,
        "entropy-2": 6.117627780662394,
        "cond_entropy-2": 0.4665233649052502,
        "distinct-3": 0.9466666666666667,
        "vocab_size-3": 71,
        "unique-3": 67,
        "entropy-3": 6.122152023829224,
        "cond_entropy-3": -0.004364645722077292,
        "total_length-nopunct": 80,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 5.878397362849466,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7125,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.520191026294638,
        "distinct-2-nopunct": 0.8918918918918919,
        "vocab_size-2-nopunct": 66,
        "unique-2-nopunct": 58,
        "entropy-2-nopunct": 5.993237149412739,
        "cond_entropy-2-nopunct": 0.49751129084182555,
        "distinct-3-nopunct": 0.9558823529411765,
        "vocab_size-3-nopunct": 65,
        "unique-3-nopunct": 62,
        "entropy-3-nopunct": 5.999227547132698,
        "cond_entropy-3-nopunct": -0.019049347908022016,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.271225040151838,
        "bleu": 52.59097,
        "rouge1": {
            "precision": 0.86625,
            "recall": 0.80249,
            "fmeasure": 0.82392
        },
        "rouge2": {
            "precision": 0.69147,
            "recall": 0.65861,
            "fmeasure": 0.66714
        },
        "rougeL": {
            "precision": 0.75902,
            "recall": 0.71411,
            "fmeasure": 0.72821
        },
        "rougeLsum": {
            "precision": 0.75902,
            "recall": 0.71411,
            "fmeasure": 0.72821
        },
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.6666666666666666,
            "3": 0.8115942028985508
        },
        "bertscore": {
            "precision": 0.95596,
            "recall": 0.93215,
            "f1": 0.94339
        },
        "bleurt": 0.33816,
        "meteor": 0.43568058542470545,
        "nubia": {
            "semantic_relation": 4.38583,
            "contradiction": 15.53857,
            "irrelevancy": 24.62035,
            "logical_agreement": 59.84108,
            "grammar_ref": 4.9652,
            "grammar_hyp": 5.31559,
            "nubia_score": 0.73965
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_challenge_test_asset_bfp05",
        "N": 359,
        "msttr-100": 0.75105,
        "msttr-100_nopunct": 0.8,
        "total_length": 5770,
        "mean_pred_length": 16.07242339832869,
        "std_pred_length": 7.585376084205693,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 56,
        "distinct-1": 0.45337954939341424,
        "vocab_size-1": 2616,
        "unique-1": 2166,
        "entropy-1": 9.340090129512081,
        "distinct-2": 0.8750693032711144,
        "vocab_size-2": 4735,
        "unique-2": 4493,
        "entropy-2": 11.955476341970614,
        "cond_entropy-2": 2.2516517948645642,
        "distinct-3": 0.9647664291369754,
        "vocab_size-3": 4874,
        "unique-3": 4813,
        "entropy-3": 12.169693569890445,
        "cond_entropy-3": 0.23529942171350193,
        "total_length-nopunct": 5139,
        "mean_pred_length-nopunct": 14.314763231197771,
        "std_pred_length-nopunct": 6.739364210210642,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.5071025491340728,
        "vocab_size-1-nopunct": 2606,
        "unique-1-nopunct": 2163,
        "entropy-1-nopunct": 9.728944302171515,
        "distinct-2-nopunct": 0.8899581589958159,
        "vocab_size-2-nopunct": 4254,
        "unique-2-nopunct": 4060,
        "entropy-2-nopunct": 11.842260650176826,
        "cond_entropy-2-nopunct": 2.2678680854354742,
        "distinct-3-nopunct": 0.9800950011309658,
        "vocab_size-3-nopunct": 4333,
        "unique-3-nopunct": 4287,
        "entropy-3-nopunct": 12.056202534818972,
        "cond_entropy-3-nopunct": 0.24131732780205717,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp05.json",
        "nist": 7.899075217597489,
        "bleu": 39.57414,
        "rouge1": {
            "precision": 0.6723,
            "recall": 0.59819,
            "fmeasure": 0.61844
        },
        "rouge2": {
            "precision": 0.44804,
            "recall": 0.39159,
            "fmeasure": 0.40365
        },
        "rougeL": {
            "precision": 0.63883,
            "recall": 0.57428,
            "fmeasure": 0.59034
        },
        "rougeLsum": {
            "precision": 0.63883,
            "recall": 0.57428,
            "fmeasure": 0.59034
        },
        "local_recall": {
            "1": 0.03632850241545894,
            "2": 0.11195054945054946,
            "3": 0.20867526377491208,
            "4": 0.301699716713881,
            "5": 0.37184594953519257,
            "6": 0.43103448275862066,
            "7": 0.519406392694064,
            "8": 0.5873015873015873,
            "9": 0.7115107913669064
        },
        "sari": 43.76535,
        "bertscore": {
            "precision": 0.86148,
            "recall": 0.88516,
            "f1": 0.86871
        },
        "bleurt": -0.80033,
        "meteor": 0.30054439477857897,
        "nubia": {
            "semantic_relation": 3.49201,
            "contradiction": 9.05652,
            "irrelevancy": 25.87476,
            "logical_agreement": 65.06872,
            "grammar_ref": 4.57404,
            "grammar_hyp": 6.54724,
            "nubia_score": 0.36513
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_441": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.816496580927726,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 13,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 32,
        "unique-1": 29,
        "entropy-1": 4.926733681937769,
        "distinct-2": 1.0,
        "vocab_size-2": 33,
        "unique-2": 33,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": -0.004318760871737864,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.13750352374993471,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 10.333333333333334,
        "std_pred_length-nopunct": 1.247219128924647,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9354838709677419,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.825164052322361,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": -0.003984245472128324,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.16349873228287956,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9396916074392854,
        "bleu": 30.84175,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.53943,
            "fmeasure": 0.53143
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.36061,
            "fmeasure": 0.34787
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.53943,
            "fmeasure": 0.53143
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.53943,
            "fmeasure": 0.53143
        },
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.7
        },
        "bertscore": {
            "precision": 0.90141,
            "recall": 0.89934,
            "f1": 0.89873
        },
        "bleurt": -0.14848,
        "meteor": 0.2687766993042245,
        "nubia": {
            "semantic_relation": 3.32766,
            "contradiction": 15.92097,
            "irrelevancy": 49.95553,
            "logical_agreement": 34.1235,
            "grammar_ref": 5.06451,
            "grammar_hyp": 4.92554,
            "nubia_score": 0.52856
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_567": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 3.0,
        "median_pred_length": 20.0,
        "min_pred_length": 17,
        "max_pred_length": 23,
        "distinct-1": 0.875,
        "vocab_size-1": 35,
        "unique-1": 32,
        "entropy-1": 5.021928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 38,
        "unique-2": 38,
        "entropy-2": 5.247927513443589,
        "cond_entropy-2": 0.18915731329306523,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.0780025120012732,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.892147223664532,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.087462841250338,
        "cond_entropy-2-nopunct": 0.21165548686685082,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.08746284125033942,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.969327090825214,
        "bleu": 59.05923,
        "rouge1": {
            "precision": 0.78542,
            "recall": 0.83449,
            "fmeasure": 0.80793
        },
        "rouge2": {
            "precision": 0.67018,
            "recall": 0.72157,
            "fmeasure": 0.69314
        },
        "rougeL": {
            "precision": 0.78542,
            "recall": 0.83449,
            "fmeasure": 0.80793
        },
        "rougeLsum": {
            "precision": 0.78542,
            "recall": 0.83449,
            "fmeasure": 0.80793
        },
        "local_recall": {
            "1": 0,
            "2": 0.875,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.93136,
            "recall": 0.95203,
            "f1": 0.93852
        },
        "bleurt": 0.41752,
        "meteor": 0.5216231980907343,
        "nubia": {
            "semantic_relation": 3.42013,
            "contradiction": 49.99279,
            "irrelevancy": 44.08156,
            "logical_agreement": 5.92565,
            "grammar_ref": 3.41143,
            "grammar_hyp": 3.29645,
            "nubia_score": 0.61461
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_532": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 49,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 17,
        "distinct-1": 0.8979591836734694,
        "vocab_size-1": 44,
        "unique-1": 40,
        "entropy-1": 5.3952223440710565,
        "distinct-2": 1.0,
        "vocab_size-2": 46,
        "unique-2": 46,
        "entropy-2": 5.5235619560570095,
        "cond_entropy-2": 0.03928689455050026,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.09729720135491506,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 0.4714045207910317,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9545454545454546,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.368522527728205,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.357552004618081,
        "cond_entropy-2-nopunct": -0.004318638409457542,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.10962449117449787,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.512887071135837,
        "bleu": 44.31253,
        "rouge1": {
            "precision": 0.87712,
            "recall": 0.75112,
            "fmeasure": 0.79441
        },
        "rouge2": {
            "precision": 0.70582,
            "recall": 0.60912,
            "fmeasure": 0.64153
        },
        "rougeL": {
            "precision": 0.82951,
            "recall": 0.7035,
            "fmeasure": 0.74679
        },
        "rougeLsum": {
            "precision": 0.82951,
            "recall": 0.7035,
            "fmeasure": 0.74679
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6981132075471698
        },
        "bertscore": {
            "precision": 0.96865,
            "recall": 0.93928,
            "f1": 0.95355
        },
        "bleurt": 0.4789,
        "meteor": 0.3761013824476556,
        "nubia": {
            "semantic_relation": 4.50624,
            "contradiction": 0.24,
            "irrelevancy": 33.14886,
            "logical_agreement": 66.61114,
            "grammar_ref": 4.33326,
            "grammar_hyp": 4.63692,
            "nubia_score": 0.76677
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_442": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.7398663923302058,
        "bleu": 16.05295,
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.36508,
            "fmeasure": 0.44048
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.20192,
            "fmeasure": 0.24812
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.27381,
            "fmeasure": 0.33036
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.27381,
            "fmeasure": 0.33036
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5
        },
        "bertscore": {
            "precision": 0.91743,
            "recall": 0.89768,
            "f1": 0.90744
        },
        "bleurt": -0.13565,
        "meteor": 0.2104797085781601,
        "nubia": {
            "semantic_relation": 2.94013,
            "contradiction": 0.35977,
            "irrelevancy": 29.57574,
            "logical_agreement": 70.06449,
            "grammar_ref": 5.77141,
            "grammar_hyp": 6.18455,
            "nubia_score": 0.32654
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_516": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 95,
        "mean_pred_length": 23.75,
        "std_pred_length": 8.98262211161084,
        "median_pred_length": 21.5,
        "min_pred_length": 15,
        "max_pred_length": 37,
        "distinct-1": 0.7263157894736842,
        "vocab_size-1": 69,
        "unique-1": 54,
        "entropy-1": 5.8985457397960275,
        "distinct-2": 0.9120879120879121,
        "vocab_size-2": 83,
        "unique-2": 75,
        "entropy-2": 6.331970464374525,
        "cond_entropy-2": 0.3750207627558506,
        "distinct-3": 0.9310344827586207,
        "vocab_size-3": 81,
        "unique-3": 75,
        "entropy-3": 6.305012461365965,
        "cond_entropy-3": -0.01887413285571501,
        "total_length-nopunct": 89,
        "mean_pred_length-nopunct": 22.25,
        "std_pred_length-nopunct": 8.257572282456872,
        "median_pred_length-nopunct": 20.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.7528089887640449,
        "vocab_size-1-nopunct": 67,
        "unique-1-nopunct": 54,
        "entropy-1-nopunct": 5.871526267923515,
        "distinct-2-nopunct": 0.9176470588235294,
        "vocab_size-2-nopunct": 78,
        "unique-2-nopunct": 71,
        "entropy-2-nopunct": 6.244685053784765,
        "cond_entropy-2-nopunct": 0.3898273582397433,
        "distinct-3-nopunct": 0.9259259259259259,
        "vocab_size-3-nopunct": 75,
        "unique-3-nopunct": 69,
        "entropy-3-nopunct": 6.191701854736466,
        "cond_entropy-3-nopunct": -0.05719525424073139,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.922696830545811,
        "bleu": 31.45597,
        "rouge1": {
            "precision": 0.76877,
            "recall": 0.75414,
            "fmeasure": 0.74808
        },
        "rouge2": {
            "precision": 0.46033,
            "recall": 0.43954,
            "fmeasure": 0.44114
        },
        "rougeL": {
            "precision": 0.68993,
            "recall": 0.6668,
            "fmeasure": 0.6658
        },
        "rougeLsum": {
            "precision": 0.68993,
            "recall": 0.6668,
            "fmeasure": 0.6658
        },
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.0,
            "3": 0.7611940298507462
        },
        "bertscore": {
            "precision": 0.92542,
            "recall": 0.90578,
            "f1": 0.91518
        },
        "bleurt": 0.09178,
        "meteor": 0.38308650568194585,
        "nubia": {
            "semantic_relation": 4.152,
            "contradiction": 7.15599,
            "irrelevancy": 40.78173,
            "logical_agreement": 52.06229,
            "grammar_ref": 4.38942,
            "grammar_hyp": 4.21091,
            "nubia_score": 0.70481
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_570": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7735572622751845,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.04332146930622849,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5906347108528585,
        "bleu": 44.285,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.78571,
            "fmeasure": 0.75862
        },
        "rouge2": {
            "precision": 0.45238,
            "recall": 0.48718,
            "fmeasure": 0.46914
        },
        "rougeL": {
            "precision": 0.48889,
            "recall": 0.52381,
            "fmeasure": 0.50575
        },
        "rougeLsum": {
            "precision": 0.48889,
            "recall": 0.52381,
            "fmeasure": 0.50575
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.25,
            "3": 0.8888888888888888
        },
        "bertscore": {
            "precision": 0.94941,
            "recall": 0.93863,
            "f1": 0.94399
        },
        "bleurt": 0.38092,
        "meteor": 0.4585192246224728,
        "nubia": {
            "semantic_relation": 4.75272,
            "contradiction": 0.34749,
            "irrelevancy": 1.86216,
            "logical_agreement": 97.79035,
            "grammar_ref": 5.70189,
            "grammar_hyp": 4.74334,
            "nubia_score": 0.95093
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_534": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 66,
        "mean_pred_length": 22.0,
        "std_pred_length": 10.03327796219494,
        "median_pred_length": 17.0,
        "min_pred_length": 13,
        "max_pred_length": 36,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 48,
        "unique-1": 36,
        "entropy-1": 5.402507331834212,
        "distinct-2": 0.9206349206349206,
        "vocab_size-2": 58,
        "unique-2": 53,
        "entropy-2": 5.818549764769761,
        "cond_entropy-2": 0.37113406564046086,
        "distinct-3": 0.95,
        "vocab_size-3": 57,
        "unique-3": 54,
        "entropy-3": 5.806890595608517,
        "cond_entropy-3": -0.003722661224731332,
        "total_length-nopunct": 58,
        "mean_pred_length-nopunct": 19.333333333333332,
        "std_pred_length-nopunct": 7.71722460186015,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.7586206896551724,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.278504435223488,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.599541531706473,
        "cond_entropy-2-nopunct": 0.352644908841393,
        "distinct-3-nopunct": 0.9423076923076923,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.585055102756479,
        "cond_entropy-3-nopunct": -0.003996918460490569,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.595441481564172,
        "bleu": 19.06824,
        "rouge1": {
            "precision": 0.61458,
            "recall": 0.55282,
            "fmeasure": 0.57522
        },
        "rouge2": {
            "precision": 0.3449,
            "recall": 0.29132,
            "fmeasure": 0.31277
        },
        "rougeL": {
            "precision": 0.57292,
            "recall": 0.50989,
            "fmeasure": 0.53346
        },
        "rougeLsum": {
            "precision": 0.57292,
            "recall": 0.50989,
            "fmeasure": 0.53346
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.6666666666666666,
            "3": 0.6060606060606061
        },
        "bertscore": {
            "precision": 0.89966,
            "recall": 0.89363,
            "f1": 0.89593
        },
        "bleurt": -0.1503,
        "meteor": 0.2773233522270216,
        "nubia": {
            "semantic_relation": 3.15077,
            "contradiction": 55.97596,
            "irrelevancy": 22.67346,
            "logical_agreement": 21.35058,
            "grammar_ref": 3.79025,
            "grammar_hyp": 3.76374,
            "nubia_score": 0.4689
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_574": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.8076923076923077,
        "vocab_size-1": 21,
        "unique-1": 17,
        "entropy-1": 4.286790198827112,
        "distinct-2": 0.92,
        "vocab_size-2": 23,
        "unique-2": 21,
        "entropy-2": 4.483856189774723,
        "cond_entropy-2": 0.2136119717201712,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": 0.10777297761309837,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.186704345910024,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.297079327540665,
        "cond_entropy-2-nopunct": 0.07574294699860612,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": 0.02961067210860201,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9828325787700956,
        "bleu": 15.66392,
        "rouge1": {
            "precision": 0.40909,
            "recall": 0.73077,
            "fmeasure": 0.52437
        },
        "rouge2": {
            "precision": 0.1746,
            "recall": 0.32576,
            "fmeasure": 0.22727
        },
        "rougeL": {
            "precision": 0.40909,
            "recall": 0.73077,
            "fmeasure": 0.52437
        },
        "rougeLsum": {
            "precision": 0.40909,
            "recall": 0.73077,
            "fmeasure": 0.52437
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.87127,
            "recall": 0.92216,
            "f1": 0.89599
        },
        "bleurt": 0.17827,
        "meteor": 0.3593908323839594,
        "nubia": {
            "semantic_relation": 4.18832,
            "contradiction": 0.47374,
            "irrelevancy": 95.94678,
            "logical_agreement": 3.57947,
            "grammar_ref": 5.03839,
            "grammar_hyp": 3.77702,
            "nubia_score": 0.66258
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_535": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3219280948873626,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 1.00634,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.33373,
            "irrelevancy": 0.59046,
            "logical_agreement": 99.07581,
            "grammar_ref": 6.68645,
            "grammar_hyp": 6.68645,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_575": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.8076923076923077,
        "vocab_size-1": 21,
        "unique-1": 17,
        "entropy-1": 4.286790198827111,
        "distinct-2": 0.96,
        "vocab_size-2": 24,
        "unique-2": 23,
        "entropy-2": 4.5638561897747225,
        "cond_entropy-2": 0.29361197172017117,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": 0.024439644279765024,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.213660689688185,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.501629167387823,
        "cond_entropy-2-nopunct": 0.30589329020324296,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": 0.02555597707498716,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.8015328027615864,
        "bleu": 8.04529,
        "rouge1": {
            "precision": 0.68,
            "recall": 0.48571,
            "fmeasure": 0.56667
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.17647,
            "fmeasure": 0.2069
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.28571,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.28571,
            "fmeasure": 0.33333
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.6956521739130435
        },
        "bertscore": {
            "precision": 0.91071,
            "recall": 0.87693,
            "f1": 0.89287
        },
        "bleurt": 0.05813,
        "meteor": 0.2956899190425847,
        "nubia": {
            "semantic_relation": 3.7418,
            "contradiction": 0.46187,
            "irrelevancy": 94.23839,
            "logical_agreement": 5.29974,
            "grammar_ref": 5.19058,
            "grammar_hyp": 5.402,
            "nubia_score": 0.48914
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_469": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 11.0,
        "std_pred_length": 4.320493798938574,
        "median_pred_length": 9.0,
        "min_pred_length": 7,
        "max_pred_length": 17,
        "distinct-1": 0.8787878787878788,
        "vocab_size-1": 29,
        "unique-1": 26,
        "entropy-1": 4.779094498080775,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": -0.0041701904166014025,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.15200309344505,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 8.666666666666666,
        "std_pred_length-nopunct": 3.7712361663282534,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9615384615384616,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.623516641218013,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": -0.08992124034494874,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.2016338611696506,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7130640029913513,
        "bleu": 38.6525,
        "rouge1": {
            "precision": 0.84921,
            "recall": 0.78836,
            "fmeasure": 0.80041
        },
        "rouge2": {
            "precision": 0.62821,
            "recall": 0.57613,
            "fmeasure": 0.59133
        },
        "rougeL": {
            "precision": 0.75397,
            "recall": 0.73016,
            "fmeasure": 0.72845
        },
        "rougeLsum": {
            "precision": 0.75397,
            "recall": 0.73016,
            "fmeasure": 0.72845
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.4117647058823529,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.95348,
            "recall": 0.94935,
            "f1": 0.95115
        },
        "bleurt": 0.41434,
        "meteor": 0.3274279085554081,
        "nubia": {
            "semantic_relation": 4.15517,
            "contradiction": 2.24074,
            "irrelevancy": 25.51009,
            "logical_agreement": 72.24917,
            "grammar_ref": 6.27104,
            "grammar_hyp": 5.87629,
            "nubia_score": 0.74432
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_576": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 61,
        "mean_pred_length": 20.333333333333332,
        "std_pred_length": 5.436502143433364,
        "median_pred_length": 17.0,
        "min_pred_length": 16,
        "max_pred_length": 28,
        "distinct-1": 0.7704918032786885,
        "vocab_size-1": 47,
        "unique-1": 38,
        "entropy-1": 5.3877961002061,
        "distinct-2": 0.9827586206896551,
        "vocab_size-2": 57,
        "unique-2": 56,
        "entropy-2": 5.823498236506881,
        "cond_entropy-2": 0.381804484747449,
        "distinct-3": 1.0,
        "vocab_size-3": 55,
        "unique-3": 55,
        "entropy-3": 5.7813597135246555,
        "cond_entropy-3": -0.040257645239276,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 3.559026084010437,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8148148148148148,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.303692539633833,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 5.6724253419715005,
        "cond_entropy-2-nopunct": 0.39527368248646355,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.5849625007211605,
        "cond_entropy-3-nopunct": -0.08746284125033933,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.335424935845177,
        "bleu": 61.60695,
        "rouge1": {
            "precision": 0.7968,
            "recall": 0.79165,
            "fmeasure": 0.78787
        },
        "rouge2": {
            "precision": 0.67701,
            "recall": 0.67103,
            "fmeasure": 0.6676
        },
        "rougeL": {
            "precision": 0.76298,
            "recall": 0.74956,
            "fmeasure": 0.74994
        },
        "rougeLsum": {
            "precision": 0.76298,
            "recall": 0.74956,
            "fmeasure": 0.74994
        },
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 0.625,
            "3": 0.9285714285714286
        },
        "bertscore": {
            "precision": 0.94241,
            "recall": 0.93903,
            "f1": 0.93625
        },
        "bleurt": 0.32507,
        "meteor": 0.4461600096890967,
        "nubia": {
            "semantic_relation": 3.98832,
            "contradiction": 33.04699,
            "irrelevancy": 34.15207,
            "logical_agreement": 32.80094,
            "grammar_ref": 4.44265,
            "grammar_hyp": 4.298,
            "nubia_score": 0.69192
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_472": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.186704345910024,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.2186000898557489,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966059,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.781490055580646,
        "bleu": 87.25129,
        "rouge1": {
            "precision": 0.92157,
            "recall": 0.85552,
            "fmeasure": 0.88671
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.75,
            "fmeasure": 0.75
        },
        "rougeL": {
            "precision": 0.92157,
            "recall": 0.85552,
            "fmeasure": 0.88671
        },
        "rougeLsum": {
            "precision": 0.92157,
            "recall": 0.85552,
            "fmeasure": 0.88671
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.9645,
            "recall": 0.97236,
            "f1": 0.96842
        },
        "bleurt": 0.60599,
        "meteor": 0.5347033086663171,
        "nubia": {
            "semantic_relation": 4.84131,
            "contradiction": 0.58627,
            "irrelevancy": 3.95162,
            "logical_agreement": 95.46212,
            "grammar_ref": 5.82691,
            "grammar_hyp": 5.33292,
            "nubia_score": 0.96383
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_473": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.7391304347826086,
        "vocab_size-1": 17,
        "unique-1": 11,
        "entropy-1": 4.001822825622231,
        "distinct-2": 0.8181818181818182,
        "vocab_size-2": 18,
        "unique-2": 14,
        "entropy-2": 4.095795255000932,
        "cond_entropy-2": 0.0722332989439208,
        "distinct-3": 0.8571428571428571,
        "vocab_size-3": 18,
        "unique-3": 15,
        "entropy-3": 4.106603137064473,
        "cond_entropy-3": 0.02812389937955851,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.821928094887362,
        "distinct-2-nopunct": 0.7894736842105263,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.8268748818646365,
        "cond_entropy-2-nopunct": -0.02136900249640835,
        "distinct-3-nopunct": 0.8333333333333334,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.8365916681089787,
        "cond_entropy-3-nopunct": -0.022446956445717602,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.5248647339526835,
        "bleu": 10.19131,
        "rouge1": {
            "precision": 0.51667,
            "recall": 0.5103,
            "fmeasure": 0.51242
        },
        "rouge2": {
            "precision": 0.21053,
            "recall": 0.20875,
            "fmeasure": 0.20918
        },
        "rougeL": {
            "precision": 0.35,
            "recall": 0.34706,
            "fmeasure": 0.34784
        },
        "rougeLsum": {
            "precision": 0.35,
            "recall": 0.34706,
            "fmeasure": 0.34784
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.5882352941176471
        },
        "bertscore": {
            "precision": 0.87692,
            "recall": 0.83009,
            "f1": 0.84696
        },
        "bleurt": -0.11516,
        "meteor": 0.26477260078368314,
        "nubia": {
            "semantic_relation": 3.68135,
            "contradiction": 1.92902,
            "irrelevancy": 2.17178,
            "logical_agreement": 95.89919,
            "grammar_ref": 4.86737,
            "grammar_hyp": 5.00042,
            "nubia_score": 0.56352
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_609": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.875,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.303508854797679,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.2322902162994857,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.152391277629865,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.2545471137682951,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.043972360358888,
        "bleu": 34.11915,
        "rouge1": {
            "precision": 0.68182,
            "recall": 0.76441,
            "fmeasure": 0.72036
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.48333,
            "fmeasure": 0.45403
        },
        "rougeL": {
            "precision": 0.34848,
            "recall": 0.36523,
            "fmeasure": 0.35625
        },
        "rougeLsum": {
            "precision": 0.34848,
            "recall": 0.36523,
            "fmeasure": 0.35625
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.91626,
            "recall": 0.92926,
            "f1": 0.92272
        },
        "bleurt": 0.15266,
        "meteor": 0.38783476425810176,
        "nubia": {
            "semantic_relation": 4.49232,
            "contradiction": 0.40885,
            "irrelevancy": 3.6276,
            "logical_agreement": 95.96355,
            "grammar_ref": 5.09304,
            "grammar_hyp": 4.44359,
            "nubia_score": 0.85454
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_474": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 2.5,
        "median_pred_length": 14.5,
        "min_pred_length": 12,
        "max_pred_length": 17,
        "distinct-1": 0.6551724137931034,
        "vocab_size-1": 19,
        "unique-1": 11,
        "entropy-1": 4.1162646156680225,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 24,
        "unique-2": 21,
        "entropy-2": 4.532665279941249,
        "cond_entropy-2": 0.39726854423319063,
        "distinct-3": 0.92,
        "vocab_size-3": 23,
        "unique-3": 21,
        "entropy-3": 4.4838561897747224,
        "cond_entropy-3": -0.031031312388743956,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 4.032303242743954,
        "distinct-2-nopunct": 0.88,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.403856189774722,
        "cond_entropy-2-nopunct": 0.42935968778433353,
        "distinct-3-nopunct": 0.9130434782608695,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.349648912578752,
        "cond_entropy-3-nopunct": -0.03333771197858132,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.952614182483677,
        "bleu": 54.50803,
        "rouge1": {
            "precision": 0.79735,
            "recall": 0.91667,
            "fmeasure": 0.84921
        },
        "rouge2": {
            "precision": 0.63333,
            "recall": 0.70875,
            "fmeasure": 0.66599
        },
        "rougeL": {
            "precision": 0.79735,
            "recall": 0.91667,
            "fmeasure": 0.84921
        },
        "rougeLsum": {
            "precision": 0.79735,
            "recall": 0.91667,
            "fmeasure": 0.84921
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.8947368421052632
        },
        "bertscore": {
            "precision": 0.95625,
            "recall": 0.96753,
            "f1": 0.96182
        },
        "bleurt": 0.79173,
        "meteor": 0.49218001068849665,
        "nubia": {
            "semantic_relation": 4.92601,
            "contradiction": 0.15262,
            "irrelevancy": 0.67798,
            "logical_agreement": 99.16941,
            "grammar_ref": 4.16906,
            "grammar_hyp": 3.86824,
            "nubia_score": 0.95815
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_519": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.6330370023236713,
        "bleu": 42.95749,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.69841,
            "fmeasure": 0.82222
        },
        "rouge2": {
            "precision": 0.74074,
            "recall": 0.50183,
            "fmeasure": 0.59816
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 0.62857,
            "fmeasure": 0.74
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 0.62857,
            "fmeasure": 0.74
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9090909090909091
        },
        "bertscore": {
            "precision": 0.98201,
            "recall": 0.93212,
            "f1": 0.95641
        },
        "bleurt": 0.45492,
        "meteor": 0.42350497485471644,
        "nubia": {
            "semantic_relation": 4.97277,
            "contradiction": 0.35627,
            "irrelevancy": 0.48729,
            "logical_agreement": 99.15644,
            "grammar_ref": 5.37123,
            "grammar_hyp": 6.85358,
            "nubia_score": 0.74277
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_610": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9047619047619048,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.201841232302569,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.129610672108602,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.505100882691675,
        "bleu": 83.33522,
        "rouge1": {
            "precision": 0.94444,
            "recall": 1.0,
            "fmeasure": 0.97143
        },
        "rouge2": {
            "precision": 0.88235,
            "recall": 0.9375,
            "fmeasure": 0.90909
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 1.0,
            "fmeasure": 0.97143
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 1.0,
            "fmeasure": 0.97143
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.98131,
            "recall": 0.99799,
            "f1": 0.98958
        },
        "bleurt": 0.73934,
        "meteor": 0.609396650051159,
        "nubia": {
            "semantic_relation": 4.05378,
            "contradiction": 16.407,
            "irrelevancy": 81.76898,
            "logical_agreement": 1.82402,
            "grammar_ref": 5.25838,
            "grammar_hyp": 5.03039,
            "nubia_score": 0.61259
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_520": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.82,
        "total_length": 114,
        "mean_pred_length": 16.285714285714285,
        "std_pred_length": 4.651091598885631,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 27,
        "distinct-1": 0.7543859649122807,
        "vocab_size-1": 86,
        "unique-1": 76,
        "entropy-1": 6.136538452890592,
        "distinct-2": 0.9906542056074766,
        "vocab_size-2": 106,
        "unique-2": 105,
        "entropy-2": 6.7227753976160916,
        "cond_entropy-2": 0.4355309720985936,
        "distinct-3": 1.0,
        "vocab_size-3": 100,
        "unique-3": 100,
        "entropy-3": 6.6438561897747395,
        "cond_entropy-3": -0.07761079662642242,
        "total_length-nopunct": 101,
        "mean_pred_length-nopunct": 14.428571428571429,
        "std_pred_length-nopunct": 4.135461378894322,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8217821782178217,
        "vocab_size-1-nopunct": 83,
        "unique-1-nopunct": 75,
        "entropy-1-nopunct": 6.1890621957690675,
        "distinct-2-nopunct": 0.9893617021276596,
        "vocab_size-2-nopunct": 93,
        "unique-2-nopunct": 92,
        "entropy-2-nopunct": 6.533312255932943,
        "cond_entropy-2-nopunct": 0.37918670919450376,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 87,
        "unique-3-nopunct": 87,
        "entropy-3-nopunct": 6.442943495848723,
        "cond_entropy-3-nopunct": -0.08865685008178277,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.0451204383326465,
        "bleu": 43.10451,
        "rouge1": {
            "precision": 0.76535,
            "recall": 0.76479,
            "fmeasure": 0.75329
        },
        "rouge2": {
            "precision": 0.54304,
            "recall": 0.56242,
            "fmeasure": 0.5448
        },
        "rougeL": {
            "precision": 0.65036,
            "recall": 0.67454,
            "fmeasure": 0.65354
        },
        "rougeLsum": {
            "precision": 0.65036,
            "recall": 0.67454,
            "fmeasure": 0.65354
        },
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.5,
            "3": 0.8260869565217391
        },
        "bertscore": {
            "precision": 0.92583,
            "recall": 0.9324,
            "f1": 0.92594
        },
        "bleurt": 0.3674,
        "meteor": 0.39927806517061987,
        "nubia": {
            "semantic_relation": 4.06681,
            "contradiction": 1.52858,
            "irrelevancy": 68.35271,
            "logical_agreement": 30.11871,
            "grammar_ref": 4.63553,
            "grammar_hyp": 4.45443,
            "nubia_score": 0.71251
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_612": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 3.2998316455372216,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 18,
        "distinct-1": 0.775,
        "vocab_size-1": 31,
        "unique-1": 26,
        "entropy-1": 4.7628148954723555,
        "distinct-2": 0.8918918918918919,
        "vocab_size-2": 33,
        "unique-2": 29,
        "entropy-2": 4.993237149412737,
        "cond_entropy-2": 0.14724528356420377,
        "distinct-3": 0.9411764705882353,
        "vocab_size-3": 32,
        "unique-3": 30,
        "entropy-3": 4.969815782426808,
        "cond_entropy-3": -0.06316699496684555,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.8284271247461903,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8055555555555556,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.680768321596843,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.8625759375402735,
        "cond_entropy-2-nopunct": 0.16567034441422615,
        "distinct-3-nopunct": 0.9666666666666667,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.840223928941852,
        "cond_entropy-3-nopunct": -0.07083685708326808,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.593159177053284,
        "bleu": 35.14897,
        "rouge1": {
            "precision": 0.75327,
            "recall": 0.60302,
            "fmeasure": 0.66262
        },
        "rouge2": {
            "precision": 0.52315,
            "recall": 0.37943,
            "fmeasure": 0.43608
        },
        "rougeL": {
            "precision": 0.69444,
            "recall": 0.53755,
            "fmeasure": 0.60071
        },
        "rougeLsum": {
            "precision": 0.69444,
            "recall": 0.53755,
            "fmeasure": 0.60071
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5384615384615384,
            "3": 0.56
        },
        "bertscore": {
            "precision": 0.94161,
            "recall": 0.90644,
            "f1": 0.92232
        },
        "bleurt": 0.4001,
        "meteor": 0.36423472177688565,
        "nubia": {
            "semantic_relation": 4.1432,
            "contradiction": 8.02907,
            "irrelevancy": 12.95312,
            "logical_agreement": 79.01781,
            "grammar_ref": 4.28129,
            "grammar_hyp": 3.8482,
            "nubia_score": 0.7991
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_536": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 17.666666666666668,
        "std_pred_length": 1.699673171197595,
        "median_pred_length": 17.0,
        "min_pred_length": 16,
        "max_pred_length": 20,
        "distinct-1": 0.7924528301886793,
        "vocab_size-1": 42,
        "unique-1": 35,
        "entropy-1": 5.246603945047593,
        "distinct-2": 0.98,
        "vocab_size-2": 49,
        "unique-2": 48,
        "entropy-2": 5.603856189774728,
        "cond_entropy-2": 0.2910334852547948,
        "distinct-3": 1.0,
        "vocab_size-3": 47,
        "unique-3": 47,
        "entropy-3": 5.55458885167764,
        "cond_entropy-3": -0.04671414660772556,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 2.0548046676563256,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8163265306122449,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.191140711417995,
        "distinct-2-nopunct": 0.9782608695652174,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.480083695187445,
        "cond_entropy-2-nopunct": 0.31656705764101023,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.426264754702098,
        "cond_entropy-3-nopunct": -0.0507855734479384,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.887420409242547,
        "bleu": 48.72887,
        "rouge1": {
            "precision": 0.78657,
            "recall": 0.78905,
            "fmeasure": 0.78266
        },
        "rouge2": {
            "precision": 0.5303,
            "recall": 0.52978,
            "fmeasure": 0.52652
        },
        "rougeL": {
            "precision": 0.6287,
            "recall": 0.58028,
            "fmeasure": 0.60124
        },
        "rougeLsum": {
            "precision": 0.6287,
            "recall": 0.58028,
            "fmeasure": 0.60124
        },
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.125,
            "3": 0.8333333333333334
        },
        "bertscore": {
            "precision": 0.92124,
            "recall": 0.92931,
            "f1": 0.92168
        },
        "bleurt": 0.16273,
        "meteor": 0.40648674725077444,
        "nubia": {
            "semantic_relation": 4.47302,
            "contradiction": 34.09923,
            "irrelevancy": 15.98774,
            "logical_agreement": 49.91304,
            "grammar_ref": 4.10939,
            "grammar_hyp": 4.30448,
            "nubia_score": 0.77742
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_615": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 61,
        "mean_pred_length": 20.333333333333332,
        "std_pred_length": 2.494438257849294,
        "median_pred_length": 21.0,
        "min_pred_length": 17,
        "max_pred_length": 23,
        "distinct-1": 0.7704918032786885,
        "vocab_size-1": 47,
        "unique-1": 38,
        "entropy-1": 5.409844919352762,
        "distinct-2": 1.0,
        "vocab_size-2": 58,
        "unique-2": 58,
        "entropy-2": 5.85798099512757,
        "cond_entropy-2": 0.39309796805871794,
        "distinct-3": 1.0,
        "vocab_size-3": 55,
        "unique-3": 55,
        "entropy-3": 5.7813597135246555,
        "cond_entropy-3": -0.0766212816029123,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 18.333333333333332,
        "std_pred_length-nopunct": 2.494438257849294,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 45,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.376547667952105,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 52,
        "unique-2-nopunct": 52,
        "entropy-2-nopunct": 5.700439718141095,
        "cond_entropy-2-nopunct": 0.32801582204894064,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.614709844115208,
        "cond_entropy-3-nopunct": -0.08572987402588379,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.887089894533411,
        "bleu": 32.73572,
        "rouge1": {
            "precision": 0.68228,
            "recall": 0.68752,
            "fmeasure": 0.68342
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.41093,
            "fmeasure": 0.40451
        },
        "rougeL": {
            "precision": 0.54292,
            "recall": 0.54796,
            "fmeasure": 0.54437
        },
        "rougeLsum": {
            "precision": 0.54292,
            "recall": 0.54796,
            "fmeasure": 0.54437
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.11764705882352941,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.88946,
            "recall": 0.87847,
            "f1": 0.88384
        },
        "bleurt": 0.00872,
        "meteor": 0.33078168268536773,
        "nubia": {
            "semantic_relation": 4.21575,
            "contradiction": 2.36658,
            "irrelevancy": 23.74869,
            "logical_agreement": 73.88473,
            "grammar_ref": 4.60968,
            "grammar_hyp": 4.17582,
            "nubia_score": 0.75045
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_539": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.5684210940655061,
        "bleu": 11.25133,
        "rouge1": {
            "precision": 0.46667,
            "recall": 0.58333,
            "fmeasure": 0.51852
        },
        "rouge2": {
            "precision": 0.21429,
            "recall": 0.27273,
            "fmeasure": 0.24
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.41667,
            "fmeasure": 0.37037
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.41667,
            "fmeasure": 0.37037
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.84205,
            "recall": 0.8351,
            "f1": 0.83856
        },
        "bleurt": 0.46301,
        "meteor": 0.30820423707448286,
        "nubia": {
            "semantic_relation": 4.36974,
            "contradiction": 0.57031,
            "irrelevancy": 92.05643,
            "logical_agreement": 7.37326,
            "grammar_ref": 5.68739,
            "grammar_hyp": 3.82267,
            "nubia_score": 0.865
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_522": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964164,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.770721208389991,
        "bleu": 80.52254,
        "rouge1": {
            "precision": 0.97222,
            "recall": 0.84455,
            "fmeasure": 0.9019
        },
        "rouge2": {
            "precision": 0.84848,
            "recall": 0.73333,
            "fmeasure": 0.78484
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.80288,
            "fmeasure": 0.85429
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.80288,
            "fmeasure": 0.85429
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9166666666666666
        },
        "bertscore": {
            "precision": 0.99811,
            "recall": 0.98882,
            "f1": 0.99345
        },
        "bleurt": 0.74939,
        "meteor": 0.5469432736955866,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.11768,
            "irrelevancy": 0.47514,
            "logical_agreement": 99.40718,
            "grammar_ref": 4.55634,
            "grammar_hyp": 4.71917,
            "nubia_score": 0.98117
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_524": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.7037037037037037,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 3.878906596444832,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.8552246949931323,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.05658352836636749,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.03740119765411,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.08866415466539351,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.655564669423137,
        "bleu": 30.6063,
        "rouge1": {
            "precision": 0.52632,
            "recall": 0.90909,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.9,
            "fmeasure": 0.64286
        },
        "rougeL": {
            "precision": 0.52632,
            "recall": 0.90909,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.52632,
            "recall": 0.90909,
            "fmeasure": 0.66667
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.81638,
            "recall": 0.9331,
            "f1": 0.87085
        },
        "bleurt": -0.24434,
        "meteor": 0.4071816185608139,
        "nubia": {
            "semantic_relation": 3.2018,
            "contradiction": 14.4499,
            "irrelevancy": 84.32085,
            "logical_agreement": 1.22924,
            "grammar_ref": 4.055,
            "grammar_hyp": 3.79756,
            "nubia_score": 0.41317
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_616": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.1213203435596424,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 15,
        "distinct-1": 0.75,
        "vocab_size-1": 36,
        "unique-1": 26,
        "entropy-1": 5.043295834054493,
        "distinct-2": 0.9545454545454546,
        "vocab_size-2": 42,
        "unique-2": 40,
        "entropy-2": 5.368522527728205,
        "cond_entropy-2": 0.19265093609795914,
        "distinct-3": 1.0,
        "vocab_size-3": 40,
        "unique-3": 40,
        "entropy-3": 5.3219280948873635,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 1.8027756377319946,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8095238095238095,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 5.011365041826381,
        "distinct-2-nopunct": 0.9473684210526315,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.142664355548852,
        "cond_entropy-2-nopunct": 0.17139956434903575,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.04281761336971669,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.2025733311555085,
        "bleu": 49.25398,
        "rouge1": {
            "precision": 0.68746,
            "recall": 0.67795,
            "fmeasure": 0.6702
        },
        "rouge2": {
            "precision": 0.53472,
            "recall": 0.56434,
            "fmeasure": 0.54283
        },
        "rougeL": {
            "precision": 0.65969,
            "recall": 0.67795,
            "fmeasure": 0.66072
        },
        "rougeLsum": {
            "precision": 0.65969,
            "recall": 0.67795,
            "fmeasure": 0.66072
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.2777777777777778,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.91253,
            "recall": 0.9064,
            "f1": 0.90552
        },
        "bleurt": 0.27073,
        "meteor": 0.37794888344361716,
        "nubia": {
            "semantic_relation": 4.0813,
            "contradiction": 24.06949,
            "irrelevancy": 10.54665,
            "logical_agreement": 65.38386,
            "grammar_ref": 4.6519,
            "grammar_hyp": 4.77748,
            "nubia_score": 0.67975
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_540": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 65,
        "mean_pred_length": 13.0,
        "std_pred_length": 4.560701700396552,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 19,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 50,
        "unique-1": 43,
        "entropy-1": 5.426536182979218,
        "distinct-2": 0.95,
        "vocab_size-2": 57,
        "unique-2": 54,
        "entropy-2": 5.806890595608517,
        "cond_entropy-2": 0.2365130405594598,
        "distinct-3": 0.9818181818181818,
        "vocab_size-3": 54,
        "unique-3": 53,
        "entropy-3": 5.744996077161019,
        "cond_entropy-3": -0.052803609356585984,
        "total_length-nopunct": 58,
        "mean_pred_length-nopunct": 11.6,
        "std_pred_length-nopunct": 4.498888751680798,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8275862068965517,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.424887624804057,
        "distinct-2-nopunct": 0.9433962264150944,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.614712907393384,
        "cond_entropy-2-nopunct": 0.23068314771418846,
        "distinct-3-nopunct": 0.9791666666666666,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.543295834054494,
        "cond_entropy-3-nopunct": -0.059624620508709814,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.269614221251818,
        "bleu": 60.39759,
        "rouge1": {
            "precision": 0.89044,
            "recall": 0.78047,
            "fmeasure": 0.80746
        },
        "rouge2": {
            "precision": 0.71114,
            "recall": 0.62561,
            "fmeasure": 0.65166
        },
        "rougeL": {
            "precision": 0.82104,
            "recall": 0.73651,
            "fmeasure": 0.75677
        },
        "rougeLsum": {
            "precision": 0.82104,
            "recall": 0.73651,
            "fmeasure": 0.75677
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.8125,
            "3": 0.7857142857142857
        },
        "bertscore": {
            "precision": 0.95067,
            "recall": 0.93722,
            "f1": 0.94098
        },
        "bleurt": 0.35599,
        "meteor": 0.44568224043903676,
        "nubia": {
            "semantic_relation": 4.01841,
            "contradiction": 21.52876,
            "irrelevancy": 31.41103,
            "logical_agreement": 47.06021,
            "grammar_ref": 4.71659,
            "grammar_hyp": 4.61491,
            "nubia_score": 0.7244
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_525": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.7483971951349195,
        "bleu": 6.07459,
        "rouge1": {
            "precision": 0.47059,
            "recall": 0.61111,
            "fmeasure": 0.52943
        },
        "rouge2": {
            "precision": 0.0625,
            "recall": 0.08283,
            "fmeasure": 0.07089
        },
        "rougeL": {
            "precision": 0.23529,
            "recall": 0.30556,
            "fmeasure": 0.26472
        },
        "rougeLsum": {
            "precision": 0.23529,
            "recall": 0.30556,
            "fmeasure": 0.26472
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6363636363636364
        },
        "bertscore": {
            "precision": 0.80128,
            "recall": 0.80854,
            "f1": 0.80183
        },
        "bleurt": -0.31715,
        "meteor": 0.22784202281145158,
        "nubia": {
            "semantic_relation": 3.75933,
            "contradiction": 0.69723,
            "irrelevancy": 44.85214,
            "logical_agreement": 54.45062,
            "grammar_ref": 5.53377,
            "grammar_hyp": 4.71163,
            "nubia_score": 0.65833
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_618": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 10.666666666666666,
        "std_pred_length": 4.4969125210773475,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 30,
        "unique-1": 29,
        "entropy-1": 4.851409765557392,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": -0.14201900487242786,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.15754127698647996,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 9.333333333333334,
        "std_pred_length-nopunct": 4.109609335312651,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.807354922057606,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": -0.16349873228287956,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1844245711374276,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9783855651473021,
        "bleu": 38.98921,
        "rouge1": {
            "precision": 0.81296,
            "recall": 0.5814,
            "fmeasure": 0.67385
        },
        "rouge2": {
            "precision": 0.56173,
            "recall": 0.38344,
            "fmeasure": 0.45205
        },
        "rougeL": {
            "precision": 0.78333,
            "recall": 0.53851,
            "fmeasure": 0.6343
        },
        "rougeLsum": {
            "precision": 0.78333,
            "recall": 0.53851,
            "fmeasure": 0.6343
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.7
        },
        "bertscore": {
            "precision": 0.92916,
            "recall": 0.88292,
            "f1": 0.89931
        },
        "bleurt": 0.09577,
        "meteor": 0.3489230798827569,
        "nubia": {
            "semantic_relation": 3.75002,
            "contradiction": 0.63288,
            "irrelevancy": 33.57572,
            "logical_agreement": 65.7914,
            "grammar_ref": 4.66623,
            "grammar_hyp": 5.42145,
            "nubia_score": 0.59069
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_543": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.1055161915432032,
        "bleu": 41.11336,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.6,
            "fmeasure": 0.54545
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8333333333333334
        },
        "bertscore": {
            "precision": 0.93887,
            "recall": 0.95113,
            "f1": 0.94496
        },
        "bleurt": 0.18287,
        "meteor": 0.4231469901582543,
        "nubia": {
            "semantic_relation": 4.01521,
            "contradiction": 10.23484,
            "irrelevancy": 37.69891,
            "logical_agreement": 52.06625,
            "grammar_ref": 7.84225,
            "grammar_hyp": 7.31486,
            "nubia_score": 0.66591
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_620": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.729374386591448,
        "bleu": 9.88372,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.53571,
            "fmeasure": 0.55769
        },
        "rouge2": {
            "precision": 0.13636,
            "recall": 0.12937,
            "fmeasure": 0.13258
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.3869,
            "fmeasure": 0.40064
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.3869,
            "fmeasure": 0.40064
        },
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.7142857142857143
        },
        "bertscore": {
            "precision": 0.86869,
            "recall": 0.88667,
            "f1": 0.87569
        },
        "bleurt": 0.21962,
        "meteor": 0.24142262177070414,
        "nubia": {
            "semantic_relation": 4.31278,
            "contradiction": 2.87478,
            "irrelevancy": 66.81052,
            "logical_agreement": 30.31469,
            "grammar_ref": 5.74657,
            "grammar_hyp": 5.28315,
            "nubia_score": 0.71643
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_544": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0286497677077553,
        "bleu": 70.16879,
        "rouge1": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.875,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.98524,
            "recall": 0.9921,
            "f1": 0.98866
        },
        "bleurt": 0.76221,
        "meteor": 0.5613051214200641,
        "nubia": {
            "semantic_relation": 4.89761,
            "contradiction": 0.83309,
            "irrelevancy": 31.2673,
            "logical_agreement": 67.89961,
            "grammar_ref": 5.45224,
            "grammar_hyp": 4.86831,
            "nubia_score": 0.98957
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_648": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.807763576417195,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.20971762763487742,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.5898980954642865,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.24009914803219054,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.930864866470748,
        "bleu": 21.40909,
        "rouge1": {
            "precision": 0.53333,
            "recall": 0.47059,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.35714,
            "recall": 0.3125,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.35294,
            "fmeasure": 0.375
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.35294,
            "fmeasure": 0.375
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.4666666666666667
        },
        "bertscore": {
            "precision": 0.9031,
            "recall": 0.85107,
            "f1": 0.87631
        },
        "bleurt": 0.01793,
        "meteor": 0.28717467067100866,
        "nubia": {
            "semantic_relation": 3.78,
            "contradiction": 0.84199,
            "irrelevancy": 4.25501,
            "logical_agreement": 94.903,
            "grammar_ref": 3.58521,
            "grammar_hyp": 3.37367,
            "nubia_score": 0.72245
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_545": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 10.5,
        "std_pred_length": 1.5,
        "median_pred_length": 10.5,
        "min_pred_length": 9,
        "max_pred_length": 12,
        "distinct-1": 0.9047619047619048,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.201841232302569,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.03912675144043809,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.1604646721932461,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.04281761336971672,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.18057224564182078,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.263700501592033,
        "bleu": 64.48218,
        "rouge1": {
            "precision": 0.85985,
            "recall": 0.75,
            "fmeasure": 0.79537
        },
        "rouge2": {
            "precision": 0.62619,
            "recall": 0.5803,
            "fmeasure": 0.5988
        },
        "rougeL": {
            "precision": 0.85985,
            "recall": 0.75,
            "fmeasure": 0.79537
        },
        "rougeLsum": {
            "precision": 0.85985,
            "recall": 0.75,
            "fmeasure": 0.79537
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.3333333333333333,
            "3": 0.7894736842105263
        },
        "bertscore": {
            "precision": 0.92137,
            "recall": 0.91616,
            "f1": 0.91595
        },
        "bleurt": 0.51842,
        "meteor": 0.4529906745494671,
        "nubia": {
            "semantic_relation": 4.41093,
            "contradiction": 1.08855,
            "irrelevancy": 0.73556,
            "logical_agreement": 98.1759,
            "grammar_ref": 5.62679,
            "grammar_hyp": 6.25766,
            "nubia_score": 0.71576
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_475": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.64,
        "msttr-100_nopunct": NaN,
        "total_length": 100,
        "mean_pred_length": 14.285714285714286,
        "std_pred_length": 6.226998490772391,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.64,
        "vocab_size-1": 64,
        "unique-1": 42,
        "entropy-1": 5.741049440399793,
        "distinct-2": 0.8602150537634409,
        "vocab_size-2": 80,
        "unique-2": 67,
        "entropy-2": 6.259588918634919,
        "cond_entropy-2": 0.37518638996869036,
        "distinct-3": 0.9186046511627907,
        "vocab_size-3": 79,
        "unique-3": 72,
        "entropy-3": 6.26347405702768,
        "cond_entropy-3": -0.019870800591979827,
        "total_length-nopunct": 89,
        "mean_pred_length-nopunct": 12.714285714285714,
        "std_pred_length-nopunct": 6.180945043652553,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6853932584269663,
        "vocab_size-1-nopunct": 61,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.727090841268755,
        "distinct-2-nopunct": 0.8780487804878049,
        "vocab_size-2-nopunct": 72,
        "unique-2-nopunct": 62,
        "entropy-2-nopunct": 6.113649565593698,
        "cond_entropy-2-nopunct": 0.40168675027474304,
        "distinct-3-nopunct": 0.9466666666666667,
        "vocab_size-3-nopunct": 71,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 6.122152023829224,
        "cond_entropy-3-nopunct": -0.022066647455536048,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.220816920374463,
        "bleu": 24.05157,
        "rouge1": {
            "precision": 0.61793,
            "recall": 0.66268,
            "fmeasure": 0.63043
        },
        "rouge2": {
            "precision": 0.26951,
            "recall": 0.31065,
            "fmeasure": 0.28345
        },
        "rougeL": {
            "precision": 0.46353,
            "recall": 0.50888,
            "fmeasure": 0.47736
        },
        "rougeLsum": {
            "precision": 0.46353,
            "recall": 0.50888,
            "fmeasure": 0.47736
        },
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.7916666666666666,
            "3": 0.6739130434782609
        },
        "bertscore": {
            "precision": 0.90757,
            "recall": 0.90573,
            "f1": 0.90657
        },
        "bleurt": 0.19897,
        "meteor": 0.33902757400913947,
        "nubia": {
            "semantic_relation": 3.99113,
            "contradiction": 14.84125,
            "irrelevancy": 42.32765,
            "logical_agreement": 42.8311,
            "grammar_ref": 5.09695,
            "grammar_hyp": 4.47492,
            "nubia_score": 0.70878
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1850,
        "msttr-100": 0.69914,
        "msttr-100_nopunct": 0.74408,
        "total_length": 24463,
        "mean_pred_length": 13.223243243243243,
        "std_pred_length": 4.421373184059973,
        "median_pred_length": 13.0,
        "min_pred_length": 4,
        "max_pred_length": 39,
        "distinct-1": 0.2572047582062707,
        "vocab_size-1": 6292,
        "unique-1": 4694,
        "entropy-1": 9.196680684065276,
        "distinct-2": 0.604696413567417,
        "vocab_size-2": 13674,
        "unique-2": 11937,
        "entropy-2": 12.492101070436204,
        "cond_entropy-2": 2.8466955210337166,
        "distinct-3": 0.768241583586187,
        "vocab_size-3": 15951,
        "unique-3": 14756,
        "entropy-3": 13.260889860926799,
        "cond_entropy-3": 0.7984632404059868,
        "total_length-nopunct": 21312,
        "mean_pred_length-nopunct": 11.52,
        "std_pred_length-nopunct": 3.837775256436849,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.29434121621621623,
        "vocab_size-1-nopunct": 6273,
        "unique-1-nopunct": 4689,
        "entropy-1-nopunct": 9.651976015323951,
        "distinct-2-nopunct": 0.6275305723974925,
        "vocab_size-2-nopunct": 12213,
        "unique-2-nopunct": 10843,
        "entropy-2-nopunct": 12.334319004520914,
        "cond_entropy-2-nopunct": 2.9083764164964196,
        "distinct-3-nopunct": 0.778332954803543,
        "vocab_size-3-nopunct": 13708,
        "unique-3-nopunct": 12762,
        "entropy-3-nopunct": 13.05720335880886,
        "cond_entropy-3-nopunct": 0.8411801589856162,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 9.523957596967954,
        "bleu": 51.126,
        "rouge1": {
            "precision": 0.76654,
            "recall": 0.73523,
            "fmeasure": 0.73713
        },
        "rouge2": {
            "precision": 0.56657,
            "recall": 0.54332,
            "fmeasure": 0.54439
        },
        "rougeL": {
            "precision": 0.69714,
            "recall": 0.67028,
            "fmeasure": 0.67112
        },
        "rougeLsum": {
            "precision": 0.69714,
            "recall": 0.67028,
            "fmeasure": 0.67112
        },
        "local_recall": {
            "1": 0.21189591078066913,
            "2": 0.47479954180985107,
            "3": 0.7819088792816761
        },
        "bertscore": {
            "precision": 0.93102,
            "recall": 0.92658,
            "f1": 0.92698
        },
        "bleurt": 0.32154,
        "meteor": 0.40588194743718303,
        "nubia": {
            "semantic_relation": 4.18998,
            "contradiction": 7.64627,
            "irrelevancy": 28.93779,
            "logical_agreement": 63.41593,
            "grammar_ref": 4.71357,
            "grammar_hyp": 4.73217,
            "nubia_score": 0.73462
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_621": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.699073089379862,
        "bleu": 75.14773,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.72222,
            "fmeasure": 0.8381
        },
        "rouge2": {
            "precision": 0.93333,
            "recall": 0.64286,
            "fmeasure": 0.76068
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.72222,
            "fmeasure": 0.8381
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.72222,
            "fmeasure": 0.8381
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.7142857142857143
        },
        "bertscore": {
            "precision": 0.97111,
            "recall": 0.90849,
            "f1": 0.93875
        },
        "bleurt": 0.05023,
        "meteor": 0.4262229212970303,
        "nubia": {
            "semantic_relation": 3.56556,
            "contradiction": 7.56306,
            "irrelevancy": 1.62233,
            "logical_agreement": 90.81461,
            "grammar_ref": 7.10682,
            "grammar_hyp": 6.45743,
            "nubia_score": 0.60188
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_650": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": 0.0930692077718899,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.5216406363433186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": 0.11094091199688534,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.50789957099271,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.89367,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.97499,
            "contradiction": 0.89945,
            "irrelevancy": 0.58957,
            "logical_agreement": 98.51098,
            "grammar_ref": 4.12966,
            "grammar_hyp": 4.39551,
            "nubia_score": 0.98513
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_651": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4457289637024866,
        "bleu": 57.60844,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.9375,
            "fmeasure": 0.75
        },
        "rouge2": {
            "precision": 0.54545,
            "recall": 0.85714,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.9375,
            "fmeasure": 0.75
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.9375,
            "fmeasure": 0.75
        },
        "local_recall": {
            "1": 0.5,
            "2": 1.0
        },
        "bertscore": {
            "precision": 0.86546,
            "recall": 0.96651,
            "f1": 0.9132
        },
        "bleurt": -0.90817,
        "meteor": 0.5108007395276796,
        "nubia": {
            "semantic_relation": 3.78386,
            "contradiction": 0.35437,
            "irrelevancy": 99.34266,
            "logical_agreement": 0.30297,
            "grammar_ref": 5.1072,
            "grammar_hyp": 5.23779,
            "nubia_score": 0.49785
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_654": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.9259259259259259,
        "vocab_size-1": 25,
        "unique-1": 24,
        "entropy-1": 4.578780557638898,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.12843250452237231,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.05658352836636749,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.523561956057013,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": -0.06413033741971555,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.497038091988463,
        "bleu": 67.32378,
        "rouge1": {
            "precision": 0.79365,
            "recall": 0.84737,
            "fmeasure": 0.81951
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.65497,
            "fmeasure": 0.62618
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.72456,
            "fmeasure": 0.69431
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.72456,
            "fmeasure": 0.69431
        },
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.8333333333333334
        },
        "bertscore": {
            "precision": 0.91772,
            "recall": 0.93462,
            "f1": 0.9261
        },
        "bleurt": 0.34742,
        "meteor": 0.47229287284102345,
        "nubia": {
            "semantic_relation": 4.51707,
            "contradiction": 0.0964,
            "irrelevancy": 0.72194,
            "logical_agreement": 99.18166,
            "grammar_ref": 3.79365,
            "grammar_hyp": 3.43016,
            "nubia_score": 0.93546
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_656": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.02961067210860201,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.763819131706362,
        "bleu": 26.68173,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.8125,
            "fmeasure": 0.76471
        },
        "rouge2": {
            "precision": 0.5098,
            "recall": 0.72323,
            "fmeasure": 0.59524
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.84028,
            "fmeasure": 0.70458
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.84028,
            "fmeasure": 0.70458
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.9090909090909091
        },
        "bertscore": {
            "precision": 0.90204,
            "recall": 0.97063,
            "f1": 0.92451
        },
        "bleurt": 0.62807,
        "meteor": 0.43067097914530694,
        "nubia": {
            "semantic_relation": 4.249,
            "contradiction": 0.6484,
            "irrelevancy": 37.98953,
            "logical_agreement": 61.36206,
            "grammar_ref": 4.67419,
            "grammar_hyp": 4.05826,
            "nubia_score": 0.79134
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_623": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.018549068142959,
        "bleu": 69.85342,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "rouge2": {
            "precision": 0.80952,
            "recall": 0.90476,
            "fmeasure": 0.85348
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "local_recall": {
            "1": 0.2,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.95785,
            "recall": 0.97999,
            "f1": 0.96524
        },
        "bleurt": 0.6035,
        "meteor": 0.5255759325753065,
        "nubia": {
            "semantic_relation": 4.40194,
            "contradiction": 0.18499,
            "irrelevancy": 63.6692,
            "logical_agreement": 36.14582,
            "grammar_ref": 5.29735,
            "grammar_hyp": 4.41374,
            "nubia_score": 0.97573
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_624": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 94,
        "mean_pred_length": 23.5,
        "std_pred_length": 7.566372975210778,
        "median_pred_length": 23.5,
        "min_pred_length": 15,
        "max_pred_length": 32,
        "distinct-1": 0.723404255319149,
        "vocab_size-1": 68,
        "unique-1": 56,
        "entropy-1": 5.799061723925992,
        "distinct-2": 0.9777777777777777,
        "vocab_size-2": 88,
        "unique-2": 86,
        "entropy-2": 6.447408651885218,
        "cond_entropy-2": 0.5930370225259687,
        "distinct-3": 1.0,
        "vocab_size-3": 86,
        "unique-3": 86,
        "entropy-3": 6.426264754702099,
        "cond_entropy-3": -0.019076713720599846,
        "total_length-nopunct": 82,
        "mean_pred_length-nopunct": 20.5,
        "std_pred_length-nopunct": 6.652067347825035,
        "median_pred_length-nopunct": 21.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.8048780487804879,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.8817038337808425,
        "distinct-2-nopunct": 0.9871794871794872,
        "vocab_size-2-nopunct": 77,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 6.259761193221231,
        "cond_entropy-2-nopunct": 0.36931928485868704,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 74,
        "unique-3-nopunct": 74,
        "entropy-3-nopunct": 6.2094533656289554,
        "cond_entropy-3-nopunct": -0.048921826206271765,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.852604637520987,
        "bleu": 24.30749,
        "rouge1": {
            "precision": 0.54884,
            "recall": 0.54575,
            "fmeasure": 0.52674
        },
        "rouge2": {
            "precision": 0.24462,
            "recall": 0.22844,
            "fmeasure": 0.22952
        },
        "rougeL": {
            "precision": 0.43955,
            "recall": 0.42401,
            "fmeasure": 0.41572
        },
        "rougeLsum": {
            "precision": 0.43955,
            "recall": 0.42401,
            "fmeasure": 0.41572
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.42105263157894735,
            "3": 0.6481481481481481
        },
        "bertscore": {
            "precision": 0.86047,
            "recall": 0.86043,
            "f1": 0.85412
        },
        "bleurt": -0.03865,
        "meteor": 0.2872057345055799,
        "nubia": {
            "semantic_relation": 3.63308,
            "contradiction": 34.37327,
            "irrelevancy": 57.15678,
            "logical_agreement": 8.46995,
            "grammar_ref": 4.54253,
            "grammar_hyp": 3.51309,
            "nubia_score": 0.6055
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_625": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.16253715874966057,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.17355726227518525,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2803485632463203,
        "bleu": 38.98939,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.59903,
            "fmeasure": 0.6595
        },
        "rouge2": {
            "precision": 0.42222,
            "recall": 0.32576,
            "fmeasure": 0.36236
        },
        "rougeL": {
            "precision": 0.4375,
            "recall": 0.343,
            "fmeasure": 0.38103
        },
        "rougeLsum": {
            "precision": 0.4375,
            "recall": 0.343,
            "fmeasure": 0.38103
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.85098,
            "recall": 0.82866,
            "f1": 0.83967
        },
        "bleurt": -0.40856,
        "meteor": 0.27517149821687287,
        "nubia": {
            "semantic_relation": 2.99835,
            "contradiction": 1.53395,
            "irrelevancy": 44.35476,
            "logical_agreement": 54.11129,
            "grammar_ref": 4.61776,
            "grammar_hyp": 3.75797,
            "nubia_score": 0.47153
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_627": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.2543218437693073,
        "bleu": 8.54916,
        "rouge1": {
            "precision": 0.45238,
            "recall": 0.37905,
            "fmeasure": 0.40537
        },
        "rouge2": {
            "precision": 0.15385,
            "recall": 0.13287,
            "fmeasure": 0.14066
        },
        "rougeL": {
            "precision": 0.21429,
            "recall": 0.18634,
            "fmeasure": 0.19691
        },
        "rougeLsum": {
            "precision": 0.21429,
            "recall": 0.18634,
            "fmeasure": 0.19691
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.85226,
            "recall": 0.85528,
            "f1": 0.85377
        },
        "bleurt": -0.04435,
        "meteor": 0.2476600939068415,
        "nubia": {
            "semantic_relation": 3.76251,
            "contradiction": 0.06707,
            "irrelevancy": 99.33837,
            "logical_agreement": 0.59455,
            "grammar_ref": 4.57081,
            "grammar_hyp": 5.46625,
            "nubia_score": 0.44816
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_580": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 82,
        "mean_pred_length": 16.4,
        "std_pred_length": 6.711184694225007,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.7926829268292683,
        "vocab_size-1": 65,
        "unique-1": 53,
        "entropy-1": 5.880485962194139,
        "distinct-2": 0.948051948051948,
        "vocab_size-2": 73,
        "unique-2": 69,
        "entropy-2": 6.162890436798801,
        "cond_entropy-2": 0.16260823743171268,
        "distinct-3": 0.9583333333333334,
        "vocab_size-3": 69,
        "unique-3": 66,
        "entropy-3": 6.086591668108984,
        "cond_entropy-3": -0.06908376147481121,
        "total_length-nopunct": 74,
        "mean_pred_length-nopunct": 14.8,
        "std_pred_length-nopunct": 6.013318551349164,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8513513513513513,
        "vocab_size-1-nopunct": 63,
        "unique-1-nopunct": 53,
        "entropy-1-nopunct": 5.901954885869989,
        "distinct-2-nopunct": 0.9420289855072463,
        "vocab_size-2-nopunct": 65,
        "unique-2-nopunct": 61,
        "entropy-2-nopunct": 5.992582427792658,
        "cond_entropy-2-nopunct": 0.08392453320955974,
        "distinct-3-nopunct": 0.953125,
        "vocab_size-3-nopunct": 61,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.90625,
        "cond_entropy-3-nopunct": -0.09289945677816912,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8208936774694138,
        "bleu": 35.14445,
        "rouge1": {
            "precision": 0.64263,
            "recall": 0.77841,
            "fmeasure": 0.69092
        },
        "rouge2": {
            "precision": 0.46936,
            "recall": 0.57575,
            "fmeasure": 0.50502
        },
        "rougeL": {
            "precision": 0.56778,
            "recall": 0.69557,
            "fmeasure": 0.61235
        },
        "rougeLsum": {
            "precision": 0.56778,
            "recall": 0.69557,
            "fmeasure": 0.61235
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.8954,
            "recall": 0.93406,
            "f1": 0.90902
        },
        "bleurt": 0.20523,
        "meteor": 0.41828104037431985,
        "nubia": {
            "semantic_relation": 4.07047,
            "contradiction": 37.25479,
            "irrelevancy": 35.09422,
            "logical_agreement": 27.65098,
            "grammar_ref": 5.55931,
            "grammar_hyp": 5.34334,
            "nubia_score": 0.65584
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_476": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 3.0,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.9666666666666667,
        "vocab_size-1": 29,
        "unique-1": 28,
        "entropy-1": 4.840223928941852,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": -0.09953567355091442,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.754887502163471,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": -0.11103131238874399,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.860681258621119,
        "bleu": 75.03712,
        "rouge1": {
            "precision": 0.96667,
            "recall": 0.91176,
            "fmeasure": 0.9375
        },
        "rouge2": {
            "precision": 0.82143,
            "recall": 0.78125,
            "fmeasure": 0.8
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.77574,
            "fmeasure": 0.7873
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.77574,
            "fmeasure": 0.7873
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.9259259259259259
        },
        "bertscore": {
            "precision": 0.98338,
            "recall": 0.96912,
            "f1": 0.97615
        },
        "bleurt": 0.6652,
        "meteor": 0.5041557239228092,
        "nubia": {
            "semantic_relation": 4.87231,
            "contradiction": 0.46149,
            "irrelevancy": 0.57973,
            "logical_agreement": 98.95877,
            "grammar_ref": 5.04945,
            "grammar_hyp": 5.31197,
            "nubia_score": 0.89032
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_477": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 19.5,
        "std_pred_length": 5.5,
        "median_pred_length": 19.5,
        "min_pred_length": 14,
        "max_pred_length": 25,
        "distinct-1": 0.7948717948717948,
        "vocab_size-1": 31,
        "unique-1": 26,
        "entropy-1": 4.782590924645919,
        "distinct-2": 0.9459459459459459,
        "vocab_size-2": 35,
        "unique-2": 33,
        "entropy-2": 5.101345257520845,
        "cond_entropy-2": 0.29187926769742584,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": 0.034115365601730965,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.6261504319610545,
        "distinct-2-nopunct": 0.9393939393939394,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.923181998146335,
        "cond_entropy-2-nopunct": 0.3275244501236931,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": 0.03883444909293794,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.126393013600408,
        "bleu": 84.32728,
        "rouge1": {
            "precision": 0.85897,
            "recall": 0.89899,
            "fmeasure": 0.87778
        },
        "rouge2": {
            "precision": 0.76389,
            "recall": 0.79545,
            "fmeasure": 0.77866
        },
        "rougeL": {
            "precision": 0.85897,
            "recall": 0.89899,
            "fmeasure": 0.87778
        },
        "rougeLsum": {
            "precision": 0.85897,
            "recall": 0.89899,
            "fmeasure": 0.87778
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.5,
            "3": 0.9615384615384616
        },
        "bertscore": {
            "precision": 0.97635,
            "recall": 0.98161,
            "f1": 0.97897
        },
        "bleurt": 0.78449,
        "meteor": 0.6021033812809709,
        "nubia": {
            "semantic_relation": 4.99122,
            "contradiction": 0.25103,
            "irrelevancy": 1.47777,
            "logical_agreement": 98.2712,
            "grammar_ref": 3.8433,
            "grammar_hyp": 3.62517,
            "nubia_score": 0.99237
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_581": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 8,
        "unique-1": 7,
        "entropy-1": 2.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": 0.08007499855768763,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": 0.0930692077718899,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9767769323620341,
        "bleu": 24.839,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.67879,
            "fmeasure": 0.76413
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.53704,
            "fmeasure": 0.61275
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.67879,
            "fmeasure": 0.76413
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.67879,
            "fmeasure": 0.76413
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.97642,
            "recall": 0.95148,
            "f1": 0.96379
        },
        "bleurt": 0.604,
        "meteor": 0.41910267807653556,
        "nubia": {
            "semantic_relation": 4.74089,
            "contradiction": 0.54392,
            "irrelevancy": 0.53393,
            "logical_agreement": 98.92214,
            "grammar_ref": 4.19474,
            "grammar_hyp": 4.75139,
            "nubia_score": 0.91626
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_630": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 64,
        "mean_pred_length": 16.0,
        "std_pred_length": 3.605551275463989,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.546875,
        "vocab_size-1": 35,
        "unique-1": 22,
        "entropy-1": 4.746268266288633,
        "distinct-2": 0.8,
        "vocab_size-2": 48,
        "unique-2": 37,
        "entropy-2": 5.494309137239126,
        "cond_entropy-2": 0.698289653197919,
        "distinct-3": 0.8392857142857143,
        "vocab_size-3": 47,
        "unique-3": 38,
        "entropy-3": 5.485926350629036,
        "cond_entropy-3": 0.021087317559147594,
        "total_length-nopunct": 60,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 3.605551275463989,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.5666666666666667,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.702910079649726,
        "distinct-2-nopunct": 0.7857142857142857,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.365303359518974,
        "cond_entropy-2-nopunct": 0.730534745294872,
        "distinct-3-nopunct": 0.8269230769230769,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.354285871987248,
        "cond_entropy-3-nopunct": 0.003755709586631439,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.123089779977665,
        "bleu": 53.08803,
        "rouge1": {
            "precision": 0.81027,
            "recall": 0.78231,
            "fmeasure": 0.79007
        },
        "rouge2": {
            "precision": 0.66183,
            "recall": 0.64103,
            "fmeasure": 0.64553
        },
        "rougeL": {
            "precision": 0.78527,
            "recall": 0.75959,
            "fmeasure": 0.76626
        },
        "rougeLsum": {
            "precision": 0.78527,
            "recall": 0.75959,
            "fmeasure": 0.76626
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.803921568627451
        },
        "bertscore": {
            "precision": 0.9417,
            "recall": 0.94768,
            "f1": 0.94463
        },
        "bleurt": 0.52966,
        "meteor": 0.42430562798499655,
        "nubia": {
            "semantic_relation": 3.9928,
            "contradiction": 50.08199,
            "irrelevancy": 9.36531,
            "logical_agreement": 40.5527,
            "grammar_ref": 3.98368,
            "grammar_hyp": 4.01507,
            "nubia_score": 0.68171
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_632": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.7727272727272727,
        "vocab_size-1": 17,
        "unique-1": 13,
        "entropy-1": 3.9705730958116834,
        "distinct-2": 0.9523809523809523,
        "vocab_size-2": 20,
        "unique-2": 19,
        "entropy-2": 4.297079327540665,
        "cond_entropy-2": 0.3497852090063903,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": 0.029610672108601997,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.7841837197791888,
        "distinct-2-nopunct": 0.9473684210526315,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.142664355548846,
        "cond_entropy-2-nopunct": 0.3341513923543005,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": 0.03310859910983796,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2746868136747835,
        "bleu": 54.60462,
        "rouge1": {
            "precision": 0.85,
            "recall": 0.72503,
            "fmeasure": 0.78082
        },
        "rouge2": {
            "precision": 0.73684,
            "recall": 0.62393,
            "fmeasure": 0.67407
        },
        "rougeL": {
            "precision": 0.55,
            "recall": 0.46914,
            "fmeasure": 0.50523
        },
        "rougeLsum": {
            "precision": 0.55,
            "recall": 0.46914,
            "fmeasure": 0.50523
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.89728,
            "recall": 0.88616,
            "f1": 0.89169
        },
        "bleurt": -0.06088,
        "meteor": 0.36589287290769124,
        "nubia": {
            "semantic_relation": 4.23146,
            "contradiction": 3.58805,
            "irrelevancy": 1.22167,
            "logical_agreement": 95.19028,
            "grammar_ref": 5.07625,
            "grammar_hyp": 4.88269,
            "nubia_score": 0.7036
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_657": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 52,
        "mean_pred_length": 26.0,
        "std_pred_length": 7.0,
        "median_pred_length": 26.0,
        "min_pred_length": 19,
        "max_pred_length": 33,
        "distinct-1": 0.6923076923076923,
        "vocab_size-1": 36,
        "unique-1": 21,
        "entropy-1": 5.0705380354071785,
        "distinct-2": 0.9,
        "vocab_size-2": 45,
        "unique-2": 40,
        "entropy-2": 5.443856189774728,
        "cond_entropy-2": 0.35851422167690183,
        "distinct-3": 0.9375,
        "vocab_size-3": 45,
        "unique-3": 42,
        "entropy-3": 5.4599625007211605,
        "cond_entropy-3": 0.02443964427976505,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 22.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 22.5,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.7111111111111111,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.897300040726042,
        "distinct-2-nopunct": 0.8837209302325582,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.193706615167214,
        "cond_entropy-2-nopunct": 0.30080439098087614,
        "distinct-3-nopunct": 0.926829268292683,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.211210541203447,
        "cond_entropy-3-nopunct": 0.02884822552574178,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.132176596791134,
        "bleu": 40.78541,
        "rouge1": {
            "precision": 0.76071,
            "recall": 0.64996,
            "fmeasure": 0.69671
        },
        "rouge2": {
            "precision": 0.52425,
            "recall": 0.43433,
            "fmeasure": 0.47304
        },
        "rougeL": {
            "precision": 0.65952,
            "recall": 0.54953,
            "fmeasure": 0.59709
        },
        "rougeLsum": {
            "precision": 0.65952,
            "recall": 0.54953,
            "fmeasure": 0.59709
        },
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.26666666666666666,
            "3": 0.7575757575757576
        },
        "bertscore": {
            "precision": 0.92718,
            "recall": 0.91264,
            "f1": 0.91814
        },
        "bleurt": 0.28972,
        "meteor": 0.38372785007469506,
        "nubia": {
            "semantic_relation": 4.22342,
            "contradiction": 38.57752,
            "irrelevancy": 3.20542,
            "logical_agreement": 58.21706,
            "grammar_ref": 3.5955,
            "grammar_hyp": 3.4289,
            "nubia_score": 0.74409
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_635": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.282100621995838,
        "bleu": 63.40466,
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.77778,
            "fmeasure": 0.73684
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.97368,
            "recall": 0.98391,
            "f1": 0.97877
        },
        "bleurt": 0.59174,
        "meteor": 0.49956437727591835,
        "nubia": {
            "semantic_relation": 4.44341,
            "contradiction": 53.77061,
            "irrelevancy": 38.83098,
            "logical_agreement": 7.39841,
            "grammar_ref": 5.3705,
            "grammar_hyp": 4.99775,
            "nubia_score": 0.66513
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_549": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 3.0,
        "median_pred_length": 18.0,
        "min_pred_length": 15,
        "max_pred_length": 21,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 30,
        "unique-1": 26,
        "entropy-1": 4.79465347354434,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": 0.22165107518698668,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.08746284125033942,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.726409765557392,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": 0.1987201790139674,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.09953567355091442,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6032717183851943,
        "bleu": 18.71016,
        "rouge1": {
            "precision": 0.69841,
            "recall": 0.75675,
            "fmeasure": 0.71781
        },
        "rouge2": {
            "precision": 0.29186,
            "recall": 0.34359,
            "fmeasure": 0.31174
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.61916,
            "fmeasure": 0.5873
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.61916,
            "fmeasure": 0.5873
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.8,
            "3": 0.6956521739130435
        },
        "bertscore": {
            "precision": 0.92692,
            "recall": 0.93126,
            "f1": 0.92866
        },
        "bleurt": 0.07326,
        "meteor": 0.38590363339978395,
        "nubia": {
            "semantic_relation": 4.37002,
            "contradiction": 0.63842,
            "irrelevancy": 70.58916,
            "logical_agreement": 28.77242,
            "grammar_ref": 4.72797,
            "grammar_hyp": 4.64739,
            "nubia_score": 0.70095
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_636": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.033108599109837954,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.037537158749660585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0398761319201837,
        "bleu": 46.0002,
        "rouge1": {
            "precision": 0.89474,
            "recall": 0.76153,
            "fmeasure": 0.82269
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.55267,
            "fmeasure": 0.60427
        },
        "rougeL": {
            "precision": 0.82456,
            "recall": 0.69104,
            "fmeasure": 0.75184
        },
        "rougeLsum": {
            "precision": 0.82456,
            "recall": 0.69104,
            "fmeasure": 0.75184
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.7647058823529411
        },
        "bertscore": {
            "precision": 0.95573,
            "recall": 0.93158,
            "f1": 0.9435
        },
        "bleurt": 0.43261,
        "meteor": 0.41086177530149887,
        "nubia": {
            "semantic_relation": 4.34275,
            "contradiction": 0.11339,
            "irrelevancy": 1.47731,
            "logical_agreement": 98.40931,
            "grammar_ref": 3.0511,
            "grammar_hyp": 2.85893,
            "nubia_score": 0.92287
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_582": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 13.5,
        "std_pred_length": 3.774917217635375,
        "median_pred_length": 11.5,
        "min_pred_length": 11,
        "max_pred_length": 20,
        "distinct-1": 0.7407407407407407,
        "vocab_size-1": 40,
        "unique-1": 30,
        "entropy-1": 5.1713731502314895,
        "distinct-2": 0.84,
        "vocab_size-2": 42,
        "unique-2": 35,
        "entropy-2": 5.308758439731456,
        "cond_entropy-2": 0.024066437654525413,
        "distinct-3": 0.8913043478260869,
        "vocab_size-3": 41,
        "unique-3": 36,
        "entropy-3": 5.306170651709183,
        "cond_entropy-3": 0.026551146764102772,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.9154759474226504,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7708333333333334,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 5.095175521464346,
        "distinct-2-nopunct": 0.8181818181818182,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 5.078638720860853,
        "cond_entropy-2-nopunct": 0.027989288419856123,
        "distinct-3-nopunct": 0.875,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 5.071928094887363,
        "cond_entropy-3-nopunct": 0.0313686638041517,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.370638223410693,
        "bleu": 74.31053,
        "rouge1": {
            "precision": 0.975,
            "recall": 0.92643,
            "fmeasure": 0.94807
        },
        "rouge2": {
            "precision": 0.89425,
            "recall": 0.86591,
            "fmeasure": 0.87912
        },
        "rougeL": {
            "precision": 0.94167,
            "recall": 0.88839,
            "fmeasure": 0.91141
        },
        "rougeLsum": {
            "precision": 0.94167,
            "recall": 0.88839,
            "fmeasure": 0.91141
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9024390243902439
        },
        "bertscore": {
            "precision": 0.98748,
            "recall": 0.98115,
            "f1": 0.98304
        },
        "bleurt": 0.7087,
        "meteor": 0.5559131802200744,
        "nubia": {
            "semantic_relation": 4.80972,
            "contradiction": 0.2607,
            "irrelevancy": 8.77328,
            "logical_agreement": 90.96602,
            "grammar_ref": 5.18336,
            "grammar_hyp": 5.03931,
            "nubia_score": 0.94183
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_550": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 23.5,
        "std_pred_length": 5.5,
        "median_pred_length": 23.5,
        "min_pred_length": 18,
        "max_pred_length": 29,
        "distinct-1": 0.8936170212765957,
        "vocab_size-1": 42,
        "unique-1": 38,
        "entropy-1": 5.325761458014587,
        "distinct-2": 0.9777777777777777,
        "vocab_size-2": 44,
        "unique-2": 43,
        "entropy-2": 5.447408651885229,
        "cond_entropy-2": 0.08737285581122535,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.019076713720599835,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 20.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 20.5,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.926829268292683,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.192798650906777,
        "distinct-2-nopunct": 0.9743589743589743,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.234120167580196,
        "cond_entropy-2-nopunct": 0.049770406607330814,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.02189479917924466,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.452738070535388,
        "bleu": 41.04025,
        "rouge1": {
            "precision": 0.77529,
            "recall": 0.76135,
            "fmeasure": 0.76696
        },
        "rouge2": {
            "precision": 0.57986,
            "recall": 0.56888,
            "fmeasure": 0.57322
        },
        "rougeL": {
            "precision": 0.60941,
            "recall": 0.59897,
            "fmeasure": 0.60336
        },
        "rougeLsum": {
            "precision": 0.60941,
            "recall": 0.59897,
            "fmeasure": 0.60336
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.93435,
            "recall": 0.93529,
            "f1": 0.93477
        },
        "bleurt": 0.31178,
        "meteor": 0.4254809115718414,
        "nubia": {
            "semantic_relation": 4.44122,
            "contradiction": 0.29077,
            "irrelevancy": 26.63139,
            "logical_agreement": 73.07784,
            "grammar_ref": 4.42501,
            "grammar_hyp": 4.43262,
            "nubia_score": 0.76516
        }
    },
    "web_nlg_en_validation": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_validation",
        "N": 1667,
        "msttr-100": 0.56005,
        "msttr-100_nopunct": 0.58802,
        "total_length": 36737,
        "mean_pred_length": 22.037792441511698,
        "std_pred_length": 11.28447179025203,
        "median_pred_length": 21.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.09804828919073413,
        "vocab_size-1": 3602,
        "unique-1": 1187,
        "entropy-1": 8.757995012388777,
        "distinct-2": 0.33033932135728544,
        "vocab_size-2": 11585,
        "unique-2": 6331,
        "entropy-2": 12.297004834973201,
        "cond_entropy-2": 3.309901674453943,
        "distinct-3": 0.5419273717929527,
        "vocab_size-3": 18102,
        "unique-3": 12422,
        "entropy-3": 13.5311576250125,
        "cond_entropy-3": 1.2798885655594148,
        "total_length-nopunct": 32416,
        "mean_pred_length-nopunct": 19.445710857828434,
        "std_pred_length-nopunct": 10.085294218201398,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.11077862783810465,
        "vocab_size-1-nopunct": 3591,
        "unique-1-nopunct": 1186,
        "entropy-1-nopunct": 9.143033301514967,
        "distinct-2-nopunct": 0.3460275130898566,
        "vocab_size-2-nopunct": 10640,
        "unique-2-nopunct": 6014,
        "entropy-2-nopunct": 12.193193674368553,
        "cond_entropy-2-nopunct": 3.1925849961512798,
        "distinct-3-nopunct": 0.5520253077504986,
        "vocab_size-3-nopunct": 16054,
        "unique-3-nopunct": 11189,
        "entropy-3-nopunct": 13.360422996241127,
        "cond_entropy-3-nopunct": 1.216407792240574,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_validation.json",
        "nist": 11.391998400620162,
        "bleu": 62.4249,
        "rouge1": {
            "precision": 0.83177,
            "recall": 0.82342,
            "fmeasure": 0.82269
        },
        "rouge2": {
            "precision": 0.62403,
            "recall": 0.61814,
            "fmeasure": 0.61719
        },
        "rougeL": {
            "precision": 0.70259,
            "recall": 0.69746,
            "fmeasure": 0.69562
        },
        "rougeLsum": {
            "precision": 0.70259,
            "recall": 0.69746,
            "fmeasure": 0.69562
        },
        "local_recall": {
            "1": 0.3233927768619811,
            "2": 0.7368773946360153,
            "3": 0.9424209378407852,
            "4": 0.900709219858156,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0,
            "8": 1.0
        },
        "bertscore": {
            "precision": 0.95354,
            "recall": 0.95405,
            "f1": 0.95297
        },
        "bleurt": 0.43101,
        "meteor": 0.4581833929983367,
        "nubia": {
            "semantic_relation": 4.76176,
            "contradiction": 2.62034,
            "irrelevancy": 3.81343,
            "logical_agreement": 93.56623,
            "grammar_ref": 4.59465,
            "grammar_hyp": 4.57459,
            "nubia_score": 0.89269
        }
    },
    "schema_guided_dialog_challenge_test_bfp05_parent": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.67918,
        "msttr-100_nopunct": 0.70333,
        "total_length": 6177,
        "mean_pred_length": 12.354,
        "std_pred_length": 7.089194876712023,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 42,
        "distinct-1": 0.1559009227780476,
        "vocab_size-1": 963,
        "unique-1": 550,
        "entropy-1": 7.727961440433858,
        "distinct-2": 0.46115906288532676,
        "vocab_size-2": 2618,
        "unique-2": 1823,
        "entropy-2": 10.461113097860826,
        "cond_entropy-2": 2.4841740234814007,
        "distinct-3": 0.6644774966196639,
        "vocab_size-3": 3440,
        "unique-3": 2793,
        "entropy-3": 11.248386500589096,
        "cond_entropy-3": 0.8106919257040641,
        "total_length-nopunct": 5435,
        "mean_pred_length-nopunct": 10.87,
        "std_pred_length-nopunct": 6.553556286475306,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.17516099356025758,
        "vocab_size-1-nopunct": 952,
        "unique-1-nopunct": 547,
        "entropy-1-nopunct": 7.902526012067022,
        "distinct-2-nopunct": 0.47477203647416416,
        "vocab_size-2-nopunct": 2343,
        "unique-2-nopunct": 1679,
        "entropy-2-nopunct": 10.275337869140985,
        "cond_entropy-2-nopunct": 2.5038021211765993,
        "distinct-3-nopunct": 0.67576099210823,
        "vocab_size-3-nopunct": 2997,
        "unique-3-nopunct": 2478,
        "entropy-3-nopunct": 11.039515644963725,
        "cond_entropy-3-nopunct": 0.7977213077457478,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.216683852845533,
        "bleu": 33.7788,
        "rouge1": {
            "precision": 0.59301,
            "recall": 0.56224,
            "fmeasure": 0.56566
        },
        "rouge2": {
            "precision": 0.37232,
            "recall": 0.35066,
            "fmeasure": 0.35311
        },
        "rougeL": {
            "precision": 0.53832,
            "recall": 0.50884,
            "fmeasure": 0.51267
        },
        "rougeLsum": {
            "precision": 0.53832,
            "recall": 0.50884,
            "fmeasure": 0.51267
        },
        "local_recall": {
            "1": 0.5776841333821913
        },
        "bertscore": {
            "precision": 0.87824,
            "recall": 0.87027,
            "f1": 0.87379
        },
        "bleurt": -0.03603,
        "meteor": 0.32433485532269696,
        "nubia": {
            "semantic_relation": 3.62898,
            "contradiction": 7.17231,
            "irrelevancy": 21.43463,
            "logical_agreement": 71.39306,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.60912,
            "nubia_score": 0.64274
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_660": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 10.666666666666666,
        "std_pred_length": 2.494438257849294,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 14,
        "distinct-1": 0.84375,
        "vocab_size-1": 27,
        "unique-1": 24,
        "entropy-1": 4.640319531114783,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.09090815037458831,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.15754127698647996,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 2.160246899469287,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9259259259259259,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.578780557638898,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.02819531114783215,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.19264507794239577,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0294262036953996,
        "bleu": 23.95511,
        "rouge1": {
            "precision": 0.75794,
            "recall": 0.53045,
            "fmeasure": 0.62014
        },
        "rouge2": {
            "precision": 0.46777,
            "recall": 0.3045,
            "fmeasure": 0.36526
        },
        "rougeL": {
            "precision": 0.61574,
            "recall": 0.42964,
            "fmeasure": 0.50296
        },
        "rougeLsum": {
            "precision": 0.61574,
            "recall": 0.42964,
            "fmeasure": 0.50296
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.5,
            "3": 0.5833333333333334
        },
        "bertscore": {
            "precision": 0.89539,
            "recall": 0.86309,
            "f1": 0.87843
        },
        "bleurt": -0.00969,
        "meteor": 0.30341214505295405,
        "nubia": {
            "semantic_relation": 3.61751,
            "contradiction": 10.50632,
            "irrelevancy": 25.02735,
            "logical_agreement": 64.46633,
            "grammar_ref": 4.31237,
            "grammar_hyp": 4.99093,
            "nubia_score": 0.55091
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_637": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8204580279315103,
        "bleu": 48.32698,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.72365,
            "fmeasure": 0.72311
        },
        "rouge2": {
            "precision": 0.40741,
            "recall": 0.34722,
            "fmeasure": 0.37162
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.63248,
            "fmeasure": 0.67429
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.63248,
            "fmeasure": 0.67429
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.2857142857142857,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.93117,
            "recall": 0.90925,
            "f1": 0.92008
        },
        "bleurt": 0.43562,
        "meteor": 0.37194330680678134,
        "nubia": {
            "semantic_relation": 4.58758,
            "contradiction": 0.13568,
            "irrelevancy": 0.81852,
            "logical_agreement": 99.0458,
            "grammar_ref": 5.94843,
            "grammar_hyp": 5.82569,
            "nubia_score": 0.87078
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_480": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.79,
        "total_length": 176,
        "mean_pred_length": 17.6,
        "std_pred_length": 3.6932370625238775,
        "median_pred_length": 17.0,
        "min_pred_length": 13,
        "max_pred_length": 26,
        "distinct-1": 0.6420454545454546,
        "vocab_size-1": 113,
        "unique-1": 95,
        "entropy-1": 6.329939989127478,
        "distinct-2": 0.9096385542168675,
        "vocab_size-2": 151,
        "unique-2": 140,
        "entropy-2": 7.173173316863013,
        "cond_entropy-2": 0.7111588418694402,
        "distinct-3": 0.9615384615384616,
        "vocab_size-3": 150,
        "unique-3": 144,
        "entropy-3": 7.208479141939189,
        "cond_entropy-3": 0.048245960619983486,
        "total_length-nopunct": 159,
        "mean_pred_length-nopunct": 15.9,
        "std_pred_length-nopunct": 3.5341194094144583,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6855345911949685,
        "vocab_size-1-nopunct": 109,
        "unique-1-nopunct": 93,
        "entropy-1-nopunct": 6.34457097182258,
        "distinct-2-nopunct": 0.9060402684563759,
        "vocab_size-2-nopunct": 135,
        "unique-2-nopunct": 125,
        "entropy-2-nopunct": 7.007693520433129,
        "cond_entropy-2-nopunct": 0.7107611884353292,
        "distinct-3-nopunct": 0.9640287769784173,
        "vocab_size-3-nopunct": 134,
        "unique-3-nopunct": 129,
        "entropy-3-nopunct": 7.046998626680358,
        "cond_entropy-3-nopunct": 0.05451913502628784,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.447697600548072,
        "bleu": 50.1482,
        "rouge1": {
            "precision": 0.83074,
            "recall": 0.76336,
            "fmeasure": 0.78961
        },
        "rouge2": {
            "precision": 0.62333,
            "recall": 0.57989,
            "fmeasure": 0.59542
        },
        "rougeL": {
            "precision": 0.70879,
            "recall": 0.65299,
            "fmeasure": 0.67389
        },
        "rougeLsum": {
            "precision": 0.70879,
            "recall": 0.65299,
            "fmeasure": 0.67389
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.3888888888888889,
            "3": 0.811965811965812
        },
        "bertscore": {
            "precision": 0.93926,
            "recall": 0.93001,
            "f1": 0.93422
        },
        "bleurt": 0.31823,
        "meteor": 0.41012927367166535,
        "nubia": {
            "semantic_relation": 4.34116,
            "contradiction": 23.70089,
            "irrelevancy": 16.51012,
            "logical_agreement": 59.78899,
            "grammar_ref": 4.07874,
            "grammar_hyp": 4.5049,
            "nubia_score": 0.73942
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_552": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 41,
        "mean_pred_length": 13.666666666666666,
        "std_pred_length": 3.0912061651652345,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 18,
        "distinct-1": 0.8048780487804879,
        "vocab_size-1": 33,
        "unique-1": 27,
        "entropy-1": 4.930484321585718,
        "distinct-2": 1.0,
        "vocab_size-2": 38,
        "unique-2": 38,
        "entropy-2": 5.247927513443589,
        "cond_entropy-2": 0.22603044309296155,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": -0.11864449649861893,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.160246899469287,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8611111111111112,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.871178126382214,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.20037479979988243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.13750352374993471,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0156286580352387,
        "bleu": 13.03651,
        "rouge1": {
            "precision": 0.51852,
            "recall": 0.55094,
            "fmeasure": 0.53217
        },
        "rouge2": {
            "precision": 0.16017,
            "recall": 0.14986,
            "fmeasure": 0.1515
        },
        "rougeL": {
            "precision": 0.45185,
            "recall": 0.41929,
            "fmeasure": 0.42843
        },
        "rougeLsum": {
            "precision": 0.45185,
            "recall": 0.41929,
            "fmeasure": 0.42843
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.25,
            "3": 0.5517241379310345
        },
        "bertscore": {
            "precision": 0.85675,
            "recall": 0.85885,
            "f1": 0.85278
        },
        "bleurt": -0.04887,
        "meteor": 0.25535985295056635,
        "nubia": {
            "semantic_relation": 3.66116,
            "contradiction": 14.31431,
            "irrelevancy": 40.19493,
            "logical_agreement": 45.49077,
            "grammar_ref": 4.76688,
            "grammar_hyp": 4.5642,
            "nubia_score": 0.58559
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_663": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 4.784233364802441,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 20,
        "distinct-1": 0.775,
        "vocab_size-1": 31,
        "unique-1": 25,
        "entropy-1": 4.803055907333277,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.3199577031740197,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.12199052437861026,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 11.333333333333334,
        "std_pred_length-nopunct": 3.39934634239519,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7941176470588235,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.616874605956221,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.3828625013946004,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.14684138832927116,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.8505135439008535,
        "bleu": 71.01094,
        "rouge1": {
            "precision": 0.7665,
            "recall": 0.73529,
            "fmeasure": 0.73289
        },
        "rouge2": {
            "precision": 0.59502,
            "recall": 0.58611,
            "fmeasure": 0.5767
        },
        "rougeL": {
            "precision": 0.7665,
            "recall": 0.73529,
            "fmeasure": 0.73289
        },
        "rougeLsum": {
            "precision": 0.7665,
            "recall": 0.73529,
            "fmeasure": 0.73289
        },
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.0,
            "3": 0.7916666666666666
        },
        "bertscore": {
            "precision": 0.96433,
            "recall": 0.93556,
            "f1": 0.94596
        },
        "bleurt": 0.37244,
        "meteor": 0.4479442561078186,
        "nubia": {
            "semantic_relation": 3.67532,
            "contradiction": 33.7249,
            "irrelevancy": 12.43252,
            "logical_agreement": 53.84258,
            "grammar_ref": 4.11451,
            "grammar_hyp": 3.59576,
            "nubia_score": 0.67171
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_553": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 8.178562764256865,
        "median_pred_length": 12.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.7872340425531915,
        "vocab_size-1": 37,
        "unique-1": 29,
        "entropy-1": 5.096934064351535,
        "distinct-2": 0.9772727272727273,
        "vocab_size-2": 43,
        "unique-2": 42,
        "entropy-2": 5.41397707318275,
        "cond_entropy-2": 0.2401811192815566,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.05309912621433558,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 4.988876515698588,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8918918918918919,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.993237149412737,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.087462841250338,
        "cond_entropy-2-nopunct": 0.1133035932684486,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.13326653086346418,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.116078847230159,
        "bleu": 28.4552,
        "rouge1": {
            "precision": 0.73251,
            "recall": 0.66366,
            "fmeasure": 0.69253
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.37582,
            "fmeasure": 0.39272
        },
        "rougeL": {
            "precision": 0.68719,
            "recall": 0.61834,
            "fmeasure": 0.64721
        },
        "rougeLsum": {
            "precision": 0.68719,
            "recall": 0.61834,
            "fmeasure": 0.64721
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.5652173913043478,
            "3": 0.6470588235294118
        },
        "bertscore": {
            "precision": 0.9311,
            "recall": 0.91464,
            "f1": 0.92273
        },
        "bleurt": 0.35377,
        "meteor": 0.3239956064488769,
        "nubia": {
            "semantic_relation": 4.19046,
            "contradiction": 0.25694,
            "irrelevancy": 0.98942,
            "logical_agreement": 98.75364,
            "grammar_ref": 4.61531,
            "grammar_hyp": 4.76586,
            "nubia_score": 0.7277
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_665": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.09251370597287,
        "bleu": 67.29865,
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.81667,
            "fmeasure": 0.82857
        },
        "rouge2": {
            "precision": 0.70833,
            "recall": 0.68506,
            "fmeasure": 0.69398
        },
        "rougeL": {
            "precision": 0.84615,
            "recall": 0.81667,
            "fmeasure": 0.82857
        },
        "rougeLsum": {
            "precision": 0.84615,
            "recall": 0.81667,
            "fmeasure": 0.82857
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 1.0
        },
        "bertscore": {
            "precision": 0.9565,
            "recall": 0.9669,
            "f1": 0.96167
        },
        "bleurt": 0.67946,
        "meteor": 0.5934341018717497,
        "nubia": {
            "semantic_relation": 4.67622,
            "contradiction": 0.49994,
            "irrelevancy": 0.68259,
            "logical_agreement": 98.81746,
            "grammar_ref": 5.25223,
            "grammar_hyp": 5.20882,
            "nubia_score": 0.8468
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_483": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.449489742783178,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 15,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 30,
        "unique-1": 26,
        "entropy-1": 4.79465347354434,
        "distinct-2": 1.0,
        "vocab_size-2": 33,
        "unique-2": 33,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": 0.1397687391938218,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.13750352374993471,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 10.666666666666666,
        "std_pred_length-nopunct": 2.494438257849294,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.726409765557392,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.12539090899527794,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.15754127698647996,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8577434893006353,
        "bleu": 43.70465,
        "rouge1": {
            "precision": 0.72344,
            "recall": 0.80149,
            "fmeasure": 0.74472
        },
        "rouge2": {
            "precision": 0.59402,
            "recall": 0.62302,
            "fmeasure": 0.59813
        },
        "rougeL": {
            "precision": 0.72344,
            "recall": 0.80149,
            "fmeasure": 0.74472
        },
        "rougeLsum": {
            "precision": 0.72344,
            "recall": 0.80149,
            "fmeasure": 0.74472
        },
        "local_recall": {
            "1": 0.0625,
            "2": 0.7692307692307693,
            "3": 0.9166666666666666
        },
        "bertscore": {
            "precision": 0.91223,
            "recall": 0.94662,
            "f1": 0.92695
        },
        "bleurt": 0.44331,
        "meteor": 0.4574491164287982,
        "nubia": {
            "semantic_relation": 4.3854,
            "contradiction": 0.41561,
            "irrelevancy": 33.59309,
            "logical_agreement": 65.9913,
            "grammar_ref": 5.27099,
            "grammar_hyp": 5.02168,
            "nubia_score": 0.85582
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_640": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 13.25,
        "std_pred_length": 7.292976072907411,
        "median_pred_length": 13.0,
        "min_pred_length": 4,
        "max_pred_length": 23,
        "distinct-1": 0.8679245283018868,
        "vocab_size-1": 46,
        "unique-1": 41,
        "entropy-1": 5.426033662110366,
        "distinct-2": 1.0,
        "vocab_size-2": 49,
        "unique-2": 49,
        "entropy-2": 5.614709844115208,
        "cond_entropy-2": 0.05005469567445818,
        "distinct-3": 1.0,
        "vocab_size-3": 45,
        "unique-3": 45,
        "entropy-3": 5.491853096329673,
        "cond_entropy-3": -0.12285674778553377,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 6.96419413859206,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.418295834054493,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.4594316186372955,
        "cond_entropy-2-nopunct": 0.03356002700705,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.13750352374993507,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.988893050047741,
        "bleu": 44.41281,
        "rouge1": {
            "precision": 0.81448,
            "recall": 0.67838,
            "fmeasure": 0.73283
        },
        "rouge2": {
            "precision": 0.475,
            "recall": 0.42045,
            "fmeasure": 0.44524
        },
        "rougeL": {
            "precision": 0.76687,
            "recall": 0.6349,
            "fmeasure": 0.68737
        },
        "rougeLsum": {
            "precision": 0.76687,
            "recall": 0.6349,
            "fmeasure": 0.68737
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.7333333333333333
        },
        "bertscore": {
            "precision": 0.92916,
            "recall": 0.87316,
            "f1": 0.89994
        },
        "bleurt": 0.24791,
        "meteor": 0.38074399835072975,
        "nubia": {
            "semantic_relation": 4.20493,
            "contradiction": 2.84957,
            "irrelevancy": 2.96328,
            "logical_agreement": 94.18716,
            "grammar_ref": 4.34153,
            "grammar_hyp": 5.59647,
            "nubia_score": 0.6767
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_555": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.3764992953429935,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.91462,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.23486,
            "irrelevancy": 0.53273,
            "logical_agreement": 99.23241,
            "grammar_ref": 4.18747,
            "grammar_hyp": 4.4235,
            "nubia_score": 0.98266
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_642": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 56,
        "mean_pred_length": 18.666666666666668,
        "std_pred_length": 2.6246692913372702,
        "median_pred_length": 20.0,
        "min_pred_length": 15,
        "max_pred_length": 21,
        "distinct-1": 0.7678571428571429,
        "vocab_size-1": 43,
        "unique-1": 35,
        "entropy-1": 5.266914520155993,
        "distinct-2": 1.0,
        "vocab_size-2": 53,
        "unique-2": 53,
        "entropy-2": 5.727920454563195,
        "cond_entropy-2": 0.3783893533827723,
        "distinct-3": 1.0,
        "vocab_size-3": 50,
        "unique-3": 50,
        "entropy-3": 5.643856189774728,
        "cond_entropy-3": -0.08406426478847459,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 3.39934634239519,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8297872340425532,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.182040447330258,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.4594316186372955,
        "cond_entropy-2-nopunct": 0.3027921988761809,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.10187961401921372,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.130508558851462,
        "bleu": 36.28921,
        "rouge1": {
            "precision": 0.82702,
            "recall": 0.82858,
            "fmeasure": 0.8271
        },
        "rouge2": {
            "precision": 0.62546,
            "recall": 0.62653,
            "fmeasure": 0.62552
        },
        "rougeL": {
            "precision": 0.64507,
            "recall": 0.65261,
            "fmeasure": 0.64867
        },
        "rougeLsum": {
            "precision": 0.64507,
            "recall": 0.65261,
            "fmeasure": 0.64867
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.5714285714285714,
            "3": 0.8108108108108109
        },
        "bertscore": {
            "precision": 0.92625,
            "recall": 0.93993,
            "f1": 0.93304
        },
        "bleurt": 0.31633,
        "meteor": 0.4244502810484395,
        "nubia": {
            "semantic_relation": 4.72969,
            "contradiction": 0.1898,
            "irrelevancy": 12.03714,
            "logical_agreement": 87.77306,
            "grammar_ref": 4.591,
            "grammar_hyp": 4.49688,
            "nubia_score": 0.895
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_667": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.11768784439846629,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.129610672108602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4527500603034875,
        "bleu": 10.62492,
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.59048,
            "fmeasure": 0.58072
        },
        "rouge2": {
            "precision": 0.23333,
            "recall": 0.23684,
            "fmeasure": 0.23504
        },
        "rougeL": {
            "precision": 0.31746,
            "recall": 0.32222,
            "fmeasure": 0.31978
        },
        "rougeLsum": {
            "precision": 0.31746,
            "recall": 0.32222,
            "fmeasure": 0.31978
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.82423,
            "recall": 0.81902,
            "f1": 0.82162
        },
        "bleurt": -0.33972,
        "meteor": 0.28678969974909313,
        "nubia": {
            "semantic_relation": 3.69631,
            "contradiction": 0.08513,
            "irrelevancy": 99.73088,
            "logical_agreement": 0.18399,
            "grammar_ref": 4.46991,
            "grammar_hyp": 4.11428,
            "nubia_score": 0.63663
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_644": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 1.0,
        "median_pred_length": 15.0,
        "min_pred_length": 14,
        "max_pred_length": 16,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 28,
        "unique-1": 26,
        "entropy-1": 4.773557262275186,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": -0.028107102122342922,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9642857142857143,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.735926350629034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": -0.029992126993435272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.343452825284802,
        "bleu": 66.14566,
        "rouge1": {
            "precision": 0.88259,
            "recall": 0.85519,
            "fmeasure": 0.86838
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.75307,
            "fmeasure": 0.76494
        },
        "rougeL": {
            "precision": 0.88259,
            "recall": 0.85519,
            "fmeasure": 0.86838
        },
        "rougeLsum": {
            "precision": 0.88259,
            "recall": 0.85519,
            "fmeasure": 0.86838
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.92
        },
        "bertscore": {
            "precision": 0.97618,
            "recall": 0.97039,
            "f1": 0.97327
        },
        "bleurt": 0.55603,
        "meteor": 0.48425296272997537,
        "nubia": {
            "semantic_relation": 4.68308,
            "contradiction": 1.15161,
            "irrelevancy": 2.39387,
            "logical_agreement": 96.45452,
            "grammar_ref": 4.65278,
            "grammar_hyp": 4.67846,
            "nubia_score": 0.88145
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_560": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 57,
        "mean_pred_length": 19.0,
        "std_pred_length": 5.887840577551898,
        "median_pred_length": 17.0,
        "min_pred_length": 13,
        "max_pred_length": 27,
        "distinct-1": 0.7719298245614035,
        "vocab_size-1": 44,
        "unique-1": 35,
        "entropy-1": 5.315174663211634,
        "distinct-2": 0.9629629629629629,
        "vocab_size-2": 52,
        "unique-2": 50,
        "entropy-2": 5.680813428089393,
        "cond_entropy-2": 0.3063472565573095,
        "distinct-3": 0.9803921568627451,
        "vocab_size-3": 50,
        "unique-3": 49,
        "entropy-3": 5.63320965569699,
        "cond_entropy-3": -0.043246473917463175,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 4.189935029992178,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8163265306122449,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.191140711417995,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.5235619560570095,
        "cond_entropy-2-nopunct": 0.33830618807579277,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.426264754702098,
        "cond_entropy-3-nopunct": -0.09729720135491506,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.5528157869750014,
        "bleu": 38.67279,
        "rouge1": {
            "precision": 0.64731,
            "recall": 0.6242,
            "fmeasure": 0.63128
        },
        "rouge2": {
            "precision": 0.4038,
            "recall": 0.3807,
            "fmeasure": 0.38922
        },
        "rougeL": {
            "precision": 0.6271,
            "recall": 0.60192,
            "fmeasure": 0.61011
        },
        "rougeLsum": {
            "precision": 0.6271,
            "recall": 0.60192,
            "fmeasure": 0.61011
        },
        "local_recall": {
            "1": 0.35294117647058826,
            "2": 0.0,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.92244,
            "recall": 0.90619,
            "f1": 0.9108
        },
        "bleurt": 0.33714,
        "meteor": 0.4088301843924897,
        "nubia": {
            "semantic_relation": 4.10766,
            "contradiction": 0.20206,
            "irrelevancy": 14.39625,
            "logical_agreement": 85.4017,
            "grammar_ref": 4.73268,
            "grammar_hyp": 4.08395,
            "nubia_score": 0.78775
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_670": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.0316004400734653,
        "bleu": 50.66546,
        "rouge1": {
            "precision": 0.74074,
            "recall": 0.54924,
            "fmeasure": 0.62667
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.4,
            "fmeasure": 0.45733
        },
        "rougeL": {
            "precision": 0.74074,
            "recall": 0.54924,
            "fmeasure": 0.62667
        },
        "rougeLsum": {
            "precision": 0.74074,
            "recall": 0.54924,
            "fmeasure": 0.62667
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.5555555555555556
        },
        "bertscore": {
            "precision": 0.93758,
            "recall": 0.91397,
            "f1": 0.92563
        },
        "bleurt": 0.26082,
        "meteor": 0.38825000730456566,
        "nubia": {
            "semantic_relation": 4.10711,
            "contradiction": 0.56773,
            "irrelevancy": 0.50794,
            "logical_agreement": 98.92433,
            "grammar_ref": 4.84054,
            "grammar_hyp": 4.44408,
            "nubia_score": 0.77938
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_561": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.7735572622751845,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.043321469306228516,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.046930949929641655,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.6017006625380596,
        "bleu": 45.46697,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rouge2": {
            "precision": 0.81818,
            "recall": 0.81818,
            "fmeasure": 0.81818
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.89081,
            "recall": 0.92678,
            "f1": 0.90844
        },
        "bleurt": -0.11575,
        "meteor": 0.4486121983053691,
        "nubia": {
            "semantic_relation": 4.27352,
            "contradiction": 6.06656,
            "irrelevancy": 34.69403,
            "logical_agreement": 59.23942,
            "grammar_ref": 4.85143,
            "grammar_hyp": 5.53057,
            "nubia_score": 0.55699
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_564": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 1.5,
        "median_pred_length": 12.5,
        "min_pred_length": 11,
        "max_pred_length": 14,
        "distinct-1": 0.68,
        "vocab_size-1": 17,
        "unique-1": 10,
        "entropy-1": 3.973660689688184,
        "distinct-2": 0.782608695652174,
        "vocab_size-2": 18,
        "unique-2": 13,
        "entropy-2": 4.088779347361361,
        "cond_entropy-2": 0.08644000550678686,
        "distinct-3": 0.8095238095238095,
        "vocab_size-3": 17,
        "unique-3": 13,
        "entropy-3": 4.011365041826378,
        "cond_entropy-3": -0.03600643804015717,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.6818181818181818,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.788754913993502,
        "distinct-2-nopunct": 0.75,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.8219280948873626,
        "cond_entropy-2-nopunct": 0.10024085135823842,
        "distinct-3-nopunct": 0.7777777777777778,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.7254805569978675,
        "cond_entropy-3-nopunct": -0.04089198233393865,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.50723024425183,
        "bleu": 79.33704,
        "rouge1": {
            "precision": 0.89153,
            "recall": 0.92857,
            "fmeasure": 0.90774
        },
        "rouge2": {
            "precision": 0.84776,
            "recall": 0.88248,
            "fmeasure": 0.86264
        },
        "rougeL": {
            "precision": 0.83201,
            "recall": 0.86905,
            "fmeasure": 0.84821
        },
        "rougeLsum": {
            "precision": 0.83201,
            "recall": 0.86905,
            "fmeasure": 0.84821
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.6666666666666666,
            "3": 0.9375
        },
        "bertscore": {
            "precision": 0.9864,
            "recall": 0.9864,
            "f1": 0.9864
        },
        "bleurt": 0.57687,
        "meteor": 0.5757164646767627,
        "nubia": {
            "semantic_relation": 3.98309,
            "contradiction": 46.89232,
            "irrelevancy": 2.95218,
            "logical_agreement": 50.1555,
            "grammar_ref": 4.81259,
            "grammar_hyp": 4.25894,
            "nubia_score": 0.71371
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_700": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 8.5,
        "std_pred_length": 0.5,
        "median_pred_length": 8.5,
        "min_pred_length": 8,
        "max_pred_length": 9,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.18057224564182078,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.2064508774674265,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 6.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 6.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.24100809950379498,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.2895066171949847,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.475016750213334,
        "bleu": 100.0,
        "rouge1": {
            "precision": 0.97222,
            "recall": 0.95556,
            "fmeasure": 0.96345
        },
        "rouge2": {
            "precision": 0.93333,
            "recall": 0.91481,
            "fmeasure": 0.92353
        },
        "rougeL": {
            "precision": 0.97222,
            "recall": 0.95556,
            "fmeasure": 0.96345
        },
        "rougeLsum": {
            "precision": 0.97222,
            "recall": 0.95556,
            "fmeasure": 0.96345
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.5,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.63231,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.57359,
            "contradiction": 7.89581,
            "irrelevancy": 3.11481,
            "logical_agreement": 88.98938,
            "grammar_ref": 5.35128,
            "grammar_hyp": 5.66336,
            "nubia_score": 0.83692
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_702": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.963073623196114,
        "bleu": 26.13023,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.84175,
            "fmeasure": 0.77571
        },
        "rouge2": {
            "precision": 0.42424,
            "recall": 0.5,
            "fmeasure": 0.45781
        },
        "rougeL": {
            "precision": 0.63889,
            "recall": 0.74411,
            "fmeasure": 0.68599
        },
        "rougeLsum": {
            "precision": 0.63889,
            "recall": 0.74411,
            "fmeasure": 0.68599
        },
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.88277,
            "recall": 0.93209,
            "f1": 0.90676
        },
        "bleurt": -0.34271,
        "meteor": 0.4214732311961696,
        "nubia": {
            "semantic_relation": 4.05495,
            "contradiction": 6.8078,
            "irrelevancy": 90.32411,
            "logical_agreement": 2.8681,
            "grammar_ref": 6.0554,
            "grammar_hyp": 5.96594,
            "nubia_score": 0.49806
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_770": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.1625371587496606,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.10689059560851857,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.546342687603557,
        "bleu": 33.29923,
        "rouge1": {
            "precision": 0.79167,
            "recall": 0.64386,
            "fmeasure": 0.71005
        },
        "rouge2": {
            "precision": 0.37778,
            "recall": 0.30994,
            "fmeasure": 0.34046
        },
        "rougeL": {
            "precision": 0.60417,
            "recall": 0.50088,
            "fmeasure": 0.54762
        },
        "rougeLsum": {
            "precision": 0.60417,
            "recall": 0.50088,
            "fmeasure": 0.54762
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.75,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.87556,
            "recall": 0.88117,
            "f1": 0.87836
        },
        "bleurt": -0.55359,
        "meteor": 0.3409105429722403,
        "nubia": {
            "semantic_relation": 4.6574,
            "contradiction": 0.70818,
            "irrelevancy": 0.87815,
            "logical_agreement": 98.41367,
            "grammar_ref": 5.26752,
            "grammar_hyp": 6.03877,
            "nubia_score": 0.70366
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_705": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.3327418980586743,
        "bleu": 13.53233,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.37546,
            "fmeasure": 0.46898
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.16239,
            "fmeasure": 0.20702
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.37546,
            "fmeasure": 0.46898
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.37546,
            "fmeasure": 0.46898
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.4
        },
        "bertscore": {
            "precision": 0.90675,
            "recall": 0.84016,
            "f1": 0.87218
        },
        "bleurt": -0.13664,
        "meteor": 0.20607227491115282,
        "nubia": {
            "semantic_relation": 3.29048,
            "contradiction": 1.89717,
            "irrelevancy": 8.27865,
            "logical_agreement": 89.82417,
            "grammar_ref": 5.35534,
            "grammar_hyp": 5.79395,
            "nubia_score": 0.38314
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_774": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.0,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 15,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 24,
        "unique-1": 22,
        "entropy-1": 4.546593564294937,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": -0.03214388408660256,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9565217391304348,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.436605434317882,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": -0.03600643804015718,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.14438990933517493,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.058052645450254,
        "bleu": 39.49103,
        "rouge1": {
            "precision": 0.77949,
            "recall": 0.65269,
            "fmeasure": 0.69749
        },
        "rouge2": {
            "precision": 0.49537,
            "recall": 0.43353,
            "fmeasure": 0.4546
        },
        "rougeL": {
            "precision": 0.60641,
            "recall": 0.53462,
            "fmeasure": 0.55811
        },
        "rougeLsum": {
            "precision": 0.60641,
            "recall": 0.53462,
            "fmeasure": 0.55811
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6,
            "3": 0.6
        },
        "bertscore": {
            "precision": 0.89516,
            "recall": 0.88618,
            "f1": 0.88725
        },
        "bleurt": 0.08655,
        "meteor": 0.307788056909899,
        "nubia": {
            "semantic_relation": 4.21608,
            "contradiction": 0.23277,
            "irrelevancy": 49.48498,
            "logical_agreement": 50.28225,
            "grammar_ref": 4.18803,
            "grammar_hyp": 3.85654,
            "nubia_score": 0.76194
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_780": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1699250014423126,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.99428,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.22767,
            "irrelevancy": 0.5448,
            "logical_agreement": 99.22753,
            "grammar_ref": 5.18772,
            "grammar_hyp": 5.18772,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_645": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 28.0,
        "std_pred_length": 0.0,
        "median_pred_length": 28.0,
        "min_pred_length": 28,
        "max_pred_length": 28,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 26,
        "unique-1": 24,
        "entropy-1": 4.664497779200462,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.0956807282540127,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.05444778402237652,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.523561956057013,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": -0.06413033741971555,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6306634347596423,
        "bleu": 61.00034,
        "rouge1": {
            "precision": 0.78261,
            "recall": 0.93158,
            "fmeasure": 0.8505
        },
        "rouge2": {
            "precision": 0.68182,
            "recall": 0.81871,
            "fmeasure": 0.7439
        },
        "rougeL": {
            "precision": 0.78261,
            "recall": 0.93158,
            "fmeasure": 0.8505
        },
        "rougeLsum": {
            "precision": 0.78261,
            "recall": 0.93158,
            "fmeasure": 0.8505
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9444444444444444
        },
        "bertscore": {
            "precision": 0.94759,
            "recall": 0.97957,
            "f1": 0.96331
        },
        "bleurt": 0.06873,
        "meteor": 0.5134029864282491,
        "nubia": {
            "semantic_relation": 3.90841,
            "contradiction": 91.17064,
            "irrelevancy": 5.78166,
            "logical_agreement": 3.04771,
            "grammar_ref": 3.98302,
            "grammar_hyp": 3.80405,
            "nubia_score": 0.63952
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_707": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.090634124990776,
        "bleu": 76.11606,
        "rouge1": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rouge2": {
            "precision": 0.78788,
            "recall": 0.8963,
            "fmeasure": 0.8381
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.98299,
            "recall": 0.99732,
            "f1": 0.9901
        },
        "bleurt": 0.48581,
        "meteor": 0.5715186082473627,
        "nubia": {
            "semantic_relation": 4.3761,
            "contradiction": 0.09394,
            "irrelevancy": 99.63689,
            "logical_agreement": 0.26917,
            "grammar_ref": 5.85321,
            "grammar_hyp": 5.83654,
            "nubia_score": 0.79202
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_584": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5786529413771158,
        "bleu": 65.00593,
        "rouge1": {
            "precision": 0.95833,
            "recall": 0.88426,
            "fmeasure": 0.91912
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.60714,
            "fmeasure": 0.63492
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.76852,
            "fmeasure": 0.79902
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.76852,
            "fmeasure": 0.79902
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.98848,
            "recall": 0.9735,
            "f1": 0.98093
        },
        "bleurt": 0.60894,
        "meteor": 0.4688551030349617,
        "nubia": {
            "semantic_relation": 4.95991,
            "contradiction": 0.71544,
            "irrelevancy": 0.62403,
            "logical_agreement": 98.66053,
            "grammar_ref": 5.94246,
            "grammar_hyp": 6.5727,
            "nubia_score": 0.90996
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_672": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 5.5,
        "median_pred_length": 18.5,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.8378378378378378,
        "vocab_size-1": 31,
        "unique-1": 27,
        "entropy-1": 4.831074987250574,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.26268679417315943,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.08488889758651327,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8529411764705882,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.7345216647797495,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.2562871587496608,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.09310940439148141,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.512830050529297,
        "bleu": 36.46589,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.61228,
            "fmeasure": 0.66077
        },
        "rouge2": {
            "precision": 0.40731,
            "recall": 0.36852,
            "fmeasure": 0.38627
        },
        "rougeL": {
            "precision": 0.52778,
            "recall": 0.43421,
            "fmeasure": 0.4749
        },
        "rougeLsum": {
            "precision": 0.52778,
            "recall": 0.43421,
            "fmeasure": 0.4749
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6333333333333333
        },
        "bertscore": {
            "precision": 0.88972,
            "recall": 0.84315,
            "f1": 0.86383
        },
        "bleurt": -0.08604,
        "meteor": 0.3455808951289972,
        "nubia": {
            "semantic_relation": 3.06226,
            "contradiction": 0.12457,
            "irrelevancy": 50.25133,
            "logical_agreement": 49.62409,
            "grammar_ref": 4.36031,
            "grammar_hyp": 4.6621,
            "nubia_score": 0.4247
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_785": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.6,
        "vocab_size-1": 12,
        "unique-1": 4,
        "entropy-1": 3.5219280948873624,
        "distinct-2": 0.6666666666666666,
        "vocab_size-2": 12,
        "unique-2": 6,
        "entropy-2": 3.503258334775645,
        "cond_entropy-2": -0.040891982333938634,
        "distinct-3": 0.6875,
        "vocab_size-3": 11,
        "unique-3": 6,
        "entropy-3": 3.375,
        "cond_entropy-3": -0.04492500144231237,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.6111111111111112,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 3.392147223664534,
        "distinct-2-nopunct": 0.625,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 3.25,
        "cond_entropy-2-nopunct": -0.04492500144231236,
        "distinct-3-nopunct": 0.6428571428571429,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 3.09306920777189,
        "cond_entropy-3-nopunct": -0.04978793508525296,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.27669746579841,
        "bleu": 33.92072,
        "rouge1": {
            "precision": 0.87037,
            "recall": 0.65302,
            "fmeasure": 0.74196
        },
        "rouge2": {
            "precision": 0.52083,
            "recall": 0.38681,
            "fmeasure": 0.44167
        },
        "rougeL": {
            "precision": 0.7963,
            "recall": 0.60311,
            "fmeasure": 0.68298
        },
        "rougeLsum": {
            "precision": 0.7963,
            "recall": 0.60311,
            "fmeasure": 0.68298
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "bertscore": {
            "precision": 0.96929,
            "recall": 0.94456,
            "f1": 0.95676
        },
        "bleurt": 0.36837,
        "meteor": 0.41664419714148093,
        "nubia": {
            "semantic_relation": 4.84412,
            "contradiction": 0.57963,
            "irrelevancy": 0.83691,
            "logical_agreement": 98.58346,
            "grammar_ref": 4.6711,
            "grammar_hyp": 4.92275,
            "nubia_score": 0.93636
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_791": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.9259259259259259,
        "vocab_size-1": 25,
        "unique-1": 23,
        "entropy-1": 4.606739354015322,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.09939836982377731,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.05658352836636749,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.9583333333333334,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.501629167387823,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.02555597707498718,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.06413033741971555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9037293070270045,
        "bleu": 23.42302,
        "rouge1": {
            "precision": 0.56522,
            "recall": 0.55556,
            "fmeasure": 0.56013
        },
        "rouge2": {
            "precision": 0.27273,
            "recall": 0.26639,
            "fmeasure": 0.26942
        },
        "rougeL": {
            "precision": 0.56522,
            "recall": 0.55556,
            "fmeasure": 0.56013
        },
        "rougeLsum": {
            "precision": 0.56522,
            "recall": 0.55556,
            "fmeasure": 0.56013
        },
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.47368421052631576
        },
        "bertscore": {
            "precision": 0.8808,
            "recall": 0.89698,
            "f1": 0.88882
        },
        "bleurt": 0.11178,
        "meteor": 0.29742341391358207,
        "nubia": {
            "semantic_relation": 4.14861,
            "contradiction": 0.17424,
            "irrelevancy": 66.5368,
            "logical_agreement": 33.28895,
            "grammar_ref": 4.34096,
            "grammar_hyp": 4.81206,
            "nubia_score": 0.64925
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_708": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.816496580927726,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 24,
        "unique-1": 16,
        "entropy-1": 4.476064195050471,
        "distinct-2": 0.8,
        "vocab_size-2": 24,
        "unique-2": 18,
        "entropy-2": 4.506890595608519,
        "cond_entropy-2": -0.07083685708326805,
        "distinct-3": 0.8148148148148148,
        "vocab_size-3": 22,
        "unique-3": 17,
        "entropy-3": 4.384517131793101,
        "cond_entropy-3": -0.07792901937097599,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.816496580927726,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.7666666666666667,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.440223928941853,
        "distinct-2-nopunct": 0.7777777777777778,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.310443057719026,
        "cond_entropy-2-nopunct": -0.07792901937097599,
        "distinct-3-nopunct": 0.7916666666666666,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 4.16829583405449,
        "cond_entropy-3-nopunct": -0.08659166810897906,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.413538218275817,
        "bleu": 79.61398,
        "rouge1": {
            "precision": 0.92593,
            "recall": 0.9,
            "fmeasure": 0.91228
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.85185,
            "fmeasure": 0.86275
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.86667,
            "fmeasure": 0.87719
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.86667,
            "fmeasure": 0.87719
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.7,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.97883,
            "recall": 0.96357,
            "f1": 0.97101
        },
        "bleurt": 0.70404,
        "meteor": 0.5605502867884248,
        "nubia": {
            "semantic_relation": 4.65167,
            "contradiction": 0.57252,
            "irrelevancy": 15.6934,
            "logical_agreement": 83.73408,
            "grammar_ref": 5.72052,
            "grammar_hyp": 5.78744,
            "nubia_score": 0.86596
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_720": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 62,
        "mean_pred_length": 15.5,
        "std_pred_length": 5.722761571129799,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 25,
        "distinct-1": 0.7419354838709677,
        "vocab_size-1": 46,
        "unique-1": 34,
        "entropy-1": 5.37355114909655,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 56,
        "unique-2": 54,
        "entropy-2": 5.789015477886191,
        "cond_entropy-2": 0.31757778818897264,
        "distinct-3": 0.9814814814814815,
        "vocab_size-3": 53,
        "unique-3": 52,
        "entropy-3": 5.717850465126429,
        "cond_entropy-3": -0.06605645592706633,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.898979485566356,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.343069207771893,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.623516641218018,
        "cond_entropy-2-nopunct": 0.31616171916041075,
        "distinct-3-nopunct": 0.9791666666666666,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.5432958340544936,
        "cond_entropy-3-nopunct": -0.07381055075326921,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.335355628401615,
        "bleu": 38.79845,
        "rouge1": {
            "precision": 0.70812,
            "recall": 0.7136,
            "fmeasure": 0.69373
        },
        "rouge2": {
            "precision": 0.4329,
            "recall": 0.43955,
            "fmeasure": 0.42765
        },
        "rougeL": {
            "precision": 0.55584,
            "recall": 0.58294,
            "fmeasure": 0.55527
        },
        "rougeLsum": {
            "precision": 0.55584,
            "recall": 0.58294,
            "fmeasure": 0.55527
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.5,
            "3": 0.8157894736842105
        },
        "bertscore": {
            "precision": 0.9262,
            "recall": 0.91833,
            "f1": 0.92026
        },
        "bleurt": 0.50023,
        "meteor": 0.3630098024755804,
        "nubia": {
            "semantic_relation": 4.57188,
            "contradiction": 7.06869,
            "irrelevancy": 20.48089,
            "logical_agreement": 72.45043,
            "grammar_ref": 4.54108,
            "grammar_hyp": 4.62909,
            "nubia_score": 0.75493
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_792": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 22.0,
        "std_pred_length": 4.0,
        "median_pred_length": 22.0,
        "min_pred_length": 18,
        "max_pred_length": 26,
        "distinct-1": 0.75,
        "vocab_size-1": 33,
        "unique-1": 25,
        "entropy-1": 4.896820539042672,
        "distinct-2": 0.9761904761904762,
        "vocab_size-2": 41,
        "unique-2": 40,
        "entropy-2": 5.344698375159714,
        "cond_entropy-2": 0.42704979228821266,
        "distinct-3": 1.0,
        "vocab_size-3": 40,
        "unique-3": 40,
        "entropy-3": 5.3219280948873635,
        "cond_entropy-3": -0.02038932789139803,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7692307692307693,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.753225616242672,
        "distinct-2-nopunct": 0.972972972972973,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.1553993115749,
        "cond_entropy-2-nopunct": 0.38810317383270954,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.0230274915411262,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9334621447475526,
        "bleu": 46.22581,
        "rouge1": {
            "precision": 0.56086,
            "recall": 0.76806,
            "fmeasure": 0.63873
        },
        "rouge2": {
            "precision": 0.38333,
            "recall": 0.48684,
            "fmeasure": 0.41716
        },
        "rougeL": {
            "precision": 0.49836,
            "recall": 0.60278,
            "fmeasure": 0.53333
        },
        "rougeLsum": {
            "precision": 0.49836,
            "recall": 0.60278,
            "fmeasure": 0.53333
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.42857142857142855,
            "3": 0.8095238095238095
        },
        "bertscore": {
            "precision": 0.90161,
            "recall": 0.92519,
            "f1": 0.90636
        },
        "bleurt": 0.34826,
        "meteor": 0.4268110728314226,
        "nubia": {
            "semantic_relation": 4.4643,
            "contradiction": 0.24784,
            "irrelevancy": 38.89978,
            "logical_agreement": 60.85239,
            "grammar_ref": 4.56769,
            "grammar_hyp": 3.56566,
            "nubia_score": 0.78926
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_585": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 79,
        "mean_pred_length": 13.166666666666666,
        "std_pred_length": 6.465721580423608,
        "median_pred_length": 9.5,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.5063291139240507,
        "vocab_size-1": 40,
        "unique-1": 26,
        "entropy-1": 4.9152923371427875,
        "distinct-2": 0.726027397260274,
        "vocab_size-2": 53,
        "unique-2": 41,
        "entropy-2": 5.552436545003575,
        "cond_entropy-2": 0.5388038717221368,
        "distinct-3": 0.7761194029850746,
        "vocab_size-3": 52,
        "unique-3": 43,
        "entropy-3": 5.550726130562532,
        "cond_entropy-3": -0.015599360991848854,
        "total_length-nopunct": 72,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 6.377042156569663,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5277777777777778,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.861858203284201,
        "distinct-2-nopunct": 0.7272727272727273,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.411448096467285,
        "cond_entropy-2-nopunct": 0.5813097914677052,
        "distinct-3-nopunct": 0.7833333333333333,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.410649970428229,
        "cond_entropy-3-nopunct": -0.01675164878599261,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.552110020282993,
        "bleu": 73.29603,
        "rouge1": {
            "precision": 0.86657,
            "recall": 0.90325,
            "fmeasure": 0.87914
        },
        "rouge2": {
            "precision": 0.74306,
            "recall": 0.77713,
            "fmeasure": 0.75511
        },
        "rougeL": {
            "precision": 0.85101,
            "recall": 0.88551,
            "fmeasure": 0.86237
        },
        "rougeLsum": {
            "precision": 0.85101,
            "recall": 0.88551,
            "fmeasure": 0.86237
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.46153846153846156,
            "3": 0.9523809523809523
        },
        "bertscore": {
            "precision": 0.97439,
            "recall": 0.98448,
            "f1": 0.97938
        },
        "bleurt": 0.66688,
        "meteor": 0.5304910630838816,
        "nubia": {
            "semantic_relation": 4.38135,
            "contradiction": 21.97681,
            "irrelevancy": 11.74504,
            "logical_agreement": 66.27816,
            "grammar_ref": 4.0718,
            "grammar_hyp": 3.96741,
            "nubia_score": 0.8455
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_795": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.1985265509331526,
        "bleu": 9.61608,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.66667,
            "fmeasure": 0.75
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.25,
            "fmeasure": 0.28571
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.33333,
            "fmeasure": 0.375
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.33333,
            "fmeasure": 0.375
        },
        "local_recall": {
            "1": 0,
            "2": 0.5454545454545454
        },
        "bertscore": {
            "precision": 0.80951,
            "recall": 0.79287,
            "f1": 0.8011
        },
        "bleurt": -0.27155,
        "meteor": 0.2600284722570357,
        "nubia": {
            "semantic_relation": 4.26058,
            "contradiction": 6.89408,
            "irrelevancy": 13.44554,
            "logical_agreement": 79.66037,
            "grammar_ref": 4.80739,
            "grammar_hyp": 5.67561,
            "nubia_score": 0.54837
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_588": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 14,
        "unique-1": 10,
        "entropy-1": 3.681880802803401,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 17,
        "unique-2": 16,
        "entropy-2": 4.058813890331201,
        "cond_entropy-2": 0.4083801270078083,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": 0.03518489863155644,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7058823529411765,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.4548223999466066,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.875,
        "cond_entropy-2-nopunct": 0.45971762763487756,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": 0.040223928941851894,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.1681907449941207,
        "bleu": 41.12176,
        "rouge1": {
            "precision": 0.52778,
            "recall": 0.75962,
            "fmeasure": 0.62258
        },
        "rouge2": {
            "precision": 0.47059,
            "recall": 0.69697,
            "fmeasure": 0.56158
        },
        "rougeL": {
            "precision": 0.52778,
            "recall": 0.75962,
            "fmeasure": 0.62258
        },
        "rougeLsum": {
            "precision": 0.52778,
            "recall": 0.75962,
            "fmeasure": 0.62258
        },
        "local_recall": {
            "1": 0,
            "2": 0.7
        },
        "bertscore": {
            "precision": 0.91274,
            "recall": 0.95219,
            "f1": 0.93205
        },
        "bleurt": 0.58168,
        "meteor": 0.40391483707176334,
        "nubia": {
            "semantic_relation": 4.43122,
            "contradiction": 0.24231,
            "irrelevancy": 97.69814,
            "logical_agreement": 2.05955,
            "grammar_ref": 3.96979,
            "grammar_hyp": 2.99247,
            "nubia_score": 0.81442
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_798": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 59,
        "mean_pred_length": 19.666666666666668,
        "std_pred_length": 3.858612300930075,
        "median_pred_length": 18.0,
        "min_pred_length": 16,
        "max_pred_length": 25,
        "distinct-1": 0.5254237288135594,
        "vocab_size-1": 31,
        "unique-1": 19,
        "entropy-1": 4.636051947300235,
        "distinct-2": 0.6785714285714286,
        "vocab_size-2": 38,
        "unique-2": 26,
        "entropy-2": 5.083616975397234,
        "cond_entropy-2": 0.4294379888830914,
        "distinct-3": 0.7169811320754716,
        "vocab_size-3": 38,
        "unique-3": 27,
        "entropy-3": 5.104910077041428,
        "cond_entropy-3": 0.062259400511763686,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 18.666666666666668,
        "std_pred_length-nopunct": 3.858612300930075,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5357142857142857,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.578890859209905,
        "distinct-2-nopunct": 0.660377358490566,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.9632162090352585,
        "cond_entropy-2-nopunct": 0.40508817412388265,
        "distinct-3-nopunct": 0.7,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.983465189601646,
        "cond_entropy-3-nopunct": 0.034431985283641144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.846411930189869,
        "bleu": 50.28842,
        "rouge1": {
            "precision": 0.79542,
            "recall": 0.82349,
            "fmeasure": 0.80152
        },
        "rouge2": {
            "precision": 0.55707,
            "recall": 0.56998,
            "fmeasure": 0.55675
        },
        "rougeL": {
            "precision": 0.6988,
            "recall": 0.71141,
            "fmeasure": 0.6986
        },
        "rougeLsum": {
            "precision": 0.6988,
            "recall": 0.71141,
            "fmeasure": 0.6986
        },
        "local_recall": {
            "1": 0.7,
            "2": 0.5,
            "3": 0.8421052631578947
        },
        "bertscore": {
            "precision": 0.93253,
            "recall": 0.92752,
            "f1": 0.92994
        },
        "bleurt": -0.00678,
        "meteor": 0.451592616160842,
        "nubia": {
            "semantic_relation": 4.32585,
            "contradiction": 0.85781,
            "irrelevancy": 53.56735,
            "logical_agreement": 45.57484,
            "grammar_ref": 5.76985,
            "grammar_hyp": 5.59664,
            "nubia_score": 0.73333
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_800": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 12.333333333333334,
        "std_pred_length": 4.109609335312651,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 17,
        "distinct-1": 0.7297297297297297,
        "vocab_size-1": 27,
        "unique-1": 19,
        "entropy-1": 4.614858771034358,
        "distinct-2": 0.9411764705882353,
        "vocab_size-2": 32,
        "unique-2": 30,
        "entropy-2": 4.969815782426809,
        "cond_entropy-2": 0.23095065209197801,
        "distinct-3": 0.967741935483871,
        "vocab_size-3": 30,
        "unique-3": 29,
        "entropy-3": 4.889680181354619,
        "cond_entropy-3": -0.06875040183120609,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 9.333333333333334,
        "std_pred_length-nopunct": 2.8674417556808756,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8214285714285714,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.450212064914749,
        "distinct-2-nopunct": 0.92,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.483856189774723,
        "cond_entropy-2-nopunct": 0.07650126771712043,
        "distinct-3-nopunct": 0.9545454545454546,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.368522527728205,
        "cond_entropy-3-nopunct": -0.09351548022833661,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0819955751196257,
        "bleu": 9.2021,
        "rouge1": {
            "precision": 0.66097,
            "recall": 0.5813,
            "fmeasure": 0.61224
        },
        "rouge2": {
            "precision": 0.20556,
            "recall": 0.1777,
            "fmeasure": 0.18823
        },
        "rougeL": {
            "precision": 0.48718,
            "recall": 0.41217,
            "fmeasure": 0.43976
        },
        "rougeLsum": {
            "precision": 0.48718,
            "recall": 0.41217,
            "fmeasure": 0.43976
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6206896551724138
        },
        "bertscore": {
            "precision": 0.91262,
            "recall": 0.89552,
            "f1": 0.90391
        },
        "bleurt": -0.01408,
        "meteor": 0.27728804713869354,
        "nubia": {
            "semantic_relation": 4.07128,
            "contradiction": 36.13975,
            "irrelevancy": 41.96246,
            "logical_agreement": 21.89778,
            "grammar_ref": 5.969,
            "grammar_hyp": 6.22769,
            "nubia_score": 0.54121
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_845": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 10,
        "unique-1": 8,
        "entropy-1": 3.2516291673878226,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.23810548155250455,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.0957952550009344,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.262496476250065,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.12356491777363,
        "bleu": 59.22252,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.60317,
            "fmeasure": 0.72115
        },
        "rouge2": {
            "precision": 0.9,
            "recall": 0.57857,
            "fmeasure": 0.7
        },
        "rougeL": {
            "precision": 0.90909,
            "recall": 0.60317,
            "fmeasure": 0.72115
        },
        "rougeLsum": {
            "precision": 0.90909,
            "recall": 0.60317,
            "fmeasure": 0.72115
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.98789,
            "recall": 0.8933,
            "f1": 0.93822
        },
        "bleurt": 0.24584,
        "meteor": 0.4466946348571188,
        "nubia": {
            "semantic_relation": 4.1524,
            "contradiction": 0.3849,
            "irrelevancy": 0.53944,
            "logical_agreement": 99.07566,
            "grammar_ref": 2.70093,
            "grammar_hyp": 2.95932,
            "nubia_score": 0.8747
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_675": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.031192427318204,
        "bleu": 81.47064,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.86713,
            "fmeasure": 0.87652
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.75556,
            "fmeasure": 0.73982
        },
        "rougeL": {
            "precision": 0.80556,
            "recall": 0.83683,
            "fmeasure": 0.81971
        },
        "rougeLsum": {
            "precision": 0.80556,
            "recall": 0.83683,
            "fmeasure": 0.81971
        },
        "local_recall": {
            "1": 0.4,
            "2": 1.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.95034,
            "recall": 0.96658,
            "f1": 0.94107
        },
        "bleurt": 0.38827,
        "meteor": 0.5292398399849825,
        "nubia": {
            "semantic_relation": 4.86365,
            "contradiction": 0.73994,
            "irrelevancy": 41.40122,
            "logical_agreement": 57.85884,
            "grammar_ref": 4.43463,
            "grammar_hyp": 4.4846,
            "nubia_score": 0.92055
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_849": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.17355726227518525,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.555739355110267,
        "bleu": 11.19644,
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.41667,
            "fmeasure": 0.47619
        },
        "rouge2": {
            "precision": 0.27451,
            "recall": 0.20842,
            "fmeasure": 0.23684
        },
        "rougeL": {
            "precision": 0.51852,
            "recall": 0.39899,
            "fmeasure": 0.45079
        },
        "rougeLsum": {
            "precision": 0.51852,
            "recall": 0.39899,
            "fmeasure": 0.45079
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.35294117647058826
        },
        "bertscore": {
            "precision": 0.80609,
            "recall": 0.77273,
            "f1": 0.78906
        },
        "bleurt": -0.27688,
        "meteor": 0.18219322294073376,
        "nubia": {
            "semantic_relation": 2.77586,
            "contradiction": 20.43178,
            "irrelevancy": 79.11888,
            "logical_agreement": 0.44934,
            "grammar_ref": 3.8277,
            "grammar_hyp": 4.02141,
            "nubia_score": 0.26427
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_852": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.7109047337507373,
        "bleu": 53.10725,
        "rouge1": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.65278,
            "fmeasure": 0.5381
        },
        "rougeL": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rougeLsum": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "bertscore": {
            "precision": 0.91794,
            "recall": 0.99099,
            "f1": 0.95307
        },
        "bleurt": 0.22576,
        "meteor": 0.5033950705050299,
        "nubia": {
            "semantic_relation": 4.03158,
            "contradiction": 0.1933,
            "irrelevancy": 99.65987,
            "logical_agreement": 0.14683,
            "grammar_ref": 5.68221,
            "grammar_hyp": 4.97464,
            "nubia_score": 0.75981
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_590": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 55,
        "mean_pred_length": 18.333333333333332,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 19,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 40,
        "unique-1": 32,
        "entropy-1": 5.11308903166714,
        "distinct-2": 0.9807692307692307,
        "vocab_size-2": 51,
        "unique-2": 50,
        "entropy-2": 5.661978179679557,
        "cond_entropy-2": 0.4960030815395097,
        "distinct-3": 1.0,
        "vocab_size-3": 49,
        "unique-3": 49,
        "entropy-3": 5.614709844115208,
        "cond_entropy-3": -0.044913547495271496,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 16.666666666666668,
        "std_pred_length-nopunct": 1.247219128924647,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.76,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.0438561897747265,
        "distinct-2-nopunct": 0.9787234042553191,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.512035660188278,
        "cond_entropy-2-nopunct": 0.4639241512646148,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.4594316186372955,
        "cond_entropy-3-nopunct": -0.04970268758579487,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1862334292908323,
        "bleu": 17.57045,
        "rouge1": {
            "precision": 0.55185,
            "recall": 0.82268,
            "fmeasure": 0.64613
        },
        "rouge2": {
            "precision": 0.26517,
            "recall": 0.4438,
            "fmeasure": 0.32415
        },
        "rougeL": {
            "precision": 0.44198,
            "recall": 0.69304,
            "fmeasure": 0.52536
        },
        "rougeLsum": {
            "precision": 0.44198,
            "recall": 0.69304,
            "fmeasure": 0.52536
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.6666666666666666,
            "3": 0.8461538461538461
        },
        "bertscore": {
            "precision": 0.86314,
            "recall": 0.9244,
            "f1": 0.89171
        },
        "bleurt": 0.12668,
        "meteor": 0.37627934739377933,
        "nubia": {
            "semantic_relation": 3.62539,
            "contradiction": 13.17182,
            "irrelevancy": 64.10667,
            "logical_agreement": 22.72151,
            "grammar_ref": 4.63208,
            "grammar_hyp": 3.78707,
            "nubia_score": 0.53981
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_678": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673073,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432275,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.733880981892677,
        "bleu": 57.60844,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.9,
            "fmeasure": 0.92105
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.8888888888888888
        },
        "bertscore": {
            "precision": 0.90565,
            "recall": 0.94307,
            "f1": 0.92398
        },
        "bleurt": -0.0324,
        "meteor": 0.45231505213245843,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.39232,
            "irrelevancy": 0.99354,
            "logical_agreement": 97.61415,
            "grammar_ref": 5.30755,
            "grammar_hyp": 5.79546,
            "nubia_score": 0.75076
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_854": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 67,
        "mean_pred_length": 22.333333333333332,
        "std_pred_length": 4.714045207910316,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 29,
        "distinct-1": 0.5223880597014925,
        "vocab_size-1": 35,
        "unique-1": 23,
        "entropy-1": 4.776482802488993,
        "distinct-2": 0.796875,
        "vocab_size-2": 51,
        "unique-2": 46,
        "entropy-2": 5.460479296672174,
        "cond_entropy-2": 0.6701516763979104,
        "distinct-3": 0.8360655737704918,
        "vocab_size-3": 51,
        "unique-3": 46,
        "entropy-3": 5.54099246033637,
        "cond_entropy-3": 0.10704696874589374,
        "total_length-nopunct": 59,
        "mean_pred_length-nopunct": 19.666666666666668,
        "std_pred_length-nopunct": 4.4969125210773475,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.559322033898305,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.695539659237978,
        "distinct-2-nopunct": 0.7678571428571429,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.190759832540094,
        "cond_entropy-2-nopunct": 0.5126549531172946,
        "distinct-3-nopunct": 0.8113207547169812,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.279346161906265,
        "cond_entropy-3-nopunct": 0.07471506083469524,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.578602830331293,
        "bleu": 15.56741,
        "rouge1": {
            "precision": 0.53121,
            "recall": 0.67094,
            "fmeasure": 0.58467
        },
        "rouge2": {
            "precision": 0.30444,
            "recall": 0.39502,
            "fmeasure": 0.33687
        },
        "rougeL": {
            "precision": 0.40165,
            "recall": 0.52877,
            "fmeasure": 0.44965
        },
        "rougeLsum": {
            "precision": 0.40165,
            "recall": 0.52877,
            "fmeasure": 0.44965
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6,
            "3": 0.5789473684210527
        },
        "bertscore": {
            "precision": 0.85054,
            "recall": 0.86905,
            "f1": 0.85891
        },
        "bleurt": -0.1833,
        "meteor": 0.34965017056990805,
        "nubia": {
            "semantic_relation": 3.54336,
            "contradiction": 4.38352,
            "irrelevancy": 55.8136,
            "logical_agreement": 39.80287,
            "grammar_ref": 3.73262,
            "grammar_hyp": 4.04433,
            "nubia_score": 0.56285
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_855": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 18,
        "unique-1": 15,
        "entropy-1": 4.061482186720775,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.3497852090063903,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.892407118592875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.29726901589669724,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.170984270746223,
        "bleu": 62.90474,
        "rouge1": {
            "precision": 0.89474,
            "recall": 0.80952,
            "fmeasure": 0.85
        },
        "rouge2": {
            "precision": 0.61111,
            "recall": 0.63077,
            "fmeasure": 0.6146
        },
        "rougeL": {
            "precision": 0.68421,
            "recall": 0.61905,
            "fmeasure": 0.65
        },
        "rougeLsum": {
            "precision": 0.68421,
            "recall": 0.61905,
            "fmeasure": 0.65
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.5,
            "3": 0.9090909090909091
        },
        "bertscore": {
            "precision": 0.96711,
            "recall": 0.95188,
            "f1": 0.95229
        },
        "bleurt": 0.38266,
        "meteor": 0.47850301634404113,
        "nubia": {
            "semantic_relation": 4.60924,
            "contradiction": 0.13041,
            "irrelevancy": 33.54402,
            "logical_agreement": 66.32557,
            "grammar_ref": 3.68983,
            "grammar_hyp": 3.47861,
            "nubia_score": 0.9235
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_592": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.944797625754069,
        "bleu": 100.0,
        "rouge1": {
            "precision": 0.95833,
            "recall": 1.0,
            "fmeasure": 0.97778
        },
        "rouge2": {
            "precision": 0.90476,
            "recall": 0.94444,
            "fmeasure": 0.92308
        },
        "rougeL": {
            "precision": 0.95833,
            "recall": 1.0,
            "fmeasure": 0.97778
        },
        "rougeLsum": {
            "precision": 0.95833,
            "recall": 1.0,
            "fmeasure": 0.97778
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 1.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.56963,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.73925,
            "contradiction": 0.27952,
            "irrelevancy": 59.63412,
            "logical_agreement": 40.08636,
            "grammar_ref": 5.97194,
            "grammar_hyp": 6.19529,
            "nubia_score": 0.89159
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_680": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 7.0,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.84375,
        "vocab_size-1": 27,
        "unique-1": 24,
        "entropy-1": 4.625,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.2402239289418518,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8620689655172413,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.513153408920675,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": 0.267276877406267,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.186321539717365,
        "bleu": 45.44091,
        "rouge1": {
            "precision": 0.81052,
            "recall": 0.76706,
            "fmeasure": 0.77273
        },
        "rouge2": {
            "precision": 0.70357,
            "recall": 0.70128,
            "fmeasure": 0.68696
        },
        "rougeL": {
            "precision": 0.74702,
            "recall": 0.72947,
            "fmeasure": 0.72508
        },
        "rougeLsum": {
            "precision": 0.74702,
            "recall": 0.72947,
            "fmeasure": 0.72508
        },
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.64
        },
        "bertscore": {
            "precision": 0.94863,
            "recall": 0.92964,
            "f1": 0.93883
        },
        "bleurt": 0.19199,
        "meteor": 0.36468445972946717,
        "nubia": {
            "semantic_relation": 4.22344,
            "contradiction": 0.10407,
            "irrelevancy": 82.78403,
            "logical_agreement": 17.1119,
            "grammar_ref": 5.14413,
            "grammar_hyp": 4.5615,
            "nubia_score": 0.81688
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_856": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 18,
        "unique-1": 15,
        "entropy-1": 4.106603137064474,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.22961067210860203,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185188,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.5765888603710794,
        "bleu": 20.36398,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.63889,
            "fmeasure": 0.66741
        },
        "rouge2": {
            "precision": 0.36842,
            "recall": 0.35,
            "fmeasure": 0.35897
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.47619,
            "fmeasure": 0.4878
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.47619,
            "fmeasure": 0.4878
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6
        },
        "bertscore": {
            "precision": 0.8564,
            "recall": 0.88131,
            "f1": 0.86731
        },
        "bleurt": -0.14189,
        "meteor": 0.3541199882495489,
        "nubia": {
            "semantic_relation": 4.17243,
            "contradiction": 1.87045,
            "irrelevancy": 87.32571,
            "logical_agreement": 10.80383,
            "grammar_ref": 6.02354,
            "grammar_hyp": 5.3795,
            "nubia_score": 0.71203
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_594": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 3.5,
        "median_pred_length": 14.5,
        "min_pred_length": 11,
        "max_pred_length": 18,
        "distinct-1": 0.7241379310344828,
        "vocab_size-1": 21,
        "unique-1": 15,
        "entropy-1": 4.237291339955158,
        "distinct-2": 0.9629629629629629,
        "vocab_size-2": 26,
        "unique-2": 25,
        "entropy-2": 4.6808134280893965,
        "cond_entropy-2": 0.4154250255544153,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.031031312388743976,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7407407407407407,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.162294909570877,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.5638561897747225,
        "cond_entropy-2-nopunct": 0.448968687611256,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.03333771197858132,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.273112446193407,
        "bleu": 56.45863,
        "rouge1": {
            "precision": 0.87451,
            "recall": 0.78492,
            "fmeasure": 0.82322
        },
        "rouge2": {
            "precision": 0.66551,
            "recall": 0.59636,
            "fmeasure": 0.6246
        },
        "rougeL": {
            "precision": 0.87451,
            "recall": 0.78492,
            "fmeasure": 0.82322
        },
        "rougeLsum": {
            "precision": 0.87451,
            "recall": 0.78492,
            "fmeasure": 0.82322
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.8666666666666667,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.95528,
            "recall": 0.9326,
            "f1": 0.93543
        },
        "bleurt": 0.4454,
        "meteor": 0.42664755624832146,
        "nubia": {
            "semantic_relation": 3.43758,
            "contradiction": 51.02494,
            "irrelevancy": 0.87046,
            "logical_agreement": 48.10459,
            "grammar_ref": 4.13759,
            "grammar_hyp": 4.30943,
            "nubia_score": 0.50248
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_721": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 1.0,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.037503523749935014,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.04089198233393865,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4214063993308628,
        "bleu": 62.04446,
        "rouge1": {
            "precision": 0.87955,
            "recall": 0.79343,
            "fmeasure": 0.83235
        },
        "rouge2": {
            "precision": 0.73889,
            "recall": 0.66212,
            "fmeasure": 0.69664
        },
        "rougeL": {
            "precision": 0.83409,
            "recall": 0.75455,
            "fmeasure": 0.79054
        },
        "rougeLsum": {
            "precision": 0.83409,
            "recall": 0.75455,
            "fmeasure": 0.79054
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.6153846153846154,
            "3": 0.8888888888888888
        },
        "bertscore": {
            "precision": 0.93271,
            "recall": 0.91699,
            "f1": 0.92458
        },
        "bleurt": 0.12311,
        "meteor": 0.4340994638573465,
        "nubia": {
            "semantic_relation": 3.85616,
            "contradiction": 43.42154,
            "irrelevancy": 9.49791,
            "logical_agreement": 47.08054,
            "grammar_ref": 4.61516,
            "grammar_hyp": 4.55106,
            "nubia_score": 0.57298
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_805": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.1393070338981919,
        "bleu": 7.34705,
        "rouge1": {
            "precision": 0.30769,
            "recall": 0.44444,
            "fmeasure": 0.36063
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.09091,
            "fmeasure": 0.08696
        },
        "rougeL": {
            "precision": 0.23077,
            "recall": 0.25,
            "fmeasure": 0.24
        },
        "rougeLsum": {
            "precision": 0.23077,
            "recall": 0.25,
            "fmeasure": 0.24
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "bertscore": {
            "precision": 0.74687,
            "recall": 0.86202,
            "f1": 0.80033
        },
        "bleurt": -0.1837,
        "meteor": 0.17497899226239466,
        "nubia": {
            "semantic_relation": 3.37727,
            "contradiction": 0.08148,
            "irrelevancy": 99.73484,
            "logical_agreement": 0.18367,
            "grammar_ref": 5.08958,
            "grammar_hyp": 3.94514,
            "nubia_score": 0.6138
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_858": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.026442737724814782,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5250688330901574,
        "bleu": 57.30574,
        "rouge1": {
            "precision": 0.92857,
            "recall": 0.96154,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.80769,
            "recall": 0.83654,
            "fmeasure": 0.82154
        },
        "rougeL": {
            "precision": 0.78571,
            "recall": 0.81319,
            "fmeasure": 0.79894
        },
        "rougeLsum": {
            "precision": 0.78571,
            "recall": 0.81319,
            "fmeasure": 0.79894
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.9
        },
        "bertscore": {
            "precision": 0.91482,
            "recall": 0.93084,
            "f1": 0.92276
        },
        "bleurt": 0.00639,
        "meteor": 0.4382839556598504,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.24687,
            "irrelevancy": 0.82478,
            "logical_agreement": 98.92835,
            "grammar_ref": 4.1674,
            "grammar_hyp": 5.64158,
            "nubia_score": 0.77523
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_595": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 28,
        "unique-1": 25,
        "entropy-1": 4.726409765557392,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.13205351234730067,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8928571428571429,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.5661089398374815,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.15288816155131352,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6537671662024827,
        "bleu": 21.90924,
        "rouge1": {
            "precision": 0.80208,
            "recall": 0.77676,
            "fmeasure": 0.77937
        },
        "rouge2": {
            "precision": 0.44949,
            "recall": 0.44859,
            "fmeasure": 0.44268
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.63105,
            "fmeasure": 0.64032
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.63105,
            "fmeasure": 0.64032
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.93325,
            "recall": 0.93352,
            "f1": 0.9332
        },
        "bleurt": 0.34406,
        "meteor": 0.4176999741334799,
        "nubia": {
            "semantic_relation": 4.88957,
            "contradiction": 0.86495,
            "irrelevancy": 16.26934,
            "logical_agreement": 82.86571,
            "grammar_ref": 4.12394,
            "grammar_hyp": 4.14289,
            "nubia_score": 0.92777
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_600": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 12.333333333333334,
        "std_pred_length": 1.247219128924647,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 14,
        "distinct-1": 0.8378378378378378,
        "vocab_size-1": 31,
        "unique-1": 28,
        "entropy-1": 4.810672622327237,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": 0.1721271226802133,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.13326653086346418,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.816496580927726,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8787878787878788,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.741363816328152,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": 0.19582980958339857,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.15200309344505,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6131169686398295,
        "bleu": 60.48222,
        "rouge1": {
            "precision": 0.88384,
            "recall": 0.71759,
            "fmeasure": 0.78726
        },
        "rouge2": {
            "precision": 0.69169,
            "recall": 0.56136,
            "fmeasure": 0.61432
        },
        "rougeL": {
            "precision": 0.85606,
            "recall": 0.69537,
            "fmeasure": 0.76257
        },
        "rougeLsum": {
            "precision": 0.85606,
            "recall": 0.69537,
            "fmeasure": 0.76257
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.96016,
            "recall": 0.94317,
            "f1": 0.94124
        },
        "bleurt": 0.40672,
        "meteor": 0.4297403036175553,
        "nubia": {
            "semantic_relation": 3.8892,
            "contradiction": 3.35473,
            "irrelevancy": 58.36839,
            "logical_agreement": 38.27688,
            "grammar_ref": 4.26152,
            "grammar_hyp": 4.38425,
            "nubia_score": 0.62707
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_682": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.940508444262489,
        "bleu": 49.61683,
        "rouge1": {
            "precision": 0.80556,
            "recall": 0.72222,
            "fmeasure": 0.75533
        },
        "rouge2": {
            "precision": 0.51515,
            "recall": 0.44444,
            "fmeasure": 0.47333
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.64444,
            "fmeasure": 0.67565
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.64444,
            "fmeasure": 0.67565
        },
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 1.0,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.96587,
            "recall": 0.91627,
            "f1": 0.94042
        },
        "bleurt": 0.27517,
        "meteor": 0.4353638323937945,
        "nubia": {
            "semantic_relation": 4.45913,
            "contradiction": 0.66624,
            "irrelevancy": 37.0063,
            "logical_agreement": 62.32746,
            "grammar_ref": 4.75278,
            "grammar_hyp": 5.58836,
            "nubia_score": 0.66347
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_808": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673076,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.154129315728811,
        "bleu": 45.06775,
        "rouge1": {
            "precision": 0.82051,
            "recall": 0.62626,
            "fmeasure": 0.70476
        },
        "rouge2": {
            "precision": 0.61111,
            "recall": 0.45455,
            "fmeasure": 0.51584
        },
        "rougeL": {
            "precision": 0.79487,
            "recall": 0.61111,
            "fmeasure": 0.68571
        },
        "rougeLsum": {
            "precision": 0.79487,
            "recall": 0.61111,
            "fmeasure": 0.68571
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6923076923076923
        },
        "bertscore": {
            "precision": 0.95217,
            "recall": 0.9302,
            "f1": 0.9376
        },
        "bleurt": 0.03585,
        "meteor": 0.3600988628001968,
        "nubia": {
            "semantic_relation": 3.56101,
            "contradiction": 6.55523,
            "irrelevancy": 92.10978,
            "logical_agreement": 1.335,
            "grammar_ref": 4.44297,
            "grammar_hyp": 5.1044,
            "nubia_score": 0.37822
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_810": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 2.5,
        "median_pred_length": 18.5,
        "min_pred_length": 16,
        "max_pred_length": 21,
        "distinct-1": 0.7567567567567568,
        "vocab_size-1": 28,
        "unique-1": 24,
        "entropy-1": 4.571354974427957,
        "distinct-2": 0.9714285714285714,
        "vocab_size-2": 34,
        "unique-2": 33,
        "entropy-2": 5.072140159802107,
        "cond_entropy-2": 0.48010509344278274,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.02428283698045264,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7714285714285715,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.511864717675341,
        "distinct-2-nopunct": 0.9696969696969697,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.9837880587523955,
        "cond_entropy-2-nopunct": 0.5093426319418749,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.025681679939320107,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.967842641982552,
        "bleu": 61.68945,
        "rouge1": {
            "precision": 0.70833,
            "recall": 0.98039,
            "fmeasure": 0.80775
        },
        "rouge2": {
            "precision": 0.60777,
            "recall": 0.72399,
            "fmeasure": 0.63799
        },
        "rougeL": {
            "precision": 0.70833,
            "recall": 0.98039,
            "fmeasure": 0.80775
        },
        "rougeLsum": {
            "precision": 0.70833,
            "recall": 0.98039,
            "fmeasure": 0.80775
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.9523809523809523
        },
        "bertscore": {
            "precision": 0.931,
            "recall": 0.96487,
            "f1": 0.94744
        },
        "bleurt": 0.3103,
        "meteor": 0.5545258176732052,
        "nubia": {
            "semantic_relation": 4.22353,
            "contradiction": 0.31172,
            "irrelevancy": 51.47732,
            "logical_agreement": 48.21095,
            "grammar_ref": 5.29605,
            "grammar_hyp": 4.18403,
            "nubia_score": 0.81674
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_726": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 1.8856180831641267,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 40,
        "unique-1": 37,
        "entropy-1": 5.260456902679035,
        "distinct-2": 1.0,
        "vocab_size-2": 41,
        "unique-2": 41,
        "entropy-2": 5.357552004618081,
        "cond_entropy-2": -0.004318638409457551,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.10962449117449787,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 1.632993161855452,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9743589743589743,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.234120167580196,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.1699250014423095,
        "cond_entropy-2-nopunct": -0.05992166186438028,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.474690758902884,
        "bleu": 55.52268,
        "rouge1": {
            "precision": 0.85641,
            "recall": 0.82164,
            "fmeasure": 0.83587
        },
        "rouge2": {
            "precision": 0.69048,
            "recall": 0.66361,
            "fmeasure": 0.67453
        },
        "rougeL": {
            "precision": 0.70171,
            "recall": 0.67622,
            "fmeasure": 0.68665
        },
        "rougeLsum": {
            "precision": 0.70171,
            "recall": 0.67622,
            "fmeasure": 0.68665
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6875,
            "3": 0.9130434782608695
        },
        "bertscore": {
            "precision": 0.93695,
            "recall": 0.9532,
            "f1": 0.94412
        },
        "bleurt": 0.3418,
        "meteor": 0.4755747492384585,
        "nubia": {
            "semantic_relation": 4.19619,
            "contradiction": 3.96057,
            "irrelevancy": 62.38452,
            "logical_agreement": 33.65491,
            "grammar_ref": 4.8308,
            "grammar_hyp": 5.18889,
            "nubia_score": 0.65173
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_684": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 97,
        "mean_pred_length": 16.166666666666668,
        "std_pred_length": 5.30461015427985,
        "median_pred_length": 14.5,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.6701030927835051,
        "vocab_size-1": 65,
        "unique-1": 47,
        "entropy-1": 5.772708399326027,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 78,
        "unique-2": 65,
        "entropy-2": 6.222080354484419,
        "cond_entropy-2": 0.33347581947531046,
        "distinct-3": 0.8823529411764706,
        "vocab_size-3": 75,
        "unique-3": 65,
        "entropy-3": 6.174096818490646,
        "cond_entropy-3": -0.05134488053158269,
        "total_length-nopunct": 86,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 4.4969125210773475,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7325581395348837,
        "vocab_size-1-nopunct": 63,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.808597132856009,
        "distinct-2-nopunct": 0.8625,
        "vocab_size-2-nopunct": 69,
        "unique-2-nopunct": 58,
        "entropy-2-nopunct": 6.046928094887357,
        "cond_entropy-2-nopunct": 0.2596560336698109,
        "distinct-3-nopunct": 0.8918918918918919,
        "vocab_size-3-nopunct": 66,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.99323714941274,
        "cond_entropy-3-nopunct": -0.05842067520435861,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.864963299307576,
        "bleu": 68.08199,
        "rouge1": {
            "precision": 0.86772,
            "recall": 0.85443,
            "fmeasure": 0.84184
        },
        "rouge2": {
            "precision": 0.71302,
            "recall": 0.70597,
            "fmeasure": 0.69654
        },
        "rougeL": {
            "precision": 0.79436,
            "recall": 0.79815,
            "fmeasure": 0.78111
        },
        "rougeLsum": {
            "precision": 0.79436,
            "recall": 0.79815,
            "fmeasure": 0.78111
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.6,
            "3": 0.8548387096774194
        },
        "bertscore": {
            "precision": 0.94554,
            "recall": 0.94459,
            "f1": 0.94413
        },
        "bleurt": 0.31895,
        "meteor": 0.4731389532166975,
        "nubia": {
            "semantic_relation": 4.46974,
            "contradiction": 3.81095,
            "irrelevancy": 30.97867,
            "logical_agreement": 65.21038,
            "grammar_ref": 4.51194,
            "grammar_hyp": 4.451,
            "nubia_score": 0.81727
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_860": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.3443609377704335,
        "bleu": 14.82734,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.41667,
            "fmeasure": 0.52632
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.18182,
            "fmeasure": 0.23529
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.33333,
            "fmeasure": 0.42105
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.33333,
            "fmeasure": 0.42105
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.93434,
            "recall": 0.8604,
            "f1": 0.89585
        },
        "bleurt": 0.19251,
        "meteor": 0.2960818466263167,
        "nubia": {
            "semantic_relation": 4.48985,
            "contradiction": 2.16688,
            "irrelevancy": 1.20275,
            "logical_agreement": 96.63037,
            "grammar_ref": 5.64121,
            "grammar_hyp": 6.93606,
            "nubia_score": 0.63471
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_603": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 20,
        "unique-1": 16,
        "entropy-1": 4.1619781796795525,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.5034164716336328,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.001629167387823,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.5472951075097697,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.06413033741971555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.873534918451332,
        "bleu": 51.7928,
        "rouge1": {
            "precision": 0.84722,
            "recall": 0.66883,
            "fmeasure": 0.74163
        },
        "rouge2": {
            "precision": 0.71014,
            "recall": 0.55556,
            "fmeasure": 0.61817
        },
        "rougeL": {
            "precision": 0.80556,
            "recall": 0.63174,
            "fmeasure": 0.70186
        },
        "rougeLsum": {
            "precision": 0.80556,
            "recall": 0.63174,
            "fmeasure": 0.70186
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8095238095238095
        },
        "bertscore": {
            "precision": 0.9501,
            "recall": 0.8996,
            "f1": 0.92416
        },
        "bleurt": 0.07447,
        "meteor": 0.39321646977951724,
        "nubia": {
            "semantic_relation": 3.04979,
            "contradiction": 98.19767,
            "irrelevancy": 0.88203,
            "logical_agreement": 0.92029,
            "grammar_ref": 3.4256,
            "grammar_hyp": 3.30123,
            "nubia_score": 0.36565
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_686": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8936441277848375,
        "bleu": 100.0,
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "rouge2": {
            "precision": 0.92593,
            "recall": 0.75926,
            "fmeasure": 0.83069
        },
        "rougeL": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "rougeLsum": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.98107,
            "recall": 0.98047,
            "f1": 0.98047
        },
        "bleurt": 0.55466,
        "meteor": 0.9652173913043478,
        "nubia": {
            "semantic_relation": 4.57319,
            "contradiction": 0.20028,
            "irrelevancy": 0.43256,
            "logical_agreement": 99.36716,
            "grammar_ref": 4.05789,
            "grammar_hyp": 4.18715,
            "nubia_score": 0.88792
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_728": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 0.5,
        "median_pred_length": 12.5,
        "min_pred_length": 12,
        "max_pred_length": 13,
        "distinct-1": 0.64,
        "vocab_size-1": 16,
        "unique-1": 9,
        "entropy-1": 3.843856189774724,
        "distinct-2": 0.7391304347826086,
        "vocab_size-2": 17,
        "unique-2": 11,
        "entropy-2": 4.001822825622231,
        "cond_entropy-2": 0.14057533149967955,
        "distinct-3": 0.7619047619047619,
        "vocab_size-3": 16,
        "unique-3": 11,
        "entropy-3": 3.9161269465882835,
        "cond_entropy-3": -0.03600643804015718,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.6363636363636364,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.6412498004554785,
        "distinct-2-nopunct": 0.7,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.721928094887362,
        "cond_entropy-2-nopunct": 0.112496476250065,
        "distinct-3-nopunct": 0.7222222222222222,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.6143694458867563,
        "cond_entropy-3-nopunct": -0.09644753788949417,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.578785494835544,
        "bleu": 41.68916,
        "rouge1": {
            "precision": 0.65152,
            "recall": 0.74038,
            "fmeasure": 0.67128
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.45505,
            "fmeasure": 0.40895
        },
        "rougeL": {
            "precision": 0.59091,
            "recall": 0.68697,
            "fmeasure": 0.61452
        },
        "rougeLsum": {
            "precision": 0.59091,
            "recall": 0.68697,
            "fmeasure": 0.61452
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.90737,
            "recall": 0.94906,
            "f1": 0.92646
        },
        "bleurt": -0.10508,
        "meteor": 0.4305838108304038,
        "nubia": {
            "semantic_relation": 3.8364,
            "contradiction": 0.42339,
            "irrelevancy": 66.17507,
            "logical_agreement": 33.40155,
            "grammar_ref": 5.09196,
            "grammar_hyp": 4.57149,
            "nubia_score": 0.68139
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_864": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 8,
        "unique-1": 7,
        "entropy-1": 2.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": 0.08007499855768763,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": 0.0930692077718899,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4156844010247407,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.6432,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.64096,
            "contradiction": 0.21793,
            "irrelevancy": 0.49368,
            "logical_agreement": 99.2884,
            "grammar_ref": 5.14316,
            "grammar_hyp": 5.3673,
            "nubia_score": 0.85584
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_604": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8082905473662385,
        "bleu": 74.26141,
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "rouge2": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.99613,
            "recall": 0.98505,
            "f1": 0.99056
        },
        "bleurt": 0.78859,
        "meteor": 0.5623201842518945,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.39726,
            "irrelevancy": 1.06237,
            "logical_agreement": 98.54037,
            "grammar_ref": 6.26263,
            "grammar_hyp": 6.48369,
            "nubia_score": 0.98579
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_693": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964164,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.259466968861382,
        "bleu": 59.82478,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.85714,
            "fmeasure": 0.88889
        },
        "rouge2": {
            "precision": 0.72222,
            "recall": 0.66667,
            "fmeasure": 0.69333
        },
        "rougeL": {
            "precision": 0.87179,
            "recall": 0.80952,
            "fmeasure": 0.83951
        },
        "rougeLsum": {
            "precision": 0.87179,
            "recall": 0.80952,
            "fmeasure": 0.83951
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.9
        },
        "bertscore": {
            "precision": 0.97432,
            "recall": 0.96889,
            "f1": 0.9716
        },
        "bleurt": 0.5837,
        "meteor": 0.46036015895471294,
        "nubia": {
            "semantic_relation": 4.95681,
            "contradiction": 2.96079,
            "irrelevancy": 11.47546,
            "logical_agreement": 85.56375,
            "grammar_ref": 4.18993,
            "grammar_hyp": 4.11551,
            "nubia_score": 0.94116
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_868": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 0.5,
        "median_pred_length": 16.5,
        "min_pred_length": 16,
        "max_pred_length": 17,
        "distinct-1": 0.5757575757575758,
        "vocab_size-1": 19,
        "unique-1": 8,
        "entropy-1": 4.112427831414106,
        "distinct-2": 0.7096774193548387,
        "vocab_size-2": 22,
        "unique-2": 13,
        "entropy-2": 4.373551149096553,
        "cond_entropy-2": 0.2567340459369209,
        "distinct-3": 0.7586206896551724,
        "vocab_size-3": 22,
        "unique-3": 15,
        "entropy-3": 4.375222374437916,
        "cond_entropy-3": 0.04171571922345565,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.5806451612903226,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 4.026619294188054,
        "distinct-2-nopunct": 0.6896551724137931,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 4.237291339955158,
        "cond_entropy-2-nopunct": 0.21998899513525952,
        "distinct-3-nopunct": 0.7407407407407407,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 4.236368983644952,
        "cond_entropy-3-nopunct": 0.04505465518404472,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.962484524276351,
        "bleu": 43.85281,
        "rouge1": {
            "precision": 0.5817,
            "recall": 0.64842,
            "fmeasure": 0.60035
        },
        "rouge2": {
            "precision": 0.40441,
            "recall": 0.45532,
            "fmeasure": 0.41809
        },
        "rougeL": {
            "precision": 0.45588,
            "recall": 0.63141,
            "fmeasure": 0.52935
        },
        "rougeLsum": {
            "precision": 0.45588,
            "recall": 0.63141,
            "fmeasure": 0.52935
        },
        "local_recall": {
            "1": 0.47058823529411764,
            "2": 0.2857142857142857,
            "3": 0.625
        },
        "bertscore": {
            "precision": 0.89302,
            "recall": 0.91864,
            "f1": 0.90235
        },
        "bleurt": 0.02091,
        "meteor": 0.40907482769637576,
        "nubia": {
            "semantic_relation": 3.87312,
            "contradiction": 22.96735,
            "irrelevancy": 56.06816,
            "logical_agreement": 20.96449,
            "grammar_ref": 3.56015,
            "grammar_hyp": 3.16916,
            "nubia_score": 0.75553
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_735": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.03126257645096008,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.03310859910983796,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3329385809554286,
        "bleu": 49.03047,
        "rouge1": {
            "precision": 0.61905,
            "recall": 0.85458,
            "fmeasure": 0.71345
        },
        "rouge2": {
            "precision": 0.45,
            "recall": 0.73295,
            "fmeasure": 0.55376
        },
        "rougeL": {
            "precision": 0.52381,
            "recall": 0.8268,
            "fmeasure": 0.63743
        },
        "rougeLsum": {
            "precision": 0.52381,
            "recall": 0.8268,
            "fmeasure": 0.63743
        },
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666,
            "3": 0.9
        },
        "bertscore": {
            "precision": 0.91017,
            "recall": 0.96892,
            "f1": 0.93659
        },
        "bleurt": 0.235,
        "meteor": 0.4944705877070372,
        "nubia": {
            "semantic_relation": 4.29671,
            "contradiction": 1.80362,
            "irrelevancy": 38.28341,
            "logical_agreement": 59.91297,
            "grammar_ref": 4.69116,
            "grammar_hyp": 4.10269,
            "nubia_score": 0.7591
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_873": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.7857142857142857,
        "vocab_size-1": 11,
        "unique-1": 9,
        "entropy-1": 3.3248629576173574,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.41269152701913925,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7692307692307693,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.180832987205441,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.44743007442701976,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.3330872431410694,
        "bleu": 12.43902,
        "rouge1": {
            "precision": 0.80769,
            "recall": 0.52328,
            "fmeasure": 0.63063
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.21196,
            "fmeasure": 0.25714
        },
        "rougeL": {
            "precision": 0.61538,
            "recall": 0.40196,
            "fmeasure": 0.48288
        },
        "rougeLsum": {
            "precision": 0.61538,
            "recall": 0.40196,
            "fmeasure": 0.48288
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5714285714285714
        },
        "bertscore": {
            "precision": 0.93611,
            "recall": 0.88697,
            "f1": 0.91088
        },
        "bleurt": 0.1598,
        "meteor": 0.2854882302944084,
        "nubia": {
            "semantic_relation": 4.08361,
            "contradiction": 0.86186,
            "irrelevancy": 1.20541,
            "logical_agreement": 97.93274,
            "grammar_ref": 4.95035,
            "grammar_hyp": 5.72147,
            "nubia_score": 0.56726
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_695": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.0,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.75,
        "vocab_size-1": 18,
        "unique-1": 12,
        "entropy-1": 4.084962500721156,
        "distinct-2": 0.8181818181818182,
        "vocab_size-2": 18,
        "unique-2": 14,
        "entropy-2": 4.095795255000932,
        "cond_entropy-2": -0.034621791174768185,
        "distinct-3": 0.85,
        "vocab_size-3": 17,
        "unique-3": 14,
        "entropy-3": 4.021928094887363,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7727272727272727,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.004886164091841,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.9219280948873623,
        "cond_entropy-2-nopunct": -0.08750352374993502,
        "distinct-3-nopunct": 0.8333333333333334,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.8365916681089787,
        "cond_entropy-3-nopunct": -0.09644753788949419,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.6530437207411035,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.9828,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.34259,
            "irrelevancy": 0.55688,
            "logical_agreement": 99.10053,
            "grammar_ref": 6.12532,
            "grammar_hyp": 6.14583,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_876": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.75,
        "bleu": 17.24222,
        "rouge1": {
            "precision": 0.63636,
            "recall": 1.0,
            "fmeasure": 0.77778
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.66667,
            "fmeasure": 0.5
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 1.0,
            "fmeasure": 0.77778
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 1.0,
            "fmeasure": 0.77778
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.90645,
            "recall": 0.96569,
            "f1": 0.93513
        },
        "bleurt": 0.72343,
        "meteor": 0.4505550676842954,
        "nubia": {
            "semantic_relation": 4.83252,
            "contradiction": 0.17884,
            "irrelevancy": 49.06748,
            "logical_agreement": 50.75368,
            "grammar_ref": 5.74517,
            "grammar_hyp": 4.12045,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_605": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9438230237901655,
        "bleu": 53.47161,
        "rouge1": {
            "precision": 0.87179,
            "recall": 0.65833,
            "fmeasure": 0.74817
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.52632,
            "fmeasure": 0.64516
        },
        "rougeL": {
            "precision": 0.71795,
            "recall": 0.54167,
            "fmeasure": 0.61581
        },
        "rougeLsum": {
            "precision": 0.71795,
            "recall": 0.54167,
            "fmeasure": 0.61581
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.95582,
            "recall": 0.92292,
            "f1": 0.93908
        },
        "bleurt": 0.42696,
        "meteor": 0.3970655806086951,
        "nubia": {
            "semantic_relation": 4.65753,
            "contradiction": 0.28054,
            "irrelevancy": 0.47929,
            "logical_agreement": 99.24018,
            "grammar_ref": 3.95052,
            "grammar_hyp": 4.96557,
            "nubia_score": 0.82061
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_696": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 60,
        "mean_pred_length": 20.0,
        "std_pred_length": 6.97614984548545,
        "median_pred_length": 19.0,
        "min_pred_length": 12,
        "max_pred_length": 29,
        "distinct-1": 0.8,
        "vocab_size-1": 48,
        "unique-1": 42,
        "entropy-1": 5.389898095464286,
        "distinct-2": 1.0,
        "vocab_size-2": 57,
        "unique-2": 57,
        "entropy-2": 5.832890014164737,
        "cond_entropy-2": 0.38678297130166917,
        "distinct-3": 1.0,
        "vocab_size-3": 54,
        "unique-3": 54,
        "entropy-3": 5.7548875021634665,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 18.666666666666668,
        "std_pred_length-nopunct": 6.548960901462833,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.8214285714285714,
        "vocab_size-1-nopunct": 46,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.338343091584565,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 53,
        "entropy-2-nopunct": 5.727920454563195,
        "cond_entropy-2-nopunct": 0.41612520243937606,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.643856189774728,
        "cond_entropy-3-nopunct": -0.08406426478847459,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.545862384521203,
        "bleu": 53.1289,
        "rouge1": {
            "precision": 0.82564,
            "recall": 0.75313,
            "fmeasure": 0.78277
        },
        "rouge2": {
            "precision": 0.65575,
            "recall": 0.64477,
            "fmeasure": 0.6487
        },
        "rougeL": {
            "precision": 0.62898,
            "recall": 0.62537,
            "fmeasure": 0.62601
        },
        "rougeLsum": {
            "precision": 0.62898,
            "recall": 0.62537,
            "fmeasure": 0.62601
        },
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.15384615384615385,
            "3": 0.9024390243902439
        },
        "bertscore": {
            "precision": 0.94354,
            "recall": 0.94033,
            "f1": 0.94016
        },
        "bleurt": 0.19904,
        "meteor": 0.4238854369037533,
        "nubia": {
            "semantic_relation": 4.25148,
            "contradiction": 3.29141,
            "irrelevancy": 59.05304,
            "logical_agreement": 37.65555,
            "grammar_ref": 4.54005,
            "grammar_hyp": 4.31043,
            "nubia_score": 0.74877
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_910": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 4.5,
        "median_pred_length": 18.5,
        "min_pred_length": 14,
        "max_pred_length": 23,
        "distinct-1": 0.7837837837837838,
        "vocab_size-1": 29,
        "unique-1": 21,
        "entropy-1": 4.777020933196519,
        "distinct-2": 0.9714285714285714,
        "vocab_size-2": 34,
        "unique-2": 33,
        "entropy-2": 5.072140159802107,
        "cond_entropy-2": 0.26268679417315943,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.02428283698045265,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7941176470588235,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.675698135367986,
        "distinct-2-nopunct": 0.96875,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.9375,
        "cond_entropy-2-nopunct": 0.2875371587496607,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.02644273772481478,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9759470831615298,
        "bleu": 12.1426,
        "rouge1": {
            "precision": 0.485,
            "recall": 0.70669,
            "fmeasure": 0.57469
        },
        "rouge2": {
            "precision": 0.26894,
            "recall": 0.4212,
            "fmeasure": 0.32823
        },
        "rougeL": {
            "precision": 0.425,
            "recall": 0.62281,
            "fmeasure": 0.50484
        },
        "rougeLsum": {
            "precision": 0.425,
            "recall": 0.62281,
            "fmeasure": 0.50484
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.875,
            "3": 0.4
        },
        "bertscore": {
            "precision": 0.87807,
            "recall": 0.91573,
            "f1": 0.8965
        },
        "bleurt": 0.19193,
        "meteor": 0.29744793649758977,
        "nubia": {
            "semantic_relation": 4.0119,
            "contradiction": 0.84255,
            "irrelevancy": 71.40708,
            "logical_agreement": 27.75037,
            "grammar_ref": 4.27476,
            "grammar_hyp": 3.81112,
            "nubia_score": 0.68857
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_606": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 10.0,
        "std_pred_length": 1.224744871391589,
        "median_pred_length": 9.5,
        "min_pred_length": 9,
        "max_pred_length": 12,
        "distinct-1": 0.775,
        "vocab_size-1": 31,
        "unique-1": 27,
        "entropy-1": 4.731687083026443,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.2815980308448616,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.16992500144231223,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 1.224744871391589,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.736323877152398,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.3178762633838381,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.1926450779423958,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.778362631923373,
        "bleu": 64.1397,
        "rouge1": {
            "precision": 0.82292,
            "recall": 0.8127,
            "fmeasure": 0.81082
        },
        "rouge2": {
            "precision": 0.67143,
            "recall": 0.66142,
            "fmeasure": 0.65905
        },
        "rougeL": {
            "precision": 0.82292,
            "recall": 0.8127,
            "fmeasure": 0.81082
        },
        "rougeLsum": {
            "precision": 0.82292,
            "recall": 0.8127,
            "fmeasure": 0.81082
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.6,
            "3": 0.84
        },
        "bertscore": {
            "precision": 0.94843,
            "recall": 0.94538,
            "f1": 0.94675
        },
        "bleurt": 0.50235,
        "meteor": 0.47379705507481107,
        "nubia": {
            "semantic_relation": 4.34167,
            "contradiction": 3.0718,
            "irrelevancy": 35.30235,
            "logical_agreement": 61.62586,
            "grammar_ref": 4.98306,
            "grammar_hyp": 5.16171,
            "nubia_score": 0.73685
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_608": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 3.0,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.7666666666666667,
        "vocab_size-1": 23,
        "unique-1": 16,
        "entropy-1": 4.440223928941852,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 24,
        "unique-2": 20,
        "entropy-2": 4.52164063634332,
        "cond_entropy-2": 0.04332146930622849,
        "distinct-3": 0.9230769230769231,
        "vocab_size-3": 24,
        "unique-3": 22,
        "entropy-3": 4.546593564294937,
        "cond_entropy-3": 0.046930949929641676,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.378783493486177,
        "distinct-2-nopunct": 0.8461538461538461,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.392747410448783,
        "cond_entropy-2-nopunct": 0.0084694114681032,
        "distinct-3-nopunct": 0.9166666666666666,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.418295834054489,
        "cond_entropy-3-nopunct": 0.009522782580064105,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.513055497942787,
        "bleu": 50.54264,
        "rouge1": {
            "precision": 0.70321,
            "recall": 0.82546,
            "fmeasure": 0.75832
        },
        "rouge2": {
            "precision": 0.52708,
            "recall": 0.59585,
            "fmeasure": 0.55923
        },
        "rougeL": {
            "precision": 0.6934,
            "recall": 0.77937,
            "fmeasure": 0.73368
        },
        "rougeLsum": {
            "precision": 0.6934,
            "recall": 0.77937,
            "fmeasure": 0.73368
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.91855,
            "recall": 0.93031,
            "f1": 0.92438
        },
        "bleurt": 0.5913,
        "meteor": 0.44492029594113786,
        "nubia": {
            "semantic_relation": 4.85206,
            "contradiction": 0.22398,
            "irrelevancy": 16.68795,
            "logical_agreement": 83.08807,
            "grammar_ref": 4.34398,
            "grammar_hyp": 4.32962,
            "nubia_score": 0.92547
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_912": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 58,
        "mean_pred_length": 14.5,
        "std_pred_length": 4.5,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.7413793103448276,
        "vocab_size-1": 43,
        "unique-1": 36,
        "entropy-1": 5.196523616220669,
        "distinct-2": 0.9814814814814815,
        "vocab_size-2": 53,
        "unique-2": 52,
        "entropy-2": 5.717850465126429,
        "cond_entropy-2": 0.39832901809239374,
        "distinct-3": 1.0,
        "vocab_size-3": 50,
        "unique-3": 50,
        "entropy-3": 5.643856189774728,
        "cond_entropy-3": -0.07103131238874395,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 12.25,
        "std_pred_length-nopunct": 3.6996621467371855,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7959183673469388,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.10950805835677,
        "distinct-2-nopunct": 0.9777777777777777,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.447408651885229,
        "cond_entropy-2-nopunct": 0.3828074189292103,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.08552060390671315,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.683402679251203,
        "bleu": 59.79806,
        "rouge1": {
            "precision": 0.77967,
            "recall": 0.69096,
            "fmeasure": 0.72261
        },
        "rouge2": {
            "precision": 0.63064,
            "recall": 0.54374,
            "fmeasure": 0.57178
        },
        "rougeL": {
            "precision": 0.76405,
            "recall": 0.67846,
            "fmeasure": 0.70872
        },
        "rougeLsum": {
            "precision": 0.76405,
            "recall": 0.67846,
            "fmeasure": 0.70872
        },
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.55,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.93713,
            "recall": 0.93743,
            "f1": 0.93699
        },
        "bleurt": 0.28714,
        "meteor": 0.4286648422412341,
        "nubia": {
            "semantic_relation": 3.83101,
            "contradiction": 28.55921,
            "irrelevancy": 33.50624,
            "logical_agreement": 37.93454,
            "grammar_ref": 4.43752,
            "grammar_hyp": 4.21524,
            "nubia_score": 0.68419
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1005": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.2776134368191165,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8998572512287097,
        "bleu": 70.97039,
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.79167,
            "recall": 0.63333,
            "fmeasure": 0.7037
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "local_recall": {
            "1": 0.25,
            "2": 0,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.98271,
            "recall": 0.9644,
            "f1": 0.97347
        },
        "bleurt": 0.49536,
        "meteor": 0.5047034859011716,
        "nubia": {
            "semantic_relation": 4.54342,
            "contradiction": 0.48545,
            "irrelevancy": 0.54019,
            "logical_agreement": 98.97436,
            "grammar_ref": 4.98843,
            "grammar_hyp": 5.36395,
            "nubia_score": 0.7985
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1010": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.043321469306228495,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9092063526201066,
        "bleu": 32.37723,
        "rouge1": {
            "precision": 0.53846,
            "recall": 0.58333,
            "fmeasure": 0.56
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.34091,
            "fmeasure": 0.28696
        },
        "rougeL": {
            "precision": 0.38462,
            "recall": 0.50926,
            "fmeasure": 0.43636
        },
        "rougeLsum": {
            "precision": 0.38462,
            "recall": 0.50926,
            "fmeasure": 0.43636
        },
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666,
            "3": 0.6363636363636364
        },
        "bertscore": {
            "precision": 0.9027,
            "recall": 0.91195,
            "f1": 0.89135
        },
        "bleurt": 0.37412,
        "meteor": 0.34621271749008287,
        "nubia": {
            "semantic_relation": 4.29039,
            "contradiction": 0.23172,
            "irrelevancy": 34.21065,
            "logical_agreement": 65.55763,
            "grammar_ref": 4.00353,
            "grammar_hyp": 3.85378,
            "nubia_score": 0.8083
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_915": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 7.408703590297622,
        "median_pred_length": 11.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.7954545454545454,
        "vocab_size-1": 35,
        "unique-1": 27,
        "entropy-1": 5.033184175406308,
        "distinct-2": 1.0,
        "vocab_size-2": 41,
        "unique-2": 41,
        "entropy-2": 5.357552004618081,
        "cond_entropy-2": 0.23958380061493262,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.10962449117449787,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 6.018490028422597,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.932138039759376,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.129283016944964,
        "cond_entropy-2-nopunct": 0.22421264635852378,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.12928301694496638,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.759555053347681,
        "bleu": 51.69414,
        "rouge1": {
            "precision": 0.84192,
            "recall": 0.84361,
            "fmeasure": 0.83748
        },
        "rouge2": {
            "precision": 0.58488,
            "recall": 0.58818,
            "fmeasure": 0.58226
        },
        "rougeL": {
            "precision": 0.69813,
            "recall": 0.71,
            "fmeasure": 0.69926
        },
        "rougeLsum": {
            "precision": 0.69813,
            "recall": 0.71,
            "fmeasure": 0.69926
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.2,
            "3": 0.9354838709677419
        },
        "bertscore": {
            "precision": 0.94277,
            "recall": 0.94221,
            "f1": 0.94239
        },
        "bleurt": 0.13685,
        "meteor": 0.47621771053583856,
        "nubia": {
            "semantic_relation": 4.43948,
            "contradiction": 0.54329,
            "irrelevancy": 63.5007,
            "logical_agreement": 35.95601,
            "grammar_ref": 5.15251,
            "grammar_hyp": 5.05168,
            "nubia_score": 0.80254
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_812": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0945894140476606,
        "bleu": 62.62845,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "bertscore": {
            "precision": 0.96634,
            "recall": 0.98092,
            "f1": 0.97358
        },
        "bleurt": 0.79405,
        "meteor": 0.512675617900284,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.37071,
            "irrelevancy": 0.70467,
            "logical_agreement": 98.92462,
            "grammar_ref": 4.58246,
            "grammar_hyp": 4.34125,
            "nubia_score": 0.98178
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1014": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.277613436819116,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.077067708633815,
        "bleu": 15.85117,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.8,
            "fmeasure": 0.61538
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.5,
            "fmeasure": 0.36364
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.8,
            "fmeasure": 0.61538
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.8,
            "fmeasure": 0.61538
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.88308,
            "recall": 0.96214,
            "f1": 0.92092
        },
        "bleurt": 0.52633,
        "meteor": 0.4157242800169579,
        "nubia": {
            "semantic_relation": 4.32515,
            "contradiction": 0.1052,
            "irrelevancy": 99.78136,
            "logical_agreement": 0.11345,
            "grammar_ref": 6.34893,
            "grammar_hyp": 4.71705,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_815": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 1.0,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 15,
        "distinct-1": 0.8928571428571429,
        "vocab_size-1": 25,
        "unique-1": 23,
        "entropy-1": 4.566108939837482,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.07596508462823662,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.92,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.453660689688183,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.08644000550678685,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.072348304754054,
        "bleu": 55.06028,
        "rouge1": {
            "precision": 0.85165,
            "recall": 0.87454,
            "fmeasure": 0.8623
        },
        "rouge2": {
            "precision": 0.67628,
            "recall": 0.70085,
            "fmeasure": 0.68778
        },
        "rougeL": {
            "precision": 0.81319,
            "recall": 0.837,
            "fmeasure": 0.82431
        },
        "rougeLsum": {
            "precision": 0.81319,
            "recall": 0.837,
            "fmeasure": 0.82431
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8947368421052632
        },
        "bertscore": {
            "precision": 0.95606,
            "recall": 0.96548,
            "f1": 0.95939
        },
        "bleurt": 0.58578,
        "meteor": 0.5230036211612383,
        "nubia": {
            "semantic_relation": 4.58976,
            "contradiction": 0.1936,
            "irrelevancy": 48.78432,
            "logical_agreement": 51.02208,
            "grammar_ref": 4.97173,
            "grammar_hyp": 4.69012,
            "nubia_score": 0.84413
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_816": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.67,
        "msttr-100_nopunct": NaN,
        "total_length": 126,
        "mean_pred_length": 25.2,
        "std_pred_length": 14.274452704044382,
        "median_pred_length": 20.0,
        "min_pred_length": 12,
        "max_pred_length": 53,
        "distinct-1": 0.6428571428571429,
        "vocab_size-1": 81,
        "unique-1": 63,
        "entropy-1": 5.971698777434543,
        "distinct-2": 0.9173553719008265,
        "vocab_size-2": 111,
        "unique-2": 103,
        "entropy-2": 6.73704505545642,
        "cond_entropy-2": 0.7109517760044367,
        "distinct-3": 0.9568965517241379,
        "vocab_size-3": 111,
        "unique-3": 106,
        "entropy-3": 6.771774098575833,
        "cond_entropy-3": 0.025324654404701746,
        "total_length-nopunct": 97,
        "mean_pred_length-nopunct": 19.4,
        "std_pred_length-nopunct": 7.761443164772902,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.7628865979381443,
        "vocab_size-1-nopunct": 74,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 6.027913425121528,
        "distinct-2-nopunct": 0.9347826086956522,
        "vocab_size-2-nopunct": 86,
        "unique-2-nopunct": 80,
        "entropy-2-nopunct": 6.393127173448331,
        "cond_entropy-2-nopunct": 0.37456154273253817,
        "distinct-3-nopunct": 0.9425287356321839,
        "vocab_size-3-nopunct": 82,
        "unique-3-nopunct": 77,
        "entropy-3-nopunct": 6.328000967113091,
        "cond_entropy-3-nopunct": -0.06912420733472141,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.474261127482661,
        "bleu": 59.23914,
        "rouge1": {
            "precision": 0.74734,
            "recall": 0.83564,
            "fmeasure": 0.77084
        },
        "rouge2": {
            "precision": 0.60108,
            "recall": 0.65325,
            "fmeasure": 0.61375
        },
        "rougeL": {
            "precision": 0.66321,
            "recall": 0.71841,
            "fmeasure": 0.67675
        },
        "rougeLsum": {
            "precision": 0.66321,
            "recall": 0.71841,
            "fmeasure": 0.67675
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.7450980392156863,
            "3": 0.9142857142857143
        },
        "bertscore": {
            "precision": 0.93351,
            "recall": 0.94675,
            "f1": 0.9371
        },
        "bleurt": 0.19018,
        "meteor": 0.46294264609257046,
        "nubia": {
            "semantic_relation": 4.09867,
            "contradiction": 12.42939,
            "irrelevancy": 34.57641,
            "logical_agreement": 52.99421,
            "grammar_ref": 4.74118,
            "grammar_hyp": 4.42393,
            "nubia_score": 0.75315
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_736": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 9.5,
        "std_pred_length": 0.5,
        "median_pred_length": 9.5,
        "min_pred_length": 9,
        "max_pred_length": 10,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.042817613369716734,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.18057224564182078,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.047238912308487487,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.2064508774674265,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.767792283860976,
        "bleu": 56.91879,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.98333,
            "fmeasure": 0.96182
        },
        "rouge2": {
            "precision": 0.85417,
            "recall": 0.89153,
            "fmeasure": 0.87059
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.85833,
            "fmeasure": 0.84417
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.85833,
            "fmeasure": 0.84417
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8823529411764706
        },
        "bertscore": {
            "precision": 0.96036,
            "recall": 0.97571,
            "f1": 0.96797
        },
        "bleurt": 0.56192,
        "meteor": 0.5672280595023577,
        "nubia": {
            "semantic_relation": 4.83422,
            "contradiction": 0.82237,
            "irrelevancy": 21.99511,
            "logical_agreement": 77.18253,
            "grammar_ref": 4.99735,
            "grammar_hyp": 5.09212,
            "nubia_score": 0.84596
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_882": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 5.5,
        "median_pred_length": 18.5,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.8378378378378378,
        "vocab_size-1": 31,
        "unique-1": 27,
        "entropy-1": 4.831074987250574,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.2626867941731595,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.08488889758651327,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8787878787878788,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.741363816328152,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.2323828361897122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.09621531525930291,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.162028142972403,
        "bleu": 65.5974,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.92667,
            "fmeasure": 0.92047
        },
        "rouge2": {
            "precision": 0.80159,
            "recall": 0.81898,
            "fmeasure": 0.80969
        },
        "rougeL": {
            "precision": 0.78788,
            "recall": 0.76029,
            "fmeasure": 0.77329
        },
        "rougeLsum": {
            "precision": 0.78788,
            "recall": 0.76029,
            "fmeasure": 0.77329
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.96759,
            "recall": 0.98149,
            "f1": 0.97337
        },
        "bleurt": 0.69537,
        "meteor": 0.5334464707278733,
        "nubia": {
            "semantic_relation": 4.6995,
            "contradiction": 0.20689,
            "irrelevancy": 0.59169,
            "logical_agreement": 99.20142,
            "grammar_ref": 4.2058,
            "grammar_hyp": 4.13553,
            "nubia_score": 0.93293
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_740": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7224676484285957,
        "bleu": 100.0,
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.88889,
            "fmeasure": 0.92063
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.81818,
            "fmeasure": 0.84211
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.88889,
            "fmeasure": 0.92063
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.88889,
            "fmeasure": 0.92063
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.68577,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.40157,
            "contradiction": 5.65972,
            "irrelevancy": 2.65283,
            "logical_agreement": 91.68745,
            "grammar_ref": 4.01628,
            "grammar_hyp": 3.81914,
            "nubia_score": 0.8297
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_888": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 71,
        "mean_pred_length": 17.75,
        "std_pred_length": 5.931905258852336,
        "median_pred_length": 20.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.6901408450704225,
        "vocab_size-1": 49,
        "unique-1": 37,
        "entropy-1": 5.355291176454449,
        "distinct-2": 0.9104477611940298,
        "vocab_size-2": 61,
        "unique-2": 55,
        "entropy-2": 5.886984712845828,
        "cond_entropy-2": 0.4597207568719964,
        "distinct-3": 0.9682539682539683,
        "vocab_size-3": 61,
        "unique-3": 59,
        "entropy-3": 5.913787860007855,
        "cond_entropy-3": 0.03817486002627102,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 5.522680508593631,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.71875,
        "vocab_size-1-nopunct": 46,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.274900438178645,
        "distinct-2-nopunct": 0.9,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.706890595608518,
        "cond_entropy-2-nopunct": 0.4539140865392771,
        "distinct-3-nopunct": 0.9642857142857143,
        "vocab_size-3-nopunct": 54,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 5.735926350629038,
        "cond_entropy-3-nopunct": 0.04332146930622849,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8417672975082864,
        "bleu": 28.92703,
        "rouge1": {
            "precision": 0.6598,
            "recall": 0.60918,
            "fmeasure": 0.62836
        },
        "rouge2": {
            "precision": 0.43236,
            "recall": 0.38233,
            "fmeasure": 0.40208
        },
        "rougeL": {
            "precision": 0.56646,
            "recall": 0.50673,
            "fmeasure": 0.53113
        },
        "rougeLsum": {
            "precision": 0.56646,
            "recall": 0.50673,
            "fmeasure": 0.53113
        },
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.5454545454545454,
            "3": 0.5945945945945946
        },
        "bertscore": {
            "precision": 0.90199,
            "recall": 0.89433,
            "f1": 0.89794
        },
        "bleurt": 0.12999,
        "meteor": 0.30037777057154547,
        "nubia": {
            "semantic_relation": 3.44214,
            "contradiction": 55.74294,
            "irrelevancy": 8.57997,
            "logical_agreement": 35.67708,
            "grammar_ref": 4.12218,
            "grammar_hyp": 3.56562,
            "nubia_score": 0.61275
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1015": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 3.0,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 19,
        "distinct-1": 0.90625,
        "vocab_size-1": 29,
        "unique-1": 26,
        "entropy-1": 4.8125,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.04022392894185191,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9310344827586207,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.720049960644813,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": 0.045054655184044716,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9430595155500736,
        "bleu": 30.00339,
        "rouge1": {
            "precision": 0.55952,
            "recall": 0.4478,
            "fmeasure": 0.49353
        },
        "rouge2": {
            "precision": 0.3625,
            "recall": 0.28193,
            "fmeasure": 0.31413
        },
        "rougeL": {
            "precision": 0.43498,
            "recall": 0.35143,
            "fmeasure": 0.38565
        },
        "rougeLsum": {
            "precision": 0.43498,
            "recall": 0.35143,
            "fmeasure": 0.38565
        },
        "local_recall": {
            "1": 0.37037037037037035,
            "2": 0.5238095238095238
        },
        "bertscore": {
            "precision": 0.89083,
            "recall": 0.84545,
            "f1": 0.86367
        },
        "bleurt": -0.3232,
        "meteor": 0.23706008308763796,
        "nubia": {
            "semantic_relation": 3.1976,
            "contradiction": 0.38755,
            "irrelevancy": 68.64708,
            "logical_agreement": 30.96537,
            "grammar_ref": 4.87596,
            "grammar_hyp": 4.91893,
            "nubia_score": 0.40235
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1020": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 6.0,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.84375,
        "vocab_size-1": 27,
        "unique-1": 22,
        "entropy-1": 4.6875,
        "distinct-2": 0.9666666666666667,
        "vocab_size-2": 29,
        "unique-2": 28,
        "entropy-2": 4.840223928941852,
        "cond_entropy-2": 0.10689059560851849,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.028107102122342943,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8518518518518519,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.458591205867174,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.5638561897747225,
        "cond_entropy-2-nopunct": 0.12896868761125616,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.03333771197858132,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.905349758425851,
        "bleu": 49.61087,
        "rouge1": {
            "precision": 0.7232,
            "recall": 0.73565,
            "fmeasure": 0.72231
        },
        "rouge2": {
            "precision": 0.55093,
            "recall": 0.54789,
            "fmeasure": 0.52853
        },
        "rougeL": {
            "precision": 0.71637,
            "recall": 0.67857,
            "fmeasure": 0.67686
        },
        "rougeLsum": {
            "precision": 0.71637,
            "recall": 0.67857,
            "fmeasure": 0.67686
        },
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.7272727272727273,
            "3": 0.9090909090909091
        },
        "bertscore": {
            "precision": 0.94571,
            "recall": 0.94472,
            "f1": 0.93957
        },
        "bleurt": 0.11184,
        "meteor": 0.383076037941439,
        "nubia": {
            "semantic_relation": 4.19896,
            "contradiction": 8.85506,
            "irrelevancy": 23.84269,
            "logical_agreement": 67.30224,
            "grammar_ref": 4.3679,
            "grammar_hyp": 4.0107,
            "nubia_score": 0.75017
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_889": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 12,
        "unique-1": 10,
        "entropy-1": 3.521640636343319,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.2007771037757955,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.21785611591339743,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.282146783768088,
        "bleu": 3.9538,
        "rouge1": {
            "precision": 0.28571,
            "recall": 0.57143,
            "fmeasure": 0.38095
        },
        "rouge2": {
            "precision": 0.07692,
            "recall": 0.16667,
            "fmeasure": 0.10526
        },
        "rougeL": {
            "precision": 0.19048,
            "recall": 0.22024,
            "fmeasure": 0.19683
        },
        "rougeLsum": {
            "precision": 0.19048,
            "recall": 0.22024,
            "fmeasure": 0.19683
        },
        "local_recall": {
            "1": 0.125,
            "2": 0,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.7987,
            "recall": 0.86973,
            "f1": 0.8153
        },
        "bleurt": 0.37129,
        "meteor": 0.24876208989937637,
        "nubia": {
            "semantic_relation": 4.05505,
            "contradiction": 0.07724,
            "irrelevancy": 94.08487,
            "logical_agreement": 5.83789,
            "grammar_ref": 4.92688,
            "grammar_hyp": 3.24158,
            "nubia_score": 0.78413
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_890": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.2349851365001359,
        "bleu": 16.78446,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.59028,
            "fmeasure": 0.54094
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.40179,
            "fmeasure": 0.36397
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.59028,
            "fmeasure": 0.54094
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.59028,
            "fmeasure": 0.54094
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855
        },
        "bertscore": {
            "precision": 0.85831,
            "recall": 0.87683,
            "f1": 0.86747
        },
        "bleurt": 0.52303,
        "meteor": 0.27858768568166986,
        "nubia": {
            "semantic_relation": 4.2029,
            "contradiction": 7.06447,
            "irrelevancy": 12.79331,
            "logical_agreement": 80.14222,
            "grammar_ref": 4.73918,
            "grammar_hyp": 4.01995,
            "nubia_score": 0.76232
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1022": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.284561971965138,
        "bleu": 33.34477,
        "rouge1": {
            "precision": 0.46154,
            "recall": 0.66667,
            "fmeasure": 0.54545
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.375,
            "fmeasure": 0.3
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.66667,
            "fmeasure": 0.54545
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.66667,
            "fmeasure": 0.54545
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.625
        },
        "bertscore": {
            "precision": 0.88561,
            "recall": 0.91719,
            "f1": 0.8997
        },
        "bleurt": 0.39219,
        "meteor": 0.2385077002682506,
        "nubia": {
            "semantic_relation": 3.52825,
            "contradiction": 2.93428,
            "irrelevancy": 85.55928,
            "logical_agreement": 11.50644,
            "grammar_ref": 5.49813,
            "grammar_hyp": 5.07579,
            "nubia_score": 0.43266
        }
    },
    "web_nlg_en_test": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 1779,
        "msttr-100": 0.63463,
        "msttr-100_nopunct": 0.67443,
        "total_length": 45446,
        "mean_pred_length": 25.545812254075322,
        "std_pred_length": 12.997881444126877,
        "median_pred_length": 23.0,
        "min_pred_length": 5,
        "max_pred_length": 75,
        "distinct-1": 0.0500154028957444,
        "vocab_size-1": 2273,
        "unique-1": 687,
        "entropy-1": 8.064921841760448,
        "distinct-2": 0.19014358669017795,
        "vocab_size-2": 8303,
        "unique-2": 3930,
        "entropy-2": 11.483340194916822,
        "cond_entropy-2": 3.2541899185173273,
        "distinct-3": 0.3534902597402597,
        "vocab_size-3": 14807,
        "unique-3": 8997,
        "entropy-3": 12.835091066818217,
        "cond_entropy-3": 1.4105019766901625,
        "total_length-nopunct": 40243,
        "mean_pred_length-nopunct": 22.621135469364813,
        "std_pred_length-nopunct": 11.68431120494885,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 65,
        "distinct-1-nopunct": 0.05623338220311607,
        "vocab_size-1-nopunct": 2263,
        "unique-1-nopunct": 687,
        "entropy-1-nopunct": 8.347918835972235,
        "distinct-2-nopunct": 0.2060108153078203,
        "vocab_size-2-nopunct": 7924,
        "unique-2-nopunct": 4015,
        "entropy-2-nopunct": 11.409349830596447,
        "cond_entropy-2-nopunct": 3.201561734690716,
        "distinct-3-nopunct": 0.3716777974649039,
        "vocab_size-3-nopunct": 13635,
        "unique-3-nopunct": 8610,
        "entropy-3-nopunct": 12.711727275329093,
        "cond_entropy-3-nopunct": 1.3603244650635986,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.743174542580261,
        "bleu": 38.217,
        "rouge1": {
            "precision": 0.67588,
            "recall": 0.68752,
            "fmeasure": 0.67511
        },
        "rouge2": {
            "precision": 0.40884,
            "recall": 0.41622,
            "fmeasure": 0.40818
        },
        "rougeL": {
            "precision": 0.53129,
            "recall": 0.54213,
            "fmeasure": 0.53105
        },
        "rougeLsum": {
            "precision": 0.53129,
            "recall": 0.54213,
            "fmeasure": 0.53105
        },
        "local_recall": {
            "1": 0.22726490332204946,
            "2": 0.5483150432164708,
            "3": 0.7772307692307693,
            "4": 0.8545454545454545,
            "5": 0.7241379310344828
        },
        "bertscore": {
            "precision": 0.89484,
            "recall": 0.89839,
            "f1": 0.89541
        },
        "bleurt": -0.03709,
        "meteor": 0.33807259122231476,
        "nubia": {
            "semantic_relation": 3.99144,
            "contradiction": 24.78583,
            "irrelevancy": 10.04073,
            "logical_agreement": 65.17345,
            "grammar_ref": 4.5596,
            "grammar_hyp": 4.66775,
            "nubia_score": 0.65718
        }
    },
    "web_nlg_en_challenge_train_sample": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_challenge_train_sample",
        "N": 502
    },
    "web_nlg_en_challenge_validation_sample": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_challenge_validation_sample",
        "N": 499
    },
    "totto_test_contrast_challenge_table_size-table_size_918": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 51,
        "mean_pred_length": 51.0,
        "std_pred_length": 0.0,
        "median_pred_length": 51.0,
        "min_pred_length": 51,
        "max_pred_length": 51,
        "distinct-1": 0.7254901960784313,
        "vocab_size-1": 37,
        "unique-1": 28,
        "entropy-1": 5.000569214393256,
        "distinct-2": 0.92,
        "vocab_size-2": 46,
        "unique-2": 42,
        "entropy-2": 5.483856189774728,
        "cond_entropy-2": 0.4650248479186143,
        "distinct-3": 0.9795918367346939,
        "vocab_size-3": 48,
        "unique-3": 47,
        "entropy-3": 5.5738935175845965,
        "cond_entropy-3": 0.09330263393232063,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 42.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 42.0,
        "min_pred_length-nopunct": 42,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 5.0589840894454285,
        "distinct-2-nopunct": 0.926829268292683,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.211210541203447,
        "cond_entropy-2-nopunct": 0.13596628915639664,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": 0.08937609026927872,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.735394587785707,
        "bleu": 30.99145,
        "rouge1": {
            "precision": 0.55814,
            "recall": 0.91168,
            "fmeasure": 0.69234
        },
        "rouge2": {
            "precision": 0.35714,
            "recall": 0.59231,
            "fmeasure": 0.44557
        },
        "rougeL": {
            "precision": 0.46512,
            "recall": 0.75973,
            "fmeasure": 0.57695
        },
        "rougeLsum": {
            "precision": 0.46512,
            "recall": 0.75973,
            "fmeasure": 0.57695
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.9166666666666666,
            "3": 0.9
        },
        "bertscore": {
            "precision": 0.87127,
            "recall": 0.95231,
            "f1": 0.90725
        },
        "bleurt": -0.23609,
        "meteor": 0.4110903054759302,
        "nubia": {
            "semantic_relation": 3.738,
            "contradiction": 95.07989,
            "irrelevancy": 2.62692,
            "logical_agreement": 2.29318,
            "grammar_ref": 4.65446,
            "grammar_hyp": 4.08331,
            "nubia_score": 0.42773
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_822": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.0,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 18,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 24,
        "unique-1": 20,
        "entropy-1": 4.52164063634332,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.12385402685271857,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.88,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.403856189774722,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.14057533149967955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.581780211452203,
        "bleu": 28.5812,
        "rouge1": {
            "precision": 0.60662,
            "recall": 0.58613,
            "fmeasure": 0.59087
        },
        "rouge2": {
            "precision": 0.27976,
            "recall": 0.29754,
            "fmeasure": 0.28592
        },
        "rougeL": {
            "precision": 0.52451,
            "recall": 0.51653,
            "fmeasure": 0.51571
        },
        "rougeLsum": {
            "precision": 0.52451,
            "recall": 0.51653,
            "fmeasure": 0.51571
        },
        "local_recall": {
            "1": 0.6,
            "2": 0.3333333333333333,
            "3": 0.6470588235294118
        },
        "bertscore": {
            "precision": 0.91402,
            "recall": 0.90599,
            "f1": 0.90981
        },
        "bleurt": 0.47456,
        "meteor": 0.34430782972696217,
        "nubia": {
            "semantic_relation": 4.18585,
            "contradiction": 4.77951,
            "irrelevancy": 35.15268,
            "logical_agreement": 60.06781,
            "grammar_ref": 4.56502,
            "grammar_hyp": 4.87786,
            "nubia_score": 0.72251
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_828": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 66,
        "mean_pred_length": 33.0,
        "std_pred_length": 7.0,
        "median_pred_length": 33.0,
        "min_pred_length": 26,
        "max_pred_length": 40,
        "distinct-1": 0.803030303030303,
        "vocab_size-1": 53,
        "unique-1": 46,
        "entropy-1": 5.536670255656537,
        "distinct-2": 0.984375,
        "vocab_size-2": 63,
        "unique-2": 62,
        "entropy-2": 5.96875,
        "cond_entropy-2": 0.41669611508415444,
        "distinct-3": 1.0,
        "vocab_size-3": 62,
        "unique-3": 62,
        "entropy-3": 5.954196310386873,
        "cond_entropy-3": -0.013545625096995736,
        "total_length-nopunct": 60,
        "mean_pred_length-nopunct": 30.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 30.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.8166666666666667,
        "vocab_size-1-nopunct": 49,
        "unique-1-nopunct": 44,
        "entropy-1-nopunct": 5.415061012203068,
        "distinct-2-nopunct": 0.9827586206896551,
        "vocab_size-2-nopunct": 57,
        "unique-2-nopunct": 56,
        "entropy-2-nopunct": 5.823498236506881,
        "cond_entropy-2-nopunct": 0.39091410649020747,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 56,
        "unique-3-nopunct": 56,
        "entropy-3-nopunct": 5.807354922057609,
        "cond_entropy-3-nopunct": -0.014911787355682111,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.608207928729736,
        "bleu": 46.49609,
        "rouge1": {
            "precision": 0.70095,
            "recall": 0.77004,
            "fmeasure": 0.73172
        },
        "rouge2": {
            "precision": 0.47998,
            "recall": 0.52329,
            "fmeasure": 0.49909
        },
        "rougeL": {
            "precision": 0.51333,
            "recall": 0.60671,
            "fmeasure": 0.55417
        },
        "rougeLsum": {
            "precision": 0.51333,
            "recall": 0.60671,
            "fmeasure": 0.55417
        },
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 0,
            "3": 0.8205128205128205
        },
        "bertscore": {
            "precision": 0.90958,
            "recall": 0.93035,
            "f1": 0.91903
        },
        "bleurt": 0.23878,
        "meteor": 0.39658723658795103,
        "nubia": {
            "semantic_relation": 3.67387,
            "contradiction": 49.86205,
            "irrelevancy": 4.653,
            "logical_agreement": 45.48496,
            "grammar_ref": 3.79147,
            "grammar_hyp": 3.65714,
            "nubia_score": 0.5696
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_895": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 3.5,
        "median_pred_length": 12.5,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.76,
        "vocab_size-1": 19,
        "unique-1": 13,
        "entropy-1": 4.163856189774723,
        "distinct-2": 0.9130434782608695,
        "vocab_size-2": 21,
        "unique-2": 19,
        "entropy-2": 4.349648912578752,
        "cond_entropy-2": 0.14057533149967955,
        "distinct-3": 0.9523809523809523,
        "vocab_size-3": 20,
        "unique-3": 19,
        "entropy-3": 4.297079327540665,
        "cond_entropy-3": -0.036006438040157185,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.782608695652174,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.088779347361362,
        "distinct-2-nopunct": 0.9047619047619048,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.201841232302569,
        "cond_entropy-2-nopunct": 0.10685070481698568,
        "distinct-3-nopunct": 0.9473684210526315,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.142664355548846,
        "cond_entropy-3-nopunct": -0.09175833038780651,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.229036952631846,
        "bleu": 33.10021,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.59086,
            "fmeasure": 0.62627
        },
        "rouge2": {
            "precision": 0.39286,
            "recall": 0.34412,
            "fmeasure": 0.36678
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.59086,
            "fmeasure": 0.62627
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.59086,
            "fmeasure": 0.62627
        },
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.5333333333333333,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.90714,
            "recall": 0.87018,
            "f1": 0.88507
        },
        "bleurt": 0.11694,
        "meteor": 0.28490799526391,
        "nubia": {
            "semantic_relation": 3.84855,
            "contradiction": 3.25873,
            "irrelevancy": 54.59568,
            "logical_agreement": 42.14559,
            "grammar_ref": 4.46901,
            "grammar_hyp": 4.31093,
            "nubia_score": 0.62538
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_830": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.6416041678685933,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.4769363694743175,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.4677201004745006,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2588453731729854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.89145926838456,
        "bleu": 56.49269,
        "rouge1": {
            "precision": 0.9375,
            "recall": 1.0,
            "fmeasure": 0.96774
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.71429,
            "fmeasure": 0.68966
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.6,
            "fmeasure": 0.58065
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.6,
            "fmeasure": 0.58065
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.96781,
            "recall": 0.97397,
            "f1": 0.97088
        },
        "bleurt": 0.65892,
        "meteor": 0.5178515092602387,
        "nubia": {
            "semantic_relation": 4.92199,
            "contradiction": 0.648,
            "irrelevancy": 14.49103,
            "logical_agreement": 84.86097,
            "grammar_ref": 4.08392,
            "grammar_hyp": 3.84603,
            "nubia_score": 0.96737
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_833": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185189,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.074202687561549,
        "bleu": 79.93249,
        "rouge1": {
            "precision": 0.96078,
            "recall": 0.75591,
            "fmeasure": 0.84444
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.67677,
            "fmeasure": 0.76161
        },
        "rougeL": {
            "precision": 0.96078,
            "recall": 0.75591,
            "fmeasure": 0.84444
        },
        "rougeLsum": {
            "precision": 0.96078,
            "recall": 0.75591,
            "fmeasure": 0.84444
        },
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 1.0,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.97669,
            "recall": 0.96698,
            "f1": 0.97081
        },
        "bleurt": 0.52498,
        "meteor": 0.5293855573293579,
        "nubia": {
            "semantic_relation": 4.64656,
            "contradiction": 0.65741,
            "irrelevancy": 0.75432,
            "logical_agreement": 98.58827,
            "grammar_ref": 4.95426,
            "grammar_hyp": 5.01119,
            "nubia_score": 0.85081
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_920": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 0.9428090415820634,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 16,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 38,
        "unique-1": 34,
        "entropy-1": 5.1523912776298655,
        "distinct-2": 1.0,
        "vocab_size-2": 41,
        "unique-2": 41,
        "entropy-2": 5.357552004618081,
        "cond_entropy-2": 0.11165422749696838,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.10962449117449787,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 2.0548046676563256,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.017535737070865,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.129283016944964,
        "cond_entropy-2-nopunct": 0.13149514642033722,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.12928301694496638,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.263157736291619,
        "bleu": 31.24095,
        "rouge1": {
            "precision": 0.77725,
            "recall": 0.69815,
            "fmeasure": 0.728
        },
        "rouge2": {
            "precision": 0.54487,
            "recall": 0.49624,
            "fmeasure": 0.51225
        },
        "rougeL": {
            "precision": 0.66455,
            "recall": 0.60988,
            "fmeasure": 0.62913
        },
        "rougeLsum": {
            "precision": 0.66455,
            "recall": 0.60988,
            "fmeasure": 0.62913
        },
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.3,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.92612,
            "recall": 0.90471,
            "f1": 0.90853
        },
        "bleurt": 0.16372,
        "meteor": 0.3011291649693279,
        "nubia": {
            "semantic_relation": 3.63705,
            "contradiction": 23.64961,
            "irrelevancy": 29.9247,
            "logical_agreement": 46.42569,
            "grammar_ref": 4.46773,
            "grammar_hyp": 4.25782,
            "nubia_score": 0.56575
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_924": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6868288363625352,
        "bleu": 38.80234,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.71053,
            "fmeasure": 0.82949
        },
        "rouge2": {
            "precision": 0.81818,
            "recall": 0.56667,
            "fmeasure": 0.66844
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.59211,
            "fmeasure": 0.69124
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.59211,
            "fmeasure": 0.69124
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.93399,
            "recall": 0.82306,
            "f1": 0.87502
        },
        "bleurt": 0.08263,
        "meteor": 0.3750409314937454,
        "nubia": {
            "semantic_relation": 4.16142,
            "contradiction": 0.4753,
            "irrelevancy": 0.54212,
            "logical_agreement": 98.98258,
            "grammar_ref": 4.542,
            "grammar_hyp": 4.52386,
            "nubia_score": 0.72933
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_834": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.306797170061882,
        "bleu": 69.04427,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.82353,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.66667,
            "fmeasure": 0.70238
        },
        "rougeL": {
            "precision": 0.65385,
            "recall": 0.58145,
            "fmeasure": 0.61282
        },
        "rougeLsum": {
            "precision": 0.65385,
            "recall": 0.58145,
            "fmeasure": 0.61282
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "bertscore": {
            "precision": 0.97265,
            "recall": 0.97025,
            "f1": 0.97145
        },
        "bleurt": 0.47554,
        "meteor": 0.5500501807094148,
        "nubia": {
            "semantic_relation": 4.27928,
            "contradiction": 0.25448,
            "irrelevancy": 0.49291,
            "logical_agreement": 99.25261,
            "grammar_ref": 4.29821,
            "grammar_hyp": 4.38971,
            "nubia_score": 0.78008
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_742": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.456435556800404,
        "bleu": 50.0,
        "rouge1": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.8,
            "fmeasure": 0.72727
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.98601,
            "recall": 0.99497,
            "f1": 0.99047
        },
        "bleurt": 0.93658,
        "meteor": 0.5277006683854432,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.14589,
            "irrelevancy": 0.6446,
            "logical_agreement": 98.20952,
            "grammar_ref": 4.87815,
            "grammar_hyp": 4.39193,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_840": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 75,
        "mean_pred_length": 15.0,
        "std_pred_length": 4.979959839195493,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 22,
        "distinct-1": 0.68,
        "vocab_size-1": 51,
        "unique-1": 36,
        "entropy-1": 5.4558297778153895,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 60,
        "unique-2": 51,
        "entropy-2": 5.832784624056917,
        "cond_entropy-2": 0.2663163332267543,
        "distinct-3": 0.8923076923076924,
        "vocab_size-3": 58,
        "unique-3": 51,
        "entropy-3": 5.806983197643843,
        "cond_entropy-3": -0.0029938577293818934,
        "total_length-nopunct": 65,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 4.560701700396552,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7384615384615385,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.432144305696146,
        "distinct-2-nopunct": 0.85,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.594309137239127,
        "cond_entropy-2-nopunct": 0.21135012382067758,
        "distinct-3-nopunct": 0.8909090909090909,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.563177895342839,
        "cond_entropy-3-nopunct": -0.0027147456808866537,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.378277321834618,
        "bleu": 66.38283,
        "rouge1": {
            "precision": 0.86905,
            "recall": 0.86435,
            "fmeasure": 0.8666
        },
        "rouge2": {
            "precision": 0.72999,
            "recall": 0.72558,
            "fmeasure": 0.72769
        },
        "rougeL": {
            "precision": 0.7881,
            "recall": 0.84054,
            "fmeasure": 0.8047
        },
        "rougeLsum": {
            "precision": 0.7881,
            "recall": 0.84054,
            "fmeasure": 0.8047
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6428571428571429,
            "3": 0.9130434782608695
        },
        "bertscore": {
            "precision": 0.93713,
            "recall": 0.95212,
            "f1": 0.94428
        },
        "bleurt": 0.37172,
        "meteor": 0.5281217990955542,
        "nubia": {
            "semantic_relation": 3.93339,
            "contradiction": 20.98342,
            "irrelevancy": 6.59472,
            "logical_agreement": 72.42185,
            "grammar_ref": 5.02868,
            "grammar_hyp": 4.65055,
            "nubia_score": 0.75635
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_896": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.6,
        "msttr-100_nopunct": 0.6,
        "total_length": 109,
        "mean_pred_length": 13.625,
        "std_pred_length": 2.9973947020704497,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 16,
        "distinct-1": 0.5688073394495413,
        "vocab_size-1": 62,
        "unique-1": 41,
        "entropy-1": 5.5549840407629105,
        "distinct-2": 0.8217821782178217,
        "vocab_size-2": 83,
        "unique-2": 69,
        "entropy-2": 6.267025591619831,
        "cond_entropy-2": 0.5705128604818042,
        "distinct-3": 0.8817204301075269,
        "vocab_size-3": 82,
        "unique-3": 72,
        "entropy-3": 6.294482601407355,
        "cond_entropy-3": 0.06110740902466086,
        "total_length-nopunct": 100,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.6,
        "vocab_size-1-nopunct": 60,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.561467880199458,
        "distinct-2-nopunct": 0.8043478260869565,
        "vocab_size-2-nopunct": 74,
        "unique-2-nopunct": 60,
        "entropy-2-nopunct": 6.094107879923034,
        "cond_entropy-2-nopunct": 0.5506737657735986,
        "distinct-3-nopunct": 0.8690476190476191,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 63,
        "entropy-3-nopunct": 6.121425904895862,
        "cond_entropy-3-nopunct": 0.008694603652265032,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5566830047034435,
        "bleu": 39.68638,
        "rouge1": {
            "precision": 0.73604,
            "recall": 0.59879,
            "fmeasure": 0.63992
        },
        "rouge2": {
            "precision": 0.56,
            "recall": 0.46341,
            "fmeasure": 0.49116
        },
        "rougeL": {
            "precision": 0.64067,
            "recall": 0.52655,
            "fmeasure": 0.56021
        },
        "rougeLsum": {
            "precision": 0.64067,
            "recall": 0.52655,
            "fmeasure": 0.56021
        },
        "local_recall": {
            "1": 0.3076923076923077,
            "2": 0.5675675675675675,
            "3": 0.6027397260273972
        },
        "bertscore": {
            "precision": 0.91023,
            "recall": 0.86915,
            "f1": 0.88731
        },
        "bleurt": -0.02023,
        "meteor": 0.33316949247475824,
        "nubia": {
            "semantic_relation": 3.79383,
            "contradiction": 22.79866,
            "irrelevancy": 39.3242,
            "logical_agreement": 37.87713,
            "grammar_ref": 4.28101,
            "grammar_hyp": 4.48668,
            "nubia_score": 0.57539
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_925": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.539439360821673,
        "bleu": 54.43985,
        "rouge1": {
            "precision": 0.92857,
            "recall": 0.92857,
            "fmeasure": 0.92857
        },
        "rouge2": {
            "precision": 0.76923,
            "recall": 0.76923,
            "fmeasure": 0.76923
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.97201,
            "recall": 0.96861,
            "f1": 0.97031
        },
        "bleurt": 0.51947,
        "meteor": 0.5345728454781155,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.42826,
            "irrelevancy": 0.4297,
            "logical_agreement": 99.14204,
            "grammar_ref": 5.0526,
            "grammar_hyp": 5.57734,
            "nubia_score": 0.90242
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_900": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 1.5,
        "median_pred_length": 11.5,
        "min_pred_length": 10,
        "max_pred_length": 13,
        "distinct-1": 0.8695652173913043,
        "vocab_size-1": 20,
        "unique-1": 17,
        "entropy-1": 4.262692390839622,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.05923165719793806,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.14438990933517493,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.06613640645429873,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.7920724127339955,
        "bleu": 74.75019,
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.96154,
            "fmeasure": 0.94394
        },
        "rouge2": {
            "precision": 0.77946,
            "recall": 0.80952,
            "fmeasure": 0.79081
        },
        "rougeL": {
            "precision": 0.89167,
            "recall": 0.92308,
            "fmeasure": 0.90394
        },
        "rougeLsum": {
            "precision": 0.89167,
            "recall": 0.92308,
            "fmeasure": 0.90394
        },
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.97518,
            "recall": 0.97012,
            "f1": 0.97249
        },
        "bleurt": 0.6255,
        "meteor": 0.5368340688340381,
        "nubia": {
            "semantic_relation": 4.61445,
            "contradiction": 0.31099,
            "irrelevancy": 33.52218,
            "logical_agreement": 66.16683,
            "grammar_ref": 5.10267,
            "grammar_hyp": 5.23823,
            "nubia_score": 0.86102
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_903": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.6402239289418516,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.11475004073479991,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.423065265165703,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.94038,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.31517,
            "irrelevancy": 0.55477,
            "logical_agreement": 99.13006,
            "grammar_ref": 5.42428,
            "grammar_hyp": 5.51742,
            "nubia_score": 0.98965
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_931": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.581867248302647,
        "bleu": 18.55329,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.65769,
            "fmeasure": 0.69783
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.29167,
            "fmeasure": 0.30952
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.44231,
            "fmeasure": 0.46739
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.44231,
            "fmeasure": 0.46739
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.875
        },
        "bertscore": {
            "precision": 0.94321,
            "recall": 0.90901,
            "f1": 0.92338
        },
        "bleurt": 0.04066,
        "meteor": 0.3567154643095743,
        "nubia": {
            "semantic_relation": 4.26126,
            "contradiction": 0.56059,
            "irrelevancy": 0.57916,
            "logical_agreement": 98.86025,
            "grammar_ref": 4.19915,
            "grammar_hyp": 4.39446,
            "nubia_score": 0.7965
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1141": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.038944894698677,
        "bleu": 22.35234,
        "rouge1": {
            "precision": 0.62963,
            "recall": 0.48485,
            "fmeasure": 0.54762
        },
        "rouge2": {
            "precision": 0.29167,
            "recall": 0.21515,
            "fmeasure": 0.24756
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.38889,
            "fmeasure": 0.45635
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.38889,
            "fmeasure": 0.45635
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.8988,
            "recall": 0.87691,
            "f1": 0.88772
        },
        "bleurt": 0.05805,
        "meteor": 0.24545494528992856,
        "nubia": {
            "semantic_relation": 3.91397,
            "contradiction": 0.94826,
            "irrelevancy": 45.28218,
            "logical_agreement": 53.76955,
            "grammar_ref": 4.53537,
            "grammar_hyp": 4.57978,
            "nubia_score": 0.61473
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1032": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.7276594188003902,
        "bleu": 15.7168,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.34343,
            "fmeasure": 0.45118
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.1,
            "fmeasure": 0.125
        },
        "rougeL": {
            "precision": 0.38095,
            "recall": 0.19394,
            "fmeasure": 0.25589
        },
        "rougeLsum": {
            "precision": 0.38095,
            "recall": 0.19394,
            "fmeasure": 0.25589
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.4
        },
        "bertscore": {
            "precision": 0.87596,
            "recall": 0.79176,
            "f1": 0.82939
        },
        "bleurt": -0.29315,
        "meteor": 0.19688254453404394,
        "nubia": {
            "semantic_relation": 3.21109,
            "contradiction": 1.11176,
            "irrelevancy": 72.74205,
            "logical_agreement": 26.14619,
            "grammar_ref": 4.59968,
            "grammar_hyp": 5.87137,
            "nubia_score": 0.29499
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_909": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.816496580927726,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 14,
        "distinct-1": 0.6923076923076923,
        "vocab_size-1": 27,
        "unique-1": 19,
        "entropy-1": 4.580023372597455,
        "distinct-2": 0.8611111111111112,
        "vocab_size-2": 31,
        "unique-2": 26,
        "entropy-2": 4.892147223664533,
        "cond_entropy-2": 0.23882521319571604,
        "distinct-3": 0.9090909090909091,
        "vocab_size-3": 30,
        "unique-3": 27,
        "entropy-3": 4.862575937540274,
        "cond_entropy-3": -0.06492482147779848,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 0.4714045207910317,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.7142857142857143,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.479143374026009,
        "distinct-2-nopunct": 0.875,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.75,
        "cond_entropy-2-nopunct": 0.26930721749764186,
        "distinct-3-nopunct": 0.9310344827586207,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.720049960644813,
        "cond_entropy-3-nopunct": -0.07305348763104855,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.9626481511603275,
        "bleu": 81.92915,
        "rouge1": {
            "precision": 0.96581,
            "recall": 0.99074,
            "fmeasure": 0.97702
        },
        "rouge2": {
            "precision": 0.8963,
            "recall": 0.91717,
            "fmeasure": 0.90551
        },
        "rougeL": {
            "precision": 0.91453,
            "recall": 0.9335,
            "fmeasure": 0.92295
        },
        "rougeLsum": {
            "precision": 0.91453,
            "recall": 0.9335,
            "fmeasure": 0.92295
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.967741935483871
        },
        "bertscore": {
            "precision": 0.98482,
            "recall": 0.98878,
            "f1": 0.98456
        },
        "bleurt": 0.73605,
        "meteor": 0.5939092573530671,
        "nubia": {
            "semantic_relation": 4.77978,
            "contradiction": 0.69047,
            "irrelevancy": 1.4228,
            "logical_agreement": 97.88673,
            "grammar_ref": 3.77014,
            "grammar_hyp": 3.90991,
            "nubia_score": 0.90602
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_936": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 2.5,
        "median_pred_length": 15.5,
        "min_pred_length": 13,
        "max_pred_length": 18,
        "distinct-1": 0.9032258064516129,
        "vocab_size-1": 28,
        "unique-1": 25,
        "entropy-1": 4.760647923290102,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 28,
        "unique-2": 27,
        "entropy-2": 4.789015477886192,
        "cond_entropy-2": -0.02724979801792366,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.029019418890029344,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.546593564294937,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.501629167387823,
        "cond_entropy-2-nopunct": -0.03214388408660254,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.034621791174768206,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.151147693339616,
        "bleu": 37.35291,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.78958,
            "fmeasure": 0.83796
        },
        "rouge2": {
            "precision": 0.72222,
            "recall": 0.64827,
            "fmeasure": 0.67562
        },
        "rougeL": {
            "precision": 0.76042,
            "recall": 0.68021,
            "fmeasure": 0.71065
        },
        "rougeLsum": {
            "precision": 0.76042,
            "recall": 0.68021,
            "fmeasure": 0.71065
        },
        "local_recall": {
            "1": 0.06666666666666667,
            "2": 0.6666666666666666,
            "3": 0.6923076923076923
        },
        "bertscore": {
            "precision": 0.9225,
            "recall": 0.92874,
            "f1": 0.92534
        },
        "bleurt": 0.17066,
        "meteor": 0.3614780426783212,
        "nubia": {
            "semantic_relation": 4.2649,
            "contradiction": 32.61645,
            "irrelevancy": 3.36233,
            "logical_agreement": 64.02123,
            "grammar_ref": 4.54027,
            "grammar_hyp": 5.19498,
            "nubia_score": 0.55435
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1152": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6609640474436813,
        "bleu": 12.54931,
        "rouge1": {
            "precision": 0.4,
            "recall": 0.44444,
            "fmeasure": 0.42105
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.25,
            "fmeasure": 0.23529
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.44444,
            "fmeasure": 0.42105
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.44444,
            "fmeasure": 0.42105
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.4444444444444444
        },
        "bertscore": {
            "precision": 0.87901,
            "recall": 0.89984,
            "f1": 0.8893
        },
        "bleurt": 0.30052,
        "meteor": 0.29568923502227945,
        "nubia": {
            "semantic_relation": 4.59766,
            "contradiction": 0.24242,
            "irrelevancy": 90.95441,
            "logical_agreement": 8.80317,
            "grammar_ref": 3.99081,
            "grammar_hyp": 2.90139,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1036": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 9.5,
        "std_pred_length": 1.5,
        "median_pred_length": 9.5,
        "min_pred_length": 8,
        "max_pred_length": 11,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548847,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.1604646721932461,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.18057224564182078,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.18057224564182078,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.2064508774674265,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.657073302730112,
        "bleu": 28.58615,
        "rouge1": {
            "precision": 0.87857,
            "recall": 0.70606,
            "fmeasure": 0.76912
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.47143,
            "fmeasure": 0.50975
        },
        "rougeL": {
            "precision": 0.66905,
            "recall": 0.55589,
            "fmeasure": 0.59626
        },
        "rougeLsum": {
            "precision": 0.66905,
            "recall": 0.55589,
            "fmeasure": 0.59626
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.14285714285714285,
            "3": 0.6842105263157895
        },
        "bertscore": {
            "precision": 0.92803,
            "recall": 0.88261,
            "f1": 0.90388
        },
        "bleurt": 0.28379,
        "meteor": 0.3819396600152327,
        "nubia": {
            "semantic_relation": 4.11922,
            "contradiction": 0.21797,
            "irrelevancy": 0.95817,
            "logical_agreement": 98.82387,
            "grammar_ref": 4.70186,
            "grammar_hyp": 5.72358,
            "nubia_score": 0.64063
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_938": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 30.0,
        "std_pred_length": 0.0,
        "median_pred_length": 30.0,
        "min_pred_length": 30,
        "max_pred_length": 30,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 26,
        "unique-1": 22,
        "entropy-1": 4.640223928941852,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.19246970986388115,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.0506260730699678,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 26.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 26,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.546593564294937,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.1034164716336324,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.058893689053568274,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.947893022820673,
        "bleu": 71.6765,
        "rouge1": {
            "precision": 0.96154,
            "recall": 0.96154,
            "fmeasure": 0.96154
        },
        "rouge2": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rougeL": {
            "precision": 0.88462,
            "recall": 0.88462,
            "fmeasure": 0.88462
        },
        "rougeLsum": {
            "precision": 0.88462,
            "recall": 0.88462,
            "fmeasure": 0.88462
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9583333333333334
        },
        "bertscore": {
            "precision": 0.98821,
            "recall": 0.98052,
            "f1": 0.98435
        },
        "bleurt": 0.69253,
        "meteor": 0.5596521072209456,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.19171,
            "irrelevancy": 0.40775,
            "logical_agreement": 99.40054,
            "grammar_ref": 4.59074,
            "grammar_hyp": 4.58392,
            "nubia_score": 0.996
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1155": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.8125,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.577819531114783,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 14,
        "unique-2": 13,
        "entropy-2": 3.7735572622751845,
        "cond_entropy-2": 0.22388309575274978,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": 0.04332146930622849,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3248629576173574,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.5465935642949384,
        "cond_entropy-2-nopunct": 0.2588453731729854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": 0.05118944924673077,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.503310677983855,
        "bleu": 81.53551,
        "rouge1": {
            "precision": 0.96078,
            "recall": 1.0,
            "fmeasure": 0.97917
        },
        "rouge2": {
            "precision": 0.9375,
            "recall": 0.97619,
            "fmeasure": 0.95556
        },
        "rougeL": {
            "precision": 0.96078,
            "recall": 1.0,
            "fmeasure": 0.97917
        },
        "rougeLsum": {
            "precision": 0.96078,
            "recall": 1.0,
            "fmeasure": 0.97917
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.99266,
            "recall": 0.99927,
            "f1": 0.99595
        },
        "bleurt": 0.83419,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.16036,
            "irrelevancy": 2.58913,
            "logical_agreement": 97.25051,
            "grammar_ref": 3.50326,
            "grammar_hyp": 3.06363,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1043": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 1.0,
        "vocab_size-1": 26,
        "unique-1": 26,
        "entropy-1": 4.70043971814109,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": -0.05658352836636749,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.459431618637295,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": -0.06711419585853673,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.420391214988346,
        "bleu": 25.13074,
        "rouge1": {
            "precision": 0.42424,
            "recall": 0.68687,
            "fmeasure": 0.52198
        },
        "rouge2": {
            "precision": 0.26984,
            "recall": 0.45238,
            "fmeasure": 0.3361
        },
        "rougeL": {
            "precision": 0.42424,
            "recall": 0.68687,
            "fmeasure": 0.52198
        },
        "rougeLsum": {
            "precision": 0.42424,
            "recall": 0.68687,
            "fmeasure": 0.52198
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.83872,
            "recall": 0.92087,
            "f1": 0.87788
        },
        "bleurt": -0.17838,
        "meteor": 0.35104917883272224,
        "nubia": {
            "semantic_relation": 3.76634,
            "contradiction": 72.40375,
            "irrelevancy": 25.39814,
            "logical_agreement": 2.19811,
            "grammar_ref": 5.20931,
            "grammar_hyp": 5.06589,
            "nubia_score": 0.5062
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1304": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.555569092624466,
        "bleu": 59.2847,
        "rouge1": {
            "precision": 0.82353,
            "recall": 0.65657,
            "fmeasure": 0.73054
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.59048,
            "fmeasure": 0.66066
        },
        "rougeL": {
            "precision": 0.76471,
            "recall": 0.60967,
            "fmeasure": 0.67836
        },
        "rougeLsum": {
            "precision": 0.76471,
            "recall": 0.60967,
            "fmeasure": 0.67836
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.9
        },
        "bertscore": {
            "precision": 0.8824,
            "recall": 0.9579,
            "f1": 0.91061
        },
        "bleurt": 0.09516,
        "meteor": 0.3816110892838245,
        "nubia": {
            "semantic_relation": 3.86427,
            "contradiction": 9.62825,
            "irrelevancy": 82.14571,
            "logical_agreement": 8.22605,
            "grammar_ref": 3.44293,
            "grammar_hyp": 4.10856,
            "nubia_score": 0.5902
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_940": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.5555555555555556,
        "vocab_size-1": 15,
        "unique-1": 8,
        "entropy-1": 3.7080481500712326,
        "distinct-2": 0.8076923076923077,
        "vocab_size-2": 21,
        "unique-2": 17,
        "entropy-2": 4.286790198827111,
        "cond_entropy-2": 0.6190051007594287,
        "distinct-3": 0.92,
        "vocab_size-3": 23,
        "unique-3": 21,
        "entropy-3": 4.4838561897747224,
        "cond_entropy-3": 0.21361197172017118,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5416666666666666,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.490601562950723,
        "distinct-2-nopunct": 0.8260869565217391,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.142914673354254,
        "cond_entropy-2-nopunct": 0.6309826076665428,
        "distinct-3-nopunct": 0.9545454545454546,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.368522527728205,
        "cond_entropy-3-nopunct": 0.17086625355493504,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.583497003048632,
        "bleu": 6.98036,
        "rouge1": {
            "precision": 0.29167,
            "recall": 0.41447,
            "fmeasure": 0.34186
        },
        "rouge2": {
            "precision": 0.07246,
            "recall": 0.10972,
            "fmeasure": 0.08727
        },
        "rougeL": {
            "precision": 0.23611,
            "recall": 0.34804,
            "fmeasure": 0.2813
        },
        "rougeLsum": {
            "precision": 0.23611,
            "recall": 0.34804,
            "fmeasure": 0.2813
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.14285714285714285,
            "3": 0.4444444444444444
        },
        "bertscore": {
            "precision": 0.84603,
            "recall": 0.82719,
            "f1": 0.83651
        },
        "bleurt": -0.19198,
        "meteor": 0.18338594839569475,
        "nubia": {
            "semantic_relation": 2.34216,
            "contradiction": 2.3539,
            "irrelevancy": 94.84109,
            "logical_agreement": 2.805,
            "grammar_ref": 3.5564,
            "grammar_hyp": 2.62123,
            "nubia_score": 0.40484
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1164": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 0.5,
        "median_pred_length": 15.5,
        "min_pred_length": 15,
        "max_pred_length": 16,
        "distinct-1": 0.7419354838709677,
        "vocab_size-1": 23,
        "unique-1": 18,
        "entropy-1": 4.349199939349345,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 28,
        "unique-2": 27,
        "entropy-2": 4.789015477886192,
        "cond_entropy-2": 0.41257390895323043,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.029019418890029347,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.208966082694624,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.623516641218013,
        "cond_entropy-2-nopunct": 0.4605804692436212,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.032143884086602556,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.643615316856224,
        "bleu": 11.81093,
        "rouge1": {
            "precision": 0.5254,
            "recall": 0.62424,
            "fmeasure": 0.55706
        },
        "rouge2": {
            "precision": 0.25549,
            "recall": 0.29148,
            "fmeasure": 0.2652
        },
        "rougeL": {
            "precision": 0.44286,
            "recall": 0.50227,
            "fmeasure": 0.46026
        },
        "rougeLsum": {
            "precision": 0.44286,
            "recall": 0.50227,
            "fmeasure": 0.46026
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.1111111111111111,
            "3": 0.5882352941176471
        },
        "bertscore": {
            "precision": 0.87831,
            "recall": 0.90796,
            "f1": 0.89195
        },
        "bleurt": 0.08629,
        "meteor": 0.28983030232173396,
        "nubia": {
            "semantic_relation": 3.55095,
            "contradiction": 45.16156,
            "irrelevancy": 54.10146,
            "logical_agreement": 0.73698,
            "grammar_ref": 4.30067,
            "grammar_hyp": 4.29184,
            "nubia_score": 0.52524
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1050": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.7990385038524417,
        "bleu": 20.16495,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.56667,
            "fmeasure": 0.45455
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.94225,
            "recall": 0.97743,
            "f1": 0.95951
        },
        "bleurt": 0.49066,
        "meteor": 0.861811391223156,
        "nubia": {
            "semantic_relation": 4.21377,
            "contradiction": 0.17851,
            "irrelevancy": 33.78877,
            "logical_agreement": 66.03272,
            "grammar_ref": 5.27628,
            "grammar_hyp": 4.69427,
            "nubia_score": 0.81239
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1165": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.8094988549899862,
        "bleu": 24.59813,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.26984,
            "fmeasure": 0.32727
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.97738,
            "recall": 0.94093,
            "f1": 0.95881
        },
        "bleurt": 0.30353,
        "meteor": 0.3010544205973617,
        "nubia": {
            "semantic_relation": 4.18837,
            "contradiction": 0.38664,
            "irrelevancy": 0.58445,
            "logical_agreement": 99.02891,
            "grammar_ref": 4.24352,
            "grammar_hyp": 4.86986,
            "nubia_score": 0.75842
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1055": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.2775418301849517,
        "bleu": 11.33958,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.57143,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.33333,
            "fmeasure": 0.28571
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.57143,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.57143,
            "fmeasure": 0.5
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.8573,
            "recall": 0.88842,
            "f1": 0.87258
        },
        "bleurt": -0.04695,
        "meteor": 0.31127891035349853,
        "nubia": {
            "semantic_relation": 3.94411,
            "contradiction": 0.52809,
            "irrelevancy": 90.87595,
            "logical_agreement": 8.59595,
            "grammar_ref": 5.4078,
            "grammar_hyp": 5.74554,
            "nubia_score": 0.60532
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_945": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 3.5,
        "median_pred_length": 13.5,
        "min_pred_length": 10,
        "max_pred_length": 17,
        "distinct-1": 0.8518518518518519,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.43063240949075,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.15916418769779475,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.303508854797679,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.18150945892357132,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4738027764343204,
        "bleu": 54.8773,
        "rouge1": {
            "precision": 0.82222,
            "recall": 0.84551,
            "fmeasure": 0.82773
        },
        "rouge2": {
            "precision": 0.60714,
            "recall": 0.62149,
            "fmeasure": 0.60882
        },
        "rougeL": {
            "precision": 0.63333,
            "recall": 0.65747,
            "fmeasure": 0.64092
        },
        "rougeLsum": {
            "precision": 0.63333,
            "recall": 0.65747,
            "fmeasure": 0.64092
        },
        "local_recall": {
            "1": 0.125,
            "2": 0.125,
            "3": 0.9473684210526315
        },
        "bertscore": {
            "precision": 0.95022,
            "recall": 0.95107,
            "f1": 0.95065
        },
        "bleurt": 0.35308,
        "meteor": 0.467374245638681,
        "nubia": {
            "semantic_relation": 3.83113,
            "contradiction": 0.78716,
            "irrelevancy": 1.0609,
            "logical_agreement": 98.15194,
            "grammar_ref": 4.25678,
            "grammar_hyp": 4.02886,
            "nubia_score": 0.66449
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_952": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.3958920781800714,
        "bleu": 8.60612,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.38462,
            "fmeasure": 0.43478
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.2037,
            "fmeasure": 0.21164
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.38462,
            "fmeasure": 0.43478
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.38462,
            "fmeasure": 0.43478
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.42857142857142855
        },
        "bertscore": {
            "precision": 0.89235,
            "recall": 0.85571,
            "f1": 0.87365
        },
        "bleurt": -0.19069,
        "meteor": 0.23484797711253358,
        "nubia": {
            "semantic_relation": 3.48593,
            "contradiction": 5.45948,
            "irrelevancy": 89.32513,
            "logical_agreement": 5.2154,
            "grammar_ref": 5.35395,
            "grammar_hyp": 4.57908,
            "nubia_score": 0.48361
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1168": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.7727272727272727,
        "vocab_size-1": 17,
        "unique-1": 12,
        "entropy-1": 4.004886164091841,
        "distinct-2": 0.8095238095238095,
        "vocab_size-2": 17,
        "unique-2": 13,
        "entropy-2": 4.011365041826378,
        "cond_entropy-2": 0.02812389937955851,
        "distinct-3": 0.85,
        "vocab_size-3": 17,
        "unique-3": 14,
        "entropy-3": 4.021928094887363,
        "cond_entropy-3": 0.029610672108602014,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.625,
        "distinct-2-nopunct": 0.8666666666666667,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.640223928941851,
        "cond_entropy-2-nopunct": -0.026442737724814775,
        "distinct-3-nopunct": 0.9285714285714286,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.6644977792004623,
        "cond_entropy-3-nopunct": -0.02810710212234295,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.4547983819871213,
        "bleu": 6.63807,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.44444,
            "fmeasure": 0.55814
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.19231,
            "fmeasure": 0.2439
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.33333,
            "fmeasure": 0.4186
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.33333,
            "fmeasure": 0.4186
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.4444444444444444
        },
        "bertscore": {
            "precision": 0.89169,
            "recall": 0.84969,
            "f1": 0.87018
        },
        "bleurt": -0.45081,
        "meteor": 0.20684694572431764,
        "nubia": {
            "semantic_relation": 2.77615,
            "contradiction": 48.14251,
            "irrelevancy": 9.55262,
            "logical_agreement": 42.30487,
            "grammar_ref": 4.95946,
            "grammar_hyp": 5.2891,
            "nubia_score": 0.27725
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_960": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 46,
        "mean_pred_length": 11.5,
        "std_pred_length": 1.6583123951777,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 13,
        "distinct-1": 0.717391304347826,
        "vocab_size-1": 33,
        "unique-1": 23,
        "entropy-1": 4.89845570600998,
        "distinct-2": 0.8809523809523809,
        "vocab_size-2": 37,
        "unique-2": 32,
        "entropy-2": 5.1542221846835234,
        "cond_entropy-2": 0.12482421677325871,
        "distinct-3": 0.8947368421052632,
        "vocab_size-3": 34,
        "unique-3": 30,
        "entropy-3": 5.0374011976541135,
        "cond_entropy-3": -0.09175833038780645,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.5811388300841898,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.775,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.853055907333276,
        "distinct-2-nopunct": 0.8888888888888888,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.947702779220088,
        "cond_entropy-2-nopunct": 0.11896600383726882,
        "distinct-3-nopunct": 0.90625,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.8125,
        "cond_entropy-3-nopunct": -0.10742500144231229,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.57211796904415,
        "bleu": 63.56452,
        "rouge1": {
            "precision": 0.7952,
            "recall": 0.7845,
            "fmeasure": 0.77106
        },
        "rouge2": {
            "precision": 0.71193,
            "recall": 0.69583,
            "fmeasure": 0.67541
        },
        "rougeL": {
            "precision": 0.7952,
            "recall": 0.75544,
            "fmeasure": 0.74836
        },
        "rougeLsum": {
            "precision": 0.7952,
            "recall": 0.75544,
            "fmeasure": 0.74836
        },
        "local_recall": {
            "1": 0.3,
            "2": 0.16666666666666666,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.95415,
            "recall": 0.9584,
            "f1": 0.95457
        },
        "bleurt": 0.38295,
        "meteor": 0.4529854349092034,
        "nubia": {
            "semantic_relation": 4.52971,
            "contradiction": 4.47367,
            "irrelevancy": 51.35797,
            "logical_agreement": 44.16836,
            "grammar_ref": 4.5734,
            "grammar_hyp": 4.74583,
            "nubia_score": 0.76748
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_748": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 6.5,
        "median_pred_length": 17.5,
        "min_pred_length": 11,
        "max_pred_length": 24,
        "distinct-1": 0.6285714285714286,
        "vocab_size-1": 22,
        "unique-1": 10,
        "entropy-1": 4.364857659740294,
        "distinct-2": 0.7575757575757576,
        "vocab_size-2": 25,
        "unique-2": 17,
        "entropy-2": 4.55954563450997,
        "cond_entropy-2": 0.18041072369116762,
        "distinct-3": 0.8064516129032258,
        "vocab_size-3": 25,
        "unique-3": 19,
        "entropy-3": 4.567099536193328,
        "cond_entropy-3": 0.038834449092937956,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 4.240223928941852,
        "distinct-2-nopunct": 0.7142857142857143,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 4.235926350629034,
        "cond_entropy-2-nopunct": -0.028107102122342926,
        "distinct-3-nopunct": 0.7692307692307693,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 4.23890125660263,
        "cond_entropy-3-nopunct": -0.029992126993435266,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7667231342129157,
        "bleu": 45.04995,
        "rouge1": {
            "precision": 0.75833,
            "recall": 0.75532,
            "fmeasure": 0.75551
        },
        "rouge2": {
            "precision": 0.53216,
            "recall": 0.62458,
            "fmeasure": 0.56226
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.62228,
            "fmeasure": 0.6047
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.62228,
            "fmeasure": 0.6047
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6363636363636364,
            "3": 0.9444444444444444
        },
        "bertscore": {
            "precision": 0.95983,
            "recall": 0.95402,
            "f1": 0.95571
        },
        "bleurt": 0.41635,
        "meteor": 0.4507044634878868,
        "nubia": {
            "semantic_relation": 4.61739,
            "contradiction": 15.35207,
            "irrelevancy": 13.94888,
            "logical_agreement": 70.69905,
            "grammar_ref": 3.87403,
            "grammar_hyp": 3.71888,
            "nubia_score": 0.89464
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1056": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 12,
        "unique-1": 10,
        "entropy-1": 3.521640636343319,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 12,
        "unique-2": 11,
        "entropy-2": 3.5465935642949384,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": 0.05118944924673077,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.418295834054489,
        "cond_entropy-2-nopunct": 0.05118944924673078,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": 0.056287299734322706,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9893549141691644,
        "bleu": 21.97281,
        "rouge1": {
            "precision": 0.46154,
            "recall": 0.53595,
            "fmeasure": 0.48485
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.40625,
            "fmeasure": 0.35714
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.53595,
            "fmeasure": 0.48485
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.53595,
            "fmeasure": 0.48485
        },
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.5714285714285714
        },
        "bertscore": {
            "precision": 0.86926,
            "recall": 0.90425,
            "f1": 0.88641
        },
        "bleurt": 0.12935,
        "meteor": 0.43134542746287874,
        "nubia": {
            "semantic_relation": 4.18552,
            "contradiction": 0.41189,
            "irrelevancy": 87.81293,
            "logical_agreement": 11.77518,
            "grammar_ref": 5.6106,
            "grammar_hyp": 4.37783,
            "nubia_score": 0.74712
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1170": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.0909514646162273,
        "bleu": 31.85036,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.47009,
            "fmeasure": 0.59649
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.3125,
            "fmeasure": 0.40724
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.47009,
            "fmeasure": 0.59649
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.47009,
            "fmeasure": 0.59649
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.625
        },
        "bertscore": {
            "precision": 0.94653,
            "recall": 0.89087,
            "f1": 0.91786
        },
        "bleurt": 0.09535,
        "meteor": 0.3769465296142278,
        "nubia": {
            "semantic_relation": 3.4502,
            "contradiction": 1.65058,
            "irrelevancy": 0.74865,
            "logical_agreement": 97.60076,
            "grammar_ref": 4.45494,
            "grammar_hyp": 5.46862,
            "nubia_score": 0.42783
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1072": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 1.5,
        "median_pred_length": 14.5,
        "min_pred_length": 13,
        "max_pred_length": 16,
        "distinct-1": 0.8620689655172413,
        "vocab_size-1": 25,
        "unique-1": 22,
        "entropy-1": 4.556088322639176,
        "distinct-2": 0.9629629629629629,
        "vocab_size-2": 26,
        "unique-2": 25,
        "entropy-2": 4.6808134280893965,
        "cond_entropy-2": 0.07301345156046948,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.031031312388743976,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8846153846153846,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.440636352673265,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.501629167387823,
        "cond_entropy-2-nopunct": 0.08264309517020865,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.034621791174768185,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.193950317458596,
        "bleu": 25.14553,
        "rouge1": {
            "precision": 0.69413,
            "recall": 0.67033,
            "fmeasure": 0.67548
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.35192,
            "fmeasure": 0.37142
        },
        "rougeL": {
            "precision": 0.52652,
            "recall": 0.51923,
            "fmeasure": 0.51766
        },
        "rougeLsum": {
            "precision": 0.52652,
            "recall": 0.51923,
            "fmeasure": 0.51766
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.7142857142857143
        },
        "bertscore": {
            "precision": 0.90797,
            "recall": 0.90897,
            "f1": 0.90835
        },
        "bleurt": 0.01232,
        "meteor": 0.34762661546992446,
        "nubia": {
            "semantic_relation": 3.92611,
            "contradiction": 50.0683,
            "irrelevancy": 0.804,
            "logical_agreement": 49.1277,
            "grammar_ref": 4.47266,
            "grammar_hyp": 4.00484,
            "nubia_score": 0.71378
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1172": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717246,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.2498374470198415,
        "bleu": 26.30501,
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.72222,
            "fmeasure": 0.61988
        },
        "rouge2": {
            "precision": 0.20833,
            "recall": 0.21481,
            "fmeasure": 0.20814
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.57778,
            "fmeasure": 0.49591
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.57778,
            "fmeasure": 0.49591
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.87592,
            "recall": 0.90797,
            "f1": 0.89166
        },
        "bleurt": -0.4803,
        "meteor": 0.4172537347238426,
        "nubia": {
            "semantic_relation": 3.98778,
            "contradiction": 26.38742,
            "irrelevancy": 19.66923,
            "logical_agreement": 53.94335,
            "grammar_ref": 7.45181,
            "grammar_hyp": 6.64792,
            "nubia_score": 0.63175
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_966": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.796413345906897,
        "bleu": 53.98996,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.85714,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.76923,
            "fmeasure": 0.71429
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.85714,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.85714,
            "fmeasure": 0.8
        },
        "local_recall": {
            "1": 0,
            "2": 0.6,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.92293,
            "recall": 0.9919,
            "f1": 0.9408
        },
        "bleurt": 0.35457,
        "meteor": 0.5095454278464926,
        "nubia": {
            "semantic_relation": 4.54133,
            "contradiction": 0.54632,
            "irrelevancy": 49.00848,
            "logical_agreement": 50.4452,
            "grammar_ref": 6.35753,
            "grammar_hyp": 6.05692,
            "nubia_score": 0.77842
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_749": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.037537158749660585,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185189,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.5848040654130635,
        "bleu": 37.42032,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.76923,
            "fmeasure": 0.68966
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.58333,
            "fmeasure": 0.51852
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.76923,
            "fmeasure": 0.68966
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.76923,
            "fmeasure": 0.68966
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.9266,
            "recall": 0.9505,
            "f1": 0.9384
        },
        "bleurt": 0.62156,
        "meteor": 0.4854043997759893,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.06983,
            "irrelevancy": 2.29714,
            "logical_agreement": 97.63303,
            "grammar_ref": 4.23153,
            "grammar_hyp": 3.7095,
            "nubia_score": 0.99841
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1080": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 1.0,
        "vocab_size-1": 21,
        "unique-1": 21,
        "entropy-1": 4.39231742277876,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.07038932789139804,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.247927513443583,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.07800251200127316,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8871990755783954,
        "bleu": 12.68538,
        "rouge1": {
            "precision": 0.80702,
            "recall": 0.72222,
            "fmeasure": 0.76088
        },
        "rouge2": {
            "precision": 0.27778,
            "recall": 0.2479,
            "fmeasure": 0.26148
        },
        "rougeL": {
            "precision": 0.45614,
            "recall": 0.50833,
            "fmeasure": 0.47961
        },
        "rougeLsum": {
            "precision": 0.45614,
            "recall": 0.50833,
            "fmeasure": 0.47961
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.75,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.87969,
            "recall": 0.88462,
            "f1": 0.87526
        },
        "bleurt": -0.09213,
        "meteor": 0.36204822920126223,
        "nubia": {
            "semantic_relation": 4.04919,
            "contradiction": 74.5414,
            "irrelevancy": 22.92077,
            "logical_agreement": 2.53782,
            "grammar_ref": 4.75667,
            "grammar_hyp": 4.3752,
            "nubia_score": 0.65987
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_968": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9237891711216144,
        "bleu": 30.92852,
        "rouge1": {
            "precision": 0.82222,
            "recall": 0.65899,
            "fmeasure": 0.72807
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.39773,
            "fmeasure": 0.44074
        },
        "rougeL": {
            "precision": 0.75556,
            "recall": 0.60529,
            "fmeasure": 0.66886
        },
        "rougeLsum": {
            "precision": 0.75556,
            "recall": 0.60529,
            "fmeasure": 0.66886
        },
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.94455,
            "recall": 0.94914,
            "f1": 0.94684
        },
        "bleurt": 0.51106,
        "meteor": 0.4363997992440335,
        "nubia": {
            "semantic_relation": 4.45779,
            "contradiction": 0.45814,
            "irrelevancy": 33.13018,
            "logical_agreement": 66.41168,
            "grammar_ref": 4.20692,
            "grammar_hyp": 5.05688,
            "nubia_score": 0.70529
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_972": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.14421971022094898,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.15283195745508585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7117070857269048,
        "bleu": 37.62957,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.74854,
            "fmeasure": 0.74046
        },
        "rouge2": {
            "precision": 0.45614,
            "recall": 0.51111,
            "fmeasure": 0.48119
        },
        "rougeL": {
            "precision": 0.63333,
            "recall": 0.70614,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.63333,
            "recall": 0.70614,
            "fmeasure": 0.66667
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7142857142857143
        },
        "bertscore": {
            "precision": 0.93229,
            "recall": 0.93598,
            "f1": 0.93413
        },
        "bleurt": 0.40374,
        "meteor": 0.41776939552496006,
        "nubia": {
            "semantic_relation": 4.13292,
            "contradiction": 0.14683,
            "irrelevancy": 33.55304,
            "logical_agreement": 66.30013,
            "grammar_ref": 4.42639,
            "grammar_hyp": 3.73509,
            "nubia_score": 0.83928
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1098": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.7735572622751845,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.04332146930622849,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.4552484410019946,
        "bleu": 7.47488,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.60185,
            "fmeasure": 0.54581
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.1369,
            "fmeasure": 0.12255
        },
        "rougeL": {
            "precision": 0.26667,
            "recall": 0.28333,
            "fmeasure": 0.27407
        },
        "rougeLsum": {
            "precision": 0.26667,
            "recall": 0.28333,
            "fmeasure": 0.27407
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "bertscore": {
            "precision": 0.8362,
            "recall": 0.88873,
            "f1": 0.86166
        },
        "bleurt": -0.29212,
        "meteor": 0.262014743347204,
        "nubia": {
            "semantic_relation": 2.34201,
            "contradiction": 22.85493,
            "irrelevancy": 75.95599,
            "logical_agreement": 1.18908,
            "grammar_ref": 5.1757,
            "grammar_hyp": 3.79547,
            "nubia_score": 0.22943
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_752": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.029610672108601997,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.033108599109837954,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0961769012815985,
        "bleu": 60.54783,
        "rouge1": {
            "precision": 0.52632,
            "recall": 0.79514,
            "fmeasure": 0.62143
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.67917,
            "fmeasure": 0.52564
        },
        "rougeL": {
            "precision": 0.52632,
            "recall": 0.79514,
            "fmeasure": 0.62143
        },
        "rougeLsum": {
            "precision": 0.52632,
            "recall": 0.79514,
            "fmeasure": 0.62143
        },
        "local_recall": {
            "1": 0.5454545454545454,
            "2": 1.0
        },
        "bertscore": {
            "precision": 0.90717,
            "recall": 0.95643,
            "f1": 0.93115
        },
        "bleurt": -0.33838,
        "meteor": 0.5158668426787606,
        "nubia": {
            "semantic_relation": 2.9498,
            "contradiction": 0.88065,
            "irrelevancy": 98.13057,
            "logical_agreement": 0.98878,
            "grammar_ref": 4.24724,
            "grammar_hyp": 3.80836,
            "nubia_score": 0.37984
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1310": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673076,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8646054890616752,
        "bleu": 42.50281,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rouge2": {
            "precision": 0.69697,
            "recall": 0.79259,
            "fmeasure": 0.74127
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "bertscore": {
            "precision": 0.96145,
            "recall": 0.96696,
            "f1": 0.9642
        },
        "bleurt": 0.68139,
        "meteor": 0.48351570164972274,
        "nubia": {
            "semantic_relation": 4.6542,
            "contradiction": 0.23542,
            "irrelevancy": 4.26769,
            "logical_agreement": 95.49688,
            "grammar_ref": 4.67316,
            "grammar_hyp": 4.03878,
            "nubia_score": 0.87015
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1100": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 52,
        "mean_pred_length": 26.0,
        "std_pred_length": 6.0,
        "median_pred_length": 26.0,
        "min_pred_length": 20,
        "max_pred_length": 32,
        "distinct-1": 0.6153846153846154,
        "vocab_size-1": 32,
        "unique-1": 20,
        "entropy-1": 4.789207449193897,
        "distinct-2": 0.86,
        "vocab_size-2": 43,
        "unique-2": 37,
        "entropy-2": 5.348758439731457,
        "cond_entropy-2": 0.5560002812954463,
        "distinct-3": 0.9583333333333334,
        "vocab_size-3": 46,
        "unique-3": 44,
        "entropy-3": 5.5016291673878275,
        "cond_entropy-3": 0.12349980057483731,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.585786399423351,
        "distinct-2-nopunct": 0.9,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.103055907333276,
        "cond_entropy-2-nopunct": 0.5325960590776957,
        "distinct-3-nopunct": 0.9736842105263158,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.19529593449622,
        "cond_entropy-3-nopunct": 0.10375961598157762,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5420911315230876,
        "bleu": 23.804,
        "rouge1": {
            "precision": 0.51736,
            "recall": 0.60519,
            "fmeasure": 0.54793
        },
        "rouge2": {
            "precision": 0.2359,
            "recall": 0.32209,
            "fmeasure": 0.26518
        },
        "rougeL": {
            "precision": 0.39776,
            "recall": 0.56141,
            "fmeasure": 0.46103
        },
        "rougeLsum": {
            "precision": 0.39776,
            "recall": 0.56141,
            "fmeasure": 0.46103
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.8,
            "3": 0.6086956521739131
        },
        "bertscore": {
            "precision": 0.87884,
            "recall": 0.92368,
            "f1": 0.89762
        },
        "bleurt": 0.31498,
        "meteor": 0.3545202590236422,
        "nubia": {
            "semantic_relation": 4.45575,
            "contradiction": 41.65459,
            "irrelevancy": 56.64815,
            "logical_agreement": 1.69726,
            "grammar_ref": 4.39403,
            "grammar_hyp": 3.52272,
            "nubia_score": 0.84659
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1315": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.0949385676221532,
        "bleu": 16.51582,
        "rouge1": {
            "precision": 0.52381,
            "recall": 0.56944,
            "fmeasure": 0.54359
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.13333,
            "fmeasure": 0.12121
        },
        "rougeL": {
            "precision": 0.47619,
            "recall": 0.52778,
            "fmeasure": 0.49915
        },
        "rougeLsum": {
            "precision": 0.47619,
            "recall": 0.52778,
            "fmeasure": 0.49915
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.83661,
            "recall": 0.87925,
            "f1": 0.8574
        },
        "bleurt": -0.04532,
        "meteor": 0.3262776065014196,
        "nubia": {
            "semantic_relation": 4.03033,
            "contradiction": 6.85329,
            "irrelevancy": 56.30165,
            "logical_agreement": 36.84506,
            "grammar_ref": 5.75818,
            "grammar_hyp": 5.99399,
            "nubia_score": 0.57323
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_755": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 1.0,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.6363636363636364,
        "vocab_size-1": 14,
        "unique-1": 6,
        "entropy-1": 3.73215889136457,
        "distinct-2": 0.75,
        "vocab_size-2": 15,
        "unique-2": 10,
        "entropy-2": 3.821928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 0.7777777777777778,
        "vocab_size-3": 14,
        "unique-3": 10,
        "entropy-3": 3.7254805569978675,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.65,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.621928094887362,
        "distinct-2-nopunct": 0.7777777777777778,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.7254805569978675,
        "cond_entropy-2-nopunct": 0.07021912877717248,
        "distinct-3-nopunct": 0.8125,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.625,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.490498678107601,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.92254,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.91381,
            "contradiction": 0.28512,
            "irrelevancy": 0.56352,
            "logical_agreement": 99.15137,
            "grammar_ref": 5.78027,
            "grammar_hyp": 5.87845,
            "nubia_score": 0.96986
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1113": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 47.0,
        "std_pred_length": 0.0,
        "median_pred_length": 47.0,
        "min_pred_length": 47,
        "max_pred_length": 47,
        "distinct-1": 0.7446808510638298,
        "vocab_size-1": 35,
        "unique-1": 30,
        "entropy-1": 4.777369170550387,
        "distinct-2": 0.9782608695652174,
        "vocab_size-2": 45,
        "unique-2": 44,
        "entropy-2": 5.480083695187445,
        "cond_entropy-2": 0.719610604661567,
        "distinct-3": 1.0,
        "vocab_size-3": 45,
        "unique-3": 45,
        "entropy-3": 5.491853096329673,
        "cond_entropy-3": 0.012735584717106084,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 37.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 37.0,
        "min_pred_length-nopunct": 37,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.8918918918918919,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.993237149412737,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.1699250014423095,
        "cond_entropy-2-nopunct": 0.18269385803558488,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.04064198449734609,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.148656372275869,
        "bleu": 58.14481,
        "rouge1": {
            "precision": 0.77477,
            "recall": 0.88693,
            "fmeasure": 0.82689
        },
        "rouge2": {
            "precision": 0.69444,
            "recall": 0.79805,
            "fmeasure": 0.74261
        },
        "rougeL": {
            "precision": 0.77477,
            "recall": 0.87753,
            "fmeasure": 0.82291
        },
        "rougeLsum": {
            "precision": 0.77477,
            "recall": 0.87753,
            "fmeasure": 0.82291
        },
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.8888888888888888
        },
        "bertscore": {
            "precision": 0.89611,
            "recall": 0.95869,
            "f1": 0.92635
        },
        "bleurt": 0.22454,
        "meteor": 0.48799064327746144,
        "nubia": {
            "semantic_relation": 3.70375,
            "contradiction": 0.23706,
            "irrelevancy": 50.96115,
            "logical_agreement": 48.80179,
            "grammar_ref": 3.7645,
            "grammar_hyp": 3.29842,
            "nubia_score": 0.65178
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_976": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.7727272727272727,
        "vocab_size-1": 17,
        "unique-1": 13,
        "entropy-1": 3.9705730958116834,
        "distinct-2": 0.9523809523809523,
        "vocab_size-2": 20,
        "unique-2": 19,
        "entropy-2": 4.297079327540665,
        "cond_entropy-2": 0.3497852090063903,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": 0.02961067210860201,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.7841837197791883,
        "distinct-2-nopunct": 0.9473684210526315,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.142664355548847,
        "cond_entropy-2-nopunct": 0.33415139235430047,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.022446956445717602,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.786416212243771,
        "bleu": 62.83081,
        "rouge1": {
            "precision": 0.85,
            "recall": 0.92788,
            "fmeasure": 0.88709
        },
        "rouge2": {
            "precision": 0.73684,
            "recall": 0.80828,
            "fmeasure": 0.77077
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.87329,
            "fmeasure": 0.83491
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.87329,
            "fmeasure": 0.83491
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9333333333333333
        },
        "bertscore": {
            "precision": 0.98334,
            "recall": 0.98739,
            "f1": 0.98536
        },
        "bleurt": 0.77508,
        "meteor": 0.5505794412321797,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20095,
            "irrelevancy": 0.57007,
            "logical_agreement": 99.22898,
            "grammar_ref": 3.47563,
            "grammar_hyp": 3.36526,
            "nubia_score": 0.99779
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_756": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 1.0,
        "vocab_size-1": 20,
        "unique-1": 20,
        "entropy-1": 4.321928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.07400058144377676,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.247927513443583,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.07800251200127316,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.996322418108996,
        "bleu": 45.72702,
        "rouge1": {
            "precision": 0.61364,
            "recall": 0.71449,
            "fmeasure": 0.65285
        },
        "rouge2": {
            "precision": 0.40476,
            "recall": 0.46429,
            "fmeasure": 0.42724
        },
        "rougeL": {
            "precision": 0.52273,
            "recall": 0.59275,
            "fmeasure": 0.54955
        },
        "rougeLsum": {
            "precision": 0.52273,
            "recall": 0.59275,
            "fmeasure": 0.54955
        },
        "local_recall": {
            "1": 0.8333333333333334,
            "2": 0.75
        },
        "bertscore": {
            "precision": 0.91995,
            "recall": 0.93437,
            "f1": 0.92711
        },
        "bleurt": -0.27489,
        "meteor": 0.383832659492833,
        "nubia": {
            "semantic_relation": 3.64411,
            "contradiction": 4.52564,
            "irrelevancy": 87.77299,
            "logical_agreement": 7.70138,
            "grammar_ref": 5.51157,
            "grammar_hyp": 5.37344,
            "nubia_score": 0.53427
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1174": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 3.0,
        "median_pred_length": 10.0,
        "min_pred_length": 7,
        "max_pred_length": 13,
        "distinct-1": 0.75,
        "vocab_size-1": 15,
        "unique-1": 10,
        "entropy-1": 3.821928094887362,
        "distinct-2": 0.8333333333333334,
        "vocab_size-2": 15,
        "unique-2": 12,
        "entropy-2": 3.8365916681089787,
        "cond_entropy-2": -0.04089198233393866,
        "distinct-3": 0.875,
        "vocab_size-3": 14,
        "unique-3": 12,
        "entropy-3": 3.75,
        "cond_entropy-3": -0.04492500144231237,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.7254805569978675,
        "distinct-2-nopunct": 0.8125,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.625,
        "cond_entropy-2-nopunct": -0.10742500144231237,
        "distinct-3-nopunct": 0.8571428571428571,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.521640636343319,
        "cond_entropy-3-nopunct": -0.12121650651382439,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.375251578024412,
        "bleu": 63.76078,
        "rouge1": {
            "precision": 0.80769,
            "recall": 0.80952,
            "fmeasure": 0.80718
        },
        "rouge2": {
            "precision": 0.71667,
            "recall": 0.71717,
            "fmeasure": 0.71542
        },
        "rougeL": {
            "precision": 0.80769,
            "recall": 0.80952,
            "fmeasure": 0.80718
        },
        "rougeLsum": {
            "precision": 0.80769,
            "recall": 0.80952,
            "fmeasure": 0.80718
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.9634,
            "recall": 0.97314,
            "f1": 0.96822
        },
        "bleurt": 0.74065,
        "meteor": 0.4938847974697208,
        "nubia": {
            "semantic_relation": 4.69158,
            "contradiction": 0.51383,
            "irrelevancy": 16.46751,
            "logical_agreement": 83.01866,
            "grammar_ref": 4.94813,
            "grammar_hyp": 5.05901,
            "nubia_score": 0.87075
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1122": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.046930949929641676,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.2019502482195246,
        "bleu": 15.8445,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.47348,
            "fmeasure": 0.47548
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.13853,
            "fmeasure": 0.13714
        },
        "rougeL": {
            "precision": 0.36667,
            "recall": 0.36364,
            "fmeasure": 0.35736
        },
        "rougeLsum": {
            "precision": 0.36667,
            "recall": 0.36364,
            "fmeasure": 0.35736
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.625
        },
        "bertscore": {
            "precision": 0.86483,
            "recall": 0.89866,
            "f1": 0.88142
        },
        "bleurt": 0.01351,
        "meteor": 0.3175864870577234,
        "nubia": {
            "semantic_relation": 3.36751,
            "contradiction": 2.24677,
            "irrelevancy": 84.14986,
            "logical_agreement": 13.60337,
            "grammar_ref": 4.87259,
            "grammar_hyp": 4.76054,
            "nubia_score": 0.42562
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_760": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 66,
        "mean_pred_length": 16.5,
        "std_pred_length": 6.800735254367722,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.7121212121212122,
        "vocab_size-1": 47,
        "unique-1": 40,
        "entropy-1": 5.233639952626233,
        "distinct-2": 0.9838709677419355,
        "vocab_size-2": 61,
        "unique-2": 60,
        "entropy-2": 5.921938245870744,
        "cond_entropy-2": 0.6115727556143401,
        "distinct-3": 1.0,
        "vocab_size-3": 58,
        "unique-3": 58,
        "entropy-3": 5.85798099512757,
        "cond_entropy-3": -0.061732556638613253,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 4.031128874149275,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 45,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.356558335416674,
        "distinct-2-nopunct": 0.98,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.603856189774728,
        "cond_entropy-2-nopunct": 0.2591641876977948,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.5235619560570095,
        "cond_entropy-3-nopunct": -0.07681597284814654,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.487151988189659,
        "bleu": 31.76605,
        "rouge1": {
            "precision": 0.67778,
            "recall": 0.77775,
            "fmeasure": 0.70426
        },
        "rouge2": {
            "precision": 0.28564,
            "recall": 0.3501,
            "fmeasure": 0.30666
        },
        "rougeL": {
            "precision": 0.5131,
            "recall": 0.619,
            "fmeasure": 0.54476
        },
        "rougeLsum": {
            "precision": 0.5131,
            "recall": 0.619,
            "fmeasure": 0.54476
        },
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.7222222222222222,
            "3": 0.8695652173913043
        },
        "bertscore": {
            "precision": 0.90679,
            "recall": 0.93064,
            "f1": 0.91464
        },
        "bleurt": 0.26077,
        "meteor": 0.3736056536870798,
        "nubia": {
            "semantic_relation": 4.04578,
            "contradiction": 1.36081,
            "irrelevancy": 29.67486,
            "logical_agreement": 68.96433,
            "grammar_ref": 4.9362,
            "grammar_hyp": 3.81068,
            "nubia_score": 0.77225
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_980": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.13652573434569687,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.037537158749660585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.1915993001016405,
        "bleu": 38.63165,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.55633,
            "fmeasure": 0.64576
        },
        "rouge2": {
            "precision": 0.56863,
            "recall": 0.40303,
            "fmeasure": 0.46954
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.40097,
            "fmeasure": 0.46409
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.40097,
            "fmeasure": 0.46409
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.2222222222222222,
            "3": 0.6111111111111112
        },
        "bertscore": {
            "precision": 0.95838,
            "recall": 0.92102,
            "f1": 0.93933
        },
        "bleurt": -0.01472,
        "meteor": 0.35108450367945376,
        "nubia": {
            "semantic_relation": 3.77188,
            "contradiction": 0.22764,
            "irrelevancy": 30.6501,
            "logical_agreement": 69.12226,
            "grammar_ref": 3.59602,
            "grammar_hyp": 3.08568,
            "nubia_score": 0.72172
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1176": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 10.5,
        "std_pred_length": 0.5,
        "median_pred_length": 10.5,
        "min_pred_length": 10,
        "max_pred_length": 11,
        "distinct-1": 0.9047619047619048,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.201841232302569,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.0391267514404381,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.1604646721932461,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.04281761336971671,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.18057224564182078,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6066135650348863,
        "bleu": 59.40637,
        "rouge1": {
            "precision": 0.68704,
            "recall": 0.73333,
            "fmeasure": 0.70686
        },
        "rouge2": {
            "precision": 0.52546,
            "recall": 0.56296,
            "fmeasure": 0.53989
        },
        "rougeL": {
            "precision": 0.65,
            "recall": 0.73333,
            "fmeasure": 0.68333
        },
        "rougeLsum": {
            "precision": 0.65,
            "recall": 0.73333,
            "fmeasure": 0.68333
        },
        "local_recall": {
            "1": 0.2,
            "2": 0,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.92478,
            "recall": 0.92847,
            "f1": 0.92662
        },
        "bleurt": 0.18971,
        "meteor": 0.43115560515334744,
        "nubia": {
            "semantic_relation": 4.06955,
            "contradiction": 0.27083,
            "irrelevancy": 49.93805,
            "logical_agreement": 49.79112,
            "grammar_ref": 5.47595,
            "grammar_hyp": 5.31876,
            "nubia_score": 0.7286
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1320": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.8492125634412494,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.87179,
            "fmeasure": 0.92063
        },
        "rouge2": {
            "precision": 0.90476,
            "recall": 0.80556,
            "fmeasure": 0.84211
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.82051,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.82051,
            "fmeasure": 0.85714
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.33679,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.10842,
            "contradiction": 0.14426,
            "irrelevancy": 0.4271,
            "logical_agreement": 99.42863,
            "grammar_ref": 4.62626,
            "grammar_hyp": 5.09643,
            "nubia_score": 0.67307
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1330": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 5.0,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 18,
        "distinct-1": 0.7307692307692307,
        "vocab_size-1": 19,
        "unique-1": 12,
        "entropy-1": 4.1619781796795525,
        "distinct-2": 0.875,
        "vocab_size-2": 21,
        "unique-2": 18,
        "entropy-2": 4.334962500721156,
        "cond_entropy-2": 0.13452278258006417,
        "distinct-3": 0.9545454545454546,
        "vocab_size-3": 21,
        "unique-3": 20,
        "entropy-3": 4.368522527728205,
        "cond_entropy-3": 0.05628729973432273,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.084962500721157,
        "distinct-2-nopunct": 0.8636363636363636,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.186704345910023,
        "cond_entropy-2-nopunct": 0.1017418451888682,
        "distinct-3-nopunct": 0.95,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.221928094887362,
        "cond_entropy-3-nopunct": 0.012496476250064989,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.947104722914164,
        "bleu": 24.36742,
        "rouge1": {
            "precision": 0.80672,
            "recall": 0.71801,
            "fmeasure": 0.75604
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.49216,
            "fmeasure": 0.51881
        },
        "rougeL": {
            "precision": 0.63025,
            "recall": 0.60566,
            "fmeasure": 0.61588
        },
        "rougeLsum": {
            "precision": 0.63025,
            "recall": 0.60566,
            "fmeasure": 0.61588
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.5,
            "3": 0.7368421052631579
        },
        "bertscore": {
            "precision": 0.92284,
            "recall": 0.87118,
            "f1": 0.89617
        },
        "bleurt": -0.13783,
        "meteor": 0.3551998858601622,
        "nubia": {
            "semantic_relation": 4.50298,
            "contradiction": 0.90845,
            "irrelevancy": 5.95282,
            "logical_agreement": 93.13873,
            "grammar_ref": 6.00658,
            "grammar_hyp": 6.32292,
            "nubia_score": 0.78038
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_990": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.5555555555555556,
        "vocab_size-1": 10,
        "unique-1": 2,
        "entropy-1": 3.281036112553423,
        "distinct-2": 0.5625,
        "vocab_size-2": 9,
        "unique-2": 2,
        "entropy-2": 3.125,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 0.5714285714285714,
        "vocab_size-3": 8,
        "unique-3": 2,
        "entropy-3": 2.950212064914747,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.5625,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 2,
        "entropy-1-nopunct": 3.125,
        "distinct-2-nopunct": 0.5714285714285714,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 2,
        "entropy-2-nopunct": 2.950212064914747,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 0.5833333333333334,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 2,
        "entropy-3-nopunct": 2.7516291673878226,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.3685466228182268,
        "bleu": 30.25224,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.52273,
            "fmeasure": 0.64912
        },
        "rouge2": {
            "precision": 0.59524,
            "recall": 0.38333,
            "fmeasure": 0.44474
        },
        "rougeL": {
            "precision": 0.79167,
            "recall": 0.47633,
            "fmeasure": 0.58991
        },
        "rougeLsum": {
            "precision": 0.79167,
            "recall": 0.47633,
            "fmeasure": 0.58991
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.2857142857142857,
            "3": 0.5789473684210527
        },
        "bertscore": {
            "precision": 0.91775,
            "recall": 0.82179,
            "f1": 0.86682
        },
        "bleurt": 0.08219,
        "meteor": 0.2942230320084224,
        "nubia": {
            "semantic_relation": 4.01533,
            "contradiction": 0.32774,
            "irrelevancy": 18.23643,
            "logical_agreement": 81.43583,
            "grammar_ref": 4.70595,
            "grammar_hyp": 5.93925,
            "nubia_score": 0.54207
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1180": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 0.5,
        "median_pred_length": 11.5,
        "min_pred_length": 11,
        "max_pred_length": 12,
        "distinct-1": 0.8260869565217391,
        "vocab_size-1": 19,
        "unique-1": 15,
        "entropy-1": 4.1757358691004915,
        "distinct-2": 0.9047619047619048,
        "vocab_size-2": 19,
        "unique-2": 17,
        "entropy-2": 4.201841232302569,
        "cond_entropy-2": -0.03600643804015718,
        "distinct-3": 0.9473684210526315,
        "vocab_size-3": 18,
        "unique-3": 17,
        "entropy-3": 4.142664355548846,
        "cond_entropy-3": -0.0391267514404381,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.106603137064473,
        "distinct-2-nopunct": 0.8947368421052632,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.03740119765411,
        "cond_entropy-2-nopunct": -0.039126751440438104,
        "distinct-3-nopunct": 0.9411764705882353,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.969815782426811,
        "cond_entropy-3-nopunct": -0.04281761336971671,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.840943383935989,
        "bleu": 42.83043,
        "rouge1": {
            "precision": 0.65455,
            "recall": 0.59768,
            "fmeasure": 0.62164
        },
        "rouge2": {
            "precision": 0.45556,
            "recall": 0.38729,
            "fmeasure": 0.41719
        },
        "rougeL": {
            "precision": 0.65455,
            "recall": 0.59768,
            "fmeasure": 0.62164
        },
        "rougeLsum": {
            "precision": 0.65455,
            "recall": 0.59768,
            "fmeasure": 0.62164
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6190476190476191
        },
        "bertscore": {
            "precision": 0.94791,
            "recall": 0.93556,
            "f1": 0.94169
        },
        "bleurt": 0.55213,
        "meteor": 0.3616563898584464,
        "nubia": {
            "semantic_relation": 4.21339,
            "contradiction": 0.3755,
            "irrelevancy": 5.46039,
            "logical_agreement": 94.1641,
            "grammar_ref": 5.01983,
            "grammar_hyp": 5.30893,
            "nubia_score": 0.69155
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_764": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964168,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8935169340538587,
        "bleu": 55.77619,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.73684,
            "fmeasure": 0.84848
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.72222,
            "fmeasure": 0.83871
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.73684,
            "fmeasure": 0.84848
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.73684,
            "fmeasure": 0.84848
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.97972,
            "recall": 0.89823,
            "f1": 0.93721
        },
        "bleurt": 0.30923,
        "meteor": 0.4112119220357105,
        "nubia": {
            "semantic_relation": 3.98058,
            "contradiction": 2.00846,
            "irrelevancy": 0.72483,
            "logical_agreement": 97.26671,
            "grammar_ref": 4.21408,
            "grammar_hyp": 4.96318,
            "nubia_score": 0.57827
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1128": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.955323867359043,
        "bleu": 47.33407,
        "rouge1": {
            "precision": 0.74074,
            "recall": 0.63333,
            "fmeasure": 0.6817
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.46128,
            "fmeasure": 0.49742
        },
        "rougeL": {
            "precision": 0.74074,
            "recall": 0.63333,
            "fmeasure": 0.6817
        },
        "rougeLsum": {
            "precision": 0.74074,
            "recall": 0.63333,
            "fmeasure": 0.6817
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.36363636363636365,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.93604,
            "recall": 0.88554,
            "f1": 0.91009
        },
        "bleurt": 0.25451,
        "meteor": 0.3323642087904796,
        "nubia": {
            "semantic_relation": 3.73051,
            "contradiction": 10.66019,
            "irrelevancy": 29.60807,
            "logical_agreement": 59.73173,
            "grammar_ref": 4.72922,
            "grammar_hyp": 5.8088,
            "nubia_score": 0.41593
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_765": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.768492245572466,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.97268,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.373,
            "irrelevancy": 0.51156,
            "logical_agreement": 99.11544,
            "grammar_ref": 5.07856,
            "grammar_hyp": 5.22425,
            "nubia_score": 0.9763
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1000": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964164,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.051189449246730745,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.622084427089623,
        "bleu": 16.54462,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.81818,
            "fmeasure": 0.69231
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.6,
            "fmeasure": 0.5
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.81818,
            "fmeasure": 0.69231
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.81818,
            "fmeasure": 0.69231
        },
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.94004,
            "recall": 0.93999,
            "f1": 0.92778
        },
        "bleurt": 0.47011,
        "meteor": 0.33566695931982926,
        "nubia": {
            "semantic_relation": 4.96799,
            "contradiction": 0.52732,
            "irrelevancy": 71.3483,
            "logical_agreement": 28.12438,
            "grammar_ref": 3.90557,
            "grammar_hyp": 3.88941,
            "nubia_score": 0.94132
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1135": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.03126257645096008,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.033108599109837954,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2718899099398837,
        "bleu": 28.12915,
        "rouge1": {
            "precision": 0.64912,
            "recall": 0.72807,
            "fmeasure": 0.68521
        },
        "rouge2": {
            "precision": 0.37037,
            "recall": 0.39259,
            "fmeasure": 0.38047
        },
        "rougeL": {
            "precision": 0.4386,
            "recall": 0.47135,
            "fmeasure": 0.45304
        },
        "rougeLsum": {
            "precision": 0.4386,
            "recall": 0.47135,
            "fmeasure": 0.45304
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 1.0,
            "3": 0.7272727272727273
        },
        "bertscore": {
            "precision": 0.87531,
            "recall": 0.87044,
            "f1": 0.86787
        },
        "bleurt": 0.24131,
        "meteor": 0.33950161590542083,
        "nubia": {
            "semantic_relation": 4.13649,
            "contradiction": 0.10441,
            "irrelevancy": 0.92803,
            "logical_agreement": 98.96756,
            "grammar_ref": 5.46955,
            "grammar_hyp": 4.14985,
            "nubia_score": 0.86968
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1359": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 1.0,
        "vocab_size-1": 21,
        "unique-1": 21,
        "entropy-1": 4.39231742277876,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.07038932789139804,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.7534711311036353,
        "bleu": 28.41189,
        "rouge1": {
            "precision": 0.58824,
            "recall": 0.69048,
            "fmeasure": 0.63508
        },
        "rouge2": {
            "precision": 0.34375,
            "recall": 0.40934,
            "fmeasure": 0.37356
        },
        "rougeL": {
            "precision": 0.47059,
            "recall": 0.55238,
            "fmeasure": 0.50806
        },
        "rougeLsum": {
            "precision": 0.47059,
            "recall": 0.55238,
            "fmeasure": 0.50806
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.7272727272727273
        },
        "bertscore": {
            "precision": 0.86712,
            "recall": 0.87622,
            "f1": 0.87158
        },
        "bleurt": 0.1831,
        "meteor": 0.36365182154260395,
        "nubia": {
            "semantic_relation": 4.48517,
            "contradiction": 0.24519,
            "irrelevancy": 59.52133,
            "logical_agreement": 40.23348,
            "grammar_ref": 5.03823,
            "grammar_hyp": 4.79482,
            "nubia_score": 0.804
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1140": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8535769082186824,
        "bleu": 76.74162,
        "rouge1": {
            "precision": 0.96154,
            "recall": 0.92857,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.84295,
            "fmeasure": 0.85833
        },
        "rougeL": {
            "precision": 0.80769,
            "recall": 0.78022,
            "fmeasure": 0.79345
        },
        "rougeLsum": {
            "precision": 0.80769,
            "recall": 0.78022,
            "fmeasure": 0.79345
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "bertscore": {
            "precision": 0.9822,
            "recall": 0.97494,
            "f1": 0.97856
        },
        "bleurt": 0.39021,
        "meteor": 0.5426177315437225,
        "nubia": {
            "semantic_relation": 3.73103,
            "contradiction": 47.93643,
            "irrelevancy": 1.84919,
            "logical_agreement": 50.21438,
            "grammar_ref": 2.33019,
            "grammar_hyp": 2.4164,
            "nubia_score": 0.6985
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1656": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.16253715874966052,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.17355726227518523,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9605114293246142,
        "bleu": 13.32358,
        "rouge1": {
            "precision": 0.58824,
            "recall": 0.76923,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.5,
            "fmeasure": 0.42857
        },
        "rougeL": {
            "precision": 0.47059,
            "recall": 0.61538,
            "fmeasure": 0.53333
        },
        "rougeLsum": {
            "precision": 0.47059,
            "recall": 0.61538,
            "fmeasure": 0.53333
        },
        "local_recall": {
            "1": 0,
            "2": 0.5833333333333334
        },
        "bertscore": {
            "precision": 0.8845,
            "recall": 0.94661,
            "f1": 0.9145
        },
        "bleurt": 0.02575,
        "meteor": 0.3996954702217728,
        "nubia": {
            "semantic_relation": 3.99293,
            "contradiction": 0.03909,
            "irrelevancy": 99.46828,
            "logical_agreement": 0.49262,
            "grammar_ref": 3.76485,
            "grammar_hyp": 3.10357,
            "nubia_score": 0.87593
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1379": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.8846153846153846,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.46967048737186,
        "distinct-2": 0.96,
        "vocab_size-2": 24,
        "unique-2": 23,
        "entropy-2": 4.5638561897747225,
        "cond_entropy-2": 0.10341647163363243,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": 0.02443964427976503,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.88,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.403856189774722,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.501629167387823,
        "cond_entropy-2-nopunct": 0.10777297761309833,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": 0.02555597707498716,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.233101956544771,
        "bleu": 45.8736,
        "rouge1": {
            "precision": 0.86957,
            "recall": 0.74074,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.61538,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.78261,
            "recall": 0.66667,
            "fmeasure": 0.72
        },
        "rougeLsum": {
            "precision": 0.78261,
            "recall": 0.66667,
            "fmeasure": 0.72
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8095238095238095
        },
        "bertscore": {
            "precision": 0.92465,
            "recall": 0.91449,
            "f1": 0.9194
        },
        "bleurt": 0.14383,
        "meteor": 0.41030282160569487,
        "nubia": {
            "semantic_relation": 4.16847,
            "contradiction": 0.12934,
            "irrelevancy": 3.90988,
            "logical_agreement": 95.96078,
            "grammar_ref": 4.19464,
            "grammar_hyp": 4.08326,
            "nubia_score": 0.73512
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1182": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.1675001135097276,
        "bleu": 3.92972,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.47222,
            "fmeasure": 0.39012
        },
        "rouge2": {
            "precision": 0.07143,
            "recall": 0.10438,
            "fmeasure": 0.08464
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.47222,
            "fmeasure": 0.39012
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.47222,
            "fmeasure": 0.39012
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.78155,
            "recall": 0.8133,
            "f1": 0.79711
        },
        "bleurt": -0.81861,
        "meteor": 0.1996101364522417,
        "nubia": {
            "semantic_relation": 2.59421,
            "contradiction": 30.16794,
            "irrelevancy": 69.43365,
            "logical_agreement": 0.39842,
            "grammar_ref": 4.40566,
            "grammar_hyp": 4.50011,
            "nubia_score": 0.25349
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2280": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.051189449246730745,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322734,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.867976246918685,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.73788,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.77875,
            "contradiction": 0.20639,
            "irrelevancy": 0.55532,
            "logical_agreement": 99.23829,
            "grammar_ref": 4.35803,
            "grammar_hyp": 4.93905,
            "nubia_score": 0.9019
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1188": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518523,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.20077710377579552,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0848474523384635,
        "bleu": 33.15796,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.47857,
            "fmeasure": 0.48892
        },
        "rouge2": {
            "precision": 0.23077,
            "recall": 0.21703,
            "fmeasure": 0.22365
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.34048,
            "fmeasure": 0.34852
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.34048,
            "fmeasure": 0.34852
        },
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.45454545454545453
        },
        "bertscore": {
            "precision": 0.89794,
            "recall": 0.89785,
            "f1": 0.89789
        },
        "bleurt": 0.22186,
        "meteor": 0.34675109852855823,
        "nubia": {
            "semantic_relation": 4.12277,
            "contradiction": 85.02813,
            "irrelevancy": 12.39056,
            "logical_agreement": 2.58131,
            "grammar_ref": 4.95834,
            "grammar_hyp": 4.65134,
            "nubia_score": 0.65997
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1680": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6961650890339652,
        "bleu": 76.11606,
        "rouge1": {
            "precision": 0.87879,
            "recall": 0.96667,
            "fmeasure": 0.92063
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.81481,
            "fmeasure": 0.77193
        },
        "rougeL": {
            "precision": 0.87879,
            "recall": 0.96667,
            "fmeasure": 0.92063
        },
        "rougeLsum": {
            "precision": 0.87879,
            "recall": 0.96667,
            "fmeasure": 0.92063
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.97599,
            "recall": 0.99403,
            "f1": 0.98493
        },
        "bleurt": 0.74566,
        "meteor": 0.5715186082473627,
        "nubia": {
            "semantic_relation": 4.94183,
            "contradiction": 0.26546,
            "irrelevancy": 2.07729,
            "logical_agreement": 97.65725,
            "grammar_ref": 4.2439,
            "grammar_hyp": 4.255,
            "nubia_score": 0.96846
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1384": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.5484412322516041,
        "bleu": 27.82462,
        "rouge1": {
            "precision": 0.34615,
            "recall": 0.57937,
            "fmeasure": 0.43182
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.45833,
            "fmeasure": 0.32222
        },
        "rougeL": {
            "precision": 0.34615,
            "recall": 0.57937,
            "fmeasure": 0.43182
        },
        "rougeLsum": {
            "precision": 0.34615,
            "recall": 0.57937,
            "fmeasure": 0.43182
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.83833,
            "recall": 0.91019,
            "f1": 0.86408
        },
        "bleurt": 0.13167,
        "meteor": 0.35149642178137297,
        "nubia": {
            "semantic_relation": 3.52491,
            "contradiction": 0.1453,
            "irrelevancy": 88.65474,
            "logical_agreement": 11.19996,
            "grammar_ref": 4.8549,
            "grammar_hyp": 4.36437,
            "nubia_score": 0.50714
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1400": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.16253715874966057,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.6402239289418516,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.18617861216337134,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.138156269161421,
        "bleu": 48.34389,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.92308,
            "fmeasure": 0.81593
        },
        "rouge2": {
            "precision": 0.60714,
            "recall": 0.78333,
            "fmeasure": 0.68269
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.92308,
            "fmeasure": 0.81593
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.92308,
            "fmeasure": 0.81593
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0
        },
        "bertscore": {
            "precision": 0.90687,
            "recall": 0.96364,
            "f1": 0.93439
        },
        "bleurt": 0.37904,
        "meteor": 0.47782529723815587,
        "nubia": {
            "semantic_relation": 4.05748,
            "contradiction": 3.93192,
            "irrelevancy": 83.89016,
            "logical_agreement": 12.17792,
            "grammar_ref": 4.75081,
            "grammar_hyp": 3.91381,
            "nubia_score": 0.70556
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1408": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 14,
        "unique-1": 11,
        "entropy-1": 3.68354236243323,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.43253122228823104,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7647058823529411,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.572469458770136,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.45971762763487756,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.1729520220840473,
        "bleu": 5.75139,
        "rouge1": {
            "precision": 0.22222,
            "recall": 0.28356,
            "fmeasure": 0.24823
        },
        "rouge2": {
            "precision": 0.05882,
            "recall": 0.07639,
            "fmeasure": 0.06618
        },
        "rougeL": {
            "precision": 0.2037,
            "recall": 0.23379,
            "fmeasure": 0.2169
        },
        "rougeLsum": {
            "precision": 0.2037,
            "recall": 0.23379,
            "fmeasure": 0.2169
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "bertscore": {
            "precision": 0.66774,
            "recall": 0.68904,
            "f1": 0.67822
        },
        "bleurt": -0.68978,
        "meteor": 0.1274449583988788,
        "nubia": {
            "semantic_relation": 1.19816,
            "contradiction": 41.25324,
            "irrelevancy": 56.07624,
            "logical_agreement": 2.67051,
            "grammar_ref": 4.12033,
            "grammar_hyp": 3.57188,
            "nubia_score": 0.1161
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1194": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3457959025749076,
        "bleu": 38.82727,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.86667,
            "fmeasure": 0.78788
        },
        "rouge2": {
            "precision": 0.51515,
            "recall": 0.62963,
            "fmeasure": 0.56667
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.66667,
            "fmeasure": 0.60606
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.66667,
            "fmeasure": 0.60606
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.94813,
            "recall": 0.95899,
            "f1": 0.95353
        },
        "bleurt": 0.65358,
        "meteor": 0.4291805170654156,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2659,
            "irrelevancy": 0.41536,
            "logical_agreement": 99.31874,
            "grammar_ref": 4.16465,
            "grammar_hyp": 3.57003,
            "nubia_score": 0.97602
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1683": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9047619047619048,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.165894208390022,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.08810692218071757,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.5740762289948527,
        "bleu": 24.48927,
        "rouge1": {
            "precision": 0.82222,
            "recall": 0.64141,
            "fmeasure": 0.71908
        },
        "rouge2": {
            "precision": 0.40476,
            "recall": 0.31466,
            "fmeasure": 0.3533
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.4697,
            "fmeasure": 0.5258
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.4697,
            "fmeasure": 0.5258
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.625
        },
        "bertscore": {
            "precision": 0.945,
            "recall": 0.91934,
            "f1": 0.9318
        },
        "bleurt": 0.01281,
        "meteor": 0.2814180794617461,
        "nubia": {
            "semantic_relation": 3.28503,
            "contradiction": 96.87764,
            "irrelevancy": 1.38569,
            "logical_agreement": 1.73666,
            "grammar_ref": 4.78465,
            "grammar_hyp": 5.14553,
            "nubia_score": 0.35446
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1685": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.8200785863811701,
        "bleu": 30.25543,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.5098,
            "fmeasure": 0.5977
        },
        "rouge2": {
            "precision": 0.51515,
            "recall": 0.35417,
            "fmeasure": 0.41975
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.39216,
            "fmeasure": 0.45977
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.39216,
            "fmeasure": 0.45977
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.93948,
            "recall": 0.91825,
            "f1": 0.92848
        },
        "bleurt": 0.42762,
        "meteor": 0.29563020110735383,
        "nubia": {
            "semantic_relation": 4.14143,
            "contradiction": 8.46344,
            "irrelevancy": 14.96147,
            "logical_agreement": 76.57509,
            "grammar_ref": 3.28677,
            "grammar_hyp": 5.09187,
            "nubia_score": 0.55245
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1206": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 22.0,
        "std_pred_length": 3.0,
        "median_pred_length": 22.0,
        "min_pred_length": 19,
        "max_pred_length": 25,
        "distinct-1": 0.75,
        "vocab_size-1": 33,
        "unique-1": 24,
        "entropy-1": 4.925118550357138,
        "distinct-2": 0.9523809523809523,
        "vocab_size-2": 40,
        "unique-2": 38,
        "entropy-2": 5.297079327540667,
        "cond_entropy-2": 0.34978520900639043,
        "distinct-3": 0.975,
        "vocab_size-3": 39,
        "unique-3": 38,
        "entropy-3": 5.271928094887364,
        "cond_entropy-3": -0.02038932789139803,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7368421052631579,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.681880802803404,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.058813890331199,
        "cond_entropy-2-nopunct": 0.3806023492300307,
        "distinct-3-nopunct": 0.9705882352941176,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.028639311838574,
        "cond_entropy-3-nopunct": -0.023638630780208267,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.130339173313721,
        "bleu": 43.21854,
        "rouge1": {
            "precision": 0.78977,
            "recall": 0.67963,
            "fmeasure": 0.72708
        },
        "rouge2": {
            "precision": 0.53016,
            "recall": 0.47206,
            "fmeasure": 0.49727
        },
        "rougeL": {
            "precision": 0.68371,
            "recall": 0.60185,
            "fmeasure": 0.63734
        },
        "rougeLsum": {
            "precision": 0.68371,
            "recall": 0.60185,
            "fmeasure": 0.63734
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.92563,
            "recall": 0.89043,
            "f1": 0.90461
        },
        "bleurt": 0.14611,
        "meteor": 0.3176951649955517,
        "nubia": {
            "semantic_relation": 4.27784,
            "contradiction": 1.48567,
            "irrelevancy": 50.87058,
            "logical_agreement": 47.64375,
            "grammar_ref": 4.16263,
            "grammar_hyp": 4.07158,
            "nubia_score": 0.76489
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1428": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.9162690271420784,
        "bleu": 6.40052,
        "rouge1": {
            "precision": 0.40741,
            "recall": 0.2619,
            "fmeasure": 0.31884
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.07692,
            "fmeasure": 0.09524
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.21429,
            "fmeasure": 0.26087
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.21429,
            "fmeasure": 0.26087
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "bertscore": {
            "precision": 0.76121,
            "recall": 0.76993,
            "f1": 0.76167
        },
        "bleurt": -0.32539,
        "meteor": 0.2047886867750067,
        "nubia": {
            "semantic_relation": 2.96464,
            "contradiction": 0.28533,
            "irrelevancy": 99.58718,
            "logical_agreement": 0.12749,
            "grammar_ref": 3.90604,
            "grammar_hyp": 3.96805,
            "nubia_score": 0.38746
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1688": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.702819531114783,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.22388309575274973,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.4677201004744997,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.13692518080981952,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.8811331011233863,
        "bleu": 21.34639,
        "rouge1": {
            "precision": 0.42857,
            "recall": 0.35294,
            "fmeasure": 0.3871
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.25,
            "fmeasure": 0.27586
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.29412,
            "fmeasure": 0.32258
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.29412,
            "fmeasure": 0.32258
        },
        "local_recall": {
            "1": 0,
            "2": 0.4
        },
        "bertscore": {
            "precision": 0.86242,
            "recall": 0.79224,
            "f1": 0.82584
        },
        "bleurt": -0.25329,
        "meteor": 0.221314129122313,
        "nubia": {
            "semantic_relation": 2.61962,
            "contradiction": 59.38278,
            "irrelevancy": 33.53765,
            "logical_agreement": 7.07957,
            "grammar_ref": 4.28272,
            "grammar_hyp": 4.278,
            "nubia_score": 0.25906
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2282": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.8076083232145888,
        "bleu": 26.68078,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.41176,
            "fmeasure": 0.51852
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.375,
            "fmeasure": 0.48
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.41176,
            "fmeasure": 0.51852
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.41176,
            "fmeasure": 0.51852
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.42857142857142855
        },
        "bertscore": {
            "precision": 0.87049,
            "recall": 0.795,
            "f1": 0.83103
        },
        "bleurt": -0.51516,
        "meteor": 0.22905788893451226,
        "nubia": {
            "semantic_relation": 3.20989,
            "contradiction": 0.14667,
            "irrelevancy": 97.50456,
            "logical_agreement": 2.34876,
            "grammar_ref": 3.64996,
            "grammar_hyp": 3.81037,
            "nubia_score": 0.48508
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1441": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 18.0,
        "std_pred_length": 6.48074069840786,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 27,
        "distinct-1": 0.5740740740740741,
        "vocab_size-1": 31,
        "unique-1": 19,
        "entropy-1": 4.669161752476604,
        "distinct-2": 0.7450980392156863,
        "vocab_size-2": 38,
        "unique-2": 28,
        "entropy-2": 5.118216273216785,
        "cond_entropy-2": 0.419687653032278,
        "distinct-3": 0.7916666666666666,
        "vocab_size-3": 38,
        "unique-3": 30,
        "entropy-3": 5.136842188131015,
        "cond_entropy-3": 0.011597315044732853,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 6.944222218666553,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5714285714285714,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.515234273075877,
        "distinct-2-nopunct": 0.7391304347826086,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.952591032002872,
        "cond_entropy-2-nopunct": 0.46558342660347424,
        "distinct-3-nopunct": 0.7906976744186046,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.972549056927052,
        "cond_entropy-3-nopunct": 0.013281577765165586,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6290822971177725,
        "bleu": 37.90344,
        "rouge1": {
            "precision": 0.69943,
            "recall": 0.67313,
            "fmeasure": 0.66952
        },
        "rouge2": {
            "precision": 0.51495,
            "recall": 0.47261,
            "fmeasure": 0.47979
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.59169,
            "fmeasure": 0.58685
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.59169,
            "fmeasure": 0.58685
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.6666666666666666,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.91075,
            "recall": 0.88335,
            "f1": 0.89588
        },
        "bleurt": -0.1158,
        "meteor": 0.37630930486547726,
        "nubia": {
            "semantic_relation": 3.78001,
            "contradiction": 2.30037,
            "irrelevancy": 59.22115,
            "logical_agreement": 38.47848,
            "grammar_ref": 4.27064,
            "grammar_hyp": 4.07121,
            "nubia_score": 0.64801
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1908": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.0433214693062285,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.355710589176038,
        "bleu": 10.07471,
        "rouge1": {
            "precision": 0.53846,
            "recall": 0.64133,
            "fmeasure": 0.57008
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.2037,
            "fmeasure": 0.17778
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.54971,
            "fmeasure": 0.48864
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.54971,
            "fmeasure": 0.48864
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.91479,
            "recall": 0.93784,
            "f1": 0.92617
        },
        "bleurt": 0.44036,
        "meteor": 0.400724566671953,
        "nubia": {
            "semantic_relation": 4.41641,
            "contradiction": 0.08277,
            "irrelevancy": 5.98007,
            "logical_agreement": 93.93716,
            "grammar_ref": 3.44041,
            "grammar_hyp": 3.51199,
            "nubia_score": 0.85963
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1446": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.807763576417195,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.20971762763487733,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.702819531114783,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.22388309575274978,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9667404416431011,
        "bleu": 19.92341,
        "rouge1": {
            "precision": 0.58333,
            "recall": 1.0,
            "fmeasure": 0.73504
        },
        "rouge2": {
            "precision": 0.51111,
            "recall": 0.92593,
            "fmeasure": 0.65657
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 1.0,
            "fmeasure": 0.73504
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 1.0,
            "fmeasure": 0.73504
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.88144,
            "recall": 0.95142,
            "f1": 0.89855
        },
        "bleurt": 0.25138,
        "meteor": 0.5053376300140145,
        "nubia": {
            "semantic_relation": 3.98806,
            "contradiction": 0.10967,
            "irrelevancy": 98.963,
            "logical_agreement": 0.92733,
            "grammar_ref": 3.90726,
            "grammar_hyp": 2.50428,
            "nubia_score": 0.76904
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1914": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.7514117701566305,
        "bleu": 28.41088,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.5037,
            "fmeasure": 0.64198
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.26891,
            "fmeasure": 0.34909
        },
        "rougeL": {
            "precision": 0.7037,
            "recall": 0.4037,
            "fmeasure": 0.51235
        },
        "rougeLsum": {
            "precision": 0.7037,
            "recall": 0.4037,
            "fmeasure": 0.51235
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.5384615384615384
        },
        "bertscore": {
            "precision": 0.94668,
            "recall": 0.88134,
            "f1": 0.91284
        },
        "bleurt": 0.03781,
        "meteor": 0.2841762990914195,
        "nubia": {
            "semantic_relation": 3.90649,
            "contradiction": 0.57624,
            "irrelevancy": 0.5262,
            "logical_agreement": 98.89756,
            "grammar_ref": 4.4151,
            "grammar_hyp": 6.06828,
            "nubia_score": 0.46595
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1692": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 4.0,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.8846153846153846,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.46967048737186,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.051189449246730766,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.056287299734322754,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.718873153220278,
        "bleu": 24.1005,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.52424,
            "fmeasure": 0.54971
        },
        "rouge2": {
            "precision": 0.37815,
            "recall": 0.34085,
            "fmeasure": 0.35662
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.49646,
            "fmeasure": 0.52193
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.49646,
            "fmeasure": 0.52193
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3684210526315789,
            "3": 0.8333333333333334
        },
        "bertscore": {
            "precision": 0.88244,
            "recall": 0.86935,
            "f1": 0.87579
        },
        "bleurt": -0.14226,
        "meteor": 0.25771944555623144,
        "nubia": {
            "semantic_relation": 3.88056,
            "contradiction": 23.04725,
            "irrelevancy": 58.88057,
            "logical_agreement": 18.07218,
            "grammar_ref": 5.11675,
            "grammar_hyp": 4.84305,
            "nubia_score": 0.54776
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1926": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 12,
        "unique-1": 10,
        "entropy-1": 3.521640636343319,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.2007771037757955,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.21785611591339743,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8302145228411035,
        "bleu": 59.82478,
        "rouge1": {
            "precision": 0.82051,
            "recall": 0.73846,
            "fmeasure": 0.77656
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.5119,
            "fmeasure": 0.54487
        },
        "rougeL": {
            "precision": 0.71795,
            "recall": 0.64274,
            "fmeasure": 0.67766
        },
        "rougeLsum": {
            "precision": 0.71795,
            "recall": 0.64274,
            "fmeasure": 0.67766
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.97507,
            "recall": 0.91595,
            "f1": 0.94459
        },
        "bleurt": 0.4061,
        "meteor": 0.40195307296036104,
        "nubia": {
            "semantic_relation": 4.81956,
            "contradiction": 0.3267,
            "irrelevancy": 0.52077,
            "logical_agreement": 99.15253,
            "grammar_ref": 4.20051,
            "grammar_hyp": 4.51816,
            "nubia_score": 0.91197
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1470": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 52,
        "mean_pred_length": 13.0,
        "std_pred_length": 4.69041575982343,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 17,
        "distinct-1": 0.75,
        "vocab_size-1": 39,
        "unique-1": 32,
        "entropy-1": 5.0780449493603195,
        "distinct-2": 0.9791666666666666,
        "vocab_size-2": 47,
        "unique-2": 46,
        "entropy-2": 5.5432958340544936,
        "cond_entropy-2": 0.32362310751862344,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": -0.08007633662931368,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 4.55521678957215,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8043478260869565,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.0723687494882395,
        "distinct-2-nopunct": 0.9761904761904762,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.344698375159715,
        "cond_entropy-2-nopunct": 0.31530040724944897,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.09175833038780648,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.0593369944640716,
        "bleu": 30.45192,
        "rouge1": {
            "precision": 0.7664,
            "recall": 0.46148,
            "fmeasure": 0.54728
        },
        "rouge2": {
            "precision": 0.39372,
            "recall": 0.27843,
            "fmeasure": 0.31538
        },
        "rougeL": {
            "precision": 0.56157,
            "recall": 0.39337,
            "fmeasure": 0.45213
        },
        "rougeLsum": {
            "precision": 0.56157,
            "recall": 0.39337,
            "fmeasure": 0.45213
        },
        "local_recall": {
            "1": 0.075,
            "2": 0.48148148148148145,
            "3": 0.5172413793103449
        },
        "bertscore": {
            "precision": 0.89074,
            "recall": 0.8493,
            "f1": 0.85523
        },
        "bleurt": -0.17236,
        "meteor": 0.2377552797941487,
        "nubia": {
            "semantic_relation": 3.96875,
            "contradiction": 2.57797,
            "irrelevancy": 50.40435,
            "logical_agreement": 47.01768,
            "grammar_ref": 5.44243,
            "grammar_hyp": 6.85704,
            "nubia_score": 0.47798
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1700": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1186190517434538,
        "bleu": 44.97332,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.73333,
            "fmeasure": 0.73333
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.48148,
            "fmeasure": 0.48148
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.73333,
            "fmeasure": 0.73333
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.73333,
            "fmeasure": 0.73333
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.9835,
            "recall": 0.9835,
            "f1": 0.9835
        },
        "bleurt": 0.1792,
        "meteor": 0.47176253367099763,
        "nubia": {
            "semantic_relation": 4.97109,
            "contradiction": 1.01778,
            "irrelevancy": 2.14795,
            "logical_agreement": 96.83427,
            "grammar_ref": 5.6957,
            "grammar_hyp": 5.09849,
            "nubia_score": 0.95254
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1928": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7021217848513936,
        "bleu": 45.93074,
        "rouge1": {
            "precision": 0.89583,
            "recall": 0.82143,
            "fmeasure": 0.8536
        },
        "rouge2": {
            "precision": 0.8,
            "recall": 0.73333,
            "fmeasure": 0.7619
        },
        "rougeL": {
            "precision": 0.8125,
            "recall": 0.75794,
            "fmeasure": 0.78153
        },
        "rougeLsum": {
            "precision": 0.8125,
            "recall": 0.75794,
            "fmeasure": 0.78153
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.8888888888888888
        },
        "bertscore": {
            "precision": 0.91381,
            "recall": 0.93259,
            "f1": 0.92311
        },
        "bleurt": -0.18438,
        "meteor": 0.4567832712434602,
        "nubia": {
            "semantic_relation": 4.16226,
            "contradiction": 0.73581,
            "irrelevancy": 46.51296,
            "logical_agreement": 52.75123,
            "grammar_ref": 3.89472,
            "grammar_hyp": 5.35472,
            "nubia_score": 0.56761
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1210": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6082285494625848,
        "bleu": 41.02024,
        "rouge1": {
            "precision": 0.80392,
            "recall": 0.63059,
            "fmeasure": 0.7067
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.42698,
            "fmeasure": 0.47748
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.52092,
            "fmeasure": 0.5848
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.52092,
            "fmeasure": 0.5848
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.6666666666666666,
            "3": 0.6428571428571429
        },
        "bertscore": {
            "precision": 0.95304,
            "recall": 0.92754,
            "f1": 0.94012
        },
        "bleurt": 0.51512,
        "meteor": 0.38360135893996405,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.28188,
            "irrelevancy": 1.45272,
            "logical_agreement": 98.26539,
            "grammar_ref": 3.4928,
            "grammar_hyp": 4.23978,
            "nubia_score": 0.95018
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1503": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.5215437171957966,
        "bleu": 10.83802,
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.61275,
            "fmeasure": 0.68199
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.26111,
            "fmeasure": 0.29277
        },
        "rougeL": {
            "precision": 0.53846,
            "recall": 0.42892,
            "fmeasure": 0.47739
        },
        "rougeLsum": {
            "precision": 0.53846,
            "recall": 0.42892,
            "fmeasure": 0.47739
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.625
        },
        "bertscore": {
            "precision": 0.92833,
            "recall": 0.86959,
            "f1": 0.898
        },
        "bleurt": 0.26163,
        "meteor": 0.2870768472705899,
        "nubia": {
            "semantic_relation": 3.45334,
            "contradiction": 0.17466,
            "irrelevancy": 1.0098,
            "logical_agreement": 98.81554,
            "grammar_ref": 4.86284,
            "grammar_hyp": 5.29522,
            "nubia_score": 0.47982
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1216": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.1208060405775977,
        "bleu": 15.79414,
        "rouge1": {
            "precision": 0.71111,
            "recall": 0.43826,
            "fmeasure": 0.54211
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.19949,
            "fmeasure": 0.24951
        },
        "rougeL": {
            "precision": 0.51111,
            "recall": 0.31478,
            "fmeasure": 0.38947
        },
        "rougeLsum": {
            "precision": 0.51111,
            "recall": 0.31478,
            "fmeasure": 0.38947
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5454545454545454,
            "3": 0.4444444444444444
        },
        "bertscore": {
            "precision": 0.92444,
            "recall": 0.8593,
            "f1": 0.89068
        },
        "bleurt": -0.17869,
        "meteor": 0.24000574567708297,
        "nubia": {
            "semantic_relation": 3.22782,
            "contradiction": 9.97626,
            "irrelevancy": 52.00128,
            "logical_agreement": 38.02246,
            "grammar_ref": 3.96534,
            "grammar_hyp": 2.83902,
            "nubia_score": 0.56123
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1730": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 52,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 1.8856180831641267,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 20,
        "distinct-1": 0.4807692307692308,
        "vocab_size-1": 25,
        "unique-1": 12,
        "entropy-1": 4.39199548703902,
        "distinct-2": 0.6938775510204082,
        "vocab_size-2": 34,
        "unique-2": 23,
        "entropy-2": 4.94084147659166,
        "cond_entropy-2": 0.5319162995759613,
        "distinct-3": 0.717391304347826,
        "vocab_size-3": 33,
        "unique-3": 23,
        "entropy-3": 4.909112771133307,
        "cond_entropy-3": 0.012219231554053883,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 2.357022603955158,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.48936170212765956,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.250669436461801,
        "distinct-2-nopunct": 0.6818181818181818,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.754441845713345,
        "cond_entropy-2-nopunct": 0.5926760057435327,
        "distinct-3-nopunct": 0.7073170731707317,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.716950480069536,
        "cond_entropy-3-nopunct": 0.014093251887212397,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.3863433661923565,
        "bleu": 50.18981,
        "rouge1": {
            "precision": 0.8939,
            "recall": 0.83693,
            "fmeasure": 0.85922
        },
        "rouge2": {
            "precision": 0.58927,
            "recall": 0.55373,
            "fmeasure": 0.56652
        },
        "rougeL": {
            "precision": 0.6391,
            "recall": 0.6076,
            "fmeasure": 0.61861
        },
        "rougeLsum": {
            "precision": 0.6391,
            "recall": 0.6076,
            "fmeasure": 0.61861
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8444444444444444
        },
        "bertscore": {
            "precision": 0.95795,
            "recall": 0.94418,
            "f1": 0.95043
        },
        "bleurt": 0.18691,
        "meteor": 0.427408000147952,
        "nubia": {
            "semantic_relation": 3.36583,
            "contradiction": 99.23824,
            "irrelevancy": 0.29493,
            "logical_agreement": 0.46683,
            "grammar_ref": 4.73012,
            "grammar_hyp": 4.8757,
            "nubia_score": 0.42322
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1936": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 9.5,
        "std_pred_length": 0.5,
        "median_pred_length": 9.5,
        "min_pred_length": 9,
        "max_pred_length": 10,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 14,
        "unique-1": 9,
        "entropy-1": 3.7216117239699,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.3101235631008714,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.18057224564182078,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.7647058823529411,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.6168746059562227,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.2860944210248459,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.2064508774674265,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.697564432802039,
        "bleu": 22.30577,
        "rouge1": {
            "precision": 0.9,
            "recall": 0.60417,
            "fmeasure": 0.71475
        },
        "rouge2": {
            "precision": 0.63194,
            "recall": 0.40963,
            "fmeasure": 0.49058
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 0.60417,
            "fmeasure": 0.71475
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 0.60417,
            "fmeasure": 0.71475
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5454545454545454
        },
        "bertscore": {
            "precision": 0.95176,
            "recall": 0.90241,
            "f1": 0.92599
        },
        "bleurt": 0.49295,
        "meteor": 0.36748226402683243,
        "nubia": {
            "semantic_relation": 4.81461,
            "contradiction": 0.70296,
            "irrelevancy": 2.1686,
            "logical_agreement": 97.12844,
            "grammar_ref": 3.22845,
            "grammar_hyp": 3.33969,
            "nubia_score": 0.95368
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1770": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964164,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673076,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.8915635893658773,
        "bleu": 22.24247,
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.69697,
            "fmeasure": 0.62769
        },
        "rouge2": {
            "precision": 0.38462,
            "recall": 0.47727,
            "fmeasure": 0.42572
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.69697,
            "fmeasure": 0.62769
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.69697,
            "fmeasure": 0.62769
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.75
        },
        "bertscore": {
            "precision": 0.88566,
            "recall": 0.92505,
            "f1": 0.90493
        },
        "bleurt": 0.01116,
        "meteor": 0.3453033701366209,
        "nubia": {
            "semantic_relation": 4.64831,
            "contradiction": 0.09363,
            "irrelevancy": 98.39961,
            "logical_agreement": 1.50677,
            "grammar_ref": 5.10481,
            "grammar_hyp": 4.96482,
            "nubia_score": 0.88193
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2290": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.396650339471512,
        "bleu": 8.34891,
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.46914,
            "fmeasure": 0.52963
        },
        "rouge2": {
            "precision": 0.29412,
            "recall": 0.23449,
            "fmeasure": 0.26091
        },
        "rougeL": {
            "precision": 0.38889,
            "recall": 0.29854,
            "fmeasure": 0.33704
        },
        "rougeLsum": {
            "precision": 0.38889,
            "recall": 0.29854,
            "fmeasure": 0.33704
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5555555555555556
        },
        "bertscore": {
            "precision": 0.86835,
            "recall": 0.86713,
            "f1": 0.86774
        },
        "bleurt": -0.23362,
        "meteor": 0.23075477802494002,
        "nubia": {
            "semantic_relation": 3.31522,
            "contradiction": 0.53487,
            "irrelevancy": 91.25236,
            "logical_agreement": 8.21277,
            "grammar_ref": 3.13705,
            "grammar_hyp": 3.83778,
            "nubia_score": 0.47256
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1969": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9782162523044395,
        "bleu": 38.05803,
        "rouge1": {
            "precision": 0.63889,
            "recall": 0.64352,
            "fmeasure": 0.61111
        },
        "rouge2": {
            "precision": 0.39394,
            "recall": 0.4058,
            "fmeasure": 0.37874
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.64815,
            "fmeasure": 0.6
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.64815,
            "fmeasure": 0.6
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.90984,
            "recall": 0.92966,
            "f1": 0.90453
        },
        "bleurt": -0.03316,
        "meteor": 0.3747685405876764,
        "nubia": {
            "semantic_relation": 3.72839,
            "contradiction": 0.46033,
            "irrelevancy": 98.3843,
            "logical_agreement": 1.15536,
            "grammar_ref": 4.62828,
            "grammar_hyp": 4.95281,
            "nubia_score": 0.50491
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1260": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.16992500144231232,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.19264507794239588,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.19264507794239588,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644807,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.06146254768693421,
        "bleu": 17.44413,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.36745,
            "fmeasure": 0.52108
        },
        "rouge2": {
            "precision": 0.76488,
            "recall": 0.25226,
            "fmeasure": 0.37586
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.35634,
            "fmeasure": 0.50354
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.35634,
            "fmeasure": 0.50354
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.17647058823529413,
            "3": 0.42857142857142855
        },
        "bertscore": {
            "precision": 0.93581,
            "recall": 0.85184,
            "f1": 0.88584
        },
        "bleurt": -0.03635,
        "meteor": 0.21532524763289326,
        "nubia": {
            "semantic_relation": 3.87193,
            "contradiction": 0.16831,
            "irrelevancy": 1.30659,
            "logical_agreement": 98.5251,
            "grammar_ref": 3.63495,
            "grammar_hyp": 4.74868,
            "nubia_score": 0.53123
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2304": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 12,
        "unique-1": 10,
        "entropy-1": 3.521640636343319,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.055725754669781344,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.06303440583379405,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.22586761496920377,
        "bleu": 14.44374,
        "rouge1": {
            "precision": 0.84524,
            "recall": 0.46948,
            "fmeasure": 0.59641
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.31738,
            "fmeasure": 0.40926
        },
        "rougeL": {
            "precision": 0.84524,
            "recall": 0.46948,
            "fmeasure": 0.59641
        },
        "rougeLsum": {
            "precision": 0.84524,
            "recall": 0.46948,
            "fmeasure": 0.59641
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.47058823529411764
        },
        "bertscore": {
            "precision": 0.93853,
            "recall": 0.85063,
            "f1": 0.89177
        },
        "bleurt": 0.19109,
        "meteor": 0.26273487353217273,
        "nubia": {
            "semantic_relation": 3.88131,
            "contradiction": 44.41343,
            "irrelevancy": 18.27861,
            "logical_agreement": 37.30796,
            "grammar_ref": 3.80999,
            "grammar_hyp": 5.87157,
            "nubia_score": 0.47528
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1552": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4003450955050463,
        "bleu": 70.71068,
        "rouge1": {
            "precision": 0.87879,
            "recall": 0.85606,
            "fmeasure": 0.86693
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.71515,
            "fmeasure": 0.72381
        },
        "rougeL": {
            "precision": 0.87879,
            "recall": 0.85606,
            "fmeasure": 0.86693
        },
        "rougeLsum": {
            "precision": 0.87879,
            "recall": 0.85606,
            "fmeasure": 0.86693
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.98873,
            "recall": 0.98873,
            "f1": 0.98873
        },
        "bleurt": 0.64695,
        "meteor": 0.5306045115147152,
        "nubia": {
            "semantic_relation": 4.91147,
            "contradiction": 0.80604,
            "irrelevancy": 0.73693,
            "logical_agreement": 98.45703,
            "grammar_ref": 6.27756,
            "grammar_hyp": 6.43508,
            "nubia_score": 0.92052
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1560": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 3.5,
        "median_pred_length": 13.5,
        "min_pred_length": 10,
        "max_pred_length": 17,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 18,
        "unique-1": 10,
        "entropy-1": 4.060262039120378,
        "distinct-2": 0.84,
        "vocab_size-2": 21,
        "unique-2": 17,
        "entropy-2": 4.323856189774722,
        "cond_entropy-2": 0.2391641876977948,
        "distinct-3": 0.9130434782608695,
        "vocab_size-3": 21,
        "unique-3": 19,
        "entropy-3": 4.349648912578752,
        "cond_entropy-3": 0.05361880976054911,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.6956521739130435,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.8820451081368628,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.106603137064473,
        "cond_entropy-2-nopunct": 0.23803582396762696,
        "distinct-3-nopunct": 0.8947368421052632,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 4.03740119765411,
        "cond_entropy-3-nopunct": -0.03912675144043809,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1920393532631453,
        "bleu": 32.00323,
        "rouge1": {
            "precision": 0.71569,
            "recall": 0.67157,
            "fmeasure": 0.65648
        },
        "rouge2": {
            "precision": 0.44792,
            "recall": 0.41514,
            "fmeasure": 0.40528
        },
        "rougeL": {
            "precision": 0.63072,
            "recall": 0.6697,
            "fmeasure": 0.59847
        },
        "rougeLsum": {
            "precision": 0.63072,
            "recall": 0.6697,
            "fmeasure": 0.59847
        },
        "local_recall": {
            "1": 0.75,
            "2": 0.25,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.86906,
            "recall": 0.93134,
            "f1": 0.88557
        },
        "bleurt": 0.13227,
        "meteor": 0.41135210531224553,
        "nubia": {
            "semantic_relation": 3.8803,
            "contradiction": 11.35014,
            "irrelevancy": 37.47,
            "logical_agreement": 51.17986,
            "grammar_ref": 4.07172,
            "grammar_hyp": 4.96075,
            "nubia_score": 0.52034
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2313": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 1.5,
        "median_pred_length": 14.5,
        "min_pred_length": 13,
        "max_pred_length": 16,
        "distinct-1": 0.8620689655172413,
        "vocab_size-1": 25,
        "unique-1": 21,
        "entropy-1": 4.582118926162054,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.11912872925811885,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.88,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.403856189774722,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.14057533149967955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.10421643672562608,
        "bleu": 2.78266,
        "rouge1": {
            "precision": 0.62821,
            "recall": 0.30948,
            "fmeasure": 0.40388
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.1049,
            "fmeasure": 0.14276
        },
        "rougeL": {
            "precision": 0.34615,
            "recall": 0.17512,
            "fmeasure": 0.22737
        },
        "rougeLsum": {
            "precision": 0.34615,
            "recall": 0.17512,
            "fmeasure": 0.22737
        },
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.0,
            "3": 0.3235294117647059
        },
        "bertscore": {
            "precision": 0.85262,
            "recall": 0.81249,
            "f1": 0.82858
        },
        "bleurt": -0.65724,
        "meteor": 0.13127839145849038,
        "nubia": {
            "semantic_relation": 2.24624,
            "contradiction": 37.39289,
            "irrelevancy": 14.84268,
            "logical_agreement": 47.76443,
            "grammar_ref": 3.44707,
            "grammar_hyp": 4.80613,
            "nubia_score": 0.11872
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1773": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.7735572622751845,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.02810710212234295,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.1488309494220283,
        "bleu": 14.02578,
        "rouge1": {
            "precision": 0.30769,
            "recall": 0.58333,
            "fmeasure": 0.401
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.27143,
            "fmeasure": 0.17028
        },
        "rougeL": {
            "precision": 0.23077,
            "recall": 0.4375,
            "fmeasure": 0.30075
        },
        "rougeLsum": {
            "precision": 0.23077,
            "recall": 0.4375,
            "fmeasure": 0.30075
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.8
        },
        "bertscore": {
            "precision": 0.73892,
            "recall": 0.88773,
            "f1": 0.80652
        },
        "bleurt": -0.75195,
        "meteor": 0.25847121850646665,
        "nubia": {
            "semantic_relation": 2.81584,
            "contradiction": 4.2075,
            "irrelevancy": 95.47696,
            "logical_agreement": 0.31554,
            "grammar_ref": 7.18676,
            "grammar_hyp": 5.56351,
            "nubia_score": 0.34084
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1272": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 10,
        "unique-1": 8,
        "entropy-1": 3.180832987205441,
        "distinct-2": 0.9166666666666666,
        "vocab_size-2": 11,
        "unique-2": 10,
        "entropy-2": 3.418295834054489,
        "cond_entropy-2": 0.28076340776035325,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": 0.056287299734322706,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.0220552088742,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.2776134368191165,
        "cond_entropy-2-nopunct": 0.3067316181128199,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": 0.06249647625006499,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.8657143603310309,
        "bleu": 9.85908,
        "rouge1": {
            "precision": 0.53846,
            "recall": 0.46875,
            "fmeasure": 0.50064
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.21538,
            "fmeasure": 0.23111
        },
        "rougeL": {
            "precision": 0.53846,
            "recall": 0.46875,
            "fmeasure": 0.50064
        },
        "rougeLsum": {
            "precision": 0.53846,
            "recall": 0.46875,
            "fmeasure": 0.50064
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.375
        },
        "bertscore": {
            "precision": 0.93939,
            "recall": 0.91777,
            "f1": 0.92845
        },
        "bleurt": 0.49807,
        "meteor": 0.3608030154480774,
        "nubia": {
            "semantic_relation": 4.97006,
            "contradiction": 0.15257,
            "irrelevancy": 0.50623,
            "logical_agreement": 99.3412,
            "grammar_ref": 3.06207,
            "grammar_hyp": 3.38185,
            "nubia_score": 0.99557
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1573": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.991511658684707,
        "bleu": 3.7165,
        "rouge1": {
            "precision": 0.38095,
            "recall": 0.5303,
            "fmeasure": 0.44121
        },
        "rouge2": {
            "precision": 0.15385,
            "recall": 0.28571,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.4697,
            "fmeasure": 0.38788
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.4697,
            "fmeasure": 0.38788
        },
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.2857142857142857
        },
        "bertscore": {
            "precision": 0.75368,
            "recall": 0.7584,
            "f1": 0.75603
        },
        "bleurt": -0.97619,
        "meteor": 0.15827338129496404,
        "nubia": {
            "semantic_relation": 2.61744,
            "contradiction": 0.66647,
            "irrelevancy": 96.66171,
            "logical_agreement": 2.67182,
            "grammar_ref": 5.51883,
            "grammar_hyp": 5.27095,
            "nubia_score": 0.26677
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-base (Baseline)/e2e_nlg_test",
        "N": 737,
        "msttr-100": 0.29286,
        "msttr-100_nopunct": 0.28379,
        "total_length": 15421,
        "mean_pred_length": 20.92401628222524,
        "std_pred_length": 4.466936412300885,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 44,
        "distinct-1": 0.014720186758316581,
        "vocab_size-1": 227,
        "unique-1": 29,
        "entropy-1": 5.994835093991353,
        "distinct-2": 0.05543448651593571,
        "vocab_size-2": 814,
        "unique-2": 183,
        "entropy-2": 7.8944830532709185,
        "cond_entropy-2": 1.7914422518325415,
        "distinct-3": 0.101025310102531,
        "vocab_size-3": 1409,
        "unique-3": 386,
        "entropy-3": 8.94349569536517,
        "cond_entropy-3": 1.075732097394028,
        "total_length-nopunct": 14053,
        "mean_pred_length-nopunct": 19.067842605156038,
        "std_pred_length-nopunct": 4.041945584852928,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.015939657012737495,
        "vocab_size-1-nopunct": 224,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 6.041483501977882,
        "distinct-2-nopunct": 0.05782517272454191,
        "vocab_size-2-nopunct": 770,
        "unique-2-nopunct": 173,
        "entropy-2-nopunct": 7.821953470235807,
        "cond_entropy-2-nopunct": 1.8417583868120142,
        "distinct-3-nopunct": 0.10517529215358931,
        "vocab_size-3-nopunct": 1323,
        "unique-3-nopunct": 358,
        "entropy-3-nopunct": 8.916250588135089,
        "cond_entropy-3-nopunct": 1.094143667465636,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 4.57763011876337,
        "bleu": 27.66815,
        "rouge1": {
            "precision": 0.67832,
            "recall": 0.6627,
            "fmeasure": 0.65839
        },
        "rouge2": {
            "precision": 0.40512,
            "recall": 0.39527,
            "fmeasure": 0.39245
        },
        "rougeL": {
            "precision": 0.52692,
            "recall": 0.515,
            "fmeasure": 0.51166
        },
        "rougeLsum": {
            "precision": 0.52692,
            "recall": 0.515,
            "fmeasure": 0.51166
        },
        "local_recall": {
            "1": 0.6494126563092081
        },
        "bertscore": {
            "precision": 0.90601,
            "recall": 0.8966,
            "f1": 0.90079
        },
        "bleurt": 0.08727,
        "meteor": 0.3370567934928373,
        "nubia": {
            "semantic_relation": 3.97504,
            "contradiction": 5.16265,
            "irrelevancy": 43.76376,
            "logical_agreement": 51.07359,
            "grammar_ref": 4.94689,
            "grammar_hyp": 4.60737,
            "nubia_score": 0.68439
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1296": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966059,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964168,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.915557858577524,
        "bleu": 57.30574,
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.76781,
            "fmeasure": 0.80066
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.65278,
            "fmeasure": 0.61111
        },
        "rougeL": {
            "precision": 0.82051,
            "recall": 0.74929,
            "fmeasure": 0.77916
        },
        "rougeLsum": {
            "precision": 0.82051,
            "recall": 0.74929,
            "fmeasure": 0.77916
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.9514,
            "recall": 0.96739,
            "f1": 0.95933
        },
        "bleurt": -0.07928,
        "meteor": 0.48687087564906883,
        "nubia": {
            "semantic_relation": 3.99612,
            "contradiction": 2.77083,
            "irrelevancy": 94.75278,
            "logical_agreement": 2.47638,
            "grammar_ref": 5.3293,
            "grammar_hyp": 5.5786,
            "nubia_score": 0.54077
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1974": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 9.5,
        "std_pred_length": 0.5,
        "median_pred_length": 9.5,
        "min_pred_length": 9,
        "max_pred_length": 10,
        "distinct-1": 0.47368421052631576,
        "vocab_size-1": 9,
        "unique-1": 3,
        "entropy-1": 2.9847696187067436,
        "distinct-2": 0.5294117647058824,
        "vocab_size-2": 9,
        "unique-2": 3,
        "entropy-2": 3.0286393118385755,
        "cond_entropy-2": 0.0748294454538127,
        "distinct-3": 0.6,
        "vocab_size-3": 9,
        "unique-3": 3,
        "entropy-3": 3.106890595608519,
        "cond_entropy-3": 0.08609442102484582,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.47058823529411764,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 3,
        "entropy-1-nopunct": 2.793345194191516,
        "distinct-2-nopunct": 0.5333333333333333,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 3,
        "entropy-2-nopunct": 2.8402239289418523,
        "cond_entropy-2-nopunct": -0.0472389123084875,
        "distinct-3-nopunct": 0.6153846153846154,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 2.931208948910323,
        "cond_entropy-3-nopunct": -0.05260472362127268,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.451815875634701,
        "bleu": 69.05636,
        "rouge1": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "rouge2": {
            "precision": 0.79464,
            "recall": 0.72685,
            "fmeasure": 0.75776
        },
        "rougeL": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "rougeLsum": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "bertscore": {
            "precision": 0.98549,
            "recall": 0.97733,
            "f1": 0.98137
        },
        "bleurt": 0.78257,
        "meteor": 0.9489775258149422,
        "nubia": {
            "semantic_relation": 4.99611,
            "contradiction": 0.40178,
            "irrelevancy": 0.5141,
            "logical_agreement": 99.08412,
            "grammar_ref": 4.85767,
            "grammar_hyp": 5.20195,
            "nubia_score": 0.97201
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1302": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.16253715874966052,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.17355726227518528,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.7512922410496652,
        "bleu": 20.06086,
        "rouge1": {
            "precision": 0.8125,
            "recall": 0.5216,
            "fmeasure": 0.63488
        },
        "rouge2": {
            "precision": 0.53333,
            "recall": 0.33445,
            "fmeasure": 0.41078
        },
        "rougeL": {
            "precision": 0.6875,
            "recall": 0.48611,
            "fmeasure": 0.5693
        },
        "rougeLsum": {
            "precision": 0.6875,
            "recall": 0.48611,
            "fmeasure": 0.5693
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.4444444444444444
        },
        "bertscore": {
            "precision": 0.90549,
            "recall": 0.88355,
            "f1": 0.89358
        },
        "bleurt": -0.36542,
        "meteor": 0.2938308140290156,
        "nubia": {
            "semantic_relation": 3.98875,
            "contradiction": 0.931,
            "irrelevancy": 43.71435,
            "logical_agreement": 55.35464,
            "grammar_ref": 3.86337,
            "grammar_hyp": 4.29992,
            "nubia_score": 0.60938
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3016": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.8,
        "vocab_size-1": 8,
        "unique-1": 6,
        "entropy-1": 2.9219280948873623,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 8,
        "unique-2": 7,
        "entropy-2": 2.94770277922009,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": 0.08007499855768763,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.725480556997868,
        "distinct-2-nopunct": 0.875,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.75,
        "cond_entropy-2-nopunct": -0.04492500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.04978793508525296,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.47872969366552,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.9148,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.20451,
            "irrelevancy": 0.76191,
            "logical_agreement": 98.03358,
            "grammar_ref": 4.07249,
            "grammar_hyp": 4.01604,
            "nubia_score": 0.98068
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1782": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9417477137214867,
        "bleu": 31.15429,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.55749,
            "fmeasure": 0.56786
        },
        "rouge2": {
            "precision": 0.44118,
            "recall": 0.42411,
            "fmeasure": 0.43062
        },
        "rougeL": {
            "precision": 0.47222,
            "recall": 0.46658,
            "fmeasure": 0.46786
        },
        "rougeLsum": {
            "precision": 0.47222,
            "recall": 0.46658,
            "fmeasure": 0.46786
        },
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.7
        },
        "bertscore": {
            "precision": 0.87463,
            "recall": 0.87043,
            "f1": 0.87252
        },
        "bleurt": -0.4307,
        "meteor": 0.42613881754827315,
        "nubia": {
            "semantic_relation": 3.09363,
            "contradiction": 0.11834,
            "irrelevancy": 99.69257,
            "logical_agreement": 0.18909,
            "grammar_ref": 3.66593,
            "grammar_hyp": 3.50426,
            "nubia_score": 0.50361
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2385": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9047619047619048,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.201841232302569,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.129610672108602,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.1219280948873624,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.13652573434569687,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.886466696659778,
        "bleu": 26.15312,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.75185,
            "fmeasure": 0.72456
        },
        "rouge2": {
            "precision": 0.50877,
            "recall": 0.52735,
            "fmeasure": 0.51754
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.6037,
            "fmeasure": 0.59298
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.6037,
            "fmeasure": 0.59298
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6923076923076923
        },
        "bertscore": {
            "precision": 0.91809,
            "recall": 0.87927,
            "f1": 0.89826
        },
        "bleurt": 0.19022,
        "meteor": 0.37277449207452173,
        "nubia": {
            "semantic_relation": 4.00683,
            "contradiction": 0.86317,
            "irrelevancy": 86.21398,
            "logical_agreement": 12.92285,
            "grammar_ref": 4.59116,
            "grammar_hyp": 4.61617,
            "nubia_score": 0.629
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2392": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 2.8284271247461903,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 20,
        "distinct-1": 0.3958333333333333,
        "vocab_size-1": 19,
        "unique-1": 6,
        "entropy-1": 4.021240625180289,
        "distinct-2": 0.6,
        "vocab_size-2": 27,
        "unique-2": 19,
        "entropy-2": 4.4687619848339475,
        "cond_entropy-2": 0.4461053179749719,
        "distinct-3": 0.7380952380952381,
        "vocab_size-3": 31,
        "unique-3": 25,
        "entropy-3": 4.778640339187873,
        "cond_entropy-3": 0.3353372432702857,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 2.8284271247461903,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.41025641025641024,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.726582026055294,
        "distinct-2-nopunct": 0.6388888888888888,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.210777084415066,
        "cond_entropy-2-nopunct": 0.5260432688314001,
        "distinct-3-nopunct": 0.7575757575757576,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.468044119096216,
        "cond_entropy-3-nopunct": 0.24840396648840227,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.771677235109544,
        "bleu": 76.50014,
        "rouge1": {
            "precision": 0.91503,
            "recall": 0.86465,
            "fmeasure": 0.88689
        },
        "rouge2": {
            "precision": 0.79167,
            "recall": 0.76859,
            "fmeasure": 0.77889
        },
        "rougeL": {
            "precision": 0.86275,
            "recall": 0.82828,
            "fmeasure": 0.84377
        },
        "rougeLsum": {
            "precision": 0.86275,
            "recall": 0.82828,
            "fmeasure": 0.84377
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.7142857142857143,
            "3": 0.8888888888888888
        },
        "bertscore": {
            "precision": 0.96863,
            "recall": 0.96358,
            "f1": 0.96608
        },
        "bleurt": 0.76694,
        "meteor": 0.5181811970557166,
        "nubia": {
            "semantic_relation": 4.61223,
            "contradiction": 0.28763,
            "irrelevancy": 33.23765,
            "logical_agreement": 66.47472,
            "grammar_ref": 4.141,
            "grammar_hyp": 4.04707,
            "nubia_score": 0.88319
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2400": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.03775765163858,
        "bleu": 18.693,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.63636,
            "fmeasure": 0.56
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.4,
            "fmeasure": 0.34783
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.63636,
            "fmeasure": 0.56
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.63636,
            "fmeasure": 0.56
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.6
        },
        "bertscore": {
            "precision": 0.87437,
            "recall": 0.92239,
            "f1": 0.89774
        },
        "bleurt": 0.20823,
        "meteor": 0.36264188374589623,
        "nubia": {
            "semantic_relation": 4.28706,
            "contradiction": 0.41014,
            "irrelevancy": 99.34598,
            "logical_agreement": 0.24387,
            "grammar_ref": 5.42176,
            "grammar_hyp": 4.90088,
            "nubia_score": 0.70204
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1582": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 2.5,
        "median_pred_length": 16.5,
        "min_pred_length": 14,
        "max_pred_length": 19,
        "distinct-1": 0.9393939393939394,
        "vocab_size-1": 31,
        "unique-1": 29,
        "entropy-1": 4.923181998146335,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": -0.025681679939320093,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.09621531525930291,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.754887502163471,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": -0.11103131238874399,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.6841220623933975,
        "bleu": 66.37619,
        "rouge1": {
            "precision": 0.86364,
            "recall": 0.8303,
            "fmeasure": 0.84639
        },
        "rouge2": {
            "precision": 0.55,
            "recall": 0.51429,
            "fmeasure": 0.53148
        },
        "rougeL": {
            "precision": 0.68182,
            "recall": 0.64848,
            "fmeasure": 0.66458
        },
        "rougeLsum": {
            "precision": 0.68182,
            "recall": 0.64848,
            "fmeasure": 0.66458
        },
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.8461538461538461
        },
        "bertscore": {
            "precision": 0.95721,
            "recall": 0.95623,
            "f1": 0.95668
        },
        "bleurt": 0.644,
        "meteor": 0.47422359848407714,
        "nubia": {
            "semantic_relation": 4.80524,
            "contradiction": 0.21018,
            "irrelevancy": 46.81705,
            "logical_agreement": 52.97277,
            "grammar_ref": 3.76682,
            "grammar_hyp": 3.7855,
            "nubia_score": 0.96832
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3047": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.5769230769230769,
        "vocab_size-1": 15,
        "unique-1": 4,
        "entropy-1": 3.854285871987246,
        "distinct-2": 0.5833333333333334,
        "vocab_size-2": 14,
        "unique-2": 4,
        "entropy-2": 3.751629167387823,
        "cond_entropy-2": -0.11547721741993588,
        "distinct-3": 0.5909090909090909,
        "vocab_size-3": 13,
        "unique-3": 4,
        "entropy-3": 3.6412498004554794,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.5833333333333334,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 3.751629167387823,
        "distinct-2-nopunct": 0.5909090909090909,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 3.6412498004554794,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 0.6,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 3.521928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2544789837508556,
        "bleu": 82.65168,
        "rouge1": {
            "precision": 0.91667,
            "recall": 1.0,
            "fmeasure": 0.95652
        },
        "rouge2": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 1.0,
            "fmeasure": 0.95652
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 1.0,
            "fmeasure": 0.95652
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.94318,
            "recall": 0.98431,
            "f1": 0.9633
        },
        "bleurt": 0.56358,
        "meteor": 0.5690637876265101,
        "nubia": {
            "semantic_relation": 4.37248,
            "contradiction": 0.31688,
            "irrelevancy": 96.54524,
            "logical_agreement": 3.13788,
            "grammar_ref": 3.76088,
            "grammar_hyp": 3.47724,
            "nubia_score": 0.89041
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2422": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.14421971022094893,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.15283195745508585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.766108987608178,
        "bleu": 10.82259,
        "rouge1": {
            "precision": 0.68519,
            "recall": 0.79186,
            "fmeasure": 0.7318
        },
        "rouge2": {
            "precision": 0.31373,
            "recall": 0.36111,
            "fmeasure": 0.33438
        },
        "rougeL": {
            "precision": 0.51852,
            "recall": 0.59729,
            "fmeasure": 0.553
        },
        "rougeLsum": {
            "precision": 0.51852,
            "recall": 0.59729,
            "fmeasure": 0.553
        },
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.90898,
            "recall": 0.91729,
            "f1": 0.90244
        },
        "bleurt": 0.03682,
        "meteor": 0.3342479591621596,
        "nubia": {
            "semantic_relation": 3.82094,
            "contradiction": 4.66579,
            "irrelevancy": 92.67367,
            "logical_agreement": 2.66055,
            "grammar_ref": 5.01319,
            "grammar_hyp": 4.62159,
            "nubia_score": 0.57147
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1788": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.701890343613897,
        "bleu": 18.48652,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.64706,
            "fmeasure": 0.6875
        },
        "rouge2": {
            "precision": 0.35714,
            "recall": 0.3125,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.64706,
            "fmeasure": 0.6875
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.64706,
            "fmeasure": 0.6875
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7333333333333333
        },
        "bertscore": {
            "precision": 0.93197,
            "recall": 0.89349,
            "f1": 0.91233
        },
        "bleurt": 0.25732,
        "meteor": 0.37031302336613536,
        "nubia": {
            "semantic_relation": 3.76897,
            "contradiction": 0.54316,
            "irrelevancy": 3.61086,
            "logical_agreement": 95.84599,
            "grammar_ref": 4.8802,
            "grammar_hyp": 5.33471,
            "nubia_score": 0.54206
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1638": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.353995254377449,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.89781,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.40892,
            "irrelevancy": 0.54064,
            "logical_agreement": 99.05044,
            "grammar_ref": 4.6206,
            "grammar_hyp": 4.8105,
            "nubia_score": 0.99007
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1980": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8043533630124777,
        "bleu": 38.82727,
        "rouge1": {
            "precision": 0.93333,
            "recall": 1.0,
            "fmeasure": 0.96296
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.81905,
            "fmeasure": 0.76863
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.81905,
            "fmeasure": 0.76863
        },
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.95635,
            "recall": 0.92424,
            "f1": 0.94002
        },
        "bleurt": 0.39135,
        "meteor": 0.45626915779345323,
        "nubia": {
            "semantic_relation": 4.8136,
            "contradiction": 0.69691,
            "irrelevancy": 56.12808,
            "logical_agreement": 43.17501,
            "grammar_ref": 6.57473,
            "grammar_hyp": 4.94905,
            "nubia_score": 0.99874
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2040": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 1.5,
        "median_pred_length": 15.5,
        "min_pred_length": 14,
        "max_pred_length": 17,
        "distinct-1": 0.6774193548387096,
        "vocab_size-1": 21,
        "unique-1": 12,
        "entropy-1": 4.284683810317086,
        "distinct-2": 0.7586206896551724,
        "vocab_size-2": 22,
        "unique-2": 15,
        "entropy-2": 4.375222374437917,
        "cond_entropy-2": 0.06774632274633391,
        "distinct-3": 0.8148148148148148,
        "vocab_size-3": 22,
        "unique-3": 17,
        "entropy-3": 4.3845171317931,
        "cond_entropy-3": -0.029019418890029347,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.6896551724137931,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.21126073643228,
        "distinct-2-nopunct": 0.7777777777777778,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.310443057719025,
        "cond_entropy-2-nopunct": 0.07301345156046951,
        "distinct-3-nopunct": 0.84,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.323856189774723,
        "cond_entropy-3-nopunct": -0.031031312388743945,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.137364568985228,
        "bleu": 72.07387,
        "rouge1": {
            "precision": 0.98718,
            "recall": 0.94118,
            "fmeasure": 0.96208
        },
        "rouge2": {
            "precision": 0.84325,
            "recall": 0.8125,
            "fmeasure": 0.82609
        },
        "rougeL": {
            "precision": 0.88718,
            "recall": 0.85294,
            "fmeasure": 0.86833
        },
        "rougeLsum": {
            "precision": 0.88718,
            "recall": 0.85294,
            "fmeasure": 0.86833
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.75,
            "3": 0.9565217391304348
        },
        "bertscore": {
            "precision": 0.99064,
            "recall": 0.98861,
            "f1": 0.98962
        },
        "bleurt": 0.55567,
        "meteor": 0.5339831827968969,
        "nubia": {
            "semantic_relation": 4.78943,
            "contradiction": 0.24143,
            "irrelevancy": 32.88542,
            "logical_agreement": 66.87314,
            "grammar_ref": 4.08754,
            "grammar_hyp": 4.3519,
            "nubia_score": 0.89425
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3141": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9997292837160456,
        "bleu": 50.08718,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.68182,
            "fmeasure": 0.65217
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.4,
            "fmeasure": 0.38095
        },
        "rougeL": {
            "precision": 0.54167,
            "recall": 0.59091,
            "fmeasure": 0.56522
        },
        "rougeLsum": {
            "precision": 0.54167,
            "recall": 0.59091,
            "fmeasure": 0.56522
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.5714285714285714
        },
        "bertscore": {
            "precision": 0.88097,
            "recall": 0.89407,
            "f1": 0.88747
        },
        "bleurt": -0.17979,
        "meteor": 0.32475256955519033,
        "nubia": {
            "semantic_relation": 3.22419,
            "contradiction": 0.08178,
            "irrelevancy": 99.56479,
            "logical_agreement": 0.35343,
            "grammar_ref": 4.25346,
            "grammar_hyp": 3.90368,
            "nubia_score": 0.53738
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2080": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 28.0,
        "std_pred_length": 0.0,
        "median_pred_length": 28.0,
        "min_pred_length": 28,
        "max_pred_length": 28,
        "distinct-1": 0.7857142857142857,
        "vocab_size-1": 22,
        "unique-1": 17,
        "entropy-1": 4.351823225551767,
        "distinct-2": 0.9629629629629629,
        "vocab_size-2": 26,
        "unique-2": 25,
        "entropy-2": 4.6808134280893965,
        "cond_entropy-2": 0.34586174685265964,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": 0.02247529290070043,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.070656113151927,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.2673550472167754,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.585926742402555,
        "bleu": 15.44168,
        "rouge1": {
            "precision": 0.76,
            "recall": 0.56577,
            "fmeasure": 0.64704
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.3,
            "fmeasure": 0.33246
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.26724,
            "fmeasure": 0.29589
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.26724,
            "fmeasure": 0.29589
        },
        "local_recall": {
            "1": 0.3,
            "2": 0.8,
            "3": 0.45
        },
        "bertscore": {
            "precision": 0.85164,
            "recall": 0.81946,
            "f1": 0.83274
        },
        "bleurt": -0.30213,
        "meteor": 0.28135059296819537,
        "nubia": {
            "semantic_relation": 3.32526,
            "contradiction": 0.65688,
            "irrelevancy": 2.49751,
            "logical_agreement": 96.8456,
            "grammar_ref": 5.53052,
            "grammar_hyp": 3.72791,
            "nubia_score": 0.66923
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1792": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 1.0,
        "vocab_size-1": 20,
        "unique-1": 20,
        "entropy-1": 4.321928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.07400058144377676,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.247927513443583,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.07800251200127316,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.1338259274987,
        "bleu": 66.49438,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.77273,
            "fmeasure": 0.87179
        },
        "rouge2": {
            "precision": 0.85417,
            "recall": 0.65079,
            "fmeasure": 0.73874
        },
        "rougeL": {
            "precision": 0.94118,
            "recall": 0.72727,
            "fmeasure": 0.82051
        },
        "rougeLsum": {
            "precision": 0.94118,
            "recall": 0.72727,
            "fmeasure": 0.82051
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.75,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.97205,
            "recall": 0.93675,
            "f1": 0.95407
        },
        "bleurt": 0.05712,
        "meteor": 0.45532127755528956,
        "nubia": {
            "semantic_relation": 4.41068,
            "contradiction": 0.25383,
            "irrelevancy": 33.28628,
            "logical_agreement": 66.45989,
            "grammar_ref": 3.23206,
            "grammar_hyp": 3.26591,
            "nubia_score": 0.87103
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1800": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 2.0,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 20,
        "unique-1": 15,
        "entropy-1": 4.107010619399147,
        "distinct-2": 0.9615384615384616,
        "vocab_size-2": 25,
        "unique-2": 24,
        "entropy-2": 4.623516641218013,
        "cond_entropy-2": 0.4934555835618268,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.03214388408660255,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7083333333333334,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.8512274809529563,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.368522527728205,
        "cond_entropy-2-nopunct": 0.5839982303905416,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.037503523749935014,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.7692830471892043,
        "bleu": 32.91974,
        "rouge1": {
            "precision": 0.72593,
            "recall": 0.51923,
            "fmeasure": 0.59533
        },
        "rouge2": {
            "precision": 0.39286,
            "recall": 0.22,
            "fmeasure": 0.28205
        },
        "rougeL": {
            "precision": 0.67037,
            "recall": 0.46506,
            "fmeasure": 0.54064
        },
        "rougeLsum": {
            "precision": 0.67037,
            "recall": 0.46506,
            "fmeasure": 0.54064
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.89985,
            "recall": 0.85039,
            "f1": 0.87345
        },
        "bleurt": -0.23616,
        "meteor": 0.2606038900812762,
        "nubia": {
            "semantic_relation": 3.5052,
            "contradiction": 57.70713,
            "irrelevancy": 16.14798,
            "logical_agreement": 26.14488,
            "grammar_ref": 4.38763,
            "grammar_hyp": 4.01912,
            "nubia_score": 0.50124
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1809": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966059,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.7996845904759893,
        "bleu": 9.62994,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.30357,
            "fmeasure": 0.30842
        },
        "rouge2": {
            "precision": 0.11765,
            "recall": 0.11396,
            "fmeasure": 0.11212
        },
        "rougeL": {
            "precision": 0.30556,
            "recall": 0.28571,
            "fmeasure": 0.28668
        },
        "rougeLsum": {
            "precision": 0.30556,
            "recall": 0.28571,
            "fmeasure": 0.28668
        },
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.4444444444444444
        },
        "bertscore": {
            "precision": 0.80694,
            "recall": 0.80082,
            "f1": 0.80108
        },
        "bleurt": -0.11121,
        "meteor": 0.20218592338898117,
        "nubia": {
            "semantic_relation": 2.50928,
            "contradiction": 9.79456,
            "irrelevancy": 85.95607,
            "logical_agreement": 4.24938,
            "grammar_ref": 3.10421,
            "grammar_hyp": 3.1709,
            "nubia_score": 0.27805
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1640": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9767865386982915,
        "bleu": 59.00962,
        "rouge1": {
            "precision": 0.92105,
            "recall": 0.875,
            "fmeasure": 0.89744
        },
        "rouge2": {
            "precision": 0.72222,
            "recall": 0.68421,
            "fmeasure": 0.7027
        },
        "rougeL": {
            "precision": 0.71053,
            "recall": 0.675,
            "fmeasure": 0.69231
        },
        "rougeLsum": {
            "precision": 0.71053,
            "recall": 0.675,
            "fmeasure": 0.69231
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.9375
        },
        "bertscore": {
            "precision": 0.94263,
            "recall": 0.95072,
            "f1": 0.94666
        },
        "bleurt": 0.3887,
        "meteor": 0.47928551418313564,
        "nubia": {
            "semantic_relation": 4.87887,
            "contradiction": 0.22901,
            "irrelevancy": 0.47504,
            "logical_agreement": 99.29595,
            "grammar_ref": 4.55046,
            "grammar_hyp": 4.72911,
            "nubia_score": 0.91093
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2104": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.09447391714623149,
        "bleu": 6.39871,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.32639,
            "fmeasure": 0.46898
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.20952,
            "fmeasure": 0.31053
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.32026,
            "fmeasure": 0.46239
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.32026,
            "fmeasure": 0.46239
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "bertscore": {
            "precision": 0.87103,
            "recall": 0.75728,
            "f1": 0.80848
        },
        "bleurt": -0.52332,
        "meteor": 0.18053128723363673,
        "nubia": {
            "semantic_relation": 3.66161,
            "contradiction": 0.72243,
            "irrelevancy": 1.40121,
            "logical_agreement": 97.87636,
            "grammar_ref": 4.68072,
            "grammar_hyp": 6.43651,
            "nubia_score": 0.42823
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1820": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.0005299062814954,
        "bleu": 17.70204,
        "rouge1": {
            "precision": 0.40476,
            "recall": 0.61111,
            "fmeasure": 0.47858
        },
        "rouge2": {
            "precision": 0.23077,
            "recall": 0.35714,
            "fmeasure": 0.27407
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.52778,
            "fmeasure": 0.41797
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.52778,
            "fmeasure": 0.41797
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "bertscore": {
            "precision": 0.84043,
            "recall": 0.93102,
            "f1": 0.88341
        },
        "bleurt": -0.47557,
        "meteor": 0.30902148240347416,
        "nubia": {
            "semantic_relation": 3.50774,
            "contradiction": 0.32707,
            "irrelevancy": 99.53977,
            "logical_agreement": 0.13316,
            "grammar_ref": 4.70243,
            "grammar_hyp": 5.00925,
            "nubia_score": 0.44421
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2112": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0881978509745025,
        "bleu": 68.94026,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.5873,
            "fmeasure": 0.65152
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.98644,
            "recall": 0.96366,
            "f1": 0.97492
        },
        "bleurt": 0.64449,
        "meteor": 0.81809314801268,
        "nubia": {
            "semantic_relation": 4.6318,
            "contradiction": 0.66466,
            "irrelevancy": 0.56229,
            "logical_agreement": 98.77305,
            "grammar_ref": 5.07671,
            "grammar_hyp": 5.29413,
            "nubia_score": 0.85198
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2123": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.179158422000987,
        "bleu": 50.78432,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.62465,
            "fmeasure": 0.69142
        },
        "rouge2": {
            "precision": 0.69697,
            "recall": 0.51282,
            "fmeasure": 0.58951
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.62465,
            "fmeasure": 0.69142
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.62465,
            "fmeasure": 0.69142
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6923076923076923
        },
        "bertscore": {
            "precision": 0.96075,
            "recall": 0.91274,
            "f1": 0.92047
        },
        "bleurt": 0.05546,
        "meteor": 0.3876669651197313,
        "nubia": {
            "semantic_relation": 3.83539,
            "contradiction": 27.20618,
            "irrelevancy": 67.00664,
            "logical_agreement": 5.78718,
            "grammar_ref": 4.48877,
            "grammar_hyp": 4.52277,
            "nubia_score": 0.58167
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2490": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.9722195534156317,
        "bleu": 8.6979,
        "rouge1": {
            "precision": 0.35714,
            "recall": 0.34194,
            "fmeasure": 0.32593
        },
        "rouge2": {
            "precision": 0.07692,
            "recall": 0.08519,
            "fmeasure": 0.07611
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.16129,
            "fmeasure": 0.22222
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.16129,
            "fmeasure": 0.22222
        },
        "local_recall": {
            "1": 1.0,
            "2": 0.2857142857142857,
            "3": 0.3333333333333333
        },
        "bertscore": {
            "precision": 0.85116,
            "recall": 0.77408,
            "f1": 0.80695
        },
        "bleurt": -0.429,
        "meteor": 0.11719349583040845,
        "nubia": {
            "semantic_relation": 1.60503,
            "contradiction": 66.12905,
            "irrelevancy": 25.53023,
            "logical_agreement": 8.34072,
            "grammar_ref": 4.34568,
            "grammar_hyp": 3.86986,
            "nubia_score": 0.10127
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2148": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.5209521882110533,
        "bleu": 25.23283,
        "rouge1": {
            "precision": 0.94118,
            "recall": 0.6689,
            "fmeasure": 0.7814
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.43636,
            "fmeasure": 0.51348
        },
        "rougeL": {
            "precision": 0.82353,
            "recall": 0.58528,
            "fmeasure": 0.68372
        },
        "rougeLsum": {
            "precision": 0.82353,
            "recall": 0.58528,
            "fmeasure": 0.68372
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6190476190476191
        },
        "bertscore": {
            "precision": 0.95943,
            "recall": 0.88498,
            "f1": 0.9207
        },
        "bleurt": 0.48812,
        "meteor": 0.37315910513729983,
        "nubia": {
            "semantic_relation": 4.58621,
            "contradiction": 0.14856,
            "irrelevancy": 0.41863,
            "logical_agreement": 99.43281,
            "grammar_ref": 3.26294,
            "grammar_hyp": 2.92705,
            "nubia_score": 0.96456
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1824": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 39.0,
        "std_pred_length": 0.0,
        "median_pred_length": 39.0,
        "min_pred_length": 39,
        "max_pred_length": 39,
        "distinct-1": 0.5897435897435898,
        "vocab_size-1": 23,
        "unique-1": 10,
        "entropy-1": 4.394251257268314,
        "distinct-2": 0.7631578947368421,
        "vocab_size-2": 29,
        "unique-2": 20,
        "entropy-2": 4.77424330291727,
        "cond_entropy-2": 0.36173384725087165,
        "distinct-3": 0.7837837837837838,
        "vocab_size-3": 29,
        "unique-3": 21,
        "entropy-3": 4.77702093319652,
        "cond_entropy-3": 0.015579906239418094,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 32.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 32.0,
        "min_pred_length-nopunct": 32,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.59375,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 4.125,
        "distinct-2-nopunct": 0.7096774193548387,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 4.373551149096553,
        "cond_entropy-2-nopunct": 0.24451889103203658,
        "distinct-3-nopunct": 0.7333333333333333,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 4.373557262275185,
        "cond_entropy-3-nopunct": -0.01397238144502348,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.1841938575051616,
        "bleu": 27.28701,
        "rouge1": {
            "precision": 0.53571,
            "recall": 0.76842,
            "fmeasure": 0.63121
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.56725,
            "fmeasure": 0.46135
        },
        "rougeL": {
            "precision": 0.53571,
            "recall": 0.76842,
            "fmeasure": 0.63121
        },
        "rougeLsum": {
            "precision": 0.53571,
            "recall": 0.76842,
            "fmeasure": 0.63121
        },
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.5714285714285714
        },
        "bertscore": {
            "precision": 0.81691,
            "recall": 0.89203,
            "f1": 0.85282
        },
        "bleurt": -0.30398,
        "meteor": 0.32339325633497085,
        "nubia": {
            "semantic_relation": 4.73738,
            "contradiction": 0.895,
            "irrelevancy": 40.55575,
            "logical_agreement": 58.54926,
            "grammar_ref": 4.38153,
            "grammar_hyp": 3.90596,
            "nubia_score": 0.41982
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2205": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8483609718589222,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.90755,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.37344,
            "irrelevancy": 0.48743,
            "logical_agreement": 99.13913,
            "grammar_ref": 6.21263,
            "grammar_hyp": 6.40603,
            "nubia_score": 0.97334
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2640": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4929182263680483,
        "bleu": 19.43406,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.72727,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.4,
            "fmeasure": 0.44444
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6363636363636364
        },
        "bertscore": {
            "precision": 0.96843,
            "recall": 0.92985,
            "f1": 0.94874
        },
        "bleurt": 0.5593,
        "meteor": 0.38388402914845343,
        "nubia": {
            "semantic_relation": 4.25211,
            "contradiction": 0.57776,
            "irrelevancy": 0.52541,
            "logical_agreement": 98.89683,
            "grammar_ref": 5.20642,
            "grammar_hyp": 4.57554,
            "nubia_score": 0.83281
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3204": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 12,
        "unique-1": 10,
        "entropy-1": 3.521640636343319,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.2007771037757955,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.21785611591339743,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5018922921767515,
        "bleu": 72.8596,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.92308,
            "fmeasure": 0.92308
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.83333,
            "fmeasure": 0.83333
        },
        "rougeL": {
            "precision": 0.92308,
            "recall": 0.92308,
            "fmeasure": 0.92308
        },
        "rougeLsum": {
            "precision": 0.92308,
            "recall": 0.92308,
            "fmeasure": 0.92308
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "bertscore": {
            "precision": 0.98725,
            "recall": 0.9597,
            "f1": 0.97328
        },
        "bleurt": 0.84323,
        "meteor": 0.5191093433145909,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 2.33141,
            "irrelevancy": 0.80416,
            "logical_agreement": 96.86442,
            "grammar_ref": 3.94537,
            "grammar_hyp": 3.99145,
            "nubia_score": 0.98622
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2667": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 10.5,
        "std_pred_length": 1.5,
        "median_pred_length": 10.5,
        "min_pred_length": 9,
        "max_pred_length": 12,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 14,
        "unique-1": 7,
        "entropy-1": 3.7256507561120933,
        "distinct-2": 0.7368421052631579,
        "vocab_size-2": 14,
        "unique-2": 9,
        "entropy-2": 3.7216117239699007,
        "cond_entropy-2": -0.03912675144043809,
        "distinct-3": 0.8235294117647058,
        "vocab_size-3": 14,
        "unique-3": 11,
        "entropy-3": 3.734521664779752,
        "cond_entropy-3": -0.042817613369716706,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.6842105263157895,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.616348566075164,
        "distinct-2-nopunct": 0.7647058823529411,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.6168746059562227,
        "cond_entropy-2-nopunct": -0.04281761336971671,
        "distinct-3-nopunct": 0.8666666666666667,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.640223928941851,
        "cond_entropy-3-nopunct": -0.04723891230848748,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.0940903513621185,
        "bleu": 58.30738,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.94444,
            "fmeasure": 0.97059
        },
        "rouge2": {
            "precision": 0.72857,
            "recall": 0.69722,
            "fmeasure": 0.71053
        },
        "rougeL": {
            "precision": 0.86364,
            "recall": 0.80808,
            "fmeasure": 0.83422
        },
        "rougeLsum": {
            "precision": 0.86364,
            "recall": 0.80808,
            "fmeasure": 0.83422
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.98779,
            "recall": 0.98124,
            "f1": 0.98272
        },
        "bleurt": 0.79948,
        "meteor": 0.49092678627539355,
        "nubia": {
            "semantic_relation": 4.99837,
            "contradiction": 0.4857,
            "irrelevancy": 8.63101,
            "logical_agreement": 90.88329,
            "grammar_ref": 4.57714,
            "grammar_hyp": 4.76708,
            "nubia_score": 0.97498
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5094": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.036680632058506,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.93333,
            "fmeasure": 0.96296
        },
        "rouge2": {
            "precision": 0.95238,
            "recall": 0.88889,
            "fmeasure": 0.91667
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.93333,
            "fmeasure": 0.96296
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.93333,
            "fmeasure": 0.96296
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.67104,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.48528,
            "contradiction": 2.29987,
            "irrelevancy": 0.99674,
            "logical_agreement": 96.70339,
            "grammar_ref": 4.01433,
            "grammar_hyp": 4.43425,
            "nubia_score": 0.78188
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2681": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.031262576450960096,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.988477286463126,
        "bleu": 19.49625,
        "rouge1": {
            "precision": 0.7037,
            "recall": 0.71678,
            "fmeasure": 0.71005
        },
        "rouge2": {
            "precision": 0.35294,
            "recall": 0.36765,
            "fmeasure": 0.36007
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.51961,
            "fmeasure": 0.50952
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.51961,
            "fmeasure": 0.50952
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.6470588235294118
        },
        "bertscore": {
            "precision": 0.89358,
            "recall": 0.90429,
            "f1": 0.89891
        },
        "bleurt": 0.20889,
        "meteor": 0.34906325128091836,
        "nubia": {
            "semantic_relation": 3.94635,
            "contradiction": 0.24696,
            "irrelevancy": 86.73263,
            "logical_agreement": 13.02042,
            "grammar_ref": 4.84215,
            "grammar_hyp": 4.14996,
            "nubia_score": 0.69312
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5166": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.9313738634396848,
        "bleu": 8.29519,
        "rouge1": {
            "precision": 0.4,
            "recall": 0.35354,
            "fmeasure": 0.37518
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.19394,
            "fmeasure": 0.20702
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.35354,
            "fmeasure": 0.37518
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.35354,
            "fmeasure": 0.37518
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.2222222222222222
        },
        "bertscore": {
            "precision": 0.79602,
            "recall": 0.78154,
            "f1": 0.78871
        },
        "bleurt": -0.53575,
        "meteor": 0.2331715255855191,
        "nubia": {
            "semantic_relation": 2.78899,
            "contradiction": 0.29727,
            "irrelevancy": 97.22608,
            "logical_agreement": 2.47665,
            "grammar_ref": 4.79209,
            "grammar_hyp": 3.90146,
            "nubia_score": 0.40056
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2232": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.688682921318198,
        "bleu": 35.99727,
        "rouge1": {
            "precision": 0.4902,
            "recall": 0.47059,
            "fmeasure": 0.48011
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.33053,
            "fmeasure": 0.35053
        },
        "rougeL": {
            "precision": 0.4902,
            "recall": 0.47059,
            "fmeasure": 0.48011
        },
        "rougeLsum": {
            "precision": 0.4902,
            "recall": 0.47059,
            "fmeasure": 0.48011
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.1111111111111111,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.86555,
            "recall": 0.8989,
            "f1": 0.88191
        },
        "bleurt": -0.70761,
        "meteor": 0.2729825866684779,
        "nubia": {
            "semantic_relation": 2.99743,
            "contradiction": 68.22051,
            "irrelevancy": 31.10766,
            "logical_agreement": 0.67183,
            "grammar_ref": 5.24053,
            "grammar_hyp": 5.59498,
            "nubia_score": 0.28507
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3222": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.188721875540867,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.3067316181128199,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.027169118440619,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.3379852264664119,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9105250180801645,
        "bleu": 62.207,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.72751,
            "fmeasure": 0.83954
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.51584,
            "fmeasure": 0.60333
        },
        "rougeL": {
            "precision": 0.93939,
            "recall": 0.51704,
            "fmeasure": 0.66347
        },
        "rougeLsum": {
            "precision": 0.93939,
            "recall": 0.51704,
            "fmeasure": 0.66347
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "bertscore": {
            "precision": 0.96167,
            "recall": 0.90351,
            "f1": 0.93168
        },
        "bleurt": -0.14434,
        "meteor": 0.3977613383709655,
        "nubia": {
            "semantic_relation": 3.27646,
            "contradiction": 93.29798,
            "irrelevancy": 1.81369,
            "logical_agreement": 4.88833,
            "grammar_ref": 3.09217,
            "grammar_hyp": 2.87496,
            "nubia_score": 0.56072
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5360": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.886341699752534,
        "bleu": 41.25398,
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.71852,
            "fmeasure": 0.77143
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.37473,
            "fmeasure": 0.39886
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.61481,
            "fmeasure": 0.65714
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.61481,
            "fmeasure": 0.65714
        },
        "local_recall": {
            "1": 0,
            "2": 0.2857142857142857,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.96015,
            "recall": 0.93128,
            "f1": 0.94549
        },
        "bleurt": 0.41749,
        "meteor": 0.39519209321630533,
        "nubia": {
            "semantic_relation": 4.63784,
            "contradiction": 0.53526,
            "irrelevancy": 0.58276,
            "logical_agreement": 98.88198,
            "grammar_ref": 3.74426,
            "grammar_hyp": 3.98157,
            "nubia_score": 0.89439
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2682": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.13652573434569687,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.15283195745508585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7270111845199487,
        "bleu": 14.02578,
        "rouge1": {
            "precision": 0.68519,
            "recall": 0.83968,
            "fmeasure": 0.75442
        },
        "rouge2": {
            "precision": 0.2549,
            "recall": 0.31502,
            "fmeasure": 0.28172
        },
        "rougeL": {
            "precision": 0.42593,
            "recall": 0.52222,
            "fmeasure": 0.46907
        },
        "rougeLsum": {
            "precision": 0.42593,
            "recall": 0.52222,
            "fmeasure": 0.46907
        },
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 1.0,
            "3": 0.9
        },
        "bertscore": {
            "precision": 0.88805,
            "recall": 0.90295,
            "f1": 0.88817
        },
        "bleurt": 0.20683,
        "meteor": 0.38978154361127293,
        "nubia": {
            "semantic_relation": 4.04726,
            "contradiction": 3.77728,
            "irrelevancy": 59.04767,
            "logical_agreement": 37.17505,
            "grammar_ref": 4.11472,
            "grammar_hyp": 3.00796,
            "nubia_score": 0.8498
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3432": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9446616610533678,
        "bleu": 31.98048,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.62222,
            "fmeasure": 0.73016
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.45887,
            "fmeasure": 0.54226
        },
        "rougeL": {
            "precision": 0.81481,
            "recall": 0.57778,
            "fmeasure": 0.6746
        },
        "rougeLsum": {
            "precision": 0.81481,
            "recall": 0.57778,
            "fmeasure": 0.6746
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.93873,
            "recall": 0.87074,
            "f1": 0.90346
        },
        "bleurt": 0.2729,
        "meteor": 0.3613362424002765,
        "nubia": {
            "semantic_relation": 4.47767,
            "contradiction": 0.28392,
            "irrelevancy": 0.721,
            "logical_agreement": 98.99508,
            "grammar_ref": 4.47457,
            "grammar_hyp": 5.02376,
            "nubia_score": 0.84041
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2718": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3219280948873626,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.97683,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29478,
            "irrelevancy": 0.49577,
            "logical_agreement": 99.20945,
            "grammar_ref": 4.98947,
            "grammar_hyp": 4.98947,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1836": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.9057645846554525,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.19723710464117222,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.0571233370405895,
        "bleu": 10.58447,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.48667,
            "fmeasure": 0.5982
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.18254,
            "fmeasure": 0.22256
        },
        "rougeL": {
            "precision": 0.46667,
            "recall": 0.30545,
            "fmeasure": 0.36892
        },
        "rougeLsum": {
            "precision": 0.46667,
            "recall": 0.30545,
            "fmeasure": 0.36892
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.47368421052631576
        },
        "bertscore": {
            "precision": 0.89107,
            "recall": 0.84186,
            "f1": 0.86577
        },
        "bleurt": -0.41213,
        "meteor": 0.22702393500841556,
        "nubia": {
            "semantic_relation": 3.90224,
            "contradiction": 0.38858,
            "irrelevancy": 98.42229,
            "logical_agreement": 1.18913,
            "grammar_ref": 4.82125,
            "grammar_hyp": 4.99977,
            "nubia_score": 0.52159
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5418": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518525,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.640223928941851,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.18617861216337134,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.991401229002271,
        "bleu": 15.73796,
        "rouge1": {
            "precision": 0.63333,
            "recall": 0.36232,
            "fmeasure": 0.45906
        },
        "rouge2": {
            "precision": 0.35714,
            "recall": 0.19436,
            "fmeasure": 0.25065
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.34565,
            "fmeasure": 0.43684
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.34565,
            "fmeasure": 0.43684
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.42105263157894735
        },
        "bertscore": {
            "precision": 0.89837,
            "recall": 0.81808,
            "f1": 0.85635
        },
        "bleurt": -0.2063,
        "meteor": 0.19574236130540607,
        "nubia": {
            "semantic_relation": 3.91264,
            "contradiction": 0.72404,
            "irrelevancy": 1.86882,
            "logical_agreement": 97.40713,
            "grammar_ref": 4.294,
            "grammar_hyp": 4.79751,
            "nubia_score": 0.54015
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1840": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 1.00232,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.55079,
            "irrelevancy": 0.53693,
            "logical_agreement": 98.91228,
            "grammar_ref": 4.38626,
            "grammar_hyp": 4.38626,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2884": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 12,
        "unique-1": 10,
        "entropy-1": 3.521640636343319,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.2007771037757955,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.21785611591339746,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.0600905711694244,
        "bleu": 5.85516,
        "rouge1": {
            "precision": 0.23077,
            "recall": 0.2,
            "fmeasure": 0.21429
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.07143,
            "fmeasure": 0.07692
        },
        "rougeL": {
            "precision": 0.23077,
            "recall": 0.2,
            "fmeasure": 0.21429
        },
        "rougeLsum": {
            "precision": 0.23077,
            "recall": 0.2,
            "fmeasure": 0.21429
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.25
        },
        "bertscore": {
            "precision": 0.79252,
            "recall": 0.78006,
            "f1": 0.78334
        },
        "bleurt": -0.34068,
        "meteor": 0.11705853950642585,
        "nubia": {
            "semantic_relation": 2.19814,
            "contradiction": 0.37339,
            "irrelevancy": 99.29582,
            "logical_agreement": 0.33079,
            "grammar_ref": 5.48676,
            "grammar_hyp": 4.70782,
            "nubia_score": 0.20289
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3479": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 1.0,
        "vocab_size-1": 22,
        "unique-1": 22,
        "entropy-1": 4.459431618637295,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": -0.06711419585853673,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.07400058144377676,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.664135019007784,
        "bleu": 39.04439,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.77632,
            "fmeasure": 0.76282
        },
        "rouge2": {
            "precision": 0.45614,
            "recall": 0.47368,
            "fmeasure": 0.46468
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.72456,
            "fmeasure": 0.71197
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.72456,
            "fmeasure": 0.71197
        },
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "bertscore": {
            "precision": 0.94173,
            "recall": 0.94398,
            "f1": 0.94286
        },
        "bleurt": 0.55355,
        "meteor": 0.40194593927160005,
        "nubia": {
            "semantic_relation": 4.75687,
            "contradiction": 0.44649,
            "irrelevancy": 0.60729,
            "logical_agreement": 98.94622,
            "grammar_ref": 4.62058,
            "grammar_hyp": 4.53002,
            "nubia_score": 0.90399
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1878": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 2.5,
        "median_pred_length": 15.5,
        "min_pred_length": 13,
        "max_pred_length": 18,
        "distinct-1": 0.9032258064516129,
        "vocab_size-1": 28,
        "unique-1": 26,
        "entropy-1": 4.7362967135428935,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.06774632274633388,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.6375375112660535,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.07596508462823659,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.921291096620022,
        "bleu": 21.95745,
        "rouge1": {
            "precision": 0.7496,
            "recall": 0.58312,
            "fmeasure": 0.64867
        },
        "rouge2": {
            "precision": 0.41852,
            "recall": 0.33824,
            "fmeasure": 0.36988
        },
        "rougeL": {
            "precision": 0.45534,
            "recall": 0.35192,
            "fmeasure": 0.39259
        },
        "rougeLsum": {
            "precision": 0.45534,
            "recall": 0.35192,
            "fmeasure": 0.39259
        },
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.6333333333333333
        },
        "bertscore": {
            "precision": 0.91425,
            "recall": 0.89209,
            "f1": 0.90183
        },
        "bleurt": 0.25739,
        "meteor": 0.3444005746599896,
        "nubia": {
            "semantic_relation": 4.24237,
            "contradiction": 16.51165,
            "irrelevancy": 8.3301,
            "logical_agreement": 75.15825,
            "grammar_ref": 4.13564,
            "grammar_hyp": 4.56668,
            "nubia_score": 0.67525
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3492": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0088906840841796,
        "bleu": 58.33511,
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.63636,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8181818181818182
        },
        "bertscore": {
            "precision": 0.97213,
            "recall": 0.96481,
            "f1": 0.96846
        },
        "bleurt": 0.7528,
        "meteor": 0.4630505936482093,
        "nubia": {
            "semantic_relation": 4.98921,
            "contradiction": 0.42473,
            "irrelevancy": 22.33974,
            "logical_agreement": 77.23553,
            "grammar_ref": 4.14586,
            "grammar_hyp": 3.79251,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2940": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.5769230769230769,
        "vocab_size-1": 15,
        "unique-1": 4,
        "entropy-1": 3.854285871987246,
        "distinct-2": 0.5833333333333334,
        "vocab_size-2": 14,
        "unique-2": 4,
        "entropy-2": 3.751629167387823,
        "cond_entropy-2": -0.11547721741993588,
        "distinct-3": 0.5909090909090909,
        "vocab_size-3": 13,
        "unique-3": 4,
        "entropy-3": 3.6412498004554794,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.5909090909090909,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 3.6412498004554794,
        "distinct-2-nopunct": 0.6,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 3.521928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 0.6111111111111112,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 3.392147223664534,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.854285871987245,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.94692,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.32615,
            "irrelevancy": 0.47325,
            "logical_agreement": 99.2006,
            "grammar_ref": 5.00662,
            "grammar_hyp": 5.00662,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5455": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.616961879953846,
        "bleu": 74.19447,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 0.90909,
            "recall": 0.90909,
            "fmeasure": 0.90909
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.83333,
            "fmeasure": 0.83333
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.83333,
            "fmeasure": 0.83333
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.96124,
            "recall": 0.96353,
            "f1": 0.96239
        },
        "bleurt": 0.65172,
        "meteor": 0.549453875996166,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.24117,
            "irrelevancy": 0.43431,
            "logical_agreement": 99.32451,
            "grammar_ref": 4.72684,
            "grammar_hyp": 4.55935,
            "nubia_score": 0.9976
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3540": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.1126567718249225,
        "bleu": 84.64817,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.82143,
            "fmeasure": 0.9011
        },
        "rouge2": {
            "precision": 0.93333,
            "recall": 0.74603,
            "fmeasure": 0.82828
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.82143,
            "fmeasure": 0.9011
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.82143,
            "fmeasure": 0.9011
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "bertscore": {
            "precision": 0.97931,
            "recall": 0.9326,
            "f1": 0.95538
        },
        "bleurt": -0.15862,
        "meteor": 0.507208078598044,
        "nubia": {
            "semantic_relation": 3.69006,
            "contradiction": 0.31517,
            "irrelevancy": 0.57051,
            "logical_agreement": 99.11432,
            "grammar_ref": 6.37596,
            "grammar_hyp": 5.64518,
            "nubia_score": 0.75233
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1890": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.0433214693062285,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.046930949929641655,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.376541167720662,
        "bleu": 11.72655,
        "rouge1": {
            "precision": 0.78571,
            "recall": 0.64706,
            "fmeasure": 0.70968
        },
        "rouge2": {
            "precision": 0.23077,
            "recall": 0.1875,
            "fmeasure": 0.2069
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.35294,
            "fmeasure": 0.3871
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.35294,
            "fmeasure": 0.3871
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "bertscore": {
            "precision": 0.91617,
            "recall": 0.88913,
            "f1": 0.90245
        },
        "bleurt": 0.17978,
        "meteor": 0.26967068956458207,
        "nubia": {
            "semantic_relation": 3.37984,
            "contradiction": 72.63476,
            "irrelevancy": 13.29336,
            "logical_agreement": 14.07188,
            "grammar_ref": 4.71038,
            "grammar_hyp": 4.73068,
            "nubia_score": 0.41349
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2233": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.190572262757721,
        "bleu": 100.0,
        "rouge1": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "rouge2": {
            "precision": 0.85,
            "recall": 0.81818,
            "fmeasure": 0.83333
        },
        "rougeL": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "rougeLsum": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.83087,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.98748,
            "contradiction": 0.44405,
            "irrelevancy": 0.50174,
            "logical_agreement": 99.05421,
            "grammar_ref": 4.19853,
            "grammar_hyp": 3.68353,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3546": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4052088690524895,
        "bleu": 17.31747,
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.875,
            "fmeasure": 0.90323
        },
        "rouge2": {
            "precision": 0.47619,
            "recall": 0.49231,
            "fmeasure": 0.48361
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.34226,
            "fmeasure": 0.33741
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.34226,
            "fmeasure": 0.33741
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7272727272727273
        },
        "bertscore": {
            "precision": 0.89853,
            "recall": 0.89961,
            "f1": 0.89907
        },
        "bleurt": -0.22161,
        "meteor": 0.37239613830825974,
        "nubia": {
            "semantic_relation": 4.40134,
            "contradiction": 0.28662,
            "irrelevancy": 33.62168,
            "logical_agreement": 66.09171,
            "grammar_ref": 4.41465,
            "grammar_hyp": 5.63693,
            "nubia_score": 0.63015
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5538": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.32249814589546,
        "bleu": 41.10546,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.47222,
            "fmeasure": 0.55238
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5555555555555556
        },
        "bertscore": {
            "precision": 0.96587,
            "recall": 0.9307,
            "f1": 0.94796
        },
        "bleurt": 0.65075,
        "meteor": 0.8569614896318238,
        "nubia": {
            "semantic_relation": 4.62868,
            "contradiction": 0.5038,
            "irrelevancy": 0.54324,
            "logical_agreement": 98.95296,
            "grammar_ref": 4.24503,
            "grammar_hyp": 4.03961,
            "nubia_score": 0.96227
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3591": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8465578035643277,
        "bleu": 100.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.87565,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.69325,
            "irrelevancy": 0.54497,
            "logical_agreement": 98.76179,
            "grammar_ref": 7.00423,
            "grammar_hyp": 7.45225,
            "nubia_score": 0.93405
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5550": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.7684879138581233,
        "bleu": 39.23542,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.66667,
            "fmeasure": 0.70588
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.375,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.55556,
            "fmeasure": 0.58824
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.55556,
            "fmeasure": 0.58824
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "bertscore": {
            "precision": 0.9355,
            "recall": 0.92185,
            "f1": 0.92862
        },
        "bleurt": 0.66905,
        "meteor": 0.3428184196534971,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.34582,
            "irrelevancy": 0.48108,
            "logical_agreement": 99.17311,
            "grammar_ref": 4.6877,
            "grammar_hyp": 5.47532,
            "nubia_score": 0.9449
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2247": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 9.666666666666666,
        "std_pred_length": 1.247219128924647,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 11,
        "distinct-1": 0.5517241379310345,
        "vocab_size-1": 16,
        "unique-1": 8,
        "entropy-1": 3.83127625337525,
        "distinct-2": 0.6923076923076923,
        "vocab_size-2": 18,
        "unique-2": 12,
        "entropy-2": 4.026986833359286,
        "cond_entropy-2": 0.13129622317994066,
        "distinct-3": 0.8260869565217391,
        "vocab_size-3": 19,
        "unique-3": 15,
        "entropy-3": 4.1757358691004915,
        "cond_entropy-3": 0.029856477140419467,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.816496580927726,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.5833333333333334,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.6258145836939115,
        "distinct-2-nopunct": 0.7619047619047619,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.880179922675737,
        "cond_entropy-2-nopunct": 0.1649632555969821,
        "distinct-3-nopunct": 0.8888888888888888,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.94770277922009,
        "cond_entropy-3-nopunct": 0.041767995450411356,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.619691924599654,
        "bleu": 40.57392,
        "rouge1": {
            "precision": 0.81414,
            "recall": 0.70203,
            "fmeasure": 0.74136
        },
        "rouge2": {
            "precision": 0.63858,
            "recall": 0.56852,
            "fmeasure": 0.59245
        },
        "rougeL": {
            "precision": 0.81414,
            "recall": 0.70203,
            "fmeasure": 0.74136
        },
        "rougeLsum": {
            "precision": 0.81414,
            "recall": 0.70203,
            "fmeasure": 0.74136
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.5925925925925926
        },
        "bertscore": {
            "precision": 0.94159,
            "recall": 0.90772,
            "f1": 0.92286
        },
        "bleurt": 0.21237,
        "meteor": 0.41737434149700403,
        "nubia": {
            "semantic_relation": 3.65262,
            "contradiction": 78.2404,
            "irrelevancy": 17.28311,
            "logical_agreement": 4.4765,
            "grammar_ref": 4.42296,
            "grammar_hyp": 4.51625,
            "nubia_score": 0.48885
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2960": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.573335161354208,
        "bleu": 28.99784,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.79545,
            "fmeasure": 0.74074
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.60119,
            "fmeasure": 0.53431
        },
        "rougeL": {
            "precision": 0.63333,
            "recall": 0.76852,
            "fmeasure": 0.69396
        },
        "rougeLsum": {
            "precision": 0.63333,
            "recall": 0.76852,
            "fmeasure": 0.69396
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.83406,
            "recall": 0.89226,
            "f1": 0.86218
        },
        "bleurt": -0.40575,
        "meteor": 0.35544347173293367,
        "nubia": {
            "semantic_relation": 2.49111,
            "contradiction": 23.11552,
            "irrelevancy": 74.93293,
            "logical_agreement": 1.95155,
            "grammar_ref": 3.66596,
            "grammar_hyp": 4.48074,
            "nubia_score": 0.23506
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2248": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673076,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2340686174361553,
        "bleu": 67.03421,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.99407,
            "recall": 0.98329,
            "f1": 0.98865
        },
        "bleurt": 0.75312,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.74676,
            "contradiction": 0.20597,
            "irrelevancy": 33.54833,
            "logical_agreement": 66.24571,
            "grammar_ref": 4.85772,
            "grammar_hyp": 4.97714,
            "nubia_score": 0.86781
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5656": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 0.5,
        "median_pred_length": 14.5,
        "min_pred_length": 14,
        "max_pred_length": 15,
        "distinct-1": 0.6896551724137931,
        "vocab_size-1": 20,
        "unique-1": 11,
        "entropy-1": 4.237291339955158,
        "distinct-2": 0.8148148148148148,
        "vocab_size-2": 22,
        "unique-2": 17,
        "entropy-2": 4.384517131793101,
        "cond_entropy-2": 0.11912872925811879,
        "distinct-3": 0.84,
        "vocab_size-3": 21,
        "unique-3": 17,
        "entropy-3": 4.323856189774722,
        "cond_entropy-3": -0.03103131238874396,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.7391304347826086,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 4.001822825622231,
        "distinct-2-nopunct": 0.8095238095238095,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 4.011365041826378,
        "cond_entropy-2-nopunct": 0.05923165719793804,
        "distinct-3-nopunct": 0.8421052631578947,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.9321380397593733,
        "cond_entropy-3-nopunct": -0.03912675144043809,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2661330047416093,
        "bleu": 22.23263,
        "rouge1": {
            "precision": 0.70076,
            "recall": 0.77365,
            "fmeasure": 0.73144
        },
        "rouge2": {
            "precision": 0.38182,
            "recall": 0.43468,
            "fmeasure": 0.40384
        },
        "rougeL": {
            "precision": 0.6553,
            "recall": 0.72946,
            "fmeasure": 0.68665
        },
        "rougeLsum": {
            "precision": 0.6553,
            "recall": 0.72946,
            "fmeasure": 0.68665
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.7894736842105263
        },
        "bertscore": {
            "precision": 0.90754,
            "recall": 0.92111,
            "f1": 0.91026
        },
        "bleurt": 0.21456,
        "meteor": 0.3544138185116908,
        "nubia": {
            "semantic_relation": 4.4803,
            "contradiction": 0.7572,
            "irrelevancy": 22.04098,
            "logical_agreement": 77.20182,
            "grammar_ref": 6.17452,
            "grammar_hyp": 6.04365,
            "nubia_score": 0.72757
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3612": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 1.0,
        "vocab_size-1": 22,
        "unique-1": 22,
        "entropy-1": 4.459431618637295,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": -0.06711419585853673,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4990124974735433,
        "bleu": 20.22928,
        "rouge1": {
            "precision": 0.52632,
            "recall": 0.4986,
            "fmeasure": 0.51111
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.30833,
            "fmeasure": 0.31992
        },
        "rougeL": {
            "precision": 0.42105,
            "recall": 0.39589,
            "fmeasure": 0.40741
        },
        "rougeLsum": {
            "precision": 0.42105,
            "recall": 0.39589,
            "fmeasure": 0.40741
        },
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.0,
            "3": 0.6
        },
        "bertscore": {
            "precision": 0.85963,
            "recall": 0.88525,
            "f1": 0.87225
        },
        "bleurt": -0.1247,
        "meteor": 0.36154959612477855,
        "nubia": {
            "semantic_relation": 3.51047,
            "contradiction": 2.22169,
            "irrelevancy": 55.39171,
            "logical_agreement": 42.3866,
            "grammar_ref": 5.50536,
            "grammar_hyp": 4.82808,
            "nubia_score": 0.55591
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3720": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 1.0,
        "median_pred_length": 16.0,
        "min_pred_length": 15,
        "max_pred_length": 17,
        "distinct-1": 0.59375,
        "vocab_size-1": 19,
        "unique-1": 8,
        "entropy-1": 4.125,
        "distinct-2": 0.7333333333333333,
        "vocab_size-2": 22,
        "unique-2": 14,
        "entropy-2": 4.3735572622751855,
        "cond_entropy-2": 0.24022392894185185,
        "distinct-3": 0.8214285714285714,
        "vocab_size-3": 23,
        "unique-3": 18,
        "entropy-3": 4.450212064914748,
        "cond_entropy-3": 0.04332146930622849,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.625,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.8349625007211565,
        "distinct-2-nopunct": 0.7272727272727273,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.913977073182751,
        "cond_entropy-2-nopunct": 0.05628729973432271,
        "distinct-3-nopunct": 0.8,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.9219280948873623,
        "cond_entropy-3-nopunct": -0.037503523749935014,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.282514138572009,
        "bleu": 79.81519,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9130434782608695
        },
        "bertscore": {
            "precision": 0.98345,
            "recall": 0.93834,
            "f1": 0.95858
        },
        "bleurt": 0.4515,
        "meteor": 0.4570160089905608,
        "nubia": {
            "semantic_relation": 4.32726,
            "contradiction": 43.9504,
            "irrelevancy": 13.81033,
            "logical_agreement": 42.23927,
            "grammar_ref": 4.1188,
            "grammar_hyp": 4.60786,
            "nubia_score": 0.66303
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2260": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9110840865659036,
        "bleu": 29.98221,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.625,
            "fmeasure": 0.55556
        },
        "rouge2": {
            "precision": 0.27778,
            "recall": 0.35714,
            "fmeasure": 0.3125
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.625,
            "fmeasure": 0.55556
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.625,
            "fmeasure": 0.55556
        },
        "local_recall": {
            "1": 0.4,
            "2": 1.0
        },
        "bertscore": {
            "precision": 0.87958,
            "recall": 0.90512,
            "f1": 0.89217
        },
        "bleurt": -0.22228,
        "meteor": 0.3899344179774085,
        "nubia": {
            "semantic_relation": 4.11619,
            "contradiction": 0.36829,
            "irrelevancy": 71.65613,
            "logical_agreement": 27.97558,
            "grammar_ref": 5.57872,
            "grammar_hyp": 5.74917,
            "nubia_score": 0.60283
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3908": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.188721875540867,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.30673161811281996,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.027169118440619,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.17948897639429623,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.266571618204611,
        "bleu": 71.02992,
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.82906,
            "fmeasure": 0.81667
        },
        "rouge2": {
            "precision": 0.65,
            "recall": 0.66667,
            "fmeasure": 0.65152
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.82906,
            "fmeasure": 0.81667
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.82906,
            "fmeasure": 0.81667
        },
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 1.0
        },
        "bertscore": {
            "precision": 0.96718,
            "recall": 0.9662,
            "f1": 0.95869
        },
        "bleurt": 0.59362,
        "meteor": 0.4673255074023409,
        "nubia": {
            "semantic_relation": 4.52128,
            "contradiction": 0.70741,
            "irrelevancy": 39.25063,
            "logical_agreement": 60.04197,
            "grammar_ref": 4.60771,
            "grammar_hyp": 3.5855,
            "nubia_score": 0.90974
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3944": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.724828456273269,
        "bleu": 11.35509,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.38182,
            "fmeasure": 0.41053
        },
        "rouge2": {
            "precision": 0.1875,
            "recall": 0.16111,
            "fmeasure": 0.1732
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.38182,
            "fmeasure": 0.41053
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.38182,
            "fmeasure": 0.41053
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.4444444444444444
        },
        "bertscore": {
            "precision": 0.89773,
            "recall": 0.87974,
            "f1": 0.88864
        },
        "bleurt": 0.31472,
        "meteor": 0.23647970285015268,
        "nubia": {
            "semantic_relation": 3.19379,
            "contradiction": 77.42395,
            "irrelevancy": 15.57207,
            "logical_agreement": 7.00397,
            "grammar_ref": 4.7527,
            "grammar_hyp": 5.40419,
            "nubia_score": 0.28775
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6225": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 1.0,
        "vocab_size-1": 20,
        "unique-1": 20,
        "entropy-1": 4.321928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.07400058144377676,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.6122524549323574,
        "bleu": 17.04921,
        "rouge1": {
            "precision": 0.56667,
            "recall": 0.53968,
            "fmeasure": 0.55285
        },
        "rouge2": {
            "precision": 0.29825,
            "recall": 0.28333,
            "fmeasure": 0.2906
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.34592,
            "fmeasure": 0.36901
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.34592,
            "fmeasure": 0.36901
        },
        "local_recall": {
            "1": 0.25,
            "2": 0.1,
            "3": 0.6363636363636364
        },
        "bertscore": {
            "precision": 0.89383,
            "recall": 0.89007,
            "f1": 0.88995
        },
        "bleurt": 0.2697,
        "meteor": 0.3324976051398784,
        "nubia": {
            "semantic_relation": 4.2202,
            "contradiction": 0.12628,
            "irrelevancy": 40.80793,
            "logical_agreement": 59.06579,
            "grammar_ref": 3.9898,
            "grammar_hyp": 4.02169,
            "nubia_score": 0.75362
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4050": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.16253715874966054,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.046930949929641655,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.5891780034221727,
        "bleu": 13.67919,
        "rouge1": {
            "precision": 0.61905,
            "recall": 0.51961,
            "fmeasure": 0.56487
        },
        "rouge2": {
            "precision": 0.07692,
            "recall": 0.06528,
            "fmeasure": 0.07061
        },
        "rougeL": {
            "precision": 0.40476,
            "recall": 0.33946,
            "fmeasure": 0.36918
        },
        "rougeLsum": {
            "precision": 0.40476,
            "recall": 0.33946,
            "fmeasure": 0.36918
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5384615384615384
        },
        "bertscore": {
            "precision": 0.88722,
            "recall": 0.8793,
            "f1": 0.88311
        },
        "bleurt": 0.22677,
        "meteor": 0.2586285996088886,
        "nubia": {
            "semantic_relation": 3.67717,
            "contradiction": 0.19389,
            "irrelevancy": 2.2027,
            "logical_agreement": 97.60341,
            "grammar_ref": 5.85115,
            "grammar_hyp": 4.50157,
            "nubia_score": 0.73277
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2262": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.5135013331538176,
        "bleu": 24.90329,
        "rouge1": {
            "precision": 0.53333,
            "recall": 0.75556,
            "fmeasure": 0.6242
        },
        "rouge2": {
            "precision": 0.35714,
            "recall": 0.55556,
            "fmeasure": 0.43478
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.75556,
            "fmeasure": 0.6242
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.75556,
            "fmeasure": 0.6242
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.87095,
            "recall": 0.9107,
            "f1": 0.88579
        },
        "bleurt": 0.08386,
        "meteor": 0.32182504834592524,
        "nubia": {
            "semantic_relation": 4.24894,
            "contradiction": 0.20019,
            "irrelevancy": 48.96582,
            "logical_agreement": 50.834,
            "grammar_ref": 5.64952,
            "grammar_hyp": 4.35653,
            "nubia_score": 0.71942
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6643": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.403677461028802,
        "bleu": 10.55267,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.66667,
            "fmeasure": 0.53333
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.2,
            "fmeasure": 0.15385
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.5,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.5,
            "fmeasure": 0.4
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.84115,
            "recall": 0.87803,
            "f1": 0.8592
        },
        "bleurt": 0.60379,
        "meteor": 0.2976554604054448,
        "nubia": {
            "semantic_relation": 4.75829,
            "contradiction": 0.42227,
            "irrelevancy": 1.84884,
            "logical_agreement": 97.72889,
            "grammar_ref": 5.72796,
            "grammar_hyp": 4.3559,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2976": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.483379566806771,
        "bleu": 8.27638,
        "rouge1": {
            "precision": 0.38095,
            "recall": 0.64286,
            "fmeasure": 0.47131
        },
        "rouge2": {
            "precision": 0.20513,
            "recall": 0.31515,
            "fmeasure": 0.24074
        },
        "rougeL": {
            "precision": 0.38095,
            "recall": 0.64286,
            "fmeasure": 0.47131
        },
        "rougeLsum": {
            "precision": 0.38095,
            "recall": 0.64286,
            "fmeasure": 0.47131
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.82024,
            "recall": 0.89,
            "f1": 0.83674
        },
        "bleurt": -1.16535,
        "meteor": 0.24739174149792909,
        "nubia": {
            "semantic_relation": 3.02154,
            "contradiction": 0.87628,
            "irrelevancy": 98.8874,
            "logical_agreement": 0.23631,
            "grammar_ref": 6.44614,
            "grammar_hyp": 5.51961,
            "nubia_score": 0.36411
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8082": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.758572044313509,
        "bleu": 24.07844,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.58333,
            "fmeasure": 0.53846
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.36364,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.5,
            "fmeasure": 0.46154
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.5,
            "fmeasure": 0.46154
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5833333333333334
        },
        "bertscore": {
            "precision": 0.81523,
            "recall": 0.8879,
            "f1": 0.85002
        },
        "bleurt": -0.81336,
        "meteor": 0.27393242266513296,
        "nubia": {
            "semantic_relation": 3.28979,
            "contradiction": 41.32265,
            "irrelevancy": 54.96127,
            "logical_agreement": 3.71607,
            "grammar_ref": 4.44512,
            "grammar_hyp": 4.73924,
            "nubia_score": 0.40016
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8822": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 2.0,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 12,
        "distinct-1": 0.75,
        "vocab_size-1": 15,
        "unique-1": 10,
        "entropy-1": 3.821928094887362,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 16,
        "unique-2": 14,
        "entropy-2": 3.94770277922009,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 0.9375,
        "vocab_size-3": 15,
        "unique-3": 14,
        "entropy-3": 3.875,
        "cond_entropy-3": -0.04492500144231237,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.7254805569978675,
        "distinct-2-nopunct": 0.875,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.75,
        "cond_entropy-2-nopunct": 0.017574998557687627,
        "distinct-3-nopunct": 0.9285714285714286,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.6644977792004623,
        "cond_entropy-3-nopunct": -0.12121650651382439,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6018824137987517,
        "bleu": 9.3145,
        "rouge1": {
            "precision": 0.52381,
            "recall": 0.4537,
            "fmeasure": 0.47745
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.15278,
            "fmeasure": 0.17037
        },
        "rougeL": {
            "precision": 0.42208,
            "recall": 0.36667,
            "fmeasure": 0.38529
        },
        "rougeLsum": {
            "precision": 0.42208,
            "recall": 0.36667,
            "fmeasure": 0.38529
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.4666666666666667
        },
        "bertscore": {
            "precision": 0.85276,
            "recall": 0.82293,
            "f1": 0.83708
        },
        "bleurt": 0.07505,
        "meteor": 0.22454079846157055,
        "nubia": {
            "semantic_relation": 3.6936,
            "contradiction": 1.74562,
            "irrelevancy": 84.18849,
            "logical_agreement": 14.06589,
            "grammar_ref": 5.12311,
            "grammar_hyp": 4.90669,
            "nubia_score": 0.54747
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8946": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1566687205209765,
        "bleu": 47.0852,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.5,
            "fmeasure": 0.53333
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.96017,
            "recall": 0.94001,
            "f1": 0.94998
        },
        "bleurt": 0.6985,
        "meteor": 0.506392260197945,
        "nubia": {
            "semantic_relation": 4.8718,
            "contradiction": 0.95834,
            "irrelevancy": 0.67672,
            "logical_agreement": 98.36494,
            "grammar_ref": 5.69157,
            "grammar_hyp": 5.45667,
            "nubia_score": 0.93365
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2221,
        "msttr-100": 0.74018,
        "msttr-100_nopunct": 0.79547,
        "total_length": 33243,
        "mean_pred_length": 14.967582170193607,
        "std_pred_length": 4.488800707850753,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 44,
        "distinct-1": 0.25620431369010016,
        "vocab_size-1": 8517,
        "unique-1": 6107,
        "entropy-1": 9.758653807647963,
        "distinct-2": 0.6591773580039971,
        "vocab_size-2": 20449,
        "unique-2": 17695,
        "entropy-2": 13.525546349513156,
        "cond_entropy-2": 3.346330048324013,
        "distinct-3": 0.8534078677823687,
        "vocab_size-3": 24579,
        "unique-3": 22824,
        "entropy-3": 14.35831289954619,
        "cond_entropy-3": 0.8000731352358066,
        "total_length-nopunct": 28985,
        "mean_pred_length-nopunct": 13.05042773525439,
        "std_pred_length-nopunct": 4.0159717202708345,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.29328963256856994,
        "vocab_size-1-nopunct": 8501,
        "unique-1-nopunct": 6106,
        "entropy-1-nopunct": 10.27885220906902,
        "distinct-2-nopunct": 0.6972425646390674,
        "vocab_size-2-nopunct": 18661,
        "unique-2-nopunct": 16475,
        "entropy-2-nopunct": 13.447981204120495,
        "cond_entropy-2-nopunct": 3.3272180172734105,
        "distinct-3-nopunct": 0.8771136372896549,
        "vocab_size-3-nopunct": 21527,
        "unique-3-nopunct": 20189,
        "entropy-3-nopunct": 14.213803123961805,
        "cond_entropy-3-nopunct": 0.8179757554739728,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 10.25614090695166,
        "bleu": 48.85471,
        "rouge1": {
            "precision": 0.79286,
            "recall": 0.75692,
            "fmeasure": 0.76403
        },
        "rouge2": {
            "precision": 0.5648,
            "recall": 0.53862,
            "fmeasure": 0.5436
        },
        "rougeL": {
            "precision": 0.68891,
            "recall": 0.66009,
            "fmeasure": 0.66494
        },
        "rougeLsum": {
            "precision": 0.68891,
            "recall": 0.66009,
            "fmeasure": 0.66494
        },
        "local_recall": {
            "1": 0.20291479820627803,
            "2": 0.450768156424581,
            "3": 0.7965545160129544
        },
        "bertscore": {
            "precision": 0.93526,
            "recall": 0.93115,
            "f1": 0.93163
        },
        "bleurt": 0.32567,
        "meteor": 0.40923923587878486,
        "nubia": {
            "semantic_relation": 4.34405,
            "contradiction": 6.37117,
            "irrelevancy": 27.00388,
            "logical_agreement": 66.62495,
            "grammar_ref": 4.79644,
            "grammar_hyp": 4.81998,
            "nubia_score": 0.76069
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3000": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.702819531114783,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.22388309575274978,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.334679141051595,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.2807634077603532,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.496629595269688,
        "bleu": 19.25161,
        "rouge1": {
            "precision": 0.69231,
            "recall": 0.6,
            "fmeasure": 0.64286
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.14286,
            "fmeasure": 0.15385
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.43333,
            "fmeasure": 0.46429
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.43333,
            "fmeasure": 0.46429
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.87737,
            "recall": 0.87085,
            "f1": 0.87409
        },
        "bleurt": -0.39984,
        "meteor": 0.32572165141765835,
        "nubia": {
            "semantic_relation": 3.60347,
            "contradiction": 9.14936,
            "irrelevancy": 82.86343,
            "logical_agreement": 7.98721,
            "grammar_ref": 5.62728,
            "grammar_hyp": 4.58618,
            "nubia_score": 0.56592
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_10500": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0747878573094933,
        "bleu": 84.64817,
        "rouge1": {
            "precision": 0.9,
            "recall": 0.70238,
            "fmeasure": 0.78788
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.56667,
            "fmeasure": 0.64444
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 0.70238,
            "fmeasure": 0.78788
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 0.70238,
            "fmeasure": 0.78788
        },
        "local_recall": {
            "1": 0.5,
            "2": 0.8
        },
        "bertscore": {
            "precision": 0.98986,
            "recall": 0.96034,
            "f1": 0.97488
        },
        "bleurt": 0.7278,
        "meteor": 0.5474647947689384,
        "nubia": {
            "semantic_relation": 4.98577,
            "contradiction": 0.54944,
            "irrelevancy": 0.59468,
            "logical_agreement": 98.85589,
            "grammar_ref": 7.77345,
            "grammar_hyp": 9.2348,
            "nubia_score": 0.88052
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_challenge_test_asset_nopunc",
        "N": 359,
        "msttr-100": 0.72203,
        "msttr-100_nopunct": 0.76596,
        "total_length": 5934,
        "mean_pred_length": 16.52924791086351,
        "std_pred_length": 7.522564551320972,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 46,
        "distinct-1": 0.37428378833838893,
        "vocab_size-1": 2221,
        "unique-1": 1654,
        "entropy-1": 8.981019165659765,
        "distinct-2": 0.8342600896860987,
        "vocab_size-2": 4651,
        "unique-2": 4290,
        "entropy-2": 11.867916365930967,
        "cond_entropy-2": 2.5584288795902723,
        "distinct-3": 0.9547546012269938,
        "vocab_size-3": 4980,
        "unique-3": 4877,
        "entropy-3": 12.186631753582185,
        "cond_entropy-3": 0.34400433544134723,
        "total_length-nopunct": 5278,
        "mean_pred_length-nopunct": 14.701949860724234,
        "std_pred_length-nopunct": 6.68451597785586,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.41890867752936717,
        "vocab_size-1-nopunct": 2211,
        "unique-1-nopunct": 1652,
        "entropy-1-nopunct": 9.329981772968242,
        "distinct-2-nopunct": 0.8503760927017686,
        "vocab_size-2-nopunct": 4183,
        "unique-2-nopunct": 3879,
        "entropy-2-nopunct": 11.764234569187819,
        "cond_entropy-2-nopunct": 2.5995602595075704,
        "distinct-3-nopunct": 0.9712719298245615,
        "vocab_size-3-nopunct": 4429,
        "unique-3-nopunct": 4341,
        "entropy-3-nopunct": 12.084381587043831,
        "cond_entropy-3-nopunct": 0.35009100691599815,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_nopunc.json",
        "nist": 10.789578044429316,
        "bleu": 64.50853,
        "rouge1": {
            "precision": 0.81596,
            "recall": 0.73764,
            "fmeasure": 0.75965
        },
        "rouge2": {
            "precision": 0.64882,
            "recall": 0.58372,
            "fmeasure": 0.59723
        },
        "rougeL": {
            "precision": 0.77669,
            "recall": 0.70741,
            "fmeasure": 0.72399
        },
        "rougeLsum": {
            "precision": 0.77669,
            "recall": 0.70741,
            "fmeasure": 0.72399
        },
        "local_recall": {
            "1": 0.04657004830917874,
            "2": 0.14285714285714285,
            "3": 0.24501758499413834,
            "4": 0.37393767705382436,
            "5": 0.46215139442231074,
            "6": 0.5307881773399015,
            "7": 0.6655251141552512,
            "8": 0.751984126984127,
            "9": 0.8705035971223022
        },
        "sari": 47.18395,
        "bertscore": {
            "precision": 0.94671,
            "recall": 0.9351,
            "f1": 0.93648
        },
        "bleurt": 0.06208,
        "meteor": 0.4106296705660659,
        "nubia": {
            "semantic_relation": 3.96009,
            "contradiction": 4.08434,
            "irrelevancy": 25.42735,
            "logical_agreement": 70.48831,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.06966,
            "nubia_score": 0.58106
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4060": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 2.0,
        "median_pred_length": 17.0,
        "min_pred_length": 15,
        "max_pred_length": 19,
        "distinct-1": 0.7058823529411765,
        "vocab_size-1": 24,
        "unique-1": 17,
        "entropy-1": 4.393061650825727,
        "distinct-2": 0.875,
        "vocab_size-2": 28,
        "unique-2": 24,
        "entropy-2": 4.75,
        "cond_entropy-2": 0.3378384235758112,
        "distinct-3": 0.9666666666666667,
        "vocab_size-3": 29,
        "unique-3": 28,
        "entropy-3": 4.840223928941852,
        "cond_entropy-3": 0.10689059560851859,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8076923076923077,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.315824333525707,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.418295834054489,
        "cond_entropy-2-nopunct": 0.13452278258006406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": 0.05628729973432271,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.595086509779482,
        "bleu": 49.30278,
        "rouge1": {
            "precision": 0.81548,
            "recall": 0.91288,
            "fmeasure": 0.85833
        },
        "rouge2": {
            "precision": 0.67832,
            "recall": 0.75909,
            "fmeasure": 0.71344
        },
        "rougeL": {
            "precision": 0.74405,
            "recall": 0.82197,
            "fmeasure": 0.77833
        },
        "rougeLsum": {
            "precision": 0.74405,
            "recall": 0.82197,
            "fmeasure": 0.77833
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9090909090909091
        },
        "bertscore": {
            "precision": 0.89851,
            "recall": 0.96362,
            "f1": 0.92856
        },
        "bleurt": 0.01646,
        "meteor": 0.4695506624632364,
        "nubia": {
            "semantic_relation": 4.37384,
            "contradiction": 3.5929,
            "irrelevancy": 47.65822,
            "logical_agreement": 48.74887,
            "grammar_ref": 6.50157,
            "grammar_hyp": 6.68239,
            "nubia_score": 0.68727
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3008": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9131113378579667,
        "bleu": 52.18739,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.89356,
            "fmeasure": 0.88937
        },
        "rouge2": {
            "precision": 0.54762,
            "recall": 0.55609,
            "fmeasure": 0.55062
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.80672,
            "fmeasure": 0.80172
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.80672,
            "fmeasure": 0.80172
        },
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333,
            "3": 0.9285714285714286
        },
        "bertscore": {
            "precision": 0.97993,
            "recall": 0.98922,
            "f1": 0.98456
        },
        "bleurt": 0.65866,
        "meteor": 0.46827837129790095,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.26714,
            "irrelevancy": 0.408,
            "logical_agreement": 99.32486,
            "grammar_ref": 5.90677,
            "grammar_hyp": 6.1993,
            "nubia_score": 0.91178
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4320": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 51,
        "mean_pred_length": 25.5,
        "std_pred_length": 7.5,
        "median_pred_length": 25.5,
        "min_pred_length": 18,
        "max_pred_length": 33,
        "distinct-1": 0.5686274509803921,
        "vocab_size-1": 29,
        "unique-1": 15,
        "entropy-1": 4.662429753651361,
        "distinct-2": 0.7142857142857143,
        "vocab_size-2": 35,
        "unique-2": 22,
        "entropy-2": 5.027875405295545,
        "cond_entropy-2": 0.3658536348409265,
        "distinct-3": 0.7446808510638298,
        "vocab_size-3": 35,
        "unique-3": 23,
        "entropy-3": 5.043950553805299,
        "cond_entropy-3": 0.041046826757396494,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 23.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 23.5,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.5531914893617021,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.50118938350047,
        "distinct-2-nopunct": 0.6888888888888889,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.8528555962815965,
        "cond_entropy-2-nopunct": 0.3984839669223365,
        "distinct-3-nopunct": 0.7209302325581395,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.868125219818376,
        "cond_entropy-3-nopunct": 0.04499043749250407,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.212007175887564,
        "bleu": 84.21856,
        "rouge1": {
            "precision": 0.95556,
            "recall": 0.91895,
            "fmeasure": 0.93611
        },
        "rouge2": {
            "precision": 0.87931,
            "recall": 0.84727,
            "fmeasure": 0.86225
        },
        "rougeL": {
            "precision": 0.88333,
            "recall": 0.85196,
            "fmeasure": 0.86667
        },
        "rougeLsum": {
            "precision": 0.88333,
            "recall": 0.85196,
            "fmeasure": 0.86667
        },
        "local_recall": {
            "1": 0.0,
            "2": 0.6,
            "3": 0.9714285714285714
        },
        "bertscore": {
            "precision": 0.97832,
            "recall": 0.96507,
            "f1": 0.97129
        },
        "bleurt": 0.62716,
        "meteor": 0.5447546646925127,
        "nubia": {
            "semantic_relation": 4.86465,
            "contradiction": 0.8353,
            "irrelevancy": 2.8672,
            "logical_agreement": 96.2975,
            "grammar_ref": 4.56621,
            "grammar_hyp": 4.59339,
            "nubia_score": 0.90485
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4340": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.1828072560398453,
        "bleu": 23.5305,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.61616,
            "fmeasure": 0.71528
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.2875,
            "fmeasure": 0.33929
        },
        "rougeL": {
            "precision": 0.64286,
            "recall": 0.4697,
            "fmeasure": 0.54167
        },
        "rougeLsum": {
            "precision": 0.64286,
            "recall": 0.4697,
            "fmeasure": 0.54167
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.7142857142857143
        },
        "bertscore": {
            "precision": 0.89979,
            "recall": 0.86645,
            "f1": 0.88281
        },
        "bleurt": 0.39598,
        "meteor": 0.32490576420926026,
        "nubia": {
            "semantic_relation": 4.42528,
            "contradiction": 0.45014,
            "irrelevancy": 8.48336,
            "logical_agreement": 91.06649,
            "grammar_ref": 5.60099,
            "grammar_hyp": 6.75964,
            "nubia_score": 0.66005
        }
    },
    "web_nlg_en_challenge_test_scramble": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.52795,
        "msttr-100_nopunct": 0.53982,
        "total_length": 12771,
        "mean_pred_length": 25.542,
        "std_pred_length": 13.331475387218024,
        "median_pred_length": 24.0,
        "min_pred_length": 5,
        "max_pred_length": 68,
        "distinct-1": 0.1129120664004385,
        "vocab_size-1": 1442,
        "unique-1": 524,
        "entropy-1": 7.930470012291201,
        "distinct-2": 0.34691549180995845,
        "vocab_size-2": 4257,
        "unique-2": 2364,
        "entropy-2": 11.07796026365561,
        "cond_entropy-2": 2.988564998239842,
        "distinct-3": 0.5539886160903916,
        "vocab_size-3": 6521,
        "unique-3": 4578,
        "entropy-3": 12.153682286487438,
        "cond_entropy-3": 1.124711537625409,
        "total_length-nopunct": 11358,
        "mean_pred_length-nopunct": 22.716,
        "std_pred_length-nopunct": 12.071758115535616,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 63,
        "distinct-1-nopunct": 0.12607853495333685,
        "vocab_size-1-nopunct": 1432,
        "unique-1-nopunct": 523,
        "entropy-1-nopunct": 8.183609445126107,
        "distinct-2-nopunct": 0.3627739915269847,
        "vocab_size-2-nopunct": 3939,
        "unique-2-nopunct": 2296,
        "entropy-2-nopunct": 10.979347947649183,
        "cond_entropy-2-nopunct": 2.9233141296020437,
        "distinct-3-nopunct": 0.5667117204093455,
        "vocab_size-3-nopunct": 5870,
        "unique-3-nopunct": 4225,
        "entropy-3-nopunct": 12.003790501960879,
        "cond_entropy-3-nopunct": 1.068961147185998,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_scramble.json",
        "nist": 7.538618626226375,
        "bleu": 37.84709,
        "rouge1": {
            "precision": 0.67329,
            "recall": 0.68736,
            "fmeasure": 0.67377
        },
        "rouge2": {
            "precision": 0.40851,
            "recall": 0.41294,
            "fmeasure": 0.40656
        },
        "rougeL": {
            "precision": 0.52797,
            "recall": 0.53931,
            "fmeasure": 0.52836
        },
        "rougeLsum": {
            "precision": 0.52797,
            "recall": 0.53931,
            "fmeasure": 0.52836
        },
        "local_recall": {
            "1": 0.22435263886143506,
            "2": 0.5408890397013912,
            "3": 0.7793567688855647,
            "4": 0.4,
            "5": 0.7222222222222222
        },
        "bertscore": {
            "precision": 0.89331,
            "recall": 0.89644,
            "f1": 0.89371
        },
        "bleurt": -0.03745,
        "meteor": 0.3345531200145773,
        "nubia": {
            "semantic_relation": 3.96776,
            "contradiction": 25.13829,
            "irrelevancy": 10.84612,
            "logical_agreement": 64.01559,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.67182,
            "nubia_score": 0.65202
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_13590": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 7.0,
        "std_pred_length": 2.0,
        "median_pred_length": 7.0,
        "min_pred_length": 5,
        "max_pred_length": 9,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 10,
        "unique-1": 6,
        "entropy-1": 3.2359263506290334,
        "distinct-2": 0.8333333333333334,
        "vocab_size-2": 10,
        "unique-2": 8,
        "entropy-2": 3.2516291673878226,
        "cond_entropy-2": -0.05572575466978136,
        "distinct-3": 0.9,
        "vocab_size-3": 9,
        "unique-3": 8,
        "entropy-3": 3.121928094887362,
        "cond_entropy-3": -0.06303440583379406,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.0849625007211556,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.9219280948873623,
        "cond_entropy-2-nopunct": -0.16303440583379405,
        "distinct-3-nopunct": 0.875,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.75,
        "cond_entropy-3-nopunct": -0.19692809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.314881869149367,
        "bleu": 46.04104,
        "rouge1": {
            "precision": 0.9375,
            "recall": 0.63889,
            "fmeasure": 0.73718
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.5006,
            "fmeasure": 0.56346
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.63005,
            "fmeasure": 0.72402
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.63005,
            "fmeasure": 0.72402
        },
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.35714285714285715,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.96773,
            "recall": 0.89832,
            "f1": 0.93081
        },
        "bleurt": 0.13236,
        "meteor": 0.40633621987494106,
        "nubia": {
            "semantic_relation": 3.98444,
            "contradiction": 12.63145,
            "irrelevancy": 21.34056,
            "logical_agreement": 66.028,
            "grammar_ref": 5.40028,
            "grammar_hyp": 5.92491,
            "nubia_score": 0.61189
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4352": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.043321469306228516,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.373609831586596,
        "bleu": 85.22457,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9375,
            "fmeasure": 0.96774
        },
        "rouge2": {
            "precision": 0.92857,
            "recall": 0.86667,
            "fmeasure": 0.89655
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9375,
            "fmeasure": 0.96774
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9375,
            "fmeasure": 0.96774
        },
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.9230769230769231
        },
        "bertscore": {
            "precision": 0.99784,
            "recall": 0.98969,
            "f1": 0.99375
        },
        "bleurt": 0.78906,
        "meteor": 0.5747920211718521,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.35488,
            "irrelevancy": 10.42506,
            "logical_agreement": 89.22006,
            "grammar_ref": 4.10709,
            "grammar_hyp": 4.15345,
            "nubia_score": 0.98846
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5082": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6707202247306157,
        "bleu": 46.35024,
        "rouge1": {
            "precision": 0.80556,
            "recall": 1.0,
            "fmeasure": 0.89177
        },
        "rouge2": {
            "precision": 0.39394,
            "recall": 0.49537,
            "fmeasure": 0.4386
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.8963,
            "fmeasure": 0.79942
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.8963,
            "fmeasure": 0.79942
        },
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.9295,
            "recall": 0.95059,
            "f1": 0.93993
        },
        "bleurt": 0.27623,
        "meteor": 0.4556374247954699,
        "nubia": {
            "semantic_relation": 4.69883,
            "contradiction": 0.4107,
            "irrelevancy": 85.68926,
            "logical_agreement": 13.90004,
            "grammar_ref": 4.96639,
            "grammar_hyp": 5.24878,
            "nubia_score": 0.73823
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_14710": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8847261486639773,
        "bleu": 62.38986,
        "rouge1": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.8,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85714
        },
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 1.0,
            "3": 0.8333333333333334
        },
        "bertscore": {
            "precision": 0.95679,
            "recall": 0.96954,
            "f1": 0.96312
        },
        "bleurt": 0.38009,
        "meteor": 0.47681970506965704,
        "nubia": {
            "semantic_relation": 4.50225,
            "contradiction": 21.81559,
            "irrelevancy": 19.52177,
            "logical_agreement": 58.66264,
            "grammar_ref": 5.78237,
            "grammar_hyp": 6.70668,
            "nubia_score": 0.59673
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-7": {
        "predictions_file": "T5-base (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.72857,
        "msttr-100_nopunct": 0.754,
        "total_length": 2181,
        "mean_pred_length": 20.57547169811321,
        "std_pred_length": 4.977208646377642,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 32,
        "distinct-1": 0.41861531407611186,
        "vocab_size-1": 913,
        "unique-1": 677,
        "entropy-1": 8.285490826550507,
        "distinct-2": 0.8559036144578314,
        "vocab_size-2": 1776,
        "unique-2": 1641,
        "entropy-2": 10.604044773274953,
        "cond_entropy-2": 2.1221029794096724,
        "distinct-3": 0.9766378872524124,
        "vocab_size-3": 1923,
        "unique-3": 1886,
        "entropy-3": 10.892574751152475,
        "cond_entropy-3": 0.29650840721525873,
        "total_length-nopunct": 2037,
        "mean_pred_length-nopunct": 19.21698113207547,
        "std_pred_length-nopunct": 4.846715902276494,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.44378988708885614,
        "vocab_size-1-nopunct": 904,
        "unique-1-nopunct": 673,
        "entropy-1-nopunct": 8.4036465739735,
        "distinct-2-nopunct": 0.8586224754013465,
        "vocab_size-2-nopunct": 1658,
        "unique-2-nopunct": 1534,
        "entropy-2-nopunct": 10.504631908404697,
        "cond_entropy-2-nopunct": 2.1964814032297917,
        "distinct-3-nopunct": 0.9802739726027397,
        "vocab_size-3-nopunct": 1789,
        "unique-3-nopunct": 1757,
        "entropy-3-nopunct": 10.792574145910486,
        "cond_entropy-3-nopunct": 0.2966180497208939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.021148412226879,
        "bleu": 7.55999,
        "rouge1": {
            "precision": 0.39394,
            "recall": 0.3498,
            "fmeasure": 0.36251
        },
        "rouge2": {
            "precision": 0.14444,
            "recall": 0.12523,
            "fmeasure": 0.13125
        },
        "rougeL": {
            "precision": 0.31124,
            "recall": 0.27474,
            "fmeasure": 0.28532
        },
        "rougeLsum": {
            "precision": 0.31124,
            "recall": 0.27474,
            "fmeasure": 0.28532
        },
        "local_recall": {
            "1": 0.32244517032197856
        },
        "bertscore": {
            "precision": 0.83084,
            "recall": 0.81224,
            "f1": 0.82119
        },
        "bleurt": -0.35913,
        "meteor": 0.15884761247546558,
        "nubia": {
            "semantic_relation": 2.78264,
            "contradiction": 22.83684,
            "irrelevancy": 64.40592,
            "logical_agreement": 12.75724,
            "grammar_ref": 3.75874,
            "grammar_hyp": 3.6438,
            "nubia_score": 0.40197
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15144": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9898332363522426,
        "bleu": 61.0195,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.875,
            "fmeasure": 0.93333
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.71429,
            "fmeasure": 0.76923
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.875,
            "fmeasure": 0.93333
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.875,
            "fmeasure": 0.93333
        },
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.99164,
            "recall": 0.97723,
            "f1": 0.98438
        },
        "bleurt": 0.84839,
        "meteor": 0.5230551846972475,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.51812,
            "irrelevancy": 0.46692,
            "logical_agreement": 99.01496,
            "grammar_ref": 5.85687,
            "grammar_hyp": 6.57356,
            "nubia_score": 0.90444
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15834": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8610927314735184,
        "bleu": 33.12203,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.41071,
            "fmeasure": 0.45055
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.95923,
            "recall": 0.93678,
            "f1": 0.94787
        },
        "bleurt": 0.35902,
        "meteor": 0.3707878006073302,
        "nubia": {
            "semantic_relation": 4.56442,
            "contradiction": 2.44907,
            "irrelevancy": 2.37459,
            "logical_agreement": 95.17634,
            "grammar_ref": 5.6187,
            "grammar_hyp": 6.50772,
            "nubia_score": 0.67533
        }
    },
    "schema_guided_dialog_challenge_test_nopunc_parent": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.69765,
        "msttr-100_nopunct": 0.72383,
        "total_length": 6853,
        "mean_pred_length": 13.706,
        "std_pred_length": 7.898073435971586,
        "median_pred_length": 12.0,
        "min_pred_length": 2,
        "max_pred_length": 50,
        "distinct-1": 0.15584415584415584,
        "vocab_size-1": 1068,
        "unique-1": 605,
        "entropy-1": 7.886591846132171,
        "distinct-2": 0.47221784983472376,
        "vocab_size-2": 3000,
        "unique-2": 2100,
        "entropy-2": 10.726512779482338,
        "cond_entropy-2": 2.621593112093055,
        "distinct-3": 0.684947889970955,
        "vocab_size-3": 4009,
        "unique-3": 3261,
        "entropy-3": 11.558923438120136,
        "cond_entropy-3": 0.8601412357690572,
        "total_length-nopunct": 6039,
        "mean_pred_length-nopunct": 12.078,
        "std_pred_length-nopunct": 7.1481407372826675,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.17502897830766684,
        "vocab_size-1-nopunct": 1057,
        "unique-1-nopunct": 605,
        "entropy-1-nopunct": 8.061957033259379,
        "distinct-2-nopunct": 0.4858277667448998,
        "vocab_size-2-nopunct": 2691,
        "unique-2-nopunct": 1921,
        "entropy-2-nopunct": 10.56144456469173,
        "cond_entropy-2-nopunct": 2.633486929191517,
        "distinct-3-nopunct": 0.6996031746031746,
        "vocab_size-3-nopunct": 3526,
        "unique-3-nopunct": 2923,
        "entropy-3-nopunct": 11.373739585707268,
        "cond_entropy-3-nopunct": 0.8470068179241066,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.27197090004431,
        "bleu": 32.38306,
        "rouge1": {
            "precision": 0.59012,
            "recall": 0.55748,
            "fmeasure": 0.56114
        },
        "rouge2": {
            "precision": 0.36496,
            "recall": 0.34598,
            "fmeasure": 0.34774
        },
        "rougeL": {
            "precision": 0.53032,
            "recall": 0.5005,
            "fmeasure": 0.50415
        },
        "rougeLsum": {
            "precision": 0.53032,
            "recall": 0.5005,
            "fmeasure": 0.50415
        },
        "local_recall": {
            "1": 0.5723477973931694
        },
        "bertscore": {
            "precision": 0.87745,
            "recall": 0.86796,
            "f1": 0.87222
        },
        "bleurt": -0.04494,
        "meteor": 0.31913280427652646,
        "nubia": {
            "semantic_relation": 3.68237,
            "contradiction": 8.33563,
            "irrelevancy": 19.85544,
            "logical_agreement": 71.80893,
            "grammar_ref": 4.79983,
            "grammar_hyp": 4.59988,
            "nubia_score": 0.65132
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 1369,
        "msttr-100": 0.73052,
        "msttr-100_nopunct": 0.78018,
        "total_length": 24960,
        "mean_pred_length": 18.23228634039445,
        "std_pred_length": 5.442449614958506,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 44,
        "distinct-1": 0.2557291666666667,
        "vocab_size-1": 6383,
        "unique-1": 4554,
        "entropy-1": 9.57622437199789,
        "distinct-2": 0.6569878343436056,
        "vocab_size-2": 15499,
        "unique-2": 13298,
        "entropy-2": 13.182550797276487,
        "cond_entropy-2": 3.2924169228552618,
        "distinct-3": 0.8529835298352983,
        "vocab_size-3": 18955,
        "unique-3": 17569,
        "entropy-3": 13.981535687673846,
        "cond_entropy-3": 0.787512142615045,
        "total_length-nopunct": 21854,
        "mean_pred_length-nopunct": 15.963476990504018,
        "std_pred_length-nopunct": 4.653687860277584,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.29134254598700465,
        "vocab_size-1-nopunct": 6367,
        "unique-1-nopunct": 4551,
        "entropy-1-nopunct": 10.030928637756706,
        "distinct-2-nopunct": 0.6943617280937271,
        "vocab_size-2-nopunct": 14224,
        "unique-2-nopunct": 12477,
        "entropy-2-nopunct": 13.09821139464005,
        "cond_entropy-2-nopunct": 3.1929896579653763,
        "distinct-3-nopunct": 0.8717827997489015,
        "vocab_size-3-nopunct": 16665,
        "unique-3-nopunct": 15603,
        "entropy-3-nopunct": 13.826954784404395,
        "cond_entropy-3-nopunct": 0.7723333385331428,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 9.958151809191566,
        "bleu": 48.1519,
        "rouge1": {
            "precision": 0.77876,
            "recall": 0.7426,
            "fmeasure": 0.75008
        },
        "rouge2": {
            "precision": 0.54345,
            "recall": 0.52202,
            "fmeasure": 0.52515
        },
        "rougeL": {
            "precision": 0.656,
            "recall": 0.63201,
            "fmeasure": 0.63481
        },
        "rougeLsum": {
            "precision": 0.656,
            "recall": 0.63201,
            "fmeasure": 0.63481
        },
        "local_recall": {
            "1": 0.22695187165775402,
            "2": 0.4395309064256047,
            "3": 0.7842782104691179
        },
        "bertscore": {
            "precision": 0.93206,
            "recall": 0.92703,
            "f1": 0.9279
        },
        "bleurt": 0.28691,
        "meteor": 0.4044834878681344,
        "nubia": {
            "semantic_relation": 4.24332,
            "contradiction": 9.50824,
            "irrelevancy": 28.88595,
            "logical_agreement": 61.60581,
            "grammar_ref": 4.49662,
            "grammar_hyp": 4.46675,
            "nubia_score": 0.74349
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-8": {
        "predictions_file": "T5-base (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.73182,
        "msttr-100_nopunct": 0.75524,
        "total_length": 2290,
        "mean_pred_length": 21.60377358490566,
        "std_pred_length": 4.538471285478576,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 34,
        "distinct-1": 0.4218340611353712,
        "vocab_size-1": 966,
        "unique-1": 735,
        "entropy-1": 8.334646816113045,
        "distinct-2": 0.8539377289377289,
        "vocab_size-2": 1865,
        "unique-2": 1713,
        "entropy-2": 10.670353160994294,
        "cond_entropy-2": 2.146350964343146,
        "distinct-3": 0.973051010587103,
        "vocab_size-3": 2022,
        "unique-3": 1974,
        "entropy-3": 10.963939840245754,
        "cond_entropy-3": 0.3024943594076711,
        "total_length-nopunct": 2120,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 4.249306269685078,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.4523584905660377,
        "vocab_size-1-nopunct": 959,
        "unique-1-nopunct": 733,
        "entropy-1-nopunct": 8.478018891217447,
        "distinct-2-nopunct": 0.8629592850049652,
        "vocab_size-2-nopunct": 1738,
        "unique-2-nopunct": 1605,
        "entropy-2-nopunct": 10.577467839474075,
        "cond_entropy-2-nopunct": 2.189810889895304,
        "distinct-3-nopunct": 0.9785115303983228,
        "vocab_size-3-nopunct": 1867,
        "unique-3-nopunct": 1830,
        "entropy-3-nopunct": 10.85328594342235,
        "cond_entropy-3-nopunct": 0.2877710540835468,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.0515518609019296,
        "bleu": 7.32673,
        "rouge1": {
            "precision": 0.38233,
            "recall": 0.3514,
            "fmeasure": 0.35772
        },
        "rouge2": {
            "precision": 0.12589,
            "recall": 0.1167,
            "fmeasure": 0.11777
        },
        "rougeL": {
            "precision": 0.27978,
            "recall": 0.25876,
            "fmeasure": 0.26248
        },
        "rougeLsum": {
            "precision": 0.27978,
            "recall": 0.25876,
            "fmeasure": 0.26248
        },
        "local_recall": {
            "1": 0.31981566820276497
        },
        "bertscore": {
            "precision": 0.82771,
            "recall": 0.81864,
            "f1": 0.82283
        },
        "bleurt": -0.35709,
        "meteor": 0.15481020069665194,
        "nubia": {
            "semantic_relation": 2.78795,
            "contradiction": 22.47631,
            "irrelevancy": 63.54373,
            "logical_agreement": 13.97996,
            "grammar_ref": 3.78639,
            "grammar_hyp": 3.58401,
            "nubia_score": 0.39261
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 483,
        "msttr-100": 0.72735,
        "msttr-100_nopunct": 0.77955,
        "total_length": 10223,
        "mean_pred_length": 21.165631469979296,
        "std_pred_length": 5.307666528723112,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 51,
        "distinct-1": 0.3145847598552284,
        "vocab_size-1": 3216,
        "unique-1": 2371,
        "entropy-1": 9.224215687311391,
        "distinct-2": 0.7254620123203286,
        "vocab_size-2": 7066,
        "unique-2": 6144,
        "entropy-2": 12.30838220782201,
        "cond_entropy-2": 2.843651933819804,
        "distinct-3": 0.8987793021497246,
        "vocab_size-3": 8320,
        "unique-3": 7783,
        "entropy-3": 12.917999881942393,
        "cond_entropy-3": 0.600741373905673,
        "total_length-nopunct": 8952,
        "mean_pred_length-nopunct": 18.53416149068323,
        "std_pred_length-nopunct": 4.713354081602446,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.3579088471849866,
        "vocab_size-1-nopunct": 3204,
        "unique-1-nopunct": 2369,
        "entropy-1-nopunct": 9.625260284372283,
        "distinct-2-nopunct": 0.7586491911677884,
        "vocab_size-2-nopunct": 6425,
        "unique-2-nopunct": 5707,
        "entropy-2-nopunct": 12.20626651241891,
        "cond_entropy-2-nopunct": 2.6702829460483617,
        "distinct-3-nopunct": 0.913473578762835,
        "vocab_size-3-nopunct": 7295,
        "unique-3-nopunct": 6897,
        "entropy-3-nopunct": 12.740846748643351,
        "cond_entropy-3-nopunct": 0.559745610974014,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.936772256178859,
        "bleu": 43.42289,
        "rouge1": {
            "precision": 0.76776,
            "recall": 0.73773,
            "fmeasure": 0.74329
        },
        "rouge2": {
            "precision": 0.52072,
            "recall": 0.50155,
            "fmeasure": 0.50458
        },
        "rougeL": {
            "precision": 0.6303,
            "recall": 0.60933,
            "fmeasure": 0.61174
        },
        "rougeLsum": {
            "precision": 0.6303,
            "recall": 0.60933,
            "fmeasure": 0.61174
        },
        "local_recall": {
            "1": 0.22047702152414195,
            "2": 0.39548387096774196,
            "3": 0.7784588441330998
        },
        "bertscore": {
            "precision": 0.92505,
            "recall": 0.92261,
            "f1": 0.92207
        },
        "bleurt": 0.217,
        "meteor": 0.39183495730938106,
        "nubia": {
            "semantic_relation": 4.20499,
            "contradiction": 7.85246,
            "irrelevancy": 34.03035,
            "logical_agreement": 58.1172,
            "grammar_ref": 4.32701,
            "grammar_hyp": 4.2709,
            "nubia_score": 0.73951
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-9": {
        "predictions_file": "T5-base (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.7181,
        "msttr-100_nopunct": 0.741,
        "total_length": 2155,
        "mean_pred_length": 20.330188679245282,
        "std_pred_length": 5.253429604164272,
        "median_pred_length": 20.0,
        "min_pred_length": 6,
        "max_pred_length": 43,
        "distinct-1": 0.417169373549884,
        "vocab_size-1": 899,
        "unique-1": 696,
        "entropy-1": 8.212544940825357,
        "distinct-2": 0.8374816983894583,
        "vocab_size-2": 1716,
        "unique-2": 1577,
        "entropy-2": 10.516561691274587,
        "cond_entropy-2": 2.1119291730488534,
        "distinct-3": 0.9603705609881626,
        "vocab_size-3": 1866,
        "unique-3": 1815,
        "entropy-3": 10.831979113528128,
        "cond_entropy-3": 0.3293414833622154,
        "total_length-nopunct": 2009,
        "mean_pred_length-nopunct": 18.952830188679247,
        "std_pred_length-nopunct": 5.090468480260201,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.44400199104031857,
        "vocab_size-1-nopunct": 892,
        "unique-1-nopunct": 692,
        "entropy-1-nopunct": 8.343921822052652,
        "distinct-2-nopunct": 0.837624802942722,
        "vocab_size-2-nopunct": 1594,
        "unique-2-nopunct": 1471,
        "entropy-2-nopunct": 10.402134550004089,
        "cond_entropy-2-nopunct": 2.160747577946587,
        "distinct-3-nopunct": 0.9604897050639956,
        "vocab_size-3-nopunct": 1726,
        "unique-3-nopunct": 1679,
        "entropy-3-nopunct": 10.719592304524724,
        "cond_entropy-3-nopunct": 0.3319637455096152,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 2.877199569346009,
        "bleu": 8.20873,
        "rouge1": {
            "precision": 0.37434,
            "recall": 0.33497,
            "fmeasure": 0.34714
        },
        "rouge2": {
            "precision": 0.14606,
            "recall": 0.12949,
            "fmeasure": 0.13481
        },
        "rougeL": {
            "precision": 0.29592,
            "recall": 0.26316,
            "fmeasure": 0.27357
        },
        "rougeLsum": {
            "precision": 0.29592,
            "recall": 0.26316,
            "fmeasure": 0.27357
        },
        "local_recall": {
            "1": 0.30375586854460096
        },
        "bertscore": {
            "precision": 0.82814,
            "recall": 0.81223,
            "f1": 0.81982
        },
        "bleurt": -0.38593,
        "meteor": 0.1455579038879867,
        "nubia": {
            "semantic_relation": 2.59188,
            "contradiction": 27.23249,
            "irrelevancy": 60.93121,
            "logical_agreement": 11.8363,
            "grammar_ref": 3.81724,
            "grammar_hyp": 3.59338,
            "nubia_score": 0.35693
        }
    },
    "schema_guided_dialog_challenge_test_scramble_parent": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.68662,
        "msttr-100_nopunct": 0.71632,
        "total_length": 6589,
        "mean_pred_length": 13.178,
        "std_pred_length": 7.355427655819885,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 38,
        "distinct-1": 0.14858096828046743,
        "vocab_size-1": 979,
        "unique-1": 522,
        "entropy-1": 7.778026122397611,
        "distinct-2": 0.45836754803744456,
        "vocab_size-2": 2791,
        "unique-2": 1876,
        "entropy-2": 10.641586362902043,
        "cond_entropy-2": 2.631297145277003,
        "distinct-3": 0.6768652710681696,
        "vocab_size-3": 3783,
        "unique-3": 3004,
        "entropy-3": 11.486445132911056,
        "cond_entropy-3": 0.8682386151031246,
        "total_length-nopunct": 5790,
        "mean_pred_length-nopunct": 11.58,
        "std_pred_length-nopunct": 6.727228255381261,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.16718480138169256,
        "vocab_size-1-nopunct": 968,
        "unique-1-nopunct": 520,
        "entropy-1-nopunct": 7.961248134176392,
        "distinct-2-nopunct": 0.47429111531190926,
        "vocab_size-2-nopunct": 2509,
        "unique-2-nopunct": 1730,
        "entropy-2-nopunct": 10.47751896197198,
        "cond_entropy-2-nopunct": 2.654151038542116,
        "distinct-3-nopunct": 0.6898998330550918,
        "vocab_size-3-nopunct": 3306,
        "unique-3-nopunct": 2680,
        "entropy-3-nopunct": 11.284596665708673,
        "cond_entropy-3-nopunct": 0.8534929518450016,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.096138175396689,
        "bleu": 31.61055,
        "rouge1": {
            "precision": 0.57548,
            "recall": 0.54788,
            "fmeasure": 0.54992
        },
        "rouge2": {
            "precision": 0.35735,
            "recall": 0.34111,
            "fmeasure": 0.34193
        },
        "rougeL": {
            "precision": 0.51587,
            "recall": 0.4907,
            "fmeasure": 0.49261
        },
        "rougeLsum": {
            "precision": 0.51587,
            "recall": 0.4907,
            "fmeasure": 0.49261
        },
        "local_recall": {
            "1": 0.561349165376011
        },
        "bertscore": {
            "precision": 0.87041,
            "recall": 0.86323,
            "f1": 0.86636
        },
        "bleurt": -0.11557,
        "meteor": 0.3111091066893579,
        "nubia": {
            "semantic_relation": 3.53896,
            "contradiction": 8.55738,
            "irrelevancy": 24.40136,
            "logical_agreement": 67.04126,
            "grammar_ref": 4.7801,
            "grammar_hyp": 4.63688,
            "nubia_score": 0.61731
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-10": {
        "predictions_file": "T5-base (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.73667,
        "msttr-100_nopunct": 0.75789,
        "total_length": 2163,
        "mean_pred_length": 20.40566037735849,
        "std_pred_length": 8.056145318580743,
        "median_pred_length": 20.0,
        "min_pred_length": 7,
        "max_pred_length": 86,
        "distinct-1": 0.4415164123901988,
        "vocab_size-1": 955,
        "unique-1": 746,
        "entropy-1": 8.387170415814305,
        "distinct-2": 0.8575595527467185,
        "vocab_size-2": 1764,
        "unique-2": 1637,
        "entropy-2": 10.578302166056336,
        "cond_entropy-2": 1.987881540753446,
        "distinct-3": 0.9543823680164019,
        "vocab_size-3": 1862,
        "unique-3": 1808,
        "entropy-3": 10.814740235115266,
        "cond_entropy-3": 0.2433287734773455,
        "total_length-nopunct": 1993,
        "mean_pred_length-nopunct": 18.80188679245283,
        "std_pred_length-nopunct": 6.80651714794705,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 70,
        "distinct-1-nopunct": 0.4746613146011039,
        "vocab_size-1-nopunct": 946,
        "unique-1-nopunct": 743,
        "entropy-1-nopunct": 8.552691322771135,
        "distinct-2-nopunct": 0.863275039745628,
        "vocab_size-2-nopunct": 1629,
        "unique-2-nopunct": 1514,
        "entropy-2-nopunct": 10.477921567990816,
        "cond_entropy-2-nopunct": 2.018290933587828,
        "distinct-3-nopunct": 0.9601347557551937,
        "vocab_size-3-nopunct": 1710,
        "unique-3-nopunct": 1665,
        "entropy-3-nopunct": 10.700985608545365,
        "cond_entropy-3-nopunct": 0.2361225550822717,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 2.5399136561234053,
        "bleu": 6.3291,
        "rouge1": {
            "precision": 0.34257,
            "recall": 0.30081,
            "fmeasure": 0.31005
        },
        "rouge2": {
            "precision": 0.11521,
            "recall": 0.10019,
            "fmeasure": 0.10378
        },
        "rougeL": {
            "precision": 0.28006,
            "recall": 0.24617,
            "fmeasure": 0.25327
        },
        "rougeLsum": {
            "precision": 0.28006,
            "recall": 0.24617,
            "fmeasure": 0.25327
        },
        "local_recall": {
            "1": 0.2723735408560311
        },
        "bertscore": {
            "precision": 0.81453,
            "recall": 0.80128,
            "f1": 0.8074
        },
        "bleurt": -0.45613,
        "meteor": 0.12851152975461702,
        "nubia": {
            "semantic_relation": 2.48031,
            "contradiction": 26.40633,
            "irrelevancy": 65.18622,
            "logical_agreement": 8.40745,
            "grammar_ref": 3.93729,
            "grammar_hyp": 3.76149,
            "nubia_score": 0.3236
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 469,
        "msttr-100": 0.69735,
        "msttr-100_nopunct": 0.71418,
        "total_length": 10246,
        "mean_pred_length": 21.84648187633262,
        "std_pred_length": 5.596402037719877,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 41,
        "distinct-1": 0.11575248877610775,
        "vocab_size-1": 1186,
        "unique-1": 593,
        "entropy-1": 7.796210481040953,
        "distinct-2": 0.3198322593842692,
        "vocab_size-2": 3127,
        "unique-2": 1910,
        "entropy-2": 10.368198218589672,
        "cond_entropy-2": 2.443514668804714,
        "distinct-3": 0.5019338203695746,
        "vocab_size-3": 4672,
        "unique-3": 3288,
        "entropy-3": 11.478541834989949,
        "cond_entropy-3": 1.1437144631025724,
        "total_length-nopunct": 9177,
        "mean_pred_length-nopunct": 19.567164179104477,
        "std_pred_length-nopunct": 5.005143266910444,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.12825542116159966,
        "vocab_size-1-nopunct": 1177,
        "unique-1-nopunct": 593,
        "entropy-1-nopunct": 7.9467163462835995,
        "distinct-2-nopunct": 0.3367018833256775,
        "vocab_size-2-nopunct": 2932,
        "unique-2-nopunct": 1822,
        "entropy-2-nopunct": 10.300310496389974,
        "cond_entropy-2-nopunct": 2.4501255388845395,
        "distinct-3-nopunct": 0.5255492171380022,
        "vocab_size-3-nopunct": 4330,
        "unique-3-nopunct": 3093,
        "entropy-3-nopunct": 11.41588557936074,
        "cond_entropy-3-nopunct": 1.1431168341655993,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.542827974092515,
        "bleu": 34.02795,
        "rouge1": {
            "precision": 0.65888,
            "recall": 0.65992,
            "fmeasure": 0.6487
        },
        "rouge2": {
            "precision": 0.42957,
            "recall": 0.42988,
            "fmeasure": 0.42285
        },
        "rougeL": {
            "precision": 0.56499,
            "recall": 0.56571,
            "fmeasure": 0.55647
        },
        "rougeLsum": {
            "precision": 0.56499,
            "recall": 0.56571,
            "fmeasure": 0.55647
        },
        "local_recall": {
            "1": 0.6414591777649102
        },
        "bertscore": {
            "precision": 0.89137,
            "recall": 0.88962,
            "f1": 0.89015
        },
        "bleurt": -0.01773,
        "meteor": 0.3447287302835187,
        "nubia": {
            "semantic_relation": 4.22782,
            "contradiction": 10.26137,
            "irrelevancy": 17.86852,
            "logical_agreement": 71.8701,
            "grammar_ref": 4.86994,
            "grammar_hyp": 4.70655,
            "nubia_score": 0.72782
        }
    },
    "web_nlg_en_challenge_test_numbers": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_challenge_test_numbers",
        "N": 500,
        "msttr-100": 0.64094,
        "msttr-100_nopunct": 0.67816,
        "total_length": 12870,
        "mean_pred_length": 25.74,
        "std_pred_length": 13.176964749137033,
        "median_pred_length": 24.0,
        "min_pred_length": 5,
        "max_pred_length": 72,
        "distinct-1": 0.12191142191142192,
        "vocab_size-1": 1569,
        "unique-1": 672,
        "entropy-1": 8.01035595183535,
        "distinct-2": 0.35755860953920776,
        "vocab_size-2": 4423,
        "unique-2": 2574,
        "entropy-2": 11.144103022168746,
        "cond_entropy-2": 2.9732920858523744,
        "distinct-3": 0.5586352148272957,
        "vocab_size-3": 6631,
        "unique-3": 4750,
        "entropy-3": 12.171291695309046,
        "cond_entropy-3": 1.0722885572242138,
        "total_length-nopunct": 11410,
        "mean_pred_length-nopunct": 22.82,
        "std_pred_length-nopunct": 11.860168632865216,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 65,
        "distinct-1-nopunct": 0.13663453111305873,
        "vocab_size-1-nopunct": 1559,
        "unique-1-nopunct": 672,
        "entropy-1-nopunct": 8.279126652121958,
        "distinct-2-nopunct": 0.3734188817598533,
        "vocab_size-2-nopunct": 4074,
        "unique-2-nopunct": 2464,
        "entropy-2-nopunct": 11.044679240191602,
        "cond_entropy-2-nopunct": 2.891066134363772,
        "distinct-3-nopunct": 0.5707973102785783,
        "vocab_size-3-nopunct": 5942,
        "unique-3-nopunct": 4359,
        "entropy-3-nopunct": 12.013407729640209,
        "cond_entropy-3-nopunct": 1.0132139008737584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_numbers.json",
        "nist": 7.50431069403652,
        "bleu": 38.25773,
        "rouge1": {
            "precision": 0.67319,
            "recall": 0.67611,
            "fmeasure": 0.66843
        },
        "rouge2": {
            "precision": 0.40723,
            "recall": 0.41039,
            "fmeasure": 0.40467
        },
        "rougeL": {
            "precision": 0.52981,
            "recall": 0.53493,
            "fmeasure": 0.52703
        },
        "rougeLsum": {
            "precision": 0.52981,
            "recall": 0.53493,
            "fmeasure": 0.52703
        },
        "local_recall": {
            "1": 0.2205728622203638,
            "2": 0.5569315445476436,
            "3": 0.7696719842265639,
            "4": 0.5555555555555556,
            "5": 0.7272727272727273
        },
        "bertscore": {
            "precision": 0.89463,
            "recall": 0.89788,
            "f1": 0.89499
        },
        "bleurt": -0.0515,
        "meteor": 0.33714761124533044,
        "nubia": {
            "semantic_relation": 3.82648,
            "contradiction": 34.23252,
            "irrelevancy": 9.32733,
            "logical_agreement": 56.44015,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.66309,
            "nubia_score": 0.61122
        }
    },
    "xsum_challenge_test_backtranslation_parent": {
        "predictions_file": "T5-base (Baseline)/xsum_test",
        "N": 500,
        "msttr-100": 0.72962,
        "msttr-100_nopunct": 0.75,
        "total_length": 10682,
        "mean_pred_length": 21.364,
        "std_pred_length": 5.565564122350941,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 86,
        "distinct-1": 0.2694252012731698,
        "vocab_size-1": 2878,
        "unique-1": 1830,
        "entropy-1": 9.025743626829628,
        "distinct-2": 0.7302101748183069,
        "vocab_size-2": 7435,
        "unique-2": 6432,
        "entropy-2": 12.369933291087465,
        "cond_entropy-2": 3.1200414742015647,
        "distinct-3": 0.9209873992976658,
        "vocab_size-3": 8917,
        "unique-3": 8466,
        "entropy-3": 13.033883059307763,
        "cond_entropy-3": 0.6735257832156187,
        "total_length-nopunct": 9932,
        "mean_pred_length-nopunct": 19.864,
        "std_pred_length-nopunct": 5.098382488593809,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 70,
        "distinct-1-nopunct": 0.2886629077728554,
        "vocab_size-1-nopunct": 2867,
        "unique-1-nopunct": 1828,
        "entropy-1-nopunct": 9.21182131049363,
        "distinct-2-nopunct": 0.7387616624257846,
        "vocab_size-2-nopunct": 6968,
        "unique-2-nopunct": 6060,
        "entropy-2-nopunct": 12.288495415391958,
        "cond_entropy-2-nopunct": 3.1921597654933898,
        "distinct-3-nopunct": 0.9289072995969547,
        "vocab_size-3-nopunct": 8297,
        "unique-3-nopunct": 7905,
        "entropy-3-nopunct": 12.945255551967804,
        "cond_entropy-3-nopunct": 0.6732778722516957,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.7771099256912515,
        "bleu": 11.22507,
        "rouge1": {
            "precision": 0.41366,
            "recall": 0.38472,
            "fmeasure": 0.39033
        },
        "rouge2": {
            "precision": 0.16797,
            "recall": 0.15654,
            "fmeasure": 0.15861
        },
        "rougeL": {
            "precision": 0.3272,
            "recall": 0.30469,
            "fmeasure": 0.30882
        },
        "rougeLsum": {
            "precision": 0.3272,
            "recall": 0.30469,
            "fmeasure": 0.30882
        },
        "local_recall": {
            "1": 0.3591428282624078
        },
        "bertscore": {
            "precision": 0.83474,
            "recall": 0.82476,
            "f1": 0.82938
        },
        "bleurt": -0.30788,
        "meteor": 0.17469789522003099,
        "nubia": {
            "semantic_relation": 2.92906,
            "contradiction": 22.02805,
            "irrelevancy": 63.06238,
            "logical_agreement": 14.90957,
            "grammar_ref": 3.78538,
            "grammar_hyp": 3.58677,
            "nubia_score": 0.44035
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 335,
        "msttr-100": 0.64837,
        "msttr-100_nopunct": 0.65013,
        "total_length": 8626,
        "mean_pred_length": 25.749253731343284,
        "std_pred_length": 5.01250296860234,
        "median_pred_length": 25.0,
        "min_pred_length": 16,
        "max_pred_length": 41,
        "distinct-1": 0.10468351495478785,
        "vocab_size-1": 903,
        "unique-1": 446,
        "entropy-1": 7.454466931070166,
        "distinct-2": 0.2875407067904957,
        "vocab_size-2": 2384,
        "unique-2": 1414,
        "entropy-2": 9.931522203193664,
        "cond_entropy-2": 2.3957790602410687,
        "distinct-3": 0.46568627450980393,
        "vocab_size-3": 3705,
        "unique-3": 2569,
        "entropy-3": 11.072983704397743,
        "cond_entropy-3": 1.1206723541832266,
        "total_length-nopunct": 7865,
        "mean_pred_length-nopunct": 23.47761194029851,
        "std_pred_length-nopunct": 4.3850431300495485,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.11315956770502225,
        "vocab_size-1-nopunct": 890,
        "unique-1-nopunct": 443,
        "entropy-1-nopunct": 7.5014249153083155,
        "distinct-2-nopunct": 0.30132802124833996,
        "vocab_size-2-nopunct": 2269,
        "unique-2-nopunct": 1366,
        "entropy-2-nopunct": 9.893568449547704,
        "cond_entropy-2-nopunct": 2.40418753169639,
        "distinct-3-nopunct": 0.4826963168867269,
        "vocab_size-3-nopunct": 3473,
        "unique-3-nopunct": 2451,
        "entropy-3-nopunct": 10.986635310949039,
        "cond_entropy-3-nopunct": 1.10200676438944,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 7.103048310088221,
        "bleu": 40.61211,
        "rouge1": {
            "precision": 0.75244,
            "recall": 0.69396,
            "fmeasure": 0.71524
        },
        "rouge2": {
            "precision": 0.53141,
            "recall": 0.48893,
            "fmeasure": 0.50426
        },
        "rougeL": {
            "precision": 0.64515,
            "recall": 0.59421,
            "fmeasure": 0.61279
        },
        "rougeLsum": {
            "precision": 0.64515,
            "recall": 0.59421,
            "fmeasure": 0.61279
        },
        "local_recall": {
            "1": 0.6768152866242039
        },
        "bertscore": {
            "precision": 0.91275,
            "recall": 0.89956,
            "f1": 0.90585
        },
        "bleurt": 0.07749,
        "meteor": 0.3817751368488368,
        "nubia": {
            "semantic_relation": 4.50244,
            "contradiction": 1.64507,
            "irrelevancy": 6.72047,
            "logical_agreement": 91.63446,
            "grammar_ref": 4.45968,
            "grammar_hyp": 4.40126,
            "nubia_score": 0.82366
        }
    },
    "xsum_challenge_test_bfp_02_parent": {
        "predictions_file": "T5-base (Baseline)/xsum_test",
        "N": 500,
        "msttr-100": 0.72821,
        "msttr-100_nopunct": 0.74717,
        "total_length": 10656,
        "mean_pred_length": 21.312,
        "std_pred_length": 4.80818635246181,
        "median_pred_length": 21.0,
        "min_pred_length": 9,
        "max_pred_length": 43,
        "distinct-1": 0.2667980480480481,
        "vocab_size-1": 2843,
        "unique-1": 1820,
        "entropy-1": 8.97060937429045,
        "distinct-2": 0.7181961402126822,
        "vocab_size-2": 7294,
        "unique-2": 6291,
        "entropy-2": 12.301274414115468,
        "cond_entropy-2": 3.106314149127131,
        "distinct-3": 0.9053438276719138,
        "vocab_size-3": 8742,
        "unique-3": 8242,
        "entropy-3": 12.978300573276094,
        "cond_entropy-3": 0.6896814130637351,
        "total_length-nopunct": 9936,
        "mean_pred_length-nopunct": 19.872,
        "std_pred_length-nopunct": 4.60169707825276,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.2852254428341385,
        "vocab_size-1-nopunct": 2834,
        "unique-1-nopunct": 1818,
        "entropy-1-nopunct": 9.145029888821806,
        "distinct-2-nopunct": 0.7240356083086054,
        "vocab_size-2-nopunct": 6832,
        "unique-2-nopunct": 5927,
        "entropy-2-nopunct": 12.207604164737921,
        "cond_entropy-2-nopunct": 3.1802048857304515,
        "distinct-3-nopunct": 0.9112578334825425,
        "vocab_size-3-nopunct": 8143,
        "unique-3-nopunct": 7699,
        "entropy-3-nopunct": 12.8883519280035,
        "cond_entropy-3-nopunct": 0.7001110613909451,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.748982583303089,
        "bleu": 10.54734,
        "rouge1": {
            "precision": 0.41035,
            "recall": 0.37925,
            "fmeasure": 0.38649
        },
        "rouge2": {
            "precision": 0.16699,
            "recall": 0.15516,
            "fmeasure": 0.15766
        },
        "rougeL": {
            "precision": 0.32038,
            "recall": 0.29727,
            "fmeasure": 0.30227
        },
        "rougeLsum": {
            "precision": 0.32038,
            "recall": 0.29727,
            "fmeasure": 0.30227
        },
        "local_recall": {
            "1": 0.35489302694136293
        },
        "bertscore": {
            "precision": 0.83386,
            "recall": 0.82316,
            "f1": 0.82815
        },
        "bleurt": -0.31894,
        "meteor": 0.17304569047664184,
        "nubia": {
            "semantic_relation": 2.88391,
            "contradiction": 19.93321,
            "irrelevancy": 65.09145,
            "logical_agreement": 14.97534,
            "grammar_ref": 3.74155,
            "grammar_hyp": 3.51155,
            "nubia_score": 0.43423
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_challenge_test_turk_backtranslation",
        "N": 359,
        "msttr-100": 0.71313,
        "msttr-100_nopunct": 0.751,
        "total_length": 6783,
        "mean_pred_length": 18.894150417827298,
        "std_pred_length": 10.565089107228095,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 120,
        "distinct-1": 0.3634085213032581,
        "vocab_size-1": 2465,
        "unique-1": 1812,
        "entropy-1": 9.05712783327005,
        "distinct-2": 0.8284557907845579,
        "vocab_size-2": 5322,
        "unique-2": 4919,
        "entropy-2": 12.04127438279222,
        "cond_entropy-2": 2.710553187114766,
        "distinct-3": 0.948722176422094,
        "vocab_size-3": 5754,
        "unique-3": 5631,
        "entropy-3": 12.39796257495441,
        "cond_entropy-3": 0.37156992197460076,
        "total_length-nopunct": 6062,
        "mean_pred_length-nopunct": 16.885793871866294,
        "std_pred_length-nopunct": 9.594612803198734,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 112,
        "distinct-1-nopunct": 0.4046519300560871,
        "vocab_size-1-nopunct": 2453,
        "unique-1-nopunct": 1809,
        "entropy-1-nopunct": 9.369495911977364,
        "distinct-2-nopunct": 0.8432403997895844,
        "vocab_size-2-nopunct": 4809,
        "unique-2-nopunct": 4474,
        "entropy-2-nopunct": 11.923013496371292,
        "cond_entropy-2-nopunct": 2.6935964530627428,
        "distinct-3-nopunct": 0.9597679640718563,
        "vocab_size-3-nopunct": 5129,
        "unique-3-nopunct": 5027,
        "entropy-3-nopunct": 12.268595179286729,
        "cond_entropy-3-nopunct": 0.37274016648736275,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_backtranslation.json",
        "nist": 8.001917686528941,
        "bleu": 40.08238,
        "rouge1": {
            "precision": 0.70374,
            "recall": 0.6236,
            "fmeasure": 0.6445
        },
        "rouge2": {
            "precision": 0.4665,
            "recall": 0.41463,
            "fmeasure": 0.42571
        },
        "rougeL": {
            "precision": 0.65024,
            "recall": 0.57782,
            "fmeasure": 0.59623
        },
        "rougeLsum": {
            "precision": 0.65024,
            "recall": 0.57782,
            "fmeasure": 0.59623
        },
        "local_recall": {
            "1": 0.059422750424448216,
            "2": 0.16219667943805874,
            "3": 0.2910284463894967,
            "4": 0.30269413629160064,
            "5": 0.4143302180685358,
            "6": 0.5597826086956522,
            "7": 0.7056128293241696
        },
        "sari": 44.27957,
        "bertscore": {
            "precision": 0.91091,
            "recall": 0.89524,
            "f1": 0.90011
        },
        "bleurt": -0.09852,
        "meteor": 0.33325517145204264,
        "nubia": {
            "semantic_relation": 3.63577,
            "contradiction": 13.12082,
            "irrelevancy": 24.37931,
            "logical_agreement": 62.49988,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.13957,
            "nubia_score": 0.51768
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 256,
        "msttr-100": 0.62865,
        "msttr-100_nopunct": 0.63478,
        "total_length": 7435,
        "mean_pred_length": 29.04296875,
        "std_pred_length": 6.602120677216029,
        "median_pred_length": 29.0,
        "min_pred_length": 11,
        "max_pred_length": 50,
        "distinct-1": 0.07962340282447881,
        "vocab_size-1": 592,
        "unique-1": 248,
        "entropy-1": 7.099777623479338,
        "distinct-2": 0.2422342944699819,
        "vocab_size-2": 1739,
        "unique-2": 865,
        "entropy-2": 9.546495288983495,
        "cond_entropy-2": 2.3806236887935834,
        "distinct-3": 0.42799364437382637,
        "vocab_size-3": 2963,
        "unique-3": 1912,
        "entropy-3": 10.754404468292275,
        "cond_entropy-3": 1.2304296246782638,
        "total_length-nopunct": 6768,
        "mean_pred_length-nopunct": 26.4375,
        "std_pred_length-nopunct": 5.759163893309514,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.08643617021276596,
        "vocab_size-1-nopunct": 585,
        "unique-1-nopunct": 248,
        "entropy-1-nopunct": 7.142225011996108,
        "distinct-2-nopunct": 0.2541461916461916,
        "vocab_size-2-nopunct": 1655,
        "unique-2-nopunct": 843,
        "entropy-2-nopunct": 9.475898830918167,
        "cond_entropy-2-nopunct": 2.384214571194262,
        "distinct-3-nopunct": 0.44421355498721227,
        "vocab_size-3-nopunct": 2779,
        "unique-3-nopunct": 1839,
        "entropy-3-nopunct": 10.663459557420882,
        "cond_entropy-3-nopunct": 1.2124272516890493,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.276817446777765,
        "bleu": 34.34121,
        "rouge1": {
            "precision": 0.70557,
            "recall": 0.63605,
            "fmeasure": 0.65915
        },
        "rouge2": {
            "precision": 0.4614,
            "recall": 0.41779,
            "fmeasure": 0.43183
        },
        "rougeL": {
            "precision": 0.5785,
            "recall": 0.52222,
            "fmeasure": 0.54082
        },
        "rougeLsum": {
            "precision": 0.5785,
            "recall": 0.52222,
            "fmeasure": 0.54082
        },
        "local_recall": {
            "1": 0.6232571937110649
        },
        "bertscore": {
            "precision": 0.90127,
            "recall": 0.88731,
            "f1": 0.89391
        },
        "bleurt": -0.04437,
        "meteor": 0.34141618652677796,
        "nubia": {
            "semantic_relation": 3.90902,
            "contradiction": 8.10666,
            "irrelevancy": 18.04138,
            "logical_agreement": 73.85196,
            "grammar_ref": 4.19274,
            "grammar_hyp": 4.12792,
            "nubia_score": 0.64188
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 46,
        "msttr-100": 0.56692,
        "msttr-100_nopunct": 0.56833,
        "total_length": 1395,
        "mean_pred_length": 30.32608695652174,
        "std_pred_length": 6.477567806522039,
        "median_pred_length": 30.0,
        "min_pred_length": 20,
        "max_pred_length": 53,
        "distinct-1": 0.14121863799283155,
        "vocab_size-1": 197,
        "unique-1": 72,
        "entropy-1": 6.421677199232232,
        "distinct-2": 0.407709414381023,
        "vocab_size-2": 550,
        "unique-2": 302,
        "entropy-2": 8.472323126287245,
        "cond_entropy-2": 2.000413903865798,
        "distinct-3": 0.6285495011511896,
        "vocab_size-3": 819,
        "unique-3": 590,
        "entropy-3": 9.366798792716859,
        "cond_entropy-3": 0.8921583541820862,
        "total_length-nopunct": 1277,
        "mean_pred_length-nopunct": 27.76086956521739,
        "std_pred_length-nopunct": 5.5996303550700155,
        "median_pred_length-nopunct": 27.5,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.15035238841033674,
        "vocab_size-1-nopunct": 192,
        "unique-1-nopunct": 71,
        "entropy-1-nopunct": 6.407252919815143,
        "distinct-2-nopunct": 0.4191714053614947,
        "vocab_size-2-nopunct": 516,
        "unique-2-nopunct": 293,
        "entropy-2-nopunct": 8.368624089810817,
        "cond_entropy-2-nopunct": 1.9723632760050755,
        "distinct-3-nopunct": 0.6388185654008439,
        "vocab_size-3-nopunct": 757,
        "unique-3-nopunct": 556,
        "entropy-3-nopunct": 9.252224325297673,
        "cond_entropy-3-nopunct": 0.901510344139891,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 5.187160688950884,
        "bleu": 33.74051,
        "rouge1": {
            "precision": 0.63329,
            "recall": 0.62867,
            "fmeasure": 0.62161
        },
        "rouge2": {
            "precision": 0.40096,
            "recall": 0.40546,
            "fmeasure": 0.39703
        },
        "rougeL": {
            "precision": 0.50344,
            "recall": 0.50398,
            "fmeasure": 0.49623
        },
        "rougeLsum": {
            "precision": 0.50344,
            "recall": 0.50398,
            "fmeasure": 0.49623
        },
        "local_recall": {
            "1": 0.6193228736581338
        },
        "bertscore": {
            "precision": 0.88856,
            "recall": 0.88986,
            "f1": 0.88895
        },
        "bleurt": -0.15515,
        "meteor": 0.3117599669191293,
        "nubia": {
            "semantic_relation": 3.66879,
            "contradiction": 54.13415,
            "irrelevancy": 24.70368,
            "logical_agreement": 21.16217,
            "grammar_ref": 4.5797,
            "grammar_hyp": 4.43606,
            "nubia_score": 0.54955
        }
    },
    "xsum_challenge_test_bfp_05_parent": {
        "predictions_file": "T5-base (Baseline)/xsum_test",
        "N": 500,
        "msttr-100": 0.72925,
        "msttr-100_nopunct": 0.75343,
        "total_length": 10639,
        "mean_pred_length": 21.278,
        "std_pred_length": 4.608765127450085,
        "median_pred_length": 22.0,
        "min_pred_length": 9,
        "max_pred_length": 40,
        "distinct-1": 0.26835228874894257,
        "vocab_size-1": 2855,
        "unique-1": 1847,
        "entropy-1": 9.006242527739419,
        "distinct-2": 0.722161948910149,
        "vocab_size-2": 7322,
        "unique-2": 6303,
        "entropy-2": 12.328575883882078,
        "cond_entropy-2": 3.0967619088275526,
        "distinct-3": 0.912024068886814,
        "vocab_size-3": 8791,
        "unique-3": 8310,
        "entropy-3": 13.00020052209881,
        "cond_entropy-3": 0.6846823586972126,
        "total_length-nopunct": 9910,
        "mean_pred_length-nopunct": 19.82,
        "std_pred_length-nopunct": 4.46,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.2869828456104945,
        "vocab_size-1-nopunct": 2844,
        "unique-1-nopunct": 1845,
        "entropy-1-nopunct": 9.180449238994663,
        "distinct-2-nopunct": 0.7279489904357067,
        "vocab_size-2-nopunct": 6850,
        "unique-2-nopunct": 5930,
        "entropy-2-nopunct": 12.2349472260875,
        "cond_entropy-2-nopunct": 3.1758737856869614,
        "distinct-3-nopunct": 0.9185185185185185,
        "vocab_size-3-nopunct": 8184,
        "unique-3-nopunct": 7761,
        "entropy-3-nopunct": 12.90965950371793,
        "cond_entropy-3-nopunct": 0.6965171308250383,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.6864777738854757,
        "bleu": 10.13622,
        "rouge1": {
            "precision": 0.40234,
            "recall": 0.37431,
            "fmeasure": 0.38018
        },
        "rouge2": {
            "precision": 0.15896,
            "recall": 0.14874,
            "fmeasure": 0.15042
        },
        "rougeL": {
            "precision": 0.31626,
            "recall": 0.29451,
            "fmeasure": 0.29889
        },
        "rougeLsum": {
            "precision": 0.31626,
            "recall": 0.29451,
            "fmeasure": 0.29889
        },
        "local_recall": {
            "1": 0.350457984866587
        },
        "bertscore": {
            "precision": 0.83371,
            "recall": 0.82198,
            "f1": 0.82748
        },
        "bleurt": -0.31141,
        "meteor": 0.17096813110788747,
        "nubia": {
            "semantic_relation": 2.87067,
            "contradiction": 22.66234,
            "irrelevancy": 61.61692,
            "logical_agreement": 15.72074,
            "grammar_ref": 3.79385,
            "grammar_hyp": 3.59136,
            "nubia_score": 0.42794
        }
    },
    "xsum_challenge_test_nopunc_parent": {
        "predictions_file": "T5-base (Baseline)/xsum_test",
        "N": 500,
        "msttr-100": 0.73495,
        "msttr-100_nopunct": 0.75796,
        "total_length": 10536,
        "mean_pred_length": 21.072,
        "std_pred_length": 4.808618928549028,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 43,
        "distinct-1": 0.27780941533788917,
        "vocab_size-1": 2927,
        "unique-1": 1908,
        "entropy-1": 9.052361873161175,
        "distinct-2": 0.7354523714627341,
        "vocab_size-2": 7381,
        "unique-2": 6408,
        "entropy-2": 12.366829674892314,
        "cond_entropy-2": 3.0835843593099033,
        "distinct-3": 0.9208263422818792,
        "vocab_size-3": 8781,
        "unique-3": 8352,
        "entropy-3": 13.010951000690675,
        "cond_entropy-3": 0.65405458155893,
        "total_length-nopunct": 9821,
        "mean_pred_length-nopunct": 19.642,
        "std_pred_length-nopunct": 4.645194936706101,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.2970165970878729,
        "vocab_size-1-nopunct": 2917,
        "unique-1-nopunct": 1907,
        "entropy-1-nopunct": 9.230102195754363,
        "distinct-2-nopunct": 0.7405857740585774,
        "vocab_size-2-nopunct": 6903,
        "unique-2-nopunct": 6022,
        "entropy-2-nopunct": 12.271037250926423,
        "cond_entropy-2-nopunct": 3.1604155754643712,
        "distinct-3-nopunct": 0.9256320145108264,
        "vocab_size-3-nopunct": 8165,
        "unique-3-nopunct": 7786,
        "entropy-3-nopunct": 12.915183541984213,
        "cond_entropy-3-nopunct": 0.6635290958263033,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.7629428831783684,
        "bleu": 10.37858,
        "rouge1": {
            "precision": 0.41131,
            "recall": 0.38153,
            "fmeasure": 0.3881
        },
        "rouge2": {
            "precision": 0.16526,
            "recall": 0.15265,
            "fmeasure": 0.15532
        },
        "rougeL": {
            "precision": 0.32137,
            "recall": 0.2976,
            "fmeasure": 0.30278
        },
        "rougeLsum": {
            "precision": 0.32137,
            "recall": 0.2976,
            "fmeasure": 0.30278
        },
        "local_recall": {
            "1": 0.35767376456408195
        },
        "bertscore": {
            "precision": 0.83574,
            "recall": 0.82388,
            "f1": 0.82945
        },
        "bleurt": -0.32129,
        "meteor": 0.1720751638759911,
        "nubia": {
            "semantic_relation": 2.88746,
            "contradiction": 23.70534,
            "irrelevancy": 61.64445,
            "logical_agreement": 14.65021,
            "grammar_ref": 3.78318,
            "grammar_hyp": 3.63681,
            "nubia_score": 0.42434
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 214,
        "msttr-100": 0.455,
        "msttr-100_nopunct": 0.45073,
        "total_length": 12018,
        "mean_pred_length": 56.1588785046729,
        "std_pred_length": 13.474551668515055,
        "median_pred_length": 57.0,
        "min_pred_length": 24,
        "max_pred_length": 87,
        "distinct-1": 0.11050091529372608,
        "vocab_size-1": 1328,
        "unique-1": 614,
        "entropy-1": 5.837058059528,
        "distinct-2": 0.27058624195188075,
        "vocab_size-2": 3194,
        "unique-2": 1708,
        "entropy-2": 9.979614163191528,
        "cond_entropy-2": 4.145765841437534,
        "distinct-3": 0.4542709232096635,
        "vocab_size-3": 5265,
        "unique-3": 3281,
        "entropy-3": 11.514704458749696,
        "cond_entropy-3": 1.5595243607937626,
        "total_length-nopunct": 11070,
        "mean_pred_length-nopunct": 51.728971962616825,
        "std_pred_length-nopunct": 13.271478865581926,
        "median_pred_length-nopunct": 52.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 82,
        "distinct-1-nopunct": 0.11933152664859982,
        "vocab_size-1-nopunct": 1321,
        "unique-1-nopunct": 613,
        "entropy-1-nopunct": 5.742085681288153,
        "distinct-2-nopunct": 0.2751473839351511,
        "vocab_size-2-nopunct": 2987,
        "unique-2-nopunct": 1618,
        "entropy-2-nopunct": 9.878454457182304,
        "cond_entropy-2-nopunct": 4.193752795765994,
        "distinct-3-nopunct": 0.45564743469272695,
        "vocab_size-3-nopunct": 4849,
        "unique-3-nopunct": 3071,
        "entropy-3-nopunct": 11.365910634288449,
        "cond_entropy-3-nopunct": 1.5104277408276305,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.1343239351030439,
        "bleu": 2.16864,
        "rouge1": {
            "precision": 0.44799,
            "recall": 0.38758,
            "fmeasure": 0.40239
        },
        "rouge2": {
            "precision": 0.20024,
            "recall": 0.18062,
            "fmeasure": 0.18347
        },
        "rougeL": {
            "precision": 0.42401,
            "recall": 0.36528,
            "fmeasure": 0.37942
        },
        "rougeLsum": {
            "precision": 0.42401,
            "recall": 0.36528,
            "fmeasure": 0.37942
        },
        "local_recall": {
            "1": 0.08717660292463442,
            "2": 0.1875,
            "3": 0.2600732600732601
        },
        "bertscore": {
            "precision": 0.85977,
            "recall": 0.86873,
            "f1": 0.86383
        },
        "bleurt": -0.50859,
        "meteor": 0.12245815591961548,
        "nubia": {
            "semantic_relation": 3.34358,
            "contradiction": 31.45087,
            "irrelevancy": 17.383,
            "logical_agreement": 51.16613,
            "grammar_ref": 2.5317,
            "grammar_hyp": 2.473,
            "nubia_score": 0.1378
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "T5-base (Baseline)/e2e_nlg_test",
        "N": 1187,
        "msttr-100": 0.29526,
        "msttr-100_nopunct": 0.28662,
        "total_length": 28740,
        "mean_pred_length": 24.212299915754002,
        "std_pred_length": 5.0912896545418445,
        "median_pred_length": 24.0,
        "min_pred_length": 15,
        "max_pred_length": 47,
        "distinct-1": 0.00859429366736256,
        "vocab_size-1": 247,
        "unique-1": 29,
        "entropy-1": 5.910620085886967,
        "distinct-2": 0.03741879287191957,
        "vocab_size-2": 1031,
        "unique-2": 233,
        "entropy-2": 7.915283594402566,
        "cond_entropy-2": 1.9154441044506973,
        "distinct-3": 0.0758552681483729,
        "vocab_size-3": 2000,
        "unique-3": 582,
        "entropy-3": 9.07672066793868,
        "cond_entropy-3": 1.173978182572811,
        "total_length-nopunct": 26336,
        "mean_pred_length-nopunct": 22.187026116259478,
        "std_pred_length-nopunct": 4.74332592820212,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.009302855407047388,
        "vocab_size-1-nopunct": 245,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 5.942730623425253,
        "distinct-2-nopunct": 0.03952443437114796,
        "vocab_size-2-nopunct": 994,
        "unique-2-nopunct": 235,
        "entropy-2-nopunct": 7.849567002886318,
        "cond_entropy-2-nopunct": 1.9478705264771274,
        "distinct-3-nopunct": 0.07941741090059261,
        "vocab_size-3-nopunct": 1903,
        "unique-3-nopunct": 562,
        "entropy-3-nopunct": 9.054875375269,
        "cond_entropy-3-nopunct": 1.2003272457597953,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 4.73402184558412,
        "bleu": 28.70589,
        "rouge1": {
            "precision": 0.71413,
            "recall": 0.71354,
            "fmeasure": 0.70182
        },
        "rouge2": {
            "precision": 0.40495,
            "recall": 0.40297,
            "fmeasure": 0.3969
        },
        "rougeL": {
            "precision": 0.50298,
            "recall": 0.50071,
            "fmeasure": 0.49347
        },
        "rougeLsum": {
            "precision": 0.50298,
            "recall": 0.50071,
            "fmeasure": 0.49347
        },
        "local_recall": {
            "1": 0.7018570766833705
        },
        "bertscore": {
            "precision": 0.90981,
            "recall": 0.90607,
            "f1": 0.90755
        },
        "bleurt": 0.14093,
        "meteor": 0.3566945152425701,
        "nubia": {
            "semantic_relation": 4.13796,
            "contradiction": 2.73186,
            "irrelevancy": 36.94373,
            "logical_agreement": 60.32441,
            "grammar_ref": 4.92209,
            "grammar_hyp": 4.58977,
            "nubia_score": 0.73299
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-2": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 1397,
        "msttr-100": 0.61965,
        "msttr-100_nopunct": 0.6252,
        "total_length": 28350,
        "mean_pred_length": 20.29348604151754,
        "std_pred_length": 6.533196477092023,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 45,
        "distinct-1": 0.06084656084656084,
        "vocab_size-1": 1725,
        "unique-1": 818,
        "entropy-1": 7.41569911512508,
        "distinct-2": 0.1928542277297518,
        "vocab_size-2": 5198,
        "unique-2": 3027,
        "entropy-2": 10.15725536814409,
        "cond_entropy-2": 2.633219896883715,
        "distinct-3": 0.3537329785568947,
        "vocab_size-3": 9040,
        "unique-3": 6250,
        "entropy-3": 11.644074458742843,
        "cond_entropy-3": 1.506713577578309,
        "total_length-nopunct": 25606,
        "mean_pred_length-nopunct": 18.329277022190407,
        "std_pred_length-nopunct": 6.0769659438054004,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.06685932984456767,
        "vocab_size-1-nopunct": 1712,
        "unique-1-nopunct": 816,
        "entropy-1-nopunct": 7.481917358118435,
        "distinct-2-nopunct": 0.20657606675203435,
        "vocab_size-2-nopunct": 5001,
        "unique-2-nopunct": 2982,
        "entropy-2-nopunct": 10.10687042657868,
        "cond_entropy-2-nopunct": 2.7042166744830274,
        "distinct-3-nopunct": 0.3729615991583377,
        "vocab_size-3-nopunct": 8508,
        "unique-3-nopunct": 5961,
        "entropy-3-nopunct": 11.584872213885326,
        "cond_entropy-3-nopunct": 1.5233063377534055,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.722291016992167,
        "bleu": 36.30658,
        "rouge1": {
            "precision": 0.65891,
            "recall": 0.65141,
            "fmeasure": 0.64336
        },
        "rouge2": {
            "precision": 0.44423,
            "recall": 0.44076,
            "fmeasure": 0.43442
        },
        "rougeL": {
            "precision": 0.57148,
            "recall": 0.56642,
            "fmeasure": 0.55884
        },
        "rougeLsum": {
            "precision": 0.57148,
            "recall": 0.56642,
            "fmeasure": 0.55884
        },
        "local_recall": {
            "1": 0.6389589263928426
        },
        "bertscore": {
            "precision": 0.88436,
            "recall": 0.88144,
            "f1": 0.88249
        },
        "bleurt": -0.04548,
        "meteor": 0.3442650507909396,
        "nubia": {
            "semantic_relation": 4.06324,
            "contradiction": 8.56625,
            "irrelevancy": 22.10469,
            "logical_agreement": 69.32906,
            "grammar_ref": 4.97201,
            "grammar_hyp": 4.82139,
            "nubia_score": 0.68611
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_challenge_test_turk_bfp02",
        "N": 359,
        "msttr-100": 0.74652,
        "msttr-100_nopunct": 0.79177,
        "total_length": 6960,
        "mean_pred_length": 19.38718662952646,
        "std_pred_length": 9.266283725988409,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.4064655172413793,
        "vocab_size-1": 2829,
        "unique-1": 2214,
        "entropy-1": 9.34842441277325,
        "distinct-2": 0.86244508407817,
        "vocab_size-2": 5693,
        "unique-2": 5343,
        "entropy-2": 12.209575019614595,
        "cond_entropy-2": 2.5784705016773106,
        "distinct-3": 0.9735661646908043,
        "vocab_size-3": 6077,
        "unique-3": 6002,
        "entropy-3": 12.516086130354136,
        "cond_entropy-3": 0.32325875874721394,
        "total_length-nopunct": 6209,
        "mean_pred_length-nopunct": 17.295264623955433,
        "std_pred_length-nopunct": 8.31629302425968,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4533741343211467,
        "vocab_size-1-nopunct": 2815,
        "unique-1-nopunct": 2211,
        "entropy-1-nopunct": 9.701051364077593,
        "distinct-2-nopunct": 0.88,
        "vocab_size-2-nopunct": 5148,
        "unique-2-nopunct": 4858,
        "entropy-2-nopunct": 12.104807808657537,
        "cond_entropy-2-nopunct": 2.5416560916595023,
        "distinct-3-nopunct": 0.9854307047896558,
        "vocab_size-3-nopunct": 5411,
        "unique-3-nopunct": 5351,
        "entropy-3-nopunct": 12.389351967211013,
        "cond_entropy-3-nopunct": 0.30731860594841265,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp02.json",
        "nist": 9.443110758756971,
        "bleu": 51.89923,
        "rouge1": {
            "precision": 0.76915,
            "recall": 0.70173,
            "fmeasure": 0.7206
        },
        "rouge2": {
            "precision": 0.58502,
            "recall": 0.5286,
            "fmeasure": 0.54331
        },
        "rougeL": {
            "precision": 0.7435,
            "recall": 0.67758,
            "fmeasure": 0.69613
        },
        "rougeLsum": {
            "precision": 0.7435,
            "recall": 0.67758,
            "fmeasure": 0.69613
        },
        "local_recall": {
            "1": 0.039898132427843805,
            "2": 0.14942528735632185,
            "3": 0.31947483588621445,
            "4": 0.44532488114104596,
            "5": 0.5742471443406023,
            "6": 0.6853864734299517,
            "7": 0.7697594501718213
        },
        "sari": 46.55717,
        "bertscore": {
            "precision": 0.90525,
            "recall": 0.9145,
            "f1": 0.90721
        },
        "bleurt": -0.3785,
        "meteor": 0.37734238835191175,
        "nubia": {
            "semantic_relation": 4.01642,
            "contradiction": 6.392,
            "irrelevancy": 17.1187,
            "logical_agreement": 76.4893,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.85244,
            "nubia_score": 0.53848
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-3": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 983,
        "msttr-100": 0.20635,
        "msttr-100_nopunct": 0.20119,
        "total_length": 5299,
        "mean_pred_length": 5.390640895218718,
        "std_pred_length": 1.5703230373861579,
        "median_pred_length": 5.0,
        "min_pred_length": 2,
        "max_pred_length": 12,
        "distinct-1": 0.013210039630118891,
        "vocab_size-1": 70,
        "unique-1": 10,
        "entropy-1": 3.8089927191506385,
        "distinct-2": 0.02942539388322521,
        "vocab_size-2": 127,
        "unique-2": 25,
        "entropy-2": 4.539793224723307,
        "cond_entropy-2": 0.6557114680020559,
        "distinct-3": 0.0462046204620462,
        "vocab_size-3": 154,
        "unique-3": 37,
        "entropy-3": 5.218232546521513,
        "cond_entropy-3": 0.5853829393399799,
        "total_length-nopunct": 4284,
        "mean_pred_length-nopunct": 4.358087487283825,
        "std_pred_length-nopunct": 1.2581183791792327,
        "median_pred_length-nopunct": 4.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.015639589169000934,
        "vocab_size-1-nopunct": 67,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.5434301100256786,
        "distinct-2-nopunct": 0.030596788851863073,
        "vocab_size-2-nopunct": 101,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.172574933540983,
        "cond_entropy-2-nopunct": 0.4913430668515461,
        "distinct-3-nopunct": 0.04184641932700604,
        "vocab_size-3-nopunct": 97,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.458117991217668,
        "cond_entropy-3-nopunct": 0.4828926517874871,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 2.9227978128668517,
        "bleu": 31.15321,
        "rouge1": {
            "precision": 0.54567,
            "recall": 0.51762,
            "fmeasure": 0.52346
        },
        "rouge2": {
            "precision": 0.37504,
            "recall": 0.35186,
            "fmeasure": 0.35733
        },
        "rougeL": {
            "precision": 0.54449,
            "recall": 0.51671,
            "fmeasure": 0.52244
        },
        "rougeLsum": {
            "precision": 0.54449,
            "recall": 0.51671,
            "fmeasure": 0.52244
        },
        "local_recall": {
            "1": 0.49903660886319845
        },
        "bertscore": {
            "precision": 0.85985,
            "recall": 0.8545,
            "f1": 0.85675
        },
        "bleurt": 0.15005,
        "meteor": 0.27849812210561636,
        "nubia": {
            "semantic_relation": 3.15729,
            "contradiction": 2.42396,
            "irrelevancy": 22.91841,
            "logical_agreement": 74.65763,
            "grammar_ref": 4.77701,
            "grammar_hyp": 4.56971,
            "nubia_score": 0.60261
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_challenge_test_turk_bfp05",
        "N": 359,
        "msttr-100": 0.7658,
        "msttr-100_nopunct": 0.81279,
        "total_length": 6900,
        "mean_pred_length": 19.220055710306408,
        "std_pred_length": 9.148970686413406,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.4498550724637681,
        "vocab_size-1": 3104,
        "unique-1": 2579,
        "entropy-1": 9.538264672801047,
        "distinct-2": 0.8824338786118331,
        "vocab_size-2": 5772,
        "unique-2": 5498,
        "entropy-2": 12.267081242988098,
        "cond_entropy-2": 2.433417108813669,
        "distinct-3": 0.977030087350372,
        "vocab_size-3": 6040,
        "unique-3": 5977,
        "entropy-3": 12.51578081767613,
        "cond_entropy-3": 0.26307505478169757,
        "total_length-nopunct": 6156,
        "mean_pred_length-nopunct": 17.147632311977716,
        "std_pred_length-nopunct": 8.269684120481825,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.50227420402859,
        "vocab_size-1-nopunct": 3092,
        "unique-1-nopunct": 2575,
        "entropy-1-nopunct": 9.924540557193678,
        "distinct-2-nopunct": 0.8978782128687252,
        "vocab_size-2-nopunct": 5205,
        "unique-2-nopunct": 4985,
        "entropy-2-nopunct": 12.150829750321908,
        "cond_entropy-2-nopunct": 2.3567645361587837,
        "distinct-3-nopunct": 0.9871276204486944,
        "vocab_size-3-nopunct": 5368,
        "unique-3-nopunct": 5317,
        "entropy-3-nopunct": 12.378969789198168,
        "cond_entropy-3-nopunct": 0.24744655205358787,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp05.json",
        "nist": 8.236015353535679,
        "bleu": 40.85339,
        "rouge1": {
            "precision": 0.70003,
            "recall": 0.63223,
            "fmeasure": 0.65219
        },
        "rouge2": {
            "precision": 0.47856,
            "recall": 0.43218,
            "fmeasure": 0.44375
        },
        "rougeL": {
            "precision": 0.67558,
            "recall": 0.61127,
            "fmeasure": 0.62961
        },
        "rougeLsum": {
            "precision": 0.67558,
            "recall": 0.61127,
            "fmeasure": 0.62961
        },
        "local_recall": {
            "1": 0.03544142614601019,
            "2": 0.12643678160919541,
            "3": 0.2910284463894967,
            "4": 0.39461172741679873,
            "5": 0.49221183800623053,
            "6": 0.6099033816425121,
            "7": 0.7067583046964491
        },
        "sari": 45.3763,
        "bertscore": {
            "precision": 0.86761,
            "recall": 0.89115,
            "f1": 0.87627
        },
        "bleurt": -0.77223,
        "meteor": 0.3236237635893122,
        "nubia": {
            "semantic_relation": 3.79442,
            "contradiction": 8.83797,
            "irrelevancy": 17.63888,
            "logical_agreement": 73.52314,
            "grammar_ref": 4.55265,
            "grammar_hyp": 6.52091,
            "nubia_score": 0.44538
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "T5-base (Baseline)/e2e_nlg_test",
        "N": 1406,
        "msttr-100": 0.30816,
        "msttr-100_nopunct": 0.30072,
        "total_length": 38144,
        "mean_pred_length": 27.129445234708392,
        "std_pred_length": 4.648562463617432,
        "median_pred_length": 27.0,
        "min_pred_length": 17,
        "max_pred_length": 49,
        "distinct-1": 0.00587248322147651,
        "vocab_size-1": 224,
        "unique-1": 33,
        "entropy-1": 5.795548463158888,
        "distinct-2": 0.027764167891556425,
        "vocab_size-2": 1020,
        "unique-2": 202,
        "entropy-2": 7.830927662604307,
        "cond_entropy-2": 1.9576499157721328,
        "distinct-3": 0.06254953017094984,
        "vocab_size-3": 2210,
        "unique-3": 538,
        "entropy-3": 9.107367276873456,
        "cond_entropy-3": 1.282593109814387,
        "total_length-nopunct": 34889,
        "mean_pred_length-nopunct": 24.814366998577526,
        "std_pred_length-nopunct": 4.339483435986488,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.006363037060391527,
        "vocab_size-1-nopunct": 222,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.824538677029983,
        "distinct-2-nopunct": 0.030702147358360958,
        "vocab_size-2-nopunct": 1028,
        "unique-2-nopunct": 226,
        "entropy-2-nopunct": 7.798449213739352,
        "cond_entropy-2-nopunct": 2.0060696957940487,
        "distinct-3-nopunct": 0.06758736789600026,
        "vocab_size-3-nopunct": 2168,
        "unique-3-nopunct": 547,
        "entropy-3-nopunct": 9.11547379219147,
        "cond_entropy-3-nopunct": 1.313090407907661,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 5.101031924394582,
        "bleu": 29.99574,
        "rouge1": {
            "precision": 0.77034,
            "recall": 0.71788,
            "fmeasure": 0.73422
        },
        "rouge2": {
            "precision": 0.45573,
            "recall": 0.42489,
            "fmeasure": 0.43436
        },
        "rougeL": {
            "precision": 0.52044,
            "recall": 0.48581,
            "fmeasure": 0.49647
        },
        "rougeLsum": {
            "precision": 0.52044,
            "recall": 0.48581,
            "fmeasure": 0.49647
        },
        "local_recall": {
            "1": 0.7026033597618396
        },
        "bertscore": {
            "precision": 0.92028,
            "recall": 0.90702,
            "f1": 0.91337
        },
        "bleurt": 0.24821,
        "meteor": 0.36335322413489096,
        "nubia": {
            "semantic_relation": 4.46925,
            "contradiction": 2.38063,
            "irrelevancy": 13.33255,
            "logical_agreement": 84.28682,
            "grammar_ref": 4.68084,
            "grammar_hyp": 4.42615,
            "nubia_score": 0.82234
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-4": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 1027,
        "msttr-100": 0.62841,
        "msttr-100_nopunct": 0.66804,
        "total_length": 10723,
        "mean_pred_length": 10.441090555014606,
        "std_pred_length": 4.437731683113901,
        "median_pred_length": 9.0,
        "min_pred_length": 2,
        "max_pred_length": 27,
        "distinct-1": 0.10715284901613355,
        "vocab_size-1": 1149,
        "unique-1": 611,
        "entropy-1": 7.344683552579278,
        "distinct-2": 0.29857673267326734,
        "vocab_size-2": 2895,
        "unique-2": 1759,
        "entropy-2": 10.106535527402134,
        "cond_entropy-2": 2.384738133366106,
        "distinct-3": 0.4735263582881532,
        "vocab_size-3": 4105,
        "unique-3": 2837,
        "entropy-3": 11.174704161492746,
        "cond_entropy-3": 1.1286917025238377,
        "total_length-nopunct": 9219,
        "mean_pred_length-nopunct": 8.976630963972736,
        "std_pred_length-nopunct": 4.172222226679423,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.12376613515565679,
        "vocab_size-1-nopunct": 1141,
        "unique-1-nopunct": 611,
        "entropy-1-nopunct": 7.640848291969736,
        "distinct-2-nopunct": 0.310546875,
        "vocab_size-2-nopunct": 2544,
        "unique-2-nopunct": 1553,
        "entropy-2-nopunct": 9.954285832353891,
        "cond_entropy-2-nopunct": 2.56278102442507,
        "distinct-3-nopunct": 0.49114241874738457,
        "vocab_size-3-nopunct": 3521,
        "unique-3-nopunct": 2486,
        "entropy-3-nopunct": 10.965758074589687,
        "cond_entropy-3-nopunct": 1.1645402833859024,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 7.492101735760706,
        "bleu": 46.40122,
        "rouge1": {
            "precision": 0.69128,
            "recall": 0.67344,
            "fmeasure": 0.67174
        },
        "rouge2": {
            "precision": 0.48912,
            "recall": 0.47659,
            "fmeasure": 0.47364
        },
        "rougeL": {
            "precision": 0.63579,
            "recall": 0.61791,
            "fmeasure": 0.6168
        },
        "rougeLsum": {
            "precision": 0.63579,
            "recall": 0.61791,
            "fmeasure": 0.6168
        },
        "local_recall": {
            "1": 0.6470977709114986
        },
        "bertscore": {
            "precision": 0.90881,
            "recall": 0.90425,
            "f1": 0.90621
        },
        "bleurt": 0.23832,
        "meteor": 0.3840821176323715,
        "nubia": {
            "semantic_relation": 4.10438,
            "contradiction": 7.39863,
            "irrelevancy": 14.45954,
            "logical_agreement": 78.14183,
            "grammar_ref": 4.86642,
            "grammar_hyp": 4.69975,
            "nubia_score": 0.76294
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_challenge_test_turk_nopunc",
        "N": 359,
        "msttr-100": 0.73676,
        "msttr-100_nopunct": 0.77705,
        "total_length": 6891,
        "mean_pred_length": 19.194986072423397,
        "std_pred_length": 9.098096004390067,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 53,
        "distinct-1": 0.36482368306486723,
        "vocab_size-1": 2514,
        "unique-1": 1832,
        "entropy-1": 9.159509368222665,
        "distinct-2": 0.8401714635639926,
        "vocab_size-2": 5488,
        "unique-2": 5072,
        "entropy-2": 12.121532539025878,
        "cond_entropy-2": 2.684714008456561,
        "distinct-3": 0.964684918192127,
        "vocab_size-3": 5955,
        "unique-3": 5851,
        "entropy-3": 12.471797021440771,
        "cond_entropy-3": 0.3676532397026677,
        "total_length-nopunct": 6152,
        "mean_pred_length-nopunct": 17.13649025069638,
        "std_pred_length-nopunct": 8.13916423024481,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 48,
        "distinct-1-nopunct": 0.4068595578673602,
        "vocab_size-1-nopunct": 2503,
        "unique-1-nopunct": 1831,
        "entropy-1-nopunct": 9.491955338203445,
        "distinct-2-nopunct": 0.8587950975315035,
        "vocab_size-2-nopunct": 4975,
        "unique-2-nopunct": 4635,
        "entropy-2-nopunct": 12.022532639631862,
        "cond_entropy-2-nopunct": 2.6689982760360365,
        "distinct-3-nopunct": 0.9786529260213471,
        "vocab_size-3-nopunct": 5318,
        "unique-3-nopunct": 5236,
        "entropy-3-nopunct": 12.356520748840152,
        "cond_entropy-3-nopunct": 0.35703088110987385,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_nopunc.json",
        "nist": 10.814183868637159,
        "bleu": 66.01159,
        "rouge1": {
            "precision": 0.84963,
            "recall": 0.77467,
            "fmeasure": 0.79634
        },
        "rouge2": {
            "precision": 0.71002,
            "recall": 0.64349,
            "fmeasure": 0.66105
        },
        "rougeL": {
            "precision": 0.82066,
            "recall": 0.74906,
            "fmeasure": 0.76944
        },
        "rougeLsum": {
            "precision": 0.82066,
            "recall": 0.74906,
            "fmeasure": 0.76944
        },
        "local_recall": {
            "1": 0.0432937181663837,
            "2": 0.1583652618135377,
            "3": 0.36980306345733044,
            "4": 0.5134706814580031,
            "5": 0.6230529595015576,
            "6": 0.7536231884057971,
            "7": 0.8514700267277587
        },
        "sari": 48.86345,
        "bertscore": {
            "precision": 0.95428,
            "recall": 0.93932,
            "f1": 0.94422
        },
        "bleurt": 0.18882,
        "meteor": 0.44757705185414276,
        "nubia": {
            "semantic_relation": 4.24018,
            "contradiction": 4.39112,
            "irrelevancy": 16.39623,
            "logical_agreement": 79.21265,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.99203,
            "nubia_score": 0.67513
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-5": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 958,
        "msttr-100": 0.65358,
        "msttr-100_nopunct": 0.67927,
        "total_length": 20128,
        "mean_pred_length": 21.010438413361168,
        "std_pred_length": 5.875171175569312,
        "median_pred_length": 20.0,
        "min_pred_length": 7,
        "max_pred_length": 50,
        "distinct-1": 0.08217408585055644,
        "vocab_size-1": 1654,
        "unique-1": 794,
        "entropy-1": 7.644815036198733,
        "distinct-2": 0.24522691705790298,
        "vocab_size-2": 4701,
        "unique-2": 2777,
        "entropy-2": 10.418424244534442,
        "cond_entropy-2": 2.6320589319033574,
        "distinct-3": 0.40983966615418405,
        "vocab_size-3": 7464,
        "unique-3": 5118,
        "entropy-3": 11.7313317133087,
        "cond_entropy-3": 1.3823134100166403,
        "total_length-nopunct": 17712,
        "mean_pred_length-nopunct": 18.488517745302715,
        "std_pred_length-nopunct": 5.38161387959586,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.0926490514905149,
        "vocab_size-1-nopunct": 1641,
        "unique-1-nopunct": 792,
        "entropy-1-nopunct": 7.86323532567003,
        "distinct-2-nopunct": 0.26447415542557,
        "vocab_size-2-nopunct": 4431,
        "unique-2-nopunct": 2714,
        "entropy-2-nopunct": 10.407179890777117,
        "cond_entropy-2-nopunct": 2.6894101630497587,
        "distinct-3-nopunct": 0.43909850595087363,
        "vocab_size-3-nopunct": 6936,
        "unique-3-nopunct": 4836,
        "entropy-3-nopunct": 11.757876619354192,
        "cond_entropy-3-nopunct": 1.4385961749168346,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.684002439837135,
        "bleu": 32.40158,
        "rouge1": {
            "precision": 0.65509,
            "recall": 0.62027,
            "fmeasure": 0.6269
        },
        "rouge2": {
            "precision": 0.41569,
            "recall": 0.39331,
            "fmeasure": 0.39735
        },
        "rougeL": {
            "precision": 0.57411,
            "recall": 0.54342,
            "fmeasure": 0.54945
        },
        "rougeLsum": {
            "precision": 0.57411,
            "recall": 0.54342,
            "fmeasure": 0.54945
        },
        "local_recall": {
            "1": 0.6079342589968829
        },
        "bertscore": {
            "precision": 0.88925,
            "recall": 0.88017,
            "f1": 0.88431
        },
        "bleurt": -0.0423,
        "meteor": 0.3383936075210262,
        "nubia": {
            "semantic_relation": 4.32295,
            "contradiction": 6.96322,
            "irrelevancy": 15.85478,
            "logical_agreement": 77.182,
            "grammar_ref": 4.83769,
            "grammar_hyp": 4.7829,
            "nubia_score": 0.74708
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-9": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 72,
        "msttr-100": 0.63864,
        "msttr-100_nopunct": 0.641,
        "total_length": 2262,
        "mean_pred_length": 31.416666666666668,
        "std_pred_length": 8.374481741841965,
        "median_pred_length": 32.0,
        "min_pred_length": 12,
        "max_pred_length": 53,
        "distinct-1": 0.1768346595932803,
        "vocab_size-1": 400,
        "unique-1": 218,
        "entropy-1": 6.999006007329414,
        "distinct-2": 0.4132420091324201,
        "vocab_size-2": 905,
        "unique-2": 604,
        "entropy-2": 8.928690611980059,
        "cond_entropy-2": 1.8686473460592044,
        "distinct-3": 0.5812086874409821,
        "vocab_size-3": 1231,
        "unique-3": 943,
        "entropy-3": 9.683578278436306,
        "cond_entropy-3": 0.7457017606013657,
        "total_length-nopunct": 2005,
        "mean_pred_length-nopunct": 27.84722222222222,
        "std_pred_length-nopunct": 7.766844994773586,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.19600997506234413,
        "vocab_size-1-nopunct": 393,
        "unique-1-nopunct": 217,
        "entropy-1-nopunct": 7.076510402745642,
        "distinct-2-nopunct": 0.44180031039834455,
        "vocab_size-2-nopunct": 854,
        "unique-2-nopunct": 583,
        "entropy-2-nopunct": 8.907938796803615,
        "cond_entropy-2-nopunct": 1.8390606270682262,
        "distinct-3-nopunct": 0.6023643202579259,
        "vocab_size-3-nopunct": 1121,
        "unique-3-nopunct": 874,
        "entropy-3-nopunct": 9.582323227046592,
        "cond_entropy-3-nopunct": 0.6981523400138866,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 5.976051875224713,
        "bleu": 36.30157,
        "rouge1": {
            "precision": 0.68224,
            "recall": 0.6061,
            "fmeasure": 0.63688
        },
        "rouge2": {
            "precision": 0.44806,
            "recall": 0.39599,
            "fmeasure": 0.41702
        },
        "rougeL": {
            "precision": 0.55078,
            "recall": 0.48957,
            "fmeasure": 0.51421
        },
        "rougeLsum": {
            "precision": 0.55078,
            "recall": 0.48957,
            "fmeasure": 0.51421
        },
        "local_recall": {
            "1": 0.6291687406669985
        },
        "bertscore": {
            "precision": 0.90212,
            "recall": 0.88567,
            "f1": 0.89362
        },
        "bleurt": -0.01698,
        "meteor": 0.34784701514816985,
        "nubia": {
            "semantic_relation": 4.17684,
            "contradiction": 2.37847,
            "irrelevancy": 9.74868,
            "logical_agreement": 87.87285,
            "grammar_ref": 4.20036,
            "grammar_hyp": 4.16125,
            "nubia_score": 0.72991
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "T5-base (Baseline)/e2e_nlg_test",
        "N": 774,
        "msttr-100": 0.33176,
        "msttr-100_nopunct": 0.32391,
        "total_length": 25579,
        "mean_pred_length": 33.04780361757106,
        "std_pred_length": 4.2698436673192255,
        "median_pred_length": 33.0,
        "min_pred_length": 19,
        "max_pred_length": 51,
        "distinct-1": 0.007467062824973611,
        "vocab_size-1": 191,
        "unique-1": 15,
        "entropy-1": 5.937401100141316,
        "distinct-2": 0.03354162467244507,
        "vocab_size-2": 832,
        "unique-2": 118,
        "entropy-2": 7.974672410470538,
        "cond_entropy-2": 1.9742655255940957,
        "distinct-3": 0.07111647455370147,
        "vocab_size-3": 1709,
        "unique-3": 295,
        "entropy-3": 9.233982508770177,
        "cond_entropy-3": 1.2597431660802532,
        "total_length-nopunct": 23385,
        "mean_pred_length-nopunct": 30.213178294573645,
        "std_pred_length-nopunct": 3.9174006538698243,
        "median_pred_length-nopunct": 30.5,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.008082103912764593,
        "vocab_size-1-nopunct": 189,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 5.965319573928416,
        "distinct-2-nopunct": 0.03622130821281677,
        "vocab_size-2-nopunct": 819,
        "unique-2-nopunct": 122,
        "entropy-2-nopunct": 7.944245280288637,
        "cond_entropy-2-nopunct": 1.9966623127243386,
        "distinct-3-nopunct": 0.07588038649997711,
        "vocab_size-3-nopunct": 1657,
        "unique-3-nopunct": 293,
        "entropy-3-nopunct": 9.231621417873768,
        "cond_entropy-3-nopunct": 1.274142639512584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 5.4155708349863625,
        "bleu": 31.92515,
        "rouge1": {
            "precision": 0.77856,
            "recall": 0.74123,
            "fmeasure": 0.75397
        },
        "rouge2": {
            "precision": 0.46147,
            "recall": 0.43916,
            "fmeasure": 0.44676
        },
        "rougeL": {
            "precision": 0.50956,
            "recall": 0.48676,
            "fmeasure": 0.49435
        },
        "rougeLsum": {
            "precision": 0.50956,
            "recall": 0.48676,
            "fmeasure": 0.49435
        },
        "local_recall": {
            "1": 0.7227630537053426
        },
        "bertscore": {
            "precision": 0.91783,
            "recall": 0.90937,
            "f1": 0.91344
        },
        "bleurt": 0.26635,
        "meteor": 0.3716024320366905,
        "nubia": {
            "semantic_relation": 4.5062,
            "contradiction": 3.20264,
            "irrelevancy": 12.9506,
            "logical_agreement": 83.84676,
            "grammar_ref": 4.52626,
            "grammar_hyp": 4.22511,
            "nubia_score": 0.8385
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "T5-base (Baseline)/e2e_nlg_test",
        "N": 73,
        "msttr-100": 0.40292,
        "msttr-100_nopunct": 0.4,
        "total_length": 2481,
        "mean_pred_length": 33.986301369863014,
        "std_pred_length": 4.282788589337212,
        "median_pred_length": 33.0,
        "min_pred_length": 26,
        "max_pred_length": 45,
        "distinct-1": 0.04514308746473196,
        "vocab_size-1": 112,
        "unique-1": 12,
        "entropy-1": 5.772196960760115,
        "distinct-2": 0.15656146179401995,
        "vocab_size-2": 377,
        "unique-2": 122,
        "entropy-2": 7.565010223162492,
        "cond_entropy-2": 1.7355972038051515,
        "distinct-3": 0.28822269807280515,
        "vocab_size-3": 673,
        "unique-3": 298,
        "entropy-3": 8.595643044415368,
        "cond_entropy-3": 1.0278922170648377,
        "total_length-nopunct": 2289,
        "mean_pred_length-nopunct": 31.356164383561644,
        "std_pred_length-nopunct": 3.9599704683197254,
        "median_pred_length-nopunct": 31.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.048055919615552646,
        "vocab_size-1-nopunct": 110,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 5.787420480210196,
        "distinct-2-nopunct": 0.16471119133574008,
        "vocab_size-2-nopunct": 365,
        "unique-2-nopunct": 116,
        "entropy-2-nopunct": 7.543399029281651,
        "cond_entropy-2-nopunct": 1.7639673496758403,
        "distinct-3-nopunct": 0.3028464769015399,
        "vocab_size-3-nopunct": 649,
        "unique-3-nopunct": 288,
        "entropy-3-nopunct": 8.6042753224919,
        "cond_entropy-3-nopunct": 1.0272944003686535,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 5.311678622767206,
        "bleu": 37.60006,
        "rouge1": {
            "precision": 0.76718,
            "recall": 0.78131,
            "fmeasure": 0.77103
        },
        "rouge2": {
            "precision": 0.49078,
            "recall": 0.4975,
            "fmeasure": 0.49214
        },
        "rougeL": {
            "precision": 0.52787,
            "recall": 0.53604,
            "fmeasure": 0.52998
        },
        "rougeLsum": {
            "precision": 0.52787,
            "recall": 0.53604,
            "fmeasure": 0.52998
        },
        "local_recall": {
            "1": 0.7688008130081301
        },
        "bertscore": {
            "precision": 0.92212,
            "recall": 0.91779,
            "f1": 0.91983
        },
        "bleurt": 0.30439,
        "meteor": 0.3959896734617483,
        "nubia": {
            "semantic_relation": 4.47724,
            "contradiction": 4.8409,
            "irrelevancy": 16.38925,
            "logical_agreement": 78.76985,
            "grammar_ref": 4.71083,
            "grammar_hyp": 4.25412,
            "nubia_score": 0.84682
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-10": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 1024,
        "msttr-100": 0.50303,
        "msttr-100_nopunct": 0.53488,
        "total_length": 9946,
        "mean_pred_length": 9.712890625,
        "std_pred_length": 5.903652689800367,
        "median_pred_length": 6.0,
        "min_pred_length": 3,
        "max_pred_length": 36,
        "distinct-1": 0.07500502714659159,
        "vocab_size-1": 746,
        "unique-1": 424,
        "entropy-1": 6.374437947450446,
        "distinct-2": 0.21452589105581707,
        "vocab_size-2": 1914,
        "unique-2": 1168,
        "entropy-2": 8.951212944460778,
        "cond_entropy-2": 2.259092754753192,
        "distinct-3": 0.3597113193213472,
        "vocab_size-3": 2841,
        "unique-3": 1974,
        "entropy-3": 10.004858754592181,
        "cond_entropy-3": 1.0237523940213926,
        "total_length-nopunct": 8431,
        "mean_pred_length-nopunct": 8.2333984375,
        "std_pred_length-nopunct": 5.194763154550221,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.08753410034396869,
        "vocab_size-1-nopunct": 738,
        "unique-1-nopunct": 423,
        "entropy-1-nopunct": 6.605225640706652,
        "distinct-2-nopunct": 0.23693803159173754,
        "vocab_size-2-nopunct": 1755,
        "unique-2-nopunct": 1104,
        "entropy-2-nopunct": 8.850919588886033,
        "cond_entropy-2-nopunct": 2.426604295785267,
        "distinct-3-nopunct": 0.40137866207112644,
        "vocab_size-3-nopunct": 2562,
        "unique-3-nopunct": 1846,
        "entropy-3-nopunct": 9.950237182489664,
        "cond_entropy-3-nopunct": 1.0894865005299221,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 4.449343007331904,
        "bleu": 24.76238,
        "rouge1": {
            "precision": 0.42013,
            "recall": 0.38935,
            "fmeasure": 0.39397
        },
        "rouge2": {
            "precision": 0.20615,
            "recall": 0.19556,
            "fmeasure": 0.19674
        },
        "rougeL": {
            "precision": 0.3798,
            "recall": 0.35002,
            "fmeasure": 0.35494
        },
        "rougeLsum": {
            "precision": 0.3798,
            "recall": 0.35002,
            "fmeasure": 0.35494
        },
        "local_recall": {
            "1": 0.4178269926543142
        },
        "bertscore": {
            "precision": 0.85053,
            "recall": 0.83963,
            "f1": 0.84462
        },
        "bleurt": -0.51955,
        "meteor": 0.2437934619934266,
        "nubia": {
            "semantic_relation": 2.47593,
            "contradiction": 11.68457,
            "irrelevancy": 30.63894,
            "logical_agreement": 57.67649,
            "grammar_ref": 5.2128,
            "grammar_hyp": 5.05903,
            "nubia_score": 0.40732
        }
    },
    "cs_restaurants_validation": {
        "predictions_file": "T5-base (Baseline)/cs_restaurants_validation",
        "N": 781,
        "msttr-100": 0.53857,
        "msttr-100_nopunct": 0.54711,
        "total_length": 14099,
        "mean_pred_length": 18.05249679897567,
        "std_pred_length": 6.961099854158624,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 66,
        "distinct-1": 0.03503794595361373,
        "vocab_size-1": 494,
        "unique-1": 138,
        "entropy-1": 6.295900704547285,
        "distinct-2": 0.11848625919807779,
        "vocab_size-2": 1578,
        "unique-2": 584,
        "entropy-2": 9.130090710812208,
        "cond_entropy-2": 2.747626843220853,
        "distinct-3": 0.207545664832097,
        "vocab_size-3": 2602,
        "unique-3": 1227,
        "entropy-3": 10.023319589523267,
        "cond_entropy-3": 0.8859255753493238,
        "total_length-nopunct": 12898,
        "mean_pred_length-nopunct": 16.51472471190781,
        "std_pred_length-nopunct": 6.730316362765605,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 61,
        "distinct-1-nopunct": 0.03799038610637308,
        "vocab_size-1-nopunct": 490,
        "unique-1-nopunct": 138,
        "entropy-1-nopunct": 6.287009112961538,
        "distinct-2-nopunct": 0.12131715771230503,
        "vocab_size-2-nopunct": 1470,
        "unique-2-nopunct": 557,
        "entropy-2-nopunct": 9.026269083992862,
        "cond_entropy-2-nopunct": 2.776026634339706,
        "distinct-3-nopunct": 0.21480239943542695,
        "vocab_size-3-nopunct": 2435,
        "unique-3-nopunct": 1185,
        "entropy-3-nopunct": 9.926815505434844,
        "cond_entropy-3-nopunct": 0.8753387412570234,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_validation.json",
        "nist": 1.3179113561313702,
        "bleu": 2.90977,
        "rouge1": {
            "precision": 0.43349,
            "recall": 0.47239,
            "fmeasure": 0.43507
        },
        "rouge2": {
            "precision": 0.23985,
            "recall": 0.26426,
            "fmeasure": 0.24038
        },
        "rougeL": {
            "precision": 0.39315,
            "recall": 0.43257,
            "fmeasure": 0.39628
        },
        "rougeLsum": {
            "precision": 0.39315,
            "recall": 0.43257,
            "fmeasure": 0.39628
        },
        "local_recall": {
            "1": 0.27603550295857987
        },
        "bertscore": {
            "precision": 0.81343,
            "recall": 0.84688,
            "f1": 0.82951
        },
        "bleurt": -0.73662,
        "meteor": 0.1277823446462565,
        "nubia": {
            "semantic_relation": 2.67861,
            "contradiction": 32.37643,
            "irrelevancy": 27.13399,
            "logical_agreement": 40.48958,
            "grammar_ref": 6.54085,
            "grammar_hyp": 5.97635,
            "nubia_score": 0.26815
        }
    },
    "cs_restaurants_test": {
        "predictions_file": "T5-base (Baseline)/cs_restaurants_test",
        "N": 842,
        "msttr-100": 0.53867,
        "msttr-100_nopunct": 0.55484,
        "total_length": 13599,
        "mean_pred_length": 16.15083135391924,
        "std_pred_length": 6.172293123040792,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 49,
        "distinct-1": 0.051253768659460255,
        "vocab_size-1": 697,
        "unique-1": 250,
        "entropy-1": 6.32672323286927,
        "distinct-2": 0.15818766167594261,
        "vocab_size-2": 2018,
        "unique-2": 976,
        "entropy-2": 8.99672158273527,
        "cond_entropy-2": 2.595351652608047,
        "distinct-3": 0.25975660931598826,
        "vocab_size-3": 3095,
        "unique-3": 1824,
        "entropy-3": 9.73563365418172,
        "cond_entropy-3": 0.8233144104270493,
        "total_length-nopunct": 12223,
        "mean_pred_length-nopunct": 14.516627078384799,
        "std_pred_length-nopunct": 5.741074578594715,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.05669639204777878,
        "vocab_size-1-nopunct": 693,
        "unique-1-nopunct": 250,
        "entropy-1-nopunct": 6.337246439989225,
        "distinct-2-nopunct": 0.15402864423161408,
        "vocab_size-2-nopunct": 1753,
        "unique-2-nopunct": 837,
        "entropy-2-nopunct": 8.825146636004163,
        "cond_entropy-2-nopunct": 2.679405445135076,
        "distinct-3-nopunct": 0.26074580130942215,
        "vocab_size-3-nopunct": 2748,
        "unique-3-nopunct": 1623,
        "entropy-3-nopunct": 9.582341625737344,
        "cond_entropy-3-nopunct": 0.8566999058912385,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 1.6352336681550381,
        "bleu": 3.96374,
        "rouge1": {
            "precision": 0.43861,
            "recall": 0.43075,
            "fmeasure": 0.42083
        },
        "rouge2": {
            "precision": 0.23318,
            "recall": 0.23007,
            "fmeasure": 0.22397
        },
        "rougeL": {
            "precision": 0.38658,
            "recall": 0.38001,
            "fmeasure": 0.37136
        },
        "rougeLsum": {
            "precision": 0.38658,
            "recall": 0.38001,
            "fmeasure": 0.37136
        },
        "local_recall": {
            "1": 0.2837351066777501
        },
        "bertscore": {
            "precision": 0.82178,
            "recall": 0.84973,
            "f1": 0.83518
        },
        "bleurt": -0.72112,
        "meteor": 0.13175112932857208,
        "nubia": {
            "semantic_relation": 2.74861,
            "contradiction": 33.19284,
            "irrelevancy": 25.8779,
            "logical_agreement": 40.92926,
            "grammar_ref": 6.8707,
            "grammar_hyp": 6.22791,
            "nubia_score": 0.34599
        }
    },
    "cs_restaurants_challenge_train_sample": {
        "predictions_file": "T5-base (Baseline)/cs_restaurants_challenge_train_sample",
        "N": 500
    },
    "cs_restaurants_challenge_validation_sample": {
        "predictions_file": "T5-base (Baseline)/cs_restaurants_challenge_validation_sample",
        "N": 500
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 5049,
        "msttr-100": 0.56782,
        "msttr-100_nopunct": 0.59031,
        "total_length": 37782,
        "mean_pred_length": 7.483065953654189,
        "std_pred_length": 2.753589354882339,
        "median_pred_length": 7.0,
        "min_pred_length": 2,
        "max_pred_length": 28,
        "distinct-1": 0.03049070986183897,
        "vocab_size-1": 1152,
        "unique-1": 480,
        "entropy-1": 6.8226562589249875,
        "distinct-2": 0.1140133809916598,
        "vocab_size-2": 3732,
        "unique-2": 1812,
        "entropy-2": 9.35765606720351,
        "cond_entropy-2": 2.1605492672902886,
        "distinct-3": 0.1998988585464528,
        "vocab_size-3": 5534,
        "unique-3": 3131,
        "entropy-3": 10.246146158791637,
        "cond_entropy-3": 0.9164550149263747,
        "total_length-nopunct": 32197,
        "mean_pred_length-nopunct": 6.3769063180827885,
        "std_pred_length-nopunct": 2.5611069135891062,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.03546914308786533,
        "vocab_size-1-nopunct": 1142,
        "unique-1-nopunct": 480,
        "entropy-1-nopunct": 6.990090924875024,
        "distinct-2-nopunct": 0.11709886547811993,
        "vocab_size-2-nopunct": 3179,
        "unique-2-nopunct": 1590,
        "entropy-2-nopunct": 9.05232862468834,
        "cond_entropy-2-nopunct": 2.2678062409888056,
        "distinct-3-nopunct": 0.20243372839952953,
        "vocab_size-3-nopunct": 4475,
        "unique-3-nopunct": 2606,
        "entropy-3-nopunct": 9.851766346126027,
        "cond_entropy-3-nopunct": 0.9333827321986339,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 4.877012552166609,
        "bleu": 27.7146,
        "rouge1": {
            "precision": 0.51955,
            "recall": 0.49552,
            "fmeasure": 0.49497
        },
        "rouge2": {
            "precision": 0.31329,
            "recall": 0.29989,
            "fmeasure": 0.29844
        },
        "rougeL": {
            "precision": 0.49631,
            "recall": 0.47231,
            "fmeasure": 0.47247
        },
        "rougeLsum": {
            "precision": 0.49631,
            "recall": 0.47231,
            "fmeasure": 0.47247
        },
        "local_recall": {
            "1": 0.4753762370439773
        },
        "bertscore": {
            "precision": 0.86203,
            "recall": 0.85514,
            "f1": 0.858
        },
        "bleurt": -0.07822,
        "meteor": 0.26922595883567274,
        "nubia": {
            "semantic_relation": 3.18438,
            "contradiction": 8.07581,
            "irrelevancy": 24.11978,
            "logical_agreement": 67.80442,
            "grammar_ref": 4.77787,
            "grammar_hyp": 4.5225,
            "nubia_score": 0.5836
        }
    },
    "cs_restaurants_challenge_test_scramble": {
        "predictions_file": "T5-base (Baseline)/cs_restaurants_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.55321,
        "msttr-100_nopunct": 0.55425,
        "total_length": 8188,
        "mean_pred_length": 16.376,
        "std_pred_length": 6.220821810661353,
        "median_pred_length": 16.0,
        "min_pred_length": 3,
        "max_pred_length": 37,
        "distinct-1": 0.06875915974596972,
        "vocab_size-1": 563,
        "unique-1": 227,
        "entropy-1": 6.330165145834638,
        "distinct-2": 0.20187304890738814,
        "vocab_size-2": 1552,
        "unique-2": 827,
        "entropy-2": 8.924810369926103,
        "cond_entropy-2": 2.5248539741599427,
        "distinct-3": 0.3159432387312187,
        "vocab_size-3": 2271,
        "unique-3": 1451,
        "entropy-3": 9.605847187970122,
        "cond_entropy-3": 0.7554367454521926,
        "total_length-nopunct": 7351,
        "mean_pred_length-nopunct": 14.702,
        "std_pred_length-nopunct": 5.745014882487251,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.07604407563596789,
        "vocab_size-1-nopunct": 559,
        "unique-1-nopunct": 227,
        "entropy-1-nopunct": 6.343023114291616,
        "distinct-2-nopunct": 0.1982192380674354,
        "vocab_size-2-nopunct": 1358,
        "unique-2-nopunct": 714,
        "entropy-2-nopunct": 8.755746110005685,
        "cond_entropy-2-nopunct": 2.590829770489994,
        "distinct-3-nopunct": 0.3161706817823965,
        "vocab_size-3-nopunct": 2008,
        "unique-3-nopunct": 1276,
        "entropy-3-nopunct": 9.452933121465263,
        "cond_entropy-3-nopunct": 0.7788248603548601,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_challenge_test_scramble.json",
        "nist": 1.5530014366564941,
        "bleu": 3.51593,
        "rouge1": {
            "precision": 0.42983,
            "recall": 0.42819,
            "fmeasure": 0.41592
        },
        "rouge2": {
            "precision": 0.22609,
            "recall": 0.22533,
            "fmeasure": 0.21908
        },
        "rougeL": {
            "precision": 0.37535,
            "recall": 0.37428,
            "fmeasure": 0.36367
        },
        "rougeLsum": {
            "precision": 0.37535,
            "recall": 0.37428,
            "fmeasure": 0.36367
        },
        "local_recall": {
            "1": 0.2783601211274167
        },
        "bertscore": {
            "precision": 0.8202,
            "recall": 0.84863,
            "f1": 0.83384
        },
        "bleurt": -0.72713,
        "meteor": 0.1293427430814596,
        "nubia": {
            "semantic_relation": 2.73542,
            "contradiction": 32.91357,
            "irrelevancy": 26.39483,
            "logical_agreement": 40.6916,
            "grammar_ref": 6.87434,
            "grammar_hyp": 6.22871,
            "nubia_score": 0.33525
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-11": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 1246,
        "msttr-100": 0.66814,
        "msttr-100_nopunct": 0.68631,
        "total_length": 18857,
        "mean_pred_length": 15.13402889245586,
        "std_pred_length": 5.392359583147677,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 41,
        "distinct-1": 0.09932651004931856,
        "vocab_size-1": 1873,
        "unique-1": 908,
        "entropy-1": 7.90923384157783,
        "distinct-2": 0.2786894554539776,
        "vocab_size-2": 4908,
        "unique-2": 2919,
        "entropy-2": 10.607215469894191,
        "cond_entropy-2": 2.4942594472977055,
        "distinct-3": 0.4433852734494348,
        "vocab_size-3": 7256,
        "unique-3": 5008,
        "entropy-3": 11.789704378744105,
        "cond_entropy-3": 1.2452305142436233,
        "total_length-nopunct": 16845,
        "mean_pred_length-nopunct": 13.519261637239165,
        "std_pred_length-nopunct": 4.900047312044844,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.11029979222321164,
        "vocab_size-1-nopunct": 1858,
        "unique-1-nopunct": 906,
        "entropy-1-nopunct": 8.063900813104418,
        "distinct-2-nopunct": 0.2855952304634912,
        "vocab_size-2-nopunct": 4455,
        "unique-2-nopunct": 2720,
        "entropy-2-nopunct": 10.446719182923223,
        "cond_entropy-2-nopunct": 2.544304118239179,
        "distinct-3-nopunct": 0.4540514178220581,
        "vocab_size-3-nopunct": 6517,
        "unique-3-nopunct": 4585,
        "entropy-3-nopunct": 11.632410872446455,
        "cond_entropy-3-nopunct": 1.2787233517584715,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 7.294785745036657,
        "bleu": 38.96114,
        "rouge1": {
            "precision": 0.69985,
            "recall": 0.66726,
            "fmeasure": 0.67162
        },
        "rouge2": {
            "precision": 0.49113,
            "recall": 0.46737,
            "fmeasure": 0.47014
        },
        "rougeL": {
            "precision": 0.61532,
            "recall": 0.58717,
            "fmeasure": 0.59095
        },
        "rougeLsum": {
            "precision": 0.61532,
            "recall": 0.58717,
            "fmeasure": 0.59095
        },
        "local_recall": {
            "1": 0.6424650996301158
        },
        "bertscore": {
            "precision": 0.90137,
            "recall": 0.89177,
            "f1": 0.8961
        },
        "bleurt": -0.01075,
        "meteor": 0.36786951983878974,
        "nubia": {
            "semantic_relation": 4.29326,
            "contradiction": 8.53172,
            "irrelevancy": 19.03157,
            "logical_agreement": 72.43671,
            "grammar_ref": 4.92094,
            "grammar_hyp": 4.80796,
            "nubia_score": 0.76537
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-12": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.31073,
        "msttr-100_nopunct": 0.31083,
        "total_length": 4168,
        "mean_pred_length": 8.336,
        "std_pred_length": 1.7202046389892105,
        "median_pred_length": 8.0,
        "min_pred_length": 5,
        "max_pred_length": 21,
        "distinct-1": 0.020393474088291747,
        "vocab_size-1": 85,
        "unique-1": 22,
        "entropy-1": 4.748984976013557,
        "distinct-2": 0.06461286804798255,
        "vocab_size-2": 237,
        "unique-2": 88,
        "entropy-2": 6.166074253466807,
        "cond_entropy-2": 1.1941955725318314,
        "distinct-3": 0.11710858585858586,
        "vocab_size-3": 371,
        "unique-3": 152,
        "entropy-3": 6.826587436061576,
        "cond_entropy-3": 0.719817437904197,
        "total_length-nopunct": 3672,
        "mean_pred_length-nopunct": 7.344,
        "std_pred_length-nopunct": 1.7162936811629879,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.022603485838779955,
        "vocab_size-1-nopunct": 83,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.79002834405551,
        "distinct-2-nopunct": 0.06683480453972257,
        "vocab_size-2-nopunct": 212,
        "unique-2-nopunct": 81,
        "entropy-2-nopunct": 5.89830306077724,
        "cond_entropy-2-nopunct": 1.2617098727586302,
        "distinct-3-nopunct": 0.11751497005988024,
        "vocab_size-3-nopunct": 314,
        "unique-3-nopunct": 133,
        "entropy-3-nopunct": 6.492903466423039,
        "cond_entropy-3-nopunct": 0.7992496700509072,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 3.805410413551159,
        "bleu": 29.81306,
        "rouge1": {
            "precision": 0.57633,
            "recall": 0.54774,
            "fmeasure": 0.55189
        },
        "rouge2": {
            "precision": 0.34865,
            "recall": 0.33014,
            "fmeasure": 0.33203
        },
        "rougeL": {
            "precision": 0.55528,
            "recall": 0.52812,
            "fmeasure": 0.53192
        },
        "rougeLsum": {
            "precision": 0.55528,
            "recall": 0.52812,
            "fmeasure": 0.53192
        },
        "local_recall": {
            "1": 0.5346429519511547
        },
        "bertscore": {
            "precision": 0.89147,
            "recall": 0.88568,
            "f1": 0.88822
        },
        "bleurt": 0.09023,
        "meteor": 0.2953630380359517,
        "nubia": {
            "semantic_relation": 3.6324,
            "contradiction": 7.48029,
            "irrelevancy": 19.83902,
            "logical_agreement": 72.6807,
            "grammar_ref": 4.43492,
            "grammar_hyp": 3.94823,
            "nubia_score": 0.7052
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-13": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 2078,
        "msttr-100": 0.50269,
        "msttr-100_nopunct": 0.5208,
        "total_length": 21684,
        "mean_pred_length": 10.435033686236766,
        "std_pred_length": 5.5258047875723095,
        "median_pred_length": 9.0,
        "min_pred_length": 2,
        "max_pred_length": 52,
        "distinct-1": 0.021490499907766095,
        "vocab_size-1": 466,
        "unique-1": 132,
        "entropy-1": 6.2072595014048755,
        "distinct-2": 0.10139753136794859,
        "vocab_size-2": 1988,
        "unique-2": 810,
        "entropy-2": 8.922818114159982,
        "cond_entropy-2": 2.4167192494496854,
        "distinct-3": 0.21297352806937472,
        "vocab_size-3": 3733,
        "unique-3": 1998,
        "entropy-3": 10.18759281710315,
        "cond_entropy-3": 1.335477749022494,
        "total_length-nopunct": 18869,
        "mean_pred_length-nopunct": 9.08036573628489,
        "std_pred_length-nopunct": 5.010363606151951,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.024431607398378293,
        "vocab_size-1-nopunct": 461,
        "unique-1-nopunct": 132,
        "entropy-1-nopunct": 6.378097630685905,
        "distinct-2-nopunct": 0.110952295872789,
        "vocab_size-2-nopunct": 1863,
        "unique-2-nopunct": 833,
        "entropy-2-nopunct": 8.670362879599866,
        "cond_entropy-2-nopunct": 2.4900917268216607,
        "distinct-3-nopunct": 0.2247893449306877,
        "vocab_size-3-nopunct": 3308,
        "unique-3-nopunct": 1887,
        "entropy-3-nopunct": 9.911718038607017,
        "cond_entropy-3-nopunct": 1.3487953063877114,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 3.839564162726109,
        "bleu": 18.87927,
        "rouge1": {
            "precision": 0.49784,
            "recall": 0.4591,
            "fmeasure": 0.46226
        },
        "rouge2": {
            "precision": 0.25756,
            "recall": 0.24105,
            "fmeasure": 0.23981
        },
        "rougeL": {
            "precision": 0.4581,
            "recall": 0.42414,
            "fmeasure": 0.42642
        },
        "rougeLsum": {
            "precision": 0.4581,
            "recall": 0.42414,
            "fmeasure": 0.42642
        },
        "local_recall": {
            "1": 0.4475086666321726
        },
        "bertscore": {
            "precision": 0.85385,
            "recall": 0.84238,
            "f1": 0.84732
        },
        "bleurt": -0.23857,
        "meteor": 0.24334642820581515,
        "nubia": {
            "semantic_relation": 3.19204,
            "contradiction": 11.34704,
            "irrelevancy": 25.03049,
            "logical_agreement": 63.62247,
            "grammar_ref": 4.54436,
            "grammar_hyp": 4.36904,
            "nubia_score": 0.54236
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-15": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 715,
        "msttr-100": 0.23712,
        "msttr-100_nopunct": 0.2281,
        "total_length": 6689,
        "mean_pred_length": 9.355244755244755,
        "std_pred_length": 3.2209471378106156,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 24,
        "distinct-1": 0.015697413664224846,
        "vocab_size-1": 105,
        "unique-1": 25,
        "entropy-1": 4.368979974571097,
        "distinct-2": 0.043187144291931705,
        "vocab_size-2": 258,
        "unique-2": 76,
        "entropy-2": 5.362608088584666,
        "cond_entropy-2": 0.8593190400862476,
        "distinct-3": 0.06788362806617228,
        "vocab_size-3": 357,
        "unique-3": 126,
        "entropy-3": 5.68651906994988,
        "cond_entropy-3": 0.32454501053581386,
        "total_length-nopunct": 5884,
        "mean_pred_length-nopunct": 8.22937062937063,
        "std_pred_length-nopunct": 2.866830616850391,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.01733514615907546,
        "vocab_size-1-nopunct": 102,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.273390353914435,
        "distinct-2-nopunct": 0.044882956084349,
        "vocab_size-2-nopunct": 232,
        "unique-2-nopunct": 72,
        "entropy-2-nopunct": 5.0923559805259675,
        "cond_entropy-2-nopunct": 0.7912988228468256,
        "distinct-3-nopunct": 0.07049842837898518,
        "vocab_size-3-nopunct": 314,
        "unique-3-nopunct": 118,
        "entropy-3-nopunct": 5.398734817477936,
        "cond_entropy-3-nopunct": 0.2805127902733087,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 3.1080488913212077,
        "bleu": 28.73095,
        "rouge1": {
            "precision": 0.55283,
            "recall": 0.58254,
            "fmeasure": 0.55631
        },
        "rouge2": {
            "precision": 0.31707,
            "recall": 0.32969,
            "fmeasure": 0.31592
        },
        "rougeL": {
            "precision": 0.47756,
            "recall": 0.49765,
            "fmeasure": 0.47789
        },
        "rougeLsum": {
            "precision": 0.47756,
            "recall": 0.49765,
            "fmeasure": 0.47789
        },
        "local_recall": {
            "1": 0.574017584783779
        },
        "bertscore": {
            "precision": 0.86092,
            "recall": 0.86527,
            "f1": 0.86257
        },
        "bleurt": 0.22734,
        "meteor": 0.29524671111601847,
        "nubia": {
            "semantic_relation": 3.68919,
            "contradiction": 0.87135,
            "irrelevancy": 24.11467,
            "logical_agreement": 75.01398,
            "grammar_ref": 4.09289,
            "grammar_hyp": 3.44592,
            "nubia_score": 0.75215
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 2517,
        "msttr-100": 0.68734,
        "msttr-100_nopunct": 0.7143,
        "total_length": 37276,
        "mean_pred_length": 14.809694080254271,
        "std_pred_length": 4.507876982849872,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 39,
        "distinct-1": 0.06693314733340487,
        "vocab_size-1": 2495,
        "unique-1": 1179,
        "entropy-1": 8.079226804144866,
        "distinct-2": 0.24025432262147933,
        "vocab_size-2": 8351,
        "unique-2": 4821,
        "entropy-2": 11.375511022881568,
        "cond_entropy-2": 3.066810134404475,
        "distinct-3": 0.41836734693877553,
        "vocab_size-3": 13489,
        "unique-3": 9215,
        "entropy-3": 12.66903464987487,
        "cond_entropy-3": 1.353649484084034,
        "total_length-nopunct": 32824,
        "mean_pred_length-nopunct": 13.040921732220898,
        "std_pred_length-nopunct": 4.0390812837621874,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.0755849378503534,
        "vocab_size-1-nopunct": 2481,
        "unique-1-nopunct": 1177,
        "entropy-1-nopunct": 8.290379906676401,
        "distinct-2-nopunct": 0.2555185270729534,
        "vocab_size-2-nopunct": 7744,
        "unique-2-nopunct": 4655,
        "entropy-2-nopunct": 11.24643495822799,
        "cond_entropy-2-nopunct": 3.1363499655213993,
        "distinct-3-nopunct": 0.4357682619647355,
        "vocab_size-3-nopunct": 12110,
        "unique-3-nopunct": 8497,
        "entropy-3-nopunct": 12.50789464686135,
        "cond_entropy-3-nopunct": 1.3565990871324194,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.917280994399298,
        "bleu": 33.82405,
        "rouge1": {
            "precision": 0.63891,
            "recall": 0.61801,
            "fmeasure": 0.61689
        },
        "rouge2": {
            "precision": 0.40767,
            "recall": 0.39457,
            "fmeasure": 0.39341
        },
        "rougeL": {
            "precision": 0.55987,
            "recall": 0.54213,
            "fmeasure": 0.54089
        },
        "rougeLsum": {
            "precision": 0.55987,
            "recall": 0.54213,
            "fmeasure": 0.54089
        },
        "local_recall": {
            "1": 0.5939873121035032
        },
        "bertscore": {
            "precision": 0.88547,
            "recall": 0.87964,
            "f1": 0.88213
        },
        "bleurt": -0.04337,
        "meteor": 0.3301943008894551,
        "nubia": {
            "semantic_relation": 4.01538,
            "contradiction": 7.67469,
            "irrelevancy": 22.07803,
            "logical_agreement": 70.24728,
            "grammar_ref": 4.80017,
            "grammar_hyp": 4.63257,
            "nubia_score": 0.70257
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-0": {
        "predictions_file": "T5-base (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.72727,
        "msttr-100_nopunct": 0.75333,
        "total_length": 2282,
        "mean_pred_length": 21.528301886792452,
        "std_pred_length": 4.562371832616566,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 34,
        "distinct-1": 0.41148115687992987,
        "vocab_size-1": 939,
        "unique-1": 692,
        "entropy-1": 8.317691131393419,
        "distinct-2": 0.8492647058823529,
        "vocab_size-2": 1848,
        "unique-2": 1690,
        "entropy-2": 10.664561389045089,
        "cond_entropy-2": 2.157398740177258,
        "distinct-3": 0.9666666666666667,
        "vocab_size-3": 2001,
        "unique-3": 1953,
        "entropy-3": 10.936533790301654,
        "cond_entropy-3": 0.2773916831211811,
        "total_length-nopunct": 2113,
        "mean_pred_length-nopunct": 19.933962264150942,
        "std_pred_length-nopunct": 4.309421157830497,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.4406057737813535,
        "vocab_size-1-nopunct": 931,
        "unique-1-nopunct": 691,
        "entropy-1-nopunct": 8.456662273311322,
        "distinct-2-nopunct": 0.8570004982561036,
        "vocab_size-2-nopunct": 1720,
        "unique-2-nopunct": 1580,
        "entropy-2-nopunct": 10.570035121309695,
        "cond_entropy-2-nopunct": 2.200689352972968,
        "distinct-3-nopunct": 0.9721199368753288,
        "vocab_size-3-nopunct": 1848,
        "unique-3-nopunct": 1807,
        "entropy-3-nopunct": 10.830191777714724,
        "cond_entropy-3-nopunct": 0.26777163021347583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 4.283740886748802,
        "bleu": 19.42371,
        "rouge1": {
            "precision": 0.47598,
            "recall": 0.48206,
            "fmeasure": 0.46929
        },
        "rouge2": {
            "precision": 0.23689,
            "recall": 0.24467,
            "fmeasure": 0.23615
        },
        "rougeL": {
            "precision": 0.37763,
            "recall": 0.38382,
            "fmeasure": 0.37302
        },
        "rougeLsum": {
            "precision": 0.37763,
            "recall": 0.38382,
            "fmeasure": 0.37302
        },
        "local_recall": {
            "1": 0.461226558540294
        },
        "bertscore": {
            "precision": 0.85566,
            "recall": 0.85099,
            "f1": 0.85297
        },
        "bleurt": -0.18367,
        "meteor": 0.22990864732018568,
        "nubia": {
            "semantic_relation": 3.24881,
            "contradiction": 16.41266,
            "irrelevancy": 63.32578,
            "logical_agreement": 20.26156,
            "grammar_ref": 3.74062,
            "grammar_hyp": 3.52007,
            "nubia_score": 0.52877
        }
    },
    "e2e_nlg_validation": {
        "predictions_file": "T5-base (Baseline)/e2e_nlg_validation",
        "N": 4299,
        "msttr-100": 0.31937,
        "msttr-100_nopunct": 0.31121,
        "total_length": 110311,
        "mean_pred_length": 25.65968829960456,
        "std_pred_length": 6.743137663975145,
        "median_pred_length": 26.0,
        "min_pred_length": 5,
        "max_pred_length": 44,
        "distinct-1": 0.004151897816174271,
        "vocab_size-1": 458,
        "unique-1": 74,
        "entropy-1": 6.137824074023649,
        "distinct-2": 0.021261743953514697,
        "vocab_size-2": 2254,
        "unique-2": 537,
        "entropy-2": 8.305563837776113,
        "cond_entropy-2": 2.0789397904001894,
        "distinct-3": 0.046552554737349205,
        "vocab_size-3": 4735,
        "unique-3": 1296,
        "entropy-3": 9.71955539817349,
        "cond_entropy-3": 1.4310506956897169,
        "total_length-nopunct": 100813,
        "mean_pred_length-nopunct": 23.450337287741334,
        "std_pred_length-nopunct": 6.231446469432542,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.004503387459950601,
        "vocab_size-1-nopunct": 454,
        "unique-1-nopunct": 74,
        "entropy-1-nopunct": 6.192707918326782,
        "distinct-2-nopunct": 0.023530265039268913,
        "vocab_size-2-nopunct": 2271,
        "unique-2-nopunct": 553,
        "entropy-2-nopunct": 8.26264018629175,
        "cond_entropy-2-nopunct": 2.115543796010095,
        "distinct-3-nopunct": 0.050046087946646424,
        "vocab_size-3-nopunct": 4615,
        "unique-3-nopunct": 1268,
        "entropy-3-nopunct": 9.719991103713236,
        "cond_entropy-3-nopunct": 1.4587251436571367,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_validation.json",
        "nist": 4.859154547456599,
        "bleu": 30.19846,
        "rouge1": {
            "precision": 0.67597,
            "recall": 0.7107,
            "fmeasure": 0.68252
        },
        "rouge2": {
            "precision": 0.4031,
            "recall": 0.42211,
            "fmeasure": 0.40629
        },
        "rougeL": {
            "precision": 0.49098,
            "recall": 0.5168,
            "fmeasure": 0.49611
        },
        "rougeLsum": {
            "precision": 0.49098,
            "recall": 0.5168,
            "fmeasure": 0.49611
        },
        "local_recall": {
            "1": 0.7019192023854753
        },
        "bertscore": {
            "precision": 0.90027,
            "recall": 0.90233,
            "f1": 0.90097
        },
        "bleurt": 0.16698,
        "meteor": 0.3624934846653173,
        "nubia": {
            "semantic_relation": 4.22069,
            "contradiction": 3.33633,
            "irrelevancy": 29.64139,
            "logical_agreement": 67.02228,
            "grammar_ref": 4.85661,
            "grammar_hyp": 4.41697,
            "nubia_score": 0.75782
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-1": {
        "predictions_file": "T5-base (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.73909,
        "msttr-100_nopunct": 0.75571,
        "total_length": 2274,
        "mean_pred_length": 21.452830188679247,
        "std_pred_length": 4.211690996100713,
        "median_pred_length": 22.0,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.4173262972735268,
        "vocab_size-1": 949,
        "unique-1": 712,
        "entropy-1": 8.336375345204003,
        "distinct-2": 0.8500922509225092,
        "vocab_size-2": 1843,
        "unique-2": 1700,
        "entropy-2": 10.636384704200868,
        "cond_entropy-2": 2.1086774394151315,
        "distinct-3": 0.9684772065955383,
        "vocab_size-3": 1997,
        "unique-3": 1954,
        "entropy-3": 10.933435288816415,
        "cond_entropy-3": 0.31184017347945175,
        "total_length-nopunct": 2127,
        "mean_pred_length-nopunct": 20.066037735849058,
        "std_pred_length-nopunct": 4.09847847498273,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.44334743770568874,
        "vocab_size-1-nopunct": 943,
        "unique-1-nopunct": 711,
        "entropy-1-nopunct": 8.464871939182594,
        "distinct-2-nopunct": 0.8530430479960416,
        "vocab_size-2-nopunct": 1724,
        "unique-2-nopunct": 1593,
        "entropy-2-nopunct": 10.54252023403752,
        "cond_entropy-2-nopunct": 2.1764936542336972,
        "distinct-3-nopunct": 0.9718015665796345,
        "vocab_size-3-nopunct": 1861,
        "unique-3-nopunct": 1822,
        "entropy-3-nopunct": 10.838902191976626,
        "cond_entropy-3-nopunct": 0.3105149050814283,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.7381771725313953,
        "bleu": 12.98339,
        "rouge1": {
            "precision": 0.44683,
            "recall": 0.4177,
            "fmeasure": 0.42488
        },
        "rouge2": {
            "precision": 0.19749,
            "recall": 0.18267,
            "fmeasure": 0.18659
        },
        "rougeL": {
            "precision": 0.35517,
            "recall": 0.33386,
            "fmeasure": 0.33884
        },
        "rougeLsum": {
            "precision": 0.35517,
            "recall": 0.33386,
            "fmeasure": 0.33884
        },
        "local_recall": {
            "1": 0.3912837517764093
        },
        "bertscore": {
            "precision": 0.84463,
            "recall": 0.83547,
            "f1": 0.83966
        },
        "bleurt": -0.23953,
        "meteor": 0.19886467621323756,
        "nubia": {
            "semantic_relation": 3.19362,
            "contradiction": 17.06771,
            "irrelevancy": 66.03484,
            "logical_agreement": 16.89745,
            "grammar_ref": 3.75111,
            "grammar_hyp": 3.6033,
            "nubia_score": 0.51025
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-2": {
        "predictions_file": "T5-base (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.73174,
        "msttr-100_nopunct": 0.74905,
        "total_length": 2315,
        "mean_pred_length": 21.839622641509433,
        "std_pred_length": 5.050941986594203,
        "median_pred_length": 22.0,
        "min_pred_length": 9,
        "max_pred_length": 38,
        "distinct-1": 0.416414686825054,
        "vocab_size-1": 964,
        "unique-1": 746,
        "entropy-1": 8.329843981589423,
        "distinct-2": 0.8483476686283387,
        "vocab_size-2": 1874,
        "unique-2": 1712,
        "entropy-2": 10.675201532242953,
        "cond_entropy-2": 2.1591273091196284,
        "distinct-3": 0.9700427960057061,
        "vocab_size-3": 2040,
        "unique-3": 1992,
        "entropy-3": 10.969906656143017,
        "cond_entropy-3": 0.2985099142654712,
        "total_length-nopunct": 2162,
        "mean_pred_length-nopunct": 20.39622641509434,
        "std_pred_length-nopunct": 4.94245994302016,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.44264569842738205,
        "vocab_size-1-nopunct": 957,
        "unique-1-nopunct": 743,
        "entropy-1-nopunct": 8.459899957802486,
        "distinct-2-nopunct": 0.8521400778210116,
        "vocab_size-2-nopunct": 1752,
        "unique-2-nopunct": 1602,
        "entropy-2-nopunct": 10.583571653958426,
        "cond_entropy-2-nopunct": 2.2101217950902385,
        "distinct-3-nopunct": 0.9753846153846154,
        "vocab_size-3-nopunct": 1902,
        "unique-3-nopunct": 1860,
        "entropy-3-nopunct": 10.877704908630015,
        "cond_entropy-3-nopunct": 0.29826464168696076,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.7172325411755343,
        "bleu": 11.14753,
        "rouge1": {
            "precision": 0.43625,
            "recall": 0.40859,
            "fmeasure": 0.41495
        },
        "rouge2": {
            "precision": 0.18104,
            "recall": 0.16878,
            "fmeasure": 0.17167
        },
        "rougeL": {
            "precision": 0.34542,
            "recall": 0.32348,
            "fmeasure": 0.32863
        },
        "rougeLsum": {
            "precision": 0.34542,
            "recall": 0.32348,
            "fmeasure": 0.32863
        },
        "local_recall": {
            "1": 0.3921658986175115
        },
        "bertscore": {
            "precision": 0.844,
            "recall": 0.83334,
            "f1": 0.83833
        },
        "bleurt": -0.27773,
        "meteor": 0.1938675954389789,
        "nubia": {
            "semantic_relation": 2.98418,
            "contradiction": 27.12954,
            "irrelevancy": 55.63913,
            "logical_agreement": 17.23133,
            "grammar_ref": 3.66018,
            "grammar_hyp": 3.55551,
            "nubia_score": 0.44958
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-3": {
        "predictions_file": "T5-base (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.76095,
        "total_length": 2275,
        "mean_pred_length": 21.462264150943398,
        "std_pred_length": 4.068226001360889,
        "median_pred_length": 21.0,
        "min_pred_length": 13,
        "max_pred_length": 32,
        "distinct-1": 0.41098901098901097,
        "vocab_size-1": 935,
        "unique-1": 687,
        "entropy-1": 8.348253417909643,
        "distinct-2": 0.8441678192715537,
        "vocab_size-2": 1831,
        "unique-2": 1655,
        "entropy-2": 10.657497654741833,
        "cond_entropy-2": 2.11745104065675,
        "distinct-3": 0.9636451769268056,
        "vocab_size-3": 1988,
        "unique-3": 1933,
        "entropy-3": 10.928897651212324,
        "cond_entropy-3": 0.278949096511504,
        "total_length-nopunct": 2123,
        "mean_pred_length-nopunct": 20.028301886792452,
        "std_pred_length-nopunct": 3.874097696944172,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.4371172868582195,
        "vocab_size-1-nopunct": 928,
        "unique-1-nopunct": 684,
        "entropy-1-nopunct": 8.482675816656368,
        "distinct-2-nopunct": 0.849281110560238,
        "vocab_size-2-nopunct": 1713,
        "unique-2-nopunct": 1556,
        "entropy-2-nopunct": 10.563576580912232,
        "cond_entropy-2-nopunct": 2.166163969566579,
        "distinct-3-nopunct": 0.9686028257456829,
        "vocab_size-3-nopunct": 1851,
        "unique-3-nopunct": 1806,
        "entropy-3-nopunct": 10.830366268882974,
        "cond_entropy-3-nopunct": 0.27160194546426514,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.60512020917001,
        "bleu": 11.95106,
        "rouge1": {
            "precision": 0.42579,
            "recall": 0.40029,
            "fmeasure": 0.40618
        },
        "rouge2": {
            "precision": 0.18413,
            "recall": 0.17447,
            "fmeasure": 0.17601
        },
        "rougeL": {
            "precision": 0.34017,
            "recall": 0.31942,
            "fmeasure": 0.32414
        },
        "rougeLsum": {
            "precision": 0.34017,
            "recall": 0.31942,
            "fmeasure": 0.32414
        },
        "local_recall": {
            "1": 0.3798594847775176
        },
        "bertscore": {
            "precision": 0.83561,
            "recall": 0.82644,
            "f1": 0.83072
        },
        "bleurt": -0.30621,
        "meteor": 0.18371609706127537,
        "nubia": {
            "semantic_relation": 2.99551,
            "contradiction": 17.40741,
            "irrelevancy": 65.92769,
            "logical_agreement": 16.6649,
            "grammar_ref": 3.68583,
            "grammar_hyp": 3.55691,
            "nubia_score": 0.45916
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-4": {
        "predictions_file": "T5-base (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.72955,
        "msttr-100_nopunct": 0.74524,
        "total_length": 2283,
        "mean_pred_length": 21.537735849056602,
        "std_pred_length": 4.615753435711324,
        "median_pred_length": 22.0,
        "min_pred_length": 11,
        "max_pred_length": 34,
        "distinct-1": 0.4296977660972405,
        "vocab_size-1": 981,
        "unique-1": 760,
        "entropy-1": 8.374113218378765,
        "distinct-2": 0.8663298116674323,
        "vocab_size-2": 1886,
        "unique-2": 1757,
        "entropy-2": 10.691592984409237,
        "cond_entropy-2": 2.125378817916753,
        "distinct-3": 0.9744084983099952,
        "vocab_size-3": 2018,
        "unique-3": 1982,
        "entropy-3": 10.95491190177269,
        "cond_entropy-3": 0.27202604774637956,
        "total_length-nopunct": 2126,
        "mean_pred_length-nopunct": 20.056603773584907,
        "std_pred_length-nopunct": 4.511683342041381,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.4576669802445908,
        "vocab_size-1-nopunct": 973,
        "unique-1-nopunct": 759,
        "entropy-1-nopunct": 8.49178494951005,
        "distinct-2-nopunct": 0.8688118811881188,
        "vocab_size-2-nopunct": 1755,
        "unique-2-nopunct": 1640,
        "entropy-2-nopunct": 10.586084835112247,
        "cond_entropy-2-nopunct": 2.1896879719898465,
        "distinct-3-nopunct": 0.9770114942528736,
        "vocab_size-3-nopunct": 1870,
        "unique-3-nopunct": 1837,
        "entropy-3-nopunct": 10.849951553133785,
        "cond_entropy-3-nopunct": 0.2758250807824827,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.2705463288728915,
        "bleu": 9.91192,
        "rouge1": {
            "precision": 0.40722,
            "recall": 0.37091,
            "fmeasure": 0.38076
        },
        "rouge2": {
            "precision": 0.16063,
            "recall": 0.14714,
            "fmeasure": 0.1502
        },
        "rougeL": {
            "precision": 0.31693,
            "recall": 0.28882,
            "fmeasure": 0.2964
        },
        "rougeLsum": {
            "precision": 0.31693,
            "recall": 0.28882,
            "fmeasure": 0.2964
        },
        "local_recall": {
            "1": 0.34379263301500684
        },
        "bertscore": {
            "precision": 0.83317,
            "recall": 0.82067,
            "f1": 0.82656
        },
        "bleurt": -0.32138,
        "meteor": 0.1685315366289724,
        "nubia": {
            "semantic_relation": 2.91702,
            "contradiction": 18.22419,
            "irrelevancy": 65.74282,
            "logical_agreement": 16.03299,
            "grammar_ref": 3.83852,
            "grammar_hyp": 3.59645,
            "nubia_score": 0.43408
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-5": {
        "predictions_file": "T5-base (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.73696,
        "msttr-100_nopunct": 0.74905,
        "total_length": 2316,
        "mean_pred_length": 21.849056603773583,
        "std_pred_length": 4.856026119785733,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 34,
        "distinct-1": 0.4110535405872193,
        "vocab_size-1": 952,
        "unique-1": 704,
        "entropy-1": 8.325876064695992,
        "distinct-2": 0.8443438914027149,
        "vocab_size-2": 1866,
        "unique-2": 1713,
        "entropy-2": 10.641608098027733,
        "cond_entropy-2": 2.1298062595699214,
        "distinct-3": 0.9615019011406845,
        "vocab_size-3": 2023,
        "unique-3": 1967,
        "entropy-3": 10.950163131677227,
        "cond_entropy-3": 0.31966098823891553,
        "total_length-nopunct": 2154,
        "mean_pred_length-nopunct": 20.32075471698113,
        "std_pred_length-nopunct": 4.677418998444127,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.43779015784586817,
        "vocab_size-1-nopunct": 943,
        "unique-1-nopunct": 699,
        "entropy-1-nopunct": 8.453635528271136,
        "distinct-2-nopunct": 0.84912109375,
        "vocab_size-2-nopunct": 1739,
        "unique-2-nopunct": 1605,
        "entropy-2-nopunct": 10.536787736632895,
        "cond_entropy-2-nopunct": 2.1763046597381854,
        "distinct-3-nopunct": 0.9660144181256437,
        "vocab_size-3-nopunct": 1876,
        "unique-3-nopunct": 1830,
        "entropy-3-nopunct": 10.845251837148117,
        "cond_entropy-3-nopunct": 0.3165890087652967,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.427896179978723,
        "bleu": 10.52736,
        "rouge1": {
            "precision": 0.41325,
            "recall": 0.37714,
            "fmeasure": 0.38646
        },
        "rouge2": {
            "precision": 0.16425,
            "recall": 0.15056,
            "fmeasure": 0.15352
        },
        "rougeL": {
            "precision": 0.32098,
            "recall": 0.2929,
            "fmeasure": 0.29982
        },
        "rougeLsum": {
            "precision": 0.32098,
            "recall": 0.2929,
            "fmeasure": 0.29982
        },
        "local_recall": {
            "1": 0.3606782768102658
        },
        "bertscore": {
            "precision": 0.83783,
            "recall": 0.82704,
            "f1": 0.83206
        },
        "bleurt": -0.27966,
        "meteor": 0.17330825207115405,
        "nubia": {
            "semantic_relation": 2.93312,
            "contradiction": 20.12906,
            "irrelevancy": 66.83218,
            "logical_agreement": 13.03876,
            "grammar_ref": 3.63886,
            "grammar_hyp": 3.55175,
            "nubia_score": 0.43567
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 1328,
        "msttr-100": 0.68581,
        "msttr-100_nopunct": 0.71241,
        "total_length": 25346,
        "mean_pred_length": 19.085843373493976,
        "std_pred_length": 4.8868379482129995,
        "median_pred_length": 19.0,
        "min_pred_length": 7,
        "max_pred_length": 52,
        "distinct-1": 0.07914463820721218,
        "vocab_size-1": 2006,
        "unique-1": 979,
        "entropy-1": 7.983885881271764,
        "distinct-2": 0.2615954700641186,
        "vocab_size-2": 6283,
        "unique-2": 3699,
        "entropy-2": 11.065413172382385,
        "cond_entropy-2": 2.90966539499061,
        "distinct-3": 0.4420449537241075,
        "vocab_size-3": 10030,
        "unique-3": 7005,
        "entropy-3": 12.333052113072396,
        "cond_entropy-3": 1.3244047483716375,
        "total_length-nopunct": 22419,
        "mean_pred_length-nopunct": 16.881777108433734,
        "std_pred_length-nopunct": 4.370840450013701,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.08889780989339399,
        "vocab_size-1-nopunct": 1993,
        "unique-1-nopunct": 977,
        "entropy-1-nopunct": 8.19190769394472,
        "distinct-2-nopunct": 0.28030913659854917,
        "vocab_size-2-nopunct": 5912,
        "unique-2-nopunct": 3613,
        "entropy-2-nopunct": 10.993179917721843,
        "cond_entropy-2-nopunct": 2.9405312766788554,
        "distinct-3-nopunct": 0.46556696857764507,
        "vocab_size-3-nopunct": 9201,
        "unique-3-nopunct": 6579,
        "entropy-3-nopunct": 12.250323916178456,
        "cond_entropy-3-nopunct": 1.3361370576234635,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.862216183961258,
        "bleu": 32.94881,
        "rouge1": {
            "precision": 0.64875,
            "recall": 0.62623,
            "fmeasure": 0.6259
        },
        "rouge2": {
            "precision": 0.41974,
            "recall": 0.40844,
            "fmeasure": 0.40638
        },
        "rougeL": {
            "precision": 0.55379,
            "recall": 0.53495,
            "fmeasure": 0.53477
        },
        "rougeLsum": {
            "precision": 0.55379,
            "recall": 0.53495,
            "fmeasure": 0.53477
        },
        "local_recall": {
            "1": 0.6059901531728665
        },
        "bertscore": {
            "precision": 0.89154,
            "recall": 0.88218,
            "f1": 0.88645
        },
        "bleurt": -0.03132,
        "meteor": 0.3333258968996405,
        "nubia": {
            "semantic_relation": 4.1896,
            "contradiction": 7.00822,
            "irrelevancy": 18.58016,
            "logical_agreement": 74.41161,
            "grammar_ref": 4.79322,
            "grammar_hyp": 4.65878,
            "nubia_score": 0.72965
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-6": {
        "predictions_file": "T5-base (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.72227,
        "msttr-100_nopunct": 0.73952,
        "total_length": 2255,
        "mean_pred_length": 21.27358490566038,
        "std_pred_length": 4.5402456480544995,
        "median_pred_length": 21.0,
        "min_pred_length": 9,
        "max_pred_length": 32,
        "distinct-1": 0.40487804878048783,
        "vocab_size-1": 913,
        "unique-1": 685,
        "entropy-1": 8.238711792397712,
        "distinct-2": 0.8385295486272685,
        "vocab_size-2": 1802,
        "unique-2": 1653,
        "entropy-2": 10.568455624072003,
        "cond_entropy-2": 2.1409404924216586,
        "distinct-3": 0.9642682329907,
        "vocab_size-3": 1970,
        "unique-3": 1922,
        "entropy-3": 10.90877964854866,
        "cond_entropy-3": 0.35541982315007453,
        "total_length-nopunct": 2110,
        "mean_pred_length-nopunct": 19.90566037735849,
        "std_pred_length-nopunct": 4.383778636055826,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.43033175355450237,
        "vocab_size-1-nopunct": 908,
        "unique-1-nopunct": 685,
        "entropy-1-nopunct": 8.354311633895824,
        "distinct-2-nopunct": 0.8368263473053892,
        "vocab_size-2-nopunct": 1677,
        "unique-2-nopunct": 1538,
        "entropy-2-nopunct": 10.457879934880218,
        "cond_entropy-2-nopunct": 2.2074829689943396,
        "distinct-3-nopunct": 0.9678609062170705,
        "vocab_size-3-nopunct": 1837,
        "unique-3-nopunct": 1794,
        "entropy-3-nopunct": 10.814182281239038,
        "cond_entropy-3-nopunct": 0.37349604076174064,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.3272393781140046,
        "bleu": 8.92533,
        "rouge1": {
            "precision": 0.41768,
            "recall": 0.38131,
            "fmeasure": 0.3898
        },
        "rouge2": {
            "precision": 0.15323,
            "recall": 0.13729,
            "fmeasure": 0.14096
        },
        "rougeL": {
            "precision": 0.32162,
            "recall": 0.29446,
            "fmeasure": 0.30006
        },
        "rougeLsum": {
            "precision": 0.32162,
            "recall": 0.29446,
            "fmeasure": 0.30006
        },
        "local_recall": {
            "1": 0.36051899907321594
        },
        "bertscore": {
            "precision": 0.83294,
            "recall": 0.8221,
            "f1": 0.82711
        },
        "bleurt": -0.35969,
        "meteor": 0.16689114820997508,
        "nubia": {
            "semantic_relation": 2.86458,
            "contradiction": 27.79512,
            "irrelevancy": 61.7505,
            "logical_agreement": 10.45438,
            "grammar_ref": 3.80483,
            "grammar_hyp": 3.60249,
            "nubia_score": 0.41709
        }
    },
    "schema_guided_dialog_validation": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_validation",
        "N": 10000,
        "msttr-100": 0.69567,
        "msttr-100_nopunct": 0.72361,
        "total_length": 122526,
        "mean_pred_length": 12.2526,
        "std_pred_length": 7.2668558015141596,
        "median_pred_length": 10.0,
        "min_pred_length": 1,
        "max_pred_length": 58,
        "distinct-1": 0.03386220067577494,
        "vocab_size-1": 4149,
        "unique-1": 1750,
        "entropy-1": 8.10449661369035,
        "distinct-2": 0.1372393935623767,
        "vocab_size-2": 15443,
        "unique-2": 8110,
        "entropy-2": 11.524776291806484,
        "cond_entropy-2": 3.1558524656286817,
        "distinct-3": 0.27876559345343177,
        "vocab_size-3": 28581,
        "unique-3": 18067,
        "entropy-3": 13.041111729716567,
        "cond_entropy-3": 1.5370930869735895,
        "total_length-nopunct": 107510,
        "mean_pred_length-nopunct": 10.751,
        "std_pred_length-nopunct": 6.673694553993313,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 52,
        "distinct-1-nopunct": 0.038442935540879915,
        "vocab_size-1-nopunct": 4133,
        "unique-1-nopunct": 1747,
        "entropy-1-nopunct": 8.336002877421704,
        "distinct-2-nopunct": 0.15143062250025638,
        "vocab_size-2-nopunct": 14766,
        "unique-2-nopunct": 8115,
        "entropy-2-nopunct": 11.42086243099105,
        "cond_entropy-2-nopunct": 3.232071341440247,
        "distinct-3-nopunct": 0.30130709992916066,
        "vocab_size-3-nopunct": 26371,
        "unique-3-nopunct": 17238,
        "entropy-3-nopunct": 12.931158955272068,
        "cond_entropy-3-nopunct": 1.5444781553061284,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_validation.json",
        "nist": 7.74402818240522,
        "bleu": 37.44662,
        "rouge1": {
            "precision": 0.6371,
            "recall": 0.61843,
            "fmeasure": 0.61446
        },
        "rouge2": {
            "precision": 0.42383,
            "recall": 0.41243,
            "fmeasure": 0.40846
        },
        "rougeL": {
            "precision": 0.58062,
            "recall": 0.56335,
            "fmeasure": 0.55988
        },
        "rougeLsum": {
            "precision": 0.58062,
            "recall": 0.56335,
            "fmeasure": 0.55988
        },
        "local_recall": {
            "1": 0.6235955056179775
        },
        "bertscore": {
            "precision": 0.8877,
            "recall": 0.88176,
            "f1": 0.88415
        },
        "bleurt": 0.05712,
        "meteor": 0.3514235693214679,
        "nubia": {
            "semantic_relation": 3.89423,
            "contradiction": 3.66055,
            "irrelevancy": 18.17001,
            "logical_agreement": 78.16944,
            "grammar_ref": 4.88727,
            "grammar_hyp": 4.67144,
            "nubia_score": 0.71779
        }
    },
    "e2e_nlg_test": {
        "predictions_file": "T5-base (Baseline)/e2e_nlg_test",
        "N": 4693,
        "msttr-100": 0.3151,
        "msttr-100_nopunct": 0.30805,
        "total_length": 119995,
        "mean_pred_length": 25.568932452588964,
        "std_pred_length": 6.622526923256877,
        "median_pred_length": 25.0,
        "min_pred_length": 8,
        "max_pred_length": 51,
        "distinct-1": 0.0033418059085795243,
        "vocab_size-1": 401,
        "unique-1": 48,
        "entropy-1": 6.071309032729065,
        "distinct-2": 0.018221713413470713,
        "vocab_size-2": 2101,
        "unique-2": 410,
        "entropy-2": 8.286986880828024,
        "cond_entropy-2": 2.127073034079077,
        "distinct-3": 0.0423564086105109,
        "vocab_size-3": 4685,
        "unique-3": 1091,
        "entropy-3": 9.710335154370366,
        "cond_entropy-3": 1.4343725622418348,
        "total_length-nopunct": 109832,
        "mean_pred_length-nopunct": 23.403366716386106,
        "std_pred_length-nopunct": 6.092430790366881,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.003623716221137738,
        "vocab_size-1-nopunct": 398,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 6.119777412797619,
        "distinct-2-nopunct": 0.020030626123512682,
        "vocab_size-2-nopunct": 2106,
        "unique-2-nopunct": 432,
        "entropy-2-nopunct": 8.25822203147772,
        "cond_entropy-2-nopunct": 2.1826444461271004,
        "distinct-3-nopunct": 0.045586683392071364,
        "vocab_size-3-nopunct": 4579,
        "unique-3-nopunct": 1100,
        "entropy-3-nopunct": 9.731657598858055,
        "cond_entropy-3-nopunct": 1.4703588172886626,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 5.173533919710649,
        "bleu": 29.9108,
        "rouge1": {
            "precision": 0.7284,
            "recall": 0.70773,
            "fmeasure": 0.70685
        },
        "rouge2": {
            "precision": 0.42815,
            "recall": 0.4155,
            "fmeasure": 0.4149
        },
        "rougeL": {
            "precision": 0.51318,
            "recall": 0.49921,
            "fmeasure": 0.49813
        },
        "rougeLsum": {
            "precision": 0.51318,
            "recall": 0.49921,
            "fmeasure": 0.49813
        },
        "local_recall": {
            "1": 0.6970041751587945
        },
        "bertscore": {
            "precision": 0.91232,
            "recall": 0.90427,
            "f1": 0.90794
        },
        "bleurt": 0.17248,
        "meteor": 0.3583529290475939,
        "nubia": {
            "semantic_relation": 4.25473,
            "contradiction": 3.31483,
            "irrelevancy": 27.61747,
            "logical_agreement": 69.0677,
            "grammar_ref": 4.83021,
            "grammar_hyp": 4.49898,
            "nubia_score": 0.76548
        }
    },
    "e2e_nlg_challenge_train_sample": {
        "predictions_file": "T5-base (Baseline)/e2e_nlg_challenge_train_sample",
        "N": 500
    },
    "e2e_nlg_challenge_validation_sample": {
        "predictions_file": "T5-base (Baseline)/e2e_nlg_challenge_validation_sample",
        "N": 500
    },
    "e2e_nlg_challenge_test_scramble": {
        "predictions_file": "T5-base (Baseline)/e2e_nlg_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.50567,
        "msttr-100_nopunct": 0.51905,
        "total_length": 12711,
        "mean_pred_length": 25.422,
        "std_pred_length": 6.848643369310451,
        "median_pred_length": 25.5,
        "min_pred_length": 8,
        "max_pred_length": 47,
        "distinct-1": 0.022264180630949572,
        "vocab_size-1": 283,
        "unique-1": 83,
        "entropy-1": 6.067337825520815,
        "distinct-2": 0.09393170092539514,
        "vocab_size-2": 1147,
        "unique-2": 491,
        "entropy-2": 8.23012160726276,
        "cond_entropy-2": 2.072579717505408,
        "distinct-3": 0.19221244983348987,
        "vocab_size-3": 2251,
        "unique-3": 1168,
        "entropy-3": 9.546920184527067,
        "cond_entropy-3": 1.3256045679648745,
        "total_length-nopunct": 11637,
        "mean_pred_length-nopunct": 23.274,
        "std_pred_length-nopunct": 6.3156095509459735,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.02397525135344161,
        "vocab_size-1-nopunct": 279,
        "unique-1-nopunct": 81,
        "entropy-1-nopunct": 6.11697572347701,
        "distinct-2-nopunct": 0.10002693723623957,
        "vocab_size-2-nopunct": 1114,
        "unique-2-nopunct": 502,
        "entropy-2-nopunct": 8.195880865711327,
        "cond_entropy-2-nopunct": 2.123838196192281,
        "distinct-3-nopunct": 0.20334680831061389,
        "vocab_size-3-nopunct": 2163,
        "unique-3-nopunct": 1154,
        "entropy-3-nopunct": 9.560290597295705,
        "cond_entropy-3-nopunct": 1.359411877392993,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_challenge_test_scramble.json",
        "nist": 5.128208325903791,
        "bleu": 29.53056,
        "rouge1": {
            "precision": 0.72947,
            "recall": 0.70472,
            "fmeasure": 0.70607
        },
        "rouge2": {
            "precision": 0.42586,
            "recall": 0.41076,
            "fmeasure": 0.41167
        },
        "rougeL": {
            "precision": 0.50535,
            "recall": 0.48851,
            "fmeasure": 0.48922
        },
        "rougeLsum": {
            "precision": 0.50535,
            "recall": 0.48851,
            "fmeasure": 0.48922
        },
        "local_recall": {
            "1": 0.6960848135404073
        },
        "bertscore": {
            "precision": 0.91205,
            "recall": 0.90333,
            "f1": 0.90736
        },
        "bleurt": 0.16555,
        "meteor": 0.3578840609518144,
        "nubia": {
            "semantic_relation": 4.23355,
            "contradiction": 3.88797,
            "irrelevancy": 26.86217,
            "logical_agreement": 69.24987,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.49901,
            "nubia_score": 0.75859
        }
    },
    "common_gen_validation": {
        "predictions_file": "T5-base (Baseline)/common_gen_validation",
        "N": 993,
        "msttr-100": 0.59752,
        "msttr-100_nopunct": 0.62167,
        "total_length": 11774,
        "mean_pred_length": 11.856998992950654,
        "std_pred_length": 3.0208563135423163,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 24,
        "distinct-1": 0.13631730932563274,
        "vocab_size-1": 1605,
        "unique-1": 841,
        "entropy-1": 7.425301934086601,
        "distinct-2": 0.47398200537983487,
        "vocab_size-2": 5110,
        "unique-2": 3759,
        "entropy-2": 11.149000155631084,
        "cond_entropy-2": 3.4886765842096716,
        "distinct-3": 0.7467306906416019,
        "vocab_size-3": 7309,
        "unique-3": 6296,
        "entropy-3": 12.43449530444645,
        "cond_entropy-3": 1.3495127848680346,
        "total_length-nopunct": 10874,
        "mean_pred_length-nopunct": 10.950654582074522,
        "std_pred_length-nopunct": 2.9244570810759107,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.14741585433143278,
        "vocab_size-1-nopunct": 1603,
        "unique-1-nopunct": 841,
        "entropy-1-nopunct": 7.592125860460104,
        "distinct-2-nopunct": 0.4728266369800627,
        "vocab_size-2-nopunct": 4672,
        "unique-2-nopunct": 3487,
        "entropy-2-nopunct": 10.967458223276424,
        "cond_entropy-2-nopunct": 3.6796223615096864,
        "distinct-3-nopunct": 0.7496624662466247,
        "vocab_size-3-nopunct": 6663,
        "unique-3-nopunct": 5768,
        "entropy-3-nopunct": 12.292199421107808,
        "cond_entropy-3-nopunct": 1.4220130587820974,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/common_gen_validation.json",
        "nist": 6.039925754281761,
        "bleu": 19.49326,
        "rouge1": {
            "precision": 0.5705,
            "recall": 0.5991,
            "fmeasure": 0.57215
        },
        "rouge2": {
            "precision": 0.2563,
            "recall": 0.26314,
            "fmeasure": 0.25292
        },
        "rougeL": {
            "precision": 0.48982,
            "recall": 0.51116,
            "fmeasure": 0.48981
        },
        "rougeLsum": {
            "precision": 0.48982,
            "recall": 0.51116,
            "fmeasure": 0.48981
        },
        "local_recall": {
            "1": 0.10873640794900638,
            "2": 0.311436170212766,
            "3": 0.4777327935222672,
            "4": 0.7224112785610112,
            "5": 0.740343347639485,
            "6": 0.75,
            "7": 1.0,
            "8": 1.0
        },
        "bertscore": {
            "precision": 0.86744,
            "recall": 0.87518,
            "f1": 0.86987
        },
        "bleurt": -0.5533,
        "meteor": 0.23974573932128776,
        "nubia": {
            "semantic_relation": 2.86561,
            "contradiction": 33.37824,
            "irrelevancy": 36.91378,
            "logical_agreement": 29.70798,
            "grammar_ref": 4.64808,
            "grammar_hyp": 4.61059,
            "nubia_score": 0.38477
        }
    },
    "common_gen_test": {
        "predictions_file": "T5-base (Baseline)/common_gen_test",
        "N": 1497
    },
    "common_gen_challenge_train_sample": {
        "predictions_file": "T5-base (Baseline)/common_gen_challenge_train_sample",
        "N": 500
    },
    "common_gen_challenge_validation_sample": {
        "predictions_file": "T5-base (Baseline)/common_gen_challenge_validation_sample",
        "N": 500
    },
    "common_gen_challenge_test_scramble": {
        "predictions_file": "T5-base (Baseline)/common_gen_challenge_test_scramble",
        "N": 500
    },
    "schema_guided_dialog_test": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_test",
        "N": 10000,
        "msttr-100": 0.68407,
        "msttr-100_nopunct": 0.71196,
        "total_length": 128106,
        "mean_pred_length": 12.8106,
        "std_pred_length": 7.3412347490051015,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 53,
        "distinct-1": 0.03340983248247545,
        "vocab_size-1": 4280,
        "unique-1": 1872,
        "entropy-1": 8.04162970156197,
        "distinct-2": 0.13934093102805953,
        "vocab_size-2": 16457,
        "unique-2": 8807,
        "entropy-2": 11.554353547967604,
        "cond_entropy-2": 3.2528884273668783,
        "distinct-3": 0.28436904519638134,
        "vocab_size-3": 30742,
        "unique-3": 19591,
        "entropy-3": 13.143497803866316,
        "cond_entropy-3": 1.6148777834522083,
        "total_length-nopunct": 112527,
        "mean_pred_length-nopunct": 11.2527,
        "std_pred_length-nopunct": 6.7222498250213825,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.03789312787153305,
        "vocab_size-1-nopunct": 4264,
        "unique-1-nopunct": 1870,
        "entropy-1-nopunct": 8.259421389052141,
        "distinct-2-nopunct": 0.15337423312883436,
        "vocab_size-2-nopunct": 15725,
        "unique-2-nopunct": 8801,
        "entropy-2-nopunct": 11.45549928190949,
        "cond_entropy-2-nopunct": 3.3492711609425405,
        "distinct-3-nopunct": 0.30720599995677267,
        "vocab_size-3-nopunct": 28427,
        "unique-3-nopunct": 18722,
        "entropy-3-nopunct": 13.03827640523454,
        "cond_entropy-3-nopunct": 1.6392724542250594,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.990701244167269,
        "bleu": 32.60126,
        "rouge1": {
            "precision": 0.58637,
            "recall": 0.56228,
            "fmeasure": 0.56242
        },
        "rouge2": {
            "precision": 0.36814,
            "recall": 0.35407,
            "fmeasure": 0.35328
        },
        "rougeL": {
            "precision": 0.53028,
            "recall": 0.50809,
            "fmeasure": 0.50846
        },
        "rougeLsum": {
            "precision": 0.53028,
            "recall": 0.50809,
            "fmeasure": 0.50846
        },
        "local_recall": {
            "1": 0.5717738853786203
        },
        "bertscore": {
            "precision": 0.87605,
            "recall": 0.86899,
            "f1": 0.87202
        },
        "bleurt": -0.05465,
        "meteor": 0.31864666057171054,
        "nubia": {
            "semantic_relation": 3.64091,
            "contradiction": 7.9328,
            "irrelevancy": 21.84123,
            "logical_agreement": 70.22597,
            "grammar_ref": 4.76329,
            "grammar_hyp": 4.56237,
            "nubia_score": 0.64908
        }
    },
    "schema_guided_dialog_challenge_train_sample": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_challenge_train_sample",
        "N": 500
    },
    "schema_guided_dialog_challenge_validation_sample": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_challenge_validation_sample",
        "N": 500
    },
    "mlsum_de_validation": {
        "predictions_file": "T5-base (Baseline)/mlsum_de_validation",
        "N": 11392,
        "msttr-100": 0.74597,
        "msttr-100_nopunct": 0.79668,
        "total_length": 264615,
        "mean_pred_length": 23.228142556179776,
        "std_pred_length": 8.11424340640145,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 75,
        "distinct-1": 0.12460366948207774,
        "vocab_size-1": 32972,
        "unique-1": 20123,
        "entropy-1": 10.33561884208831,
        "distinct-2": 0.5272901750630867,
        "vocab_size-2": 133522,
        "unique-2": 108400,
        "entropy-2": 15.670427427060998,
        "cond_entropy-2": 5.045026496423422,
        "distinct-3": 0.8298853331458746,
        "vocab_size-3": 200692,
        "unique-3": 184242,
        "entropy-3": 17.29821774685357,
        "cond_entropy-3": 1.6041577577566344,
        "total_length-nopunct": 235212,
        "mean_pred_length-nopunct": 20.647120786516854,
        "std_pred_length-nopunct": 7.136494187932852,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 67,
        "distinct-1-nopunct": 0.1401246535040729,
        "vocab_size-1-nopunct": 32959,
        "unique-1-nopunct": 20122,
        "entropy-1-nopunct": 10.8873801491238,
        "distinct-2-nopunct": 0.5835537485479403,
        "vocab_size-2-nopunct": 130611,
        "unique-2-nopunct": 108401,
        "entropy-2-nopunct": 15.91990598034067,
        "cond_entropy-2-nopunct": 5.158995973698151,
        "distinct-3-nopunct": 0.8645611689607773,
        "vocab_size-3-nopunct": 183657,
        "unique-3-nopunct": 171295,
        "entropy-3-nopunct": 17.24375224913085,
        "cond_entropy-3-nopunct": 1.3750198091644297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_validation.json",
        "nist": 7.6942796286993795,
        "bleu": 37.36086,
        "rouge1": {
            "precision": 0.45621,
            "recall": 0.42874,
            "fmeasure": 0.43447
        },
        "rouge2": {
            "precision": 0.33631,
            "recall": 0.32928,
            "fmeasure": 0.32962
        },
        "rougeL": {
            "precision": 0.42002,
            "recall": 0.39851,
            "fmeasure": 0.40271
        },
        "rougeLsum": {
            "precision": 0.42002,
            "recall": 0.39851,
            "fmeasure": 0.40271
        },
        "local_recall": {
            "1": 0.44285198266174347
        },
        "bertscore": {
            "precision": 0.89388,
            "recall": 0.88793,
            "f1": 0.89075
        },
        "bleurt": -0.2577,
        "meteor": 0.4118198212218553,
        "nubia": {
            "semantic_relation": 2.70615,
            "contradiction": 25.953,
            "irrelevancy": 38.79557,
            "logical_agreement": 35.25143,
            "grammar_ref": 5.04919,
            "grammar_hyp": 4.99706,
            "nubia_score": 0.39923
        }
    },
    "schema_guided_dialog_challenge_test_backtranslation": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_challenge_test_backtranslation",
        "N": 500,
        "msttr-100": 0.67587,
        "msttr-100_nopunct": 0.70291,
        "total_length": 6357,
        "mean_pred_length": 12.714,
        "std_pred_length": 7.079279906883185,
        "median_pred_length": 10.0,
        "min_pred_length": 4,
        "max_pred_length": 38,
        "distinct-1": 0.15117193644801008,
        "vocab_size-1": 961,
        "unique-1": 552,
        "entropy-1": 7.716815546297078,
        "distinct-2": 0.45381594673040804,
        "vocab_size-2": 2658,
        "unique-2": 1816,
        "entropy-2": 10.502331264011797,
        "cond_entropy-2": 2.5316619692094107,
        "distinct-3": 0.6583908904237447,
        "vocab_size-3": 3527,
        "unique-3": 2814,
        "entropy-3": 11.300357699701072,
        "cond_entropy-3": 0.8247452255089399,
        "total_length-nopunct": 5567,
        "mean_pred_length-nopunct": 11.134,
        "std_pred_length-nopunct": 6.532996555945824,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.17046883420154482,
        "vocab_size-1-nopunct": 949,
        "unique-1-nopunct": 549,
        "entropy-1-nopunct": 7.903539161739423,
        "distinct-2-nopunct": 0.4679297414643773,
        "vocab_size-2-nopunct": 2371,
        "unique-2-nopunct": 1664,
        "entropy-2-nopunct": 10.320216090553242,
        "cond_entropy-2-nopunct": 2.55411353235003,
        "distinct-3-nopunct": 0.6706809721918108,
        "vocab_size-3-nopunct": 3063,
        "unique-3-nopunct": 2487,
        "entropy-3-nopunct": 11.086615055542783,
        "cond_entropy-3-nopunct": 0.810605146424162,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_backtranslation.json",
        "nist": 5.9220963851185,
        "bleu": 31.89798,
        "rouge1": {
            "precision": 0.55958,
            "recall": 0.55226,
            "fmeasure": 0.54266
        },
        "rouge2": {
            "precision": 0.33864,
            "recall": 0.33673,
            "fmeasure": 0.3296
        },
        "rougeL": {
            "precision": 0.50312,
            "recall": 0.49759,
            "fmeasure": 0.4886
        },
        "rougeLsum": {
            "precision": 0.50312,
            "recall": 0.49759,
            "fmeasure": 0.4886
        },
        "local_recall": {
            "1": 0.5689910979228486
        },
        "bertscore": {
            "precision": 0.87102,
            "recall": 0.86809,
            "f1": 0.869
        },
        "bleurt": -0.05916,
        "meteor": 0.3161653900865178,
        "nubia": {
            "semantic_relation": 3.60096,
            "contradiction": 7.47767,
            "irrelevancy": 22.61021,
            "logical_agreement": 69.91212,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.46374,
            "nubia_score": 0.64706
        }
    },
    "schema_guided_dialog_challenge_test_bfp02": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_challenge_test_bfp02",
        "N": 500,
        "msttr-100": 0.69032,
        "msttr-100_nopunct": 0.71545,
        "total_length": 6348,
        "mean_pred_length": 12.696,
        "std_pred_length": 7.489431487102343,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 40,
        "distinct-1": 0.15170132325141777,
        "vocab_size-1": 963,
        "unique-1": 532,
        "entropy-1": 7.808969504922439,
        "distinct-2": 0.46238030095759236,
        "vocab_size-2": 2704,
        "unique-2": 1847,
        "entropy-2": 10.595475534710287,
        "cond_entropy-2": 2.5531394599662844,
        "distinct-3": 0.6707180254300673,
        "vocab_size-3": 3587,
        "unique-3": 2884,
        "entropy-3": 11.3908889941041,
        "cond_entropy-3": 0.8204776068707175,
        "total_length-nopunct": 5578,
        "mean_pred_length-nopunct": 11.156,
        "std_pred_length-nopunct": 6.873984579557915,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.17013266403728936,
        "vocab_size-1-nopunct": 949,
        "unique-1-nopunct": 528,
        "entropy-1-nopunct": 7.982766272142924,
        "distinct-2-nopunct": 0.47892871209137455,
        "vocab_size-2-nopunct": 2432,
        "unique-2-nopunct": 1699,
        "entropy-2-nopunct": 10.433210116637667,
        "cond_entropy-2-nopunct": 2.5809549619940224,
        "distinct-3-nopunct": 0.6892186817983413,
        "vocab_size-3-nopunct": 3158,
        "unique-3-nopunct": 2589,
        "entropy-3-nopunct": 11.211932990771102,
        "cond_entropy-3-nopunct": 0.8075665367525504,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp02.json",
        "nist": 6.185958453363589,
        "bleu": 31.89502,
        "rouge1": {
            "precision": 0.58912,
            "recall": 0.54583,
            "fmeasure": 0.55518
        },
        "rouge2": {
            "precision": 0.369,
            "recall": 0.34084,
            "fmeasure": 0.34568
        },
        "rougeL": {
            "precision": 0.5286,
            "recall": 0.48904,
            "fmeasure": 0.49771
        },
        "rougeLsum": {
            "precision": 0.5286,
            "recall": 0.48904,
            "fmeasure": 0.49771
        },
        "local_recall": {
            "1": 0.5595258846086805
        },
        "bertscore": {
            "precision": 0.87499,
            "recall": 0.86292,
            "f1": 0.86844
        },
        "bleurt": -0.0838,
        "meteor": 0.3162332548284832,
        "nubia": {
            "semantic_relation": 3.64535,
            "contradiction": 7.49453,
            "irrelevancy": 19.3649,
            "logical_agreement": 73.14057,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.6797,
            "nubia_score": 0.64506
        }
    },
    "schema_guided_dialog_challenge_test_bfp05": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_challenge_test_bfp05",
        "N": 500,
        "msttr-100": 0.67797,
        "msttr-100_nopunct": 0.70635,
        "total_length": 5959,
        "mean_pred_length": 11.918,
        "std_pred_length": 6.945737973750521,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 49,
        "distinct-1": 0.1587514683671757,
        "vocab_size-1": 946,
        "unique-1": 551,
        "entropy-1": 7.710306309486362,
        "distinct-2": 0.4630884777431764,
        "vocab_size-2": 2528,
        "unique-2": 1776,
        "entropy-2": 10.435952742211168,
        "cond_entropy-2": 2.470157055974305,
        "distinct-3": 0.6660617059891107,
        "vocab_size-3": 3303,
        "unique-3": 2683,
        "entropy-3": 11.21448175046982,
        "cond_entropy-3": 0.7951359162744063,
        "total_length-nopunct": 5238,
        "mean_pred_length-nopunct": 10.476,
        "std_pred_length-nopunct": 6.423816933879731,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.1785032455135548,
        "vocab_size-1-nopunct": 935,
        "unique-1-nopunct": 548,
        "entropy-1-nopunct": 7.8886414026758045,
        "distinct-2-nopunct": 0.4769945124525116,
        "vocab_size-2-nopunct": 2260,
        "unique-2-nopunct": 1625,
        "entropy-2-nopunct": 10.252473640287386,
        "cond_entropy-2-nopunct": 2.4942385803356912,
        "distinct-3-nopunct": 0.6779141104294478,
        "vocab_size-3-nopunct": 2873,
        "unique-3-nopunct": 2372,
        "entropy-3-nopunct": 11.008488002888935,
        "cond_entropy-3-nopunct": 0.7891251464539614,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp05.json",
        "nist": 6.075735776427181,
        "bleu": 32.13038,
        "rouge1": {
            "precision": 0.5922,
            "recall": 0.54279,
            "fmeasure": 0.55406
        },
        "rouge2": {
            "precision": 0.36319,
            "recall": 0.32783,
            "fmeasure": 0.33605
        },
        "rougeL": {
            "precision": 0.53952,
            "recall": 0.49346,
            "fmeasure": 0.50427
        },
        "rougeLsum": {
            "precision": 0.53952,
            "recall": 0.49346,
            "fmeasure": 0.50427
        },
        "local_recall": {
            "1": 0.5567973616709417
        },
        "bertscore": {
            "precision": 0.87447,
            "recall": 0.86321,
            "f1": 0.86832
        },
        "bleurt": -0.07349,
        "meteor": 0.31380891450324455,
        "nubia": {
            "semantic_relation": 3.5825,
            "contradiction": 8.11262,
            "irrelevancy": 20.51973,
            "logical_agreement": 71.36765,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.65379,
            "nubia_score": 0.62933
        }
    },
    "schema_guided_dialog_challenge_test_nopunc": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_challenge_test_nopunc",
        "N": 500,
        "msttr-100": 0.71517,
        "msttr-100_nopunct": 0.72167,
        "total_length": 6028,
        "mean_pred_length": 12.056,
        "std_pred_length": 6.895278384517916,
        "median_pred_length": 10.0,
        "min_pred_length": 1,
        "max_pred_length": 39,
        "distinct-1": 0.16937624419376243,
        "vocab_size-1": 1021,
        "unique-1": 589,
        "entropy-1": 7.979443908284229,
        "distinct-2": 0.4793777134587554,
        "vocab_size-2": 2650,
        "unique-2": 1867,
        "entropy-2": 10.551652341142328,
        "cond_entropy-2": 2.5629751822703244,
        "distinct-3": 0.6886060847086896,
        "vocab_size-3": 3463,
        "unique-3": 2844,
        "entropy-3": 11.338163285724665,
        "cond_entropy-3": 0.8330323501754211,
        "total_length-nopunct": 5481,
        "mean_pred_length-nopunct": 10.962,
        "std_pred_length-nopunct": 6.304328354392718,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.18409049443532202,
        "vocab_size-1-nopunct": 1009,
        "unique-1-nopunct": 587,
        "entropy-1-nopunct": 8.05169170970433,
        "distinct-2-nopunct": 0.493073679983939,
        "vocab_size-2-nopunct": 2456,
        "unique-2-nopunct": 1770,
        "entropy-2-nopunct": 10.435364361316383,
        "cond_entropy-2-nopunct": 2.526533619976018,
        "distinct-3-nopunct": 0.7057117358322178,
        "vocab_size-3-nopunct": 3163,
        "unique-3-nopunct": 2639,
        "entropy-3-nopunct": 11.222340568936445,
        "cond_entropy-3-nopunct": 0.8202437913310363,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_nopunc.json",
        "nist": 5.761637298527485,
        "bleu": 28.82709,
        "rouge1": {
            "precision": 0.59894,
            "recall": 0.52975,
            "fmeasure": 0.55059
        },
        "rouge2": {
            "precision": 0.36563,
            "recall": 0.32636,
            "fmeasure": 0.3375
        },
        "rougeL": {
            "precision": 0.5356,
            "recall": 0.47492,
            "fmeasure": 0.49315
        },
        "rougeLsum": {
            "precision": 0.5356,
            "recall": 0.47492,
            "fmeasure": 0.49315
        },
        "local_recall": {
            "1": 0.5365451245669032
        },
        "bertscore": {
            "precision": 0.87322,
            "recall": 0.85215,
            "f1": 0.8621
        },
        "bleurt": -0.11244,
        "meteor": 0.3008712723813032,
        "nubia": {
            "semantic_relation": 3.61034,
            "contradiction": 9.94473,
            "irrelevancy": 17.89743,
            "logical_agreement": 72.15784,
            "grammar_ref": 4.79983,
            "grammar_hyp": 4.94182,
            "nubia_score": 0.60695
        }
    },
    "schema_guided_dialog_challenge_test_scramble": {
        "predictions_file": "T5-base (Baseline)/schema_guided_dialog_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.685,
        "msttr-100_nopunct": 0.71914,
        "total_length": 6616,
        "mean_pred_length": 13.232,
        "std_pred_length": 7.334451308721055,
        "median_pred_length": 11.5,
        "min_pred_length": 2,
        "max_pred_length": 42,
        "distinct-1": 0.15024183796856105,
        "vocab_size-1": 994,
        "unique-1": 539,
        "entropy-1": 7.787623740485554,
        "distinct-2": 0.46026814911707,
        "vocab_size-2": 2815,
        "unique-2": 1913,
        "entropy-2": 10.650487814488333,
        "cond_entropy-2": 2.6287824834304367,
        "distinct-3": 0.6773504273504274,
        "vocab_size-3": 3804,
        "unique-3": 3040,
        "entropy-3": 11.49217291862435,
        "cond_entropy-3": 0.864428791612251,
        "total_length-nopunct": 5807,
        "mean_pred_length-nopunct": 11.614,
        "std_pred_length-nopunct": 6.708278765823615,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.1692784570346134,
        "vocab_size-1-nopunct": 983,
        "unique-1-nopunct": 537,
        "entropy-1-nopunct": 7.976058680542088,
        "distinct-2-nopunct": 0.478047861315244,
        "vocab_size-2-nopunct": 2537,
        "unique-2-nopunct": 1766,
        "entropy-2-nopunct": 10.49363720797579,
        "cond_entropy-2-nopunct": 2.654336457103894,
        "distinct-3-nopunct": 0.6934913703472655,
        "vocab_size-3-nopunct": 3335,
        "unique-3-nopunct": 2724,
        "entropy-3-nopunct": 11.29882776380853,
        "cond_entropy-3-nopunct": 0.8493152895857009,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_scramble.json",
        "nist": 6.051200350794399,
        "bleu": 30.76477,
        "rouge1": {
            "precision": 0.57369,
            "recall": 0.54726,
            "fmeasure": 0.54913
        },
        "rouge2": {
            "precision": 0.35373,
            "recall": 0.33755,
            "fmeasure": 0.33871
        },
        "rougeL": {
            "precision": 0.51226,
            "recall": 0.4881,
            "fmeasure": 0.48986
        },
        "rougeLsum": {
            "precision": 0.51226,
            "recall": 0.4881,
            "fmeasure": 0.48986
        },
        "local_recall": {
            "1": 0.5599724660127344
        },
        "bertscore": {
            "precision": 0.87012,
            "recall": 0.86281,
            "f1": 0.86601
        },
        "bleurt": -0.11452,
        "meteor": 0.30986004557422625,
        "nubia": {
            "semantic_relation": 3.5465,
            "contradiction": 8.13213,
            "irrelevancy": 24.31579,
            "logical_agreement": 67.55207,
            "grammar_ref": 4.7801,
            "grammar_hyp": 4.60622,
            "nubia_score": 0.62258
        }
    },
    "xsum_validation": {
        "predictions_file": "T5-base (Baseline)/xsum_validation",
        "N": 1117,
        "msttr-100": 0.7305,
        "msttr-100_nopunct": 0.75312,
        "total_length": 23851,
        "mean_pred_length": 21.35273052820054,
        "std_pred_length": 4.669471143786842,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 47,
        "distinct-1": 0.19697287325479015,
        "vocab_size-1": 4698,
        "unique-1": 2723,
        "entropy-1": 9.234049455564787,
        "distinct-2": 0.6419459839887394,
        "vocab_size-2": 14594,
        "unique-2": 12087,
        "entropy-2": 13.098182074527266,
        "cond_entropy-2": 3.6284244712927647,
        "distinct-3": 0.8748207429338021,
        "vocab_size-3": 18911,
        "unique-3": 17576,
        "entropy-3": 14.036898724471426,
        "cond_entropy-3": 0.9401687037886404,
        "total_length-nopunct": 22159,
        "mean_pred_length-nopunct": 19.837958818263203,
        "std_pred_length-nopunct": 4.4892860167416915,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.21133625163590414,
        "vocab_size-1-nopunct": 4683,
        "unique-1-nopunct": 2720,
        "entropy-1-nopunct": 9.430500146065155,
        "distinct-2-nopunct": 0.6531223267750214,
        "vocab_size-2-nopunct": 13743,
        "unique-2-nopunct": 11460,
        "entropy-2-nopunct": 13.030572611613085,
        "cond_entropy-2-nopunct": 3.7189551234035942,
        "distinct-3-nopunct": 0.8863739021329987,
        "vocab_size-3-nopunct": 17661,
        "unique-3-nopunct": 16504,
        "entropy-3-nopunct": 13.963985089640182,
        "cond_entropy-3-nopunct": 0.944972190564482,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_validation.json",
        "nist": 3.873321090942036,
        "bleu": 10.08417,
        "rouge1": {
            "precision": 0.40756,
            "recall": 0.38101,
            "fmeasure": 0.38654
        },
        "rouge2": {
            "precision": 0.15625,
            "recall": 0.14604,
            "fmeasure": 0.14801
        },
        "rougeL": {
            "precision": 0.31708,
            "recall": 0.29721,
            "fmeasure": 0.30111
        },
        "rougeLsum": {
            "precision": 0.31708,
            "recall": 0.29721,
            "fmeasure": 0.30111
        },
        "local_recall": {
            "1": 0.35837549692808096
        },
        "bertscore": {
            "precision": 0.83393,
            "recall": 0.82388,
            "f1": 0.82858
        },
        "bleurt": -0.31206,
        "meteor": 0.17233511022825632,
        "nubia": {
            "semantic_relation": 2.89922,
            "contradiction": 20.95734,
            "irrelevancy": 64.64209,
            "logical_agreement": 14.40056,
            "grammar_ref": 3.8151,
            "grammar_hyp": 3.62452,
            "nubia_score": 0.43122
        }
    },
    "xsum_test": {
        "predictions_file": "T5-base (Baseline)/xsum_test",
        "N": 1166,
        "msttr-100": 0.72968,
        "msttr-100_nopunct": 0.75183,
        "total_length": 24789,
        "mean_pred_length": 21.259862778730703,
        "std_pred_length": 5.108619626897226,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 86,
        "distinct-1": 0.1974262777845012,
        "vocab_size-1": 4894,
        "unique-1": 2840,
        "entropy-1": 9.26402103587297,
        "distinct-2": 0.6398425263514371,
        "vocab_size-2": 15115,
        "unique-2": 12485,
        "entropy-2": 13.129739920694306,
        "cond_entropy-2": 3.627955626520485,
        "distinct-3": 0.8697510798414748,
        "vocab_size-3": 19532,
        "unique-3": 18097,
        "entropy-3": 14.07633699269706,
        "cond_entropy-3": 0.9556658524497901,
        "total_length-nopunct": 23074,
        "mean_pred_length-nopunct": 19.78902229845626,
        "std_pred_length-nopunct": 4.795661586903996,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 70,
        "distinct-1-nopunct": 0.21158013348357457,
        "vocab_size-1-nopunct": 4882,
        "unique-1-nopunct": 2838,
        "entropy-1-nopunct": 9.462579978319015,
        "distinct-2-nopunct": 0.6493974803724667,
        "vocab_size-2-nopunct": 14227,
        "unique-2-nopunct": 11833,
        "entropy-2-nopunct": 13.057641208824107,
        "cond_entropy-2-nopunct": 3.7200009232524267,
        "distinct-3-nopunct": 0.8790859126410182,
        "vocab_size-3-nopunct": 18234,
        "unique-3-nopunct": 16966,
        "entropy-3-nopunct": 13.998026717191811,
        "cond_entropy-3-nopunct": 0.9615491670669085,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.90423627505731,
        "bleu": 10.45511,
        "rouge1": {
            "precision": 0.41056,
            "recall": 0.37954,
            "fmeasure": 0.38634
        },
        "rouge2": {
            "precision": 0.16448,
            "recall": 0.15247,
            "fmeasure": 0.15479
        },
        "rougeL": {
            "precision": 0.32227,
            "recall": 0.29814,
            "fmeasure": 0.30323
        },
        "rougeLsum": {
            "precision": 0.32227,
            "recall": 0.29814,
            "fmeasure": 0.30323
        },
        "local_recall": {
            "1": 0.3547615998634055
        },
        "bertscore": {
            "precision": 0.83501,
            "recall": 0.82368,
            "f1": 0.82897
        },
        "bleurt": -0.32056,
        "meteor": 0.17252663102644122,
        "nubia": {
            "semantic_relation": 2.88905,
            "contradiction": 22.10161,
            "irrelevancy": 63.57455,
            "logical_agreement": 14.32385,
            "grammar_ref": 3.76542,
            "grammar_hyp": 3.5972,
            "nubia_score": 0.42816
        }
    },
    "xsum_challenge_train_sample": {
        "predictions_file": "T5-base (Baseline)/xsum_challenge_train_sample",
        "N": 500
    },
    "xsum_challenge_validation_sample": {
        "predictions_file": "T5-base (Baseline)/xsum_challenge_validation_sample",
        "N": 500
    },
    "xsum_challenge_test_backtranslation": {
        "predictions_file": "T5-base (Baseline)/xsum_challenge_test_backtranslation",
        "N": 500,
        "msttr-100": 0.7233,
        "msttr-100_nopunct": 0.74365,
        "total_length": 11201,
        "mean_pred_length": 22.402,
        "std_pred_length": 4.717668491956593,
        "median_pred_length": 22.0,
        "min_pred_length": 6,
        "max_pred_length": 44,
        "distinct-1": 0.2634586197660923,
        "vocab_size-1": 2951,
        "unique-1": 1899,
        "entropy-1": 8.96781661126508,
        "distinct-2": 0.7214279039342117,
        "vocab_size-2": 7720,
        "unique-2": 6654,
        "entropy-2": 12.391883559062991,
        "cond_entropy-2": 3.216579861664199,
        "distinct-3": 0.9219684344672091,
        "vocab_size-3": 9405,
        "unique-3": 8934,
        "entropy-3": 13.111650981149786,
        "cond_entropy-3": 0.7341417875793242,
        "total_length-nopunct": 10415,
        "mean_pred_length-nopunct": 20.83,
        "std_pred_length-nopunct": 4.4843171163511615,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.28218915026404223,
        "vocab_size-1-nopunct": 2939,
        "unique-1-nopunct": 1896,
        "entropy-1-nopunct": 9.129436986336898,
        "distinct-2-nopunct": 0.7275844679778114,
        "vocab_size-2-nopunct": 7214,
        "unique-2-nopunct": 6248,
        "entropy-2-nopunct": 12.296965362695166,
        "cond_entropy-2-nopunct": 3.2896556675257536,
        "distinct-3-nopunct": 0.9270313329792884,
        "vocab_size-3-nopunct": 8728,
        "unique-3-nopunct": 8307,
        "entropy-3-nopunct": 13.017404567251807,
        "cond_entropy-3-nopunct": 0.7455182627516882,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_backtranslation.json",
        "nist": 3.1331726618234303,
        "bleu": 7.79785,
        "rouge1": {
            "precision": 0.35796,
            "recall": 0.35029,
            "fmeasure": 0.34714
        },
        "rouge2": {
            "precision": 0.1183,
            "recall": 0.11568,
            "fmeasure": 0.11443
        },
        "rougeL": {
            "precision": 0.2809,
            "recall": 0.27465,
            "fmeasure": 0.27219
        },
        "rougeLsum": {
            "precision": 0.2809,
            "recall": 0.27465,
            "fmeasure": 0.27219
        },
        "local_recall": {
            "1": 0.3215404831699181
        },
        "bertscore": {
            "precision": 0.81531,
            "recall": 0.81132,
            "f1": 0.813
        },
        "bleurt": -0.42017,
        "meteor": 0.15083308617450455,
        "nubia": {
            "semantic_relation": 2.49462,
            "contradiction": 25.50162,
            "irrelevancy": 66.06917,
            "logical_agreement": 8.42921,
            "grammar_ref": 3.78538,
            "grammar_hyp": 3.61069,
            "nubia_score": 0.34769
        }
    },
    "totto_validation": {
        "predictions_file": "T5-base (Baseline)/totto_validation",
        "N": 7700,
        "msttr-100": 0.72619,
        "msttr-100_nopunct": 0.7797,
        "total_length": 124927,
        "mean_pred_length": 16.224285714285713,
        "std_pred_length": 6.740511932574005,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 56,
        "distinct-1": 0.17276489469850392,
        "vocab_size-1": 21583,
        "unique-1": 14713,
        "entropy-1": 10.115680322981849,
        "distinct-2": 0.54382522797649,
        "vocab_size-2": 63751,
        "unique-2": 53187,
        "entropy-2": 14.610214522373711,
        "cond_entropy-2": 4.093015484312719,
        "distinct-3": 0.7711249280999206,
        "vocab_size-3": 84459,
        "unique-3": 76737,
        "entropy-3": 15.860885249616873,
        "cond_entropy-3": 1.2147339613820904,
        "total_length-nopunct": 108636,
        "mean_pred_length-nopunct": 14.108571428571429,
        "std_pred_length-nopunct": 5.758936976738052,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 48,
        "distinct-1-nopunct": 0.19848853050554144,
        "vocab_size-1-nopunct": 21563,
        "unique-1-nopunct": 14711,
        "entropy-1-nopunct": 10.683664403009054,
        "distinct-2-nopunct": 0.5894031861773797,
        "vocab_size-2-nopunct": 59492,
        "unique-2-nopunct": 50754,
        "entropy-2-nopunct": 14.613939566447234,
        "cond_entropy-2-nopunct": 4.090620997213194,
        "distinct-3-nopunct": 0.7976103650950277,
        "vocab_size-3-nopunct": 74366,
        "unique-3-nopunct": 68475,
        "entropy-3-nopunct": 15.730485268190012,
        "cond_entropy-3-nopunct": 1.186020382344206,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_validation.json",
        "nist": 10.921882106458314,
        "bleu": 47.93974,
        "rouge1": {
            "precision": 0.77299,
            "recall": 0.73892,
            "fmeasure": 0.74439
        },
        "rouge2": {
            "precision": 0.55094,
            "recall": 0.52957,
            "fmeasure": 0.5318
        },
        "rougeL": {
            "precision": 0.6762,
            "recall": 0.65012,
            "fmeasure": 0.65288
        },
        "rougeLsum": {
            "precision": 0.6762,
            "recall": 0.65012,
            "fmeasure": 0.65288
        },
        "local_recall": {
            "1": 0.21680216802168023,
            "2": 0.4602544748759974,
            "3": 0.7786284411141879
        },
        "bertscore": {
            "precision": 0.93127,
            "recall": 0.92631,
            "f1": 0.92714
        },
        "bleurt": 0.28681,
        "meteor": 0.39917326719137153,
        "nubia": {
            "semantic_relation": 4.2089,
            "contradiction": 8.29017,
            "irrelevancy": 29.1909,
            "logical_agreement": 62.51893,
            "grammar_ref": 4.66172,
            "grammar_hyp": 4.65038,
            "nubia_score": 0.73456
        }
    },
    "xsum_challenge_test_bfp_02": {
        "predictions_file": "T5-base (Baseline)/xsum_challenge_test_bfp_02",
        "N": 500,
        "msttr-100": 0.7285,
        "msttr-100_nopunct": 0.7508,
        "total_length": 10793,
        "mean_pred_length": 21.586,
        "std_pred_length": 4.740738760994957,
        "median_pred_length": 21.0,
        "min_pred_length": 9,
        "max_pred_length": 43,
        "distinct-1": 0.2746224404706754,
        "vocab_size-1": 2964,
        "unique-1": 1935,
        "entropy-1": 9.011609258992676,
        "distinct-2": 0.7261245506655009,
        "vocab_size-2": 7474,
        "unique-2": 6504,
        "entropy-2": 12.333525984988324,
        "cond_entropy-2": 3.101283146152629,
        "distinct-3": 0.9141223322781579,
        "vocab_size-3": 8952,
        "unique-3": 8501,
        "entropy-3": 13.024198298458286,
        "cond_entropy-3": 0.6976234889472116,
        "total_length-nopunct": 10037,
        "mean_pred_length-nopunct": 20.074,
        "std_pred_length-nopunct": 4.506497975146555,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.29421141775430903,
        "vocab_size-1-nopunct": 2953,
        "unique-1-nopunct": 1933,
        "entropy-1-nopunct": 9.192600652411834,
        "distinct-2-nopunct": 0.7353465450351263,
        "vocab_size-2-nopunct": 7013,
        "unique-2-nopunct": 6143,
        "entropy-2-nopunct": 12.251737123434015,
        "cond_entropy-2-nopunct": 3.170173935265515,
        "distinct-3-nopunct": 0.9225406661502711,
        "vocab_size-3-nopunct": 8337,
        "unique-3-nopunct": 7943,
        "entropy-3-nopunct": 12.9390495063168,
        "cond_entropy-3-nopunct": 0.7036944622887693,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_02.json",
        "nist": 3.552642436433361,
        "bleu": 9.25685,
        "rouge1": {
            "precision": 0.39651,
            "recall": 0.37287,
            "fmeasure": 0.3765
        },
        "rouge2": {
            "precision": 0.15248,
            "recall": 0.14323,
            "fmeasure": 0.14456
        },
        "rougeL": {
            "precision": 0.30805,
            "recall": 0.29104,
            "fmeasure": 0.29307
        },
        "rougeLsum": {
            "precision": 0.30805,
            "recall": 0.29104,
            "fmeasure": 0.29307
        },
        "local_recall": {
            "1": 0.3449881141045959
        },
        "bertscore": {
            "precision": 0.82669,
            "recall": 0.82061,
            "f1": 0.8233
        },
        "bleurt": -0.4043,
        "meteor": 0.1639874053090957,
        "nubia": {
            "semantic_relation": 2.83663,
            "contradiction": 22.25504,
            "irrelevancy": 65.86597,
            "logical_agreement": 11.879,
            "grammar_ref": 3.74155,
            "grammar_hyp": 3.80292,
            "nubia_score": 0.39266
        }
    },
    "xsum_challenge_test_bfp_05": {
        "predictions_file": "T5-base (Baseline)/xsum_challenge_test_bfp_05",
        "N": 500,
        "msttr-100": 0.72787,
        "msttr-100_nopunct": 0.7481,
        "total_length": 10852,
        "mean_pred_length": 21.704,
        "std_pred_length": 4.957860829026971,
        "median_pred_length": 21.0,
        "min_pred_length": 10,
        "max_pred_length": 44,
        "distinct-1": 0.27967194987099153,
        "vocab_size-1": 3035,
        "unique-1": 2028,
        "entropy-1": 9.031780334849543,
        "distinct-2": 0.7179289026275116,
        "vocab_size-2": 7432,
        "unique-2": 6419,
        "entropy-2": 12.329581439903363,
        "cond_entropy-2": 3.076013465598649,
        "distinct-3": 0.9106780349167681,
        "vocab_size-3": 8972,
        "unique-3": 8481,
        "entropy-3": 13.027529541096841,
        "cond_entropy-3": 0.7114957449992951,
        "total_length-nopunct": 10088,
        "mean_pred_length-nopunct": 20.176,
        "std_pred_length-nopunct": 4.711371774759449,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.29976209357652656,
        "vocab_size-1-nopunct": 3024,
        "unique-1-nopunct": 2026,
        "entropy-1-nopunct": 9.207104154460591,
        "distinct-2-nopunct": 0.7235085523571131,
        "vocab_size-2-nopunct": 6937,
        "unique-2-nopunct": 6016,
        "entropy-2-nopunct": 12.232181678022561,
        "cond_entropy-2-nopunct": 3.145869681882462,
        "distinct-3-nopunct": 0.9164832746478874,
        "vocab_size-3-nopunct": 8329,
        "unique-3-nopunct": 7892,
        "entropy-3-nopunct": 12.931509724779863,
        "cond_entropy-3-nopunct": 0.7201596130961602,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_05.json",
        "nist": 3.27237045459392,
        "bleu": 8.02654,
        "rouge1": {
            "precision": 0.37215,
            "recall": 0.3515,
            "fmeasure": 0.3546
        },
        "rouge2": {
            "precision": 0.12655,
            "recall": 0.1196,
            "fmeasure": 0.1206
        },
        "rougeL": {
            "precision": 0.28756,
            "recall": 0.27183,
            "fmeasure": 0.27396
        },
        "rougeLsum": {
            "precision": 0.28756,
            "recall": 0.27183,
            "fmeasure": 0.27396
        },
        "local_recall": {
            "1": 0.3250696933492632
        },
        "bertscore": {
            "precision": 0.81577,
            "recall": 0.81156,
            "f1": 0.81335
        },
        "bleurt": -0.52764,
        "meteor": 0.15053228485589257,
        "nubia": {
            "semantic_relation": 2.60504,
            "contradiction": 25.75878,
            "irrelevancy": 63.08421,
            "logical_agreement": 11.15702,
            "grammar_ref": 3.79385,
            "grammar_hyp": 4.04882,
            "nubia_score": 0.33139
        }
    },
    "xsum_challenge_test_nopunc": {
        "predictions_file": "T5-base (Baseline)/xsum_challenge_test_nopunc",
        "N": 500,
        "msttr-100": 0.73377,
        "msttr-100_nopunct": 0.75172,
        "total_length": 10623,
        "mean_pred_length": 21.246,
        "std_pred_length": 4.832958100377034,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 39,
        "distinct-1": 0.27365151087263484,
        "vocab_size-1": 2907,
        "unique-1": 1864,
        "entropy-1": 9.047051597020365,
        "distinct-2": 0.7364417662748197,
        "vocab_size-2": 7455,
        "unique-2": 6488,
        "entropy-2": 12.377798570225268,
        "cond_entropy-2": 3.1026960900057254,
        "distinct-3": 0.9219578094149433,
        "vocab_size-3": 8872,
        "unique-3": 8457,
        "entropy-3": 13.023829717290225,
        "cond_entropy-3": 0.6577883864804422,
        "total_length-nopunct": 9901,
        "mean_pred_length-nopunct": 19.802,
        "std_pred_length-nopunct": 4.684313823816675,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.2925967074032926,
        "vocab_size-1-nopunct": 2897,
        "unique-1-nopunct": 1863,
        "entropy-1-nopunct": 9.225363889743589,
        "distinct-2-nopunct": 0.7416232315711094,
        "vocab_size-2-nopunct": 6972,
        "unique-2-nopunct": 6097,
        "entropy-2-nopunct": 12.281600289351259,
        "cond_entropy-2-nopunct": 3.1757029189767048,
        "distinct-3-nopunct": 0.9263004156836311,
        "vocab_size-3-nopunct": 8245,
        "unique-3-nopunct": 7876,
        "entropy-3-nopunct": 12.927083829521543,
        "cond_entropy-3-nopunct": 0.6644160418273105,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_nopunc.json",
        "nist": 3.7729399550547087,
        "bleu": 10.28023,
        "rouge1": {
            "precision": 0.4117,
            "recall": 0.38488,
            "fmeasure": 0.38973
        },
        "rouge2": {
            "precision": 0.16392,
            "recall": 0.15325,
            "fmeasure": 0.15499
        },
        "rougeL": {
            "precision": 0.32077,
            "recall": 0.2991,
            "fmeasure": 0.30322
        },
        "rougeLsum": {
            "precision": 0.32077,
            "recall": 0.2991,
            "fmeasure": 0.30322
        },
        "local_recall": {
            "1": 0.36028525512253917
        },
        "bertscore": {
            "precision": 0.83554,
            "recall": 0.82411,
            "f1": 0.82946
        },
        "bleurt": -0.32611,
        "meteor": 0.1724806525206285,
        "nubia": {
            "semantic_relation": 2.89311,
            "contradiction": 23.37943,
            "irrelevancy": 62.36059,
            "logical_agreement": 14.25998,
            "grammar_ref": 3.78318,
            "grammar_hyp": 3.64399,
            "nubia_score": 0.42132
        }
    },
    "totto_test": {
        "predictions_file": "T5-base (Baseline)/totto_test",
        "N": 7700,
        "msttr-100": 0.72579,
        "msttr-100_nopunct": 0.78075,
        "total_length": 124951,
        "mean_pred_length": 16.227402597402598,
        "std_pred_length": 6.7287599256190305,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 73,
        "distinct-1": 0.1720754535778025,
        "vocab_size-1": 21501,
        "unique-1": 14795,
        "entropy-1": 10.094782775197366,
        "distinct-2": 0.5404815310743618,
        "vocab_size-2": 63372,
        "unique-2": 52759,
        "entropy-2": 14.590196840935937,
        "cond_entropy-2": 4.095384037064608,
        "distinct-3": 0.7670034960885798,
        "vocab_size-3": 84026,
        "unique-3": 75959,
        "entropy-3": 15.857156301451415,
        "cond_entropy-3": 1.2298389775584315,
        "total_length-nopunct": 108575,
        "mean_pred_length-nopunct": 14.10064935064935,
        "std_pred_length-nopunct": 5.726141884117528,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 55,
        "distinct-1-nopunct": 0.1978448077365876,
        "vocab_size-1-nopunct": 21481,
        "unique-1-nopunct": 14793,
        "entropy-1-nopunct": 10.66701893627886,
        "distinct-2-nopunct": 0.5864089219330855,
        "vocab_size-2-nopunct": 59154,
        "unique-2-nopunct": 50345,
        "entropy-2-nopunct": 14.599487621734035,
        "cond_entropy-2-nopunct": 4.09397577197378,
        "distinct-3-nopunct": 0.7950630533941508,
        "vocab_size-3-nopunct": 74080,
        "unique-3-nopunct": 67882,
        "entropy-3-nopunct": 15.731856392300033,
        "cond_entropy-3-nopunct": 1.2019317524704016,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 10.850443832751557,
        "bleu": 47.33886,
        "rouge1": {
            "precision": 0.77229,
            "recall": 0.73663,
            "fmeasure": 0.74236
        },
        "rouge2": {
            "precision": 0.54919,
            "recall": 0.52497,
            "fmeasure": 0.52808
        },
        "rougeL": {
            "precision": 0.67423,
            "recall": 0.64667,
            "fmeasure": 0.64966
        },
        "rougeLsum": {
            "precision": 0.67423,
            "recall": 0.64667,
            "fmeasure": 0.64966
        },
        "local_recall": {
            "1": 0.21496615185050064,
            "2": 0.4557149065623642,
            "3": 0.7781377941878281
        },
        "bertscore": {
            "precision": 0.93069,
            "recall": 0.92576,
            "f1": 0.92652
        },
        "bleurt": 0.28807,
        "meteor": 0.39789704729202435,
        "nubia": {
            "semantic_relation": 4.20445,
            "contradiction": 8.57898,
            "irrelevancy": 28.99887,
            "logical_agreement": 62.42214,
            "grammar_ref": 4.66736,
            "grammar_hyp": 4.66296,
            "nubia_score": 0.73164
        }
    },
    "totto_challenge_train_sample": {
        "predictions_file": "T5-base (Baseline)/totto_challenge_train_sample",
        "N": 500
    },
    "totto_challenge_validation_sample": {
        "predictions_file": "T5-base (Baseline)/totto_challenge_validation_sample",
        "N": 500
    },
    "xsum_challenge_test_covid": {
        "predictions_file": "T5-base (Baseline)/xsum_challenge_test_covid",
        "N": 401,
        "msttr-100": 0.70043,
        "msttr-100_nopunct": 0.7246,
        "total_length": 9457,
        "mean_pred_length": 23.58354114713217,
        "std_pred_length": 5.026476376847916,
        "median_pred_length": 23.0,
        "min_pred_length": 10,
        "max_pred_length": 46,
        "distinct-1": 0.20746536956751613,
        "vocab_size-1": 1962,
        "unique-1": 1199,
        "entropy-1": 8.382126059066154,
        "distinct-2": 0.598939929328622,
        "vocab_size-2": 5424,
        "unique-2": 4381,
        "entropy-2": 11.676440379074966,
        "cond_entropy-2": 3.125057533428441,
        "distinct-3": 0.8262276140958983,
        "vocab_size-3": 7151,
        "unique-3": 6455,
        "entropy-3": 12.578511218412336,
        "cond_entropy-3": 0.9024090223320503,
        "total_length-nopunct": 8742,
        "mean_pred_length-nopunct": 21.800498753117207,
        "std_pred_length-nopunct": 4.745923542887738,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.22328986501944634,
        "vocab_size-1-nopunct": 1952,
        "unique-1-nopunct": 1196,
        "entropy-1-nopunct": 8.52958719830742,
        "distinct-2-nopunct": 0.6149142788634456,
        "vocab_size-2-nopunct": 5129,
        "unique-2-nopunct": 4199,
        "entropy-2-nopunct": 11.604954004949938,
        "cond_entropy-2-nopunct": 3.1531974548325943,
        "distinct-3-nopunct": 0.8397984886649874,
        "vocab_size-3-nopunct": 6668,
        "unique-3-nopunct": 6074,
        "entropy-3-nopunct": 12.492580511645887,
        "cond_entropy-3-nopunct": 0.8892145459205886,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_covid.json",
        "nist": 2.59772846014442,
        "bleu": 6.23092,
        "rouge1": {
            "precision": 0.31258,
            "recall": 0.30574,
            "fmeasure": 0.30099
        },
        "rouge2": {
            "precision": 0.09773,
            "recall": 0.09641,
            "fmeasure": 0.09444
        },
        "rougeL": {
            "precision": 0.23637,
            "recall": 0.23231,
            "fmeasure": 0.22793
        },
        "rougeLsum": {
            "precision": 0.23637,
            "recall": 0.23231,
            "fmeasure": 0.22793
        },
        "local_recall": {
            "1": 0.2849591542527631
        },
        "bertscore": {
            "precision": 0.79646,
            "recall": 0.79078,
            "f1": 0.7933
        },
        "bleurt": -0.536,
        "meteor": 0.1350270694149887,
        "nubia": {
            "semantic_relation": 2.3141,
            "contradiction": 19.86521,
            "irrelevancy": 69.77665,
            "logical_agreement": 10.35814,
            "grammar_ref": 4.04957,
            "grammar_hyp": 3.79234,
            "nubia_score": 0.30368
        }
    },
    "web_nlg_ru_challenge_test_scramble_parent": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_test",
        "N": 500,
        "msttr-100": 0.43995,
        "msttr-100_nopunct": 0.43259,
        "total_length": 21376,
        "mean_pred_length": 42.752,
        "std_pred_length": 19.024891484578827,
        "median_pred_length": 41.0,
        "min_pred_length": 7,
        "max_pred_length": 87,
        "distinct-1": 0.08060441616766467,
        "vocab_size-1": 1723,
        "unique-1": 710,
        "entropy-1": 5.898360091530367,
        "distinct-2": 0.21273232420003832,
        "vocab_size-2": 4441,
        "unique-2": 2255,
        "entropy-2": 10.164248845000284,
        "cond_entropy-2": 4.255234549066308,
        "distinct-3": 0.37112288967412643,
        "vocab_size-3": 7562,
        "unique-3": 4481,
        "entropy-3": 11.772245693913575,
        "cond_entropy-3": 1.651827727778075,
        "total_length-nopunct": 19733,
        "mean_pred_length-nopunct": 39.466,
        "std_pred_length-nopunct": 17.92620551036945,
        "median_pred_length-nopunct": 38.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 80,
        "distinct-1-nopunct": 0.08685957533066437,
        "vocab_size-1-nopunct": 1714,
        "unique-1-nopunct": 709,
        "entropy-1-nopunct": 5.805965648656411,
        "distinct-2-nopunct": 0.2118754224509957,
        "vocab_size-2-nopunct": 4075,
        "unique-2-nopunct": 2059,
        "entropy-2-nopunct": 10.022762758180253,
        "cond_entropy-2-nopunct": 4.311932676874797,
        "distinct-3-nopunct": 0.36913468211178135,
        "vocab_size-3-nopunct": 6915,
        "unique-3-nopunct": 4131,
        "entropy-3-nopunct": 11.610397161211027,
        "cond_entropy-3-nopunct": 1.6273683299584696,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 1.1520582290798405,
        "bleu": 2.06321,
        "rouge1": {
            "precision": 0.41736,
            "recall": 0.39322,
            "fmeasure": 0.39653
        },
        "rouge2": {
            "precision": 0.20596,
            "recall": 0.19405,
            "fmeasure": 0.1957
        },
        "rougeL": {
            "precision": 0.39862,
            "recall": 0.37749,
            "fmeasure": 0.37928
        },
        "rougeLsum": {
            "precision": 0.39862,
            "recall": 0.37749,
            "fmeasure": 0.37928
        },
        "local_recall": {
            "1": 0.08882007822685789,
            "2": 0.18696969696969698,
            "3": 0.26120033812341503,
            "4": 0.15555555555555556,
            "5": 0.4,
            "6": 0.3333333333333333
        },
        "bertscore": {
            "precision": 0.86308,
            "recall": 0.87278,
            "f1": 0.8674
        },
        "bleurt": -0.46448,
        "meteor": 0.12495666700256004,
        "nubia": {
            "semantic_relation": 3.28939,
            "contradiction": 33.74687,
            "irrelevancy": 17.0603,
            "logical_agreement": 49.19284,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.66649,
            "nubia_score": 0.15993
        }
    },
    "web_nlg_en_challenge_test_scramble_parent": {
        "predictions_file": "T5-base (Baseline)/web_nlg_en_test",
        "N": 500,
        "msttr-100": 0.52409,
        "msttr-100_nopunct": 0.54274,
        "total_length": 12744,
        "mean_pred_length": 25.488,
        "std_pred_length": 13.388721223477617,
        "median_pred_length": 24.0,
        "min_pred_length": 5,
        "max_pred_length": 68,
        "distinct-1": 0.113308223477715,
        "vocab_size-1": 1444,
        "unique-1": 514,
        "entropy-1": 7.938810067788936,
        "distinct-2": 0.34645540672982683,
        "vocab_size-2": 4242,
        "unique-2": 2360,
        "entropy-2": 11.081384337585,
        "cond_entropy-2": 2.9820615232936385,
        "distinct-3": 0.5489611716621253,
        "vocab_size-3": 6447,
        "unique-3": 4485,
        "entropy-3": 12.133195691368316,
        "cond_entropy-3": 1.0985006727542488,
        "total_length-nopunct": 11313,
        "mean_pred_length-nopunct": 22.626,
        "std_pred_length-nopunct": 12.042014947673831,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 59,
        "distinct-1-nopunct": 0.12675682842747282,
        "vocab_size-1-nopunct": 1434,
        "unique-1-nopunct": 512,
        "entropy-1-nopunct": 8.202225934760556,
        "distinct-2-nopunct": 0.3620641820031444,
        "vocab_size-2-nopunct": 3915,
        "unique-2-nopunct": 2277,
        "entropy-2-nopunct": 10.986085510369694,
        "cond_entropy-2-nopunct": 2.908519139516944,
        "distinct-3-nopunct": 0.5605546397750412,
        "vocab_size-3-nopunct": 5781,
        "unique-3-nopunct": 4124,
        "entropy-3-nopunct": 11.975524199936546,
        "cond_entropy-3-nopunct": 1.0363586570896361,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.585706397061596,
        "bleu": 37.84038,
        "rouge1": {
            "precision": 0.6777,
            "recall": 0.6898,
            "fmeasure": 0.67729
        },
        "rouge2": {
            "precision": 0.41055,
            "recall": 0.41669,
            "fmeasure": 0.40937
        },
        "rougeL": {
            "precision": 0.53334,
            "recall": 0.5444,
            "fmeasure": 0.5335
        },
        "rougeLsum": {
            "precision": 0.53334,
            "recall": 0.5444,
            "fmeasure": 0.5335
        },
        "local_recall": {
            "1": 0.22198062858272385,
            "2": 0.5581947743467933,
            "3": 0.7801047120418848,
            "4": 0.4,
            "5": 0.7222222222222222
        },
        "bertscore": {
            "precision": 0.89456,
            "recall": 0.89836,
            "f1": 0.8954
        },
        "bleurt": -0.02896,
        "meteor": 0.3378292118055522,
        "nubia": {
            "semantic_relation": 4.00283,
            "contradiction": 24.16777,
            "irrelevancy": 9.70033,
            "logical_agreement": 66.1319,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.66941,
            "nubia_score": 0.66172
        }
    },
    "mlsum_de_test": {
        "predictions_file": "T5-base (Baseline)/mlsum_de_test",
        "N": 10695,
        "msttr-100": 0.74578,
        "msttr-100_nopunct": 0.79587,
        "total_length": 250235,
        "mean_pred_length": 23.397381954184198,
        "std_pred_length": 8.065771744709133,
        "median_pred_length": 22.0,
        "min_pred_length": 6,
        "max_pred_length": 86,
        "distinct-1": 0.1279796990828621,
        "vocab_size-1": 32025,
        "unique-1": 19480,
        "entropy-1": 10.327984718869663,
        "distinct-2": 0.5339859731151373,
        "vocab_size-2": 127911,
        "unique-2": 104104,
        "entropy-2": 15.6353716158406,
        "cond_entropy-2": 5.019902712948796,
        "distinct-3": 0.8363084183617733,
        "vocab_size-3": 191385,
        "unique-3": 176252,
        "entropy-3": 17.24310627839492,
        "cond_entropy-3": 1.5854862521065005,
        "total_length-nopunct": 222377,
        "mean_pred_length-nopunct": 20.79261337073399,
        "std_pred_length-nopunct": 7.087392862228722,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 77,
        "distinct-1-nopunct": 0.1439447424868579,
        "vocab_size-1-nopunct": 32010,
        "unique-1-nopunct": 19478,
        "entropy-1-nopunct": 10.880731566855358,
        "distinct-2-nopunct": 0.5902910970228928,
        "vocab_size-2-nopunct": 124954,
        "unique-2-nopunct": 103875,
        "entropy-2-nopunct": 15.881526259220012,
        "cond_entropy-2-nopunct": 5.127018549844565,
        "distinct-3-nopunct": 0.8705289396826661,
        "vocab_size-3-nopunct": 174965,
        "unique-3-nopunct": 163634,
        "entropy-3-nopunct": 17.186410326909208,
        "cond_entropy-3-nopunct": 1.3557211287731188,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_test.json",
        "nist": 7.9922773025837905,
        "bleu": 39.21982,
        "rouge1": {
            "precision": 0.47199,
            "recall": 0.44303,
            "fmeasure": 0.44969
        },
        "rouge2": {
            "precision": 0.3548,
            "recall": 0.34728,
            "fmeasure": 0.34779
        },
        "rougeL": {
            "precision": 0.43701,
            "recall": 0.4145,
            "fmeasure": 0.4193
        },
        "rougeLsum": {
            "precision": 0.43701,
            "recall": 0.4145,
            "fmeasure": 0.4193
        },
        "local_recall": {
            "1": 0.45795512785215997
        },
        "bertscore": {
            "precision": 0.89671,
            "recall": 0.8904,
            "f1": 0.89341
        },
        "bleurt": -0.23146,
        "meteor": 0.4286964597054502,
        "nubia": {
            "semantic_relation": 2.76457,
            "contradiction": 25.45923,
            "irrelevancy": 37.70422,
            "logical_agreement": 36.83655,
            "grammar_ref": 5.03454,
            "grammar_hyp": 4.99889,
            "nubia_score": 0.41327
        }
    },
    "mlsum_de_challenge_train_sample": {
        "predictions_file": "T5-base (Baseline)/mlsum_de_challenge_train_sample",
        "N": 500
    },
    "mlsum_de_challenge_validation_sample": {
        "predictions_file": "T5-base (Baseline)/mlsum_de_challenge_validation_sample",
        "N": 500
    },
    "mlsum_de_challenge_test_covid": {
        "predictions_file": "T5-base (Baseline)/mlsum_de_challenge_test_covid",
        "N": 5058,
        "msttr-100": 0.70603,
        "msttr-100_nopunct": 0.74893,
        "total_length": 123787,
        "mean_pred_length": 24.473507315144325,
        "std_pred_length": 8.753996432203946,
        "median_pred_length": 26.0,
        "min_pred_length": 6,
        "max_pred_length": 62,
        "distinct-1": 0.11503631237528981,
        "vocab_size-1": 14240,
        "unique-1": 8944,
        "entropy-1": 9.217161247592081,
        "distinct-2": 0.443800587893438,
        "vocab_size-2": 52692,
        "unique-2": 43707,
        "entropy-2": 13.115259633500004,
        "cond_entropy-2": 3.6931356791457635,
        "distinct-3": 0.6511247371801075,
        "vocab_size-3": 74014,
        "unique-3": 69273,
        "entropy-3": 14.050871404398569,
        "cond_entropy-3": 0.9328266810288396,
        "total_length-nopunct": 109102,
        "mean_pred_length-nopunct": 21.570185844207195,
        "std_pred_length-nopunct": 7.730248290764893,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 52,
        "distinct-1-nopunct": 0.13040090924089384,
        "vocab_size-1-nopunct": 14227,
        "unique-1-nopunct": 8941,
        "entropy-1-nopunct": 9.672467245765871,
        "distinct-2-nopunct": 0.4901868440275268,
        "vocab_size-2-nopunct": 51001,
        "unique-2-nopunct": 43256,
        "entropy-2-nopunct": 13.23647586256801,
        "cond_entropy-2-nopunct": 3.6639031550913828,
        "distinct-3-nopunct": 0.6765401167841917,
        "vocab_size-3-nopunct": 66968,
        "unique-3-nopunct": 63544,
        "entropy-3-nopunct": 13.96796136777706,
        "cond_entropy-3-nopunct": 0.7627259249171607,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_challenge_test_covid.json",
        "nist": 4.554651096946196,
        "bleu": 23.30721,
        "rouge1": {
            "precision": 0.30672,
            "recall": 0.35952,
            "fmeasure": 0.31973
        },
        "rouge2": {
            "precision": 0.20887,
            "recall": 0.25077,
            "fmeasure": 0.22119
        },
        "rougeL": {
            "precision": 0.28219,
            "recall": 0.33155,
            "fmeasure": 0.29481
        },
        "rougeLsum": {
            "precision": 0.28219,
            "recall": 0.33155,
            "fmeasure": 0.29481
        },
        "local_recall": {
            "1": 0.3664937006662123
        },
        "bertscore": {
            "precision": 0.86638,
            "recall": 0.87353,
            "f1": 0.86968
        },
        "bleurt": -0.51972,
        "meteor": 0.3195313452712176,
        "nubia": {
            "semantic_relation": 1.98651,
            "contradiction": 25.75182,
            "irrelevancy": 56.73519,
            "logical_agreement": 17.513,
            "grammar_ref": 5.17449,
            "grammar_hyp": 5.00862,
            "nubia_score": 0.26151
        }
    },
    "mlsum_es_validation": {
        "predictions_file": "T5-base (Baseline)/mlsum_es_validation",
        "N": 9977,
        "msttr-100": 0.67732,
        "msttr-100_nopunct": 0.68404,
        "total_length": 239790,
        "mean_pred_length": 24.03427884133507,
        "std_pred_length": 7.907125249543215,
        "median_pred_length": 23.0,
        "min_pred_length": 7,
        "max_pred_length": 71,
        "distinct-1": 0.10655990658492848,
        "vocab_size-1": 25552,
        "unique-1": 14050,
        "entropy-1": 9.73682946455905,
        "distinct-2": 0.4513756837080583,
        "vocab_size-2": 103732,
        "unique-2": 80560,
        "entropy-2": 14.911673525785329,
        "cond_entropy-2": 5.346845200733053,
        "distinct-3": 0.7581606288324023,
        "vocab_size-3": 166671,
        "unique-3": 149202,
        "entropy-3": 16.810329066164435,
        "cond_entropy-3": 1.9341772904960643,
        "total_length-nopunct": 230562,
        "mean_pred_length-nopunct": 23.10935150846948,
        "std_pred_length-nopunct": 7.368299734992515,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 69,
        "distinct-1-nopunct": 0.11075979562980891,
        "vocab_size-1-nopunct": 25537,
        "unique-1-nopunct": 14049,
        "entropy-1-nopunct": 9.827736055426014,
        "distinct-2-nopunct": 0.46422920869506085,
        "vocab_size-2-nopunct": 102402,
        "unique-2-nopunct": 80360,
        "entropy-2-nopunct": 14.938043483411452,
        "cond_entropy-2-nopunct": 5.288440066571492,
        "distinct-3-nopunct": 0.7667704930486972,
        "vocab_size-3-nopunct": 161488,
        "unique-3-nopunct": 145247,
        "entropy-3-nopunct": 16.78385532716305,
        "cond_entropy-3-nopunct": 1.8783330845943371,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_validation.json",
        "nist": 2.446922875157214,
        "bleu": 6.8741,
        "rouge1": {
            "precision": 0.29215,
            "recall": 0.28387,
            "fmeasure": 0.27643
        },
        "rouge2": {
            "precision": 0.10336,
            "recall": 0.10164,
            "fmeasure": 0.09842
        },
        "rougeL": {
            "precision": 0.23143,
            "recall": 0.22627,
            "fmeasure": 0.21972
        },
        "rougeLsum": {
            "precision": 0.23143,
            "recall": 0.22627,
            "fmeasure": 0.21972
        },
        "local_recall": {
            "1": 0.25642558889519224
        },
        "bertscore": {
            "precision": 0.83044,
            "recall": 0.83224,
            "f1": 0.83113
        },
        "bleurt": -0.53903,
        "meteor": 0.18587001944143988,
        "nubia": {
            "semantic_relation": 1.60829,
            "contradiction": 31.1649,
            "irrelevancy": 57.1594,
            "logical_agreement": 11.6757,
            "grammar_ref": 5.2776,
            "grammar_hyp": 5.33784,
            "nubia_score": 0.17017
        }
    },
    "wiki_auto_asset_turk_validation": {
        "predictions_file": "T5-base (Baseline)/wiki_auto_asset_turk_validation",
        "N": 20000,
        "msttr-100": 0.25863,
        "msttr-100_nopunct": 0.24321,
        "total_length": 388800,
        "mean_pred_length": 19.44,
        "std_pred_length": 9.065119966111865,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 99,
        "distinct-1": 0.022193930041152263,
        "vocab_size-1": 8629,
        "unique-1": 0,
        "entropy-1": 9.780583857216634,
        "distinct-2": 0.07077006507592191,
        "vocab_size-2": 26100,
        "unique-2": 0,
        "entropy-2": 13.963504226441543,
        "cond_entropy-2": 3.882167976932436,
        "distinct-3": 0.09132740825688074,
        "vocab_size-3": 31855,
        "unique-3": 0,
        "entropy-3": 14.796362393810199,
        "cond_entropy-3": 0.8521293369754273,
        "total_length-nopunct": 344670,
        "mean_pred_length-nopunct": 17.2335,
        "std_pred_length-nopunct": 7.980349475430259,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 77,
        "distinct-1-nopunct": 0.02498621870194679,
        "vocab_size-1-nopunct": 8612,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 10.20271771891236,
        "distinct-2-nopunct": 0.07342532417531647,
        "vocab_size-2-nopunct": 23839,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 13.908156201210188,
        "cond_entropy-2-nopunct": 3.8855512642322707,
        "distinct-3-nopunct": 0.09290707979124956,
        "vocab_size-3-nopunct": 28306,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 14.691159059426191,
        "cond_entropy-3-nopunct": 0.8308424143141346,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_validation.json",
        "nist": 9.910095613397804,
        "bleu": 47.27468,
        "rouge1": {
            "precision": 0.74417,
            "recall": 0.74412,
            "fmeasure": 0.72511
        },
        "rouge2": {
            "precision": 0.56157,
            "recall": 0.55884,
            "fmeasure": 0.5448
        },
        "rougeL": {
            "precision": 0.69961,
            "recall": 0.69947,
            "fmeasure": 0.68186
        },
        "rougeLsum": {
            "precision": 0.69961,
            "recall": 0.69947,
            "fmeasure": 0.68186
        },
        "local_recall": {
            "1": 0.7306110833063464
        },
        "sari": 48.02608,
        "bertscore": {
            "precision": 0.92509,
            "recall": 0.92513,
            "f1": 0.9242
        },
        "bleurt": 0.30636,
        "meteor": 0.40034499787642047,
        "nubia": {
            "semantic_relation": 4.35278,
            "contradiction": 2.64981,
            "irrelevancy": 24.84781,
            "logical_agreement": 72.50238,
            "grammar_ref": 4.53224,
            "grammar_hyp": 4.77223,
            "nubia_score": 0.70413
        }
    },
    "mlsum_es_test": {
        "predictions_file": "T5-base (Baseline)/mlsum_es_test",
        "N": 13366,
        "msttr-100": 0.67885,
        "msttr-100_nopunct": 0.6846,
        "total_length": 316164,
        "mean_pred_length": 23.654346850216967,
        "std_pred_length": 7.568990792084112,
        "median_pred_length": 22.0,
        "min_pred_length": 8,
        "max_pred_length": 116,
        "distinct-1": 0.0944035374046381,
        "vocab_size-1": 29847,
        "unique-1": 15959,
        "entropy-1": 9.781143056661001,
        "distinct-2": 0.4245800830916981,
        "vocab_size-2": 128562,
        "unique-2": 98825,
        "entropy-2": 15.072371254088116,
        "cond_entropy-2": 5.4667841905822705,
        "distinct-3": 0.7363491251831172,
        "vocab_size-3": 213123,
        "unique-3": 189521,
        "entropy-3": 17.092250485815224,
        "cond_entropy-3": 2.0568680057118893,
        "total_length-nopunct": 304459,
        "mean_pred_length-nopunct": 22.778617387400867,
        "std_pred_length-nopunct": 7.047878886695995,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 81,
        "distinct-1-nopunct": 0.09798035203426406,
        "vocab_size-1-nopunct": 29831,
        "unique-1-nopunct": 15957,
        "entropy-1-nopunct": 9.869914109786889,
        "distinct-2-nopunct": 0.4374856145630434,
        "vocab_size-2-nopunct": 127349,
        "unique-2-nopunct": 99087,
        "entropy-2-nopunct": 15.104268202711983,
        "cond_entropy-2-nopunct": 5.416578405889285,
        "distinct-3-nopunct": 0.7460959863463041,
        "vocab_size-3-nopunct": 207211,
        "unique-3-nopunct": 185293,
        "entropy-3-nopunct": 17.074453406983206,
        "cond_entropy-3-nopunct": 2.004035153359202,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_test.json",
        "nist": 2.4753357366008704,
        "bleu": 6.72703,
        "rouge1": {
            "precision": 0.29325,
            "recall": 0.27991,
            "fmeasure": 0.27501
        },
        "rouge2": {
            "precision": 0.10187,
            "recall": 0.0981,
            "fmeasure": 0.09601
        },
        "rougeL": {
            "precision": 0.23174,
            "recall": 0.22236,
            "fmeasure": 0.21797
        },
        "rougeLsum": {
            "precision": 0.23174,
            "recall": 0.22236,
            "fmeasure": 0.21797
        },
        "local_recall": {
            "1": 0.25249208352541963
        },
        "bertscore": {
            "precision": 0.8308,
            "recall": 0.83145,
            "f1": 0.83091
        },
        "bleurt": -0.54418,
        "meteor": 0.18382795615061562,
        "nubia": {
            "semantic_relation": 1.58304,
            "contradiction": 32.73779,
            "irrelevancy": 55.83828,
            "logical_agreement": 11.42393,
            "grammar_ref": 5.26998,
            "grammar_hyp": 5.34705,
            "nubia_score": 0.16828
        }
    },
    "mlsum_es_challenge_train_sample": {
        "predictions_file": "T5-base (Baseline)/mlsum_es_challenge_train_sample",
        "N": 500
    },
    "mlsum_es_challenge_validation_sample": {
        "predictions_file": "T5-base (Baseline)/mlsum_es_challenge_validation_sample",
        "N": 500
    },
    "mlsum_es_challenge_test_covid": {
        "predictions_file": "T5-base (Baseline)/mlsum_es_challenge_test_covid",
        "N": 1938,
        "msttr-100": 0.67116,
        "msttr-100_nopunct": 0.67301,
        "total_length": 44114,
        "mean_pred_length": 22.76264189886481,
        "std_pred_length": 6.420459399663184,
        "median_pred_length": 22.0,
        "min_pred_length": 10,
        "max_pred_length": 59,
        "distinct-1": 0.17024073990116517,
        "vocab_size-1": 7510,
        "unique-1": 4489,
        "entropy-1": 9.069913631567063,
        "distinct-2": 0.5427731411229135,
        "vocab_size-2": 22892,
        "unique-2": 18514,
        "entropy-2": 13.305681758348502,
        "cond_entropy-2": 4.376603611302251,
        "distinct-3": 0.8116705601670063,
        "vocab_size-3": 32660,
        "unique-3": 29763,
        "entropy-3": 14.656185157375706,
        "cond_entropy-3": 1.3577881742002134,
        "total_length-nopunct": 42838,
        "mean_pred_length-nopunct": 22.104231166150672,
        "std_pred_length-nopunct": 6.04587490411958,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 58,
        "distinct-1-nopunct": 0.17503151407628742,
        "vocab_size-1-nopunct": 7498,
        "unique-1-nopunct": 4487,
        "entropy-1-nopunct": 9.107421661655508,
        "distinct-2-nopunct": 0.5503667481662592,
        "vocab_size-2-nopunct": 22510,
        "unique-2-nopunct": 18303,
        "entropy-2-nopunct": 13.292148296780354,
        "cond_entropy-2-nopunct": 4.32924200903312,
        "distinct-3-nopunct": 0.8156408808582721,
        "vocab_size-3-nopunct": 31779,
        "unique-3-nopunct": 29034,
        "entropy-3-nopunct": 14.622129779752651,
        "cond_entropy-3-nopunct": 1.3357643095968679,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_challenge_test_covid.json",
        "nist": 2.205326938121258,
        "bleu": 5.49698,
        "rouge1": {
            "precision": 0.30829,
            "recall": 0.26485,
            "fmeasure": 0.27403
        },
        "rouge2": {
            "precision": 0.09883,
            "recall": 0.08495,
            "fmeasure": 0.08796
        },
        "rougeL": {
            "precision": 0.2392,
            "recall": 0.20697,
            "fmeasure": 0.21336
        },
        "rougeLsum": {
            "precision": 0.2392,
            "recall": 0.20697,
            "fmeasure": 0.21336
        },
        "local_recall": {
            "1": 0.2389461516231577
        },
        "bertscore": {
            "precision": 0.83368,
            "recall": 0.82964,
            "f1": 0.83147
        },
        "bleurt": -0.56724,
        "meteor": 0.17749271279627976,
        "nubia": {
            "semantic_relation": 1.53964,
            "contradiction": 30.80632,
            "irrelevancy": 59.08268,
            "logical_agreement": 10.111,
            "grammar_ref": 5.23427,
            "grammar_hyp": 5.38385,
            "nubia_score": 0.16178
        }
    },
    "wiki_lingua_spanish_es_validation": {
        "predictions_file": "T5-base (Baseline)/wiki_lingua_spanish_es_validation",
        "N": 11316,
        "msttr-100": 0.48343,
        "msttr-100_nopunct": 0.55093,
        "total_length": 268114,
        "mean_pred_length": 23.693354542241075,
        "std_pred_length": 18.272963540679275,
        "median_pred_length": 19.0,
        "min_pred_length": 2,
        "max_pred_length": 145,
        "distinct-1": 0.03697680837255794,
        "vocab_size-1": 9914,
        "unique-1": 3489,
        "entropy-1": 8.463490350994658,
        "distinct-2": 0.20296497636274427,
        "vocab_size-2": 52121,
        "unique-2": 30861,
        "entropy-2": 13.245933361737945,
        "cond_entropy-2": 4.536698518081359,
        "distinct-3": 0.459182343308267,
        "vocab_size-3": 112721,
        "unique-3": 84570,
        "entropy-3": 15.415576052549397,
        "cond_entropy-3": 2.1994648391559433,
        "total_length-nopunct": 223024,
        "mean_pred_length-nopunct": 19.70873100035348,
        "std_pred_length-nopunct": 15.71028345164056,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 122,
        "distinct-1-nopunct": 0.044371906162565464,
        "vocab_size-1-nopunct": 9896,
        "unique-1-nopunct": 3489,
        "entropy-1-nopunct": 9.335516373270808,
        "distinct-2-nopunct": 0.30235513065165226,
        "vocab_size-2-nopunct": 64011,
        "unique-2-nopunct": 43552,
        "entropy-2-nopunct": 13.878546652871155,
        "cond_entropy-2-nopunct": 4.720989487990187,
        "distinct-3-nopunct": 0.5715896842189309,
        "vocab_size-3-nopunct": 114542,
        "unique-3-nopunct": 92470,
        "entropy-3-nopunct": 15.859857574441255,
        "cond_entropy-3-nopunct": 2.0655971864620213,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_validation.json",
        "nist": 1.4348260047230856,
        "bleu": 5.98261,
        "rouge1": {
            "precision": 0.43789,
            "recall": 0.25389,
            "fmeasure": 0.29376
        },
        "rouge2": {
            "precision": 0.15519,
            "recall": 0.0891,
            "fmeasure": 0.10279
        },
        "rougeL": {
            "precision": 0.36583,
            "recall": 0.21439,
            "fmeasure": 0.24641
        },
        "rougeLsum": {
            "precision": 0.36583,
            "recall": 0.21439,
            "fmeasure": 0.24641
        },
        "local_recall": {
            "1": 0.20919521036409303
        },
        "sari": 66.48145,
        "bertscore": {
            "precision": 0.85627,
            "recall": 0.80816,
            "f1": 0.83078
        },
        "bleurt": -0.5195,
        "meteor": 0.11967970851484869,
        "nubia": {
            "semantic_relation": 2.71423,
            "contradiction": 17.13832,
            "irrelevancy": 38.77178,
            "logical_agreement": 44.0899,
            "grammar_ref": 3.95671,
            "grammar_hyp": 3.75745,
            "nubia_score": 0.37255
        }
    },
    "wiki_lingua_spanish_es_test": {
        "predictions_file": "T5-base (Baseline)/wiki_lingua_spanish_es_test",
        "N": 22632,
        "msttr-100": 0.48819,
        "msttr-100_nopunct": 0.55576,
        "total_length": 528650,
        "mean_pred_length": 23.358518911276068,
        "std_pred_length": 17.895089406959713,
        "median_pred_length": 19.0,
        "min_pred_length": 2,
        "max_pred_length": 151,
        "distinct-1": 0.025275702260474795,
        "vocab_size-1": 13362,
        "unique-1": 4461,
        "entropy-1": 8.529553813044947,
        "distinct-2": 0.1630851076443921,
        "vocab_size-2": 82524,
        "unique-2": 47707,
        "entropy-2": 13.501928306594396,
        "cond_entropy-2": 4.720451713888443,
        "distinct-3": 0.4077610853438039,
        "vocab_size-3": 197106,
        "unique-3": 143667,
        "entropy-3": 15.957122207428998,
        "cond_entropy-3": 2.481510745968135,
        "total_length-nopunct": 439951,
        "mean_pred_length-nopunct": 19.43933368681513,
        "std_pred_length-nopunct": 15.422852606382651,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 126,
        "distinct-1-nopunct": 0.030326104498000914,
        "vocab_size-1-nopunct": 13342,
        "unique-1-nopunct": 4461,
        "entropy-1-nopunct": 9.40845528135514,
        "distinct-2-nopunct": 0.2558354639975654,
        "vocab_size-2-nopunct": 106765,
        "unique-2-nopunct": 70706,
        "entropy-2-nopunct": 14.229683651444743,
        "cond_entropy-2-nopunct": 5.005003666625699,
        "distinct-3-nopunct": 0.5255923666288309,
        "vocab_size-3-nopunct": 207445,
        "unique-3-nopunct": 163805,
        "entropy-3-nopunct": 16.52563377470259,
        "cond_entropy-3-nopunct": 2.385538787532339,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_test.json",
        "nist": 1.328677507870605,
        "bleu": 5.91187,
        "rouge1": {
            "precision": 0.44078,
            "recall": 0.251,
            "fmeasure": 0.29299
        },
        "rouge2": {
            "precision": 0.15799,
            "recall": 0.08848,
            "fmeasure": 0.10331
        },
        "rougeL": {
            "precision": 0.3683,
            "recall": 0.2118,
            "fmeasure": 0.24568
        },
        "rougeLsum": {
            "precision": 0.3683,
            "recall": 0.2118,
            "fmeasure": 0.24568
        },
        "local_recall": {
            "1": 0.20736473621098975
        },
        "sari": 66.45337,
        "bertscore": {
            "precision": 0.85641,
            "recall": 0.80723,
            "f1": 0.83037
        },
        "bleurt": -0.52776,
        "meteor": 0.1180253575874078,
        "nubia": {
            "semantic_relation": 2.70119,
            "contradiction": 17.23416,
            "irrelevancy": 38.73065,
            "logical_agreement": 44.03519,
            "grammar_ref": 3.9494,
            "grammar_hyp": 3.77281,
            "nubia_score": 0.3704
        }
    },
    "wiki_lingua_turkish_tr_validation": {
        "predictions_file": "T5-base (Baseline)/wiki_lingua_turkish_tr_validation",
        "N": 449,
        "msttr-100": 0.59736,
        "msttr-100_nopunct": 0.66966,
        "total_length": 17604,
        "mean_pred_length": 39.207126948775056,
        "std_pred_length": 20.32901626828017,
        "median_pred_length": 36.0,
        "min_pred_length": 4,
        "max_pred_length": 116,
        "distinct-1": 0.1552488070892979,
        "vocab_size-1": 2733,
        "unique-1": 1326,
        "entropy-1": 8.368981080635566,
        "distinct-2": 0.5090644127076654,
        "vocab_size-2": 8733,
        "unique-2": 6198,
        "entropy-2": 12.200607581314667,
        "cond_entropy-2": 3.6958222123282067,
        "distinct-3": 0.7571531186400096,
        "vocab_size-3": 12649,
        "unique-3": 10518,
        "entropy-3": 13.338335622837276,
        "cond_entropy-3": 1.1469911561726367,
        "total_length-nopunct": 14892,
        "mean_pred_length-nopunct": 33.16703786191537,
        "std_pred_length-nopunct": 17.9523293623164,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 107,
        "distinct-1-nopunct": 0.18284985226967498,
        "vocab_size-1-nopunct": 2723,
        "unique-1-nopunct": 1324,
        "entropy-1-nopunct": 9.077154682976689,
        "distinct-2-nopunct": 0.6090839853216091,
        "vocab_size-2-nopunct": 8797,
        "unique-2-nopunct": 6716,
        "entropy-2-nopunct": 12.505958983580953,
        "cond_entropy-2-nopunct": 3.505178972761571,
        "distinct-3-nopunct": 0.8347148778047735,
        "vocab_size-3-nopunct": 11681,
        "unique-3-nopunct": 10138,
        "entropy-3-nopunct": 13.365493967925357,
        "cond_entropy-3-nopunct": 0.8740834726236115,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_validation.json",
        "nist": 2.791307528878602,
        "bleu": 12.58783,
        "rouge1": {
            "precision": 0.28223,
            "recall": 0.28057,
            "fmeasure": 0.25844
        },
        "rouge2": {
            "precision": 0.10543,
            "recall": 0.10684,
            "fmeasure": 0.09897
        },
        "rougeL": {
            "precision": 0.2316,
            "recall": 0.23035,
            "fmeasure": 0.21124
        },
        "rougeLsum": {
            "precision": 0.2316,
            "recall": 0.23035,
            "fmeasure": 0.21124
        },
        "local_recall": {
            "1": 0.25387806637806637
        },
        "sari": 66.6396,
        "bertscore": {
            "precision": 0.81147,
            "recall": 0.80757,
            "f1": 0.80892
        },
        "bleurt": -0.69427,
        "meteor": 0.13612653218511447,
        "nubia": {
            "semantic_relation": 2.1054,
            "contradiction": 28.47754,
            "irrelevancy": 51.7951,
            "logical_agreement": 19.72736,
            "grammar_ref": 3.85457,
            "grammar_hyp": 3.74872,
            "nubia_score": 0.23656
        }
    },
    "wiki_lingua_turkish_tr_test": {
        "predictions_file": "T5-base (Baseline)/wiki_lingua_turkish_tr_test",
        "N": 900,
        "msttr-100": 0.58552,
        "msttr-100_nopunct": 0.65649,
        "total_length": 35529,
        "mean_pred_length": 39.47666666666667,
        "std_pred_length": 19.327140099984902,
        "median_pred_length": 36.5,
        "min_pred_length": 3,
        "max_pred_length": 114,
        "distinct-1": 0.10405584170677475,
        "vocab_size-1": 3697,
        "unique-1": 1551,
        "entropy-1": 8.410382005476269,
        "distinct-2": 0.3954200236795749,
        "vocab_size-2": 13693,
        "unique-2": 8620,
        "entropy-2": 12.479808512590353,
        "cond_entropy-2": 3.9275596257411687,
        "distinct-3": 0.6324824335141866,
        "vocab_size-3": 21333,
        "unique-3": 16013,
        "entropy-3": 13.862920557306099,
        "cond_entropy-3": 1.3895272685505626,
        "total_length-nopunct": 29933,
        "mean_pred_length-nopunct": 33.25888888888889,
        "std_pred_length-nopunct": 16.75823773846061,
        "median_pred_length-nopunct": 31.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 103,
        "distinct-1-nopunct": 0.12300805131460261,
        "vocab_size-1-nopunct": 3682,
        "unique-1-nopunct": 1549,
        "entropy-1-nopunct": 9.140271399856475,
        "distinct-2-nopunct": 0.48861640202528156,
        "vocab_size-2-nopunct": 14186,
        "unique-2-nopunct": 9591,
        "entropy-2-nopunct": 12.91884127007567,
        "cond_entropy-2-nopunct": 3.8499247643996664,
        "distinct-3-nopunct": 0.7228166210500124,
        "vocab_size-3-nopunct": 20335,
        "unique-3-nopunct": 16024,
        "entropy-3-nopunct": 14.028889403673322,
        "cond_entropy-3-nopunct": 1.123802574401426,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_test.json",
        "nist": 2.921353078821274,
        "bleu": 12.26638,
        "rouge1": {
            "precision": 0.28955,
            "recall": 0.28574,
            "fmeasure": 0.26619
        },
        "rouge2": {
            "precision": 0.10908,
            "recall": 0.1064,
            "fmeasure": 0.1012
        },
        "rougeL": {
            "precision": 0.2344,
            "recall": 0.23147,
            "fmeasure": 0.21519
        },
        "rougeLsum": {
            "precision": 0.2344,
            "recall": 0.23147,
            "fmeasure": 0.21519
        },
        "local_recall": {
            "1": 0.26318401227049215
        },
        "sari": 66.06983,
        "bertscore": {
            "precision": 0.81393,
            "recall": 0.81144,
            "f1": 0.81215
        },
        "bleurt": -0.67459,
        "meteor": 0.1417949711840316,
        "nubia": {
            "semantic_relation": 2.17163,
            "contradiction": 29.69966,
            "irrelevancy": 49.89386,
            "logical_agreement": 20.40649,
            "grammar_ref": 3.87672,
            "grammar_hyp": 3.71725,
            "nubia_score": 0.24738
        }
    },
    "wiki_lingua_vietnamese_vi_validation": {
        "predictions_file": "T5-base (Baseline)/wiki_lingua_vietnamese_vi_validation",
        "N": 1957,
        "msttr-100": 0.36003,
        "msttr-100_nopunct": 0.40928,
        "total_length": 60277,
        "mean_pred_length": 30.80071538068472,
        "std_pred_length": 23.603091253233455,
        "median_pred_length": 23.0,
        "min_pred_length": 3,
        "max_pred_length": 128,
        "distinct-1": 0.04973704729830615,
        "vocab_size-1": 2998,
        "unique-1": 860,
        "entropy-1": 7.740577691845041,
        "distinct-2": 0.16659807956104253,
        "vocab_size-2": 9716,
        "unique-2": 4226,
        "entropy-2": 11.259538262125979,
        "cond_entropy-2": 3.3563060126734032,
        "distinct-3": 0.2952113975480368,
        "vocab_size-3": 16639,
        "unique-3": 9289,
        "entropy-3": 12.626196721947535,
        "cond_entropy-3": 1.401471057499272,
        "total_length-nopunct": 49735,
        "mean_pred_length-nopunct": 25.41389882473173,
        "std_pred_length-nopunct": 20.37590958312755,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 117,
        "distinct-1-nopunct": 0.06007841560269428,
        "vocab_size-1-nopunct": 2988,
        "unique-1-nopunct": 858,
        "entropy-1-nopunct": 8.514840291509024,
        "distinct-2-nopunct": 0.22349198375821508,
        "vocab_size-2-nopunct": 10678,
        "unique-2-nopunct": 5419,
        "entropy-2-nopunct": 11.682121801192018,
        "cond_entropy-2-nopunct": 3.2862721447590344,
        "distinct-3-nopunct": 0.36681870757949414,
        "vocab_size-3-nopunct": 16808,
        "unique-3-nopunct": 10364,
        "entropy-3-nopunct": 12.944334523780594,
        "cond_entropy-3-nopunct": 1.30651336212148,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_validation.json",
        "nist": 1.689624715393735,
        "bleu": 4.21716,
        "rouge1": {
            "precision": 0.21963,
            "recall": 0.16434,
            "fmeasure": 0.1703
        },
        "rouge2": {
            "precision": 0.04974,
            "recall": 0.0402,
            "fmeasure": 0.04015
        },
        "rougeL": {
            "precision": 0.18765,
            "recall": 0.14145,
            "fmeasure": 0.14575
        },
        "rougeLsum": {
            "precision": 0.18765,
            "recall": 0.14145,
            "fmeasure": 0.14575
        },
        "local_recall": {
            "1": 0.13190825913921142
        },
        "sari": 64.50713,
        "bertscore": {
            "precision": 0.80567,
            "recall": 0.76788,
            "f1": 0.78561
        },
        "bleurt": -0.7231,
        "meteor": 0.09043549454257185,
        "nubia": {
            "semantic_relation": 2.35677,
            "contradiction": 20.46762,
            "irrelevancy": 37.50107,
            "logical_agreement": 42.03131,
            "grammar_ref": 3.90718,
            "grammar_hyp": 2.8334,
            "nubia_score": 0.32984
        }
    },
    "wiki_lingua_vietnamese_vi_test": {
        "predictions_file": "T5-base (Baseline)/wiki_lingua_vietnamese_vi_test",
        "N": 3917,
        "msttr-100": 0.35849,
        "msttr-100_nopunct": 0.40666,
        "total_length": 121990,
        "mean_pred_length": 31.143732448302273,
        "std_pred_length": 23.753285134213474,
        "median_pred_length": 23.0,
        "min_pred_length": 3,
        "max_pred_length": 130,
        "distinct-1": 0.034420854168374454,
        "vocab_size-1": 4199,
        "unique-1": 1075,
        "entropy-1": 7.813215437641663,
        "distinct-2": 0.1285052467541267,
        "vocab_size-2": 15173,
        "unique-2": 6139,
        "entropy-2": 11.489756364469425,
        "cond_entropy-2": 3.511883242549451,
        "distinct-3": 0.24632082413539366,
        "vocab_size-3": 28119,
        "unique-3": 14860,
        "entropy-3": 13.055911368590115,
        "cond_entropy-3": 1.5964566283623303,
        "total_length-nopunct": 100431,
        "mean_pred_length-nopunct": 25.639775338269082,
        "std_pred_length-nopunct": 20.305018508126082,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 120,
        "distinct-1-nopunct": 0.04165048640360048,
        "vocab_size-1-nopunct": 4183,
        "unique-1-nopunct": 1071,
        "entropy-1-nopunct": 8.607400288833981,
        "distinct-2-nopunct": 0.1798599166960234,
        "vocab_size-2-nopunct": 17359,
        "unique-2-nopunct": 8270,
        "entropy-2-nopunct": 12.008911056978262,
        "cond_entropy-2-nopunct": 3.517224173814737,
        "distinct-3-nopunct": 0.31658693046211,
        "vocab_size-3-nopunct": 29315,
        "unique-3-nopunct": 17197,
        "entropy-3-nopunct": 13.476795849553799,
        "cond_entropy-3-nopunct": 1.515145523835827,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_test.json",
        "nist": 1.8091001344946465,
        "bleu": 4.49831,
        "rouge1": {
            "precision": 0.21938,
            "recall": 0.16624,
            "fmeasure": 0.17084
        },
        "rouge2": {
            "precision": 0.05222,
            "recall": 0.04194,
            "fmeasure": 0.04224
        },
        "rougeL": {
            "precision": 0.18773,
            "recall": 0.14321,
            "fmeasure": 0.14653
        },
        "rougeLsum": {
            "precision": 0.18773,
            "recall": 0.14321,
            "fmeasure": 0.14653
        },
        "local_recall": {
            "1": 0.1378146518845153
        },
        "sari": 64.1886,
        "bertscore": {
            "precision": 0.80558,
            "recall": 0.76842,
            "f1": 0.78585
        },
        "bleurt": -0.73012,
        "meteor": 0.09235141813086027,
        "nubia": {
            "semantic_relation": 2.36022,
            "contradiction": 20.27165,
            "irrelevancy": 37.45997,
            "logical_agreement": 42.26837,
            "grammar_ref": 3.92068,
            "grammar_hyp": 2.84035,
            "nubia_score": 0.33261
        }
    },
    "wiki_lingua_russian_ru_validation": {
        "predictions_file": "T5-base (Baseline)/wiki_lingua_russian_ru_validation",
        "N": 5288,
        "msttr-100": 0.33244,
        "msttr-100_nopunct": 0.37282,
        "total_length": 168554,
        "mean_pred_length": 31.87481089258699,
        "std_pred_length": 26.070503750626674,
        "median_pred_length": 24.0,
        "min_pred_length": 3,
        "max_pred_length": 149,
        "distinct-1": 0.025392455830179052,
        "vocab_size-1": 4280,
        "unique-1": 995,
        "entropy-1": 7.757767174296398,
        "distinct-2": 0.10144181887226979,
        "vocab_size-2": 16562,
        "unique-2": 6288,
        "entropy-2": 11.590018215690266,
        "cond_entropy-2": 3.676677835679842,
        "distinct-3": 0.2206193267416982,
        "vocab_size-3": 34853,
        "unique-3": 18097,
        "entropy-3": 13.253731619841771,
        "cond_entropy-3": 1.7034425419439208,
        "total_length-nopunct": 139684,
        "mean_pred_length-nopunct": 26.415279878971255,
        "std_pred_length-nopunct": 22.265885918906086,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 127,
        "distinct-1-nopunct": 0.030554680564703188,
        "vocab_size-1-nopunct": 4268,
        "unique-1-nopunct": 995,
        "entropy-1-nopunct": 8.514015545847974,
        "distinct-2-nopunct": 0.1520953004553707,
        "vocab_size-2-nopunct": 20441,
        "unique-2-nopunct": 9692,
        "entropy-2-nopunct": 12.076695295187156,
        "cond_entropy-2-nopunct": 3.6895571820712445,
        "distinct-3-nopunct": 0.29137621216346005,
        "vocab_size-3-nopunct": 37619,
        "unique-3-nopunct": 22064,
        "entropy-3-nopunct": 13.698604132782934,
        "cond_entropy-3-nopunct": 1.678590144537837,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_validation.json",
        "nist": 1.8256759175158697,
        "bleu": 4.09971,
        "rouge1": {
            "precision": 0.27233,
            "recall": 0.18864,
            "fmeasure": 0.20022
        },
        "rouge2": {
            "precision": 0.06733,
            "recall": 0.04769,
            "fmeasure": 0.05025
        },
        "rougeL": {
            "precision": 0.23444,
            "recall": 0.16452,
            "fmeasure": 0.17324
        },
        "rougeLsum": {
            "precision": 0.23444,
            "recall": 0.16452,
            "fmeasure": 0.17324
        },
        "local_recall": {
            "1": 0.1436327629558755
        },
        "sari": 66.46189,
        "bertscore": {
            "precision": 0.8176,
            "recall": 0.7747,
            "f1": 0.79475
        },
        "bleurt": -0.66245,
        "meteor": 0.09346771051865514,
        "nubia": {
            "semantic_relation": 2.50745,
            "contradiction": 21.64213,
            "irrelevancy": 34.8232,
            "logical_agreement": 43.53466,
            "grammar_ref": 3.95099,
            "grammar_hyp": 2.73847,
            "nubia_score": 0.38017
        }
    },
    "wiki_lingua_russian_ru_test": {
        "predictions_file": "T5-base (Baseline)/wiki_lingua_russian_ru_test",
        "N": 10580,
        "msttr-100": 0.34522,
        "msttr-100_nopunct": 0.38525,
        "total_length": 302240,
        "mean_pred_length": 28.56710775047259,
        "std_pred_length": 26.308819874066636,
        "median_pred_length": 20.0,
        "min_pred_length": 2,
        "max_pred_length": 142,
        "distinct-1": 0.018475383800952885,
        "vocab_size-1": 5584,
        "unique-1": 1226,
        "entropy-1": 7.782674465514784,
        "distinct-2": 0.08601110882534457,
        "vocab_size-2": 25086,
        "unique-2": 9462,
        "entropy-2": 11.735564102480076,
        "cond_entropy-2": 3.78031093909958,
        "distinct-3": 0.20008538494378825,
        "vocab_size-3": 56240,
        "unique-3": 28753,
        "entropy-3": 13.591646606775551,
        "cond_entropy-3": 1.9064368685230666,
        "total_length-nopunct": 252171,
        "mean_pred_length-nopunct": 23.83468809073724,
        "std_pred_length-nopunct": 22.374501651356816,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 123,
        "distinct-1-nopunct": 0.022080255065015406,
        "vocab_size-1-nopunct": 5568,
        "unique-1-nopunct": 1226,
        "entropy-1-nopunct": 8.495540803073554,
        "distinct-2-nopunct": 0.1298020207706413,
        "vocab_size-2-nopunct": 31359,
        "unique-2-nopunct": 14689,
        "entropy-2-nopunct": 12.243025234370537,
        "cond_entropy-2-nopunct": 3.898279024472645,
        "distinct-3-nopunct": 0.26389105327861756,
        "vocab_size-3-nopunct": 60962,
        "unique-3-nopunct": 35068,
        "entropy-3-nopunct": 14.0820892663757,
        "cond_entropy-3-nopunct": 1.9188671546542,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_test.json",
        "nist": 1.379617591865195,
        "bleu": 3.30056,
        "rouge1": {
            "precision": 0.26515,
            "recall": 0.1663,
            "fmeasure": 0.17958
        },
        "rouge2": {
            "precision": 0.06232,
            "recall": 0.04017,
            "fmeasure": 0.04244
        },
        "rougeL": {
            "precision": 0.22835,
            "recall": 0.14511,
            "fmeasure": 0.15532
        },
        "rougeLsum": {
            "precision": 0.22835,
            "recall": 0.14511,
            "fmeasure": 0.15532
        },
        "local_recall": {
            "1": 0.12788707655584997
        },
        "sari": 65.54592,
        "bertscore": {
            "precision": 0.80898,
            "recall": 0.76584,
            "f1": 0.78598
        },
        "bleurt": -0.75242,
        "meteor": 0.07989991134584273,
        "nubia": {
            "semantic_relation": 2.37184,
            "contradiction": 24.55898,
            "irrelevancy": 35.77477,
            "logical_agreement": 39.66625,
            "grammar_ref": 3.95647,
            "grammar_hyp": 2.94218,
            "nubia_score": 0.35527
        }
    },
    "dart_validation": {
        "predictions_file": "T5-base (Baseline)/dart_validation",
        "N": 2768,
        "msttr-100": 0.44123,
        "msttr-100_nopunct": 0.44805,
        "total_length": 62498,
        "mean_pred_length": 22.578757225433527,
        "std_pred_length": 9.469887454331646,
        "median_pred_length": 23.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.05587378796121476,
        "vocab_size-1": 3492,
        "unique-1": 1555,
        "entropy-1": 7.610699445471023,
        "distinct-2": 0.1762598359283442,
        "vocab_size-2": 10528,
        "unique-2": 6344,
        "entropy-2": 10.35163724130939,
        "cond_entropy-2": 2.5700861493970333,
        "distinct-3": 0.27126856500825114,
        "vocab_size-3": 15452,
        "unique-3": 10579,
        "entropy-3": 11.503998773904192,
        "cond_entropy-3": 1.2092940945071302,
        "total_length-nopunct": 56320,
        "mean_pred_length-nopunct": 20.346820809248555,
        "std_pred_length-nopunct": 8.650801276478157,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 67,
        "distinct-1-nopunct": 0.06168323863636364,
        "vocab_size-1-nopunct": 3474,
        "unique-1-nopunct": 1549,
        "entropy-1-nopunct": 7.806214559665812,
        "distinct-2-nopunct": 0.1803854197789065,
        "vocab_size-2-nopunct": 9660,
        "unique-2-nopunct": 5924,
        "entropy-2-nopunct": 10.230656711627192,
        "cond_entropy-2-nopunct": 2.545568502526324,
        "distinct-3-nopunct": 0.27262523629489605,
        "vocab_size-3-nopunct": 13845,
        "unique-3-nopunct": 9554,
        "entropy-3-nopunct": 11.390995869011485,
        "cond_entropy-3-nopunct": 1.2152637361973362,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/dart_validation.json",
        "nist": 0.5859510114888932,
        "bleu": 0.0053,
        "rouge1": {
            "precision": 0.03909,
            "recall": 0.75323,
            "fmeasure": 0.07354
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.03909,
            "recall": 0.75323,
            "fmeasure": 0.07354
        },
        "rougeLsum": {
            "precision": 0.03909,
            "recall": 0.75323,
            "fmeasure": 0.07354
        },
        "local_recall": {
            "1": 0.03126724296487033,
            "2": 0.01752980066112391,
            "3": 0.014144271570014143,
            "4": 0.028218369605311693,
            "5": 0.04570303958014432,
            "6": 0.0628775398132894,
            "7": 0.08154362416107383,
            "8": 0.0939516129032258,
            "9": 0.10259301014656144,
            "10": 0.1145374449339207,
            "11": 0.10867178924259056,
            "12": 0.12324492979719189,
            "13": 0.09190371991247265,
            "14": 0.06956521739130435,
            "15": 0.08018867924528301,
            "16": 0.11805555555555555,
            "17": 0.038461538461538464,
            "18": 0.08,
            "19": 0.08333333333333333,
            "20": 0.11764705882352941,
            "21": 0.08695652173913043,
            "22": 0.0,
            "23": 0.06666666666666667,
            "24": 0.0,
            "25": 0.3333333333333333,
            "26": 0.25,
            "27": 0,
            "28": 0.0,
            "29": 0.5,
            "30": 0.0,
            "31": 0.0,
            "32": 0,
            "33": 0,
            "34": 0,
            "35": 0,
            "36": 0,
            "37": 0.0,
            "38": 0,
            "39": 0,
            "40": 0,
            "41": 0,
            "42": 0,
            "43": 0,
            "44": 0,
            "45": 0,
            "46": 0,
            "47": 0,
            "48": 0,
            "49": 0,
            "50": 0,
            "51": 0,
            "52": 0,
            "53": 0,
            "54": 0,
            "55": 0,
            "56": 0,
            "57": 0,
            "58": 0,
            "59": 0,
            "60": 0,
            "61": 0,
            "62": 0,
            "63": 0,
            "64": 0,
            "65": 0,
            "66": 0,
            "67": 0,
            "68": 0,
            "69": 0,
            "70": 0,
            "71": 0,
            "72": 0
        },
        "bertscore": {
            "precision": 0.912,
            "recall": 0.90703,
            "f1": 0.90922
        },
        "bleurt": 0.23969,
        "meteor": 0.07852200482191254,
        "nubia": {
            "semantic_relation": 4.32734,
            "contradiction": 5.8855,
            "irrelevancy": 18.14387,
            "logical_agreement": 75.97063,
            "grammar_ref": 4.89251,
            "grammar_hyp": 4.57368,
            "nubia_score": 0.78445
        }
    },
    "dart_test": {
        "predictions_file": "T5-base (Baseline)/dart_test",
        "N": 6959
    },
    "web_nlg_ru_validation": {
        "predictions_file": "T5-base (Baseline)/web_nlg_ru_validation",
        "N": 790,
        "msttr-100": 0.36747,
        "msttr-100_nopunct": 0.35691,
        "total_length": 33628,
        "mean_pred_length": 42.56708860759494,
        "std_pred_length": 18.501725691110835,
        "median_pred_length": 43.0,
        "min_pred_length": 9,
        "max_pred_length": 80,
        "distinct-1": 0.03946116331628405,
        "vocab_size-1": 1327,
        "unique-1": 422,
        "entropy-1": 5.5743129975734425,
        "distinct-2": 0.10871551251598757,
        "vocab_size-2": 3570,
        "unique-2": 1415,
        "entropy-2": 9.633190659310378,
        "cond_entropy-2": 4.053916357650734,
        "distinct-3": 0.19873315027458813,
        "vocab_size-3": 6369,
        "unique-3": 2985,
        "entropy-3": 11.108964701907274,
        "cond_entropy-3": 1.5156617131896273,
        "total_length-nopunct": 31108,
        "mean_pred_length-nopunct": 39.37721518987342,
        "std_pred_length-nopunct": 17.38927320576048,
        "median_pred_length-nopunct": 39.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 76,
        "distinct-1-nopunct": 0.042432814710042434,
        "vocab_size-1-nopunct": 1320,
        "unique-1-nopunct": 422,
        "entropy-1-nopunct": 5.462236225836057,
        "distinct-2-nopunct": 0.10812058842931592,
        "vocab_size-2-nopunct": 3278,
        "unique-2-nopunct": 1288,
        "entropy-2-nopunct": 9.493950755463642,
        "cond_entropy-2-nopunct": 4.10900359925366,
        "distinct-3-nopunct": 0.19842183690056894,
        "vocab_size-3-nopunct": 5859,
        "unique-3-nopunct": 2806,
        "entropy-3-nopunct": 10.954878234249856,
        "cond_entropy-3-nopunct": 1.5039258257045887,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_validation.json",
        "nist": 0.945114037684433,
        "bleu": 1.26117,
        "rouge1": {
            "precision": 0.31164,
            "recall": 0.2917,
            "fmeasure": 0.29754
        },
        "rouge2": {
            "precision": 0.10614,
            "recall": 0.09643,
            "fmeasure": 0.09909
        },
        "rougeL": {
            "precision": 0.29855,
            "recall": 0.27975,
            "fmeasure": 0.28508
        },
        "rougeLsum": {
            "precision": 0.29855,
            "recall": 0.27975,
            "fmeasure": 0.28508
        },
        "local_recall": {
            "1": 0.06886354034643008,
            "2": 0.17251051893408134,
            "3": 0.23348132671715852,
            "4": 0.24242424242424243,
            "5": 0.2692307692307692,
            "6": 0.3,
            "7": 0.125,
            "8": 0,
            "9": 0.0
        },
        "bertscore": {
            "precision": 0.85462,
            "recall": 0.86571,
            "f1": 0.85958
        },
        "bleurt": -0.50032,
        "meteor": 0.10678380314817802,
        "nubia": {
            "semantic_relation": 3.25446,
            "contradiction": 35.04762,
            "irrelevancy": 16.95082,
            "logical_agreement": 48.00156,
            "grammar_ref": 2.60252,
            "grammar_hyp": 2.58293,
            "nubia_score": 0.15196
        }
    }
}
